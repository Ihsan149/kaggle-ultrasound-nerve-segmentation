I0624 12:23:13.160629 17113 caffe.cpp:185] Using GPUs 1
I0624 12:23:13.177649 17113 caffe.cpp:190] GPU 1: GeForce GTX TITAN X
I0624 12:23:13.530556 17113 solver.cpp:48] Initializing solver from parameters: 
test_iter: 16
test_interval: 100
base_lr: 0.01
display: 20
max_iter: 1000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 1000
snapshot: 500
snapshot_prefix: "data/models/segnet"
solver_mode: GPU
device_id: 1
net: "models/segnet/train_val.prototxt"
test_initialization: true
iter_size: 1
I0624 12:23:13.530695 17113 solver.cpp:91] Creating training net from net file: models/segnet/train_val.prototxt
I0624 12:23:13.532145 17113 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0624 12:23:13.532594 17113 net.cpp:49] Initializing net from parameters: 
name: "segnet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "DenseImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 224
    mean_value: 100
  }
  dense_image_data_param {
    source: "data/train.txt"
    batch_size: 32
    shuffle: true
    new_height: 224
    new_width: 310
    is_color: false
    root_folder: "data/raw/train/"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 14
    upsample_w: 14
  }
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2_D"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2_D"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1_D"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1_D"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 28
    upsample_w: 28
  }
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2_D"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2_D"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1_D"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1_D"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
    upsample_h: 56
    upsample_w: 56
  }
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn3_2_D"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2_D"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1_D"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1_D"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
    upsample_h: 112
    upsample_w: 112
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2_D"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2_D"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1_D"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1_D"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
    upsample_h: 224
    upsample_w: 224
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2_D"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2_D"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2
    bias_term: true
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "accuracy"
}
I0624 12:23:13.533007 17113 layer_factory.hpp:77] Creating layer data
I0624 12:23:13.533047 17113 net.cpp:91] Creating Layer data
I0624 12:23:13.533056 17113 net.cpp:399] data -> data
I0624 12:23:13.533083 17113 net.cpp:399] data -> label
I0624 12:23:13.533524 17113 dense_image_data_layer.cpp:38] Opening file data/train.txt
I0624 12:23:13.537318 17113 dense_image_data_layer.cpp:48] Shuffling data
I0624 12:23:13.537824 17113 dense_image_data_layer.cpp:53] A total of 4930 examples.
I0624 12:23:13.782735 17113 dense_image_data_layer.cpp:92] output data size: 1,1,224,224
I0624 12:23:13.784548 17113 net.cpp:141] Setting up data
I0624 12:23:13.784569 17113 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 12:23:13.784577 17113 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 12:23:13.784581 17113 net.cpp:156] Memory required for data: 401408
I0624 12:23:13.784591 17113 layer_factory.hpp:77] Creating layer label_data_1_split
I0624 12:23:13.784627 17113 net.cpp:91] Creating Layer label_data_1_split
I0624 12:23:13.784636 17113 net.cpp:425] label_data_1_split <- label
I0624 12:23:13.784649 17113 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0624 12:23:13.784662 17113 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0624 12:23:13.784729 17113 net.cpp:141] Setting up label_data_1_split
I0624 12:23:13.784739 17113 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 12:23:13.784744 17113 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 12:23:13.784747 17113 net.cpp:156] Memory required for data: 802816
I0624 12:23:13.784751 17113 layer_factory.hpp:77] Creating layer conv1_1
I0624 12:23:13.784771 17113 net.cpp:91] Creating Layer conv1_1
I0624 12:23:13.784780 17113 net.cpp:425] conv1_1 <- data
I0624 12:23:13.784790 17113 net.cpp:399] conv1_1 -> conv1_1
I0624 12:23:13.972441 17113 net.cpp:141] Setting up conv1_1
I0624 12:23:13.972467 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:13.972471 17113 net.cpp:156] Memory required for data: 7225344
I0624 12:23:13.972486 17113 layer_factory.hpp:77] Creating layer bn1_1
I0624 12:23:13.972504 17113 net.cpp:91] Creating Layer bn1_1
I0624 12:23:13.972510 17113 net.cpp:425] bn1_1 <- conv1_1
I0624 12:23:13.972518 17113 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0624 12:23:13.972721 17113 net.cpp:141] Setting up bn1_1
I0624 12:23:13.972733 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:13.972735 17113 net.cpp:156] Memory required for data: 13647872
I0624 12:23:13.972750 17113 layer_factory.hpp:77] Creating layer scale1_1
I0624 12:23:13.972765 17113 net.cpp:91] Creating Layer scale1_1
I0624 12:23:13.972774 17113 net.cpp:425] scale1_1 <- conv1_1
I0624 12:23:13.972782 17113 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0624 12:23:13.972829 17113 layer_factory.hpp:77] Creating layer scale1_1
I0624 12:23:13.973011 17113 net.cpp:141] Setting up scale1_1
I0624 12:23:13.973021 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:13.973026 17113 net.cpp:156] Memory required for data: 20070400
I0624 12:23:13.973036 17113 layer_factory.hpp:77] Creating layer relu1_1
I0624 12:23:13.973044 17113 net.cpp:91] Creating Layer relu1_1
I0624 12:23:13.973049 17113 net.cpp:425] relu1_1 <- conv1_1
I0624 12:23:13.973057 17113 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0624 12:23:13.973343 17113 net.cpp:141] Setting up relu1_1
I0624 12:23:13.973356 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:13.973361 17113 net.cpp:156] Memory required for data: 26492928
I0624 12:23:13.973364 17113 layer_factory.hpp:77] Creating layer conv1_2
I0624 12:23:13.973379 17113 net.cpp:91] Creating Layer conv1_2
I0624 12:23:13.973384 17113 net.cpp:425] conv1_2 <- conv1_1
I0624 12:23:13.973393 17113 net.cpp:399] conv1_2 -> conv1_2
I0624 12:23:13.975051 17113 net.cpp:141] Setting up conv1_2
I0624 12:23:13.975065 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:13.975069 17113 net.cpp:156] Memory required for data: 32915456
I0624 12:23:13.975077 17113 layer_factory.hpp:77] Creating layer bn1_2
I0624 12:23:13.975085 17113 net.cpp:91] Creating Layer bn1_2
I0624 12:23:13.975090 17113 net.cpp:425] bn1_2 <- conv1_2
I0624 12:23:13.975100 17113 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0624 12:23:13.975303 17113 net.cpp:141] Setting up bn1_2
I0624 12:23:13.975314 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:13.975318 17113 net.cpp:156] Memory required for data: 39337984
I0624 12:23:13.975330 17113 layer_factory.hpp:77] Creating layer scale1_2
I0624 12:23:13.975359 17113 net.cpp:91] Creating Layer scale1_2
I0624 12:23:13.975365 17113 net.cpp:425] scale1_2 <- conv1_2
I0624 12:23:13.975373 17113 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0624 12:23:13.975419 17113 layer_factory.hpp:77] Creating layer scale1_2
I0624 12:23:13.975600 17113 net.cpp:141] Setting up scale1_2
I0624 12:23:13.975610 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:13.975615 17113 net.cpp:156] Memory required for data: 45760512
I0624 12:23:13.975622 17113 layer_factory.hpp:77] Creating layer relu1_2
I0624 12:23:13.975630 17113 net.cpp:91] Creating Layer relu1_2
I0624 12:23:13.975633 17113 net.cpp:425] relu1_2 <- conv1_2
I0624 12:23:13.975641 17113 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0624 12:23:13.975791 17113 net.cpp:141] Setting up relu1_2
I0624 12:23:13.975802 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:13.975806 17113 net.cpp:156] Memory required for data: 52183040
I0624 12:23:13.975811 17113 layer_factory.hpp:77] Creating layer pool1
I0624 12:23:13.975816 17113 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 12:23:13.975823 17113 net.cpp:91] Creating Layer pool1
I0624 12:23:13.975827 17113 net.cpp:425] pool1 <- conv1_2
I0624 12:23:13.975834 17113 net.cpp:399] pool1 -> pool1
I0624 12:23:13.975844 17113 net.cpp:399] pool1 -> pool1_mask
I0624 12:23:13.975903 17113 net.cpp:141] Setting up pool1
I0624 12:23:13.975913 17113 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:23:13.975919 17113 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:23:13.975921 17113 net.cpp:156] Memory required for data: 55394304
I0624 12:23:13.975925 17113 layer_factory.hpp:77] Creating layer conv2_1
I0624 12:23:13.975937 17113 net.cpp:91] Creating Layer conv2_1
I0624 12:23:13.975942 17113 net.cpp:425] conv2_1 <- pool1
I0624 12:23:13.975951 17113 net.cpp:399] conv2_1 -> conv2_1
I0624 12:23:13.977628 17113 net.cpp:141] Setting up conv2_1
I0624 12:23:13.977643 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:13.977648 17113 net.cpp:156] Memory required for data: 58605568
I0624 12:23:13.977653 17113 layer_factory.hpp:77] Creating layer bn2_1
I0624 12:23:13.977665 17113 net.cpp:91] Creating Layer bn2_1
I0624 12:23:13.977670 17113 net.cpp:425] bn2_1 <- conv2_1
I0624 12:23:13.977676 17113 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0624 12:23:13.977926 17113 net.cpp:141] Setting up bn2_1
I0624 12:23:13.977936 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:13.977941 17113 net.cpp:156] Memory required for data: 61816832
I0624 12:23:13.977951 17113 layer_factory.hpp:77] Creating layer scale2_1
I0624 12:23:13.977962 17113 net.cpp:91] Creating Layer scale2_1
I0624 12:23:13.977967 17113 net.cpp:425] scale2_1 <- conv2_1
I0624 12:23:13.977974 17113 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0624 12:23:13.978025 17113 layer_factory.hpp:77] Creating layer scale2_1
I0624 12:23:13.978144 17113 net.cpp:141] Setting up scale2_1
I0624 12:23:13.978154 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:13.978158 17113 net.cpp:156] Memory required for data: 65028096
I0624 12:23:13.978171 17113 layer_factory.hpp:77] Creating layer relu2_1
I0624 12:23:13.978181 17113 net.cpp:91] Creating Layer relu2_1
I0624 12:23:13.978185 17113 net.cpp:425] relu2_1 <- conv2_1
I0624 12:23:13.978193 17113 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0624 12:23:13.978469 17113 net.cpp:141] Setting up relu2_1
I0624 12:23:13.978482 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:13.978487 17113 net.cpp:156] Memory required for data: 68239360
I0624 12:23:13.978490 17113 layer_factory.hpp:77] Creating layer conv2_2
I0624 12:23:13.978503 17113 net.cpp:91] Creating Layer conv2_2
I0624 12:23:13.978508 17113 net.cpp:425] conv2_2 <- conv2_1
I0624 12:23:13.978518 17113 net.cpp:399] conv2_2 -> conv2_2
I0624 12:23:13.979557 17113 net.cpp:141] Setting up conv2_2
I0624 12:23:13.979573 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:13.979578 17113 net.cpp:156] Memory required for data: 71450624
I0624 12:23:13.979595 17113 layer_factory.hpp:77] Creating layer bn2_2
I0624 12:23:13.979607 17113 net.cpp:91] Creating Layer bn2_2
I0624 12:23:13.979611 17113 net.cpp:425] bn2_2 <- conv2_2
I0624 12:23:13.979620 17113 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0624 12:23:13.979789 17113 net.cpp:141] Setting up bn2_2
I0624 12:23:13.979801 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:13.979805 17113 net.cpp:156] Memory required for data: 74661888
I0624 12:23:13.979816 17113 layer_factory.hpp:77] Creating layer scale2_2
I0624 12:23:13.979826 17113 net.cpp:91] Creating Layer scale2_2
I0624 12:23:13.979830 17113 net.cpp:425] scale2_2 <- conv2_2
I0624 12:23:13.979840 17113 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0624 12:23:13.979885 17113 layer_factory.hpp:77] Creating layer scale2_2
I0624 12:23:13.980001 17113 net.cpp:141] Setting up scale2_2
I0624 12:23:13.980011 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:13.980015 17113 net.cpp:156] Memory required for data: 77873152
I0624 12:23:13.980023 17113 layer_factory.hpp:77] Creating layer relu2_2
I0624 12:23:13.980031 17113 net.cpp:91] Creating Layer relu2_2
I0624 12:23:13.980034 17113 net.cpp:425] relu2_2 <- conv2_2
I0624 12:23:13.980041 17113 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0624 12:23:13.980322 17113 net.cpp:141] Setting up relu2_2
I0624 12:23:13.980335 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:13.980340 17113 net.cpp:156] Memory required for data: 81084416
I0624 12:23:13.980345 17113 layer_factory.hpp:77] Creating layer pool2
I0624 12:23:13.980348 17113 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 12:23:13.980355 17113 net.cpp:91] Creating Layer pool2
I0624 12:23:13.980360 17113 net.cpp:425] pool2 <- conv2_2
I0624 12:23:13.980370 17113 net.cpp:399] pool2 -> pool2
I0624 12:23:13.980378 17113 net.cpp:399] pool2 -> pool2_mask
I0624 12:23:13.980425 17113 net.cpp:141] Setting up pool2
I0624 12:23:13.980434 17113 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:23:13.980440 17113 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:23:13.980443 17113 net.cpp:156] Memory required for data: 82690048
I0624 12:23:13.980448 17113 layer_factory.hpp:77] Creating layer conv3_1
I0624 12:23:13.980461 17113 net.cpp:91] Creating Layer conv3_1
I0624 12:23:13.980466 17113 net.cpp:425] conv3_1 <- pool2
I0624 12:23:13.980474 17113 net.cpp:399] conv3_1 -> conv3_1
I0624 12:23:13.982422 17113 net.cpp:141] Setting up conv3_1
I0624 12:23:13.982436 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:13.982440 17113 net.cpp:156] Memory required for data: 84295680
I0624 12:23:13.982447 17113 layer_factory.hpp:77] Creating layer bn3_1
I0624 12:23:13.982457 17113 net.cpp:91] Creating Layer bn3_1
I0624 12:23:13.982463 17113 net.cpp:425] bn3_1 <- conv3_1
I0624 12:23:13.982470 17113 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0624 12:23:13.983237 17113 net.cpp:141] Setting up bn3_1
I0624 12:23:13.983249 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:13.983253 17113 net.cpp:156] Memory required for data: 85901312
I0624 12:23:13.983263 17113 layer_factory.hpp:77] Creating layer scale3_1
I0624 12:23:13.983273 17113 net.cpp:91] Creating Layer scale3_1
I0624 12:23:13.983278 17113 net.cpp:425] scale3_1 <- conv3_1
I0624 12:23:13.983286 17113 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0624 12:23:13.983335 17113 layer_factory.hpp:77] Creating layer scale3_1
I0624 12:23:13.983443 17113 net.cpp:141] Setting up scale3_1
I0624 12:23:13.983453 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:13.983458 17113 net.cpp:156] Memory required for data: 87506944
I0624 12:23:13.983465 17113 layer_factory.hpp:77] Creating layer relu3_1
I0624 12:23:13.983472 17113 net.cpp:91] Creating Layer relu3_1
I0624 12:23:13.983476 17113 net.cpp:425] relu3_1 <- conv3_1
I0624 12:23:13.983482 17113 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0624 12:23:13.983639 17113 net.cpp:141] Setting up relu3_1
I0624 12:23:13.983650 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:13.983666 17113 net.cpp:156] Memory required for data: 89112576
I0624 12:23:13.983671 17113 layer_factory.hpp:77] Creating layer conv3_2
I0624 12:23:13.983686 17113 net.cpp:91] Creating Layer conv3_2
I0624 12:23:13.983692 17113 net.cpp:425] conv3_2 <- conv3_1
I0624 12:23:13.983700 17113 net.cpp:399] conv3_2 -> conv3_2
I0624 12:23:13.985590 17113 net.cpp:141] Setting up conv3_2
I0624 12:23:13.985607 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:13.985611 17113 net.cpp:156] Memory required for data: 90718208
I0624 12:23:13.985616 17113 layer_factory.hpp:77] Creating layer bn3_2
I0624 12:23:13.985621 17113 net.cpp:91] Creating Layer bn3_2
I0624 12:23:13.985625 17113 net.cpp:425] bn3_2 <- conv3_2
I0624 12:23:13.985630 17113 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0624 12:23:13.985800 17113 net.cpp:141] Setting up bn3_2
I0624 12:23:13.985808 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:13.985810 17113 net.cpp:156] Memory required for data: 92323840
I0624 12:23:13.985821 17113 layer_factory.hpp:77] Creating layer scale3_2
I0624 12:23:13.985828 17113 net.cpp:91] Creating Layer scale3_2
I0624 12:23:13.985836 17113 net.cpp:425] scale3_2 <- conv3_2
I0624 12:23:13.985839 17113 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0624 12:23:13.985872 17113 layer_factory.hpp:77] Creating layer scale3_2
I0624 12:23:13.985962 17113 net.cpp:141] Setting up scale3_2
I0624 12:23:13.985970 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:13.985972 17113 net.cpp:156] Memory required for data: 93929472
I0624 12:23:13.985976 17113 layer_factory.hpp:77] Creating layer relu3_2
I0624 12:23:13.985983 17113 net.cpp:91] Creating Layer relu3_2
I0624 12:23:13.985986 17113 net.cpp:425] relu3_2 <- conv3_2
I0624 12:23:13.985990 17113 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0624 12:23:13.986270 17113 net.cpp:141] Setting up relu3_2
I0624 12:23:13.986280 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:13.986284 17113 net.cpp:156] Memory required for data: 95535104
I0624 12:23:13.986285 17113 layer_factory.hpp:77] Creating layer pool3
I0624 12:23:13.986289 17113 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 12:23:13.986294 17113 net.cpp:91] Creating Layer pool3
I0624 12:23:13.986297 17113 net.cpp:425] pool3 <- conv3_2
I0624 12:23:13.986301 17113 net.cpp:399] pool3 -> pool3
I0624 12:23:13.986307 17113 net.cpp:399] pool3 -> pool3_mask
I0624 12:23:13.986345 17113 net.cpp:141] Setting up pool3
I0624 12:23:13.986351 17113 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:23:13.986353 17113 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:23:13.986356 17113 net.cpp:156] Memory required for data: 96337920
I0624 12:23:13.986357 17113 layer_factory.hpp:77] Creating layer conv4_1
I0624 12:23:13.986366 17113 net.cpp:91] Creating Layer conv4_1
I0624 12:23:13.986367 17113 net.cpp:425] conv4_1 <- pool3
I0624 12:23:13.986372 17113 net.cpp:399] conv4_1 -> conv4_1
I0624 12:23:13.989696 17113 net.cpp:141] Setting up conv4_1
I0624 12:23:13.989711 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:13.989713 17113 net.cpp:156] Memory required for data: 97140736
I0624 12:23:13.989718 17113 layer_factory.hpp:77] Creating layer bn4_1
I0624 12:23:13.989725 17113 net.cpp:91] Creating Layer bn4_1
I0624 12:23:13.989728 17113 net.cpp:425] bn4_1 <- conv4_1
I0624 12:23:13.989732 17113 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0624 12:23:13.989893 17113 net.cpp:141] Setting up bn4_1
I0624 12:23:13.989902 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:13.989903 17113 net.cpp:156] Memory required for data: 97943552
I0624 12:23:13.989909 17113 layer_factory.hpp:77] Creating layer scale4_1
I0624 12:23:13.989915 17113 net.cpp:91] Creating Layer scale4_1
I0624 12:23:13.989918 17113 net.cpp:425] scale4_1 <- conv4_1
I0624 12:23:13.989922 17113 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0624 12:23:13.989956 17113 layer_factory.hpp:77] Creating layer scale4_1
I0624 12:23:13.990051 17113 net.cpp:141] Setting up scale4_1
I0624 12:23:13.990067 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:13.990070 17113 net.cpp:156] Memory required for data: 98746368
I0624 12:23:13.990074 17113 layer_factory.hpp:77] Creating layer relu4_1
I0624 12:23:13.990083 17113 net.cpp:91] Creating Layer relu4_1
I0624 12:23:13.990088 17113 net.cpp:425] relu4_1 <- conv4_1
I0624 12:23:13.990092 17113 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0624 12:23:13.990367 17113 net.cpp:141] Setting up relu4_1
I0624 12:23:13.990378 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:13.990381 17113 net.cpp:156] Memory required for data: 99549184
I0624 12:23:13.990384 17113 layer_factory.hpp:77] Creating layer conv4_2
I0624 12:23:13.990397 17113 net.cpp:91] Creating Layer conv4_2
I0624 12:23:13.990401 17113 net.cpp:425] conv4_2 <- conv4_1
I0624 12:23:13.990404 17113 net.cpp:399] conv4_2 -> conv4_2
I0624 12:23:13.995945 17113 net.cpp:141] Setting up conv4_2
I0624 12:23:13.995959 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:13.995961 17113 net.cpp:156] Memory required for data: 100352000
I0624 12:23:13.995965 17113 layer_factory.hpp:77] Creating layer bn4_2
I0624 12:23:13.995972 17113 net.cpp:91] Creating Layer bn4_2
I0624 12:23:13.995975 17113 net.cpp:425] bn4_2 <- conv4_2
I0624 12:23:13.995980 17113 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0624 12:23:13.996145 17113 net.cpp:141] Setting up bn4_2
I0624 12:23:13.996151 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:13.996155 17113 net.cpp:156] Memory required for data: 101154816
I0624 12:23:13.996160 17113 layer_factory.hpp:77] Creating layer scale4_2
I0624 12:23:13.996165 17113 net.cpp:91] Creating Layer scale4_2
I0624 12:23:13.996167 17113 net.cpp:425] scale4_2 <- conv4_2
I0624 12:23:13.996172 17113 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0624 12:23:13.996207 17113 layer_factory.hpp:77] Creating layer scale4_2
I0624 12:23:13.996299 17113 net.cpp:141] Setting up scale4_2
I0624 12:23:13.996309 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:13.996311 17113 net.cpp:156] Memory required for data: 101957632
I0624 12:23:13.996315 17113 layer_factory.hpp:77] Creating layer relu4_2
I0624 12:23:13.996320 17113 net.cpp:91] Creating Layer relu4_2
I0624 12:23:13.996322 17113 net.cpp:425] relu4_2 <- conv4_2
I0624 12:23:13.996328 17113 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0624 12:23:13.996471 17113 net.cpp:141] Setting up relu4_2
I0624 12:23:13.996480 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:13.996482 17113 net.cpp:156] Memory required for data: 102760448
I0624 12:23:13.996485 17113 layer_factory.hpp:77] Creating layer pool4
I0624 12:23:13.996487 17113 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 12:23:13.996493 17113 net.cpp:91] Creating Layer pool4
I0624 12:23:13.996496 17113 net.cpp:425] pool4 <- conv4_2
I0624 12:23:13.996500 17113 net.cpp:399] pool4 -> pool4
I0624 12:23:13.996505 17113 net.cpp:399] pool4 -> pool4_mask
I0624 12:23:13.996543 17113 net.cpp:141] Setting up pool4
I0624 12:23:13.996549 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:13.996552 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:13.996554 17113 net.cpp:156] Memory required for data: 103161856
I0624 12:23:13.996556 17113 layer_factory.hpp:77] Creating layer conv5_1
I0624 12:23:13.996563 17113 net.cpp:91] Creating Layer conv5_1
I0624 12:23:13.996567 17113 net.cpp:425] conv5_1 <- pool4
I0624 12:23:13.996570 17113 net.cpp:399] conv5_1 -> conv5_1
I0624 12:23:14.002126 17113 net.cpp:141] Setting up conv5_1
I0624 12:23:14.002141 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.002145 17113 net.cpp:156] Memory required for data: 103362560
I0624 12:23:14.002148 17113 layer_factory.hpp:77] Creating layer bn5_1
I0624 12:23:14.002156 17113 net.cpp:91] Creating Layer bn5_1
I0624 12:23:14.002158 17113 net.cpp:425] bn5_1 <- conv5_1
I0624 12:23:14.002163 17113 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0624 12:23:14.002329 17113 net.cpp:141] Setting up bn5_1
I0624 12:23:14.002347 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.002349 17113 net.cpp:156] Memory required for data: 103563264
I0624 12:23:14.002356 17113 layer_factory.hpp:77] Creating layer scale5_1
I0624 12:23:14.002362 17113 net.cpp:91] Creating Layer scale5_1
I0624 12:23:14.002364 17113 net.cpp:425] scale5_1 <- conv5_1
I0624 12:23:14.002374 17113 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0624 12:23:14.002410 17113 layer_factory.hpp:77] Creating layer scale5_1
I0624 12:23:14.002503 17113 net.cpp:141] Setting up scale5_1
I0624 12:23:14.002511 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.002513 17113 net.cpp:156] Memory required for data: 103763968
I0624 12:23:14.002517 17113 layer_factory.hpp:77] Creating layer relu5_1
I0624 12:23:14.002521 17113 net.cpp:91] Creating Layer relu5_1
I0624 12:23:14.002524 17113 net.cpp:425] relu5_1 <- conv5_1
I0624 12:23:14.002527 17113 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0624 12:23:14.002801 17113 net.cpp:141] Setting up relu5_1
I0624 12:23:14.002812 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.002815 17113 net.cpp:156] Memory required for data: 103964672
I0624 12:23:14.002818 17113 layer_factory.hpp:77] Creating layer conv5_2
I0624 12:23:14.002826 17113 net.cpp:91] Creating Layer conv5_2
I0624 12:23:14.002830 17113 net.cpp:425] conv5_2 <- conv5_1
I0624 12:23:14.002835 17113 net.cpp:399] conv5_2 -> conv5_2
I0624 12:23:14.008262 17113 net.cpp:141] Setting up conv5_2
I0624 12:23:14.008275 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.008278 17113 net.cpp:156] Memory required for data: 104165376
I0624 12:23:14.008282 17113 layer_factory.hpp:77] Creating layer bn5_2
I0624 12:23:14.008290 17113 net.cpp:91] Creating Layer bn5_2
I0624 12:23:14.008292 17113 net.cpp:425] bn5_2 <- conv5_2
I0624 12:23:14.008296 17113 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0624 12:23:14.008465 17113 net.cpp:141] Setting up bn5_2
I0624 12:23:14.008472 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.008474 17113 net.cpp:156] Memory required for data: 104366080
I0624 12:23:14.008479 17113 layer_factory.hpp:77] Creating layer scale5_2
I0624 12:23:14.008487 17113 net.cpp:91] Creating Layer scale5_2
I0624 12:23:14.008489 17113 net.cpp:425] scale5_2 <- conv5_2
I0624 12:23:14.008493 17113 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0624 12:23:14.008527 17113 layer_factory.hpp:77] Creating layer scale5_2
I0624 12:23:14.008618 17113 net.cpp:141] Setting up scale5_2
I0624 12:23:14.008625 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.008627 17113 net.cpp:156] Memory required for data: 104566784
I0624 12:23:14.008631 17113 layer_factory.hpp:77] Creating layer relu5_2
I0624 12:23:14.008637 17113 net.cpp:91] Creating Layer relu5_2
I0624 12:23:14.008640 17113 net.cpp:425] relu5_2 <- conv5_2
I0624 12:23:14.008642 17113 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0624 12:23:14.008919 17113 net.cpp:141] Setting up relu5_2
I0624 12:23:14.008929 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.008931 17113 net.cpp:156] Memory required for data: 104767488
I0624 12:23:14.008934 17113 layer_factory.hpp:77] Creating layer pool5
I0624 12:23:14.008937 17113 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 12:23:14.008942 17113 net.cpp:91] Creating Layer pool5
I0624 12:23:14.008945 17113 net.cpp:425] pool5 <- conv5_2
I0624 12:23:14.008951 17113 net.cpp:399] pool5 -> pool5
I0624 12:23:14.008956 17113 net.cpp:399] pool5 -> pool5_mask
I0624 12:23:14.008997 17113 net.cpp:141] Setting up pool5
I0624 12:23:14.009003 17113 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 12:23:14.009006 17113 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 12:23:14.009008 17113 net.cpp:156] Memory required for data: 104867840
I0624 12:23:14.009011 17113 layer_factory.hpp:77] Creating layer upsample5
I0624 12:23:14.009017 17113 net.cpp:91] Creating Layer upsample5
I0624 12:23:14.009019 17113 net.cpp:425] upsample5 <- pool5
I0624 12:23:14.009022 17113 net.cpp:425] upsample5 <- pool5_mask
I0624 12:23:14.009037 17113 net.cpp:399] upsample5 -> pool5_D
I0624 12:23:14.009069 17113 net.cpp:141] Setting up upsample5
I0624 12:23:14.009076 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.009078 17113 net.cpp:156] Memory required for data: 105068544
I0624 12:23:14.009080 17113 layer_factory.hpp:77] Creating layer conv5_2_D
I0624 12:23:14.009088 17113 net.cpp:91] Creating Layer conv5_2_D
I0624 12:23:14.009090 17113 net.cpp:425] conv5_2_D <- pool5_D
I0624 12:23:14.009094 17113 net.cpp:399] conv5_2_D -> conv5_2_D
I0624 12:23:14.014504 17113 net.cpp:141] Setting up conv5_2_D
I0624 12:23:14.014518 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.014519 17113 net.cpp:156] Memory required for data: 105269248
I0624 12:23:14.014524 17113 layer_factory.hpp:77] Creating layer bn5_2_D
I0624 12:23:14.014531 17113 net.cpp:91] Creating Layer bn5_2_D
I0624 12:23:14.014534 17113 net.cpp:425] bn5_2_D <- conv5_2_D
I0624 12:23:14.014539 17113 net.cpp:386] bn5_2_D -> conv5_2_D (in-place)
I0624 12:23:14.014706 17113 net.cpp:141] Setting up bn5_2_D
I0624 12:23:14.014714 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.014716 17113 net.cpp:156] Memory required for data: 105469952
I0624 12:23:14.014721 17113 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 12:23:14.014727 17113 net.cpp:91] Creating Layer scale5_2_D
I0624 12:23:14.014730 17113 net.cpp:425] scale5_2_D <- conv5_2_D
I0624 12:23:14.014734 17113 net.cpp:386] scale5_2_D -> conv5_2_D (in-place)
I0624 12:23:14.014768 17113 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 12:23:14.014873 17113 net.cpp:141] Setting up scale5_2_D
I0624 12:23:14.014880 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.014883 17113 net.cpp:156] Memory required for data: 105670656
I0624 12:23:14.014899 17113 layer_factory.hpp:77] Creating layer relu5_2_D
I0624 12:23:14.014906 17113 net.cpp:91] Creating Layer relu5_2_D
I0624 12:23:14.014909 17113 net.cpp:425] relu5_2_D <- conv5_2_D
I0624 12:23:14.014912 17113 net.cpp:386] relu5_2_D -> conv5_2_D (in-place)
I0624 12:23:14.015341 17113 net.cpp:141] Setting up relu5_2_D
I0624 12:23:14.015350 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.015352 17113 net.cpp:156] Memory required for data: 105871360
I0624 12:23:14.015355 17113 layer_factory.hpp:77] Creating layer conv5_1_D
I0624 12:23:14.015363 17113 net.cpp:91] Creating Layer conv5_1_D
I0624 12:23:14.015367 17113 net.cpp:425] conv5_1_D <- conv5_2_D
I0624 12:23:14.015372 17113 net.cpp:399] conv5_1_D -> conv5_1_D
I0624 12:23:14.020800 17113 net.cpp:141] Setting up conv5_1_D
I0624 12:23:14.020813 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.020817 17113 net.cpp:156] Memory required for data: 106072064
I0624 12:23:14.020820 17113 layer_factory.hpp:77] Creating layer bn5_1_D
I0624 12:23:14.020828 17113 net.cpp:91] Creating Layer bn5_1_D
I0624 12:23:14.020830 17113 net.cpp:425] bn5_1_D <- conv5_1_D
I0624 12:23:14.020833 17113 net.cpp:386] bn5_1_D -> conv5_1_D (in-place)
I0624 12:23:14.021021 17113 net.cpp:141] Setting up bn5_1_D
I0624 12:23:14.021029 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.021031 17113 net.cpp:156] Memory required for data: 106272768
I0624 12:23:14.021037 17113 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 12:23:14.021044 17113 net.cpp:91] Creating Layer scale5_1_D
I0624 12:23:14.021045 17113 net.cpp:425] scale5_1_D <- conv5_1_D
I0624 12:23:14.021050 17113 net.cpp:386] scale5_1_D -> conv5_1_D (in-place)
I0624 12:23:14.021085 17113 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 12:23:14.021184 17113 net.cpp:141] Setting up scale5_1_D
I0624 12:23:14.021191 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.021193 17113 net.cpp:156] Memory required for data: 106473472
I0624 12:23:14.021198 17113 layer_factory.hpp:77] Creating layer relu5_1_D
I0624 12:23:14.021203 17113 net.cpp:91] Creating Layer relu5_1_D
I0624 12:23:14.021206 17113 net.cpp:425] relu5_1_D <- conv5_1_D
I0624 12:23:14.021210 17113 net.cpp:386] relu5_1_D -> conv5_1_D (in-place)
I0624 12:23:14.024405 17113 net.cpp:141] Setting up relu5_1_D
I0624 12:23:14.024416 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.024420 17113 net.cpp:156] Memory required for data: 106674176
I0624 12:23:14.024422 17113 layer_factory.hpp:77] Creating layer upsample4
I0624 12:23:14.024428 17113 net.cpp:91] Creating Layer upsample4
I0624 12:23:14.024431 17113 net.cpp:425] upsample4 <- conv5_1_D
I0624 12:23:14.024436 17113 net.cpp:425] upsample4 <- pool4_mask
I0624 12:23:14.024441 17113 net.cpp:399] upsample4 -> pool4_D
I0624 12:23:14.024474 17113 net.cpp:141] Setting up upsample4
I0624 12:23:14.024482 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:14.024483 17113 net.cpp:156] Memory required for data: 107476992
I0624 12:23:14.024485 17113 layer_factory.hpp:77] Creating layer conv4_2_D
I0624 12:23:14.024494 17113 net.cpp:91] Creating Layer conv4_2_D
I0624 12:23:14.024497 17113 net.cpp:425] conv4_2_D <- pool4_D
I0624 12:23:14.024502 17113 net.cpp:399] conv4_2_D -> conv4_2_D
I0624 12:23:14.029855 17113 net.cpp:141] Setting up conv4_2_D
I0624 12:23:14.029870 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:14.029873 17113 net.cpp:156] Memory required for data: 108279808
I0624 12:23:14.029878 17113 layer_factory.hpp:77] Creating layer bn4_2_D
I0624 12:23:14.029887 17113 net.cpp:91] Creating Layer bn4_2_D
I0624 12:23:14.029891 17113 net.cpp:425] bn4_2_D <- conv4_2_D
I0624 12:23:14.029896 17113 net.cpp:386] bn4_2_D -> conv4_2_D (in-place)
I0624 12:23:14.030079 17113 net.cpp:141] Setting up bn4_2_D
I0624 12:23:14.030086 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:14.030088 17113 net.cpp:156] Memory required for data: 109082624
I0624 12:23:14.030094 17113 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 12:23:14.030100 17113 net.cpp:91] Creating Layer scale4_2_D
I0624 12:23:14.030103 17113 net.cpp:425] scale4_2_D <- conv4_2_D
I0624 12:23:14.030107 17113 net.cpp:386] scale4_2_D -> conv4_2_D (in-place)
I0624 12:23:14.030143 17113 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 12:23:14.030248 17113 net.cpp:141] Setting up scale4_2_D
I0624 12:23:14.030256 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:14.030257 17113 net.cpp:156] Memory required for data: 109885440
I0624 12:23:14.030261 17113 layer_factory.hpp:77] Creating layer relu4_2_D
I0624 12:23:14.030267 17113 net.cpp:91] Creating Layer relu4_2_D
I0624 12:23:14.030269 17113 net.cpp:425] relu4_2_D <- conv4_2_D
I0624 12:23:14.030273 17113 net.cpp:386] relu4_2_D -> conv4_2_D (in-place)
I0624 12:23:14.030551 17113 net.cpp:141] Setting up relu4_2_D
I0624 12:23:14.030562 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:14.030565 17113 net.cpp:156] Memory required for data: 110688256
I0624 12:23:14.030567 17113 layer_factory.hpp:77] Creating layer conv4_1_D
I0624 12:23:14.030575 17113 net.cpp:91] Creating Layer conv4_1_D
I0624 12:23:14.030578 17113 net.cpp:425] conv4_1_D <- conv4_2_D
I0624 12:23:14.030583 17113 net.cpp:399] conv4_1_D -> conv4_1_D
I0624 12:23:14.033905 17113 net.cpp:141] Setting up conv4_1_D
I0624 12:23:14.033920 17113 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:23:14.033922 17113 net.cpp:156] Memory required for data: 111089664
I0624 12:23:14.033926 17113 layer_factory.hpp:77] Creating layer bn4_1_D
I0624 12:23:14.033933 17113 net.cpp:91] Creating Layer bn4_1_D
I0624 12:23:14.033936 17113 net.cpp:425] bn4_1_D <- conv4_1_D
I0624 12:23:14.033941 17113 net.cpp:386] bn4_1_D -> conv4_1_D (in-place)
I0624 12:23:14.034114 17113 net.cpp:141] Setting up bn4_1_D
I0624 12:23:14.034122 17113 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:23:14.034124 17113 net.cpp:156] Memory required for data: 111491072
I0624 12:23:14.034131 17113 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 12:23:14.034137 17113 net.cpp:91] Creating Layer scale4_1_D
I0624 12:23:14.034139 17113 net.cpp:425] scale4_1_D <- conv4_1_D
I0624 12:23:14.034142 17113 net.cpp:386] scale4_1_D -> conv4_1_D (in-place)
I0624 12:23:14.034178 17113 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 12:23:14.034296 17113 net.cpp:141] Setting up scale4_1_D
I0624 12:23:14.034303 17113 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:23:14.034306 17113 net.cpp:156] Memory required for data: 111892480
I0624 12:23:14.034309 17113 layer_factory.hpp:77] Creating layer relu4_1_D
I0624 12:23:14.034323 17113 net.cpp:91] Creating Layer relu4_1_D
I0624 12:23:14.034328 17113 net.cpp:425] relu4_1_D <- conv4_1_D
I0624 12:23:14.034332 17113 net.cpp:386] relu4_1_D -> conv4_1_D (in-place)
I0624 12:23:14.034483 17113 net.cpp:141] Setting up relu4_1_D
I0624 12:23:14.034492 17113 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:23:14.034494 17113 net.cpp:156] Memory required for data: 112293888
I0624 12:23:14.034497 17113 layer_factory.hpp:77] Creating layer upsample3
I0624 12:23:14.034504 17113 net.cpp:91] Creating Layer upsample3
I0624 12:23:14.034507 17113 net.cpp:425] upsample3 <- conv4_1_D
I0624 12:23:14.034510 17113 net.cpp:425] upsample3 <- pool3_mask
I0624 12:23:14.034514 17113 net.cpp:399] upsample3 -> pool3_D
I0624 12:23:14.034543 17113 net.cpp:141] Setting up upsample3
I0624 12:23:14.034549 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:14.034551 17113 net.cpp:156] Memory required for data: 113899520
I0624 12:23:14.034554 17113 layer_factory.hpp:77] Creating layer conv3_2_D
I0624 12:23:14.034562 17113 net.cpp:91] Creating Layer conv3_2_D
I0624 12:23:14.034566 17113 net.cpp:425] conv3_2_D <- pool3_D
I0624 12:23:14.034571 17113 net.cpp:399] conv3_2_D -> conv3_2_D
I0624 12:23:14.037145 17113 net.cpp:141] Setting up conv3_2_D
I0624 12:23:14.037159 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:14.037163 17113 net.cpp:156] Memory required for data: 115505152
I0624 12:23:14.037168 17113 layer_factory.hpp:77] Creating layer bn3_2_D
I0624 12:23:14.037173 17113 net.cpp:91] Creating Layer bn3_2_D
I0624 12:23:14.037175 17113 net.cpp:425] bn3_2_D <- conv3_2_D
I0624 12:23:14.037180 17113 net.cpp:386] bn3_2_D -> conv3_2_D (in-place)
I0624 12:23:14.037364 17113 net.cpp:141] Setting up bn3_2_D
I0624 12:23:14.037371 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:14.037374 17113 net.cpp:156] Memory required for data: 117110784
I0624 12:23:14.037379 17113 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 12:23:14.037384 17113 net.cpp:91] Creating Layer scale3_2_D
I0624 12:23:14.037387 17113 net.cpp:425] scale3_2_D <- conv3_2_D
I0624 12:23:14.037391 17113 net.cpp:386] scale3_2_D -> conv3_2_D (in-place)
I0624 12:23:14.037428 17113 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 12:23:14.037531 17113 net.cpp:141] Setting up scale3_2_D
I0624 12:23:14.037540 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:14.037542 17113 net.cpp:156] Memory required for data: 118716416
I0624 12:23:14.037546 17113 layer_factory.hpp:77] Creating layer relu3_2_D
I0624 12:23:14.037550 17113 net.cpp:91] Creating Layer relu3_2_D
I0624 12:23:14.037554 17113 net.cpp:425] relu3_2_D <- conv3_2_D
I0624 12:23:14.037556 17113 net.cpp:386] relu3_2_D -> conv3_2_D (in-place)
I0624 12:23:14.037844 17113 net.cpp:141] Setting up relu3_2_D
I0624 12:23:14.037856 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:14.037858 17113 net.cpp:156] Memory required for data: 120322048
I0624 12:23:14.037861 17113 layer_factory.hpp:77] Creating layer conv3_1_D
I0624 12:23:14.037869 17113 net.cpp:91] Creating Layer conv3_1_D
I0624 12:23:14.037871 17113 net.cpp:425] conv3_1_D <- conv3_2_D
I0624 12:23:14.037878 17113 net.cpp:399] conv3_1_D -> conv3_1_D
I0624 12:23:14.039361 17113 net.cpp:141] Setting up conv3_1_D
I0624 12:23:14.039381 17113 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:23:14.039382 17113 net.cpp:156] Memory required for data: 121124864
I0624 12:23:14.039387 17113 layer_factory.hpp:77] Creating layer bn3_1_D
I0624 12:23:14.039392 17113 net.cpp:91] Creating Layer bn3_1_D
I0624 12:23:14.039396 17113 net.cpp:425] bn3_1_D <- conv3_1_D
I0624 12:23:14.039400 17113 net.cpp:386] bn3_1_D -> conv3_1_D (in-place)
I0624 12:23:14.039590 17113 net.cpp:141] Setting up bn3_1_D
I0624 12:23:14.039608 17113 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:23:14.039610 17113 net.cpp:156] Memory required for data: 121927680
I0624 12:23:14.039615 17113 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 12:23:14.039621 17113 net.cpp:91] Creating Layer scale3_1_D
I0624 12:23:14.039624 17113 net.cpp:425] scale3_1_D <- conv3_1_D
I0624 12:23:14.039628 17113 net.cpp:386] scale3_1_D -> conv3_1_D (in-place)
I0624 12:23:14.039667 17113 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 12:23:14.039783 17113 net.cpp:141] Setting up scale3_1_D
I0624 12:23:14.039790 17113 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:23:14.039793 17113 net.cpp:156] Memory required for data: 122730496
I0624 12:23:14.039796 17113 layer_factory.hpp:77] Creating layer relu3_1_D
I0624 12:23:14.039801 17113 net.cpp:91] Creating Layer relu3_1_D
I0624 12:23:14.039804 17113 net.cpp:425] relu3_1_D <- conv3_1_D
I0624 12:23:14.039808 17113 net.cpp:386] relu3_1_D -> conv3_1_D (in-place)
I0624 12:23:14.040094 17113 net.cpp:141] Setting up relu3_1_D
I0624 12:23:14.040105 17113 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:23:14.040107 17113 net.cpp:156] Memory required for data: 123533312
I0624 12:23:14.040110 17113 layer_factory.hpp:77] Creating layer upsample2
I0624 12:23:14.040117 17113 net.cpp:91] Creating Layer upsample2
I0624 12:23:14.040120 17113 net.cpp:425] upsample2 <- conv3_1_D
I0624 12:23:14.040124 17113 net.cpp:425] upsample2 <- pool2_mask
I0624 12:23:14.040127 17113 net.cpp:399] upsample2 -> pool2_D
I0624 12:23:14.040158 17113 net.cpp:141] Setting up upsample2
I0624 12:23:14.040163 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:14.040165 17113 net.cpp:156] Memory required for data: 126744576
I0624 12:23:14.040168 17113 layer_factory.hpp:77] Creating layer conv2_2_D
I0624 12:23:14.040175 17113 net.cpp:91] Creating Layer conv2_2_D
I0624 12:23:14.040177 17113 net.cpp:425] conv2_2_D <- pool2_D
I0624 12:23:14.040182 17113 net.cpp:399] conv2_2_D -> conv2_2_D
I0624 12:23:14.041451 17113 net.cpp:141] Setting up conv2_2_D
I0624 12:23:14.041463 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:14.041465 17113 net.cpp:156] Memory required for data: 129955840
I0624 12:23:14.041471 17113 layer_factory.hpp:77] Creating layer bn2_2_D
I0624 12:23:14.041476 17113 net.cpp:91] Creating Layer bn2_2_D
I0624 12:23:14.041479 17113 net.cpp:425] bn2_2_D <- conv2_2_D
I0624 12:23:14.041483 17113 net.cpp:386] bn2_2_D -> conv2_2_D (in-place)
I0624 12:23:14.041682 17113 net.cpp:141] Setting up bn2_2_D
I0624 12:23:14.041689 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:14.041692 17113 net.cpp:156] Memory required for data: 133167104
I0624 12:23:14.041697 17113 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 12:23:14.041702 17113 net.cpp:91] Creating Layer scale2_2_D
I0624 12:23:14.041705 17113 net.cpp:425] scale2_2_D <- conv2_2_D
I0624 12:23:14.041709 17113 net.cpp:386] scale2_2_D -> conv2_2_D (in-place)
I0624 12:23:14.041749 17113 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 12:23:14.041868 17113 net.cpp:141] Setting up scale2_2_D
I0624 12:23:14.041877 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:14.041878 17113 net.cpp:156] Memory required for data: 136378368
I0624 12:23:14.041882 17113 layer_factory.hpp:77] Creating layer relu2_2_D
I0624 12:23:14.041887 17113 net.cpp:91] Creating Layer relu2_2_D
I0624 12:23:14.041889 17113 net.cpp:425] relu2_2_D <- conv2_2_D
I0624 12:23:14.041893 17113 net.cpp:386] relu2_2_D -> conv2_2_D (in-place)
I0624 12:23:14.042048 17113 net.cpp:141] Setting up relu2_2_D
I0624 12:23:14.042057 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:14.042059 17113 net.cpp:156] Memory required for data: 139589632
I0624 12:23:14.042062 17113 layer_factory.hpp:77] Creating layer conv2_1_D
I0624 12:23:14.042070 17113 net.cpp:91] Creating Layer conv2_1_D
I0624 12:23:14.042073 17113 net.cpp:425] conv2_1_D <- conv2_2_D
I0624 12:23:14.042078 17113 net.cpp:399] conv2_1_D -> conv2_1_D
I0624 12:23:14.043090 17113 net.cpp:141] Setting up conv2_1_D
I0624 12:23:14.043110 17113 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:23:14.043113 17113 net.cpp:156] Memory required for data: 141195264
I0624 12:23:14.043118 17113 layer_factory.hpp:77] Creating layer bn2_1_D
I0624 12:23:14.043124 17113 net.cpp:91] Creating Layer bn2_1_D
I0624 12:23:14.043128 17113 net.cpp:425] bn2_1_D <- conv2_1_D
I0624 12:23:14.043131 17113 net.cpp:386] bn2_1_D -> conv2_1_D (in-place)
I0624 12:23:14.043341 17113 net.cpp:141] Setting up bn2_1_D
I0624 12:23:14.043349 17113 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:23:14.043351 17113 net.cpp:156] Memory required for data: 142800896
I0624 12:23:14.043357 17113 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 12:23:14.043362 17113 net.cpp:91] Creating Layer scale2_1_D
I0624 12:23:14.043365 17113 net.cpp:425] scale2_1_D <- conv2_1_D
I0624 12:23:14.043370 17113 net.cpp:386] scale2_1_D -> conv2_1_D (in-place)
I0624 12:23:14.043408 17113 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 12:23:14.043536 17113 net.cpp:141] Setting up scale2_1_D
I0624 12:23:14.043543 17113 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:23:14.043546 17113 net.cpp:156] Memory required for data: 144406528
I0624 12:23:14.043550 17113 layer_factory.hpp:77] Creating layer relu2_1_D
I0624 12:23:14.043555 17113 net.cpp:91] Creating Layer relu2_1_D
I0624 12:23:14.043557 17113 net.cpp:425] relu2_1_D <- conv2_1_D
I0624 12:23:14.043561 17113 net.cpp:386] relu2_1_D -> conv2_1_D (in-place)
I0624 12:23:14.043859 17113 net.cpp:141] Setting up relu2_1_D
I0624 12:23:14.043869 17113 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:23:14.043872 17113 net.cpp:156] Memory required for data: 146012160
I0624 12:23:14.043875 17113 layer_factory.hpp:77] Creating layer upsample1
I0624 12:23:14.043880 17113 net.cpp:91] Creating Layer upsample1
I0624 12:23:14.043884 17113 net.cpp:425] upsample1 <- conv2_1_D
I0624 12:23:14.043887 17113 net.cpp:425] upsample1 <- pool1_mask
I0624 12:23:14.043891 17113 net.cpp:399] upsample1 -> pool1_D
I0624 12:23:14.043920 17113 net.cpp:141] Setting up upsample1
I0624 12:23:14.043926 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:14.043927 17113 net.cpp:156] Memory required for data: 152434688
I0624 12:23:14.043929 17113 layer_factory.hpp:77] Creating layer conv1_2_D
I0624 12:23:14.043939 17113 net.cpp:91] Creating Layer conv1_2_D
I0624 12:23:14.043942 17113 net.cpp:425] conv1_2_D <- pool1_D
I0624 12:23:14.043946 17113 net.cpp:399] conv1_2_D -> conv1_2_D
I0624 12:23:14.044888 17113 net.cpp:141] Setting up conv1_2_D
I0624 12:23:14.044901 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:14.044904 17113 net.cpp:156] Memory required for data: 158857216
I0624 12:23:14.044909 17113 layer_factory.hpp:77] Creating layer bn1_2_D
I0624 12:23:14.044914 17113 net.cpp:91] Creating Layer bn1_2_D
I0624 12:23:14.044917 17113 net.cpp:425] bn1_2_D <- conv1_2_D
I0624 12:23:14.044921 17113 net.cpp:386] bn1_2_D -> conv1_2_D (in-place)
I0624 12:23:14.045163 17113 net.cpp:141] Setting up bn1_2_D
I0624 12:23:14.045171 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:14.045174 17113 net.cpp:156] Memory required for data: 165279744
I0624 12:23:14.045179 17113 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 12:23:14.045186 17113 net.cpp:91] Creating Layer scale1_2_D
I0624 12:23:14.045188 17113 net.cpp:425] scale1_2_D <- conv1_2_D
I0624 12:23:14.045192 17113 net.cpp:386] scale1_2_D -> conv1_2_D (in-place)
I0624 12:23:14.045230 17113 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 12:23:14.045418 17113 net.cpp:141] Setting up scale1_2_D
I0624 12:23:14.045428 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:14.045429 17113 net.cpp:156] Memory required for data: 171702272
I0624 12:23:14.045434 17113 layer_factory.hpp:77] Creating layer relu1_2_D
I0624 12:23:14.045439 17113 net.cpp:91] Creating Layer relu1_2_D
I0624 12:23:14.045441 17113 net.cpp:425] relu1_2_D <- conv1_2_D
I0624 12:23:14.045444 17113 net.cpp:386] relu1_2_D -> conv1_2_D (in-place)
I0624 12:23:14.045745 17113 net.cpp:141] Setting up relu1_2_D
I0624 12:23:14.045758 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:14.045760 17113 net.cpp:156] Memory required for data: 178124800
I0624 12:23:14.045763 17113 layer_factory.hpp:77] Creating layer conv1_1_D
I0624 12:23:14.045773 17113 net.cpp:91] Creating Layer conv1_1_D
I0624 12:23:14.045776 17113 net.cpp:425] conv1_1_D <- conv1_2_D
I0624 12:23:14.045780 17113 net.cpp:399] conv1_1_D -> conv1_1_D
I0624 12:23:14.046919 17113 net.cpp:141] Setting up conv1_1_D
I0624 12:23:14.046931 17113 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 12:23:14.046933 17113 net.cpp:156] Memory required for data: 178526208
I0624 12:23:14.046938 17113 layer_factory.hpp:77] Creating layer conv1_1_D_conv1_1_D_0_split
I0624 12:23:14.046944 17113 net.cpp:91] Creating Layer conv1_1_D_conv1_1_D_0_split
I0624 12:23:14.046947 17113 net.cpp:425] conv1_1_D_conv1_1_D_0_split <- conv1_1_D
I0624 12:23:14.046952 17113 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_0
I0624 12:23:14.046957 17113 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_1
I0624 12:23:14.047003 17113 net.cpp:141] Setting up conv1_1_D_conv1_1_D_0_split
I0624 12:23:14.047008 17113 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 12:23:14.047011 17113 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 12:23:14.047013 17113 net.cpp:156] Memory required for data: 179329024
I0624 12:23:14.047015 17113 layer_factory.hpp:77] Creating layer loss
I0624 12:23:14.047020 17113 net.cpp:91] Creating Layer loss
I0624 12:23:14.047022 17113 net.cpp:425] loss <- conv1_1_D_conv1_1_D_0_split_0
I0624 12:23:14.047025 17113 net.cpp:425] loss <- label_data_1_split_0
I0624 12:23:14.047029 17113 net.cpp:399] loss -> loss
I0624 12:23:14.047037 17113 layer_factory.hpp:77] Creating layer loss
I0624 12:23:14.047955 17113 net.cpp:141] Setting up loss
I0624 12:23:14.047966 17113 net.cpp:148] Top shape: (1)
I0624 12:23:14.047968 17113 net.cpp:151]     with loss weight 1
I0624 12:23:14.047983 17113 net.cpp:156] Memory required for data: 179329028
I0624 12:23:14.047986 17113 layer_factory.hpp:77] Creating layer accuracy
I0624 12:23:14.047991 17113 net.cpp:91] Creating Layer accuracy
I0624 12:23:14.047996 17113 net.cpp:425] accuracy <- conv1_1_D_conv1_1_D_0_split_1
I0624 12:23:14.047999 17113 net.cpp:425] accuracy <- label_data_1_split_1
I0624 12:23:14.048002 17113 net.cpp:399] accuracy -> accuracy
I0624 12:23:14.048008 17113 net.cpp:141] Setting up accuracy
I0624 12:23:14.048012 17113 net.cpp:148] Top shape: (1)
I0624 12:23:14.048014 17113 net.cpp:156] Memory required for data: 179329032
I0624 12:23:14.048017 17113 net.cpp:219] accuracy does not need backward computation.
I0624 12:23:14.048018 17113 net.cpp:217] loss needs backward computation.
I0624 12:23:14.048022 17113 net.cpp:217] conv1_1_D_conv1_1_D_0_split needs backward computation.
I0624 12:23:14.048023 17113 net.cpp:217] conv1_1_D needs backward computation.
I0624 12:23:14.048027 17113 net.cpp:217] relu1_2_D needs backward computation.
I0624 12:23:14.048028 17113 net.cpp:217] scale1_2_D needs backward computation.
I0624 12:23:14.048030 17113 net.cpp:217] bn1_2_D needs backward computation.
I0624 12:23:14.048032 17113 net.cpp:217] conv1_2_D needs backward computation.
I0624 12:23:14.048034 17113 net.cpp:217] upsample1 needs backward computation.
I0624 12:23:14.048037 17113 net.cpp:217] relu2_1_D needs backward computation.
I0624 12:23:14.048039 17113 net.cpp:217] scale2_1_D needs backward computation.
I0624 12:23:14.048040 17113 net.cpp:217] bn2_1_D needs backward computation.
I0624 12:23:14.048043 17113 net.cpp:217] conv2_1_D needs backward computation.
I0624 12:23:14.048045 17113 net.cpp:217] relu2_2_D needs backward computation.
I0624 12:23:14.048046 17113 net.cpp:217] scale2_2_D needs backward computation.
I0624 12:23:14.048048 17113 net.cpp:217] bn2_2_D needs backward computation.
I0624 12:23:14.048050 17113 net.cpp:217] conv2_2_D needs backward computation.
I0624 12:23:14.048053 17113 net.cpp:217] upsample2 needs backward computation.
I0624 12:23:14.048064 17113 net.cpp:217] relu3_1_D needs backward computation.
I0624 12:23:14.048068 17113 net.cpp:217] scale3_1_D needs backward computation.
I0624 12:23:14.048069 17113 net.cpp:217] bn3_1_D needs backward computation.
I0624 12:23:14.048071 17113 net.cpp:217] conv3_1_D needs backward computation.
I0624 12:23:14.048074 17113 net.cpp:217] relu3_2_D needs backward computation.
I0624 12:23:14.048075 17113 net.cpp:217] scale3_2_D needs backward computation.
I0624 12:23:14.048077 17113 net.cpp:217] bn3_2_D needs backward computation.
I0624 12:23:14.048079 17113 net.cpp:217] conv3_2_D needs backward computation.
I0624 12:23:14.048081 17113 net.cpp:217] upsample3 needs backward computation.
I0624 12:23:14.048084 17113 net.cpp:217] relu4_1_D needs backward computation.
I0624 12:23:14.048086 17113 net.cpp:217] scale4_1_D needs backward computation.
I0624 12:23:14.048089 17113 net.cpp:217] bn4_1_D needs backward computation.
I0624 12:23:14.048090 17113 net.cpp:217] conv4_1_D needs backward computation.
I0624 12:23:14.048094 17113 net.cpp:217] relu4_2_D needs backward computation.
I0624 12:23:14.048095 17113 net.cpp:217] scale4_2_D needs backward computation.
I0624 12:23:14.048097 17113 net.cpp:217] bn4_2_D needs backward computation.
I0624 12:23:14.048099 17113 net.cpp:217] conv4_2_D needs backward computation.
I0624 12:23:14.048101 17113 net.cpp:217] upsample4 needs backward computation.
I0624 12:23:14.048105 17113 net.cpp:217] relu5_1_D needs backward computation.
I0624 12:23:14.048106 17113 net.cpp:217] scale5_1_D needs backward computation.
I0624 12:23:14.048108 17113 net.cpp:217] bn5_1_D needs backward computation.
I0624 12:23:14.048110 17113 net.cpp:217] conv5_1_D needs backward computation.
I0624 12:23:14.048113 17113 net.cpp:217] relu5_2_D needs backward computation.
I0624 12:23:14.048115 17113 net.cpp:217] scale5_2_D needs backward computation.
I0624 12:23:14.048117 17113 net.cpp:217] bn5_2_D needs backward computation.
I0624 12:23:14.048120 17113 net.cpp:217] conv5_2_D needs backward computation.
I0624 12:23:14.048122 17113 net.cpp:217] upsample5 needs backward computation.
I0624 12:23:14.048125 17113 net.cpp:217] pool5 needs backward computation.
I0624 12:23:14.048127 17113 net.cpp:217] relu5_2 needs backward computation.
I0624 12:23:14.048130 17113 net.cpp:217] scale5_2 needs backward computation.
I0624 12:23:14.048132 17113 net.cpp:217] bn5_2 needs backward computation.
I0624 12:23:14.048135 17113 net.cpp:217] conv5_2 needs backward computation.
I0624 12:23:14.048136 17113 net.cpp:217] relu5_1 needs backward computation.
I0624 12:23:14.048140 17113 net.cpp:217] scale5_1 needs backward computation.
I0624 12:23:14.048141 17113 net.cpp:217] bn5_1 needs backward computation.
I0624 12:23:14.048143 17113 net.cpp:217] conv5_1 needs backward computation.
I0624 12:23:14.048146 17113 net.cpp:217] pool4 needs backward computation.
I0624 12:23:14.048147 17113 net.cpp:217] relu4_2 needs backward computation.
I0624 12:23:14.048149 17113 net.cpp:217] scale4_2 needs backward computation.
I0624 12:23:14.048152 17113 net.cpp:217] bn4_2 needs backward computation.
I0624 12:23:14.048154 17113 net.cpp:217] conv4_2 needs backward computation.
I0624 12:23:14.048156 17113 net.cpp:217] relu4_1 needs backward computation.
I0624 12:23:14.048158 17113 net.cpp:217] scale4_1 needs backward computation.
I0624 12:23:14.048161 17113 net.cpp:217] bn4_1 needs backward computation.
I0624 12:23:14.048163 17113 net.cpp:217] conv4_1 needs backward computation.
I0624 12:23:14.048166 17113 net.cpp:217] pool3 needs backward computation.
I0624 12:23:14.048167 17113 net.cpp:217] relu3_2 needs backward computation.
I0624 12:23:14.048171 17113 net.cpp:217] scale3_2 needs backward computation.
I0624 12:23:14.048172 17113 net.cpp:217] bn3_2 needs backward computation.
I0624 12:23:14.048174 17113 net.cpp:217] conv3_2 needs backward computation.
I0624 12:23:14.048177 17113 net.cpp:217] relu3_1 needs backward computation.
I0624 12:23:14.048178 17113 net.cpp:217] scale3_1 needs backward computation.
I0624 12:23:14.048182 17113 net.cpp:217] bn3_1 needs backward computation.
I0624 12:23:14.048187 17113 net.cpp:217] conv3_1 needs backward computation.
I0624 12:23:14.048189 17113 net.cpp:217] pool2 needs backward computation.
I0624 12:23:14.048192 17113 net.cpp:217] relu2_2 needs backward computation.
I0624 12:23:14.048193 17113 net.cpp:217] scale2_2 needs backward computation.
I0624 12:23:14.048197 17113 net.cpp:217] bn2_2 needs backward computation.
I0624 12:23:14.048198 17113 net.cpp:217] conv2_2 needs backward computation.
I0624 12:23:14.048200 17113 net.cpp:217] relu2_1 needs backward computation.
I0624 12:23:14.048202 17113 net.cpp:217] scale2_1 needs backward computation.
I0624 12:23:14.048207 17113 net.cpp:217] bn2_1 needs backward computation.
I0624 12:23:14.048209 17113 net.cpp:217] conv2_1 needs backward computation.
I0624 12:23:14.048213 17113 net.cpp:217] pool1 needs backward computation.
I0624 12:23:14.048215 17113 net.cpp:217] relu1_2 needs backward computation.
I0624 12:23:14.048218 17113 net.cpp:217] scale1_2 needs backward computation.
I0624 12:23:14.048219 17113 net.cpp:217] bn1_2 needs backward computation.
I0624 12:23:14.048221 17113 net.cpp:217] conv1_2 needs backward computation.
I0624 12:23:14.048223 17113 net.cpp:217] relu1_1 needs backward computation.
I0624 12:23:14.048225 17113 net.cpp:217] scale1_1 needs backward computation.
I0624 12:23:14.048228 17113 net.cpp:217] bn1_1 needs backward computation.
I0624 12:23:14.048230 17113 net.cpp:217] conv1_1 needs backward computation.
I0624 12:23:14.048235 17113 net.cpp:219] label_data_1_split does not need backward computation.
I0624 12:23:14.048238 17113 net.cpp:219] data does not need backward computation.
I0624 12:23:14.048240 17113 net.cpp:261] This network produces output accuracy
I0624 12:23:14.048243 17113 net.cpp:261] This network produces output loss
I0624 12:23:14.048275 17113 net.cpp:274] Network initialization done.
I0624 12:23:14.049762 17113 solver.cpp:181] Creating test net (#0) specified by net file: models/segnet/train_val.prototxt
I0624 12:23:14.049854 17113 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0624 12:23:14.050271 17113 net.cpp:49] Initializing net from parameters: 
name: "segnet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "DenseImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 224
    mean_value: 100
  }
  dense_image_data_param {
    source: "data/val.txt"
    batch_size: 1
    shuffle: true
    new_height: 224
    new_width: 310
    is_color: false
    root_folder: "data/raw/train/"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 14
    upsample_w: 14
  }
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2_D"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2_D"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1_D"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1_D"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 28
    upsample_w: 28
  }
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2_D"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2_D"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1_D"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1_D"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
    upsample_h: 56
    upsample_w: 56
  }
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn3_2_D"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2_D"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1_D"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1_D"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
    upsample_h: 112
    upsample_w: 112
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2_D"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2_D"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1_D"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1_D"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
    upsample_h: 224
    upsample_w: 224
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2_D"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2_D"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2
    bias_term: true
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "accuracy"
}
I0624 12:23:14.050511 17113 layer_factory.hpp:77] Creating layer data
I0624 12:23:14.050523 17113 net.cpp:91] Creating Layer data
I0624 12:23:14.050526 17113 net.cpp:399] data -> data
I0624 12:23:14.050534 17113 net.cpp:399] data -> label
I0624 12:23:14.050542 17113 dense_image_data_layer.cpp:38] Opening file data/val.txt
I0624 12:23:14.050871 17113 dense_image_data_layer.cpp:48] Shuffling data
I0624 12:23:14.050946 17113 dense_image_data_layer.cpp:53] A total of 705 examples.
I0624 12:23:14.055498 17113 dense_image_data_layer.cpp:92] output data size: 1,1,224,224
I0624 12:23:14.056509 17113 net.cpp:141] Setting up data
I0624 12:23:14.056522 17113 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 12:23:14.056526 17113 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 12:23:14.056529 17113 net.cpp:156] Memory required for data: 401408
I0624 12:23:14.056532 17113 layer_factory.hpp:77] Creating layer label_data_1_split
I0624 12:23:14.056538 17113 net.cpp:91] Creating Layer label_data_1_split
I0624 12:23:14.056541 17113 net.cpp:425] label_data_1_split <- label
I0624 12:23:14.056545 17113 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0624 12:23:14.056551 17113 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0624 12:23:14.056593 17113 net.cpp:141] Setting up label_data_1_split
I0624 12:23:14.056601 17113 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 12:23:14.056603 17113 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 12:23:14.056607 17113 net.cpp:156] Memory required for data: 802816
I0624 12:23:14.056608 17113 layer_factory.hpp:77] Creating layer conv1_1
I0624 12:23:14.056615 17113 net.cpp:91] Creating Layer conv1_1
I0624 12:23:14.056618 17113 net.cpp:425] conv1_1 <- data
I0624 12:23:14.056622 17113 net.cpp:399] conv1_1 -> conv1_1
I0624 12:23:14.058017 17113 net.cpp:141] Setting up conv1_1
I0624 12:23:14.058029 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:14.058032 17113 net.cpp:156] Memory required for data: 7225344
I0624 12:23:14.058037 17113 layer_factory.hpp:77] Creating layer bn1_1
I0624 12:23:14.058043 17113 net.cpp:91] Creating Layer bn1_1
I0624 12:23:14.058045 17113 net.cpp:425] bn1_1 <- conv1_1
I0624 12:23:14.058049 17113 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0624 12:23:14.058867 17113 net.cpp:141] Setting up bn1_1
I0624 12:23:14.058878 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:14.058881 17113 net.cpp:156] Memory required for data: 13647872
I0624 12:23:14.058890 17113 layer_factory.hpp:77] Creating layer scale1_1
I0624 12:23:14.058897 17113 net.cpp:91] Creating Layer scale1_1
I0624 12:23:14.058899 17113 net.cpp:425] scale1_1 <- conv1_1
I0624 12:23:14.058903 17113 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0624 12:23:14.058993 17113 layer_factory.hpp:77] Creating layer scale1_1
I0624 12:23:14.059166 17113 net.cpp:141] Setting up scale1_1
I0624 12:23:14.059175 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:14.059177 17113 net.cpp:156] Memory required for data: 20070400
I0624 12:23:14.059195 17113 layer_factory.hpp:77] Creating layer relu1_1
I0624 12:23:14.059201 17113 net.cpp:91] Creating Layer relu1_1
I0624 12:23:14.059203 17113 net.cpp:425] relu1_1 <- conv1_1
I0624 12:23:14.059206 17113 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0624 12:23:14.059502 17113 net.cpp:141] Setting up relu1_1
I0624 12:23:14.059514 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:14.059515 17113 net.cpp:156] Memory required for data: 26492928
I0624 12:23:14.059519 17113 layer_factory.hpp:77] Creating layer conv1_2
I0624 12:23:14.059525 17113 net.cpp:91] Creating Layer conv1_2
I0624 12:23:14.059527 17113 net.cpp:425] conv1_2 <- conv1_1
I0624 12:23:14.059531 17113 net.cpp:399] conv1_2 -> conv1_2
I0624 12:23:14.060451 17113 net.cpp:141] Setting up conv1_2
I0624 12:23:14.060462 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:14.060464 17113 net.cpp:156] Memory required for data: 32915456
I0624 12:23:14.060468 17113 layer_factory.hpp:77] Creating layer bn1_2
I0624 12:23:14.060474 17113 net.cpp:91] Creating Layer bn1_2
I0624 12:23:14.060477 17113 net.cpp:425] bn1_2 <- conv1_2
I0624 12:23:14.060480 17113 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0624 12:23:14.060693 17113 net.cpp:141] Setting up bn1_2
I0624 12:23:14.060700 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:14.060703 17113 net.cpp:156] Memory required for data: 39337984
I0624 12:23:14.060710 17113 layer_factory.hpp:77] Creating layer scale1_2
I0624 12:23:14.060716 17113 net.cpp:91] Creating Layer scale1_2
I0624 12:23:14.060719 17113 net.cpp:425] scale1_2 <- conv1_2
I0624 12:23:14.060721 17113 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0624 12:23:14.060760 17113 layer_factory.hpp:77] Creating layer scale1_2
I0624 12:23:14.061497 17113 net.cpp:141] Setting up scale1_2
I0624 12:23:14.061508 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:14.061511 17113 net.cpp:156] Memory required for data: 45760512
I0624 12:23:14.061516 17113 layer_factory.hpp:77] Creating layer relu1_2
I0624 12:23:14.061520 17113 net.cpp:91] Creating Layer relu1_2
I0624 12:23:14.061522 17113 net.cpp:425] relu1_2 <- conv1_2
I0624 12:23:14.061525 17113 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0624 12:23:14.061810 17113 net.cpp:141] Setting up relu1_2
I0624 12:23:14.061820 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:14.061822 17113 net.cpp:156] Memory required for data: 52183040
I0624 12:23:14.061825 17113 layer_factory.hpp:77] Creating layer pool1
I0624 12:23:14.061828 17113 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 12:23:14.061832 17113 net.cpp:91] Creating Layer pool1
I0624 12:23:14.061835 17113 net.cpp:425] pool1 <- conv1_2
I0624 12:23:14.061838 17113 net.cpp:399] pool1 -> pool1
I0624 12:23:14.061843 17113 net.cpp:399] pool1 -> pool1_mask
I0624 12:23:14.061887 17113 net.cpp:141] Setting up pool1
I0624 12:23:14.061893 17113 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:23:14.061897 17113 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:23:14.061899 17113 net.cpp:156] Memory required for data: 55394304
I0624 12:23:14.061902 17113 layer_factory.hpp:77] Creating layer conv2_1
I0624 12:23:14.061908 17113 net.cpp:91] Creating Layer conv2_1
I0624 12:23:14.061910 17113 net.cpp:425] conv2_1 <- pool1
I0624 12:23:14.061914 17113 net.cpp:399] conv2_1 -> conv2_1
I0624 12:23:14.063001 17113 net.cpp:141] Setting up conv2_1
I0624 12:23:14.063012 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:14.063015 17113 net.cpp:156] Memory required for data: 58605568
I0624 12:23:14.063019 17113 layer_factory.hpp:77] Creating layer bn2_1
I0624 12:23:14.063024 17113 net.cpp:91] Creating Layer bn2_1
I0624 12:23:14.063027 17113 net.cpp:425] bn2_1 <- conv2_1
I0624 12:23:14.063030 17113 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0624 12:23:14.063233 17113 net.cpp:141] Setting up bn2_1
I0624 12:23:14.063241 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:14.063243 17113 net.cpp:156] Memory required for data: 61816832
I0624 12:23:14.063259 17113 layer_factory.hpp:77] Creating layer scale2_1
I0624 12:23:14.063264 17113 net.cpp:91] Creating Layer scale2_1
I0624 12:23:14.063267 17113 net.cpp:425] scale2_1 <- conv2_1
I0624 12:23:14.063271 17113 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0624 12:23:14.063313 17113 layer_factory.hpp:77] Creating layer scale2_1
I0624 12:23:14.063449 17113 net.cpp:141] Setting up scale2_1
I0624 12:23:14.063457 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:14.063459 17113 net.cpp:156] Memory required for data: 65028096
I0624 12:23:14.063467 17113 layer_factory.hpp:77] Creating layer relu2_1
I0624 12:23:14.063470 17113 net.cpp:91] Creating Layer relu2_1
I0624 12:23:14.063473 17113 net.cpp:425] relu2_1 <- conv2_1
I0624 12:23:14.063477 17113 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0624 12:23:14.063629 17113 net.cpp:141] Setting up relu2_1
I0624 12:23:14.063638 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:14.063640 17113 net.cpp:156] Memory required for data: 68239360
I0624 12:23:14.063643 17113 layer_factory.hpp:77] Creating layer conv2_2
I0624 12:23:14.063649 17113 net.cpp:91] Creating Layer conv2_2
I0624 12:23:14.063652 17113 net.cpp:425] conv2_2 <- conv2_1
I0624 12:23:14.063657 17113 net.cpp:399] conv2_2 -> conv2_2
I0624 12:23:14.064971 17113 net.cpp:141] Setting up conv2_2
I0624 12:23:14.064982 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:14.064985 17113 net.cpp:156] Memory required for data: 71450624
I0624 12:23:14.064990 17113 layer_factory.hpp:77] Creating layer bn2_2
I0624 12:23:14.064996 17113 net.cpp:91] Creating Layer bn2_2
I0624 12:23:14.064998 17113 net.cpp:425] bn2_2 <- conv2_2
I0624 12:23:14.065002 17113 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0624 12:23:14.065207 17113 net.cpp:141] Setting up bn2_2
I0624 12:23:14.065214 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:14.065217 17113 net.cpp:156] Memory required for data: 74661888
I0624 12:23:14.065222 17113 layer_factory.hpp:77] Creating layer scale2_2
I0624 12:23:14.065228 17113 net.cpp:91] Creating Layer scale2_2
I0624 12:23:14.065232 17113 net.cpp:425] scale2_2 <- conv2_2
I0624 12:23:14.065235 17113 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0624 12:23:14.065274 17113 layer_factory.hpp:77] Creating layer scale2_2
I0624 12:23:14.065408 17113 net.cpp:141] Setting up scale2_2
I0624 12:23:14.065415 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:14.065418 17113 net.cpp:156] Memory required for data: 77873152
I0624 12:23:14.065421 17113 layer_factory.hpp:77] Creating layer relu2_2
I0624 12:23:14.065425 17113 net.cpp:91] Creating Layer relu2_2
I0624 12:23:14.065428 17113 net.cpp:425] relu2_2 <- conv2_2
I0624 12:23:14.065431 17113 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0624 12:23:14.065723 17113 net.cpp:141] Setting up relu2_2
I0624 12:23:14.065734 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:14.065737 17113 net.cpp:156] Memory required for data: 81084416
I0624 12:23:14.065740 17113 layer_factory.hpp:77] Creating layer pool2
I0624 12:23:14.065743 17113 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 12:23:14.065748 17113 net.cpp:91] Creating Layer pool2
I0624 12:23:14.065752 17113 net.cpp:425] pool2 <- conv2_2
I0624 12:23:14.065755 17113 net.cpp:399] pool2 -> pool2
I0624 12:23:14.065760 17113 net.cpp:399] pool2 -> pool2_mask
I0624 12:23:14.065809 17113 net.cpp:141] Setting up pool2
I0624 12:23:14.065815 17113 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:23:14.065819 17113 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:23:14.065820 17113 net.cpp:156] Memory required for data: 82690048
I0624 12:23:14.065822 17113 layer_factory.hpp:77] Creating layer conv3_1
I0624 12:23:14.065830 17113 net.cpp:91] Creating Layer conv3_1
I0624 12:23:14.065834 17113 net.cpp:425] conv3_1 <- pool2
I0624 12:23:14.065837 17113 net.cpp:399] conv3_1 -> conv3_1
I0624 12:23:14.067296 17113 net.cpp:141] Setting up conv3_1
I0624 12:23:14.067309 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:14.067322 17113 net.cpp:156] Memory required for data: 84295680
I0624 12:23:14.067327 17113 layer_factory.hpp:77] Creating layer bn3_1
I0624 12:23:14.067333 17113 net.cpp:91] Creating Layer bn3_1
I0624 12:23:14.067337 17113 net.cpp:425] bn3_1 <- conv3_1
I0624 12:23:14.067340 17113 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0624 12:23:14.067539 17113 net.cpp:141] Setting up bn3_1
I0624 12:23:14.067548 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:14.067550 17113 net.cpp:156] Memory required for data: 85901312
I0624 12:23:14.067556 17113 layer_factory.hpp:77] Creating layer scale3_1
I0624 12:23:14.067562 17113 net.cpp:91] Creating Layer scale3_1
I0624 12:23:14.067564 17113 net.cpp:425] scale3_1 <- conv3_1
I0624 12:23:14.067569 17113 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0624 12:23:14.067606 17113 layer_factory.hpp:77] Creating layer scale3_1
I0624 12:23:14.067718 17113 net.cpp:141] Setting up scale3_1
I0624 12:23:14.067725 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:14.067728 17113 net.cpp:156] Memory required for data: 87506944
I0624 12:23:14.067731 17113 layer_factory.hpp:77] Creating layer relu3_1
I0624 12:23:14.067735 17113 net.cpp:91] Creating Layer relu3_1
I0624 12:23:14.067739 17113 net.cpp:425] relu3_1 <- conv3_1
I0624 12:23:14.067741 17113 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0624 12:23:14.068037 17113 net.cpp:141] Setting up relu3_1
I0624 12:23:14.068048 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:14.068049 17113 net.cpp:156] Memory required for data: 89112576
I0624 12:23:14.068053 17113 layer_factory.hpp:77] Creating layer conv3_2
I0624 12:23:14.068060 17113 net.cpp:91] Creating Layer conv3_2
I0624 12:23:14.068063 17113 net.cpp:425] conv3_2 <- conv3_1
I0624 12:23:14.068068 17113 net.cpp:399] conv3_2 -> conv3_2
I0624 12:23:14.070545 17113 net.cpp:141] Setting up conv3_2
I0624 12:23:14.070557 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:14.070560 17113 net.cpp:156] Memory required for data: 90718208
I0624 12:23:14.070564 17113 layer_factory.hpp:77] Creating layer bn3_2
I0624 12:23:14.070570 17113 net.cpp:91] Creating Layer bn3_2
I0624 12:23:14.070572 17113 net.cpp:425] bn3_2 <- conv3_2
I0624 12:23:14.070576 17113 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0624 12:23:14.070771 17113 net.cpp:141] Setting up bn3_2
I0624 12:23:14.070778 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:14.070781 17113 net.cpp:156] Memory required for data: 92323840
I0624 12:23:14.070791 17113 layer_factory.hpp:77] Creating layer scale3_2
I0624 12:23:14.070797 17113 net.cpp:91] Creating Layer scale3_2
I0624 12:23:14.070801 17113 net.cpp:425] scale3_2 <- conv3_2
I0624 12:23:14.070803 17113 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0624 12:23:14.070843 17113 layer_factory.hpp:77] Creating layer scale3_2
I0624 12:23:14.070955 17113 net.cpp:141] Setting up scale3_2
I0624 12:23:14.070963 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:14.070966 17113 net.cpp:156] Memory required for data: 93929472
I0624 12:23:14.070969 17113 layer_factory.hpp:77] Creating layer relu3_2
I0624 12:23:14.070974 17113 net.cpp:91] Creating Layer relu3_2
I0624 12:23:14.070976 17113 net.cpp:425] relu3_2 <- conv3_2
I0624 12:23:14.070979 17113 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0624 12:23:14.071135 17113 net.cpp:141] Setting up relu3_2
I0624 12:23:14.071146 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:14.071153 17113 net.cpp:156] Memory required for data: 95535104
I0624 12:23:14.071156 17113 layer_factory.hpp:77] Creating layer pool3
I0624 12:23:14.071159 17113 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 12:23:14.071163 17113 net.cpp:91] Creating Layer pool3
I0624 12:23:14.071166 17113 net.cpp:425] pool3 <- conv3_2
I0624 12:23:14.071169 17113 net.cpp:399] pool3 -> pool3
I0624 12:23:14.071174 17113 net.cpp:399] pool3 -> pool3_mask
I0624 12:23:14.071220 17113 net.cpp:141] Setting up pool3
I0624 12:23:14.071226 17113 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:23:14.071239 17113 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:23:14.071241 17113 net.cpp:156] Memory required for data: 96337920
I0624 12:23:14.071244 17113 layer_factory.hpp:77] Creating layer conv4_1
I0624 12:23:14.071250 17113 net.cpp:91] Creating Layer conv4_1
I0624 12:23:14.071254 17113 net.cpp:425] conv4_1 <- pool3
I0624 12:23:14.071257 17113 net.cpp:399] conv4_1 -> conv4_1
I0624 12:23:14.074728 17113 net.cpp:141] Setting up conv4_1
I0624 12:23:14.074741 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:14.074744 17113 net.cpp:156] Memory required for data: 97140736
I0624 12:23:14.074748 17113 layer_factory.hpp:77] Creating layer bn4_1
I0624 12:23:14.074754 17113 net.cpp:91] Creating Layer bn4_1
I0624 12:23:14.074758 17113 net.cpp:425] bn4_1 <- conv4_1
I0624 12:23:14.074762 17113 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0624 12:23:14.074971 17113 net.cpp:141] Setting up bn4_1
I0624 12:23:14.074978 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:14.074981 17113 net.cpp:156] Memory required for data: 97943552
I0624 12:23:14.074986 17113 layer_factory.hpp:77] Creating layer scale4_1
I0624 12:23:14.074992 17113 net.cpp:91] Creating Layer scale4_1
I0624 12:23:14.074995 17113 net.cpp:425] scale4_1 <- conv4_1
I0624 12:23:14.075000 17113 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0624 12:23:14.075042 17113 layer_factory.hpp:77] Creating layer scale4_1
I0624 12:23:14.075168 17113 net.cpp:141] Setting up scale4_1
I0624 12:23:14.075178 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:14.075181 17113 net.cpp:156] Memory required for data: 98746368
I0624 12:23:14.075186 17113 layer_factory.hpp:77] Creating layer relu4_1
I0624 12:23:14.075192 17113 net.cpp:91] Creating Layer relu4_1
I0624 12:23:14.075196 17113 net.cpp:425] relu4_1 <- conv4_1
I0624 12:23:14.075201 17113 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0624 12:23:14.075496 17113 net.cpp:141] Setting up relu4_1
I0624 12:23:14.075507 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:14.075510 17113 net.cpp:156] Memory required for data: 99549184
I0624 12:23:14.075512 17113 layer_factory.hpp:77] Creating layer conv4_2
I0624 12:23:14.075520 17113 net.cpp:91] Creating Layer conv4_2
I0624 12:23:14.075523 17113 net.cpp:425] conv4_2 <- conv4_1
I0624 12:23:14.075528 17113 net.cpp:399] conv4_2 -> conv4_2
I0624 12:23:14.080924 17113 net.cpp:141] Setting up conv4_2
I0624 12:23:14.080937 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:14.080940 17113 net.cpp:156] Memory required for data: 100352000
I0624 12:23:14.080945 17113 layer_factory.hpp:77] Creating layer bn4_2
I0624 12:23:14.080952 17113 net.cpp:91] Creating Layer bn4_2
I0624 12:23:14.080955 17113 net.cpp:425] bn4_2 <- conv4_2
I0624 12:23:14.080960 17113 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0624 12:23:14.081166 17113 net.cpp:141] Setting up bn4_2
I0624 12:23:14.081174 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:14.081176 17113 net.cpp:156] Memory required for data: 101154816
I0624 12:23:14.081182 17113 layer_factory.hpp:77] Creating layer scale4_2
I0624 12:23:14.081187 17113 net.cpp:91] Creating Layer scale4_2
I0624 12:23:14.081190 17113 net.cpp:425] scale4_2 <- conv4_2
I0624 12:23:14.081194 17113 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0624 12:23:14.081236 17113 layer_factory.hpp:77] Creating layer scale4_2
I0624 12:23:14.081358 17113 net.cpp:141] Setting up scale4_2
I0624 12:23:14.081367 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:14.081368 17113 net.cpp:156] Memory required for data: 101957632
I0624 12:23:14.081372 17113 layer_factory.hpp:77] Creating layer relu4_2
I0624 12:23:14.081377 17113 net.cpp:91] Creating Layer relu4_2
I0624 12:23:14.081382 17113 net.cpp:425] relu4_2 <- conv4_2
I0624 12:23:14.081387 17113 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0624 12:23:14.081681 17113 net.cpp:141] Setting up relu4_2
I0624 12:23:14.081691 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:14.081693 17113 net.cpp:156] Memory required for data: 102760448
I0624 12:23:14.081696 17113 layer_factory.hpp:77] Creating layer pool4
I0624 12:23:14.081710 17113 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 12:23:14.081715 17113 net.cpp:91] Creating Layer pool4
I0624 12:23:14.081718 17113 net.cpp:425] pool4 <- conv4_2
I0624 12:23:14.081723 17113 net.cpp:399] pool4 -> pool4
I0624 12:23:14.081728 17113 net.cpp:399] pool4 -> pool4_mask
I0624 12:23:14.081780 17113 net.cpp:141] Setting up pool4
I0624 12:23:14.081787 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.081790 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.081792 17113 net.cpp:156] Memory required for data: 103161856
I0624 12:23:14.081794 17113 layer_factory.hpp:77] Creating layer conv5_1
I0624 12:23:14.081804 17113 net.cpp:91] Creating Layer conv5_1
I0624 12:23:14.081807 17113 net.cpp:425] conv5_1 <- pool4
I0624 12:23:14.081811 17113 net.cpp:399] conv5_1 -> conv5_1
I0624 12:23:14.087363 17113 net.cpp:141] Setting up conv5_1
I0624 12:23:14.087375 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.087378 17113 net.cpp:156] Memory required for data: 103362560
I0624 12:23:14.087383 17113 layer_factory.hpp:77] Creating layer bn5_1
I0624 12:23:14.087389 17113 net.cpp:91] Creating Layer bn5_1
I0624 12:23:14.087393 17113 net.cpp:425] bn5_1 <- conv5_1
I0624 12:23:14.087398 17113 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0624 12:23:14.087604 17113 net.cpp:141] Setting up bn5_1
I0624 12:23:14.087611 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.087615 17113 net.cpp:156] Memory required for data: 103563264
I0624 12:23:14.087620 17113 layer_factory.hpp:77] Creating layer scale5_1
I0624 12:23:14.087625 17113 net.cpp:91] Creating Layer scale5_1
I0624 12:23:14.087628 17113 net.cpp:425] scale5_1 <- conv5_1
I0624 12:23:14.087632 17113 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0624 12:23:14.087674 17113 layer_factory.hpp:77] Creating layer scale5_1
I0624 12:23:14.087790 17113 net.cpp:141] Setting up scale5_1
I0624 12:23:14.087797 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.087800 17113 net.cpp:156] Memory required for data: 103763968
I0624 12:23:14.087803 17113 layer_factory.hpp:77] Creating layer relu5_1
I0624 12:23:14.087807 17113 net.cpp:91] Creating Layer relu5_1
I0624 12:23:14.087810 17113 net.cpp:425] relu5_1 <- conv5_1
I0624 12:23:14.087813 17113 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0624 12:23:14.087981 17113 net.cpp:141] Setting up relu5_1
I0624 12:23:14.087990 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.087993 17113 net.cpp:156] Memory required for data: 103964672
I0624 12:23:14.087996 17113 layer_factory.hpp:77] Creating layer conv5_2
I0624 12:23:14.088004 17113 net.cpp:91] Creating Layer conv5_2
I0624 12:23:14.088006 17113 net.cpp:425] conv5_2 <- conv5_1
I0624 12:23:14.088012 17113 net.cpp:399] conv5_2 -> conv5_2
I0624 12:23:14.093572 17113 net.cpp:141] Setting up conv5_2
I0624 12:23:14.093590 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.093593 17113 net.cpp:156] Memory required for data: 104165376
I0624 12:23:14.093600 17113 layer_factory.hpp:77] Creating layer bn5_2
I0624 12:23:14.093611 17113 net.cpp:91] Creating Layer bn5_2
I0624 12:23:14.093616 17113 net.cpp:425] bn5_2 <- conv5_2
I0624 12:23:14.093623 17113 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0624 12:23:14.093850 17113 net.cpp:141] Setting up bn5_2
I0624 12:23:14.093861 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.093865 17113 net.cpp:156] Memory required for data: 104366080
I0624 12:23:14.093874 17113 layer_factory.hpp:77] Creating layer scale5_2
I0624 12:23:14.093886 17113 net.cpp:91] Creating Layer scale5_2
I0624 12:23:14.093891 17113 net.cpp:425] scale5_2 <- conv5_2
I0624 12:23:14.093899 17113 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0624 12:23:14.093956 17113 layer_factory.hpp:77] Creating layer scale5_2
I0624 12:23:14.094090 17113 net.cpp:141] Setting up scale5_2
I0624 12:23:14.094100 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.094105 17113 net.cpp:156] Memory required for data: 104566784
I0624 12:23:14.094125 17113 layer_factory.hpp:77] Creating layer relu5_2
I0624 12:23:14.094136 17113 net.cpp:91] Creating Layer relu5_2
I0624 12:23:14.094144 17113 net.cpp:425] relu5_2 <- conv5_2
I0624 12:23:14.094151 17113 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0624 12:23:14.094462 17113 net.cpp:141] Setting up relu5_2
I0624 12:23:14.094475 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.094480 17113 net.cpp:156] Memory required for data: 104767488
I0624 12:23:14.094485 17113 layer_factory.hpp:77] Creating layer pool5
I0624 12:23:14.094490 17113 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 12:23:14.094498 17113 net.cpp:91] Creating Layer pool5
I0624 12:23:14.094503 17113 net.cpp:425] pool5 <- conv5_2
I0624 12:23:14.094511 17113 net.cpp:399] pool5 -> pool5
I0624 12:23:14.094521 17113 net.cpp:399] pool5 -> pool5_mask
I0624 12:23:14.094583 17113 net.cpp:141] Setting up pool5
I0624 12:23:14.094594 17113 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 12:23:14.094599 17113 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 12:23:14.094602 17113 net.cpp:156] Memory required for data: 104867840
I0624 12:23:14.094606 17113 layer_factory.hpp:77] Creating layer upsample5
I0624 12:23:14.094616 17113 net.cpp:91] Creating Layer upsample5
I0624 12:23:14.094621 17113 net.cpp:425] upsample5 <- pool5
I0624 12:23:14.094626 17113 net.cpp:425] upsample5 <- pool5_mask
I0624 12:23:14.094633 17113 net.cpp:399] upsample5 -> pool5_D
I0624 12:23:14.094673 17113 net.cpp:141] Setting up upsample5
I0624 12:23:14.094682 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.094686 17113 net.cpp:156] Memory required for data: 105068544
I0624 12:23:14.094691 17113 layer_factory.hpp:77] Creating layer conv5_2_D
I0624 12:23:14.094702 17113 net.cpp:91] Creating Layer conv5_2_D
I0624 12:23:14.094707 17113 net.cpp:425] conv5_2_D <- pool5_D
I0624 12:23:14.094714 17113 net.cpp:399] conv5_2_D -> conv5_2_D
I0624 12:23:14.100437 17113 net.cpp:141] Setting up conv5_2_D
I0624 12:23:14.100455 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.100458 17113 net.cpp:156] Memory required for data: 105269248
I0624 12:23:14.100466 17113 layer_factory.hpp:77] Creating layer bn5_2_D
I0624 12:23:14.100479 17113 net.cpp:91] Creating Layer bn5_2_D
I0624 12:23:14.100487 17113 net.cpp:425] bn5_2_D <- conv5_2_D
I0624 12:23:14.100497 17113 net.cpp:386] bn5_2_D -> conv5_2_D (in-place)
I0624 12:23:14.100723 17113 net.cpp:141] Setting up bn5_2_D
I0624 12:23:14.100734 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.100739 17113 net.cpp:156] Memory required for data: 105469952
I0624 12:23:14.100749 17113 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 12:23:14.100764 17113 net.cpp:91] Creating Layer scale5_2_D
I0624 12:23:14.100770 17113 net.cpp:425] scale5_2_D <- conv5_2_D
I0624 12:23:14.100778 17113 net.cpp:386] scale5_2_D -> conv5_2_D (in-place)
I0624 12:23:14.100836 17113 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 12:23:14.100971 17113 net.cpp:141] Setting up scale5_2_D
I0624 12:23:14.100981 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.100986 17113 net.cpp:156] Memory required for data: 105670656
I0624 12:23:14.101007 17113 layer_factory.hpp:77] Creating layer relu5_2_D
I0624 12:23:14.101017 17113 net.cpp:91] Creating Layer relu5_2_D
I0624 12:23:14.101022 17113 net.cpp:425] relu5_2_D <- conv5_2_D
I0624 12:23:14.101028 17113 net.cpp:386] relu5_2_D -> conv5_2_D (in-place)
I0624 12:23:14.101339 17113 net.cpp:141] Setting up relu5_2_D
I0624 12:23:14.101351 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.101356 17113 net.cpp:156] Memory required for data: 105871360
I0624 12:23:14.101361 17113 layer_factory.hpp:77] Creating layer conv5_1_D
I0624 12:23:14.101374 17113 net.cpp:91] Creating Layer conv5_1_D
I0624 12:23:14.101380 17113 net.cpp:425] conv5_1_D <- conv5_2_D
I0624 12:23:14.101388 17113 net.cpp:399] conv5_1_D -> conv5_1_D
I0624 12:23:14.107218 17113 net.cpp:141] Setting up conv5_1_D
I0624 12:23:14.107245 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.107250 17113 net.cpp:156] Memory required for data: 106072064
I0624 12:23:14.107257 17113 layer_factory.hpp:77] Creating layer bn5_1_D
I0624 12:23:14.107267 17113 net.cpp:91] Creating Layer bn5_1_D
I0624 12:23:14.107273 17113 net.cpp:425] bn5_1_D <- conv5_1_D
I0624 12:23:14.107280 17113 net.cpp:386] bn5_1_D -> conv5_1_D (in-place)
I0624 12:23:14.107512 17113 net.cpp:141] Setting up bn5_1_D
I0624 12:23:14.107523 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.107527 17113 net.cpp:156] Memory required for data: 106272768
I0624 12:23:14.107537 17113 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 12:23:14.107548 17113 net.cpp:91] Creating Layer scale5_1_D
I0624 12:23:14.107553 17113 net.cpp:425] scale5_1_D <- conv5_1_D
I0624 12:23:14.107560 17113 net.cpp:386] scale5_1_D -> conv5_1_D (in-place)
I0624 12:23:14.107631 17113 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 12:23:14.107774 17113 net.cpp:141] Setting up scale5_1_D
I0624 12:23:14.107784 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.107787 17113 net.cpp:156] Memory required for data: 106473472
I0624 12:23:14.107795 17113 layer_factory.hpp:77] Creating layer relu5_1_D
I0624 12:23:14.107802 17113 net.cpp:91] Creating Layer relu5_1_D
I0624 12:23:14.107807 17113 net.cpp:425] relu5_1_D <- conv5_1_D
I0624 12:23:14.107815 17113 net.cpp:386] relu5_1_D -> conv5_1_D (in-place)
I0624 12:23:14.107987 17113 net.cpp:141] Setting up relu5_1_D
I0624 12:23:14.108000 17113 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:23:14.108003 17113 net.cpp:156] Memory required for data: 106674176
I0624 12:23:14.108007 17113 layer_factory.hpp:77] Creating layer upsample4
I0624 12:23:14.108016 17113 net.cpp:91] Creating Layer upsample4
I0624 12:23:14.108021 17113 net.cpp:425] upsample4 <- conv5_1_D
I0624 12:23:14.108026 17113 net.cpp:425] upsample4 <- pool4_mask
I0624 12:23:14.108036 17113 net.cpp:399] upsample4 -> pool4_D
I0624 12:23:14.108081 17113 net.cpp:141] Setting up upsample4
I0624 12:23:14.108091 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:14.108094 17113 net.cpp:156] Memory required for data: 107476992
I0624 12:23:14.108098 17113 layer_factory.hpp:77] Creating layer conv4_2_D
I0624 12:23:14.108113 17113 net.cpp:91] Creating Layer conv4_2_D
I0624 12:23:14.108119 17113 net.cpp:425] conv4_2_D <- pool4_D
I0624 12:23:14.108125 17113 net.cpp:399] conv4_2_D -> conv4_2_D
I0624 12:23:14.113699 17113 net.cpp:141] Setting up conv4_2_D
I0624 12:23:14.113715 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:14.113720 17113 net.cpp:156] Memory required for data: 108279808
I0624 12:23:14.113726 17113 layer_factory.hpp:77] Creating layer bn4_2_D
I0624 12:23:14.113735 17113 net.cpp:91] Creating Layer bn4_2_D
I0624 12:23:14.113741 17113 net.cpp:425] bn4_2_D <- conv4_2_D
I0624 12:23:14.113750 17113 net.cpp:386] bn4_2_D -> conv4_2_D (in-place)
I0624 12:23:14.113983 17113 net.cpp:141] Setting up bn4_2_D
I0624 12:23:14.113993 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:14.113997 17113 net.cpp:156] Memory required for data: 109082624
I0624 12:23:14.114008 17113 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 12:23:14.114019 17113 net.cpp:91] Creating Layer scale4_2_D
I0624 12:23:14.114024 17113 net.cpp:425] scale4_2_D <- conv4_2_D
I0624 12:23:14.114032 17113 net.cpp:386] scale4_2_D -> conv4_2_D (in-place)
I0624 12:23:14.114096 17113 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 12:23:14.114243 17113 net.cpp:141] Setting up scale4_2_D
I0624 12:23:14.114253 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:14.114256 17113 net.cpp:156] Memory required for data: 109885440
I0624 12:23:14.114264 17113 layer_factory.hpp:77] Creating layer relu4_2_D
I0624 12:23:14.114280 17113 net.cpp:91] Creating Layer relu4_2_D
I0624 12:23:14.114290 17113 net.cpp:425] relu4_2_D <- conv4_2_D
I0624 12:23:14.114297 17113 net.cpp:386] relu4_2_D -> conv4_2_D (in-place)
I0624 12:23:14.114620 17113 net.cpp:141] Setting up relu4_2_D
I0624 12:23:14.114642 17113 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:23:14.114647 17113 net.cpp:156] Memory required for data: 110688256
I0624 12:23:14.114652 17113 layer_factory.hpp:77] Creating layer conv4_1_D
I0624 12:23:14.114665 17113 net.cpp:91] Creating Layer conv4_1_D
I0624 12:23:14.114671 17113 net.cpp:425] conv4_1_D <- conv4_2_D
I0624 12:23:14.114680 17113 net.cpp:399] conv4_1_D -> conv4_1_D
I0624 12:23:14.118037 17113 net.cpp:141] Setting up conv4_1_D
I0624 12:23:14.118051 17113 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:23:14.118055 17113 net.cpp:156] Memory required for data: 111089664
I0624 12:23:14.118063 17113 layer_factory.hpp:77] Creating layer bn4_1_D
I0624 12:23:14.118073 17113 net.cpp:91] Creating Layer bn4_1_D
I0624 12:23:14.118079 17113 net.cpp:425] bn4_1_D <- conv4_1_D
I0624 12:23:14.118086 17113 net.cpp:386] bn4_1_D -> conv4_1_D (in-place)
I0624 12:23:14.118319 17113 net.cpp:141] Setting up bn4_1_D
I0624 12:23:14.118330 17113 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:23:14.118332 17113 net.cpp:156] Memory required for data: 111491072
I0624 12:23:14.118342 17113 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 12:23:14.118353 17113 net.cpp:91] Creating Layer scale4_1_D
I0624 12:23:14.118358 17113 net.cpp:425] scale4_1_D <- conv4_1_D
I0624 12:23:14.118366 17113 net.cpp:386] scale4_1_D -> conv4_1_D (in-place)
I0624 12:23:14.118425 17113 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 12:23:14.118571 17113 net.cpp:141] Setting up scale4_1_D
I0624 12:23:14.118580 17113 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:23:14.118584 17113 net.cpp:156] Memory required for data: 111892480
I0624 12:23:14.118592 17113 layer_factory.hpp:77] Creating layer relu4_1_D
I0624 12:23:14.118610 17113 net.cpp:91] Creating Layer relu4_1_D
I0624 12:23:14.118618 17113 net.cpp:425] relu4_1_D <- conv4_1_D
I0624 12:23:14.118624 17113 net.cpp:386] relu4_1_D -> conv4_1_D (in-place)
I0624 12:23:14.118947 17113 net.cpp:141] Setting up relu4_1_D
I0624 12:23:14.118959 17113 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:23:14.118963 17113 net.cpp:156] Memory required for data: 112293888
I0624 12:23:14.118969 17113 layer_factory.hpp:77] Creating layer upsample3
I0624 12:23:14.118978 17113 net.cpp:91] Creating Layer upsample3
I0624 12:23:14.118983 17113 net.cpp:425] upsample3 <- conv4_1_D
I0624 12:23:14.118988 17113 net.cpp:425] upsample3 <- pool3_mask
I0624 12:23:14.118998 17113 net.cpp:399] upsample3 -> pool3_D
I0624 12:23:14.119041 17113 net.cpp:141] Setting up upsample3
I0624 12:23:14.119051 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:14.119055 17113 net.cpp:156] Memory required for data: 113899520
I0624 12:23:14.119060 17113 layer_factory.hpp:77] Creating layer conv3_2_D
I0624 12:23:14.119073 17113 net.cpp:91] Creating Layer conv3_2_D
I0624 12:23:14.119081 17113 net.cpp:425] conv3_2_D <- pool3_D
I0624 12:23:14.119089 17113 net.cpp:399] conv3_2_D -> conv3_2_D
I0624 12:23:14.121744 17113 net.cpp:141] Setting up conv3_2_D
I0624 12:23:14.121758 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:14.121762 17113 net.cpp:156] Memory required for data: 115505152
I0624 12:23:14.121772 17113 layer_factory.hpp:77] Creating layer bn3_2_D
I0624 12:23:14.121783 17113 net.cpp:91] Creating Layer bn3_2_D
I0624 12:23:14.121788 17113 net.cpp:425] bn3_2_D <- conv3_2_D
I0624 12:23:14.121794 17113 net.cpp:386] bn3_2_D -> conv3_2_D (in-place)
I0624 12:23:14.122028 17113 net.cpp:141] Setting up bn3_2_D
I0624 12:23:14.122040 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:14.122043 17113 net.cpp:156] Memory required for data: 117110784
I0624 12:23:14.122052 17113 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 12:23:14.122062 17113 net.cpp:91] Creating Layer scale3_2_D
I0624 12:23:14.122067 17113 net.cpp:425] scale3_2_D <- conv3_2_D
I0624 12:23:14.122076 17113 net.cpp:386] scale3_2_D -> conv3_2_D (in-place)
I0624 12:23:14.122133 17113 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 12:23:14.122298 17113 net.cpp:141] Setting up scale3_2_D
I0624 12:23:14.122318 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:14.122321 17113 net.cpp:156] Memory required for data: 118716416
I0624 12:23:14.122329 17113 layer_factory.hpp:77] Creating layer relu3_2_D
I0624 12:23:14.122337 17113 net.cpp:91] Creating Layer relu3_2_D
I0624 12:23:14.122341 17113 net.cpp:425] relu3_2_D <- conv3_2_D
I0624 12:23:14.122349 17113 net.cpp:386] relu3_2_D -> conv3_2_D (in-place)
I0624 12:23:14.122531 17113 net.cpp:141] Setting up relu3_2_D
I0624 12:23:14.122542 17113 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:23:14.122546 17113 net.cpp:156] Memory required for data: 120322048
I0624 12:23:14.122551 17113 layer_factory.hpp:77] Creating layer conv3_1_D
I0624 12:23:14.122563 17113 net.cpp:91] Creating Layer conv3_1_D
I0624 12:23:14.122568 17113 net.cpp:425] conv3_1_D <- conv3_2_D
I0624 12:23:14.122575 17113 net.cpp:399] conv3_1_D -> conv3_1_D
I0624 12:23:14.124119 17113 net.cpp:141] Setting up conv3_1_D
I0624 12:23:14.124135 17113 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:23:14.124140 17113 net.cpp:156] Memory required for data: 121124864
I0624 12:23:14.124147 17113 layer_factory.hpp:77] Creating layer bn3_1_D
I0624 12:23:14.124157 17113 net.cpp:91] Creating Layer bn3_1_D
I0624 12:23:14.124162 17113 net.cpp:425] bn3_1_D <- conv3_1_D
I0624 12:23:14.124169 17113 net.cpp:386] bn3_1_D -> conv3_1_D (in-place)
I0624 12:23:14.124413 17113 net.cpp:141] Setting up bn3_1_D
I0624 12:23:14.124423 17113 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:23:14.124426 17113 net.cpp:156] Memory required for data: 121927680
I0624 12:23:14.124436 17113 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 12:23:14.124445 17113 net.cpp:91] Creating Layer scale3_1_D
I0624 12:23:14.124450 17113 net.cpp:425] scale3_1_D <- conv3_1_D
I0624 12:23:14.124456 17113 net.cpp:386] scale3_1_D -> conv3_1_D (in-place)
I0624 12:23:14.124521 17113 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 12:23:14.124676 17113 net.cpp:141] Setting up scale3_1_D
I0624 12:23:14.124686 17113 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:23:14.124689 17113 net.cpp:156] Memory required for data: 122730496
I0624 12:23:14.124697 17113 layer_factory.hpp:77] Creating layer relu3_1_D
I0624 12:23:14.124704 17113 net.cpp:91] Creating Layer relu3_1_D
I0624 12:23:14.124708 17113 net.cpp:425] relu3_1_D <- conv3_1_D
I0624 12:23:14.124714 17113 net.cpp:386] relu3_1_D -> conv3_1_D (in-place)
I0624 12:23:14.125046 17113 net.cpp:141] Setting up relu3_1_D
I0624 12:23:14.125058 17113 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:23:14.125062 17113 net.cpp:156] Memory required for data: 123533312
I0624 12:23:14.125067 17113 layer_factory.hpp:77] Creating layer upsample2
I0624 12:23:14.125075 17113 net.cpp:91] Creating Layer upsample2
I0624 12:23:14.125080 17113 net.cpp:425] upsample2 <- conv3_1_D
I0624 12:23:14.125087 17113 net.cpp:425] upsample2 <- pool2_mask
I0624 12:23:14.125092 17113 net.cpp:399] upsample2 -> pool2_D
I0624 12:23:14.125138 17113 net.cpp:141] Setting up upsample2
I0624 12:23:14.125149 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:14.125151 17113 net.cpp:156] Memory required for data: 126744576
I0624 12:23:14.125155 17113 layer_factory.hpp:77] Creating layer conv2_2_D
I0624 12:23:14.125169 17113 net.cpp:91] Creating Layer conv2_2_D
I0624 12:23:14.125174 17113 net.cpp:425] conv2_2_D <- pool2_D
I0624 12:23:14.125182 17113 net.cpp:399] conv2_2_D -> conv2_2_D
I0624 12:23:14.126402 17113 net.cpp:141] Setting up conv2_2_D
I0624 12:23:14.126416 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:14.126421 17113 net.cpp:156] Memory required for data: 129955840
I0624 12:23:14.126427 17113 layer_factory.hpp:77] Creating layer bn2_2_D
I0624 12:23:14.126438 17113 net.cpp:91] Creating Layer bn2_2_D
I0624 12:23:14.126443 17113 net.cpp:425] bn2_2_D <- conv2_2_D
I0624 12:23:14.126451 17113 net.cpp:386] bn2_2_D -> conv2_2_D (in-place)
I0624 12:23:14.127334 17113 net.cpp:141] Setting up bn2_2_D
I0624 12:23:14.127346 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:14.127363 17113 net.cpp:156] Memory required for data: 133167104
I0624 12:23:14.127375 17113 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 12:23:14.127385 17113 net.cpp:91] Creating Layer scale2_2_D
I0624 12:23:14.127396 17113 net.cpp:425] scale2_2_D <- conv2_2_D
I0624 12:23:14.127403 17113 net.cpp:386] scale2_2_D -> conv2_2_D (in-place)
I0624 12:23:14.127470 17113 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 12:23:14.127632 17113 net.cpp:141] Setting up scale2_2_D
I0624 12:23:14.127648 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:14.127651 17113 net.cpp:156] Memory required for data: 136378368
I0624 12:23:14.127657 17113 layer_factory.hpp:77] Creating layer relu2_2_D
I0624 12:23:14.127663 17113 net.cpp:91] Creating Layer relu2_2_D
I0624 12:23:14.127671 17113 net.cpp:425] relu2_2_D <- conv2_2_D
I0624 12:23:14.127677 17113 net.cpp:386] relu2_2_D -> conv2_2_D (in-place)
I0624 12:23:14.128068 17113 net.cpp:141] Setting up relu2_2_D
I0624 12:23:14.128085 17113 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:23:14.128090 17113 net.cpp:156] Memory required for data: 139589632
I0624 12:23:14.128094 17113 layer_factory.hpp:77] Creating layer conv2_1_D
I0624 12:23:14.128108 17113 net.cpp:91] Creating Layer conv2_1_D
I0624 12:23:14.128113 17113 net.cpp:425] conv2_1_D <- conv2_2_D
I0624 12:23:14.128121 17113 net.cpp:399] conv2_1_D -> conv2_1_D
I0624 12:23:14.129415 17113 net.cpp:141] Setting up conv2_1_D
I0624 12:23:14.129427 17113 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:23:14.129429 17113 net.cpp:156] Memory required for data: 141195264
I0624 12:23:14.129434 17113 layer_factory.hpp:77] Creating layer bn2_1_D
I0624 12:23:14.129441 17113 net.cpp:91] Creating Layer bn2_1_D
I0624 12:23:14.129444 17113 net.cpp:425] bn2_1_D <- conv2_1_D
I0624 12:23:14.129448 17113 net.cpp:386] bn2_1_D -> conv2_1_D (in-place)
I0624 12:23:14.129690 17113 net.cpp:141] Setting up bn2_1_D
I0624 12:23:14.129698 17113 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:23:14.129700 17113 net.cpp:156] Memory required for data: 142800896
I0624 12:23:14.129706 17113 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 12:23:14.129712 17113 net.cpp:91] Creating Layer scale2_1_D
I0624 12:23:14.129715 17113 net.cpp:425] scale2_1_D <- conv2_1_D
I0624 12:23:14.129719 17113 net.cpp:386] scale2_1_D -> conv2_1_D (in-place)
I0624 12:23:14.129765 17113 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 12:23:14.129909 17113 net.cpp:141] Setting up scale2_1_D
I0624 12:23:14.129917 17113 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:23:14.129920 17113 net.cpp:156] Memory required for data: 144406528
I0624 12:23:14.129925 17113 layer_factory.hpp:77] Creating layer relu2_1_D
I0624 12:23:14.129930 17113 net.cpp:91] Creating Layer relu2_1_D
I0624 12:23:14.129932 17113 net.cpp:425] relu2_1_D <- conv2_1_D
I0624 12:23:14.129935 17113 net.cpp:386] relu2_1_D -> conv2_1_D (in-place)
I0624 12:23:14.130105 17113 net.cpp:141] Setting up relu2_1_D
I0624 12:23:14.130113 17113 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:23:14.130116 17113 net.cpp:156] Memory required for data: 146012160
I0624 12:23:14.130118 17113 layer_factory.hpp:77] Creating layer upsample1
I0624 12:23:14.130126 17113 net.cpp:91] Creating Layer upsample1
I0624 12:23:14.130130 17113 net.cpp:425] upsample1 <- conv2_1_D
I0624 12:23:14.130132 17113 net.cpp:425] upsample1 <- pool1_mask
I0624 12:23:14.130137 17113 net.cpp:399] upsample1 -> pool1_D
I0624 12:23:14.130172 17113 net.cpp:141] Setting up upsample1
I0624 12:23:14.130177 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:14.130179 17113 net.cpp:156] Memory required for data: 152434688
I0624 12:23:14.130182 17113 layer_factory.hpp:77] Creating layer conv1_2_D
I0624 12:23:14.130189 17113 net.cpp:91] Creating Layer conv1_2_D
I0624 12:23:14.130192 17113 net.cpp:425] conv1_2_D <- pool1_D
I0624 12:23:14.130198 17113 net.cpp:399] conv1_2_D -> conv1_2_D
I0624 12:23:14.131366 17113 net.cpp:141] Setting up conv1_2_D
I0624 12:23:14.131378 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:14.131392 17113 net.cpp:156] Memory required for data: 158857216
I0624 12:23:14.131395 17113 layer_factory.hpp:77] Creating layer bn1_2_D
I0624 12:23:14.131402 17113 net.cpp:91] Creating Layer bn1_2_D
I0624 12:23:14.131404 17113 net.cpp:425] bn1_2_D <- conv1_2_D
I0624 12:23:14.131409 17113 net.cpp:386] bn1_2_D -> conv1_2_D (in-place)
I0624 12:23:14.131692 17113 net.cpp:141] Setting up bn1_2_D
I0624 12:23:14.131700 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:14.131703 17113 net.cpp:156] Memory required for data: 165279744
I0624 12:23:14.131708 17113 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 12:23:14.131714 17113 net.cpp:91] Creating Layer scale1_2_D
I0624 12:23:14.131716 17113 net.cpp:425] scale1_2_D <- conv1_2_D
I0624 12:23:14.131721 17113 net.cpp:386] scale1_2_D -> conv1_2_D (in-place)
I0624 12:23:14.131768 17113 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 12:23:14.132635 17113 net.cpp:141] Setting up scale1_2_D
I0624 12:23:14.132647 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:14.132649 17113 net.cpp:156] Memory required for data: 171702272
I0624 12:23:14.132654 17113 layer_factory.hpp:77] Creating layer relu1_2_D
I0624 12:23:14.132659 17113 net.cpp:91] Creating Layer relu1_2_D
I0624 12:23:14.132663 17113 net.cpp:425] relu1_2_D <- conv1_2_D
I0624 12:23:14.132666 17113 net.cpp:386] relu1_2_D -> conv1_2_D (in-place)
I0624 12:23:14.132989 17113 net.cpp:141] Setting up relu1_2_D
I0624 12:23:14.133000 17113 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:23:14.133002 17113 net.cpp:156] Memory required for data: 178124800
I0624 12:23:14.133005 17113 layer_factory.hpp:77] Creating layer conv1_1_D
I0624 12:23:14.133014 17113 net.cpp:91] Creating Layer conv1_1_D
I0624 12:23:14.133020 17113 net.cpp:425] conv1_1_D <- conv1_2_D
I0624 12:23:14.133025 17113 net.cpp:399] conv1_1_D -> conv1_1_D
I0624 12:23:14.134261 17113 net.cpp:141] Setting up conv1_1_D
I0624 12:23:14.134274 17113 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 12:23:14.134275 17113 net.cpp:156] Memory required for data: 178526208
I0624 12:23:14.134281 17113 layer_factory.hpp:77] Creating layer conv1_1_D_conv1_1_D_0_split
I0624 12:23:14.134286 17113 net.cpp:91] Creating Layer conv1_1_D_conv1_1_D_0_split
I0624 12:23:14.134289 17113 net.cpp:425] conv1_1_D_conv1_1_D_0_split <- conv1_1_D
I0624 12:23:14.134294 17113 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_0
I0624 12:23:14.134299 17113 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_1
I0624 12:23:14.134353 17113 net.cpp:141] Setting up conv1_1_D_conv1_1_D_0_split
I0624 12:23:14.134361 17113 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 12:23:14.134363 17113 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 12:23:14.134366 17113 net.cpp:156] Memory required for data: 179329024
I0624 12:23:14.134368 17113 layer_factory.hpp:77] Creating layer loss
I0624 12:23:14.134374 17113 net.cpp:91] Creating Layer loss
I0624 12:23:14.134377 17113 net.cpp:425] loss <- conv1_1_D_conv1_1_D_0_split_0
I0624 12:23:14.134380 17113 net.cpp:425] loss <- label_data_1_split_0
I0624 12:23:14.134384 17113 net.cpp:399] loss -> loss
I0624 12:23:14.134389 17113 layer_factory.hpp:77] Creating layer loss
I0624 12:23:14.134887 17113 net.cpp:141] Setting up loss
I0624 12:23:14.134898 17113 net.cpp:148] Top shape: (1)
I0624 12:23:14.134901 17113 net.cpp:151]     with loss weight 1
I0624 12:23:14.134908 17113 net.cpp:156] Memory required for data: 179329028
I0624 12:23:14.134912 17113 layer_factory.hpp:77] Creating layer accuracy
I0624 12:23:14.134917 17113 net.cpp:91] Creating Layer accuracy
I0624 12:23:14.134920 17113 net.cpp:425] accuracy <- conv1_1_D_conv1_1_D_0_split_1
I0624 12:23:14.134923 17113 net.cpp:425] accuracy <- label_data_1_split_1
I0624 12:23:14.134927 17113 net.cpp:399] accuracy -> accuracy
I0624 12:23:14.134934 17113 net.cpp:141] Setting up accuracy
I0624 12:23:14.134938 17113 net.cpp:148] Top shape: (1)
I0624 12:23:14.134939 17113 net.cpp:156] Memory required for data: 179329032
I0624 12:23:14.134950 17113 net.cpp:219] accuracy does not need backward computation.
I0624 12:23:14.134953 17113 net.cpp:217] loss needs backward computation.
I0624 12:23:14.134956 17113 net.cpp:217] conv1_1_D_conv1_1_D_0_split needs backward computation.
I0624 12:23:14.134958 17113 net.cpp:217] conv1_1_D needs backward computation.
I0624 12:23:14.134961 17113 net.cpp:217] relu1_2_D needs backward computation.
I0624 12:23:14.134963 17113 net.cpp:217] scale1_2_D needs backward computation.
I0624 12:23:14.134965 17113 net.cpp:217] bn1_2_D needs backward computation.
I0624 12:23:14.134966 17113 net.cpp:217] conv1_2_D needs backward computation.
I0624 12:23:14.134969 17113 net.cpp:217] upsample1 needs backward computation.
I0624 12:23:14.134971 17113 net.cpp:217] relu2_1_D needs backward computation.
I0624 12:23:14.134974 17113 net.cpp:217] scale2_1_D needs backward computation.
I0624 12:23:14.134975 17113 net.cpp:217] bn2_1_D needs backward computation.
I0624 12:23:14.134977 17113 net.cpp:217] conv2_1_D needs backward computation.
I0624 12:23:14.134979 17113 net.cpp:217] relu2_2_D needs backward computation.
I0624 12:23:14.134982 17113 net.cpp:217] scale2_2_D needs backward computation.
I0624 12:23:14.134984 17113 net.cpp:217] bn2_2_D needs backward computation.
I0624 12:23:14.134986 17113 net.cpp:217] conv2_2_D needs backward computation.
I0624 12:23:14.134989 17113 net.cpp:217] upsample2 needs backward computation.
I0624 12:23:14.134991 17113 net.cpp:217] relu3_1_D needs backward computation.
I0624 12:23:14.134994 17113 net.cpp:217] scale3_1_D needs backward computation.
I0624 12:23:14.134996 17113 net.cpp:217] bn3_1_D needs backward computation.
I0624 12:23:14.134999 17113 net.cpp:217] conv3_1_D needs backward computation.
I0624 12:23:14.135000 17113 net.cpp:217] relu3_2_D needs backward computation.
I0624 12:23:14.135002 17113 net.cpp:217] scale3_2_D needs backward computation.
I0624 12:23:14.135004 17113 net.cpp:217] bn3_2_D needs backward computation.
I0624 12:23:14.135007 17113 net.cpp:217] conv3_2_D needs backward computation.
I0624 12:23:14.135010 17113 net.cpp:217] upsample3 needs backward computation.
I0624 12:23:14.135011 17113 net.cpp:217] relu4_1_D needs backward computation.
I0624 12:23:14.135013 17113 net.cpp:217] scale4_1_D needs backward computation.
I0624 12:23:14.135016 17113 net.cpp:217] bn4_1_D needs backward computation.
I0624 12:23:14.135018 17113 net.cpp:217] conv4_1_D needs backward computation.
I0624 12:23:14.135021 17113 net.cpp:217] relu4_2_D needs backward computation.
I0624 12:23:14.135023 17113 net.cpp:217] scale4_2_D needs backward computation.
I0624 12:23:14.135025 17113 net.cpp:217] bn4_2_D needs backward computation.
I0624 12:23:14.135027 17113 net.cpp:217] conv4_2_D needs backward computation.
I0624 12:23:14.135030 17113 net.cpp:217] upsample4 needs backward computation.
I0624 12:23:14.135032 17113 net.cpp:217] relu5_1_D needs backward computation.
I0624 12:23:14.135035 17113 net.cpp:217] scale5_1_D needs backward computation.
I0624 12:23:14.135037 17113 net.cpp:217] bn5_1_D needs backward computation.
I0624 12:23:14.135040 17113 net.cpp:217] conv5_1_D needs backward computation.
I0624 12:23:14.135042 17113 net.cpp:217] relu5_2_D needs backward computation.
I0624 12:23:14.135045 17113 net.cpp:217] scale5_2_D needs backward computation.
I0624 12:23:14.135047 17113 net.cpp:217] bn5_2_D needs backward computation.
I0624 12:23:14.135049 17113 net.cpp:217] conv5_2_D needs backward computation.
I0624 12:23:14.135051 17113 net.cpp:217] upsample5 needs backward computation.
I0624 12:23:14.135056 17113 net.cpp:217] pool5 needs backward computation.
I0624 12:23:14.135058 17113 net.cpp:217] relu5_2 needs backward computation.
I0624 12:23:14.135061 17113 net.cpp:217] scale5_2 needs backward computation.
I0624 12:23:14.135062 17113 net.cpp:217] bn5_2 needs backward computation.
I0624 12:23:14.135064 17113 net.cpp:217] conv5_2 needs backward computation.
I0624 12:23:14.135067 17113 net.cpp:217] relu5_1 needs backward computation.
I0624 12:23:14.135069 17113 net.cpp:217] scale5_1 needs backward computation.
I0624 12:23:14.135076 17113 net.cpp:217] bn5_1 needs backward computation.
I0624 12:23:14.135078 17113 net.cpp:217] conv5_1 needs backward computation.
I0624 12:23:14.135082 17113 net.cpp:217] pool4 needs backward computation.
I0624 12:23:14.135084 17113 net.cpp:217] relu4_2 needs backward computation.
I0624 12:23:14.135087 17113 net.cpp:217] scale4_2 needs backward computation.
I0624 12:23:14.135088 17113 net.cpp:217] bn4_2 needs backward computation.
I0624 12:23:14.135092 17113 net.cpp:217] conv4_2 needs backward computation.
I0624 12:23:14.135093 17113 net.cpp:217] relu4_1 needs backward computation.
I0624 12:23:14.135095 17113 net.cpp:217] scale4_1 needs backward computation.
I0624 12:23:14.135097 17113 net.cpp:217] bn4_1 needs backward computation.
I0624 12:23:14.135100 17113 net.cpp:217] conv4_1 needs backward computation.
I0624 12:23:14.135103 17113 net.cpp:217] pool3 needs backward computation.
I0624 12:23:14.135105 17113 net.cpp:217] relu3_2 needs backward computation.
I0624 12:23:14.135107 17113 net.cpp:217] scale3_2 needs backward computation.
I0624 12:23:14.135110 17113 net.cpp:217] bn3_2 needs backward computation.
I0624 12:23:14.135113 17113 net.cpp:217] conv3_2 needs backward computation.
I0624 12:23:14.135114 17113 net.cpp:217] relu3_1 needs backward computation.
I0624 12:23:14.135118 17113 net.cpp:217] scale3_1 needs backward computation.
I0624 12:23:14.135119 17113 net.cpp:217] bn3_1 needs backward computation.
I0624 12:23:14.135121 17113 net.cpp:217] conv3_1 needs backward computation.
I0624 12:23:14.135123 17113 net.cpp:217] pool2 needs backward computation.
I0624 12:23:14.135126 17113 net.cpp:217] relu2_2 needs backward computation.
I0624 12:23:14.135128 17113 net.cpp:217] scale2_2 needs backward computation.
I0624 12:23:14.135130 17113 net.cpp:217] bn2_2 needs backward computation.
I0624 12:23:14.135133 17113 net.cpp:217] conv2_2 needs backward computation.
I0624 12:23:14.135135 17113 net.cpp:217] relu2_1 needs backward computation.
I0624 12:23:14.135138 17113 net.cpp:217] scale2_1 needs backward computation.
I0624 12:23:14.135139 17113 net.cpp:217] bn2_1 needs backward computation.
I0624 12:23:14.135141 17113 net.cpp:217] conv2_1 needs backward computation.
I0624 12:23:14.135143 17113 net.cpp:217] pool1 needs backward computation.
I0624 12:23:14.135146 17113 net.cpp:217] relu1_2 needs backward computation.
I0624 12:23:14.135155 17113 net.cpp:217] scale1_2 needs backward computation.
I0624 12:23:14.135159 17113 net.cpp:217] bn1_2 needs backward computation.
I0624 12:23:14.135160 17113 net.cpp:217] conv1_2 needs backward computation.
I0624 12:23:14.135162 17113 net.cpp:217] relu1_1 needs backward computation.
I0624 12:23:14.135164 17113 net.cpp:217] scale1_1 needs backward computation.
I0624 12:23:14.135167 17113 net.cpp:217] bn1_1 needs backward computation.
I0624 12:23:14.135169 17113 net.cpp:217] conv1_1 needs backward computation.
I0624 12:23:14.135172 17113 net.cpp:219] label_data_1_split does not need backward computation.
I0624 12:23:14.135175 17113 net.cpp:219] data does not need backward computation.
I0624 12:23:14.135177 17113 net.cpp:261] This network produces output accuracy
I0624 12:23:14.135179 17113 net.cpp:261] This network produces output loss
I0624 12:23:14.135211 17113 net.cpp:274] Network initialization done.
I0624 12:23:14.135464 17113 solver.cpp:60] Solver scaffolding done.
I0624 12:23:14.140035 17113 caffe.cpp:219] Starting Optimization
I0624 12:23:14.140043 17113 solver.cpp:279] Solving segnet
I0624 12:23:14.140045 17113 solver.cpp:280] Learning Rate Policy: step
I0624 12:23:14.143883 17113 solver.cpp:337] Iteration 0, Testing net (#0)
I0624 12:23:14.522853 17113 solver.cpp:404]     Test net output #0: accuracy = 0.676444
I0624 12:23:14.522877 17113 solver.cpp:404]     Test net output #1: loss = 0.593261 (* 1 = 0.593261 loss)
I0624 12:23:15.268443 17113 solver.cpp:228] Iteration 0, loss = 0.596303
I0624 12:23:15.268468 17113 solver.cpp:244]     Train net output #0: accuracy = 0.673609
I0624 12:23:15.268476 17113 solver.cpp:244]     Train net output #1: loss = 0.596303 (* 1 = 0.596303 loss)
I0624 12:23:15.268503 17113 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0624 12:23:29.579690 17113 solver.cpp:228] Iteration 20, loss = 0.161487
I0624 12:23:29.579716 17113 solver.cpp:244]     Train net output #0: accuracy = 0.980257
I0624 12:23:29.579723 17113 solver.cpp:244]     Train net output #1: loss = 0.161487 (* 1 = 0.161487 loss)
I0624 12:23:29.579727 17113 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0624 12:23:44.325611 17113 solver.cpp:228] Iteration 40, loss = 0.106828
I0624 12:23:44.325772 17113 solver.cpp:244]     Train net output #0: accuracy = 0.984036
I0624 12:23:44.325783 17113 solver.cpp:244]     Train net output #1: loss = 0.106828 (* 1 = 0.106828 loss)
I0624 12:23:44.325788 17113 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0624 12:23:59.070890 17113 solver.cpp:228] Iteration 60, loss = 0.0734623
I0624 12:23:59.070914 17113 solver.cpp:244]     Train net output #0: accuracy = 0.986991
I0624 12:23:59.070932 17113 solver.cpp:244]     Train net output #1: loss = 0.0734623 (* 1 = 0.0734623 loss)
I0624 12:23:59.070936 17113 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0624 12:24:13.832383 17113 solver.cpp:228] Iteration 80, loss = 0.0799128
I0624 12:24:13.832409 17113 solver.cpp:244]     Train net output #0: accuracy = 0.985776
I0624 12:24:13.832417 17113 solver.cpp:244]     Train net output #1: loss = 0.0799128 (* 1 = 0.0799128 loss)
I0624 12:24:13.832420 17113 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0624 12:24:28.221480 17113 solver.cpp:337] Iteration 100, Testing net (#0)
I0624 12:24:28.554592 17113 solver.cpp:404]     Test net output #0: accuracy = 0.987001
I0624 12:24:28.554627 17113 solver.cpp:404]     Test net output #1: loss = 0.0728503 (* 1 = 0.0728503 loss)
I0624 12:24:28.974186 17113 solver.cpp:228] Iteration 100, loss = 0.075103
I0624 12:24:28.974221 17113 solver.cpp:244]     Train net output #0: accuracy = 0.986527
I0624 12:24:28.974228 17113 solver.cpp:244]     Train net output #1: loss = 0.075103 (* 1 = 0.075103 loss)
I0624 12:24:28.974232 17113 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0624 12:24:43.831939 17113 solver.cpp:228] Iteration 120, loss = 0.111098
I0624 12:24:43.831964 17113 solver.cpp:244]     Train net output #0: accuracy = 0.977741
I0624 12:24:43.831971 17113 solver.cpp:244]     Train net output #1: loss = 0.111098 (* 1 = 0.111098 loss)
I0624 12:24:43.831976 17113 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0624 12:24:58.734514 17113 solver.cpp:228] Iteration 140, loss = 0.097769
I0624 12:24:58.734611 17113 solver.cpp:244]     Train net output #0: accuracy = 0.9806
I0624 12:24:58.734621 17113 solver.cpp:244]     Train net output #1: loss = 0.097769 (* 1 = 0.097769 loss)
I0624 12:24:58.734625 17113 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0624 12:25:13.532840 17113 solver.cpp:228] Iteration 160, loss = 0.0675391
I0624 12:25:13.532863 17113 solver.cpp:244]     Train net output #0: accuracy = 0.987766
I0624 12:25:13.532871 17113 solver.cpp:244]     Train net output #1: loss = 0.0675391 (* 1 = 0.0675391 loss)
I0624 12:25:13.532874 17113 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0624 12:25:28.180757 17113 solver.cpp:228] Iteration 180, loss = 0.0656246
I0624 12:25:28.180783 17113 solver.cpp:244]     Train net output #0: accuracy = 0.987892
I0624 12:25:28.180790 17113 solver.cpp:244]     Train net output #1: loss = 0.0656246 (* 1 = 0.0656246 loss)
I0624 12:25:28.180795 17113 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0624 12:25:42.412856 17113 solver.cpp:337] Iteration 200, Testing net (#0)
I0624 12:25:42.747637 17113 solver.cpp:404]     Test net output #0: accuracy = 0.988294
I0624 12:25:42.747668 17113 solver.cpp:404]     Test net output #1: loss = 0.0631272 (* 1 = 0.0631272 loss)
I0624 12:25:43.157430 17113 solver.cpp:228] Iteration 200, loss = 0.100355
I0624 12:25:43.157454 17113 solver.cpp:244]     Train net output #0: accuracy = 0.978707
I0624 12:25:43.157460 17113 solver.cpp:244]     Train net output #1: loss = 0.100355 (* 1 = 0.100355 loss)
I0624 12:25:43.157464 17113 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0624 12:25:57.806516 17113 solver.cpp:228] Iteration 220, loss = 0.0666475
I0624 12:25:57.806540 17113 solver.cpp:244]     Train net output #0: accuracy = 0.987062
I0624 12:25:57.806547 17113 solver.cpp:244]     Train net output #1: loss = 0.0666475 (* 1 = 0.0666475 loss)
I0624 12:25:57.806552 17113 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0624 12:26:12.452949 17113 solver.cpp:228] Iteration 240, loss = 0.0775432
I0624 12:26:12.453060 17113 solver.cpp:244]     Train net output #0: accuracy = 0.983836
I0624 12:26:12.453070 17113 solver.cpp:244]     Train net output #1: loss = 0.0775432 (* 1 = 0.0775432 loss)
I0624 12:26:12.453076 17113 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0624 12:26:27.103145 17113 solver.cpp:228] Iteration 260, loss = 0.0875518
I0624 12:26:27.103174 17113 solver.cpp:244]     Train net output #0: accuracy = 0.980193
I0624 12:26:27.103183 17113 solver.cpp:244]     Train net output #1: loss = 0.0875518 (* 1 = 0.0875518 loss)
I0624 12:26:27.103188 17113 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0624 12:26:41.846690 17113 solver.cpp:228] Iteration 280, loss = 0.0791577
I0624 12:26:41.846714 17113 solver.cpp:244]     Train net output #0: accuracy = 0.981805
I0624 12:26:41.846721 17113 solver.cpp:244]     Train net output #1: loss = 0.0791577 (* 1 = 0.0791577 loss)
I0624 12:26:41.846726 17113 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0624 12:26:56.084362 17113 solver.cpp:337] Iteration 300, Testing net (#0)
I0624 12:26:56.419728 17113 solver.cpp:404]     Test net output #0: accuracy = 0.975333
I0624 12:26:56.419762 17113 solver.cpp:404]     Test net output #1: loss = 0.102104 (* 1 = 0.102104 loss)
I0624 12:26:56.829998 17113 solver.cpp:228] Iteration 300, loss = 0.0697036
I0624 12:26:56.830020 17113 solver.cpp:244]     Train net output #0: accuracy = 0.983822
I0624 12:26:56.830027 17113 solver.cpp:244]     Train net output #1: loss = 0.0697036 (* 1 = 0.0697036 loss)
I0624 12:26:56.830032 17113 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0624 12:27:11.480200 17113 solver.cpp:228] Iteration 320, loss = 0.0700725
I0624 12:27:11.480223 17113 solver.cpp:244]     Train net output #0: accuracy = 0.983765
I0624 12:27:11.480229 17113 solver.cpp:244]     Train net output #1: loss = 0.0700725 (* 1 = 0.0700725 loss)
I0624 12:27:11.480234 17113 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0624 12:27:26.126611 17113 solver.cpp:228] Iteration 340, loss = 0.0717996
I0624 12:27:26.126703 17113 solver.cpp:244]     Train net output #0: accuracy = 0.981064
I0624 12:27:26.126711 17113 solver.cpp:244]     Train net output #1: loss = 0.0717996 (* 1 = 0.0717996 loss)
I0624 12:27:26.126716 17113 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0624 12:27:40.772902 17113 solver.cpp:228] Iteration 360, loss = 0.0514538
I0624 12:27:40.772936 17113 solver.cpp:244]     Train net output #0: accuracy = 0.987525
I0624 12:27:40.772943 17113 solver.cpp:244]     Train net output #1: loss = 0.0514538 (* 1 = 0.0514538 loss)
I0624 12:27:40.772948 17113 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0624 12:27:55.423295 17113 solver.cpp:228] Iteration 380, loss = 0.052733
I0624 12:27:55.423321 17113 solver.cpp:244]     Train net output #0: accuracy = 0.986019
I0624 12:27:55.423328 17113 solver.cpp:244]     Train net output #1: loss = 0.052733 (* 1 = 0.052733 loss)
I0624 12:27:55.423333 17113 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0624 12:28:09.651430 17113 solver.cpp:337] Iteration 400, Testing net (#0)
I0624 12:28:09.986579 17113 solver.cpp:404]     Test net output #0: accuracy = 0.980972
I0624 12:28:09.986613 17113 solver.cpp:404]     Test net output #1: loss = 0.0593513 (* 1 = 0.0593513 loss)
I0624 12:28:10.396561 17113 solver.cpp:228] Iteration 400, loss = 0.0464418
I0624 12:28:10.396584 17113 solver.cpp:244]     Train net output #0: accuracy = 0.987833
I0624 12:28:10.396591 17113 solver.cpp:244]     Train net output #1: loss = 0.0464418 (* 1 = 0.0464418 loss)
I0624 12:28:10.396595 17113 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0624 12:28:25.033293 17113 solver.cpp:228] Iteration 420, loss = 0.0545116
I0624 12:28:25.033316 17113 solver.cpp:244]     Train net output #0: accuracy = 0.983595
I0624 12:28:25.033324 17113 solver.cpp:244]     Train net output #1: loss = 0.0545116 (* 1 = 0.0545116 loss)
I0624 12:28:25.033329 17113 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0624 12:28:39.743666 17113 solver.cpp:228] Iteration 440, loss = 0.0628356
I0624 12:28:39.743788 17113 solver.cpp:244]     Train net output #0: accuracy = 0.980331
I0624 12:28:39.743798 17113 solver.cpp:244]     Train net output #1: loss = 0.0628356 (* 1 = 0.0628356 loss)
I0624 12:28:39.743803 17113 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0624 12:28:54.380197 17113 solver.cpp:228] Iteration 460, loss = 0.0510196
I0624 12:28:54.380220 17113 solver.cpp:244]     Train net output #0: accuracy = 0.981987
I0624 12:28:54.380226 17113 solver.cpp:244]     Train net output #1: loss = 0.0510196 (* 1 = 0.0510196 loss)
I0624 12:28:54.380231 17113 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0624 12:29:09.017973 17113 solver.cpp:228] Iteration 480, loss = 0.0429233
I0624 12:29:09.017997 17113 solver.cpp:244]     Train net output #0: accuracy = 0.986725
I0624 12:29:09.018003 17113 solver.cpp:244]     Train net output #1: loss = 0.0429233 (* 1 = 0.0429233 loss)
I0624 12:29:09.018007 17113 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0624 12:29:23.252959 17113 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_500.caffemodel
I0624 12:29:23.316947 17113 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_500.solverstate
I0624 12:29:23.344432 17113 solver.cpp:337] Iteration 500, Testing net (#0)
I0624 12:29:23.683301 17113 solver.cpp:404]     Test net output #0: accuracy = 0.982408
I0624 12:29:23.683326 17113 solver.cpp:404]     Test net output #1: loss = 0.049895 (* 1 = 0.049895 loss)
I0624 12:29:24.096122 17113 solver.cpp:228] Iteration 500, loss = 0.0532308
I0624 12:29:24.096148 17113 solver.cpp:244]     Train net output #0: accuracy = 0.982099
I0624 12:29:24.096155 17113 solver.cpp:244]     Train net output #1: loss = 0.0532308 (* 1 = 0.0532308 loss)
I0624 12:29:24.096160 17113 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0624 12:29:38.751034 17113 solver.cpp:228] Iteration 520, loss = 0.0371953
I0624 12:29:38.751057 17113 solver.cpp:244]     Train net output #0: accuracy = 0.986382
I0624 12:29:38.751065 17113 solver.cpp:244]     Train net output #1: loss = 0.0371953 (* 1 = 0.0371953 loss)
I0624 12:29:38.751070 17113 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0624 12:29:53.399472 17113 solver.cpp:228] Iteration 540, loss = 0.0503986
I0624 12:29:53.399570 17113 solver.cpp:244]     Train net output #0: accuracy = 0.981287
I0624 12:29:53.399580 17113 solver.cpp:244]     Train net output #1: loss = 0.0503986 (* 1 = 0.0503986 loss)
I0624 12:29:53.399585 17113 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0624 12:30:08.025599 17113 solver.cpp:228] Iteration 560, loss = 0.0427696
I0624 12:30:08.025625 17113 solver.cpp:244]     Train net output #0: accuracy = 0.983658
I0624 12:30:08.025643 17113 solver.cpp:244]     Train net output #1: loss = 0.0427696 (* 1 = 0.0427696 loss)
I0624 12:30:08.025648 17113 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0624 12:30:22.669544 17113 solver.cpp:228] Iteration 580, loss = 0.0475434
I0624 12:30:22.669567 17113 solver.cpp:244]     Train net output #0: accuracy = 0.984335
I0624 12:30:22.669574 17113 solver.cpp:244]     Train net output #1: loss = 0.0475434 (* 1 = 0.0475434 loss)
I0624 12:30:22.669579 17113 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0624 12:30:36.959959 17113 solver.cpp:337] Iteration 600, Testing net (#0)
I0624 12:30:37.295109 17113 solver.cpp:404]     Test net output #0: accuracy = 0.976428
I0624 12:30:37.295135 17113 solver.cpp:404]     Test net output #1: loss = 0.0456361 (* 1 = 0.0456361 loss)
I0624 12:30:37.706686 17113 solver.cpp:228] Iteration 600, loss = 0.040888
I0624 12:30:37.706710 17113 solver.cpp:244]     Train net output #0: accuracy = 0.984212
I0624 12:30:37.706718 17113 solver.cpp:244]     Train net output #1: loss = 0.040888 (* 1 = 0.040888 loss)
I0624 12:30:37.706723 17113 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0624 12:30:52.354405 17113 solver.cpp:228] Iteration 620, loss = 0.0409035
I0624 12:30:52.354430 17113 solver.cpp:244]     Train net output #0: accuracy = 0.980955
I0624 12:30:52.354437 17113 solver.cpp:244]     Train net output #1: loss = 0.0409035 (* 1 = 0.0409035 loss)
I0624 12:30:52.354442 17113 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0624 12:31:06.990363 17113 solver.cpp:228] Iteration 640, loss = 0.0370357
I0624 12:31:06.990481 17113 solver.cpp:244]     Train net output #0: accuracy = 0.98734
I0624 12:31:06.990491 17113 solver.cpp:244]     Train net output #1: loss = 0.0370357 (* 1 = 0.0370357 loss)
I0624 12:31:06.990496 17113 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0624 12:31:21.617806 17113 solver.cpp:228] Iteration 660, loss = 0.042676
I0624 12:31:21.617830 17113 solver.cpp:244]     Train net output #0: accuracy = 0.976833
I0624 12:31:21.617836 17113 solver.cpp:244]     Train net output #1: loss = 0.042676 (* 1 = 0.042676 loss)
I0624 12:31:21.617841 17113 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0624 12:31:36.257908 17113 solver.cpp:228] Iteration 680, loss = 0.052025
I0624 12:31:36.257930 17113 solver.cpp:244]     Train net output #0: accuracy = 0.97642
I0624 12:31:36.257937 17113 solver.cpp:244]     Train net output #1: loss = 0.052025 (* 1 = 0.052025 loss)
I0624 12:31:36.257942 17113 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0624 12:31:50.519706 17113 solver.cpp:337] Iteration 700, Testing net (#0)
I0624 12:31:50.854904 17113 solver.cpp:404]     Test net output #0: accuracy = 0.988732
I0624 12:31:50.854928 17113 solver.cpp:404]     Test net output #1: loss = 0.0348496 (* 1 = 0.0348496 loss)
I0624 12:31:51.266279 17113 solver.cpp:228] Iteration 700, loss = 0.0594841
I0624 12:31:51.266304 17113 solver.cpp:244]     Train net output #0: accuracy = 0.97571
I0624 12:31:51.266312 17113 solver.cpp:244]     Train net output #1: loss = 0.0594841 (* 1 = 0.0594841 loss)
I0624 12:31:51.266317 17113 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0624 12:32:05.908422 17113 solver.cpp:228] Iteration 720, loss = 0.0361897
I0624 12:32:05.908447 17113 solver.cpp:244]     Train net output #0: accuracy = 0.985066
I0624 12:32:05.908453 17113 solver.cpp:244]     Train net output #1: loss = 0.0361897 (* 1 = 0.0361897 loss)
I0624 12:32:05.908457 17113 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0624 12:32:20.549118 17113 solver.cpp:228] Iteration 740, loss = 0.0289779
I0624 12:32:20.549239 17113 solver.cpp:244]     Train net output #0: accuracy = 0.986417
I0624 12:32:20.549248 17113 solver.cpp:244]     Train net output #1: loss = 0.0289779 (* 1 = 0.0289779 loss)
I0624 12:32:20.549254 17113 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0624 12:32:35.264760 17113 solver.cpp:228] Iteration 760, loss = 0.030609
I0624 12:32:35.264793 17113 solver.cpp:244]     Train net output #0: accuracy = 0.990495
I0624 12:32:35.264801 17113 solver.cpp:244]     Train net output #1: loss = 0.030609 (* 1 = 0.030609 loss)
I0624 12:32:35.264806 17113 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0624 12:32:49.898216 17113 solver.cpp:228] Iteration 780, loss = 0.026253
I0624 12:32:49.898237 17113 solver.cpp:244]     Train net output #0: accuracy = 0.990734
I0624 12:32:49.898244 17113 solver.cpp:244]     Train net output #1: loss = 0.026253 (* 1 = 0.026253 loss)
I0624 12:32:49.898248 17113 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0624 12:33:04.121270 17113 solver.cpp:337] Iteration 800, Testing net (#0)
I0624 12:33:04.496217 17113 solver.cpp:404]     Test net output #0: accuracy = 0.987905
I0624 12:33:04.496243 17113 solver.cpp:404]     Test net output #1: loss = 0.0321276 (* 1 = 0.0321276 loss)
I0624 12:33:04.908689 17113 solver.cpp:228] Iteration 800, loss = 0.0334975
I0624 12:33:04.908712 17113 solver.cpp:244]     Train net output #0: accuracy = 0.985882
I0624 12:33:04.908720 17113 solver.cpp:244]     Train net output #1: loss = 0.0334975 (* 1 = 0.0334975 loss)
I0624 12:33:04.908725 17113 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0624 12:33:19.548547 17113 solver.cpp:228] Iteration 820, loss = 0.0263569
I0624 12:33:19.548569 17113 solver.cpp:244]     Train net output #0: accuracy = 0.988354
I0624 12:33:19.548576 17113 solver.cpp:244]     Train net output #1: loss = 0.0263569 (* 1 = 0.0263569 loss)
I0624 12:33:19.548581 17113 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0624 12:33:34.188901 17113 solver.cpp:228] Iteration 840, loss = 0.0346174
I0624 12:33:34.189034 17113 solver.cpp:244]     Train net output #0: accuracy = 0.982862
I0624 12:33:34.189044 17113 solver.cpp:244]     Train net output #1: loss = 0.0346174 (* 1 = 0.0346174 loss)
I0624 12:33:34.189049 17113 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0624 12:33:48.827303 17113 solver.cpp:228] Iteration 860, loss = 0.0396979
I0624 12:33:48.827327 17113 solver.cpp:244]     Train net output #0: accuracy = 0.982151
I0624 12:33:48.827334 17113 solver.cpp:244]     Train net output #1: loss = 0.0396979 (* 1 = 0.0396979 loss)
I0624 12:33:48.827338 17113 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0624 12:34:03.464572 17113 solver.cpp:228] Iteration 880, loss = 0.0249701
I0624 12:34:03.464596 17113 solver.cpp:244]     Train net output #0: accuracy = 0.988614
I0624 12:34:03.464603 17113 solver.cpp:244]     Train net output #1: loss = 0.0249701 (* 1 = 0.0249701 loss)
I0624 12:34:03.464608 17113 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0624 12:34:17.693038 17113 solver.cpp:337] Iteration 900, Testing net (#0)
I0624 12:34:18.028179 17113 solver.cpp:404]     Test net output #0: accuracy = 0.982
I0624 12:34:18.028214 17113 solver.cpp:404]     Test net output #1: loss = 0.0366712 (* 1 = 0.0366712 loss)
I0624 12:34:18.438310 17113 solver.cpp:228] Iteration 900, loss = 0.0429367
I0624 12:34:18.438334 17113 solver.cpp:244]     Train net output #0: accuracy = 0.980655
I0624 12:34:18.438343 17113 solver.cpp:244]     Train net output #1: loss = 0.0429367 (* 1 = 0.0429367 loss)
I0624 12:34:18.438347 17113 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0624 12:34:33.141831 17113 solver.cpp:228] Iteration 920, loss = 0.0301374
I0624 12:34:33.141856 17113 solver.cpp:244]     Train net output #0: accuracy = 0.983899
I0624 12:34:33.141863 17113 solver.cpp:244]     Train net output #1: loss = 0.0301374 (* 1 = 0.0301374 loss)
I0624 12:34:33.141868 17113 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0624 12:34:47.786298 17113 solver.cpp:228] Iteration 940, loss = 0.0276644
I0624 12:34:47.786396 17113 solver.cpp:244]     Train net output #0: accuracy = 0.984723
I0624 12:34:47.786406 17113 solver.cpp:244]     Train net output #1: loss = 0.0276644 (* 1 = 0.0276644 loss)
I0624 12:34:47.786412 17113 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0624 12:35:02.439558 17113 solver.cpp:228] Iteration 960, loss = 0.0404592
I0624 12:35:02.439591 17113 solver.cpp:244]     Train net output #0: accuracy = 0.981793
I0624 12:35:02.439599 17113 solver.cpp:244]     Train net output #1: loss = 0.0404592 (* 1 = 0.0404592 loss)
I0624 12:35:02.439604 17113 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0624 12:35:17.073254 17113 solver.cpp:228] Iteration 980, loss = 0.0199172
I0624 12:35:17.073278 17113 solver.cpp:244]     Train net output #0: accuracy = 0.994541
I0624 12:35:17.073284 17113 solver.cpp:244]     Train net output #1: loss = 0.0199172 (* 1 = 0.0199172 loss)
I0624 12:35:17.073289 17113 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0624 12:35:31.300715 17113 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_1000.caffemodel
I0624 12:35:31.346099 17113 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_1000.solverstate
I0624 12:35:31.692522 17113 solver.cpp:317] Iteration 1000, loss = 0.0324165
I0624 12:35:31.692545 17113 solver.cpp:337] Iteration 1000, Testing net (#0)
I0624 12:35:32.029485 17113 solver.cpp:404]     Test net output #0: accuracy = 0.993177
I0624 12:35:32.029518 17113 solver.cpp:404]     Test net output #1: loss = 0.0251152 (* 1 = 0.0251152 loss)
I0624 12:35:32.029523 17113 solver.cpp:322] Optimization Done.
I0624 12:35:32.029525 17113 caffe.cpp:222] Optimization Done.
runsegnet.sh: 7: runsegnet.sh: --snapshot=data/models/segnet_iter_1000.solverstate: not found
runsegnet.sh: 7: runsegnet.sh: --weights=data/models/segnet_iter_1000.caffemodel: not found
runsegnet.sh: 7: runsegnet.sh: --snapshot=data/models/segnet_iter_1000.solverstate: not found
runsegnet.sh: 7: runsegnet.sh: --snapshot=data/models/segnet_iter_1000.solverstate: not found
runsegnet.sh: 7: runsegnet.sh: -snapshot=data/models/segnet_iter_1000.solverstate: not found
I0624 12:47:26.302212 17456 caffe.cpp:185] Using GPUs 1
I0624 12:47:26.320758 17456 caffe.cpp:190] GPU 1: GeForce GTX TITAN X
I0624 12:47:26.742180 17456 solver.cpp:48] Initializing solver from parameters: 
test_iter: 16
test_interval: 100
base_lr: 0.01
display: 20
max_iter: 2000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 500
snapshot_prefix: "data/models/segnet"
solver_mode: GPU
device_id: 1
net: "models/segnet/train_val.prototxt"
test_initialization: true
iter_size: 1
I0624 12:47:26.742326 17456 solver.cpp:91] Creating training net from net file: models/segnet/train_val.prototxt
I0624 12:47:26.744251 17456 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0624 12:47:26.744786 17456 net.cpp:49] Initializing net from parameters: 
name: "segnet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "DenseImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 224
    mean_value: 100
  }
  dense_image_data_param {
    source: "data/train.txt"
    batch_size: 32
    shuffle: true
    new_height: 224
    new_width: 310
    is_color: false
    root_folder: "data/raw/train/"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 14
    upsample_w: 14
  }
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2_D"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2_D"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1_D"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1_D"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 28
    upsample_w: 28
  }
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2_D"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2_D"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1_D"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1_D"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
    upsample_h: 56
    upsample_w: 56
  }
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn3_2_D"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2_D"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1_D"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1_D"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
    upsample_h: 112
    upsample_w: 112
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2_D"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2_D"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1_D"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1_D"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
    upsample_h: 224
    upsample_w: 224
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2_D"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2_D"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2
    bias_term: true
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "accuracy"
}
I0624 12:47:26.745146 17456 layer_factory.hpp:77] Creating layer data
I0624 12:47:26.745184 17456 net.cpp:91] Creating Layer data
I0624 12:47:26.745193 17456 net.cpp:399] data -> data
I0624 12:47:26.745218 17456 net.cpp:399] data -> label
I0624 12:47:26.745627 17456 dense_image_data_layer.cpp:38] Opening file data/train.txt
I0624 12:47:26.748638 17456 dense_image_data_layer.cpp:48] Shuffling data
I0624 12:47:26.749320 17456 dense_image_data_layer.cpp:53] A total of 4930 examples.
I0624 12:47:27.073531 17456 dense_image_data_layer.cpp:92] output data size: 1,1,224,224
I0624 12:47:27.075994 17456 net.cpp:141] Setting up data
I0624 12:47:27.076021 17456 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 12:47:27.076028 17456 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 12:47:27.076032 17456 net.cpp:156] Memory required for data: 401408
I0624 12:47:27.076041 17456 layer_factory.hpp:77] Creating layer label_data_1_split
I0624 12:47:27.076081 17456 net.cpp:91] Creating Layer label_data_1_split
I0624 12:47:27.076093 17456 net.cpp:425] label_data_1_split <- label
I0624 12:47:27.076107 17456 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0624 12:47:27.076119 17456 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0624 12:47:27.076187 17456 net.cpp:141] Setting up label_data_1_split
I0624 12:47:27.076200 17456 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 12:47:27.076205 17456 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 12:47:27.076208 17456 net.cpp:156] Memory required for data: 802816
I0624 12:47:27.076212 17456 layer_factory.hpp:77] Creating layer conv1_1
I0624 12:47:27.076232 17456 net.cpp:91] Creating Layer conv1_1
I0624 12:47:27.076237 17456 net.cpp:425] conv1_1 <- data
I0624 12:47:27.076244 17456 net.cpp:399] conv1_1 -> conv1_1
I0624 12:47:27.297782 17456 net.cpp:141] Setting up conv1_1
I0624 12:47:27.297807 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.297811 17456 net.cpp:156] Memory required for data: 7225344
I0624 12:47:27.297821 17456 layer_factory.hpp:77] Creating layer bn1_1
I0624 12:47:27.297838 17456 net.cpp:91] Creating Layer bn1_1
I0624 12:47:27.297842 17456 net.cpp:425] bn1_1 <- conv1_1
I0624 12:47:27.297847 17456 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0624 12:47:27.298028 17456 net.cpp:141] Setting up bn1_1
I0624 12:47:27.298037 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.298040 17456 net.cpp:156] Memory required for data: 13647872
I0624 12:47:27.298050 17456 layer_factory.hpp:77] Creating layer scale1_1
I0624 12:47:27.298059 17456 net.cpp:91] Creating Layer scale1_1
I0624 12:47:27.298065 17456 net.cpp:425] scale1_1 <- conv1_1
I0624 12:47:27.298069 17456 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0624 12:47:27.298107 17456 layer_factory.hpp:77] Creating layer scale1_1
I0624 12:47:27.298270 17456 net.cpp:141] Setting up scale1_1
I0624 12:47:27.298285 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.298286 17456 net.cpp:156] Memory required for data: 20070400
I0624 12:47:27.298292 17456 layer_factory.hpp:77] Creating layer relu1_1
I0624 12:47:27.298298 17456 net.cpp:91] Creating Layer relu1_1
I0624 12:47:27.298301 17456 net.cpp:425] relu1_1 <- conv1_1
I0624 12:47:27.298305 17456 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0624 12:47:27.298573 17456 net.cpp:141] Setting up relu1_1
I0624 12:47:27.298583 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.298585 17456 net.cpp:156] Memory required for data: 26492928
I0624 12:47:27.298588 17456 layer_factory.hpp:77] Creating layer conv1_2
I0624 12:47:27.298599 17456 net.cpp:91] Creating Layer conv1_2
I0624 12:47:27.298601 17456 net.cpp:425] conv1_2 <- conv1_1
I0624 12:47:27.298605 17456 net.cpp:399] conv1_2 -> conv1_2
I0624 12:47:27.300109 17456 net.cpp:141] Setting up conv1_2
I0624 12:47:27.300122 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.300125 17456 net.cpp:156] Memory required for data: 32915456
I0624 12:47:27.300129 17456 layer_factory.hpp:77] Creating layer bn1_2
I0624 12:47:27.300135 17456 net.cpp:91] Creating Layer bn1_2
I0624 12:47:27.300138 17456 net.cpp:425] bn1_2 <- conv1_2
I0624 12:47:27.300143 17456 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0624 12:47:27.300313 17456 net.cpp:141] Setting up bn1_2
I0624 12:47:27.300321 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.300323 17456 net.cpp:156] Memory required for data: 39337984
I0624 12:47:27.300331 17456 layer_factory.hpp:77] Creating layer scale1_2
I0624 12:47:27.300356 17456 net.cpp:91] Creating Layer scale1_2
I0624 12:47:27.300359 17456 net.cpp:425] scale1_2 <- conv1_2
I0624 12:47:27.300364 17456 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0624 12:47:27.300400 17456 layer_factory.hpp:77] Creating layer scale1_2
I0624 12:47:27.300559 17456 net.cpp:141] Setting up scale1_2
I0624 12:47:27.300565 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.300568 17456 net.cpp:156] Memory required for data: 45760512
I0624 12:47:27.300573 17456 layer_factory.hpp:77] Creating layer relu1_2
I0624 12:47:27.300577 17456 net.cpp:91] Creating Layer relu1_2
I0624 12:47:27.300580 17456 net.cpp:425] relu1_2 <- conv1_2
I0624 12:47:27.300583 17456 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0624 12:47:27.300710 17456 net.cpp:141] Setting up relu1_2
I0624 12:47:27.300719 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.300721 17456 net.cpp:156] Memory required for data: 52183040
I0624 12:47:27.300724 17456 layer_factory.hpp:77] Creating layer pool1
I0624 12:47:27.300727 17456 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 12:47:27.300732 17456 net.cpp:91] Creating Layer pool1
I0624 12:47:27.300734 17456 net.cpp:425] pool1 <- conv1_2
I0624 12:47:27.300739 17456 net.cpp:399] pool1 -> pool1
I0624 12:47:27.300745 17456 net.cpp:399] pool1 -> pool1_mask
I0624 12:47:27.300787 17456 net.cpp:141] Setting up pool1
I0624 12:47:27.300793 17456 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:47:27.300796 17456 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:47:27.300798 17456 net.cpp:156] Memory required for data: 55394304
I0624 12:47:27.300801 17456 layer_factory.hpp:77] Creating layer conv2_1
I0624 12:47:27.300807 17456 net.cpp:91] Creating Layer conv2_1
I0624 12:47:27.300811 17456 net.cpp:425] conv2_1 <- pool1
I0624 12:47:27.300814 17456 net.cpp:399] conv2_1 -> conv2_1
I0624 12:47:27.302378 17456 net.cpp:141] Setting up conv2_1
I0624 12:47:27.302392 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.302394 17456 net.cpp:156] Memory required for data: 58605568
I0624 12:47:27.302398 17456 layer_factory.hpp:77] Creating layer bn2_1
I0624 12:47:27.302404 17456 net.cpp:91] Creating Layer bn2_1
I0624 12:47:27.302407 17456 net.cpp:425] bn2_1 <- conv2_1
I0624 12:47:27.302410 17456 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0624 12:47:27.302561 17456 net.cpp:141] Setting up bn2_1
I0624 12:47:27.302567 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.302569 17456 net.cpp:156] Memory required for data: 61816832
I0624 12:47:27.302575 17456 layer_factory.hpp:77] Creating layer scale2_1
I0624 12:47:27.302582 17456 net.cpp:91] Creating Layer scale2_1
I0624 12:47:27.302584 17456 net.cpp:425] scale2_1 <- conv2_1
I0624 12:47:27.302587 17456 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0624 12:47:27.302618 17456 layer_factory.hpp:77] Creating layer scale2_1
I0624 12:47:27.302709 17456 net.cpp:141] Setting up scale2_1
I0624 12:47:27.302716 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.302718 17456 net.cpp:156] Memory required for data: 65028096
I0624 12:47:27.302726 17456 layer_factory.hpp:77] Creating layer relu2_1
I0624 12:47:27.302731 17456 net.cpp:91] Creating Layer relu2_1
I0624 12:47:27.302733 17456 net.cpp:425] relu2_1 <- conv2_1
I0624 12:47:27.302737 17456 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0624 12:47:27.302992 17456 net.cpp:141] Setting up relu2_1
I0624 12:47:27.303002 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.303005 17456 net.cpp:156] Memory required for data: 68239360
I0624 12:47:27.303007 17456 layer_factory.hpp:77] Creating layer conv2_2
I0624 12:47:27.303016 17456 net.cpp:91] Creating Layer conv2_2
I0624 12:47:27.303020 17456 net.cpp:425] conv2_2 <- conv2_1
I0624 12:47:27.303023 17456 net.cpp:399] conv2_2 -> conv2_2
I0624 12:47:27.303997 17456 net.cpp:141] Setting up conv2_2
I0624 12:47:27.304009 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.304011 17456 net.cpp:156] Memory required for data: 71450624
I0624 12:47:27.304026 17456 layer_factory.hpp:77] Creating layer bn2_2
I0624 12:47:27.304034 17456 net.cpp:91] Creating Layer bn2_2
I0624 12:47:27.304038 17456 net.cpp:425] bn2_2 <- conv2_2
I0624 12:47:27.304041 17456 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0624 12:47:27.304188 17456 net.cpp:141] Setting up bn2_2
I0624 12:47:27.304195 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.304198 17456 net.cpp:156] Memory required for data: 74661888
I0624 12:47:27.304203 17456 layer_factory.hpp:77] Creating layer scale2_2
I0624 12:47:27.304209 17456 net.cpp:91] Creating Layer scale2_2
I0624 12:47:27.304211 17456 net.cpp:425] scale2_2 <- conv2_2
I0624 12:47:27.304215 17456 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0624 12:47:27.304246 17456 layer_factory.hpp:77] Creating layer scale2_2
I0624 12:47:27.304337 17456 net.cpp:141] Setting up scale2_2
I0624 12:47:27.304344 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.304347 17456 net.cpp:156] Memory required for data: 77873152
I0624 12:47:27.304350 17456 layer_factory.hpp:77] Creating layer relu2_2
I0624 12:47:27.304355 17456 net.cpp:91] Creating Layer relu2_2
I0624 12:47:27.304358 17456 net.cpp:425] relu2_2 <- conv2_2
I0624 12:47:27.304361 17456 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0624 12:47:27.304617 17456 net.cpp:141] Setting up relu2_2
I0624 12:47:27.304628 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.304630 17456 net.cpp:156] Memory required for data: 81084416
I0624 12:47:27.304633 17456 layer_factory.hpp:77] Creating layer pool2
I0624 12:47:27.304636 17456 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 12:47:27.304641 17456 net.cpp:91] Creating Layer pool2
I0624 12:47:27.304643 17456 net.cpp:425] pool2 <- conv2_2
I0624 12:47:27.304647 17456 net.cpp:399] pool2 -> pool2
I0624 12:47:27.304652 17456 net.cpp:399] pool2 -> pool2_mask
I0624 12:47:27.304687 17456 net.cpp:141] Setting up pool2
I0624 12:47:27.304690 17456 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:47:27.304693 17456 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:47:27.304695 17456 net.cpp:156] Memory required for data: 82690048
I0624 12:47:27.304697 17456 layer_factory.hpp:77] Creating layer conv3_1
I0624 12:47:27.304704 17456 net.cpp:91] Creating Layer conv3_1
I0624 12:47:27.304708 17456 net.cpp:425] conv3_1 <- pool2
I0624 12:47:27.304711 17456 net.cpp:399] conv3_1 -> conv3_1
I0624 12:47:27.306566 17456 net.cpp:141] Setting up conv3_1
I0624 12:47:27.306578 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.306581 17456 net.cpp:156] Memory required for data: 84295680
I0624 12:47:27.306586 17456 layer_factory.hpp:77] Creating layer bn3_1
I0624 12:47:27.306591 17456 net.cpp:91] Creating Layer bn3_1
I0624 12:47:27.306594 17456 net.cpp:425] bn3_1 <- conv3_1
I0624 12:47:27.306598 17456 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0624 12:47:27.307342 17456 net.cpp:141] Setting up bn3_1
I0624 12:47:27.307353 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.307354 17456 net.cpp:156] Memory required for data: 85901312
I0624 12:47:27.307361 17456 layer_factory.hpp:77] Creating layer scale3_1
I0624 12:47:27.307368 17456 net.cpp:91] Creating Layer scale3_1
I0624 12:47:27.307370 17456 net.cpp:425] scale3_1 <- conv3_1
I0624 12:47:27.307374 17456 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0624 12:47:27.307407 17456 layer_factory.hpp:77] Creating layer scale3_1
I0624 12:47:27.307488 17456 net.cpp:141] Setting up scale3_1
I0624 12:47:27.307495 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.307498 17456 net.cpp:156] Memory required for data: 87506944
I0624 12:47:27.307502 17456 layer_factory.hpp:77] Creating layer relu3_1
I0624 12:47:27.307507 17456 net.cpp:91] Creating Layer relu3_1
I0624 12:47:27.307509 17456 net.cpp:425] relu3_1 <- conv3_1
I0624 12:47:27.307513 17456 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0624 12:47:27.307648 17456 net.cpp:141] Setting up relu3_1
I0624 12:47:27.307657 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.307672 17456 net.cpp:156] Memory required for data: 89112576
I0624 12:47:27.307675 17456 layer_factory.hpp:77] Creating layer conv3_2
I0624 12:47:27.307683 17456 net.cpp:91] Creating Layer conv3_2
I0624 12:47:27.307687 17456 net.cpp:425] conv3_2 <- conv3_1
I0624 12:47:27.307690 17456 net.cpp:399] conv3_2 -> conv3_2
I0624 12:47:27.309393 17456 net.cpp:141] Setting up conv3_2
I0624 12:47:27.309406 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.309408 17456 net.cpp:156] Memory required for data: 90718208
I0624 12:47:27.309412 17456 layer_factory.hpp:77] Creating layer bn3_2
I0624 12:47:27.309418 17456 net.cpp:91] Creating Layer bn3_2
I0624 12:47:27.309422 17456 net.cpp:425] bn3_2 <- conv3_2
I0624 12:47:27.309425 17456 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0624 12:47:27.309571 17456 net.cpp:141] Setting up bn3_2
I0624 12:47:27.309578 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.309581 17456 net.cpp:156] Memory required for data: 92323840
I0624 12:47:27.309590 17456 layer_factory.hpp:77] Creating layer scale3_2
I0624 12:47:27.309597 17456 net.cpp:91] Creating Layer scale3_2
I0624 12:47:27.309599 17456 net.cpp:425] scale3_2 <- conv3_2
I0624 12:47:27.309603 17456 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0624 12:47:27.309633 17456 layer_factory.hpp:77] Creating layer scale3_2
I0624 12:47:27.309715 17456 net.cpp:141] Setting up scale3_2
I0624 12:47:27.309721 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.309725 17456 net.cpp:156] Memory required for data: 93929472
I0624 12:47:27.309728 17456 layer_factory.hpp:77] Creating layer relu3_2
I0624 12:47:27.309732 17456 net.cpp:91] Creating Layer relu3_2
I0624 12:47:27.309736 17456 net.cpp:425] relu3_2 <- conv3_2
I0624 12:47:27.309741 17456 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0624 12:47:27.310000 17456 net.cpp:141] Setting up relu3_2
I0624 12:47:27.310010 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.310014 17456 net.cpp:156] Memory required for data: 95535104
I0624 12:47:27.310015 17456 layer_factory.hpp:77] Creating layer pool3
I0624 12:47:27.310019 17456 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 12:47:27.310024 17456 net.cpp:91] Creating Layer pool3
I0624 12:47:27.310026 17456 net.cpp:425] pool3 <- conv3_2
I0624 12:47:27.310030 17456 net.cpp:399] pool3 -> pool3
I0624 12:47:27.310035 17456 net.cpp:399] pool3 -> pool3_mask
I0624 12:47:27.310068 17456 net.cpp:141] Setting up pool3
I0624 12:47:27.310072 17456 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:47:27.310075 17456 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:47:27.310077 17456 net.cpp:156] Memory required for data: 96337920
I0624 12:47:27.310081 17456 layer_factory.hpp:77] Creating layer conv4_1
I0624 12:47:27.310087 17456 net.cpp:91] Creating Layer conv4_1
I0624 12:47:27.310091 17456 net.cpp:425] conv4_1 <- pool3
I0624 12:47:27.310094 17456 net.cpp:399] conv4_1 -> conv4_1
I0624 12:47:27.313141 17456 net.cpp:141] Setting up conv4_1
I0624 12:47:27.313215 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.313217 17456 net.cpp:156] Memory required for data: 97140736
I0624 12:47:27.313222 17456 layer_factory.hpp:77] Creating layer bn4_1
I0624 12:47:27.313228 17456 net.cpp:91] Creating Layer bn4_1
I0624 12:47:27.313231 17456 net.cpp:425] bn4_1 <- conv4_1
I0624 12:47:27.313235 17456 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0624 12:47:27.313381 17456 net.cpp:141] Setting up bn4_1
I0624 12:47:27.313388 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.313391 17456 net.cpp:156] Memory required for data: 97943552
I0624 12:47:27.313397 17456 layer_factory.hpp:77] Creating layer scale4_1
I0624 12:47:27.313402 17456 net.cpp:91] Creating Layer scale4_1
I0624 12:47:27.313405 17456 net.cpp:425] scale4_1 <- conv4_1
I0624 12:47:27.313408 17456 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0624 12:47:27.313441 17456 layer_factory.hpp:77] Creating layer scale4_1
I0624 12:47:27.313525 17456 net.cpp:141] Setting up scale4_1
I0624 12:47:27.313542 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.313545 17456 net.cpp:156] Memory required for data: 98746368
I0624 12:47:27.313550 17456 layer_factory.hpp:77] Creating layer relu4_1
I0624 12:47:27.313557 17456 net.cpp:91] Creating Layer relu4_1
I0624 12:47:27.313560 17456 net.cpp:425] relu4_1 <- conv4_1
I0624 12:47:27.313565 17456 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0624 12:47:27.313820 17456 net.cpp:141] Setting up relu4_1
I0624 12:47:27.313832 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.313834 17456 net.cpp:156] Memory required for data: 99549184
I0624 12:47:27.313838 17456 layer_factory.hpp:77] Creating layer conv4_2
I0624 12:47:27.313846 17456 net.cpp:91] Creating Layer conv4_2
I0624 12:47:27.313848 17456 net.cpp:425] conv4_2 <- conv4_1
I0624 12:47:27.313853 17456 net.cpp:399] conv4_2 -> conv4_2
I0624 12:47:27.320019 17456 net.cpp:141] Setting up conv4_2
I0624 12:47:27.320035 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.320039 17456 net.cpp:156] Memory required for data: 100352000
I0624 12:47:27.320044 17456 layer_factory.hpp:77] Creating layer bn4_2
I0624 12:47:27.320051 17456 net.cpp:91] Creating Layer bn4_2
I0624 12:47:27.320055 17456 net.cpp:425] bn4_2 <- conv4_2
I0624 12:47:27.320058 17456 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0624 12:47:27.320210 17456 net.cpp:141] Setting up bn4_2
I0624 12:47:27.320217 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.320220 17456 net.cpp:156] Memory required for data: 101154816
I0624 12:47:27.320226 17456 layer_factory.hpp:77] Creating layer scale4_2
I0624 12:47:27.320232 17456 net.cpp:91] Creating Layer scale4_2
I0624 12:47:27.320235 17456 net.cpp:425] scale4_2 <- conv4_2
I0624 12:47:27.320238 17456 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0624 12:47:27.320271 17456 layer_factory.hpp:77] Creating layer scale4_2
I0624 12:47:27.320354 17456 net.cpp:141] Setting up scale4_2
I0624 12:47:27.320360 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.320363 17456 net.cpp:156] Memory required for data: 101957632
I0624 12:47:27.320368 17456 layer_factory.hpp:77] Creating layer relu4_2
I0624 12:47:27.320371 17456 net.cpp:91] Creating Layer relu4_2
I0624 12:47:27.320374 17456 net.cpp:425] relu4_2 <- conv4_2
I0624 12:47:27.320377 17456 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0624 12:47:27.320518 17456 net.cpp:141] Setting up relu4_2
I0624 12:47:27.320526 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.320528 17456 net.cpp:156] Memory required for data: 102760448
I0624 12:47:27.320531 17456 layer_factory.hpp:77] Creating layer pool4
I0624 12:47:27.320534 17456 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 12:47:27.320538 17456 net.cpp:91] Creating Layer pool4
I0624 12:47:27.320541 17456 net.cpp:425] pool4 <- conv4_2
I0624 12:47:27.320545 17456 net.cpp:399] pool4 -> pool4
I0624 12:47:27.320550 17456 net.cpp:399] pool4 -> pool4_mask
I0624 12:47:27.320585 17456 net.cpp:141] Setting up pool4
I0624 12:47:27.320591 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.320595 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.320596 17456 net.cpp:156] Memory required for data: 103161856
I0624 12:47:27.320598 17456 layer_factory.hpp:77] Creating layer conv5_1
I0624 12:47:27.320606 17456 net.cpp:91] Creating Layer conv5_1
I0624 12:47:27.320610 17456 net.cpp:425] conv5_1 <- pool4
I0624 12:47:27.320614 17456 net.cpp:399] conv5_1 -> conv5_1
I0624 12:47:27.325999 17456 net.cpp:141] Setting up conv5_1
I0624 12:47:27.326014 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.326016 17456 net.cpp:156] Memory required for data: 103362560
I0624 12:47:27.326021 17456 layer_factory.hpp:77] Creating layer bn5_1
I0624 12:47:27.326028 17456 net.cpp:91] Creating Layer bn5_1
I0624 12:47:27.326031 17456 net.cpp:425] bn5_1 <- conv5_1
I0624 12:47:27.326035 17456 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0624 12:47:27.326186 17456 net.cpp:141] Setting up bn5_1
I0624 12:47:27.326206 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.326210 17456 net.cpp:156] Memory required for data: 103563264
I0624 12:47:27.326215 17456 layer_factory.hpp:77] Creating layer scale5_1
I0624 12:47:27.326221 17456 net.cpp:91] Creating Layer scale5_1
I0624 12:47:27.326225 17456 net.cpp:425] scale5_1 <- conv5_1
I0624 12:47:27.326227 17456 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0624 12:47:27.326261 17456 layer_factory.hpp:77] Creating layer scale5_1
I0624 12:47:27.326344 17456 net.cpp:141] Setting up scale5_1
I0624 12:47:27.326349 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.326352 17456 net.cpp:156] Memory required for data: 103763968
I0624 12:47:27.326356 17456 layer_factory.hpp:77] Creating layer relu5_1
I0624 12:47:27.326360 17456 net.cpp:91] Creating Layer relu5_1
I0624 12:47:27.326362 17456 net.cpp:425] relu5_1 <- conv5_1
I0624 12:47:27.326366 17456 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0624 12:47:27.326629 17456 net.cpp:141] Setting up relu5_1
I0624 12:47:27.326639 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.326642 17456 net.cpp:156] Memory required for data: 103964672
I0624 12:47:27.326644 17456 layer_factory.hpp:77] Creating layer conv5_2
I0624 12:47:27.326653 17456 net.cpp:91] Creating Layer conv5_2
I0624 12:47:27.326655 17456 net.cpp:425] conv5_2 <- conv5_1
I0624 12:47:27.326660 17456 net.cpp:399] conv5_2 -> conv5_2
I0624 12:47:27.331969 17456 net.cpp:141] Setting up conv5_2
I0624 12:47:27.331982 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.331985 17456 net.cpp:156] Memory required for data: 104165376
I0624 12:47:27.331991 17456 layer_factory.hpp:77] Creating layer bn5_2
I0624 12:47:27.331997 17456 net.cpp:91] Creating Layer bn5_2
I0624 12:47:27.332001 17456 net.cpp:425] bn5_2 <- conv5_2
I0624 12:47:27.332005 17456 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0624 12:47:27.332154 17456 net.cpp:141] Setting up bn5_2
I0624 12:47:27.332161 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.332164 17456 net.cpp:156] Memory required for data: 104366080
I0624 12:47:27.332168 17456 layer_factory.hpp:77] Creating layer scale5_2
I0624 12:47:27.332175 17456 net.cpp:91] Creating Layer scale5_2
I0624 12:47:27.332177 17456 net.cpp:425] scale5_2 <- conv5_2
I0624 12:47:27.332180 17456 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0624 12:47:27.332211 17456 layer_factory.hpp:77] Creating layer scale5_2
I0624 12:47:27.332290 17456 net.cpp:141] Setting up scale5_2
I0624 12:47:27.332306 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.332309 17456 net.cpp:156] Memory required for data: 104566784
I0624 12:47:27.332314 17456 layer_factory.hpp:77] Creating layer relu5_2
I0624 12:47:27.332317 17456 net.cpp:91] Creating Layer relu5_2
I0624 12:47:27.332320 17456 net.cpp:425] relu5_2 <- conv5_2
I0624 12:47:27.332324 17456 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0624 12:47:27.332576 17456 net.cpp:141] Setting up relu5_2
I0624 12:47:27.332587 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.332589 17456 net.cpp:156] Memory required for data: 104767488
I0624 12:47:27.332592 17456 layer_factory.hpp:77] Creating layer pool5
I0624 12:47:27.332595 17456 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 12:47:27.332600 17456 net.cpp:91] Creating Layer pool5
I0624 12:47:27.332602 17456 net.cpp:425] pool5 <- conv5_2
I0624 12:47:27.332607 17456 net.cpp:399] pool5 -> pool5
I0624 12:47:27.332612 17456 net.cpp:399] pool5 -> pool5_mask
I0624 12:47:27.332648 17456 net.cpp:141] Setting up pool5
I0624 12:47:27.332653 17456 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 12:47:27.332656 17456 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 12:47:27.332659 17456 net.cpp:156] Memory required for data: 104867840
I0624 12:47:27.332660 17456 layer_factory.hpp:77] Creating layer upsample5
I0624 12:47:27.332666 17456 net.cpp:91] Creating Layer upsample5
I0624 12:47:27.332669 17456 net.cpp:425] upsample5 <- pool5
I0624 12:47:27.332671 17456 net.cpp:425] upsample5 <- pool5_mask
I0624 12:47:27.332686 17456 net.cpp:399] upsample5 -> pool5_D
I0624 12:47:27.332713 17456 net.cpp:141] Setting up upsample5
I0624 12:47:27.332717 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.332720 17456 net.cpp:156] Memory required for data: 105068544
I0624 12:47:27.332721 17456 layer_factory.hpp:77] Creating layer conv5_2_D
I0624 12:47:27.332728 17456 net.cpp:91] Creating Layer conv5_2_D
I0624 12:47:27.332731 17456 net.cpp:425] conv5_2_D <- pool5_D
I0624 12:47:27.332736 17456 net.cpp:399] conv5_2_D -> conv5_2_D
I0624 12:47:27.338127 17456 net.cpp:141] Setting up conv5_2_D
I0624 12:47:27.338141 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.338145 17456 net.cpp:156] Memory required for data: 105269248
I0624 12:47:27.338150 17456 layer_factory.hpp:77] Creating layer bn5_2_D
I0624 12:47:27.338155 17456 net.cpp:91] Creating Layer bn5_2_D
I0624 12:47:27.338158 17456 net.cpp:425] bn5_2_D <- conv5_2_D
I0624 12:47:27.338163 17456 net.cpp:386] bn5_2_D -> conv5_2_D (in-place)
I0624 12:47:27.338316 17456 net.cpp:141] Setting up bn5_2_D
I0624 12:47:27.338323 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.338326 17456 net.cpp:156] Memory required for data: 105469952
I0624 12:47:27.338332 17456 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 12:47:27.338338 17456 net.cpp:91] Creating Layer scale5_2_D
I0624 12:47:27.338340 17456 net.cpp:425] scale5_2_D <- conv5_2_D
I0624 12:47:27.338345 17456 net.cpp:386] scale5_2_D -> conv5_2_D (in-place)
I0624 12:47:27.338376 17456 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 12:47:27.338456 17456 net.cpp:141] Setting up scale5_2_D
I0624 12:47:27.338464 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.338465 17456 net.cpp:156] Memory required for data: 105670656
I0624 12:47:27.338476 17456 layer_factory.hpp:77] Creating layer relu5_2_D
I0624 12:47:27.338481 17456 net.cpp:91] Creating Layer relu5_2_D
I0624 12:47:27.338485 17456 net.cpp:425] relu5_2_D <- conv5_2_D
I0624 12:47:27.338487 17456 net.cpp:386] relu5_2_D -> conv5_2_D (in-place)
I0624 12:47:27.338620 17456 net.cpp:141] Setting up relu5_2_D
I0624 12:47:27.338631 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.338634 17456 net.cpp:156] Memory required for data: 105871360
I0624 12:47:27.338636 17456 layer_factory.hpp:77] Creating layer conv5_1_D
I0624 12:47:27.338644 17456 net.cpp:91] Creating Layer conv5_1_D
I0624 12:47:27.338647 17456 net.cpp:425] conv5_1_D <- conv5_2_D
I0624 12:47:27.338651 17456 net.cpp:399] conv5_1_D -> conv5_1_D
I0624 12:47:27.343976 17456 net.cpp:141] Setting up conv5_1_D
I0624 12:47:27.343988 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.343991 17456 net.cpp:156] Memory required for data: 106072064
I0624 12:47:27.343997 17456 layer_factory.hpp:77] Creating layer bn5_1_D
I0624 12:47:27.344002 17456 net.cpp:91] Creating Layer bn5_1_D
I0624 12:47:27.344004 17456 net.cpp:425] bn5_1_D <- conv5_1_D
I0624 12:47:27.344009 17456 net.cpp:386] bn5_1_D -> conv5_1_D (in-place)
I0624 12:47:27.344161 17456 net.cpp:141] Setting up bn5_1_D
I0624 12:47:27.344168 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.344172 17456 net.cpp:156] Memory required for data: 106272768
I0624 12:47:27.344177 17456 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 12:47:27.344182 17456 net.cpp:91] Creating Layer scale5_1_D
I0624 12:47:27.344185 17456 net.cpp:425] scale5_1_D <- conv5_1_D
I0624 12:47:27.344189 17456 net.cpp:386] scale5_1_D -> conv5_1_D (in-place)
I0624 12:47:27.344221 17456 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 12:47:27.344303 17456 net.cpp:141] Setting up scale5_1_D
I0624 12:47:27.344310 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.344311 17456 net.cpp:156] Memory required for data: 106473472
I0624 12:47:27.344316 17456 layer_factory.hpp:77] Creating layer relu5_1_D
I0624 12:47:27.344321 17456 net.cpp:91] Creating Layer relu5_1_D
I0624 12:47:27.344322 17456 net.cpp:425] relu5_1_D <- conv5_1_D
I0624 12:47:27.344326 17456 net.cpp:386] relu5_1_D -> conv5_1_D (in-place)
I0624 12:47:27.344594 17456 net.cpp:141] Setting up relu5_1_D
I0624 12:47:27.344605 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.344607 17456 net.cpp:156] Memory required for data: 106674176
I0624 12:47:27.344610 17456 layer_factory.hpp:77] Creating layer upsample4
I0624 12:47:27.344615 17456 net.cpp:91] Creating Layer upsample4
I0624 12:47:27.344619 17456 net.cpp:425] upsample4 <- conv5_1_D
I0624 12:47:27.344622 17456 net.cpp:425] upsample4 <- pool4_mask
I0624 12:47:27.344626 17456 net.cpp:399] upsample4 -> pool4_D
I0624 12:47:27.344653 17456 net.cpp:141] Setting up upsample4
I0624 12:47:27.344657 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.344660 17456 net.cpp:156] Memory required for data: 107476992
I0624 12:47:27.344662 17456 layer_factory.hpp:77] Creating layer conv4_2_D
I0624 12:47:27.344669 17456 net.cpp:91] Creating Layer conv4_2_D
I0624 12:47:27.344671 17456 net.cpp:425] conv4_2_D <- pool4_D
I0624 12:47:27.344676 17456 net.cpp:399] conv4_2_D -> conv4_2_D
I0624 12:47:27.354313 17456 net.cpp:141] Setting up conv4_2_D
I0624 12:47:27.354334 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.354337 17456 net.cpp:156] Memory required for data: 108279808
I0624 12:47:27.354344 17456 layer_factory.hpp:77] Creating layer bn4_2_D
I0624 12:47:27.354353 17456 net.cpp:91] Creating Layer bn4_2_D
I0624 12:47:27.354357 17456 net.cpp:425] bn4_2_D <- conv4_2_D
I0624 12:47:27.354363 17456 net.cpp:386] bn4_2_D -> conv4_2_D (in-place)
I0624 12:47:27.354538 17456 net.cpp:141] Setting up bn4_2_D
I0624 12:47:27.354545 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.354548 17456 net.cpp:156] Memory required for data: 109082624
I0624 12:47:27.354554 17456 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 12:47:27.354562 17456 net.cpp:91] Creating Layer scale4_2_D
I0624 12:47:27.354564 17456 net.cpp:425] scale4_2_D <- conv4_2_D
I0624 12:47:27.354568 17456 net.cpp:386] scale4_2_D -> conv4_2_D (in-place)
I0624 12:47:27.354601 17456 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 12:47:27.354694 17456 net.cpp:141] Setting up scale4_2_D
I0624 12:47:27.354701 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.354703 17456 net.cpp:156] Memory required for data: 109885440
I0624 12:47:27.354707 17456 layer_factory.hpp:77] Creating layer relu4_2_D
I0624 12:47:27.354712 17456 net.cpp:91] Creating Layer relu4_2_D
I0624 12:47:27.354714 17456 net.cpp:425] relu4_2_D <- conv4_2_D
I0624 12:47:27.354718 17456 net.cpp:386] relu4_2_D -> conv4_2_D (in-place)
I0624 12:47:27.354982 17456 net.cpp:141] Setting up relu4_2_D
I0624 12:47:27.354993 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.354996 17456 net.cpp:156] Memory required for data: 110688256
I0624 12:47:27.354998 17456 layer_factory.hpp:77] Creating layer conv4_1_D
I0624 12:47:27.355008 17456 net.cpp:91] Creating Layer conv4_1_D
I0624 12:47:27.355011 17456 net.cpp:425] conv4_1_D <- conv4_2_D
I0624 12:47:27.355016 17456 net.cpp:399] conv4_1_D -> conv4_1_D
I0624 12:47:27.358211 17456 net.cpp:141] Setting up conv4_1_D
I0624 12:47:27.358223 17456 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:47:27.358227 17456 net.cpp:156] Memory required for data: 111089664
I0624 12:47:27.358230 17456 layer_factory.hpp:77] Creating layer bn4_1_D
I0624 12:47:27.358237 17456 net.cpp:91] Creating Layer bn4_1_D
I0624 12:47:27.358239 17456 net.cpp:425] bn4_1_D <- conv4_1_D
I0624 12:47:27.358244 17456 net.cpp:386] bn4_1_D -> conv4_1_D (in-place)
I0624 12:47:27.358405 17456 net.cpp:141] Setting up bn4_1_D
I0624 12:47:27.358412 17456 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:47:27.358414 17456 net.cpp:156] Memory required for data: 111491072
I0624 12:47:27.358420 17456 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 12:47:27.358427 17456 net.cpp:91] Creating Layer scale4_1_D
I0624 12:47:27.358429 17456 net.cpp:425] scale4_1_D <- conv4_1_D
I0624 12:47:27.358433 17456 net.cpp:386] scale4_1_D -> conv4_1_D (in-place)
I0624 12:47:27.358465 17456 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 12:47:27.358579 17456 net.cpp:141] Setting up scale4_1_D
I0624 12:47:27.358587 17456 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:47:27.358588 17456 net.cpp:156] Memory required for data: 111892480
I0624 12:47:27.358593 17456 layer_factory.hpp:77] Creating layer relu4_1_D
I0624 12:47:27.358603 17456 net.cpp:91] Creating Layer relu4_1_D
I0624 12:47:27.358605 17456 net.cpp:425] relu4_1_D <- conv4_1_D
I0624 12:47:27.358608 17456 net.cpp:386] relu4_1_D -> conv4_1_D (in-place)
I0624 12:47:27.358747 17456 net.cpp:141] Setting up relu4_1_D
I0624 12:47:27.358757 17456 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:47:27.358758 17456 net.cpp:156] Memory required for data: 112293888
I0624 12:47:27.358762 17456 layer_factory.hpp:77] Creating layer upsample3
I0624 12:47:27.358768 17456 net.cpp:91] Creating Layer upsample3
I0624 12:47:27.358770 17456 net.cpp:425] upsample3 <- conv4_1_D
I0624 12:47:27.358774 17456 net.cpp:425] upsample3 <- pool3_mask
I0624 12:47:27.358778 17456 net.cpp:399] upsample3 -> pool3_D
I0624 12:47:27.358804 17456 net.cpp:141] Setting up upsample3
I0624 12:47:27.358808 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.358810 17456 net.cpp:156] Memory required for data: 113899520
I0624 12:47:27.358814 17456 layer_factory.hpp:77] Creating layer conv3_2_D
I0624 12:47:27.358820 17456 net.cpp:91] Creating Layer conv3_2_D
I0624 12:47:27.358824 17456 net.cpp:425] conv3_2_D <- pool3_D
I0624 12:47:27.358827 17456 net.cpp:399] conv3_2_D -> conv3_2_D
I0624 12:47:27.361220 17456 net.cpp:141] Setting up conv3_2_D
I0624 12:47:27.361233 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.361237 17456 net.cpp:156] Memory required for data: 115505152
I0624 12:47:27.361243 17456 layer_factory.hpp:77] Creating layer bn3_2_D
I0624 12:47:27.361248 17456 net.cpp:91] Creating Layer bn3_2_D
I0624 12:47:27.361251 17456 net.cpp:425] bn3_2_D <- conv3_2_D
I0624 12:47:27.361255 17456 net.cpp:386] bn3_2_D -> conv3_2_D (in-place)
I0624 12:47:27.361419 17456 net.cpp:141] Setting up bn3_2_D
I0624 12:47:27.361426 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.361428 17456 net.cpp:156] Memory required for data: 117110784
I0624 12:47:27.361434 17456 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 12:47:27.361440 17456 net.cpp:91] Creating Layer scale3_2_D
I0624 12:47:27.361443 17456 net.cpp:425] scale3_2_D <- conv3_2_D
I0624 12:47:27.361446 17456 net.cpp:386] scale3_2_D -> conv3_2_D (in-place)
I0624 12:47:27.361479 17456 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 12:47:27.361587 17456 net.cpp:141] Setting up scale3_2_D
I0624 12:47:27.361593 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.361596 17456 net.cpp:156] Memory required for data: 118716416
I0624 12:47:27.361600 17456 layer_factory.hpp:77] Creating layer relu3_2_D
I0624 12:47:27.361605 17456 net.cpp:91] Creating Layer relu3_2_D
I0624 12:47:27.361608 17456 net.cpp:425] relu3_2_D <- conv3_2_D
I0624 12:47:27.361611 17456 net.cpp:386] relu3_2_D -> conv3_2_D (in-place)
I0624 12:47:27.361886 17456 net.cpp:141] Setting up relu3_2_D
I0624 12:47:27.361897 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.361901 17456 net.cpp:156] Memory required for data: 120322048
I0624 12:47:27.361903 17456 layer_factory.hpp:77] Creating layer conv3_1_D
I0624 12:47:27.361912 17456 net.cpp:91] Creating Layer conv3_1_D
I0624 12:47:27.361914 17456 net.cpp:425] conv3_1_D <- conv3_2_D
I0624 12:47:27.361919 17456 net.cpp:399] conv3_1_D -> conv3_1_D
I0624 12:47:27.363255 17456 net.cpp:141] Setting up conv3_1_D
I0624 12:47:27.363267 17456 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:47:27.363270 17456 net.cpp:156] Memory required for data: 121124864
I0624 12:47:27.363275 17456 layer_factory.hpp:77] Creating layer bn3_1_D
I0624 12:47:27.363281 17456 net.cpp:91] Creating Layer bn3_1_D
I0624 12:47:27.363283 17456 net.cpp:425] bn3_1_D <- conv3_1_D
I0624 12:47:27.363287 17456 net.cpp:386] bn3_1_D -> conv3_1_D (in-place)
I0624 12:47:27.363462 17456 net.cpp:141] Setting up bn3_1_D
I0624 12:47:27.363481 17456 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:47:27.363483 17456 net.cpp:156] Memory required for data: 121927680
I0624 12:47:27.363489 17456 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 12:47:27.363495 17456 net.cpp:91] Creating Layer scale3_1_D
I0624 12:47:27.363498 17456 net.cpp:425] scale3_1_D <- conv3_1_D
I0624 12:47:27.363502 17456 net.cpp:386] scale3_1_D -> conv3_1_D (in-place)
I0624 12:47:27.363540 17456 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 12:47:27.363642 17456 net.cpp:141] Setting up scale3_1_D
I0624 12:47:27.363649 17456 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:47:27.363653 17456 net.cpp:156] Memory required for data: 122730496
I0624 12:47:27.363657 17456 layer_factory.hpp:77] Creating layer relu3_1_D
I0624 12:47:27.363662 17456 net.cpp:91] Creating Layer relu3_1_D
I0624 12:47:27.363663 17456 net.cpp:425] relu3_1_D <- conv3_1_D
I0624 12:47:27.363667 17456 net.cpp:386] relu3_1_D -> conv3_1_D (in-place)
I0624 12:47:27.363941 17456 net.cpp:141] Setting up relu3_1_D
I0624 12:47:27.363952 17456 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:47:27.363955 17456 net.cpp:156] Memory required for data: 123533312
I0624 12:47:27.363957 17456 layer_factory.hpp:77] Creating layer upsample2
I0624 12:47:27.363962 17456 net.cpp:91] Creating Layer upsample2
I0624 12:47:27.363965 17456 net.cpp:425] upsample2 <- conv3_1_D
I0624 12:47:27.363970 17456 net.cpp:425] upsample2 <- pool2_mask
I0624 12:47:27.363972 17456 net.cpp:399] upsample2 -> pool2_D
I0624 12:47:27.364001 17456 net.cpp:141] Setting up upsample2
I0624 12:47:27.364004 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.364006 17456 net.cpp:156] Memory required for data: 126744576
I0624 12:47:27.364009 17456 layer_factory.hpp:77] Creating layer conv2_2_D
I0624 12:47:27.364017 17456 net.cpp:91] Creating Layer conv2_2_D
I0624 12:47:27.364018 17456 net.cpp:425] conv2_2_D <- pool2_D
I0624 12:47:27.364022 17456 net.cpp:399] conv2_2_D -> conv2_2_D
I0624 12:47:27.365249 17456 net.cpp:141] Setting up conv2_2_D
I0624 12:47:27.365262 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.365263 17456 net.cpp:156] Memory required for data: 129955840
I0624 12:47:27.365268 17456 layer_factory.hpp:77] Creating layer bn2_2_D
I0624 12:47:27.365274 17456 net.cpp:91] Creating Layer bn2_2_D
I0624 12:47:27.365278 17456 net.cpp:425] bn2_2_D <- conv2_2_D
I0624 12:47:27.365281 17456 net.cpp:386] bn2_2_D -> conv2_2_D (in-place)
I0624 12:47:27.365464 17456 net.cpp:141] Setting up bn2_2_D
I0624 12:47:27.365471 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.365473 17456 net.cpp:156] Memory required for data: 133167104
I0624 12:47:27.365479 17456 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 12:47:27.365485 17456 net.cpp:91] Creating Layer scale2_2_D
I0624 12:47:27.365488 17456 net.cpp:425] scale2_2_D <- conv2_2_D
I0624 12:47:27.365490 17456 net.cpp:386] scale2_2_D -> conv2_2_D (in-place)
I0624 12:47:27.365526 17456 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 12:47:27.365640 17456 net.cpp:141] Setting up scale2_2_D
I0624 12:47:27.365648 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.365649 17456 net.cpp:156] Memory required for data: 136378368
I0624 12:47:27.365653 17456 layer_factory.hpp:77] Creating layer relu2_2_D
I0624 12:47:27.365658 17456 net.cpp:91] Creating Layer relu2_2_D
I0624 12:47:27.365661 17456 net.cpp:425] relu2_2_D <- conv2_2_D
I0624 12:47:27.365664 17456 net.cpp:386] relu2_2_D -> conv2_2_D (in-place)
I0624 12:47:27.365808 17456 net.cpp:141] Setting up relu2_2_D
I0624 12:47:27.365816 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.365820 17456 net.cpp:156] Memory required for data: 139589632
I0624 12:47:27.365823 17456 layer_factory.hpp:77] Creating layer conv2_1_D
I0624 12:47:27.365829 17456 net.cpp:91] Creating Layer conv2_1_D
I0624 12:47:27.365833 17456 net.cpp:425] conv2_1_D <- conv2_2_D
I0624 12:47:27.365838 17456 net.cpp:399] conv2_1_D -> conv2_1_D
I0624 12:47:27.366803 17456 net.cpp:141] Setting up conv2_1_D
I0624 12:47:27.366823 17456 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:47:27.366827 17456 net.cpp:156] Memory required for data: 141195264
I0624 12:47:27.366832 17456 layer_factory.hpp:77] Creating layer bn2_1_D
I0624 12:47:27.366838 17456 net.cpp:91] Creating Layer bn2_1_D
I0624 12:47:27.366842 17456 net.cpp:425] bn2_1_D <- conv2_1_D
I0624 12:47:27.366844 17456 net.cpp:386] bn2_1_D -> conv2_1_D (in-place)
I0624 12:47:27.367046 17456 net.cpp:141] Setting up bn2_1_D
I0624 12:47:27.367053 17456 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:47:27.367055 17456 net.cpp:156] Memory required for data: 142800896
I0624 12:47:27.367063 17456 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 12:47:27.367068 17456 net.cpp:91] Creating Layer scale2_1_D
I0624 12:47:27.367069 17456 net.cpp:425] scale2_1_D <- conv2_1_D
I0624 12:47:27.367074 17456 net.cpp:386] scale2_1_D -> conv2_1_D (in-place)
I0624 12:47:27.367110 17456 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 12:47:27.367235 17456 net.cpp:141] Setting up scale2_1_D
I0624 12:47:27.367244 17456 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:47:27.367245 17456 net.cpp:156] Memory required for data: 144406528
I0624 12:47:27.367249 17456 layer_factory.hpp:77] Creating layer relu2_1_D
I0624 12:47:27.367254 17456 net.cpp:91] Creating Layer relu2_1_D
I0624 12:47:27.367256 17456 net.cpp:425] relu2_1_D <- conv2_1_D
I0624 12:47:27.367261 17456 net.cpp:386] relu2_1_D -> conv2_1_D (in-place)
I0624 12:47:27.367552 17456 net.cpp:141] Setting up relu2_1_D
I0624 12:47:27.367563 17456 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:47:27.367565 17456 net.cpp:156] Memory required for data: 146012160
I0624 12:47:27.367569 17456 layer_factory.hpp:77] Creating layer upsample1
I0624 12:47:27.367574 17456 net.cpp:91] Creating Layer upsample1
I0624 12:47:27.367578 17456 net.cpp:425] upsample1 <- conv2_1_D
I0624 12:47:27.367583 17456 net.cpp:425] upsample1 <- pool1_mask
I0624 12:47:27.367585 17456 net.cpp:399] upsample1 -> pool1_D
I0624 12:47:27.367614 17456 net.cpp:141] Setting up upsample1
I0624 12:47:27.367619 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.367620 17456 net.cpp:156] Memory required for data: 152434688
I0624 12:47:27.367622 17456 layer_factory.hpp:77] Creating layer conv1_2_D
I0624 12:47:27.367631 17456 net.cpp:91] Creating Layer conv1_2_D
I0624 12:47:27.367635 17456 net.cpp:425] conv1_2_D <- pool1_D
I0624 12:47:27.367637 17456 net.cpp:399] conv1_2_D -> conv1_2_D
I0624 12:47:27.368669 17456 net.cpp:141] Setting up conv1_2_D
I0624 12:47:27.368682 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.368721 17456 net.cpp:156] Memory required for data: 158857216
I0624 12:47:27.368727 17456 layer_factory.hpp:77] Creating layer bn1_2_D
I0624 12:47:27.368733 17456 net.cpp:91] Creating Layer bn1_2_D
I0624 12:47:27.368736 17456 net.cpp:425] bn1_2_D <- conv1_2_D
I0624 12:47:27.368743 17456 net.cpp:386] bn1_2_D -> conv1_2_D (in-place)
I0624 12:47:27.368974 17456 net.cpp:141] Setting up bn1_2_D
I0624 12:47:27.368983 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.368984 17456 net.cpp:156] Memory required for data: 165279744
I0624 12:47:27.368990 17456 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 12:47:27.368995 17456 net.cpp:91] Creating Layer scale1_2_D
I0624 12:47:27.368999 17456 net.cpp:425] scale1_2_D <- conv1_2_D
I0624 12:47:27.369004 17456 net.cpp:386] scale1_2_D -> conv1_2_D (in-place)
I0624 12:47:27.369040 17456 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 12:47:27.369222 17456 net.cpp:141] Setting up scale1_2_D
I0624 12:47:27.369230 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.369232 17456 net.cpp:156] Memory required for data: 171702272
I0624 12:47:27.369236 17456 layer_factory.hpp:77] Creating layer relu1_2_D
I0624 12:47:27.369241 17456 net.cpp:91] Creating Layer relu1_2_D
I0624 12:47:27.369245 17456 net.cpp:425] relu1_2_D <- conv1_2_D
I0624 12:47:27.369247 17456 net.cpp:386] relu1_2_D -> conv1_2_D (in-place)
I0624 12:47:27.369547 17456 net.cpp:141] Setting up relu1_2_D
I0624 12:47:27.369560 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.369562 17456 net.cpp:156] Memory required for data: 178124800
I0624 12:47:27.369565 17456 layer_factory.hpp:77] Creating layer conv1_1_D
I0624 12:47:27.369575 17456 net.cpp:91] Creating Layer conv1_1_D
I0624 12:47:27.369577 17456 net.cpp:425] conv1_1_D <- conv1_2_D
I0624 12:47:27.369582 17456 net.cpp:399] conv1_1_D -> conv1_1_D
I0624 12:47:27.370682 17456 net.cpp:141] Setting up conv1_1_D
I0624 12:47:27.370693 17456 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 12:47:27.370697 17456 net.cpp:156] Memory required for data: 178526208
I0624 12:47:27.370702 17456 layer_factory.hpp:77] Creating layer conv1_1_D_conv1_1_D_0_split
I0624 12:47:27.370707 17456 net.cpp:91] Creating Layer conv1_1_D_conv1_1_D_0_split
I0624 12:47:27.370709 17456 net.cpp:425] conv1_1_D_conv1_1_D_0_split <- conv1_1_D
I0624 12:47:27.370714 17456 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_0
I0624 12:47:27.370719 17456 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_1
I0624 12:47:27.370764 17456 net.cpp:141] Setting up conv1_1_D_conv1_1_D_0_split
I0624 12:47:27.370770 17456 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 12:47:27.370774 17456 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 12:47:27.370775 17456 net.cpp:156] Memory required for data: 179329024
I0624 12:47:27.370777 17456 layer_factory.hpp:77] Creating layer loss
I0624 12:47:27.370782 17456 net.cpp:91] Creating Layer loss
I0624 12:47:27.370784 17456 net.cpp:425] loss <- conv1_1_D_conv1_1_D_0_split_0
I0624 12:47:27.370787 17456 net.cpp:425] loss <- label_data_1_split_0
I0624 12:47:27.370792 17456 net.cpp:399] loss -> loss
I0624 12:47:27.370800 17456 layer_factory.hpp:77] Creating layer loss
I0624 12:47:27.371722 17456 net.cpp:141] Setting up loss
I0624 12:47:27.371733 17456 net.cpp:148] Top shape: (1)
I0624 12:47:27.371737 17456 net.cpp:151]     with loss weight 1
I0624 12:47:27.371750 17456 net.cpp:156] Memory required for data: 179329028
I0624 12:47:27.371753 17456 layer_factory.hpp:77] Creating layer accuracy
I0624 12:47:27.371757 17456 net.cpp:91] Creating Layer accuracy
I0624 12:47:27.371762 17456 net.cpp:425] accuracy <- conv1_1_D_conv1_1_D_0_split_1
I0624 12:47:27.371765 17456 net.cpp:425] accuracy <- label_data_1_split_1
I0624 12:47:27.371768 17456 net.cpp:399] accuracy -> accuracy
I0624 12:47:27.371775 17456 net.cpp:141] Setting up accuracy
I0624 12:47:27.371778 17456 net.cpp:148] Top shape: (1)
I0624 12:47:27.371780 17456 net.cpp:156] Memory required for data: 179329032
I0624 12:47:27.371783 17456 net.cpp:219] accuracy does not need backward computation.
I0624 12:47:27.371785 17456 net.cpp:217] loss needs backward computation.
I0624 12:47:27.371788 17456 net.cpp:217] conv1_1_D_conv1_1_D_0_split needs backward computation.
I0624 12:47:27.371790 17456 net.cpp:217] conv1_1_D needs backward computation.
I0624 12:47:27.371793 17456 net.cpp:217] relu1_2_D needs backward computation.
I0624 12:47:27.371794 17456 net.cpp:217] scale1_2_D needs backward computation.
I0624 12:47:27.371796 17456 net.cpp:217] bn1_2_D needs backward computation.
I0624 12:47:27.371798 17456 net.cpp:217] conv1_2_D needs backward computation.
I0624 12:47:27.371800 17456 net.cpp:217] upsample1 needs backward computation.
I0624 12:47:27.371803 17456 net.cpp:217] relu2_1_D needs backward computation.
I0624 12:47:27.371805 17456 net.cpp:217] scale2_1_D needs backward computation.
I0624 12:47:27.371808 17456 net.cpp:217] bn2_1_D needs backward computation.
I0624 12:47:27.371809 17456 net.cpp:217] conv2_1_D needs backward computation.
I0624 12:47:27.371811 17456 net.cpp:217] relu2_2_D needs backward computation.
I0624 12:47:27.371814 17456 net.cpp:217] scale2_2_D needs backward computation.
I0624 12:47:27.371815 17456 net.cpp:217] bn2_2_D needs backward computation.
I0624 12:47:27.371817 17456 net.cpp:217] conv2_2_D needs backward computation.
I0624 12:47:27.371819 17456 net.cpp:217] upsample2 needs backward computation.
I0624 12:47:27.371831 17456 net.cpp:217] relu3_1_D needs backward computation.
I0624 12:47:27.371834 17456 net.cpp:217] scale3_1_D needs backward computation.
I0624 12:47:27.371835 17456 net.cpp:217] bn3_1_D needs backward computation.
I0624 12:47:27.371837 17456 net.cpp:217] conv3_1_D needs backward computation.
I0624 12:47:27.371840 17456 net.cpp:217] relu3_2_D needs backward computation.
I0624 12:47:27.371841 17456 net.cpp:217] scale3_2_D needs backward computation.
I0624 12:47:27.371843 17456 net.cpp:217] bn3_2_D needs backward computation.
I0624 12:47:27.371845 17456 net.cpp:217] conv3_2_D needs backward computation.
I0624 12:47:27.371847 17456 net.cpp:217] upsample3 needs backward computation.
I0624 12:47:27.371850 17456 net.cpp:217] relu4_1_D needs backward computation.
I0624 12:47:27.371852 17456 net.cpp:217] scale4_1_D needs backward computation.
I0624 12:47:27.371855 17456 net.cpp:217] bn4_1_D needs backward computation.
I0624 12:47:27.371856 17456 net.cpp:217] conv4_1_D needs backward computation.
I0624 12:47:27.371858 17456 net.cpp:217] relu4_2_D needs backward computation.
I0624 12:47:27.371861 17456 net.cpp:217] scale4_2_D needs backward computation.
I0624 12:47:27.371863 17456 net.cpp:217] bn4_2_D needs backward computation.
I0624 12:47:27.371865 17456 net.cpp:217] conv4_2_D needs backward computation.
I0624 12:47:27.371867 17456 net.cpp:217] upsample4 needs backward computation.
I0624 12:47:27.371870 17456 net.cpp:217] relu5_1_D needs backward computation.
I0624 12:47:27.371872 17456 net.cpp:217] scale5_1_D needs backward computation.
I0624 12:47:27.371875 17456 net.cpp:217] bn5_1_D needs backward computation.
I0624 12:47:27.371876 17456 net.cpp:217] conv5_1_D needs backward computation.
I0624 12:47:27.371879 17456 net.cpp:217] relu5_2_D needs backward computation.
I0624 12:47:27.371881 17456 net.cpp:217] scale5_2_D needs backward computation.
I0624 12:47:27.371883 17456 net.cpp:217] bn5_2_D needs backward computation.
I0624 12:47:27.371886 17456 net.cpp:217] conv5_2_D needs backward computation.
I0624 12:47:27.371887 17456 net.cpp:217] upsample5 needs backward computation.
I0624 12:47:27.371891 17456 net.cpp:217] pool5 needs backward computation.
I0624 12:47:27.371893 17456 net.cpp:217] relu5_2 needs backward computation.
I0624 12:47:27.371896 17456 net.cpp:217] scale5_2 needs backward computation.
I0624 12:47:27.371898 17456 net.cpp:217] bn5_2 needs backward computation.
I0624 12:47:27.371901 17456 net.cpp:217] conv5_2 needs backward computation.
I0624 12:47:27.371902 17456 net.cpp:217] relu5_1 needs backward computation.
I0624 12:47:27.371904 17456 net.cpp:217] scale5_1 needs backward computation.
I0624 12:47:27.371907 17456 net.cpp:217] bn5_1 needs backward computation.
I0624 12:47:27.371909 17456 net.cpp:217] conv5_1 needs backward computation.
I0624 12:47:27.371912 17456 net.cpp:217] pool4 needs backward computation.
I0624 12:47:27.371913 17456 net.cpp:217] relu4_2 needs backward computation.
I0624 12:47:27.371915 17456 net.cpp:217] scale4_2 needs backward computation.
I0624 12:47:27.371918 17456 net.cpp:217] bn4_2 needs backward computation.
I0624 12:47:27.371920 17456 net.cpp:217] conv4_2 needs backward computation.
I0624 12:47:27.371922 17456 net.cpp:217] relu4_1 needs backward computation.
I0624 12:47:27.371924 17456 net.cpp:217] scale4_1 needs backward computation.
I0624 12:47:27.371927 17456 net.cpp:217] bn4_1 needs backward computation.
I0624 12:47:27.371928 17456 net.cpp:217] conv4_1 needs backward computation.
I0624 12:47:27.371932 17456 net.cpp:217] pool3 needs backward computation.
I0624 12:47:27.371933 17456 net.cpp:217] relu3_2 needs backward computation.
I0624 12:47:27.371935 17456 net.cpp:217] scale3_2 needs backward computation.
I0624 12:47:27.371937 17456 net.cpp:217] bn3_2 needs backward computation.
I0624 12:47:27.371940 17456 net.cpp:217] conv3_2 needs backward computation.
I0624 12:47:27.371942 17456 net.cpp:217] relu3_1 needs backward computation.
I0624 12:47:27.371944 17456 net.cpp:217] scale3_1 needs backward computation.
I0624 12:47:27.371947 17456 net.cpp:217] bn3_1 needs backward computation.
I0624 12:47:27.371953 17456 net.cpp:217] conv3_1 needs backward computation.
I0624 12:47:27.371955 17456 net.cpp:217] pool2 needs backward computation.
I0624 12:47:27.371958 17456 net.cpp:217] relu2_2 needs backward computation.
I0624 12:47:27.371960 17456 net.cpp:217] scale2_2 needs backward computation.
I0624 12:47:27.371963 17456 net.cpp:217] bn2_2 needs backward computation.
I0624 12:47:27.371964 17456 net.cpp:217] conv2_2 needs backward computation.
I0624 12:47:27.371968 17456 net.cpp:217] relu2_1 needs backward computation.
I0624 12:47:27.371970 17456 net.cpp:217] scale2_1 needs backward computation.
I0624 12:47:27.371973 17456 net.cpp:217] bn2_1 needs backward computation.
I0624 12:47:27.371974 17456 net.cpp:217] conv2_1 needs backward computation.
I0624 12:47:27.371976 17456 net.cpp:217] pool1 needs backward computation.
I0624 12:47:27.371979 17456 net.cpp:217] relu1_2 needs backward computation.
I0624 12:47:27.371981 17456 net.cpp:217] scale1_2 needs backward computation.
I0624 12:47:27.371984 17456 net.cpp:217] bn1_2 needs backward computation.
I0624 12:47:27.371985 17456 net.cpp:217] conv1_2 needs backward computation.
I0624 12:47:27.371989 17456 net.cpp:217] relu1_1 needs backward computation.
I0624 12:47:27.371990 17456 net.cpp:217] scale1_1 needs backward computation.
I0624 12:47:27.371992 17456 net.cpp:217] bn1_1 needs backward computation.
I0624 12:47:27.371994 17456 net.cpp:217] conv1_1 needs backward computation.
I0624 12:47:27.371997 17456 net.cpp:219] label_data_1_split does not need backward computation.
I0624 12:47:27.372000 17456 net.cpp:219] data does not need backward computation.
I0624 12:47:27.372002 17456 net.cpp:261] This network produces output accuracy
I0624 12:47:27.372004 17456 net.cpp:261] This network produces output loss
I0624 12:47:27.372037 17456 net.cpp:274] Network initialization done.
I0624 12:47:27.373527 17456 solver.cpp:181] Creating test net (#0) specified by net file: models/segnet/train_val.prototxt
I0624 12:47:27.373610 17456 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0624 12:47:27.373989 17456 net.cpp:49] Initializing net from parameters: 
name: "segnet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "DenseImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 224
    mean_value: 100
  }
  dense_image_data_param {
    source: "data/val.txt"
    batch_size: 1
    shuffle: true
    new_height: 224
    new_width: 310
    is_color: false
    root_folder: "data/raw/train/"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 14
    upsample_w: 14
  }
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2_D"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2_D"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1_D"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1_D"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 28
    upsample_w: 28
  }
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2_D"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2_D"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1_D"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1_D"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
    upsample_h: 56
    upsample_w: 56
  }
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn3_2_D"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2_D"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1_D"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1_D"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
    upsample_h: 112
    upsample_w: 112
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2_D"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2_D"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1_D"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1_D"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
    upsample_h: 224
    upsample_w: 224
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2_D"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2_D"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 0.1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2
    bias_term: true
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "accuracy"
}
I0624 12:47:27.374230 17456 layer_factory.hpp:77] Creating layer data
I0624 12:47:27.374243 17456 net.cpp:91] Creating Layer data
I0624 12:47:27.374248 17456 net.cpp:399] data -> data
I0624 12:47:27.374253 17456 net.cpp:399] data -> label
I0624 12:47:27.374264 17456 dense_image_data_layer.cpp:38] Opening file data/val.txt
I0624 12:47:27.374590 17456 dense_image_data_layer.cpp:48] Shuffling data
I0624 12:47:27.374661 17456 dense_image_data_layer.cpp:53] A total of 705 examples.
I0624 12:47:27.379185 17456 dense_image_data_layer.cpp:92] output data size: 1,1,224,224
I0624 12:47:27.380210 17456 net.cpp:141] Setting up data
I0624 12:47:27.380221 17456 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 12:47:27.380224 17456 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 12:47:27.380226 17456 net.cpp:156] Memory required for data: 401408
I0624 12:47:27.380230 17456 layer_factory.hpp:77] Creating layer label_data_1_split
I0624 12:47:27.380235 17456 net.cpp:91] Creating Layer label_data_1_split
I0624 12:47:27.380239 17456 net.cpp:425] label_data_1_split <- label
I0624 12:47:27.380242 17456 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0624 12:47:27.380249 17456 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0624 12:47:27.380357 17456 net.cpp:141] Setting up label_data_1_split
I0624 12:47:27.380363 17456 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 12:47:27.380367 17456 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 12:47:27.380368 17456 net.cpp:156] Memory required for data: 802816
I0624 12:47:27.380370 17456 layer_factory.hpp:77] Creating layer conv1_1
I0624 12:47:27.380378 17456 net.cpp:91] Creating Layer conv1_1
I0624 12:47:27.380380 17456 net.cpp:425] conv1_1 <- data
I0624 12:47:27.380383 17456 net.cpp:399] conv1_1 -> conv1_1
I0624 12:47:27.381769 17456 net.cpp:141] Setting up conv1_1
I0624 12:47:27.381780 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.381783 17456 net.cpp:156] Memory required for data: 7225344
I0624 12:47:27.381789 17456 layer_factory.hpp:77] Creating layer bn1_1
I0624 12:47:27.381795 17456 net.cpp:91] Creating Layer bn1_1
I0624 12:47:27.381798 17456 net.cpp:425] bn1_1 <- conv1_1
I0624 12:47:27.381801 17456 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0624 12:47:27.382611 17456 net.cpp:141] Setting up bn1_1
I0624 12:47:27.382622 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.382624 17456 net.cpp:156] Memory required for data: 13647872
I0624 12:47:27.382633 17456 layer_factory.hpp:77] Creating layer scale1_1
I0624 12:47:27.382642 17456 net.cpp:91] Creating Layer scale1_1
I0624 12:47:27.382644 17456 net.cpp:425] scale1_1 <- conv1_1
I0624 12:47:27.382648 17456 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0624 12:47:27.382688 17456 layer_factory.hpp:77] Creating layer scale1_1
I0624 12:47:27.382843 17456 net.cpp:141] Setting up scale1_1
I0624 12:47:27.382851 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.382853 17456 net.cpp:156] Memory required for data: 20070400
I0624 12:47:27.382871 17456 layer_factory.hpp:77] Creating layer relu1_1
I0624 12:47:27.382876 17456 net.cpp:91] Creating Layer relu1_1
I0624 12:47:27.382879 17456 net.cpp:425] relu1_1 <- conv1_1
I0624 12:47:27.382882 17456 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0624 12:47:27.383252 17456 net.cpp:141] Setting up relu1_1
I0624 12:47:27.383263 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.383266 17456 net.cpp:156] Memory required for data: 26492928
I0624 12:47:27.383270 17456 layer_factory.hpp:77] Creating layer conv1_2
I0624 12:47:27.383276 17456 net.cpp:91] Creating Layer conv1_2
I0624 12:47:27.383280 17456 net.cpp:425] conv1_2 <- conv1_1
I0624 12:47:27.383283 17456 net.cpp:399] conv1_2 -> conv1_2
I0624 12:47:27.384181 17456 net.cpp:141] Setting up conv1_2
I0624 12:47:27.384194 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.384196 17456 net.cpp:156] Memory required for data: 32915456
I0624 12:47:27.384202 17456 layer_factory.hpp:77] Creating layer bn1_2
I0624 12:47:27.384207 17456 net.cpp:91] Creating Layer bn1_2
I0624 12:47:27.384209 17456 net.cpp:425] bn1_2 <- conv1_2
I0624 12:47:27.384213 17456 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0624 12:47:27.384416 17456 net.cpp:141] Setting up bn1_2
I0624 12:47:27.384423 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.384426 17456 net.cpp:156] Memory required for data: 39337984
I0624 12:47:27.384434 17456 layer_factory.hpp:77] Creating layer scale1_2
I0624 12:47:27.384440 17456 net.cpp:91] Creating Layer scale1_2
I0624 12:47:27.384443 17456 net.cpp:425] scale1_2 <- conv1_2
I0624 12:47:27.384446 17456 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0624 12:47:27.384481 17456 layer_factory.hpp:77] Creating layer scale1_2
I0624 12:47:27.385221 17456 net.cpp:141] Setting up scale1_2
I0624 12:47:27.385231 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.385234 17456 net.cpp:156] Memory required for data: 45760512
I0624 12:47:27.385239 17456 layer_factory.hpp:77] Creating layer relu1_2
I0624 12:47:27.385244 17456 net.cpp:91] Creating Layer relu1_2
I0624 12:47:27.385246 17456 net.cpp:425] relu1_2 <- conv1_2
I0624 12:47:27.385251 17456 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0624 12:47:27.385531 17456 net.cpp:141] Setting up relu1_2
I0624 12:47:27.385541 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.385545 17456 net.cpp:156] Memory required for data: 52183040
I0624 12:47:27.385547 17456 layer_factory.hpp:77] Creating layer pool1
I0624 12:47:27.385550 17456 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 12:47:27.385555 17456 net.cpp:91] Creating Layer pool1
I0624 12:47:27.385557 17456 net.cpp:425] pool1 <- conv1_2
I0624 12:47:27.385561 17456 net.cpp:399] pool1 -> pool1
I0624 12:47:27.385566 17456 net.cpp:399] pool1 -> pool1_mask
I0624 12:47:27.385608 17456 net.cpp:141] Setting up pool1
I0624 12:47:27.385614 17456 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:47:27.385617 17456 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:47:27.385619 17456 net.cpp:156] Memory required for data: 55394304
I0624 12:47:27.385622 17456 layer_factory.hpp:77] Creating layer conv2_1
I0624 12:47:27.385628 17456 net.cpp:91] Creating Layer conv2_1
I0624 12:47:27.385630 17456 net.cpp:425] conv2_1 <- pool1
I0624 12:47:27.385634 17456 net.cpp:399] conv2_1 -> conv2_1
I0624 12:47:27.386696 17456 net.cpp:141] Setting up conv2_1
I0624 12:47:27.386708 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.386711 17456 net.cpp:156] Memory required for data: 58605568
I0624 12:47:27.386715 17456 layer_factory.hpp:77] Creating layer bn2_1
I0624 12:47:27.386720 17456 net.cpp:91] Creating Layer bn2_1
I0624 12:47:27.386724 17456 net.cpp:425] bn2_1 <- conv2_1
I0624 12:47:27.386729 17456 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0624 12:47:27.386914 17456 net.cpp:141] Setting up bn2_1
I0624 12:47:27.386921 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.386924 17456 net.cpp:156] Memory required for data: 61816832
I0624 12:47:27.386940 17456 layer_factory.hpp:77] Creating layer scale2_1
I0624 12:47:27.386945 17456 net.cpp:91] Creating Layer scale2_1
I0624 12:47:27.386948 17456 net.cpp:425] scale2_1 <- conv2_1
I0624 12:47:27.386951 17456 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0624 12:47:27.386992 17456 layer_factory.hpp:77] Creating layer scale2_1
I0624 12:47:27.387112 17456 net.cpp:141] Setting up scale2_1
I0624 12:47:27.387120 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.387121 17456 net.cpp:156] Memory required for data: 65028096
I0624 12:47:27.387130 17456 layer_factory.hpp:77] Creating layer relu2_1
I0624 12:47:27.387133 17456 net.cpp:91] Creating Layer relu2_1
I0624 12:47:27.387135 17456 net.cpp:425] relu2_1 <- conv2_1
I0624 12:47:27.387140 17456 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0624 12:47:27.387297 17456 net.cpp:141] Setting up relu2_1
I0624 12:47:27.387307 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.387310 17456 net.cpp:156] Memory required for data: 68239360
I0624 12:47:27.387312 17456 layer_factory.hpp:77] Creating layer conv2_2
I0624 12:47:27.387320 17456 net.cpp:91] Creating Layer conv2_2
I0624 12:47:27.387323 17456 net.cpp:425] conv2_2 <- conv2_1
I0624 12:47:27.387327 17456 net.cpp:399] conv2_2 -> conv2_2
I0624 12:47:27.388622 17456 net.cpp:141] Setting up conv2_2
I0624 12:47:27.388633 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.388636 17456 net.cpp:156] Memory required for data: 71450624
I0624 12:47:27.388640 17456 layer_factory.hpp:77] Creating layer bn2_2
I0624 12:47:27.388648 17456 net.cpp:91] Creating Layer bn2_2
I0624 12:47:27.388650 17456 net.cpp:425] bn2_2 <- conv2_2
I0624 12:47:27.388654 17456 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0624 12:47:27.388852 17456 net.cpp:141] Setting up bn2_2
I0624 12:47:27.388859 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.388861 17456 net.cpp:156] Memory required for data: 74661888
I0624 12:47:27.388867 17456 layer_factory.hpp:77] Creating layer scale2_2
I0624 12:47:27.388872 17456 net.cpp:91] Creating Layer scale2_2
I0624 12:47:27.388875 17456 net.cpp:425] scale2_2 <- conv2_2
I0624 12:47:27.388878 17456 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0624 12:47:27.388916 17456 layer_factory.hpp:77] Creating layer scale2_2
I0624 12:47:27.389037 17456 net.cpp:141] Setting up scale2_2
I0624 12:47:27.389045 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.389046 17456 net.cpp:156] Memory required for data: 77873152
I0624 12:47:27.389051 17456 layer_factory.hpp:77] Creating layer relu2_2
I0624 12:47:27.389055 17456 net.cpp:91] Creating Layer relu2_2
I0624 12:47:27.389057 17456 net.cpp:425] relu2_2 <- conv2_2
I0624 12:47:27.389060 17456 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0624 12:47:27.389341 17456 net.cpp:141] Setting up relu2_2
I0624 12:47:27.389351 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.389354 17456 net.cpp:156] Memory required for data: 81084416
I0624 12:47:27.389359 17456 layer_factory.hpp:77] Creating layer pool2
I0624 12:47:27.389361 17456 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 12:47:27.389366 17456 net.cpp:91] Creating Layer pool2
I0624 12:47:27.389369 17456 net.cpp:425] pool2 <- conv2_2
I0624 12:47:27.389372 17456 net.cpp:399] pool2 -> pool2
I0624 12:47:27.389377 17456 net.cpp:399] pool2 -> pool2_mask
I0624 12:47:27.389423 17456 net.cpp:141] Setting up pool2
I0624 12:47:27.389430 17456 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:47:27.389433 17456 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:47:27.389436 17456 net.cpp:156] Memory required for data: 82690048
I0624 12:47:27.389437 17456 layer_factory.hpp:77] Creating layer conv3_1
I0624 12:47:27.389444 17456 net.cpp:91] Creating Layer conv3_1
I0624 12:47:27.389447 17456 net.cpp:425] conv3_1 <- pool2
I0624 12:47:27.389451 17456 net.cpp:399] conv3_1 -> conv3_1
I0624 12:47:27.390722 17456 net.cpp:141] Setting up conv3_1
I0624 12:47:27.390733 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.390745 17456 net.cpp:156] Memory required for data: 84295680
I0624 12:47:27.390751 17456 layer_factory.hpp:77] Creating layer bn3_1
I0624 12:47:27.390756 17456 net.cpp:91] Creating Layer bn3_1
I0624 12:47:27.390759 17456 net.cpp:425] bn3_1 <- conv3_1
I0624 12:47:27.390764 17456 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0624 12:47:27.390952 17456 net.cpp:141] Setting up bn3_1
I0624 12:47:27.390959 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.390961 17456 net.cpp:156] Memory required for data: 85901312
I0624 12:47:27.390967 17456 layer_factory.hpp:77] Creating layer scale3_1
I0624 12:47:27.390974 17456 net.cpp:91] Creating Layer scale3_1
I0624 12:47:27.390975 17456 net.cpp:425] scale3_1 <- conv3_1
I0624 12:47:27.390979 17456 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0624 12:47:27.391016 17456 layer_factory.hpp:77] Creating layer scale3_1
I0624 12:47:27.391119 17456 net.cpp:141] Setting up scale3_1
I0624 12:47:27.391124 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.391127 17456 net.cpp:156] Memory required for data: 87506944
I0624 12:47:27.391131 17456 layer_factory.hpp:77] Creating layer relu3_1
I0624 12:47:27.391135 17456 net.cpp:91] Creating Layer relu3_1
I0624 12:47:27.391137 17456 net.cpp:425] relu3_1 <- conv3_1
I0624 12:47:27.391141 17456 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0624 12:47:27.391427 17456 net.cpp:141] Setting up relu3_1
I0624 12:47:27.391438 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.391440 17456 net.cpp:156] Memory required for data: 89112576
I0624 12:47:27.391443 17456 layer_factory.hpp:77] Creating layer conv3_2
I0624 12:47:27.391450 17456 net.cpp:91] Creating Layer conv3_2
I0624 12:47:27.391453 17456 net.cpp:425] conv3_2 <- conv3_1
I0624 12:47:27.391463 17456 net.cpp:399] conv3_2 -> conv3_2
I0624 12:47:27.393842 17456 net.cpp:141] Setting up conv3_2
I0624 12:47:27.393854 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.393857 17456 net.cpp:156] Memory required for data: 90718208
I0624 12:47:27.393862 17456 layer_factory.hpp:77] Creating layer bn3_2
I0624 12:47:27.393867 17456 net.cpp:91] Creating Layer bn3_2
I0624 12:47:27.393869 17456 net.cpp:425] bn3_2 <- conv3_2
I0624 12:47:27.393873 17456 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0624 12:47:27.394057 17456 net.cpp:141] Setting up bn3_2
I0624 12:47:27.394063 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.394065 17456 net.cpp:156] Memory required for data: 92323840
I0624 12:47:27.394075 17456 layer_factory.hpp:77] Creating layer scale3_2
I0624 12:47:27.394081 17456 net.cpp:91] Creating Layer scale3_2
I0624 12:47:27.394083 17456 net.cpp:425] scale3_2 <- conv3_2
I0624 12:47:27.394088 17456 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0624 12:47:27.394124 17456 layer_factory.hpp:77] Creating layer scale3_2
I0624 12:47:27.394243 17456 net.cpp:141] Setting up scale3_2
I0624 12:47:27.394249 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.394251 17456 net.cpp:156] Memory required for data: 93929472
I0624 12:47:27.394256 17456 layer_factory.hpp:77] Creating layer relu3_2
I0624 12:47:27.394260 17456 net.cpp:91] Creating Layer relu3_2
I0624 12:47:27.394263 17456 net.cpp:425] relu3_2 <- conv3_2
I0624 12:47:27.394266 17456 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0624 12:47:27.394417 17456 net.cpp:141] Setting up relu3_2
I0624 12:47:27.394424 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.394428 17456 net.cpp:156] Memory required for data: 95535104
I0624 12:47:27.394429 17456 layer_factory.hpp:77] Creating layer pool3
I0624 12:47:27.394433 17456 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 12:47:27.394438 17456 net.cpp:91] Creating Layer pool3
I0624 12:47:27.394439 17456 net.cpp:425] pool3 <- conv3_2
I0624 12:47:27.394443 17456 net.cpp:399] pool3 -> pool3
I0624 12:47:27.394448 17456 net.cpp:399] pool3 -> pool3_mask
I0624 12:47:27.394490 17456 net.cpp:141] Setting up pool3
I0624 12:47:27.394495 17456 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:47:27.394508 17456 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:47:27.394510 17456 net.cpp:156] Memory required for data: 96337920
I0624 12:47:27.394512 17456 layer_factory.hpp:77] Creating layer conv4_1
I0624 12:47:27.394520 17456 net.cpp:91] Creating Layer conv4_1
I0624 12:47:27.394522 17456 net.cpp:425] conv4_1 <- pool3
I0624 12:47:27.394527 17456 net.cpp:399] conv4_1 -> conv4_1
I0624 12:47:27.397879 17456 net.cpp:141] Setting up conv4_1
I0624 12:47:27.397892 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.397896 17456 net.cpp:156] Memory required for data: 97140736
I0624 12:47:27.397899 17456 layer_factory.hpp:77] Creating layer bn4_1
I0624 12:47:27.397907 17456 net.cpp:91] Creating Layer bn4_1
I0624 12:47:27.397909 17456 net.cpp:425] bn4_1 <- conv4_1
I0624 12:47:27.397914 17456 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0624 12:47:27.398114 17456 net.cpp:141] Setting up bn4_1
I0624 12:47:27.398121 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.398124 17456 net.cpp:156] Memory required for data: 97943552
I0624 12:47:27.398130 17456 layer_factory.hpp:77] Creating layer scale4_1
I0624 12:47:27.398136 17456 net.cpp:91] Creating Layer scale4_1
I0624 12:47:27.398138 17456 net.cpp:425] scale4_1 <- conv4_1
I0624 12:47:27.398144 17456 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0624 12:47:27.398180 17456 layer_factory.hpp:77] Creating layer scale4_1
I0624 12:47:27.398293 17456 net.cpp:141] Setting up scale4_1
I0624 12:47:27.398300 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.398303 17456 net.cpp:156] Memory required for data: 98746368
I0624 12:47:27.398308 17456 layer_factory.hpp:77] Creating layer relu4_1
I0624 12:47:27.398314 17456 net.cpp:91] Creating Layer relu4_1
I0624 12:47:27.398318 17456 net.cpp:425] relu4_1 <- conv4_1
I0624 12:47:27.398321 17456 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0624 12:47:27.398610 17456 net.cpp:141] Setting up relu4_1
I0624 12:47:27.398622 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.398624 17456 net.cpp:156] Memory required for data: 99549184
I0624 12:47:27.398627 17456 layer_factory.hpp:77] Creating layer conv4_2
I0624 12:47:27.398636 17456 net.cpp:91] Creating Layer conv4_2
I0624 12:47:27.398639 17456 net.cpp:425] conv4_2 <- conv4_1
I0624 12:47:27.398644 17456 net.cpp:399] conv4_2 -> conv4_2
I0624 12:47:27.404176 17456 net.cpp:141] Setting up conv4_2
I0624 12:47:27.404191 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.404194 17456 net.cpp:156] Memory required for data: 100352000
I0624 12:47:27.404199 17456 layer_factory.hpp:77] Creating layer bn4_2
I0624 12:47:27.404206 17456 net.cpp:91] Creating Layer bn4_2
I0624 12:47:27.404208 17456 net.cpp:425] bn4_2 <- conv4_2
I0624 12:47:27.404213 17456 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0624 12:47:27.404418 17456 net.cpp:141] Setting up bn4_2
I0624 12:47:27.404425 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.404428 17456 net.cpp:156] Memory required for data: 101154816
I0624 12:47:27.404433 17456 layer_factory.hpp:77] Creating layer scale4_2
I0624 12:47:27.404439 17456 net.cpp:91] Creating Layer scale4_2
I0624 12:47:27.404443 17456 net.cpp:425] scale4_2 <- conv4_2
I0624 12:47:27.404446 17456 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0624 12:47:27.404486 17456 layer_factory.hpp:77] Creating layer scale4_2
I0624 12:47:27.404603 17456 net.cpp:141] Setting up scale4_2
I0624 12:47:27.404610 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.404613 17456 net.cpp:156] Memory required for data: 101957632
I0624 12:47:27.404618 17456 layer_factory.hpp:77] Creating layer relu4_2
I0624 12:47:27.404621 17456 net.cpp:91] Creating Layer relu4_2
I0624 12:47:27.404626 17456 net.cpp:425] relu4_2 <- conv4_2
I0624 12:47:27.404629 17456 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0624 12:47:27.404917 17456 net.cpp:141] Setting up relu4_2
I0624 12:47:27.404928 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.404932 17456 net.cpp:156] Memory required for data: 102760448
I0624 12:47:27.404933 17456 layer_factory.hpp:77] Creating layer pool4
I0624 12:47:27.404947 17456 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 12:47:27.404953 17456 net.cpp:91] Creating Layer pool4
I0624 12:47:27.404955 17456 net.cpp:425] pool4 <- conv4_2
I0624 12:47:27.404960 17456 net.cpp:399] pool4 -> pool4
I0624 12:47:27.404965 17456 net.cpp:399] pool4 -> pool4_mask
I0624 12:47:27.405014 17456 net.cpp:141] Setting up pool4
I0624 12:47:27.405019 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.405022 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.405025 17456 net.cpp:156] Memory required for data: 103161856
I0624 12:47:27.405026 17456 layer_factory.hpp:77] Creating layer conv5_1
I0624 12:47:27.405036 17456 net.cpp:91] Creating Layer conv5_1
I0624 12:47:27.405038 17456 net.cpp:425] conv5_1 <- pool4
I0624 12:47:27.405042 17456 net.cpp:399] conv5_1 -> conv5_1
I0624 12:47:27.410632 17456 net.cpp:141] Setting up conv5_1
I0624 12:47:27.410645 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.410647 17456 net.cpp:156] Memory required for data: 103362560
I0624 12:47:27.410652 17456 layer_factory.hpp:77] Creating layer bn5_1
I0624 12:47:27.410660 17456 net.cpp:91] Creating Layer bn5_1
I0624 12:47:27.410662 17456 net.cpp:425] bn5_1 <- conv5_1
I0624 12:47:27.410667 17456 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0624 12:47:27.410862 17456 net.cpp:141] Setting up bn5_1
I0624 12:47:27.410869 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.410871 17456 net.cpp:156] Memory required for data: 103563264
I0624 12:47:27.410876 17456 layer_factory.hpp:77] Creating layer scale5_1
I0624 12:47:27.410882 17456 net.cpp:91] Creating Layer scale5_1
I0624 12:47:27.410886 17456 net.cpp:425] scale5_1 <- conv5_1
I0624 12:47:27.410890 17456 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0624 12:47:27.410929 17456 layer_factory.hpp:77] Creating layer scale5_1
I0624 12:47:27.411039 17456 net.cpp:141] Setting up scale5_1
I0624 12:47:27.411046 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.411048 17456 net.cpp:156] Memory required for data: 103763968
I0624 12:47:27.411052 17456 layer_factory.hpp:77] Creating layer relu5_1
I0624 12:47:27.411057 17456 net.cpp:91] Creating Layer relu5_1
I0624 12:47:27.411059 17456 net.cpp:425] relu5_1 <- conv5_1
I0624 12:47:27.411062 17456 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0624 12:47:27.411228 17456 net.cpp:141] Setting up relu5_1
I0624 12:47:27.411238 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.411240 17456 net.cpp:156] Memory required for data: 103964672
I0624 12:47:27.411243 17456 layer_factory.hpp:77] Creating layer conv5_2
I0624 12:47:27.411252 17456 net.cpp:91] Creating Layer conv5_2
I0624 12:47:27.411254 17456 net.cpp:425] conv5_2 <- conv5_1
I0624 12:47:27.411259 17456 net.cpp:399] conv5_2 -> conv5_2
I0624 12:47:27.416807 17456 net.cpp:141] Setting up conv5_2
I0624 12:47:27.416821 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.416823 17456 net.cpp:156] Memory required for data: 104165376
I0624 12:47:27.416827 17456 layer_factory.hpp:77] Creating layer bn5_2
I0624 12:47:27.416834 17456 net.cpp:91] Creating Layer bn5_2
I0624 12:47:27.416838 17456 net.cpp:425] bn5_2 <- conv5_2
I0624 12:47:27.416842 17456 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0624 12:47:27.417040 17456 net.cpp:141] Setting up bn5_2
I0624 12:47:27.417047 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.417052 17456 net.cpp:156] Memory required for data: 104366080
I0624 12:47:27.417058 17456 layer_factory.hpp:77] Creating layer scale5_2
I0624 12:47:27.417064 17456 net.cpp:91] Creating Layer scale5_2
I0624 12:47:27.417068 17456 net.cpp:425] scale5_2 <- conv5_2
I0624 12:47:27.417071 17456 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0624 12:47:27.417119 17456 layer_factory.hpp:77] Creating layer scale5_2
I0624 12:47:27.417243 17456 net.cpp:141] Setting up scale5_2
I0624 12:47:27.417251 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.417253 17456 net.cpp:156] Memory required for data: 104566784
I0624 12:47:27.417268 17456 layer_factory.hpp:77] Creating layer relu5_2
I0624 12:47:27.417276 17456 net.cpp:91] Creating Layer relu5_2
I0624 12:47:27.417279 17456 net.cpp:425] relu5_2 <- conv5_2
I0624 12:47:27.417282 17456 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0624 12:47:27.417593 17456 net.cpp:141] Setting up relu5_2
I0624 12:47:27.417604 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.417608 17456 net.cpp:156] Memory required for data: 104767488
I0624 12:47:27.417609 17456 layer_factory.hpp:77] Creating layer pool5
I0624 12:47:27.417613 17456 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 12:47:27.417620 17456 net.cpp:91] Creating Layer pool5
I0624 12:47:27.417623 17456 net.cpp:425] pool5 <- conv5_2
I0624 12:47:27.417628 17456 net.cpp:399] pool5 -> pool5
I0624 12:47:27.417634 17456 net.cpp:399] pool5 -> pool5_mask
I0624 12:47:27.417685 17456 net.cpp:141] Setting up pool5
I0624 12:47:27.417690 17456 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 12:47:27.417692 17456 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 12:47:27.417695 17456 net.cpp:156] Memory required for data: 104867840
I0624 12:47:27.417696 17456 layer_factory.hpp:77] Creating layer upsample5
I0624 12:47:27.417702 17456 net.cpp:91] Creating Layer upsample5
I0624 12:47:27.417706 17456 net.cpp:425] upsample5 <- pool5
I0624 12:47:27.417708 17456 net.cpp:425] upsample5 <- pool5_mask
I0624 12:47:27.417711 17456 net.cpp:399] upsample5 -> pool5_D
I0624 12:47:27.417737 17456 net.cpp:141] Setting up upsample5
I0624 12:47:27.417742 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.417743 17456 net.cpp:156] Memory required for data: 105068544
I0624 12:47:27.417745 17456 layer_factory.hpp:77] Creating layer conv5_2_D
I0624 12:47:27.417754 17456 net.cpp:91] Creating Layer conv5_2_D
I0624 12:47:27.417757 17456 net.cpp:425] conv5_2_D <- pool5_D
I0624 12:47:27.417760 17456 net.cpp:399] conv5_2_D -> conv5_2_D
I0624 12:47:27.423154 17456 net.cpp:141] Setting up conv5_2_D
I0624 12:47:27.423167 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.423171 17456 net.cpp:156] Memory required for data: 105269248
I0624 12:47:27.423176 17456 layer_factory.hpp:77] Creating layer bn5_2_D
I0624 12:47:27.423182 17456 net.cpp:91] Creating Layer bn5_2_D
I0624 12:47:27.423185 17456 net.cpp:425] bn5_2_D <- conv5_2_D
I0624 12:47:27.423192 17456 net.cpp:386] bn5_2_D -> conv5_2_D (in-place)
I0624 12:47:27.423390 17456 net.cpp:141] Setting up bn5_2_D
I0624 12:47:27.423398 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.423401 17456 net.cpp:156] Memory required for data: 105469952
I0624 12:47:27.423406 17456 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 12:47:27.423413 17456 net.cpp:91] Creating Layer scale5_2_D
I0624 12:47:27.423416 17456 net.cpp:425] scale5_2_D <- conv5_2_D
I0624 12:47:27.423419 17456 net.cpp:386] scale5_2_D -> conv5_2_D (in-place)
I0624 12:47:27.423460 17456 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 12:47:27.423570 17456 net.cpp:141] Setting up scale5_2_D
I0624 12:47:27.423578 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.423580 17456 net.cpp:156] Memory required for data: 105670656
I0624 12:47:27.423593 17456 layer_factory.hpp:77] Creating layer relu5_2_D
I0624 12:47:27.423599 17456 net.cpp:91] Creating Layer relu5_2_D
I0624 12:47:27.423601 17456 net.cpp:425] relu5_2_D <- conv5_2_D
I0624 12:47:27.423606 17456 net.cpp:386] relu5_2_D -> conv5_2_D (in-place)
I0624 12:47:27.423899 17456 net.cpp:141] Setting up relu5_2_D
I0624 12:47:27.423910 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.423913 17456 net.cpp:156] Memory required for data: 105871360
I0624 12:47:27.423915 17456 layer_factory.hpp:77] Creating layer conv5_1_D
I0624 12:47:27.423924 17456 net.cpp:91] Creating Layer conv5_1_D
I0624 12:47:27.423928 17456 net.cpp:425] conv5_1_D <- conv5_2_D
I0624 12:47:27.423933 17456 net.cpp:399] conv5_1_D -> conv5_1_D
I0624 12:47:27.429699 17456 net.cpp:141] Setting up conv5_1_D
I0624 12:47:27.429726 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.429729 17456 net.cpp:156] Memory required for data: 106072064
I0624 12:47:27.429735 17456 layer_factory.hpp:77] Creating layer bn5_1_D
I0624 12:47:27.429744 17456 net.cpp:91] Creating Layer bn5_1_D
I0624 12:47:27.429746 17456 net.cpp:425] bn5_1_D <- conv5_1_D
I0624 12:47:27.429752 17456 net.cpp:386] bn5_1_D -> conv5_1_D (in-place)
I0624 12:47:27.430006 17456 net.cpp:141] Setting up bn5_1_D
I0624 12:47:27.430014 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.430017 17456 net.cpp:156] Memory required for data: 106272768
I0624 12:47:27.430023 17456 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 12:47:27.430030 17456 net.cpp:91] Creating Layer scale5_1_D
I0624 12:47:27.430033 17456 net.cpp:425] scale5_1_D <- conv5_1_D
I0624 12:47:27.430037 17456 net.cpp:386] scale5_1_D -> conv5_1_D (in-place)
I0624 12:47:27.430083 17456 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 12:47:27.430196 17456 net.cpp:141] Setting up scale5_1_D
I0624 12:47:27.430203 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.430207 17456 net.cpp:156] Memory required for data: 106473472
I0624 12:47:27.430210 17456 layer_factory.hpp:77] Creating layer relu5_1_D
I0624 12:47:27.430214 17456 net.cpp:91] Creating Layer relu5_1_D
I0624 12:47:27.430217 17456 net.cpp:425] relu5_1_D <- conv5_1_D
I0624 12:47:27.430222 17456 net.cpp:386] relu5_1_D -> conv5_1_D (in-place)
I0624 12:47:27.430379 17456 net.cpp:141] Setting up relu5_1_D
I0624 12:47:27.430388 17456 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 12:47:27.430390 17456 net.cpp:156] Memory required for data: 106674176
I0624 12:47:27.430393 17456 layer_factory.hpp:77] Creating layer upsample4
I0624 12:47:27.430398 17456 net.cpp:91] Creating Layer upsample4
I0624 12:47:27.430402 17456 net.cpp:425] upsample4 <- conv5_1_D
I0624 12:47:27.430405 17456 net.cpp:425] upsample4 <- pool4_mask
I0624 12:47:27.430410 17456 net.cpp:399] upsample4 -> pool4_D
I0624 12:47:27.430444 17456 net.cpp:141] Setting up upsample4
I0624 12:47:27.430450 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.430452 17456 net.cpp:156] Memory required for data: 107476992
I0624 12:47:27.430454 17456 layer_factory.hpp:77] Creating layer conv4_2_D
I0624 12:47:27.430465 17456 net.cpp:91] Creating Layer conv4_2_D
I0624 12:47:27.430469 17456 net.cpp:425] conv4_2_D <- pool4_D
I0624 12:47:27.430472 17456 net.cpp:399] conv4_2_D -> conv4_2_D
I0624 12:47:27.435992 17456 net.cpp:141] Setting up conv4_2_D
I0624 12:47:27.436007 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.436009 17456 net.cpp:156] Memory required for data: 108279808
I0624 12:47:27.436013 17456 layer_factory.hpp:77] Creating layer bn4_2_D
I0624 12:47:27.436019 17456 net.cpp:91] Creating Layer bn4_2_D
I0624 12:47:27.436022 17456 net.cpp:425] bn4_2_D <- conv4_2_D
I0624 12:47:27.436028 17456 net.cpp:386] bn4_2_D -> conv4_2_D (in-place)
I0624 12:47:27.436240 17456 net.cpp:141] Setting up bn4_2_D
I0624 12:47:27.436247 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.436249 17456 net.cpp:156] Memory required for data: 109082624
I0624 12:47:27.436255 17456 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 12:47:27.436261 17456 net.cpp:91] Creating Layer scale4_2_D
I0624 12:47:27.436264 17456 net.cpp:425] scale4_2_D <- conv4_2_D
I0624 12:47:27.436267 17456 net.cpp:386] scale4_2_D -> conv4_2_D (in-place)
I0624 12:47:27.436309 17456 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 12:47:27.436435 17456 net.cpp:141] Setting up scale4_2_D
I0624 12:47:27.436442 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.436444 17456 net.cpp:156] Memory required for data: 109885440
I0624 12:47:27.436449 17456 layer_factory.hpp:77] Creating layer relu4_2_D
I0624 12:47:27.436455 17456 net.cpp:91] Creating Layer relu4_2_D
I0624 12:47:27.436457 17456 net.cpp:425] relu4_2_D <- conv4_2_D
I0624 12:47:27.436460 17456 net.cpp:386] relu4_2_D -> conv4_2_D (in-place)
I0624 12:47:27.436765 17456 net.cpp:141] Setting up relu4_2_D
I0624 12:47:27.436787 17456 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 12:47:27.436790 17456 net.cpp:156] Memory required for data: 110688256
I0624 12:47:27.436794 17456 layer_factory.hpp:77] Creating layer conv4_1_D
I0624 12:47:27.436802 17456 net.cpp:91] Creating Layer conv4_1_D
I0624 12:47:27.436805 17456 net.cpp:425] conv4_1_D <- conv4_2_D
I0624 12:47:27.436810 17456 net.cpp:399] conv4_1_D -> conv4_1_D
I0624 12:47:27.440042 17456 net.cpp:141] Setting up conv4_1_D
I0624 12:47:27.440054 17456 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:47:27.440057 17456 net.cpp:156] Memory required for data: 111089664
I0624 12:47:27.440062 17456 layer_factory.hpp:77] Creating layer bn4_1_D
I0624 12:47:27.440069 17456 net.cpp:91] Creating Layer bn4_1_D
I0624 12:47:27.440073 17456 net.cpp:425] bn4_1_D <- conv4_1_D
I0624 12:47:27.440075 17456 net.cpp:386] bn4_1_D -> conv4_1_D (in-place)
I0624 12:47:27.440281 17456 net.cpp:141] Setting up bn4_1_D
I0624 12:47:27.440289 17456 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:47:27.440290 17456 net.cpp:156] Memory required for data: 111491072
I0624 12:47:27.440296 17456 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 12:47:27.440304 17456 net.cpp:91] Creating Layer scale4_1_D
I0624 12:47:27.440306 17456 net.cpp:425] scale4_1_D <- conv4_1_D
I0624 12:47:27.440310 17456 net.cpp:386] scale4_1_D -> conv4_1_D (in-place)
I0624 12:47:27.440369 17456 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 12:47:27.440500 17456 net.cpp:141] Setting up scale4_1_D
I0624 12:47:27.440507 17456 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:47:27.440510 17456 net.cpp:156] Memory required for data: 111892480
I0624 12:47:27.440515 17456 layer_factory.hpp:77] Creating layer relu4_1_D
I0624 12:47:27.440526 17456 net.cpp:91] Creating Layer relu4_1_D
I0624 12:47:27.440528 17456 net.cpp:425] relu4_1_D <- conv4_1_D
I0624 12:47:27.440532 17456 net.cpp:386] relu4_1_D -> conv4_1_D (in-place)
I0624 12:47:27.440832 17456 net.cpp:141] Setting up relu4_1_D
I0624 12:47:27.440843 17456 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 12:47:27.440846 17456 net.cpp:156] Memory required for data: 112293888
I0624 12:47:27.440850 17456 layer_factory.hpp:77] Creating layer upsample3
I0624 12:47:27.440855 17456 net.cpp:91] Creating Layer upsample3
I0624 12:47:27.440858 17456 net.cpp:425] upsample3 <- conv4_1_D
I0624 12:47:27.440862 17456 net.cpp:425] upsample3 <- pool3_mask
I0624 12:47:27.440867 17456 net.cpp:399] upsample3 -> pool3_D
I0624 12:47:27.440901 17456 net.cpp:141] Setting up upsample3
I0624 12:47:27.440906 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.440907 17456 net.cpp:156] Memory required for data: 113899520
I0624 12:47:27.440910 17456 layer_factory.hpp:77] Creating layer conv3_2_D
I0624 12:47:27.440919 17456 net.cpp:91] Creating Layer conv3_2_D
I0624 12:47:27.440922 17456 net.cpp:425] conv3_2_D <- pool3_D
I0624 12:47:27.440927 17456 net.cpp:399] conv3_2_D -> conv3_2_D
I0624 12:47:27.443460 17456 net.cpp:141] Setting up conv3_2_D
I0624 12:47:27.443473 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.443476 17456 net.cpp:156] Memory required for data: 115505152
I0624 12:47:27.443481 17456 layer_factory.hpp:77] Creating layer bn3_2_D
I0624 12:47:27.443490 17456 net.cpp:91] Creating Layer bn3_2_D
I0624 12:47:27.443495 17456 net.cpp:425] bn3_2_D <- conv3_2_D
I0624 12:47:27.443498 17456 net.cpp:386] bn3_2_D -> conv3_2_D (in-place)
I0624 12:47:27.443754 17456 net.cpp:141] Setting up bn3_2_D
I0624 12:47:27.443763 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.443765 17456 net.cpp:156] Memory required for data: 117110784
I0624 12:47:27.443771 17456 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 12:47:27.443778 17456 net.cpp:91] Creating Layer scale3_2_D
I0624 12:47:27.443779 17456 net.cpp:425] scale3_2_D <- conv3_2_D
I0624 12:47:27.443784 17456 net.cpp:386] scale3_2_D -> conv3_2_D (in-place)
I0624 12:47:27.443828 17456 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 12:47:27.443950 17456 net.cpp:141] Setting up scale3_2_D
I0624 12:47:27.443967 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.443969 17456 net.cpp:156] Memory required for data: 118716416
I0624 12:47:27.443974 17456 layer_factory.hpp:77] Creating layer relu3_2_D
I0624 12:47:27.443979 17456 net.cpp:91] Creating Layer relu3_2_D
I0624 12:47:27.443980 17456 net.cpp:425] relu3_2_D <- conv3_2_D
I0624 12:47:27.443984 17456 net.cpp:386] relu3_2_D -> conv3_2_D (in-place)
I0624 12:47:27.444151 17456 net.cpp:141] Setting up relu3_2_D
I0624 12:47:27.444160 17456 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 12:47:27.444164 17456 net.cpp:156] Memory required for data: 120322048
I0624 12:47:27.444165 17456 layer_factory.hpp:77] Creating layer conv3_1_D
I0624 12:47:27.444174 17456 net.cpp:91] Creating Layer conv3_1_D
I0624 12:47:27.444176 17456 net.cpp:425] conv3_1_D <- conv3_2_D
I0624 12:47:27.444181 17456 net.cpp:399] conv3_1_D -> conv3_1_D
I0624 12:47:27.445683 17456 net.cpp:141] Setting up conv3_1_D
I0624 12:47:27.445696 17456 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:47:27.445699 17456 net.cpp:156] Memory required for data: 121124864
I0624 12:47:27.445703 17456 layer_factory.hpp:77] Creating layer bn3_1_D
I0624 12:47:27.445710 17456 net.cpp:91] Creating Layer bn3_1_D
I0624 12:47:27.445713 17456 net.cpp:425] bn3_1_D <- conv3_1_D
I0624 12:47:27.445718 17456 net.cpp:386] bn3_1_D -> conv3_1_D (in-place)
I0624 12:47:27.445940 17456 net.cpp:141] Setting up bn3_1_D
I0624 12:47:27.445946 17456 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:47:27.445950 17456 net.cpp:156] Memory required for data: 121927680
I0624 12:47:27.445955 17456 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 12:47:27.445960 17456 net.cpp:91] Creating Layer scale3_1_D
I0624 12:47:27.445963 17456 net.cpp:425] scale3_1_D <- conv3_1_D
I0624 12:47:27.445966 17456 net.cpp:386] scale3_1_D -> conv3_1_D (in-place)
I0624 12:47:27.446012 17456 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 12:47:27.446143 17456 net.cpp:141] Setting up scale3_1_D
I0624 12:47:27.446151 17456 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:47:27.446152 17456 net.cpp:156] Memory required for data: 122730496
I0624 12:47:27.446156 17456 layer_factory.hpp:77] Creating layer relu3_1_D
I0624 12:47:27.446161 17456 net.cpp:91] Creating Layer relu3_1_D
I0624 12:47:27.446163 17456 net.cpp:425] relu3_1_D <- conv3_1_D
I0624 12:47:27.446166 17456 net.cpp:386] relu3_1_D -> conv3_1_D (in-place)
I0624 12:47:27.446475 17456 net.cpp:141] Setting up relu3_1_D
I0624 12:47:27.446486 17456 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 12:47:27.446488 17456 net.cpp:156] Memory required for data: 123533312
I0624 12:47:27.446491 17456 layer_factory.hpp:77] Creating layer upsample2
I0624 12:47:27.446496 17456 net.cpp:91] Creating Layer upsample2
I0624 12:47:27.446499 17456 net.cpp:425] upsample2 <- conv3_1_D
I0624 12:47:27.446502 17456 net.cpp:425] upsample2 <- pool2_mask
I0624 12:47:27.446506 17456 net.cpp:399] upsample2 -> pool2_D
I0624 12:47:27.446542 17456 net.cpp:141] Setting up upsample2
I0624 12:47:27.446547 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.446548 17456 net.cpp:156] Memory required for data: 126744576
I0624 12:47:27.446550 17456 layer_factory.hpp:77] Creating layer conv2_2_D
I0624 12:47:27.446558 17456 net.cpp:91] Creating Layer conv2_2_D
I0624 12:47:27.446562 17456 net.cpp:425] conv2_2_D <- pool2_D
I0624 12:47:27.446566 17456 net.cpp:399] conv2_2_D -> conv2_2_D
I0624 12:47:27.447732 17456 net.cpp:141] Setting up conv2_2_D
I0624 12:47:27.447744 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.447747 17456 net.cpp:156] Memory required for data: 129955840
I0624 12:47:27.447751 17456 layer_factory.hpp:77] Creating layer bn2_2_D
I0624 12:47:27.447758 17456 net.cpp:91] Creating Layer bn2_2_D
I0624 12:47:27.447762 17456 net.cpp:425] bn2_2_D <- conv2_2_D
I0624 12:47:27.447767 17456 net.cpp:386] bn2_2_D -> conv2_2_D (in-place)
I0624 12:47:27.448585 17456 net.cpp:141] Setting up bn2_2_D
I0624 12:47:27.448596 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.448608 17456 net.cpp:156] Memory required for data: 133167104
I0624 12:47:27.448616 17456 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 12:47:27.448621 17456 net.cpp:91] Creating Layer scale2_2_D
I0624 12:47:27.448624 17456 net.cpp:425] scale2_2_D <- conv2_2_D
I0624 12:47:27.448628 17456 net.cpp:386] scale2_2_D -> conv2_2_D (in-place)
I0624 12:47:27.448680 17456 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 12:47:27.448815 17456 net.cpp:141] Setting up scale2_2_D
I0624 12:47:27.448822 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.448825 17456 net.cpp:156] Memory required for data: 136378368
I0624 12:47:27.448830 17456 layer_factory.hpp:77] Creating layer relu2_2_D
I0624 12:47:27.448835 17456 net.cpp:91] Creating Layer relu2_2_D
I0624 12:47:27.448838 17456 net.cpp:425] relu2_2_D <- conv2_2_D
I0624 12:47:27.448842 17456 net.cpp:386] relu2_2_D -> conv2_2_D (in-place)
I0624 12:47:27.449163 17456 net.cpp:141] Setting up relu2_2_D
I0624 12:47:27.449174 17456 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 12:47:27.449177 17456 net.cpp:156] Memory required for data: 139589632
I0624 12:47:27.449180 17456 layer_factory.hpp:77] Creating layer conv2_1_D
I0624 12:47:27.449188 17456 net.cpp:91] Creating Layer conv2_1_D
I0624 12:47:27.449192 17456 net.cpp:425] conv2_1_D <- conv2_2_D
I0624 12:47:27.449198 17456 net.cpp:399] conv2_1_D -> conv2_1_D
I0624 12:47:27.450278 17456 net.cpp:141] Setting up conv2_1_D
I0624 12:47:27.450290 17456 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:47:27.450292 17456 net.cpp:156] Memory required for data: 141195264
I0624 12:47:27.450297 17456 layer_factory.hpp:77] Creating layer bn2_1_D
I0624 12:47:27.450304 17456 net.cpp:91] Creating Layer bn2_1_D
I0624 12:47:27.450306 17456 net.cpp:425] bn2_1_D <- conv2_1_D
I0624 12:47:27.450311 17456 net.cpp:386] bn2_1_D -> conv2_1_D (in-place)
I0624 12:47:27.450537 17456 net.cpp:141] Setting up bn2_1_D
I0624 12:47:27.450546 17456 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:47:27.450547 17456 net.cpp:156] Memory required for data: 142800896
I0624 12:47:27.450553 17456 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 12:47:27.450559 17456 net.cpp:91] Creating Layer scale2_1_D
I0624 12:47:27.450562 17456 net.cpp:425] scale2_1_D <- conv2_1_D
I0624 12:47:27.450565 17456 net.cpp:386] scale2_1_D -> conv2_1_D (in-place)
I0624 12:47:27.450608 17456 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 12:47:27.450742 17456 net.cpp:141] Setting up scale2_1_D
I0624 12:47:27.450749 17456 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:47:27.450752 17456 net.cpp:156] Memory required for data: 144406528
I0624 12:47:27.450757 17456 layer_factory.hpp:77] Creating layer relu2_1_D
I0624 12:47:27.450762 17456 net.cpp:91] Creating Layer relu2_1_D
I0624 12:47:27.450764 17456 net.cpp:425] relu2_1_D <- conv2_1_D
I0624 12:47:27.450767 17456 net.cpp:386] relu2_1_D -> conv2_1_D (in-place)
I0624 12:47:27.450925 17456 net.cpp:141] Setting up relu2_1_D
I0624 12:47:27.450934 17456 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 12:47:27.450937 17456 net.cpp:156] Memory required for data: 146012160
I0624 12:47:27.450939 17456 layer_factory.hpp:77] Creating layer upsample1
I0624 12:47:27.450944 17456 net.cpp:91] Creating Layer upsample1
I0624 12:47:27.450947 17456 net.cpp:425] upsample1 <- conv2_1_D
I0624 12:47:27.450951 17456 net.cpp:425] upsample1 <- pool1_mask
I0624 12:47:27.450956 17456 net.cpp:399] upsample1 -> pool1_D
I0624 12:47:27.450987 17456 net.cpp:141] Setting up upsample1
I0624 12:47:27.450992 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.450994 17456 net.cpp:156] Memory required for data: 152434688
I0624 12:47:27.450996 17456 layer_factory.hpp:77] Creating layer conv1_2_D
I0624 12:47:27.451004 17456 net.cpp:91] Creating Layer conv1_2_D
I0624 12:47:27.451006 17456 net.cpp:425] conv1_2_D <- pool1_D
I0624 12:47:27.451011 17456 net.cpp:399] conv1_2_D -> conv1_2_D
I0624 12:47:27.452188 17456 net.cpp:141] Setting up conv1_2_D
I0624 12:47:27.452201 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.452214 17456 net.cpp:156] Memory required for data: 158857216
I0624 12:47:27.452219 17456 layer_factory.hpp:77] Creating layer bn1_2_D
I0624 12:47:27.452226 17456 net.cpp:91] Creating Layer bn1_2_D
I0624 12:47:27.452229 17456 net.cpp:425] bn1_2_D <- conv1_2_D
I0624 12:47:27.452234 17456 net.cpp:386] bn1_2_D -> conv1_2_D (in-place)
I0624 12:47:27.452497 17456 net.cpp:141] Setting up bn1_2_D
I0624 12:47:27.452504 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.452507 17456 net.cpp:156] Memory required for data: 165279744
I0624 12:47:27.452512 17456 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 12:47:27.452518 17456 net.cpp:91] Creating Layer scale1_2_D
I0624 12:47:27.452520 17456 net.cpp:425] scale1_2_D <- conv1_2_D
I0624 12:47:27.452525 17456 net.cpp:386] scale1_2_D -> conv1_2_D (in-place)
I0624 12:47:27.452569 17456 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 12:47:27.453347 17456 net.cpp:141] Setting up scale1_2_D
I0624 12:47:27.453358 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.453361 17456 net.cpp:156] Memory required for data: 171702272
I0624 12:47:27.453366 17456 layer_factory.hpp:77] Creating layer relu1_2_D
I0624 12:47:27.453371 17456 net.cpp:91] Creating Layer relu1_2_D
I0624 12:47:27.453373 17456 net.cpp:425] relu1_2_D <- conv1_2_D
I0624 12:47:27.453378 17456 net.cpp:386] relu1_2_D -> conv1_2_D (in-place)
I0624 12:47:27.453690 17456 net.cpp:141] Setting up relu1_2_D
I0624 12:47:27.453701 17456 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 12:47:27.453703 17456 net.cpp:156] Memory required for data: 178124800
I0624 12:47:27.453706 17456 layer_factory.hpp:77] Creating layer conv1_1_D
I0624 12:47:27.453716 17456 net.cpp:91] Creating Layer conv1_1_D
I0624 12:47:27.453719 17456 net.cpp:425] conv1_1_D <- conv1_2_D
I0624 12:47:27.453725 17456 net.cpp:399] conv1_1_D -> conv1_1_D
I0624 12:47:27.455014 17456 net.cpp:141] Setting up conv1_1_D
I0624 12:47:27.455027 17456 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 12:47:27.455029 17456 net.cpp:156] Memory required for data: 178526208
I0624 12:47:27.455035 17456 layer_factory.hpp:77] Creating layer conv1_1_D_conv1_1_D_0_split
I0624 12:47:27.455041 17456 net.cpp:91] Creating Layer conv1_1_D_conv1_1_D_0_split
I0624 12:47:27.455044 17456 net.cpp:425] conv1_1_D_conv1_1_D_0_split <- conv1_1_D
I0624 12:47:27.455049 17456 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_0
I0624 12:47:27.455054 17456 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_1
I0624 12:47:27.455106 17456 net.cpp:141] Setting up conv1_1_D_conv1_1_D_0_split
I0624 12:47:27.455112 17456 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 12:47:27.455116 17456 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 12:47:27.455117 17456 net.cpp:156] Memory required for data: 179329024
I0624 12:47:27.455119 17456 layer_factory.hpp:77] Creating layer loss
I0624 12:47:27.455126 17456 net.cpp:91] Creating Layer loss
I0624 12:47:27.455128 17456 net.cpp:425] loss <- conv1_1_D_conv1_1_D_0_split_0
I0624 12:47:27.455132 17456 net.cpp:425] loss <- label_data_1_split_0
I0624 12:47:27.455135 17456 net.cpp:399] loss -> loss
I0624 12:47:27.455142 17456 layer_factory.hpp:77] Creating layer loss
I0624 12:47:27.455638 17456 net.cpp:141] Setting up loss
I0624 12:47:27.455649 17456 net.cpp:148] Top shape: (1)
I0624 12:47:27.455652 17456 net.cpp:151]     with loss weight 1
I0624 12:47:27.455660 17456 net.cpp:156] Memory required for data: 179329028
I0624 12:47:27.455663 17456 layer_factory.hpp:77] Creating layer accuracy
I0624 12:47:27.455669 17456 net.cpp:91] Creating Layer accuracy
I0624 12:47:27.455672 17456 net.cpp:425] accuracy <- conv1_1_D_conv1_1_D_0_split_1
I0624 12:47:27.455677 17456 net.cpp:425] accuracy <- label_data_1_split_1
I0624 12:47:27.455680 17456 net.cpp:399] accuracy -> accuracy
I0624 12:47:27.455687 17456 net.cpp:141] Setting up accuracy
I0624 12:47:27.455689 17456 net.cpp:148] Top shape: (1)
I0624 12:47:27.455693 17456 net.cpp:156] Memory required for data: 179329032
I0624 12:47:27.455706 17456 net.cpp:219] accuracy does not need backward computation.
I0624 12:47:27.455709 17456 net.cpp:217] loss needs backward computation.
I0624 12:47:27.455713 17456 net.cpp:217] conv1_1_D_conv1_1_D_0_split needs backward computation.
I0624 12:47:27.455714 17456 net.cpp:217] conv1_1_D needs backward computation.
I0624 12:47:27.455716 17456 net.cpp:217] relu1_2_D needs backward computation.
I0624 12:47:27.455718 17456 net.cpp:217] scale1_2_D needs backward computation.
I0624 12:47:27.455720 17456 net.cpp:217] bn1_2_D needs backward computation.
I0624 12:47:27.455723 17456 net.cpp:217] conv1_2_D needs backward computation.
I0624 12:47:27.455724 17456 net.cpp:217] upsample1 needs backward computation.
I0624 12:47:27.455727 17456 net.cpp:217] relu2_1_D needs backward computation.
I0624 12:47:27.455729 17456 net.cpp:217] scale2_1_D needs backward computation.
I0624 12:47:27.455731 17456 net.cpp:217] bn2_1_D needs backward computation.
I0624 12:47:27.455734 17456 net.cpp:217] conv2_1_D needs backward computation.
I0624 12:47:27.455736 17456 net.cpp:217] relu2_2_D needs backward computation.
I0624 12:47:27.455739 17456 net.cpp:217] scale2_2_D needs backward computation.
I0624 12:47:27.455740 17456 net.cpp:217] bn2_2_D needs backward computation.
I0624 12:47:27.455741 17456 net.cpp:217] conv2_2_D needs backward computation.
I0624 12:47:27.455744 17456 net.cpp:217] upsample2 needs backward computation.
I0624 12:47:27.455747 17456 net.cpp:217] relu3_1_D needs backward computation.
I0624 12:47:27.455749 17456 net.cpp:217] scale3_1_D needs backward computation.
I0624 12:47:27.455751 17456 net.cpp:217] bn3_1_D needs backward computation.
I0624 12:47:27.455754 17456 net.cpp:217] conv3_1_D needs backward computation.
I0624 12:47:27.455755 17456 net.cpp:217] relu3_2_D needs backward computation.
I0624 12:47:27.455757 17456 net.cpp:217] scale3_2_D needs backward computation.
I0624 12:47:27.455760 17456 net.cpp:217] bn3_2_D needs backward computation.
I0624 12:47:27.455761 17456 net.cpp:217] conv3_2_D needs backward computation.
I0624 12:47:27.455765 17456 net.cpp:217] upsample3 needs backward computation.
I0624 12:47:27.455766 17456 net.cpp:217] relu4_1_D needs backward computation.
I0624 12:47:27.455770 17456 net.cpp:217] scale4_1_D needs backward computation.
I0624 12:47:27.455771 17456 net.cpp:217] bn4_1_D needs backward computation.
I0624 12:47:27.455773 17456 net.cpp:217] conv4_1_D needs backward computation.
I0624 12:47:27.455775 17456 net.cpp:217] relu4_2_D needs backward computation.
I0624 12:47:27.455777 17456 net.cpp:217] scale4_2_D needs backward computation.
I0624 12:47:27.455780 17456 net.cpp:217] bn4_2_D needs backward computation.
I0624 12:47:27.455782 17456 net.cpp:217] conv4_2_D needs backward computation.
I0624 12:47:27.455785 17456 net.cpp:217] upsample4 needs backward computation.
I0624 12:47:27.455787 17456 net.cpp:217] relu5_1_D needs backward computation.
I0624 12:47:27.455790 17456 net.cpp:217] scale5_1_D needs backward computation.
I0624 12:47:27.455791 17456 net.cpp:217] bn5_1_D needs backward computation.
I0624 12:47:27.455793 17456 net.cpp:217] conv5_1_D needs backward computation.
I0624 12:47:27.455796 17456 net.cpp:217] relu5_2_D needs backward computation.
I0624 12:47:27.455797 17456 net.cpp:217] scale5_2_D needs backward computation.
I0624 12:47:27.455801 17456 net.cpp:217] bn5_2_D needs backward computation.
I0624 12:47:27.455802 17456 net.cpp:217] conv5_2_D needs backward computation.
I0624 12:47:27.455804 17456 net.cpp:217] upsample5 needs backward computation.
I0624 12:47:27.455808 17456 net.cpp:217] pool5 needs backward computation.
I0624 12:47:27.455811 17456 net.cpp:217] relu5_2 needs backward computation.
I0624 12:47:27.455812 17456 net.cpp:217] scale5_2 needs backward computation.
I0624 12:47:27.455816 17456 net.cpp:217] bn5_2 needs backward computation.
I0624 12:47:27.455817 17456 net.cpp:217] conv5_2 needs backward computation.
I0624 12:47:27.455819 17456 net.cpp:217] relu5_1 needs backward computation.
I0624 12:47:27.455821 17456 net.cpp:217] scale5_1 needs backward computation.
I0624 12:47:27.455828 17456 net.cpp:217] bn5_1 needs backward computation.
I0624 12:47:27.455832 17456 net.cpp:217] conv5_1 needs backward computation.
I0624 12:47:27.455833 17456 net.cpp:217] pool4 needs backward computation.
I0624 12:47:27.455837 17456 net.cpp:217] relu4_2 needs backward computation.
I0624 12:47:27.455838 17456 net.cpp:217] scale4_2 needs backward computation.
I0624 12:47:27.455840 17456 net.cpp:217] bn4_2 needs backward computation.
I0624 12:47:27.455842 17456 net.cpp:217] conv4_2 needs backward computation.
I0624 12:47:27.455845 17456 net.cpp:217] relu4_1 needs backward computation.
I0624 12:47:27.455847 17456 net.cpp:217] scale4_1 needs backward computation.
I0624 12:47:27.455849 17456 net.cpp:217] bn4_1 needs backward computation.
I0624 12:47:27.455852 17456 net.cpp:217] conv4_1 needs backward computation.
I0624 12:47:27.455853 17456 net.cpp:217] pool3 needs backward computation.
I0624 12:47:27.455857 17456 net.cpp:217] relu3_2 needs backward computation.
I0624 12:47:27.455858 17456 net.cpp:217] scale3_2 needs backward computation.
I0624 12:47:27.455860 17456 net.cpp:217] bn3_2 needs backward computation.
I0624 12:47:27.455862 17456 net.cpp:217] conv3_2 needs backward computation.
I0624 12:47:27.455864 17456 net.cpp:217] relu3_1 needs backward computation.
I0624 12:47:27.455867 17456 net.cpp:217] scale3_1 needs backward computation.
I0624 12:47:27.455868 17456 net.cpp:217] bn3_1 needs backward computation.
I0624 12:47:27.455871 17456 net.cpp:217] conv3_1 needs backward computation.
I0624 12:47:27.455873 17456 net.cpp:217] pool2 needs backward computation.
I0624 12:47:27.455875 17456 net.cpp:217] relu2_2 needs backward computation.
I0624 12:47:27.455878 17456 net.cpp:217] scale2_2 needs backward computation.
I0624 12:47:27.455880 17456 net.cpp:217] bn2_2 needs backward computation.
I0624 12:47:27.455883 17456 net.cpp:217] conv2_2 needs backward computation.
I0624 12:47:27.455885 17456 net.cpp:217] relu2_1 needs backward computation.
I0624 12:47:27.455888 17456 net.cpp:217] scale2_1 needs backward computation.
I0624 12:47:27.455889 17456 net.cpp:217] bn2_1 needs backward computation.
I0624 12:47:27.455891 17456 net.cpp:217] conv2_1 needs backward computation.
I0624 12:47:27.455894 17456 net.cpp:217] pool1 needs backward computation.
I0624 12:47:27.455896 17456 net.cpp:217] relu1_2 needs backward computation.
I0624 12:47:27.455899 17456 net.cpp:217] scale1_2 needs backward computation.
I0624 12:47:27.455901 17456 net.cpp:217] bn1_2 needs backward computation.
I0624 12:47:27.455904 17456 net.cpp:217] conv1_2 needs backward computation.
I0624 12:47:27.455905 17456 net.cpp:217] relu1_1 needs backward computation.
I0624 12:47:27.455907 17456 net.cpp:217] scale1_1 needs backward computation.
I0624 12:47:27.455910 17456 net.cpp:217] bn1_1 needs backward computation.
I0624 12:47:27.455912 17456 net.cpp:217] conv1_1 needs backward computation.
I0624 12:47:27.455915 17456 net.cpp:219] label_data_1_split does not need backward computation.
I0624 12:47:27.455919 17456 net.cpp:219] data does not need backward computation.
I0624 12:47:27.455919 17456 net.cpp:261] This network produces output accuracy
I0624 12:47:27.455922 17456 net.cpp:261] This network produces output loss
I0624 12:47:27.455955 17456 net.cpp:274] Network initialization done.
I0624 12:47:27.456210 17456 solver.cpp:60] Solver scaffolding done.
I0624 12:47:27.460674 17456 caffe.cpp:209] Resuming from data/models/segnet_iter_1000.solverstate
I0624 12:47:27.513926 17456 sgd_solver.cpp:318] SGDSolver: restoring history
I0624 12:47:27.530859 17456 caffe.cpp:219] Starting Optimization
I0624 12:47:27.530879 17456 solver.cpp:279] Solving segnet
I0624 12:47:27.530881 17456 solver.cpp:280] Learning Rate Policy: step
I0624 12:47:27.534642 17456 solver.cpp:337] Iteration 1000, Testing net (#0)
I0624 12:47:27.912616 17456 solver.cpp:404]     Test net output #0: accuracy = 0.985166
I0624 12:47:27.912643 17456 solver.cpp:404]     Test net output #1: loss = 0.0361938 (* 1 = 0.0361938 loss)
I0624 12:47:28.663550 17456 solver.cpp:228] Iteration 1000, loss = 0.0425431
I0624 12:47:28.663590 17456 solver.cpp:244]     Train net output #0: accuracy = 0.979283
I0624 12:47:28.663599 17456 solver.cpp:244]     Train net output #1: loss = 0.0425431 (* 1 = 0.0425431 loss)
I0624 12:47:28.663609 17456 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0624 12:47:42.878036 17456 solver.cpp:228] Iteration 1020, loss = 0.0426677
I0624 12:47:42.878057 17456 solver.cpp:244]     Train net output #0: accuracy = 0.981717
I0624 12:47:42.878065 17456 solver.cpp:244]     Train net output #1: loss = 0.0426677 (* 1 = 0.0426677 loss)
I0624 12:47:42.878070 17456 sgd_solver.cpp:106] Iteration 1020, lr = 0.01
I0624 12:47:57.369577 17456 solver.cpp:228] Iteration 1040, loss = 0.0369435
I0624 12:47:57.369746 17456 solver.cpp:244]     Train net output #0: accuracy = 0.986342
I0624 12:47:57.369758 17456 solver.cpp:244]     Train net output #1: loss = 0.0369435 (* 1 = 0.0369435 loss)
I0624 12:47:57.369763 17456 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I0624 12:48:11.867893 17456 solver.cpp:228] Iteration 1060, loss = 0.0232112
I0624 12:48:11.867918 17456 solver.cpp:244]     Train net output #0: accuracy = 0.994539
I0624 12:48:11.867925 17456 solver.cpp:244]     Train net output #1: loss = 0.0232112 (* 1 = 0.0232112 loss)
I0624 12:48:11.867929 17456 sgd_solver.cpp:106] Iteration 1060, lr = 0.01
I0624 12:48:26.403141 17456 solver.cpp:228] Iteration 1080, loss = 0.0352499
I0624 12:48:26.403168 17456 solver.cpp:244]     Train net output #0: accuracy = 0.981584
I0624 12:48:26.403177 17456 solver.cpp:244]     Train net output #1: loss = 0.0352499 (* 1 = 0.0352499 loss)
I0624 12:48:26.403182 17456 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I0624 12:48:40.631820 17456 solver.cpp:337] Iteration 1100, Testing net (#0)
I0624 12:48:40.965939 17456 solver.cpp:404]     Test net output #0: accuracy = 0.985206
I0624 12:48:40.965975 17456 solver.cpp:404]     Test net output #1: loss = 0.027628 (* 1 = 0.027628 loss)
I0624 12:48:41.376277 17456 solver.cpp:228] Iteration 1100, loss = 0.0413084
I0624 12:48:41.376312 17456 solver.cpp:244]     Train net output #0: accuracy = 0.978231
I0624 12:48:41.376320 17456 solver.cpp:244]     Train net output #1: loss = 0.0413084 (* 1 = 0.0413084 loss)
I0624 12:48:41.376324 17456 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0624 12:48:55.967896 17456 solver.cpp:228] Iteration 1120, loss = 0.0384907
I0624 12:48:55.967929 17456 solver.cpp:244]     Train net output #0: accuracy = 0.980604
I0624 12:48:55.967937 17456 solver.cpp:244]     Train net output #1: loss = 0.0384907 (* 1 = 0.0384907 loss)
I0624 12:48:55.967942 17456 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I0624 12:49:10.595377 17456 solver.cpp:228] Iteration 1140, loss = 0.0408401
I0624 12:49:10.595412 17456 solver.cpp:244]     Train net output #0: accuracy = 0.980395
I0624 12:49:10.595418 17456 solver.cpp:244]     Train net output #1: loss = 0.0408401 (* 1 = 0.0408401 loss)
I0624 12:49:10.595423 17456 sgd_solver.cpp:106] Iteration 1140, lr = 0.01
I0624 12:49:25.221667 17456 solver.cpp:228] Iteration 1160, loss = 0.0297495
I0624 12:49:25.221763 17456 solver.cpp:244]     Train net output #0: accuracy = 0.98822
I0624 12:49:25.221773 17456 solver.cpp:244]     Train net output #1: loss = 0.0297495 (* 1 = 0.0297495 loss)
I0624 12:49:25.221779 17456 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I0624 12:49:39.848461 17456 solver.cpp:228] Iteration 1180, loss = 0.029065
I0624 12:49:39.848485 17456 solver.cpp:244]     Train net output #0: accuracy = 0.98265
I0624 12:49:39.848492 17456 solver.cpp:244]     Train net output #1: loss = 0.029065 (* 1 = 0.029065 loss)
I0624 12:49:39.848497 17456 sgd_solver.cpp:106] Iteration 1180, lr = 0.01
I0624 12:49:54.073510 17456 solver.cpp:337] Iteration 1200, Testing net (#0)
I0624 12:49:54.409018 17456 solver.cpp:404]     Test net output #0: accuracy = 0.994836
I0624 12:49:54.409054 17456 solver.cpp:404]     Test net output #1: loss = 0.0172524 (* 1 = 0.0172524 loss)
I0624 12:49:54.818584 17456 solver.cpp:228] Iteration 1200, loss = 0.0480099
I0624 12:49:54.818620 17456 solver.cpp:244]     Train net output #0: accuracy = 0.979432
I0624 12:49:54.818629 17456 solver.cpp:244]     Train net output #1: loss = 0.0480099 (* 1 = 0.0480099 loss)
I0624 12:49:54.818632 17456 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0624 12:50:09.443588 17456 solver.cpp:228] Iteration 1220, loss = 0.0383748
I0624 12:50:09.443697 17456 solver.cpp:244]     Train net output #0: accuracy = 0.982172
I0624 12:50:09.443708 17456 solver.cpp:244]     Train net output #1: loss = 0.0383748 (* 1 = 0.0383748 loss)
I0624 12:50:09.443713 17456 sgd_solver.cpp:106] Iteration 1220, lr = 0.01
I0624 12:50:24.111971 17456 solver.cpp:228] Iteration 1240, loss = 0.0331878
I0624 12:50:24.112007 17456 solver.cpp:244]     Train net output #0: accuracy = 0.984807
I0624 12:50:24.112015 17456 solver.cpp:244]     Train net output #1: loss = 0.0331878 (* 1 = 0.0331878 loss)
I0624 12:50:24.112020 17456 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I0624 12:50:38.896812 17456 solver.cpp:228] Iteration 1260, loss = 0.0292053
I0624 12:50:38.896836 17456 solver.cpp:244]     Train net output #0: accuracy = 0.987289
I0624 12:50:38.896844 17456 solver.cpp:244]     Train net output #1: loss = 0.0292053 (* 1 = 0.0292053 loss)
I0624 12:50:38.896859 17456 sgd_solver.cpp:106] Iteration 1260, lr = 0.01
I0624 12:50:53.554618 17456 solver.cpp:228] Iteration 1280, loss = 0.0263587
I0624 12:50:53.554716 17456 solver.cpp:244]     Train net output #0: accuracy = 0.987492
I0624 12:50:53.554725 17456 solver.cpp:244]     Train net output #1: loss = 0.0263587 (* 1 = 0.0263587 loss)
I0624 12:50:53.554731 17456 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I0624 12:51:07.785270 17456 solver.cpp:337] Iteration 1300, Testing net (#0)
I0624 12:51:08.120719 17456 solver.cpp:404]     Test net output #0: accuracy = 0.987712
I0624 12:51:08.120754 17456 solver.cpp:404]     Test net output #1: loss = 0.0270231 (* 1 = 0.0270231 loss)
I0624 12:51:08.531033 17456 solver.cpp:228] Iteration 1300, loss = 0.0417407
I0624 12:51:08.531056 17456 solver.cpp:244]     Train net output #0: accuracy = 0.980189
I0624 12:51:08.531064 17456 solver.cpp:244]     Train net output #1: loss = 0.0417407 (* 1 = 0.0417407 loss)
I0624 12:51:08.531069 17456 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0624 12:51:23.172029 17456 solver.cpp:228] Iteration 1320, loss = 0.0338807
I0624 12:51:23.172052 17456 solver.cpp:244]     Train net output #0: accuracy = 0.980616
I0624 12:51:23.172060 17456 solver.cpp:244]     Train net output #1: loss = 0.0338807 (* 1 = 0.0338807 loss)
I0624 12:51:23.172065 17456 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I0624 12:51:37.811959 17456 solver.cpp:228] Iteration 1340, loss = 0.0296283
I0624 12:51:37.812060 17456 solver.cpp:244]     Train net output #0: accuracy = 0.986048
I0624 12:51:37.812070 17456 solver.cpp:244]     Train net output #1: loss = 0.0296283 (* 1 = 0.0296283 loss)
I0624 12:51:37.812075 17456 sgd_solver.cpp:106] Iteration 1340, lr = 0.01
I0624 12:51:52.453308 17456 solver.cpp:228] Iteration 1360, loss = 0.0266706
I0624 12:51:52.453332 17456 solver.cpp:244]     Train net output #0: accuracy = 0.988499
I0624 12:51:52.453339 17456 solver.cpp:244]     Train net output #1: loss = 0.0266706 (* 1 = 0.0266706 loss)
I0624 12:51:52.453344 17456 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I0624 12:52:07.092002 17456 solver.cpp:228] Iteration 1380, loss = 0.0304577
I0624 12:52:07.092025 17456 solver.cpp:244]     Train net output #0: accuracy = 0.988579
I0624 12:52:07.092032 17456 solver.cpp:244]     Train net output #1: loss = 0.0304577 (* 1 = 0.0304577 loss)
I0624 12:52:07.092037 17456 sgd_solver.cpp:106] Iteration 1380, lr = 0.01
I0624 12:52:21.323678 17456 solver.cpp:337] Iteration 1400, Testing net (#0)
I0624 12:52:21.659128 17456 solver.cpp:404]     Test net output #0: accuracy = 0.984057
I0624 12:52:21.659154 17456 solver.cpp:404]     Test net output #1: loss = 0.0364799 (* 1 = 0.0364799 loss)
I0624 12:52:22.070348 17456 solver.cpp:228] Iteration 1400, loss = 0.0315898
I0624 12:52:22.070381 17456 solver.cpp:244]     Train net output #0: accuracy = 0.988889
I0624 12:52:22.070389 17456 solver.cpp:244]     Train net output #1: loss = 0.0315898 (* 1 = 0.0315898 loss)
I0624 12:52:22.070394 17456 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0624 12:52:36.718109 17456 solver.cpp:228] Iteration 1420, loss = 0.0425341
I0624 12:52:36.718144 17456 solver.cpp:244]     Train net output #0: accuracy = 0.983216
I0624 12:52:36.718152 17456 solver.cpp:244]     Train net output #1: loss = 0.0425341 (* 1 = 0.0425341 loss)
I0624 12:52:36.718156 17456 sgd_solver.cpp:106] Iteration 1420, lr = 0.01
I0624 12:52:51.358403 17456 solver.cpp:228] Iteration 1440, loss = 0.039563
I0624 12:52:51.358549 17456 solver.cpp:244]     Train net output #0: accuracy = 0.98468
I0624 12:52:51.358561 17456 solver.cpp:244]     Train net output #1: loss = 0.039563 (* 1 = 0.039563 loss)
I0624 12:52:51.358566 17456 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I0624 12:53:05.994253 17456 solver.cpp:228] Iteration 1460, loss = 0.034216
I0624 12:53:05.994277 17456 solver.cpp:244]     Train net output #0: accuracy = 0.98557
I0624 12:53:05.994285 17456 solver.cpp:244]     Train net output #1: loss = 0.034216 (* 1 = 0.034216 loss)
I0624 12:53:05.994289 17456 sgd_solver.cpp:106] Iteration 1460, lr = 0.01
I0624 12:53:20.624169 17456 solver.cpp:228] Iteration 1480, loss = 0.0133994
I0624 12:53:20.624196 17456 solver.cpp:244]     Train net output #0: accuracy = 0.995932
I0624 12:53:20.624203 17456 solver.cpp:244]     Train net output #1: loss = 0.0133994 (* 1 = 0.0133994 loss)
I0624 12:53:20.624207 17456 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I0624 12:53:34.841742 17456 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_1500.caffemodel
I0624 12:53:34.886867 17456 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_1500.solverstate
I0624 12:53:34.907946 17456 solver.cpp:337] Iteration 1500, Testing net (#0)
I0624 12:53:35.245713 17456 solver.cpp:404]     Test net output #0: accuracy = 0.977736
I0624 12:53:35.245748 17456 solver.cpp:404]     Test net output #1: loss = 0.0558519 (* 1 = 0.0558519 loss)
I0624 12:53:35.654338 17456 solver.cpp:228] Iteration 1500, loss = 0.0305584
I0624 12:53:35.654362 17456 solver.cpp:244]     Train net output #0: accuracy = 0.987934
I0624 12:53:35.654371 17456 solver.cpp:244]     Train net output #1: loss = 0.0305584 (* 1 = 0.0305584 loss)
I0624 12:53:35.654374 17456 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0624 12:53:50.283300 17456 solver.cpp:228] Iteration 1520, loss = 0.032438
I0624 12:53:50.283324 17456 solver.cpp:244]     Train net output #0: accuracy = 0.985316
I0624 12:53:50.283331 17456 solver.cpp:244]     Train net output #1: loss = 0.032438 (* 1 = 0.032438 loss)
I0624 12:53:50.283335 17456 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I0624 12:54:04.915881 17456 solver.cpp:228] Iteration 1540, loss = 0.0227039
I0624 12:54:04.915987 17456 solver.cpp:244]     Train net output #0: accuracy = 0.991782
I0624 12:54:04.915997 17456 solver.cpp:244]     Train net output #1: loss = 0.0227039 (* 1 = 0.0227039 loss)
I0624 12:54:04.916002 17456 sgd_solver.cpp:106] Iteration 1540, lr = 0.01
I0624 12:54:19.541770 17456 solver.cpp:228] Iteration 1560, loss = 0.0224191
I0624 12:54:19.541806 17456 solver.cpp:244]     Train net output #0: accuracy = 0.991241
I0624 12:54:19.541815 17456 solver.cpp:244]     Train net output #1: loss = 0.0224191 (* 1 = 0.0224191 loss)
I0624 12:54:19.541820 17456 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I0624 12:54:34.217900 17456 solver.cpp:228] Iteration 1580, loss = 0.0365037
I0624 12:54:34.217924 17456 solver.cpp:244]     Train net output #0: accuracy = 0.986737
I0624 12:54:34.217932 17456 solver.cpp:244]     Train net output #1: loss = 0.0365037 (* 1 = 0.0365037 loss)
I0624 12:54:34.217937 17456 sgd_solver.cpp:106] Iteration 1580, lr = 0.01
I0624 12:54:48.448617 17456 solver.cpp:337] Iteration 1600, Testing net (#0)
I0624 12:54:48.784169 17456 solver.cpp:404]     Test net output #0: accuracy = 0.980591
I0624 12:54:48.784194 17456 solver.cpp:404]     Test net output #1: loss = 0.0512403 (* 1 = 0.0512403 loss)
I0624 12:54:49.193758 17456 solver.cpp:228] Iteration 1600, loss = 0.034732
I0624 12:54:49.193781 17456 solver.cpp:244]     Train net output #0: accuracy = 0.983796
I0624 12:54:49.193789 17456 solver.cpp:244]     Train net output #1: loss = 0.034732 (* 1 = 0.034732 loss)
I0624 12:54:49.193794 17456 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0624 12:55:03.854666 17456 solver.cpp:228] Iteration 1620, loss = 0.027428
I0624 12:55:03.854696 17456 solver.cpp:244]     Train net output #0: accuracy = 0.989092
I0624 12:55:03.854707 17456 solver.cpp:244]     Train net output #1: loss = 0.027428 (* 1 = 0.027428 loss)
I0624 12:55:03.854714 17456 sgd_solver.cpp:106] Iteration 1620, lr = 0.01
I0624 12:55:18.505178 17456 solver.cpp:228] Iteration 1640, loss = 0.0184716
I0624 12:55:18.505291 17456 solver.cpp:244]     Train net output #0: accuracy = 0.994243
I0624 12:55:18.505302 17456 solver.cpp:244]     Train net output #1: loss = 0.0184716 (* 1 = 0.0184716 loss)
I0624 12:55:18.505308 17456 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I0624 12:55:33.137471 17456 solver.cpp:228] Iteration 1660, loss = 0.044114
I0624 12:55:33.137495 17456 solver.cpp:244]     Train net output #0: accuracy = 0.980475
I0624 12:55:33.137502 17456 solver.cpp:244]     Train net output #1: loss = 0.044114 (* 1 = 0.044114 loss)
I0624 12:55:33.137507 17456 sgd_solver.cpp:106] Iteration 1660, lr = 0.01
I0624 12:55:47.769229 17456 solver.cpp:228] Iteration 1680, loss = 0.0308388
I0624 12:55:47.769255 17456 solver.cpp:244]     Train net output #0: accuracy = 0.988189
I0624 12:55:47.769263 17456 solver.cpp:244]     Train net output #1: loss = 0.0308388 (* 1 = 0.0308388 loss)
I0624 12:55:47.769268 17456 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I0624 12:56:02.010615 17456 solver.cpp:337] Iteration 1700, Testing net (#0)
I0624 12:56:02.346029 17456 solver.cpp:404]     Test net output #0: accuracy = 0.984487
I0624 12:56:02.346063 17456 solver.cpp:404]     Test net output #1: loss = 0.0349984 (* 1 = 0.0349984 loss)
I0624 12:56:02.756088 17456 solver.cpp:228] Iteration 1700, loss = 0.0356397
I0624 12:56:02.756110 17456 solver.cpp:244]     Train net output #0: accuracy = 0.986123
I0624 12:56:02.756117 17456 solver.cpp:244]     Train net output #1: loss = 0.0356397 (* 1 = 0.0356397 loss)
I0624 12:56:02.756121 17456 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0624 12:56:17.411093 17456 solver.cpp:228] Iteration 1720, loss = 0.0272491
I0624 12:56:17.411119 17456 solver.cpp:244]     Train net output #0: accuracy = 0.991291
I0624 12:56:17.411126 17456 solver.cpp:244]     Train net output #1: loss = 0.0272491 (* 1 = 0.0272491 loss)
I0624 12:56:17.411131 17456 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I0624 12:56:32.085103 17456 solver.cpp:228] Iteration 1740, loss = 0.0345013
I0624 12:56:32.085196 17456 solver.cpp:244]     Train net output #0: accuracy = 0.98588
I0624 12:56:32.085206 17456 solver.cpp:244]     Train net output #1: loss = 0.0345013 (* 1 = 0.0345013 loss)
I0624 12:56:32.085211 17456 sgd_solver.cpp:106] Iteration 1740, lr = 0.01
I0624 12:56:46.748355 17456 solver.cpp:228] Iteration 1760, loss = 0.0334139
I0624 12:56:46.748380 17456 solver.cpp:244]     Train net output #0: accuracy = 0.987076
I0624 12:56:46.748388 17456 solver.cpp:244]     Train net output #1: loss = 0.0334139 (* 1 = 0.0334139 loss)
I0624 12:56:46.748392 17456 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I0624 12:57:01.381386 17456 solver.cpp:228] Iteration 1780, loss = 0.027773
I0624 12:57:01.381412 17456 solver.cpp:244]     Train net output #0: accuracy = 0.987655
I0624 12:57:01.381420 17456 solver.cpp:244]     Train net output #1: loss = 0.027773 (* 1 = 0.027773 loss)
I0624 12:57:01.381425 17456 sgd_solver.cpp:106] Iteration 1780, lr = 0.01
I0624 12:57:15.617750 17456 solver.cpp:337] Iteration 1800, Testing net (#0)
I0624 12:57:15.953294 17456 solver.cpp:404]     Test net output #0: accuracy = 0.98403
I0624 12:57:15.953330 17456 solver.cpp:404]     Test net output #1: loss = 0.0463161 (* 1 = 0.0463161 loss)
I0624 12:57:16.363250 17456 solver.cpp:228] Iteration 1800, loss = 0.0288897
I0624 12:57:16.363271 17456 solver.cpp:244]     Train net output #0: accuracy = 0.989871
I0624 12:57:16.363278 17456 solver.cpp:244]     Train net output #1: loss = 0.0288897 (* 1 = 0.0288897 loss)
I0624 12:57:16.363283 17456 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0624 12:57:31.008992 17456 solver.cpp:228] Iteration 1820, loss = 0.0329067
I0624 12:57:31.009016 17456 solver.cpp:244]     Train net output #0: accuracy = 0.987497
I0624 12:57:31.009023 17456 solver.cpp:244]     Train net output #1: loss = 0.0329067 (* 1 = 0.0329067 loss)
I0624 12:57:31.009028 17456 sgd_solver.cpp:106] Iteration 1820, lr = 0.01
I0624 12:57:45.655293 17456 solver.cpp:228] Iteration 1840, loss = 0.0239686
I0624 12:57:45.655416 17456 solver.cpp:244]     Train net output #0: accuracy = 0.991607
I0624 12:57:45.655428 17456 solver.cpp:244]     Train net output #1: loss = 0.0239686 (* 1 = 0.0239686 loss)
I0624 12:57:45.655433 17456 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I0624 12:58:00.342123 17456 solver.cpp:228] Iteration 1860, loss = 0.0359275
I0624 12:58:00.342146 17456 solver.cpp:244]     Train net output #0: accuracy = 0.984605
I0624 12:58:00.342154 17456 solver.cpp:244]     Train net output #1: loss = 0.0359275 (* 1 = 0.0359275 loss)
I0624 12:58:00.342159 17456 sgd_solver.cpp:106] Iteration 1860, lr = 0.01
I0624 12:58:14.987325 17456 solver.cpp:228] Iteration 1880, loss = 0.0281631
I0624 12:58:14.987349 17456 solver.cpp:244]     Train net output #0: accuracy = 0.989351
I0624 12:58:14.987357 17456 solver.cpp:244]     Train net output #1: loss = 0.0281631 (* 1 = 0.0281631 loss)
I0624 12:58:14.987361 17456 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I0624 12:58:29.226397 17456 solver.cpp:337] Iteration 1900, Testing net (#0)
I0624 12:58:29.562239 17456 solver.cpp:404]     Test net output #0: accuracy = 0.981272
I0624 12:58:29.562263 17456 solver.cpp:404]     Test net output #1: loss = 0.0690906 (* 1 = 0.0690906 loss)
I0624 12:58:29.972693 17456 solver.cpp:228] Iteration 1900, loss = 0.0326992
I0624 12:58:29.972729 17456 solver.cpp:244]     Train net output #0: accuracy = 0.986395
I0624 12:58:29.972738 17456 solver.cpp:244]     Train net output #1: loss = 0.0326992 (* 1 = 0.0326992 loss)
I0624 12:58:29.972743 17456 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0624 12:58:44.627338 17456 solver.cpp:228] Iteration 1920, loss = 0.0265818
I0624 12:58:44.627362 17456 solver.cpp:244]     Train net output #0: accuracy = 0.988935
I0624 12:58:44.627369 17456 solver.cpp:244]     Train net output #1: loss = 0.0265818 (* 1 = 0.0265818 loss)
I0624 12:58:44.627373 17456 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I0624 12:58:59.267102 17456 solver.cpp:228] Iteration 1940, loss = 0.0356272
I0624 12:58:59.267192 17456 solver.cpp:244]     Train net output #0: accuracy = 0.98558
I0624 12:58:59.267208 17456 solver.cpp:244]     Train net output #1: loss = 0.0356272 (* 1 = 0.0356272 loss)
I0624 12:58:59.267213 17456 sgd_solver.cpp:106] Iteration 1940, lr = 0.01
I0624 12:59:13.907397 17456 solver.cpp:228] Iteration 1960, loss = 0.0381917
I0624 12:59:13.907421 17456 solver.cpp:244]     Train net output #0: accuracy = 0.985202
I0624 12:59:13.907428 17456 solver.cpp:244]     Train net output #1: loss = 0.0381917 (* 1 = 0.0381917 loss)
I0624 12:59:13.907433 17456 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I0624 12:59:28.546243 17456 solver.cpp:228] Iteration 1980, loss = 0.0299695
I0624 12:59:28.546267 17456 solver.cpp:244]     Train net output #0: accuracy = 0.987771
I0624 12:59:28.546275 17456 solver.cpp:244]     Train net output #1: loss = 0.0299695 (* 1 = 0.0299695 loss)
I0624 12:59:28.546280 17456 sgd_solver.cpp:106] Iteration 1980, lr = 0.01
I0624 12:59:42.789558 17456 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_2000.caffemodel
I0624 12:59:42.834677 17456 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_2000.solverstate
I0624 12:59:43.182786 17456 solver.cpp:317] Iteration 2000, loss = 0.0258849
I0624 12:59:43.182812 17456 solver.cpp:337] Iteration 2000, Testing net (#0)
I0624 12:59:43.521097 17456 solver.cpp:404]     Test net output #0: accuracy = 0.982208
I0624 12:59:43.521121 17456 solver.cpp:404]     Test net output #1: loss = 0.047337 (* 1 = 0.047337 loss)
I0624 12:59:43.521126 17456 solver.cpp:322] Optimization Done.
I0624 12:59:43.521128 17456 caffe.cpp:222] Optimization Done.
