I0624 21:43:38.704185 24300 caffe.cpp:185] Using GPUs 0
I0624 21:43:38.721163 24300 caffe.cpp:190] GPU 0: Graphics Device
I0624 21:43:39.190484 24300 solver.cpp:48] Initializing solver from parameters: 
test_iter: 64
test_interval: 100
base_lr: 0.001
display: 20
max_iter: 3000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 3000
snapshot: 500
snapshot_prefix: "data/models/bpgnet"
solver_mode: GPU
device_id: 0
net: "models/bpnet/train_val.prototxt"
test_initialization: true
iter_size: 1
I0624 21:43:39.190677 24300 solver.cpp:91] Creating training net from net file: models/bpnet/train_val.prototxt
I0624 21:43:39.192831 24300 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0624 21:43:39.193423 24300 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    mean_value: 100
    crop_h: 224
    crop_w: 288
    scale_jitter_range: 0.1
    contrast_jitter_range: 0.1
  }
  data_param {
    source: "data/train_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  pooling_param {
    pool: AVE
    stride: 1
    kernel_h: 7
    kernel_w: 9
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0624 21:43:39.193812 24300 layer_factory.hpp:77] Creating layer data
I0624 21:43:39.194653 24300 net.cpp:91] Creating Layer data
I0624 21:43:39.194676 24300 net.cpp:399] data -> data
I0624 21:43:39.194716 24300 net.cpp:399] data -> label
I0624 21:43:39.195991 24304 db_lmdb.cpp:35] Opened lmdb data/train_lmdb
I0624 21:43:39.246143 24300 data_layer.cpp:42] output data size: 32,3,224,288
I0624 21:43:39.314628 24300 net.cpp:141] Setting up data
I0624 21:43:39.314664 24300 net.cpp:148] Top shape: 32 3 224 288 (6193152)
I0624 21:43:39.314671 24300 net.cpp:148] Top shape: 32 (32)
I0624 21:43:39.314674 24300 net.cpp:156] Memory required for data: 24772736
I0624 21:43:39.314685 24300 layer_factory.hpp:77] Creating layer label_data_1_split
I0624 21:43:39.314707 24300 net.cpp:91] Creating Layer label_data_1_split
I0624 21:43:39.314713 24300 net.cpp:425] label_data_1_split <- label
I0624 21:43:39.314724 24300 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0624 21:43:39.314735 24300 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0624 21:43:39.314790 24300 net.cpp:141] Setting up label_data_1_split
I0624 21:43:39.314797 24300 net.cpp:148] Top shape: 32 (32)
I0624 21:43:39.314802 24300 net.cpp:148] Top shape: 32 (32)
I0624 21:43:39.314805 24300 net.cpp:156] Memory required for data: 24772992
I0624 21:43:39.314810 24300 layer_factory.hpp:77] Creating layer conv1_1
I0624 21:43:39.314827 24300 net.cpp:91] Creating Layer conv1_1
I0624 21:43:39.314831 24300 net.cpp:425] conv1_1 <- data
I0624 21:43:39.314857 24300 net.cpp:399] conv1_1 -> conv1_1
I0624 21:43:39.673661 24300 net.cpp:141] Setting up conv1_1
I0624 21:43:39.673686 24300 net.cpp:148] Top shape: 32 32 112 144 (16515072)
I0624 21:43:39.673691 24300 net.cpp:156] Memory required for data: 90833280
I0624 21:43:39.673703 24300 layer_factory.hpp:77] Creating layer bn1_1
I0624 21:43:39.673722 24300 net.cpp:91] Creating Layer bn1_1
I0624 21:43:39.673727 24300 net.cpp:425] bn1_1 <- conv1_1
I0624 21:43:39.673732 24300 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0624 21:43:39.673921 24300 net.cpp:141] Setting up bn1_1
I0624 21:43:39.673929 24300 net.cpp:148] Top shape: 32 32 112 144 (16515072)
I0624 21:43:39.673933 24300 net.cpp:156] Memory required for data: 156893568
I0624 21:43:39.673944 24300 layer_factory.hpp:77] Creating layer scale1_1
I0624 21:43:39.673956 24300 net.cpp:91] Creating Layer scale1_1
I0624 21:43:39.673960 24300 net.cpp:425] scale1_1 <- conv1_1
I0624 21:43:39.673965 24300 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0624 21:43:39.674007 24300 layer_factory.hpp:77] Creating layer scale1_1
I0624 21:43:39.674125 24300 net.cpp:141] Setting up scale1_1
I0624 21:43:39.674134 24300 net.cpp:148] Top shape: 32 32 112 144 (16515072)
I0624 21:43:39.674139 24300 net.cpp:156] Memory required for data: 222953856
I0624 21:43:39.674147 24300 layer_factory.hpp:77] Creating layer relu1_1
I0624 21:43:39.674154 24300 net.cpp:91] Creating Layer relu1_1
I0624 21:43:39.674160 24300 net.cpp:425] relu1_1 <- conv1_1
I0624 21:43:39.674167 24300 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0624 21:43:39.674341 24300 net.cpp:141] Setting up relu1_1
I0624 21:43:39.674355 24300 net.cpp:148] Top shape: 32 32 112 144 (16515072)
I0624 21:43:39.674360 24300 net.cpp:156] Memory required for data: 289014144
I0624 21:43:39.674366 24300 layer_factory.hpp:77] Creating layer conv1_2
I0624 21:43:39.674381 24300 net.cpp:91] Creating Layer conv1_2
I0624 21:43:39.674388 24300 net.cpp:425] conv1_2 <- conv1_1
I0624 21:43:39.674396 24300 net.cpp:399] conv1_2 -> conv1_2
I0624 21:43:39.675402 24300 net.cpp:141] Setting up conv1_2
I0624 21:43:39.675417 24300 net.cpp:148] Top shape: 32 32 112 144 (16515072)
I0624 21:43:39.675421 24300 net.cpp:156] Memory required for data: 355074432
I0624 21:43:39.675426 24300 layer_factory.hpp:77] Creating layer bn1_2
I0624 21:43:39.675433 24300 net.cpp:91] Creating Layer bn1_2
I0624 21:43:39.675437 24300 net.cpp:425] bn1_2 <- conv1_2
I0624 21:43:39.675442 24300 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0624 21:43:39.675612 24300 net.cpp:141] Setting up bn1_2
I0624 21:43:39.675621 24300 net.cpp:148] Top shape: 32 32 112 144 (16515072)
I0624 21:43:39.675623 24300 net.cpp:156] Memory required for data: 421134720
I0624 21:43:39.675633 24300 layer_factory.hpp:77] Creating layer scale1_2
I0624 21:43:39.675643 24300 net.cpp:91] Creating Layer scale1_2
I0624 21:43:39.675647 24300 net.cpp:425] scale1_2 <- conv1_2
I0624 21:43:39.675652 24300 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0624 21:43:39.675688 24300 layer_factory.hpp:77] Creating layer scale1_2
I0624 21:43:39.675806 24300 net.cpp:141] Setting up scale1_2
I0624 21:43:39.675814 24300 net.cpp:148] Top shape: 32 32 112 144 (16515072)
I0624 21:43:39.675820 24300 net.cpp:156] Memory required for data: 487195008
I0624 21:43:39.675827 24300 layer_factory.hpp:77] Creating layer relu1_2
I0624 21:43:39.675832 24300 net.cpp:91] Creating Layer relu1_2
I0624 21:43:39.675834 24300 net.cpp:425] relu1_2 <- conv1_2
I0624 21:43:39.675838 24300 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0624 21:43:39.675990 24300 net.cpp:141] Setting up relu1_2
I0624 21:43:39.676000 24300 net.cpp:148] Top shape: 32 32 112 144 (16515072)
I0624 21:43:39.676003 24300 net.cpp:156] Memory required for data: 553255296
I0624 21:43:39.676007 24300 layer_factory.hpp:77] Creating layer pool1
I0624 21:43:39.676013 24300 net.cpp:91] Creating Layer pool1
I0624 21:43:39.676017 24300 net.cpp:425] pool1 <- conv1_2
I0624 21:43:39.676022 24300 net.cpp:399] pool1 -> pool1
I0624 21:43:39.676074 24300 net.cpp:141] Setting up pool1
I0624 21:43:39.676096 24300 net.cpp:148] Top shape: 32 32 56 72 (4128768)
I0624 21:43:39.676100 24300 net.cpp:156] Memory required for data: 569770368
I0624 21:43:39.676103 24300 layer_factory.hpp:77] Creating layer conv2_1
I0624 21:43:39.676111 24300 net.cpp:91] Creating Layer conv2_1
I0624 21:43:39.676115 24300 net.cpp:425] conv2_1 <- pool1
I0624 21:43:39.676120 24300 net.cpp:399] conv2_1 -> conv2_1
I0624 21:43:39.678345 24300 net.cpp:141] Setting up conv2_1
I0624 21:43:39.678360 24300 net.cpp:148] Top shape: 32 64 56 72 (8257536)
I0624 21:43:39.678364 24300 net.cpp:156] Memory required for data: 602800512
I0624 21:43:39.678369 24300 layer_factory.hpp:77] Creating layer bn2_1
I0624 21:43:39.678376 24300 net.cpp:91] Creating Layer bn2_1
I0624 21:43:39.678380 24300 net.cpp:425] bn2_1 <- conv2_1
I0624 21:43:39.678385 24300 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0624 21:43:39.679766 24300 net.cpp:141] Setting up bn2_1
I0624 21:43:39.679780 24300 net.cpp:148] Top shape: 32 64 56 72 (8257536)
I0624 21:43:39.679783 24300 net.cpp:156] Memory required for data: 635830656
I0624 21:43:39.679790 24300 layer_factory.hpp:77] Creating layer scale2_1
I0624 21:43:39.679798 24300 net.cpp:91] Creating Layer scale2_1
I0624 21:43:39.679802 24300 net.cpp:425] scale2_1 <- conv2_1
I0624 21:43:39.679808 24300 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0624 21:43:39.679847 24300 layer_factory.hpp:77] Creating layer scale2_1
I0624 21:43:39.679945 24300 net.cpp:141] Setting up scale2_1
I0624 21:43:39.679954 24300 net.cpp:148] Top shape: 32 64 56 72 (8257536)
I0624 21:43:39.679955 24300 net.cpp:156] Memory required for data: 668860800
I0624 21:43:39.679965 24300 layer_factory.hpp:77] Creating layer relu2_1
I0624 21:43:39.679971 24300 net.cpp:91] Creating Layer relu2_1
I0624 21:43:39.679975 24300 net.cpp:425] relu2_1 <- conv2_1
I0624 21:43:39.679981 24300 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0624 21:43:39.680443 24300 net.cpp:141] Setting up relu2_1
I0624 21:43:39.680454 24300 net.cpp:148] Top shape: 32 64 56 72 (8257536)
I0624 21:43:39.680459 24300 net.cpp:156] Memory required for data: 701890944
I0624 21:43:39.680461 24300 layer_factory.hpp:77] Creating layer conv2_2
I0624 21:43:39.680471 24300 net.cpp:91] Creating Layer conv2_2
I0624 21:43:39.680474 24300 net.cpp:425] conv2_2 <- conv2_1
I0624 21:43:39.680485 24300 net.cpp:399] conv2_2 -> conv2_2
I0624 21:43:39.681632 24300 net.cpp:141] Setting up conv2_2
I0624 21:43:39.681645 24300 net.cpp:148] Top shape: 32 64 56 72 (8257536)
I0624 21:43:39.681649 24300 net.cpp:156] Memory required for data: 734921088
I0624 21:43:39.681654 24300 layer_factory.hpp:77] Creating layer bn2_2
I0624 21:43:39.681663 24300 net.cpp:91] Creating Layer bn2_2
I0624 21:43:39.681668 24300 net.cpp:425] bn2_2 <- conv2_2
I0624 21:43:39.681673 24300 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0624 21:43:39.681838 24300 net.cpp:141] Setting up bn2_2
I0624 21:43:39.681845 24300 net.cpp:148] Top shape: 32 64 56 72 (8257536)
I0624 21:43:39.681849 24300 net.cpp:156] Memory required for data: 767951232
I0624 21:43:39.681855 24300 layer_factory.hpp:77] Creating layer scale2_2
I0624 21:43:39.681862 24300 net.cpp:91] Creating Layer scale2_2
I0624 21:43:39.681865 24300 net.cpp:425] scale2_2 <- conv2_2
I0624 21:43:39.681870 24300 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0624 21:43:39.681905 24300 layer_factory.hpp:77] Creating layer scale2_2
I0624 21:43:39.682003 24300 net.cpp:141] Setting up scale2_2
I0624 21:43:39.682011 24300 net.cpp:148] Top shape: 32 64 56 72 (8257536)
I0624 21:43:39.682014 24300 net.cpp:156] Memory required for data: 800981376
I0624 21:43:39.682019 24300 layer_factory.hpp:77] Creating layer relu2_2
I0624 21:43:39.682024 24300 net.cpp:91] Creating Layer relu2_2
I0624 21:43:39.682027 24300 net.cpp:425] relu2_2 <- conv2_2
I0624 21:43:39.682031 24300 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0624 21:43:39.682502 24300 net.cpp:141] Setting up relu2_2
I0624 21:43:39.682518 24300 net.cpp:148] Top shape: 32 64 56 72 (8257536)
I0624 21:43:39.682521 24300 net.cpp:156] Memory required for data: 834011520
I0624 21:43:39.682538 24300 layer_factory.hpp:77] Creating layer pool2
I0624 21:43:39.682545 24300 net.cpp:91] Creating Layer pool2
I0624 21:43:39.682549 24300 net.cpp:425] pool2 <- conv2_2
I0624 21:43:39.682554 24300 net.cpp:399] pool2 -> pool2
I0624 21:43:39.682600 24300 net.cpp:141] Setting up pool2
I0624 21:43:39.682606 24300 net.cpp:148] Top shape: 32 64 28 36 (2064384)
I0624 21:43:39.682610 24300 net.cpp:156] Memory required for data: 842269056
I0624 21:43:39.682612 24300 layer_factory.hpp:77] Creating layer conv3_1
I0624 21:43:39.682621 24300 net.cpp:91] Creating Layer conv3_1
I0624 21:43:39.682624 24300 net.cpp:425] conv3_1 <- pool2
I0624 21:43:39.682628 24300 net.cpp:399] conv3_1 -> conv3_1
I0624 21:43:39.685647 24300 net.cpp:141] Setting up conv3_1
I0624 21:43:39.685664 24300 net.cpp:148] Top shape: 32 128 28 36 (4128768)
I0624 21:43:39.685668 24300 net.cpp:156] Memory required for data: 858784128
I0624 21:43:39.685674 24300 layer_factory.hpp:77] Creating layer bn3_1
I0624 21:43:39.685683 24300 net.cpp:91] Creating Layer bn3_1
I0624 21:43:39.685688 24300 net.cpp:425] bn3_1 <- conv3_1
I0624 21:43:39.685696 24300 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0624 21:43:39.687270 24300 net.cpp:141] Setting up bn3_1
I0624 21:43:39.687286 24300 net.cpp:148] Top shape: 32 128 28 36 (4128768)
I0624 21:43:39.687289 24300 net.cpp:156] Memory required for data: 875299200
I0624 21:43:39.687297 24300 layer_factory.hpp:77] Creating layer scale3_1
I0624 21:43:39.687306 24300 net.cpp:91] Creating Layer scale3_1
I0624 21:43:39.687314 24300 net.cpp:425] scale3_1 <- conv3_1
I0624 21:43:39.687321 24300 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0624 21:43:39.687377 24300 layer_factory.hpp:77] Creating layer scale3_1
I0624 21:43:39.687479 24300 net.cpp:141] Setting up scale3_1
I0624 21:43:39.687500 24300 net.cpp:148] Top shape: 32 128 28 36 (4128768)
I0624 21:43:39.687501 24300 net.cpp:156] Memory required for data: 891814272
I0624 21:43:39.687506 24300 layer_factory.hpp:77] Creating layer relu3_1
I0624 21:43:39.687515 24300 net.cpp:91] Creating Layer relu3_1
I0624 21:43:39.687520 24300 net.cpp:425] relu3_1 <- conv3_1
I0624 21:43:39.687526 24300 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0624 21:43:39.687690 24300 net.cpp:141] Setting up relu3_1
I0624 21:43:39.687700 24300 net.cpp:148] Top shape: 32 128 28 36 (4128768)
I0624 21:43:39.687702 24300 net.cpp:156] Memory required for data: 908329344
I0624 21:43:39.687706 24300 layer_factory.hpp:77] Creating layer conv3_2
I0624 21:43:39.687719 24300 net.cpp:91] Creating Layer conv3_2
I0624 21:43:39.687726 24300 net.cpp:425] conv3_2 <- conv3_1
I0624 21:43:39.687734 24300 net.cpp:399] conv3_2 -> conv3_2
I0624 21:43:39.689729 24300 net.cpp:141] Setting up conv3_2
I0624 21:43:39.689743 24300 net.cpp:148] Top shape: 32 128 28 36 (4128768)
I0624 21:43:39.689745 24300 net.cpp:156] Memory required for data: 924844416
I0624 21:43:39.689750 24300 layer_factory.hpp:77] Creating layer bn3_2
I0624 21:43:39.689756 24300 net.cpp:91] Creating Layer bn3_2
I0624 21:43:39.689759 24300 net.cpp:425] bn3_2 <- conv3_2
I0624 21:43:39.689764 24300 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0624 21:43:39.689939 24300 net.cpp:141] Setting up bn3_2
I0624 21:43:39.689949 24300 net.cpp:148] Top shape: 32 128 28 36 (4128768)
I0624 21:43:39.689951 24300 net.cpp:156] Memory required for data: 941359488
I0624 21:43:39.689966 24300 layer_factory.hpp:77] Creating layer scale3_2
I0624 21:43:39.689977 24300 net.cpp:91] Creating Layer scale3_2
I0624 21:43:39.689981 24300 net.cpp:425] scale3_2 <- conv3_2
I0624 21:43:39.689988 24300 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0624 21:43:39.690040 24300 layer_factory.hpp:77] Creating layer scale3_2
I0624 21:43:39.690160 24300 net.cpp:141] Setting up scale3_2
I0624 21:43:39.690170 24300 net.cpp:148] Top shape: 32 128 28 36 (4128768)
I0624 21:43:39.690173 24300 net.cpp:156] Memory required for data: 957874560
I0624 21:43:39.690181 24300 layer_factory.hpp:77] Creating layer relu3_2
I0624 21:43:39.690189 24300 net.cpp:91] Creating Layer relu3_2
I0624 21:43:39.690196 24300 net.cpp:425] relu3_2 <- conv3_2
I0624 21:43:39.690217 24300 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0624 21:43:39.690357 24300 net.cpp:141] Setting up relu3_2
I0624 21:43:39.690366 24300 net.cpp:148] Top shape: 32 128 28 36 (4128768)
I0624 21:43:39.690368 24300 net.cpp:156] Memory required for data: 974389632
I0624 21:43:39.690371 24300 layer_factory.hpp:77] Creating layer pool3
I0624 21:43:39.690377 24300 net.cpp:91] Creating Layer pool3
I0624 21:43:39.690381 24300 net.cpp:425] pool3 <- conv3_2
I0624 21:43:39.690384 24300 net.cpp:399] pool3 -> pool3
I0624 21:43:39.690418 24300 net.cpp:141] Setting up pool3
I0624 21:43:39.690424 24300 net.cpp:148] Top shape: 32 128 14 18 (1032192)
I0624 21:43:39.690426 24300 net.cpp:156] Memory required for data: 978518400
I0624 21:43:39.690429 24300 layer_factory.hpp:77] Creating layer conv4_1
I0624 21:43:39.690436 24300 net.cpp:91] Creating Layer conv4_1
I0624 21:43:39.690438 24300 net.cpp:425] conv4_1 <- pool3
I0624 21:43:39.690443 24300 net.cpp:399] conv4_1 -> conv4_1
I0624 21:43:39.693305 24300 net.cpp:141] Setting up conv4_1
I0624 21:43:39.693320 24300 net.cpp:148] Top shape: 32 256 14 18 (2064384)
I0624 21:43:39.693322 24300 net.cpp:156] Memory required for data: 986775936
I0624 21:43:39.693326 24300 layer_factory.hpp:77] Creating layer bn4_1
I0624 21:43:39.693333 24300 net.cpp:91] Creating Layer bn4_1
I0624 21:43:39.693336 24300 net.cpp:425] bn4_1 <- conv4_1
I0624 21:43:39.693341 24300 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0624 21:43:39.693486 24300 net.cpp:141] Setting up bn4_1
I0624 21:43:39.693493 24300 net.cpp:148] Top shape: 32 256 14 18 (2064384)
I0624 21:43:39.693495 24300 net.cpp:156] Memory required for data: 995033472
I0624 21:43:39.693501 24300 layer_factory.hpp:77] Creating layer scale4_1
I0624 21:43:39.693507 24300 net.cpp:91] Creating Layer scale4_1
I0624 21:43:39.693511 24300 net.cpp:425] scale4_1 <- conv4_1
I0624 21:43:39.693513 24300 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0624 21:43:39.693544 24300 layer_factory.hpp:77] Creating layer scale4_1
I0624 21:43:39.693620 24300 net.cpp:141] Setting up scale4_1
I0624 21:43:39.693626 24300 net.cpp:148] Top shape: 32 256 14 18 (2064384)
I0624 21:43:39.693629 24300 net.cpp:156] Memory required for data: 1003291008
I0624 21:43:39.693634 24300 layer_factory.hpp:77] Creating layer relu4_1
I0624 21:43:39.693641 24300 net.cpp:91] Creating Layer relu4_1
I0624 21:43:39.693645 24300 net.cpp:425] relu4_1 <- conv4_1
I0624 21:43:39.693647 24300 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0624 21:43:39.693788 24300 net.cpp:141] Setting up relu4_1
I0624 21:43:39.693796 24300 net.cpp:148] Top shape: 32 256 14 18 (2064384)
I0624 21:43:39.693799 24300 net.cpp:156] Memory required for data: 1011548544
I0624 21:43:39.693802 24300 layer_factory.hpp:77] Creating layer conv4_2
I0624 21:43:39.693810 24300 net.cpp:91] Creating Layer conv4_2
I0624 21:43:39.693814 24300 net.cpp:425] conv4_2 <- conv4_1
I0624 21:43:39.693819 24300 net.cpp:399] conv4_2 -> conv4_2
I0624 21:43:39.699669 24300 net.cpp:141] Setting up conv4_2
I0624 21:43:39.699687 24300 net.cpp:148] Top shape: 32 256 14 18 (2064384)
I0624 21:43:39.699689 24300 net.cpp:156] Memory required for data: 1019806080
I0624 21:43:39.699695 24300 layer_factory.hpp:77] Creating layer bn4_2
I0624 21:43:39.699704 24300 net.cpp:91] Creating Layer bn4_2
I0624 21:43:39.699708 24300 net.cpp:425] bn4_2 <- conv4_2
I0624 21:43:39.699713 24300 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0624 21:43:39.699865 24300 net.cpp:141] Setting up bn4_2
I0624 21:43:39.699872 24300 net.cpp:148] Top shape: 32 256 14 18 (2064384)
I0624 21:43:39.699874 24300 net.cpp:156] Memory required for data: 1028063616
I0624 21:43:39.699880 24300 layer_factory.hpp:77] Creating layer scale4_2
I0624 21:43:39.699889 24300 net.cpp:91] Creating Layer scale4_2
I0624 21:43:39.699893 24300 net.cpp:425] scale4_2 <- conv4_2
I0624 21:43:39.699897 24300 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0624 21:43:39.699933 24300 layer_factory.hpp:77] Creating layer scale4_2
I0624 21:43:39.700014 24300 net.cpp:141] Setting up scale4_2
I0624 21:43:39.700021 24300 net.cpp:148] Top shape: 32 256 14 18 (2064384)
I0624 21:43:39.700037 24300 net.cpp:156] Memory required for data: 1036321152
I0624 21:43:39.700042 24300 layer_factory.hpp:77] Creating layer relu4_2
I0624 21:43:39.700048 24300 net.cpp:91] Creating Layer relu4_2
I0624 21:43:39.700052 24300 net.cpp:425] relu4_2 <- conv4_2
I0624 21:43:39.700058 24300 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0624 21:43:39.700265 24300 net.cpp:141] Setting up relu4_2
I0624 21:43:39.700280 24300 net.cpp:148] Top shape: 32 256 14 18 (2064384)
I0624 21:43:39.700284 24300 net.cpp:156] Memory required for data: 1044578688
I0624 21:43:39.700289 24300 layer_factory.hpp:77] Creating layer pool4
I0624 21:43:39.700297 24300 net.cpp:91] Creating Layer pool4
I0624 21:43:39.700302 24300 net.cpp:425] pool4 <- conv4_2
I0624 21:43:39.700310 24300 net.cpp:399] pool4 -> pool4
I0624 21:43:39.700358 24300 net.cpp:141] Setting up pool4
I0624 21:43:39.700368 24300 net.cpp:148] Top shape: 32 256 7 9 (516096)
I0624 21:43:39.700371 24300 net.cpp:156] Memory required for data: 1046643072
I0624 21:43:39.700376 24300 layer_factory.hpp:77] Creating layer conv5_1
I0624 21:43:39.700388 24300 net.cpp:91] Creating Layer conv5_1
I0624 21:43:39.700397 24300 net.cpp:425] conv5_1 <- pool4
I0624 21:43:39.700404 24300 net.cpp:399] conv5_1 -> conv5_1
I0624 21:43:39.707182 24300 net.cpp:141] Setting up conv5_1
I0624 21:43:39.707201 24300 net.cpp:148] Top shape: 32 256 7 9 (516096)
I0624 21:43:39.707204 24300 net.cpp:156] Memory required for data: 1048707456
I0624 21:43:39.707211 24300 layer_factory.hpp:77] Creating layer bn5_1
I0624 21:43:39.707218 24300 net.cpp:91] Creating Layer bn5_1
I0624 21:43:39.707222 24300 net.cpp:425] bn5_1 <- conv5_1
I0624 21:43:39.707227 24300 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0624 21:43:39.707419 24300 net.cpp:141] Setting up bn5_1
I0624 21:43:39.707429 24300 net.cpp:148] Top shape: 32 256 7 9 (516096)
I0624 21:43:39.707442 24300 net.cpp:156] Memory required for data: 1050771840
I0624 21:43:39.707448 24300 layer_factory.hpp:77] Creating layer scale5_1
I0624 21:43:39.707455 24300 net.cpp:91] Creating Layer scale5_1
I0624 21:43:39.707461 24300 net.cpp:425] scale5_1 <- conv5_1
I0624 21:43:39.707468 24300 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0624 21:43:39.707520 24300 layer_factory.hpp:77] Creating layer scale5_1
I0624 21:43:39.707626 24300 net.cpp:141] Setting up scale5_1
I0624 21:43:39.707634 24300 net.cpp:148] Top shape: 32 256 7 9 (516096)
I0624 21:43:39.707638 24300 net.cpp:156] Memory required for data: 1052836224
I0624 21:43:39.707641 24300 layer_factory.hpp:77] Creating layer relu5_1
I0624 21:43:39.707648 24300 net.cpp:91] Creating Layer relu5_1
I0624 21:43:39.707653 24300 net.cpp:425] relu5_1 <- conv5_1
I0624 21:43:39.707659 24300 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0624 21:43:39.708099 24300 net.cpp:141] Setting up relu5_1
I0624 21:43:39.708115 24300 net.cpp:148] Top shape: 32 256 7 9 (516096)
I0624 21:43:39.708120 24300 net.cpp:156] Memory required for data: 1054900608
I0624 21:43:39.708124 24300 layer_factory.hpp:77] Creating layer conv5_2
I0624 21:43:39.708133 24300 net.cpp:91] Creating Layer conv5_2
I0624 21:43:39.708137 24300 net.cpp:425] conv5_2 <- conv5_1
I0624 21:43:39.708142 24300 net.cpp:399] conv5_2 -> conv5_2
I0624 21:43:39.713654 24300 net.cpp:141] Setting up conv5_2
I0624 21:43:39.713667 24300 net.cpp:148] Top shape: 32 256 7 9 (516096)
I0624 21:43:39.713670 24300 net.cpp:156] Memory required for data: 1056964992
I0624 21:43:39.713675 24300 layer_factory.hpp:77] Creating layer bn5_2
I0624 21:43:39.713682 24300 net.cpp:91] Creating Layer bn5_2
I0624 21:43:39.713685 24300 net.cpp:425] bn5_2 <- conv5_2
I0624 21:43:39.713690 24300 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0624 21:43:39.713862 24300 net.cpp:141] Setting up bn5_2
I0624 21:43:39.713874 24300 net.cpp:148] Top shape: 32 256 7 9 (516096)
I0624 21:43:39.713876 24300 net.cpp:156] Memory required for data: 1059029376
I0624 21:43:39.713886 24300 layer_factory.hpp:77] Creating layer scale5_2
I0624 21:43:39.713896 24300 net.cpp:91] Creating Layer scale5_2
I0624 21:43:39.713917 24300 net.cpp:425] scale5_2 <- conv5_2
I0624 21:43:39.713928 24300 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0624 21:43:39.713968 24300 layer_factory.hpp:77] Creating layer scale5_2
I0624 21:43:39.714057 24300 net.cpp:141] Setting up scale5_2
I0624 21:43:39.714063 24300 net.cpp:148] Top shape: 32 256 7 9 (516096)
I0624 21:43:39.714066 24300 net.cpp:156] Memory required for data: 1061093760
I0624 21:43:39.714071 24300 layer_factory.hpp:77] Creating layer relu5_2
I0624 21:43:39.714074 24300 net.cpp:91] Creating Layer relu5_2
I0624 21:43:39.714077 24300 net.cpp:425] relu5_2 <- conv5_2
I0624 21:43:39.714082 24300 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0624 21:43:39.714581 24300 net.cpp:141] Setting up relu5_2
I0624 21:43:39.714592 24300 net.cpp:148] Top shape: 32 256 7 9 (516096)
I0624 21:43:39.714596 24300 net.cpp:156] Memory required for data: 1063158144
I0624 21:43:39.714598 24300 layer_factory.hpp:77] Creating layer pool5
I0624 21:43:39.714607 24300 net.cpp:91] Creating Layer pool5
I0624 21:43:39.714609 24300 net.cpp:425] pool5 <- conv5_2
I0624 21:43:39.714613 24300 net.cpp:399] pool5 -> pool5
I0624 21:43:39.714774 24300 net.cpp:141] Setting up pool5
I0624 21:43:39.714783 24300 net.cpp:148] Top shape: 32 256 1 1 (8192)
I0624 21:43:39.714787 24300 net.cpp:156] Memory required for data: 1063190912
I0624 21:43:39.714788 24300 layer_factory.hpp:77] Creating layer fc2
I0624 21:43:39.714794 24300 net.cpp:91] Creating Layer fc2
I0624 21:43:39.714797 24300 net.cpp:425] fc2 <- pool5
I0624 21:43:39.714803 24300 net.cpp:399] fc2 -> fc2
I0624 21:43:39.714902 24300 net.cpp:141] Setting up fc2
I0624 21:43:39.714910 24300 net.cpp:148] Top shape: 32 2 (64)
I0624 21:43:39.714911 24300 net.cpp:156] Memory required for data: 1063191168
I0624 21:43:39.714915 24300 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0624 21:43:39.714921 24300 net.cpp:91] Creating Layer fc2_fc2_0_split
I0624 21:43:39.714923 24300 net.cpp:425] fc2_fc2_0_split <- fc2
I0624 21:43:39.714928 24300 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0624 21:43:39.714932 24300 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0624 21:43:39.714961 24300 net.cpp:141] Setting up fc2_fc2_0_split
I0624 21:43:39.714964 24300 net.cpp:148] Top shape: 32 2 (64)
I0624 21:43:39.714967 24300 net.cpp:148] Top shape: 32 2 (64)
I0624 21:43:39.714969 24300 net.cpp:156] Memory required for data: 1063191680
I0624 21:43:39.714972 24300 layer_factory.hpp:77] Creating layer loss
I0624 21:43:39.714982 24300 net.cpp:91] Creating Layer loss
I0624 21:43:39.714984 24300 net.cpp:425] loss <- fc2_fc2_0_split_0
I0624 21:43:39.714987 24300 net.cpp:425] loss <- label_data_1_split_0
I0624 21:43:39.714998 24300 net.cpp:399] loss -> loss
I0624 21:43:39.715005 24300 layer_factory.hpp:77] Creating layer loss
I0624 21:43:39.715252 24300 net.cpp:141] Setting up loss
I0624 21:43:39.715263 24300 net.cpp:148] Top shape: (1)
I0624 21:43:39.715265 24300 net.cpp:151]     with loss weight 1
I0624 21:43:39.715281 24300 net.cpp:156] Memory required for data: 1063191684
I0624 21:43:39.715282 24300 layer_factory.hpp:77] Creating layer accuracy
I0624 21:43:39.715288 24300 net.cpp:91] Creating Layer accuracy
I0624 21:43:39.715291 24300 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0624 21:43:39.715294 24300 net.cpp:425] accuracy <- label_data_1_split_1
I0624 21:43:39.715301 24300 net.cpp:399] accuracy -> accuracy
I0624 21:43:39.715308 24300 net.cpp:141] Setting up accuracy
I0624 21:43:39.715312 24300 net.cpp:148] Top shape: (1)
I0624 21:43:39.715313 24300 net.cpp:156] Memory required for data: 1063191688
I0624 21:43:39.715315 24300 net.cpp:219] accuracy does not need backward computation.
I0624 21:43:39.715318 24300 net.cpp:217] loss needs backward computation.
I0624 21:43:39.715322 24300 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0624 21:43:39.715323 24300 net.cpp:217] fc2 needs backward computation.
I0624 21:43:39.715325 24300 net.cpp:217] pool5 needs backward computation.
I0624 21:43:39.715327 24300 net.cpp:217] relu5_2 needs backward computation.
I0624 21:43:39.715330 24300 net.cpp:217] scale5_2 needs backward computation.
I0624 21:43:39.715342 24300 net.cpp:217] bn5_2 needs backward computation.
I0624 21:43:39.715344 24300 net.cpp:217] conv5_2 needs backward computation.
I0624 21:43:39.715348 24300 net.cpp:217] relu5_1 needs backward computation.
I0624 21:43:39.715349 24300 net.cpp:217] scale5_1 needs backward computation.
I0624 21:43:39.715351 24300 net.cpp:217] bn5_1 needs backward computation.
I0624 21:43:39.715353 24300 net.cpp:217] conv5_1 needs backward computation.
I0624 21:43:39.715356 24300 net.cpp:217] pool4 needs backward computation.
I0624 21:43:39.715358 24300 net.cpp:217] relu4_2 needs backward computation.
I0624 21:43:39.715360 24300 net.cpp:217] scale4_2 needs backward computation.
I0624 21:43:39.715363 24300 net.cpp:217] bn4_2 needs backward computation.
I0624 21:43:39.715365 24300 net.cpp:217] conv4_2 needs backward computation.
I0624 21:43:39.715368 24300 net.cpp:217] relu4_1 needs backward computation.
I0624 21:43:39.715369 24300 net.cpp:217] scale4_1 needs backward computation.
I0624 21:43:39.715373 24300 net.cpp:217] bn4_1 needs backward computation.
I0624 21:43:39.715374 24300 net.cpp:217] conv4_1 needs backward computation.
I0624 21:43:39.715376 24300 net.cpp:217] pool3 needs backward computation.
I0624 21:43:39.715379 24300 net.cpp:217] relu3_2 needs backward computation.
I0624 21:43:39.715381 24300 net.cpp:217] scale3_2 needs backward computation.
I0624 21:43:39.715384 24300 net.cpp:217] bn3_2 needs backward computation.
I0624 21:43:39.715385 24300 net.cpp:217] conv3_2 needs backward computation.
I0624 21:43:39.715389 24300 net.cpp:217] relu3_1 needs backward computation.
I0624 21:43:39.715390 24300 net.cpp:217] scale3_1 needs backward computation.
I0624 21:43:39.715392 24300 net.cpp:217] bn3_1 needs backward computation.
I0624 21:43:39.715395 24300 net.cpp:217] conv3_1 needs backward computation.
I0624 21:43:39.715397 24300 net.cpp:217] pool2 needs backward computation.
I0624 21:43:39.715399 24300 net.cpp:217] relu2_2 needs backward computation.
I0624 21:43:39.715402 24300 net.cpp:217] scale2_2 needs backward computation.
I0624 21:43:39.715404 24300 net.cpp:217] bn2_2 needs backward computation.
I0624 21:43:39.715406 24300 net.cpp:217] conv2_2 needs backward computation.
I0624 21:43:39.715409 24300 net.cpp:217] relu2_1 needs backward computation.
I0624 21:43:39.715411 24300 net.cpp:217] scale2_1 needs backward computation.
I0624 21:43:39.715415 24300 net.cpp:217] bn2_1 needs backward computation.
I0624 21:43:39.715416 24300 net.cpp:217] conv2_1 needs backward computation.
I0624 21:43:39.715418 24300 net.cpp:217] pool1 needs backward computation.
I0624 21:43:39.715421 24300 net.cpp:217] relu1_2 needs backward computation.
I0624 21:43:39.715423 24300 net.cpp:217] scale1_2 needs backward computation.
I0624 21:43:39.715425 24300 net.cpp:217] bn1_2 needs backward computation.
I0624 21:43:39.715427 24300 net.cpp:217] conv1_2 needs backward computation.
I0624 21:43:39.715430 24300 net.cpp:217] relu1_1 needs backward computation.
I0624 21:43:39.715432 24300 net.cpp:217] scale1_1 needs backward computation.
I0624 21:43:39.715435 24300 net.cpp:217] bn1_1 needs backward computation.
I0624 21:43:39.715436 24300 net.cpp:217] conv1_1 needs backward computation.
I0624 21:43:39.715440 24300 net.cpp:219] label_data_1_split does not need backward computation.
I0624 21:43:39.715442 24300 net.cpp:219] data does not need backward computation.
I0624 21:43:39.715445 24300 net.cpp:261] This network produces output accuracy
I0624 21:43:39.715447 24300 net.cpp:261] This network produces output loss
I0624 21:43:39.715468 24300 net.cpp:274] Network initialization done.
I0624 21:43:39.716356 24300 solver.cpp:181] Creating test net (#0) specified by net file: models/bpnet/train_val.prototxt
I0624 21:43:39.716413 24300 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0624 21:43:39.716642 24300 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 100
    crop_h: 224
    crop_w: 288
    contrast_jitter_range: 0.1
  }
  data_param {
    source: "data/val_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  pooling_param {
    pool: AVE
    stride: 1
    kernel_h: 7
    kernel_w: 9
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0624 21:43:39.716789 24300 layer_factory.hpp:77] Creating layer data
I0624 21:43:39.717036 24300 net.cpp:91] Creating Layer data
I0624 21:43:39.717046 24300 net.cpp:399] data -> data
I0624 21:43:39.717072 24300 net.cpp:399] data -> label
I0624 21:43:39.717965 24313 db_lmdb.cpp:35] Opened lmdb data/val_lmdb
I0624 21:43:39.718272 24300 data_layer.cpp:42] output data size: 64,3,224,288
I0624 21:43:39.824208 24300 net.cpp:141] Setting up data
I0624 21:43:39.824232 24300 net.cpp:148] Top shape: 64 3 224 288 (12386304)
I0624 21:43:39.824236 24300 net.cpp:148] Top shape: 64 (64)
I0624 21:43:39.824239 24300 net.cpp:156] Memory required for data: 49545472
I0624 21:43:39.824244 24300 layer_factory.hpp:77] Creating layer label_data_1_split
I0624 21:43:39.824255 24300 net.cpp:91] Creating Layer label_data_1_split
I0624 21:43:39.824259 24300 net.cpp:425] label_data_1_split <- label
I0624 21:43:39.824265 24300 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0624 21:43:39.824273 24300 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0624 21:43:39.824424 24300 net.cpp:141] Setting up label_data_1_split
I0624 21:43:39.824431 24300 net.cpp:148] Top shape: 64 (64)
I0624 21:43:39.824434 24300 net.cpp:148] Top shape: 64 (64)
I0624 21:43:39.824436 24300 net.cpp:156] Memory required for data: 49545984
I0624 21:43:39.824439 24300 layer_factory.hpp:77] Creating layer conv1_1
I0624 21:43:39.824450 24300 net.cpp:91] Creating Layer conv1_1
I0624 21:43:39.824453 24300 net.cpp:425] conv1_1 <- data
I0624 21:43:39.824457 24300 net.cpp:399] conv1_1 -> conv1_1
I0624 21:43:39.825573 24300 net.cpp:141] Setting up conv1_1
I0624 21:43:39.825587 24300 net.cpp:148] Top shape: 64 32 112 144 (33030144)
I0624 21:43:39.825589 24300 net.cpp:156] Memory required for data: 181666560
I0624 21:43:39.825597 24300 layer_factory.hpp:77] Creating layer bn1_1
I0624 21:43:39.825604 24300 net.cpp:91] Creating Layer bn1_1
I0624 21:43:39.825608 24300 net.cpp:425] bn1_1 <- conv1_1
I0624 21:43:39.825611 24300 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0624 21:43:39.825867 24300 net.cpp:141] Setting up bn1_1
I0624 21:43:39.825875 24300 net.cpp:148] Top shape: 64 32 112 144 (33030144)
I0624 21:43:39.825877 24300 net.cpp:156] Memory required for data: 313787136
I0624 21:43:39.825886 24300 layer_factory.hpp:77] Creating layer scale1_1
I0624 21:43:39.825893 24300 net.cpp:91] Creating Layer scale1_1
I0624 21:43:39.825911 24300 net.cpp:425] scale1_1 <- conv1_1
I0624 21:43:39.825917 24300 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0624 21:43:39.829716 24300 layer_factory.hpp:77] Creating layer scale1_1
I0624 21:43:39.829838 24300 net.cpp:141] Setting up scale1_1
I0624 21:43:39.829844 24300 net.cpp:148] Top shape: 64 32 112 144 (33030144)
I0624 21:43:39.829848 24300 net.cpp:156] Memory required for data: 445907712
I0624 21:43:39.829854 24300 layer_factory.hpp:77] Creating layer relu1_1
I0624 21:43:39.829859 24300 net.cpp:91] Creating Layer relu1_1
I0624 21:43:39.829861 24300 net.cpp:425] relu1_1 <- conv1_1
I0624 21:43:39.829865 24300 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0624 21:43:39.830016 24300 net.cpp:141] Setting up relu1_1
I0624 21:43:39.830024 24300 net.cpp:148] Top shape: 64 32 112 144 (33030144)
I0624 21:43:39.830026 24300 net.cpp:156] Memory required for data: 578028288
I0624 21:43:39.830029 24300 layer_factory.hpp:77] Creating layer conv1_2
I0624 21:43:39.830037 24300 net.cpp:91] Creating Layer conv1_2
I0624 21:43:39.830039 24300 net.cpp:425] conv1_2 <- conv1_1
I0624 21:43:39.830044 24300 net.cpp:399] conv1_2 -> conv1_2
I0624 21:43:39.830941 24300 net.cpp:141] Setting up conv1_2
I0624 21:43:39.830955 24300 net.cpp:148] Top shape: 64 32 112 144 (33030144)
I0624 21:43:39.830958 24300 net.cpp:156] Memory required for data: 710148864
I0624 21:43:39.830962 24300 layer_factory.hpp:77] Creating layer bn1_2
I0624 21:43:39.830970 24300 net.cpp:91] Creating Layer bn1_2
I0624 21:43:39.830971 24300 net.cpp:425] bn1_2 <- conv1_2
I0624 21:43:39.830976 24300 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0624 21:43:39.831143 24300 net.cpp:141] Setting up bn1_2
I0624 21:43:39.831161 24300 net.cpp:148] Top shape: 64 32 112 144 (33030144)
I0624 21:43:39.831163 24300 net.cpp:156] Memory required for data: 842269440
I0624 21:43:39.831171 24300 layer_factory.hpp:77] Creating layer scale1_2
I0624 21:43:39.831177 24300 net.cpp:91] Creating Layer scale1_2
I0624 21:43:39.831181 24300 net.cpp:425] scale1_2 <- conv1_2
I0624 21:43:39.831184 24300 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0624 21:43:39.831218 24300 layer_factory.hpp:77] Creating layer scale1_2
I0624 21:43:39.831326 24300 net.cpp:141] Setting up scale1_2
I0624 21:43:39.831332 24300 net.cpp:148] Top shape: 64 32 112 144 (33030144)
I0624 21:43:39.831334 24300 net.cpp:156] Memory required for data: 974390016
I0624 21:43:39.831338 24300 layer_factory.hpp:77] Creating layer relu1_2
I0624 21:43:39.831342 24300 net.cpp:91] Creating Layer relu1_2
I0624 21:43:39.831344 24300 net.cpp:425] relu1_2 <- conv1_2
I0624 21:43:39.831348 24300 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0624 21:43:39.831760 24300 net.cpp:141] Setting up relu1_2
I0624 21:43:39.831771 24300 net.cpp:148] Top shape: 64 32 112 144 (33030144)
I0624 21:43:39.831773 24300 net.cpp:156] Memory required for data: 1106510592
I0624 21:43:39.831776 24300 layer_factory.hpp:77] Creating layer pool1
I0624 21:43:39.831782 24300 net.cpp:91] Creating Layer pool1
I0624 21:43:39.831784 24300 net.cpp:425] pool1 <- conv1_2
I0624 21:43:39.831789 24300 net.cpp:399] pool1 -> pool1
I0624 21:43:39.831828 24300 net.cpp:141] Setting up pool1
I0624 21:43:39.831832 24300 net.cpp:148] Top shape: 64 32 56 72 (8257536)
I0624 21:43:39.831835 24300 net.cpp:156] Memory required for data: 1139540736
I0624 21:43:39.831837 24300 layer_factory.hpp:77] Creating layer conv2_1
I0624 21:43:39.831845 24300 net.cpp:91] Creating Layer conv2_1
I0624 21:43:39.831846 24300 net.cpp:425] conv2_1 <- pool1
I0624 21:43:39.831851 24300 net.cpp:399] conv2_1 -> conv2_1
I0624 21:43:39.832789 24300 net.cpp:141] Setting up conv2_1
I0624 21:43:39.832801 24300 net.cpp:148] Top shape: 64 64 56 72 (16515072)
I0624 21:43:39.832803 24300 net.cpp:156] Memory required for data: 1205601024
I0624 21:43:39.832808 24300 layer_factory.hpp:77] Creating layer bn2_1
I0624 21:43:39.832814 24300 net.cpp:91] Creating Layer bn2_1
I0624 21:43:39.832818 24300 net.cpp:425] bn2_1 <- conv2_1
I0624 21:43:39.832821 24300 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0624 21:43:39.832993 24300 net.cpp:141] Setting up bn2_1
I0624 21:43:39.833001 24300 net.cpp:148] Top shape: 64 64 56 72 (16515072)
I0624 21:43:39.833003 24300 net.cpp:156] Memory required for data: 1271661312
I0624 21:43:39.833009 24300 layer_factory.hpp:77] Creating layer scale2_1
I0624 21:43:39.833014 24300 net.cpp:91] Creating Layer scale2_1
I0624 21:43:39.833016 24300 net.cpp:425] scale2_1 <- conv2_1
I0624 21:43:39.833020 24300 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0624 21:43:39.833052 24300 layer_factory.hpp:77] Creating layer scale2_1
I0624 21:43:39.833151 24300 net.cpp:141] Setting up scale2_1
I0624 21:43:39.833158 24300 net.cpp:148] Top shape: 64 64 56 72 (16515072)
I0624 21:43:39.833159 24300 net.cpp:156] Memory required for data: 1337721600
I0624 21:43:39.833166 24300 layer_factory.hpp:77] Creating layer relu2_1
I0624 21:43:39.833176 24300 net.cpp:91] Creating Layer relu2_1
I0624 21:43:39.833178 24300 net.cpp:425] relu2_1 <- conv2_1
I0624 21:43:39.833181 24300 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0624 21:43:39.833319 24300 net.cpp:141] Setting up relu2_1
I0624 21:43:39.833328 24300 net.cpp:148] Top shape: 64 64 56 72 (16515072)
I0624 21:43:39.833330 24300 net.cpp:156] Memory required for data: 1403781888
I0624 21:43:39.833333 24300 layer_factory.hpp:77] Creating layer conv2_2
I0624 21:43:39.833343 24300 net.cpp:91] Creating Layer conv2_2
I0624 21:43:39.833345 24300 net.cpp:425] conv2_2 <- conv2_1
I0624 21:43:39.833348 24300 net.cpp:399] conv2_2 -> conv2_2
I0624 21:43:39.834403 24300 net.cpp:141] Setting up conv2_2
I0624 21:43:39.834416 24300 net.cpp:148] Top shape: 64 64 56 72 (16515072)
I0624 21:43:39.834419 24300 net.cpp:156] Memory required for data: 1469842176
I0624 21:43:39.834424 24300 layer_factory.hpp:77] Creating layer bn2_2
I0624 21:43:39.834429 24300 net.cpp:91] Creating Layer bn2_2
I0624 21:43:39.834432 24300 net.cpp:425] bn2_2 <- conv2_2
I0624 21:43:39.834437 24300 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0624 21:43:39.834594 24300 net.cpp:141] Setting up bn2_2
I0624 21:43:39.834600 24300 net.cpp:148] Top shape: 64 64 56 72 (16515072)
I0624 21:43:39.834602 24300 net.cpp:156] Memory required for data: 1535902464
I0624 21:43:39.834609 24300 layer_factory.hpp:77] Creating layer scale2_2
I0624 21:43:39.834614 24300 net.cpp:91] Creating Layer scale2_2
I0624 21:43:39.834616 24300 net.cpp:425] scale2_2 <- conv2_2
I0624 21:43:39.834620 24300 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0624 21:43:39.834651 24300 layer_factory.hpp:77] Creating layer scale2_2
I0624 21:43:39.834746 24300 net.cpp:141] Setting up scale2_2
I0624 21:43:39.834753 24300 net.cpp:148] Top shape: 64 64 56 72 (16515072)
I0624 21:43:39.834755 24300 net.cpp:156] Memory required for data: 1601962752
I0624 21:43:39.834759 24300 layer_factory.hpp:77] Creating layer relu2_2
I0624 21:43:39.834764 24300 net.cpp:91] Creating Layer relu2_2
I0624 21:43:39.834766 24300 net.cpp:425] relu2_2 <- conv2_2
I0624 21:43:39.834776 24300 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0624 21:43:39.834926 24300 net.cpp:141] Setting up relu2_2
I0624 21:43:39.834935 24300 net.cpp:148] Top shape: 64 64 56 72 (16515072)
I0624 21:43:39.834938 24300 net.cpp:156] Memory required for data: 1668023040
I0624 21:43:39.834940 24300 layer_factory.hpp:77] Creating layer pool2
I0624 21:43:39.834945 24300 net.cpp:91] Creating Layer pool2
I0624 21:43:39.834947 24300 net.cpp:425] pool2 <- conv2_2
I0624 21:43:39.834952 24300 net.cpp:399] pool2 -> pool2
I0624 21:43:39.834987 24300 net.cpp:141] Setting up pool2
I0624 21:43:39.834992 24300 net.cpp:148] Top shape: 64 64 28 36 (4128768)
I0624 21:43:39.834995 24300 net.cpp:156] Memory required for data: 1684538112
I0624 21:43:39.834997 24300 layer_factory.hpp:77] Creating layer conv3_1
I0624 21:43:39.835007 24300 net.cpp:91] Creating Layer conv3_1
I0624 21:43:39.835010 24300 net.cpp:425] conv3_1 <- pool2
I0624 21:43:39.835013 24300 net.cpp:399] conv3_1 -> conv3_1
I0624 21:43:39.838232 24300 net.cpp:141] Setting up conv3_1
I0624 21:43:39.838248 24300 net.cpp:148] Top shape: 64 128 28 36 (8257536)
I0624 21:43:39.838251 24300 net.cpp:156] Memory required for data: 1717568256
I0624 21:43:39.838269 24300 layer_factory.hpp:77] Creating layer bn3_1
I0624 21:43:39.838277 24300 net.cpp:91] Creating Layer bn3_1
I0624 21:43:39.838280 24300 net.cpp:425] bn3_1 <- conv3_1
I0624 21:43:39.838286 24300 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0624 21:43:39.838449 24300 net.cpp:141] Setting up bn3_1
I0624 21:43:39.838455 24300 net.cpp:148] Top shape: 64 128 28 36 (8257536)
I0624 21:43:39.838457 24300 net.cpp:156] Memory required for data: 1750598400
I0624 21:43:39.838464 24300 layer_factory.hpp:77] Creating layer scale3_1
I0624 21:43:39.838469 24300 net.cpp:91] Creating Layer scale3_1
I0624 21:43:39.838472 24300 net.cpp:425] scale3_1 <- conv3_1
I0624 21:43:39.838476 24300 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0624 21:43:39.838508 24300 layer_factory.hpp:77] Creating layer scale3_1
I0624 21:43:39.838608 24300 net.cpp:141] Setting up scale3_1
I0624 21:43:39.838614 24300 net.cpp:148] Top shape: 64 128 28 36 (8257536)
I0624 21:43:39.838616 24300 net.cpp:156] Memory required for data: 1783628544
I0624 21:43:39.838620 24300 layer_factory.hpp:77] Creating layer relu3_1
I0624 21:43:39.838624 24300 net.cpp:91] Creating Layer relu3_1
I0624 21:43:39.838627 24300 net.cpp:425] relu3_1 <- conv3_1
I0624 21:43:39.838630 24300 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0624 21:43:39.838778 24300 net.cpp:141] Setting up relu3_1
I0624 21:43:39.838786 24300 net.cpp:148] Top shape: 64 128 28 36 (8257536)
I0624 21:43:39.838788 24300 net.cpp:156] Memory required for data: 1816658688
I0624 21:43:39.838791 24300 layer_factory.hpp:77] Creating layer conv3_2
I0624 21:43:39.838799 24300 net.cpp:91] Creating Layer conv3_2
I0624 21:43:39.838802 24300 net.cpp:425] conv3_2 <- conv3_1
I0624 21:43:39.838807 24300 net.cpp:399] conv3_2 -> conv3_2
I0624 21:43:39.840823 24300 net.cpp:141] Setting up conv3_2
I0624 21:43:39.840836 24300 net.cpp:148] Top shape: 64 128 28 36 (8257536)
I0624 21:43:39.840838 24300 net.cpp:156] Memory required for data: 1849688832
I0624 21:43:39.840842 24300 layer_factory.hpp:77] Creating layer bn3_2
I0624 21:43:39.840850 24300 net.cpp:91] Creating Layer bn3_2
I0624 21:43:39.840852 24300 net.cpp:425] bn3_2 <- conv3_2
I0624 21:43:39.840857 24300 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0624 21:43:39.841015 24300 net.cpp:141] Setting up bn3_2
I0624 21:43:39.841022 24300 net.cpp:148] Top shape: 64 128 28 36 (8257536)
I0624 21:43:39.841024 24300 net.cpp:156] Memory required for data: 1882718976
I0624 21:43:39.841037 24300 layer_factory.hpp:77] Creating layer scale3_2
I0624 21:43:39.841042 24300 net.cpp:91] Creating Layer scale3_2
I0624 21:43:39.841044 24300 net.cpp:425] scale3_2 <- conv3_2
I0624 21:43:39.841048 24300 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0624 21:43:39.841083 24300 layer_factory.hpp:77] Creating layer scale3_2
I0624 21:43:39.841172 24300 net.cpp:141] Setting up scale3_2
I0624 21:43:39.841178 24300 net.cpp:148] Top shape: 64 128 28 36 (8257536)
I0624 21:43:39.841181 24300 net.cpp:156] Memory required for data: 1915749120
I0624 21:43:39.841184 24300 layer_factory.hpp:77] Creating layer relu3_2
I0624 21:43:39.841188 24300 net.cpp:91] Creating Layer relu3_2
I0624 21:43:39.841192 24300 net.cpp:425] relu3_2 <- conv3_2
I0624 21:43:39.841195 24300 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0624 21:43:39.841339 24300 net.cpp:141] Setting up relu3_2
I0624 21:43:39.841347 24300 net.cpp:148] Top shape: 64 128 28 36 (8257536)
I0624 21:43:39.841351 24300 net.cpp:156] Memory required for data: 1948779264
I0624 21:43:39.841353 24300 layer_factory.hpp:77] Creating layer pool3
I0624 21:43:39.841359 24300 net.cpp:91] Creating Layer pool3
I0624 21:43:39.841361 24300 net.cpp:425] pool3 <- conv3_2
I0624 21:43:39.841366 24300 net.cpp:399] pool3 -> pool3
I0624 21:43:39.841403 24300 net.cpp:141] Setting up pool3
I0624 21:43:39.841409 24300 net.cpp:148] Top shape: 64 128 14 18 (2064384)
I0624 21:43:39.841411 24300 net.cpp:156] Memory required for data: 1957036800
I0624 21:43:39.841413 24300 layer_factory.hpp:77] Creating layer conv4_1
I0624 21:43:39.841421 24300 net.cpp:91] Creating Layer conv4_1
I0624 21:43:39.841434 24300 net.cpp:425] conv4_1 <- pool3
I0624 21:43:39.841439 24300 net.cpp:399] conv4_1 -> conv4_1
I0624 21:43:39.844240 24300 net.cpp:141] Setting up conv4_1
I0624 21:43:39.844254 24300 net.cpp:148] Top shape: 64 256 14 18 (4128768)
I0624 21:43:39.844256 24300 net.cpp:156] Memory required for data: 1973551872
I0624 21:43:39.844260 24300 layer_factory.hpp:77] Creating layer bn4_1
I0624 21:43:39.844267 24300 net.cpp:91] Creating Layer bn4_1
I0624 21:43:39.844270 24300 net.cpp:425] bn4_1 <- conv4_1
I0624 21:43:39.844274 24300 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0624 21:43:39.844429 24300 net.cpp:141] Setting up bn4_1
I0624 21:43:39.844435 24300 net.cpp:148] Top shape: 64 256 14 18 (4128768)
I0624 21:43:39.844439 24300 net.cpp:156] Memory required for data: 1990066944
I0624 21:43:39.844444 24300 layer_factory.hpp:77] Creating layer scale4_1
I0624 21:43:39.844449 24300 net.cpp:91] Creating Layer scale4_1
I0624 21:43:39.844451 24300 net.cpp:425] scale4_1 <- conv4_1
I0624 21:43:39.844458 24300 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0624 21:43:39.844491 24300 layer_factory.hpp:77] Creating layer scale4_1
I0624 21:43:39.844576 24300 net.cpp:141] Setting up scale4_1
I0624 21:43:39.844583 24300 net.cpp:148] Top shape: 64 256 14 18 (4128768)
I0624 21:43:39.844584 24300 net.cpp:156] Memory required for data: 2006582016
I0624 21:43:39.844588 24300 layer_factory.hpp:77] Creating layer relu4_1
I0624 21:43:39.844601 24300 net.cpp:91] Creating Layer relu4_1
I0624 21:43:39.844604 24300 net.cpp:425] relu4_1 <- conv4_1
I0624 21:43:39.844607 24300 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0624 21:43:39.844755 24300 net.cpp:141] Setting up relu4_1
I0624 21:43:39.844763 24300 net.cpp:148] Top shape: 64 256 14 18 (4128768)
I0624 21:43:39.844766 24300 net.cpp:156] Memory required for data: 2023097088
I0624 21:43:39.844769 24300 layer_factory.hpp:77] Creating layer conv4_2
I0624 21:43:39.844776 24300 net.cpp:91] Creating Layer conv4_2
I0624 21:43:39.844779 24300 net.cpp:425] conv4_2 <- conv4_1
I0624 21:43:39.844784 24300 net.cpp:399] conv4_2 -> conv4_2
I0624 21:43:39.850320 24300 net.cpp:141] Setting up conv4_2
I0624 21:43:39.850334 24300 net.cpp:148] Top shape: 64 256 14 18 (4128768)
I0624 21:43:39.850338 24300 net.cpp:156] Memory required for data: 2039612160
I0624 21:43:39.850342 24300 layer_factory.hpp:77] Creating layer bn4_2
I0624 21:43:39.850350 24300 net.cpp:91] Creating Layer bn4_2
I0624 21:43:39.850353 24300 net.cpp:425] bn4_2 <- conv4_2
I0624 21:43:39.850358 24300 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0624 21:43:39.850518 24300 net.cpp:141] Setting up bn4_2
I0624 21:43:39.850525 24300 net.cpp:148] Top shape: 64 256 14 18 (4128768)
I0624 21:43:39.850528 24300 net.cpp:156] Memory required for data: 2056127232
I0624 21:43:39.850533 24300 layer_factory.hpp:77] Creating layer scale4_2
I0624 21:43:39.850539 24300 net.cpp:91] Creating Layer scale4_2
I0624 21:43:39.850541 24300 net.cpp:425] scale4_2 <- conv4_2
I0624 21:43:39.850545 24300 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0624 21:43:39.850581 24300 layer_factory.hpp:77] Creating layer scale4_2
I0624 21:43:39.850669 24300 net.cpp:141] Setting up scale4_2
I0624 21:43:39.850675 24300 net.cpp:148] Top shape: 64 256 14 18 (4128768)
I0624 21:43:39.850677 24300 net.cpp:156] Memory required for data: 2072642304
I0624 21:43:39.850682 24300 layer_factory.hpp:77] Creating layer relu4_2
I0624 21:43:39.850687 24300 net.cpp:91] Creating Layer relu4_2
I0624 21:43:39.850688 24300 net.cpp:425] relu4_2 <- conv4_2
I0624 21:43:39.850692 24300 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0624 21:43:39.851117 24300 net.cpp:141] Setting up relu4_2
I0624 21:43:39.851128 24300 net.cpp:148] Top shape: 64 256 14 18 (4128768)
I0624 21:43:39.851130 24300 net.cpp:156] Memory required for data: 2089157376
I0624 21:43:39.851133 24300 layer_factory.hpp:77] Creating layer pool4
I0624 21:43:39.851140 24300 net.cpp:91] Creating Layer pool4
I0624 21:43:39.851142 24300 net.cpp:425] pool4 <- conv4_2
I0624 21:43:39.851153 24300 net.cpp:399] pool4 -> pool4
I0624 21:43:39.851208 24300 net.cpp:141] Setting up pool4
I0624 21:43:39.851213 24300 net.cpp:148] Top shape: 64 256 7 9 (1032192)
I0624 21:43:39.851217 24300 net.cpp:156] Memory required for data: 2093286144
I0624 21:43:39.851218 24300 layer_factory.hpp:77] Creating layer conv5_1
I0624 21:43:39.851227 24300 net.cpp:91] Creating Layer conv5_1
I0624 21:43:39.851230 24300 net.cpp:425] conv5_1 <- pool4
I0624 21:43:39.851233 24300 net.cpp:399] conv5_1 -> conv5_1
I0624 21:43:39.857182 24300 net.cpp:141] Setting up conv5_1
I0624 21:43:39.857200 24300 net.cpp:148] Top shape: 64 256 7 9 (1032192)
I0624 21:43:39.857203 24300 net.cpp:156] Memory required for data: 2097414912
I0624 21:43:39.857208 24300 layer_factory.hpp:77] Creating layer bn5_1
I0624 21:43:39.857218 24300 net.cpp:91] Creating Layer bn5_1
I0624 21:43:39.857221 24300 net.cpp:425] bn5_1 <- conv5_1
I0624 21:43:39.857228 24300 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0624 21:43:39.857400 24300 net.cpp:141] Setting up bn5_1
I0624 21:43:39.857408 24300 net.cpp:148] Top shape: 64 256 7 9 (1032192)
I0624 21:43:39.857410 24300 net.cpp:156] Memory required for data: 2101543680
I0624 21:43:39.857416 24300 layer_factory.hpp:77] Creating layer scale5_1
I0624 21:43:39.857424 24300 net.cpp:91] Creating Layer scale5_1
I0624 21:43:39.857425 24300 net.cpp:425] scale5_1 <- conv5_1
I0624 21:43:39.857429 24300 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0624 21:43:39.857465 24300 layer_factory.hpp:77] Creating layer scale5_1
I0624 21:43:39.857560 24300 net.cpp:141] Setting up scale5_1
I0624 21:43:39.857566 24300 net.cpp:148] Top shape: 64 256 7 9 (1032192)
I0624 21:43:39.857569 24300 net.cpp:156] Memory required for data: 2105672448
I0624 21:43:39.857573 24300 layer_factory.hpp:77] Creating layer relu5_1
I0624 21:43:39.857579 24300 net.cpp:91] Creating Layer relu5_1
I0624 21:43:39.857581 24300 net.cpp:425] relu5_1 <- conv5_1
I0624 21:43:39.857584 24300 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0624 21:43:39.857728 24300 net.cpp:141] Setting up relu5_1
I0624 21:43:39.857736 24300 net.cpp:148] Top shape: 64 256 7 9 (1032192)
I0624 21:43:39.857738 24300 net.cpp:156] Memory required for data: 2109801216
I0624 21:43:39.857741 24300 layer_factory.hpp:77] Creating layer conv5_2
I0624 21:43:39.857749 24300 net.cpp:91] Creating Layer conv5_2
I0624 21:43:39.857753 24300 net.cpp:425] conv5_2 <- conv5_1
I0624 21:43:39.857758 24300 net.cpp:399] conv5_2 -> conv5_2
I0624 21:43:39.863422 24300 net.cpp:141] Setting up conv5_2
I0624 21:43:39.863438 24300 net.cpp:148] Top shape: 64 256 7 9 (1032192)
I0624 21:43:39.863441 24300 net.cpp:156] Memory required for data: 2113929984
I0624 21:43:39.863446 24300 layer_factory.hpp:77] Creating layer bn5_2
I0624 21:43:39.863454 24300 net.cpp:91] Creating Layer bn5_2
I0624 21:43:39.863457 24300 net.cpp:425] bn5_2 <- conv5_2
I0624 21:43:39.863462 24300 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0624 21:43:39.863627 24300 net.cpp:141] Setting up bn5_2
I0624 21:43:39.863634 24300 net.cpp:148] Top shape: 64 256 7 9 (1032192)
I0624 21:43:39.863636 24300 net.cpp:156] Memory required for data: 2118058752
I0624 21:43:39.863642 24300 layer_factory.hpp:77] Creating layer scale5_2
I0624 21:43:39.863649 24300 net.cpp:91] Creating Layer scale5_2
I0624 21:43:39.863651 24300 net.cpp:425] scale5_2 <- conv5_2
I0624 21:43:39.863656 24300 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0624 21:43:39.863689 24300 layer_factory.hpp:77] Creating layer scale5_2
I0624 21:43:39.863781 24300 net.cpp:141] Setting up scale5_2
I0624 21:43:39.863788 24300 net.cpp:148] Top shape: 64 256 7 9 (1032192)
I0624 21:43:39.863790 24300 net.cpp:156] Memory required for data: 2122187520
I0624 21:43:39.863795 24300 layer_factory.hpp:77] Creating layer relu5_2
I0624 21:43:39.863800 24300 net.cpp:91] Creating Layer relu5_2
I0624 21:43:39.863802 24300 net.cpp:425] relu5_2 <- conv5_2
I0624 21:43:39.863806 24300 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0624 21:43:39.863953 24300 net.cpp:141] Setting up relu5_2
I0624 21:43:39.863963 24300 net.cpp:148] Top shape: 64 256 7 9 (1032192)
I0624 21:43:39.863965 24300 net.cpp:156] Memory required for data: 2126316288
I0624 21:43:39.863983 24300 layer_factory.hpp:77] Creating layer pool5
I0624 21:43:39.863988 24300 net.cpp:91] Creating Layer pool5
I0624 21:43:39.863991 24300 net.cpp:425] pool5 <- conv5_2
I0624 21:43:39.863996 24300 net.cpp:399] pool5 -> pool5
I0624 21:43:39.864164 24300 net.cpp:141] Setting up pool5
I0624 21:43:39.864173 24300 net.cpp:148] Top shape: 64 256 1 1 (16384)
I0624 21:43:39.864176 24300 net.cpp:156] Memory required for data: 2126381824
I0624 21:43:39.864178 24300 layer_factory.hpp:77] Creating layer fc2
I0624 21:43:39.864184 24300 net.cpp:91] Creating Layer fc2
I0624 21:43:39.864187 24300 net.cpp:425] fc2 <- pool5
I0624 21:43:39.864192 24300 net.cpp:399] fc2 -> fc2
I0624 21:43:39.864295 24300 net.cpp:141] Setting up fc2
I0624 21:43:39.864302 24300 net.cpp:148] Top shape: 64 2 (128)
I0624 21:43:39.864305 24300 net.cpp:156] Memory required for data: 2126382336
I0624 21:43:39.864310 24300 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0624 21:43:39.864313 24300 net.cpp:91] Creating Layer fc2_fc2_0_split
I0624 21:43:39.864316 24300 net.cpp:425] fc2_fc2_0_split <- fc2
I0624 21:43:39.864321 24300 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0624 21:43:39.864326 24300 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0624 21:43:39.864356 24300 net.cpp:141] Setting up fc2_fc2_0_split
I0624 21:43:39.864359 24300 net.cpp:148] Top shape: 64 2 (128)
I0624 21:43:39.864362 24300 net.cpp:148] Top shape: 64 2 (128)
I0624 21:43:39.864364 24300 net.cpp:156] Memory required for data: 2126383360
I0624 21:43:39.864367 24300 layer_factory.hpp:77] Creating layer loss
I0624 21:43:39.864372 24300 net.cpp:91] Creating Layer loss
I0624 21:43:39.864373 24300 net.cpp:425] loss <- fc2_fc2_0_split_0
I0624 21:43:39.864377 24300 net.cpp:425] loss <- label_data_1_split_0
I0624 21:43:39.864379 24300 net.cpp:399] loss -> loss
I0624 21:43:39.864387 24300 layer_factory.hpp:77] Creating layer loss
I0624 21:43:39.864889 24300 net.cpp:141] Setting up loss
I0624 21:43:39.864902 24300 net.cpp:148] Top shape: (1)
I0624 21:43:39.864903 24300 net.cpp:151]     with loss weight 1
I0624 21:43:39.864912 24300 net.cpp:156] Memory required for data: 2126383364
I0624 21:43:39.864913 24300 layer_factory.hpp:77] Creating layer accuracy
I0624 21:43:39.864919 24300 net.cpp:91] Creating Layer accuracy
I0624 21:43:39.864922 24300 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0624 21:43:39.864925 24300 net.cpp:425] accuracy <- label_data_1_split_1
I0624 21:43:39.864930 24300 net.cpp:399] accuracy -> accuracy
I0624 21:43:39.864936 24300 net.cpp:141] Setting up accuracy
I0624 21:43:39.864940 24300 net.cpp:148] Top shape: (1)
I0624 21:43:39.864943 24300 net.cpp:156] Memory required for data: 2126383368
I0624 21:43:39.864944 24300 net.cpp:219] accuracy does not need backward computation.
I0624 21:43:39.864948 24300 net.cpp:217] loss needs backward computation.
I0624 21:43:39.864950 24300 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0624 21:43:39.864953 24300 net.cpp:217] fc2 needs backward computation.
I0624 21:43:39.864954 24300 net.cpp:217] pool5 needs backward computation.
I0624 21:43:39.864956 24300 net.cpp:217] relu5_2 needs backward computation.
I0624 21:43:39.864959 24300 net.cpp:217] scale5_2 needs backward computation.
I0624 21:43:39.864960 24300 net.cpp:217] bn5_2 needs backward computation.
I0624 21:43:39.864962 24300 net.cpp:217] conv5_2 needs backward computation.
I0624 21:43:39.864964 24300 net.cpp:217] relu5_1 needs backward computation.
I0624 21:43:39.864967 24300 net.cpp:217] scale5_1 needs backward computation.
I0624 21:43:39.864969 24300 net.cpp:217] bn5_1 needs backward computation.
I0624 21:43:39.864970 24300 net.cpp:217] conv5_1 needs backward computation.
I0624 21:43:39.864974 24300 net.cpp:217] pool4 needs backward computation.
I0624 21:43:39.864976 24300 net.cpp:217] relu4_2 needs backward computation.
I0624 21:43:39.864979 24300 net.cpp:217] scale4_2 needs backward computation.
I0624 21:43:39.864980 24300 net.cpp:217] bn4_2 needs backward computation.
I0624 21:43:39.864992 24300 net.cpp:217] conv4_2 needs backward computation.
I0624 21:43:39.864995 24300 net.cpp:217] relu4_1 needs backward computation.
I0624 21:43:39.864996 24300 net.cpp:217] scale4_1 needs backward computation.
I0624 21:43:39.865000 24300 net.cpp:217] bn4_1 needs backward computation.
I0624 21:43:39.865001 24300 net.cpp:217] conv4_1 needs backward computation.
I0624 21:43:39.865003 24300 net.cpp:217] pool3 needs backward computation.
I0624 21:43:39.865006 24300 net.cpp:217] relu3_2 needs backward computation.
I0624 21:43:39.865008 24300 net.cpp:217] scale3_2 needs backward computation.
I0624 21:43:39.865010 24300 net.cpp:217] bn3_2 needs backward computation.
I0624 21:43:39.865012 24300 net.cpp:217] conv3_2 needs backward computation.
I0624 21:43:39.865015 24300 net.cpp:217] relu3_1 needs backward computation.
I0624 21:43:39.865017 24300 net.cpp:217] scale3_1 needs backward computation.
I0624 21:43:39.865020 24300 net.cpp:217] bn3_1 needs backward computation.
I0624 21:43:39.865021 24300 net.cpp:217] conv3_1 needs backward computation.
I0624 21:43:39.865025 24300 net.cpp:217] pool2 needs backward computation.
I0624 21:43:39.865031 24300 net.cpp:217] relu2_2 needs backward computation.
I0624 21:43:39.865034 24300 net.cpp:217] scale2_2 needs backward computation.
I0624 21:43:39.865036 24300 net.cpp:217] bn2_2 needs backward computation.
I0624 21:43:39.865038 24300 net.cpp:217] conv2_2 needs backward computation.
I0624 21:43:39.865041 24300 net.cpp:217] relu2_1 needs backward computation.
I0624 21:43:39.865043 24300 net.cpp:217] scale2_1 needs backward computation.
I0624 21:43:39.865046 24300 net.cpp:217] bn2_1 needs backward computation.
I0624 21:43:39.865047 24300 net.cpp:217] conv2_1 needs backward computation.
I0624 21:43:39.865049 24300 net.cpp:217] pool1 needs backward computation.
I0624 21:43:39.865051 24300 net.cpp:217] relu1_2 needs backward computation.
I0624 21:43:39.865054 24300 net.cpp:217] scale1_2 needs backward computation.
I0624 21:43:39.865056 24300 net.cpp:217] bn1_2 needs backward computation.
I0624 21:43:39.865058 24300 net.cpp:217] conv1_2 needs backward computation.
I0624 21:43:39.865061 24300 net.cpp:217] relu1_1 needs backward computation.
I0624 21:43:39.865063 24300 net.cpp:217] scale1_1 needs backward computation.
I0624 21:43:39.865066 24300 net.cpp:217] bn1_1 needs backward computation.
I0624 21:43:39.865067 24300 net.cpp:217] conv1_1 needs backward computation.
I0624 21:43:39.865070 24300 net.cpp:219] label_data_1_split does not need backward computation.
I0624 21:43:39.865073 24300 net.cpp:219] data does not need backward computation.
I0624 21:43:39.865075 24300 net.cpp:261] This network produces output accuracy
I0624 21:43:39.865077 24300 net.cpp:261] This network produces output loss
I0624 21:43:39.865097 24300 net.cpp:274] Network initialization done.
I0624 21:43:39.865231 24300 solver.cpp:60] Solver scaffolding done.
I0624 21:43:39.866950 24300 caffe.cpp:219] Starting Optimization
I0624 21:43:39.866957 24300 solver.cpp:279] Solving BPnet
I0624 21:43:39.866961 24300 solver.cpp:280] Learning Rate Policy: step
I0624 21:43:39.869289 24300 solver.cpp:337] Iteration 0, Testing net (#0)
I0624 21:43:39.871551 24300 blocking_queue.cpp:50] Data layer prefetch queue empty
I0624 21:43:43.879892 24300 solver.cpp:404]     Test net output #0: accuracy = 0.422607
I0624 21:43:43.879920 24300 solver.cpp:404]     Test net output #1: loss = 0.693147 (* 1 = 0.693147 loss)
I0624 21:43:44.122961 24300 solver.cpp:228] Iteration 0, loss = 0.693147
I0624 21:43:44.122995 24300 solver.cpp:244]     Train net output #0: accuracy = 0.40625
I0624 21:43:44.123008 24300 solver.cpp:244]     Train net output #1: loss = 0.693147 (* 1 = 0.693147 loss)
I0624 21:43:44.123023 24300 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0624 21:43:46.176488 24300 solver.cpp:228] Iteration 20, loss = 0.664212
I0624 21:43:46.176524 24300 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 21:43:46.176530 24300 solver.cpp:244]     Train net output #1: loss = 0.664212 (* 1 = 0.664212 loss)
I0624 21:43:46.176535 24300 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0624 21:43:48.258311 24300 solver.cpp:228] Iteration 40, loss = 0.655871
I0624 21:43:48.258335 24300 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0624 21:43:48.258342 24300 solver.cpp:244]     Train net output #1: loss = 0.655871 (* 1 = 0.655871 loss)
I0624 21:43:48.258347 24300 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0624 21:43:50.332489 24300 solver.cpp:228] Iteration 60, loss = 0.708846
I0624 21:43:50.332514 24300 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0624 21:43:50.332523 24300 solver.cpp:244]     Train net output #1: loss = 0.708846 (* 1 = 0.708846 loss)
I0624 21:43:50.332527 24300 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0624 21:43:52.404615 24300 solver.cpp:228] Iteration 80, loss = 0.673102
I0624 21:43:52.404642 24300 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0624 21:43:52.404649 24300 solver.cpp:244]     Train net output #1: loss = 0.673102 (* 1 = 0.673102 loss)
I0624 21:43:52.404655 24300 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0624 21:43:54.443042 24300 solver.cpp:337] Iteration 100, Testing net (#0)
I0624 21:43:58.377223 24300 solver.cpp:404]     Test net output #0: accuracy = 0.576416
I0624 21:43:58.377254 24300 solver.cpp:404]     Test net output #1: loss = 0.664922 (* 1 = 0.664922 loss)
I0624 21:43:58.411917 24300 solver.cpp:228] Iteration 100, loss = 0.639614
I0624 21:43:58.411944 24300 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0624 21:43:58.411952 24300 solver.cpp:244]     Train net output #1: loss = 0.639614 (* 1 = 0.639614 loss)
I0624 21:43:58.411955 24300 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0624 21:44:00.501992 24300 solver.cpp:228] Iteration 120, loss = 0.662608
I0624 21:44:00.502037 24300 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0624 21:44:00.502043 24300 solver.cpp:244]     Train net output #1: loss = 0.662608 (* 1 = 0.662608 loss)
I0624 21:44:00.502048 24300 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0624 21:44:02.588922 24300 solver.cpp:228] Iteration 140, loss = 0.715642
I0624 21:44:02.588948 24300 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0624 21:44:02.588955 24300 solver.cpp:244]     Train net output #1: loss = 0.715642 (* 1 = 0.715642 loss)
I0624 21:44:02.588960 24300 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0624 21:44:04.674428 24300 solver.cpp:228] Iteration 160, loss = 0.661566
I0624 21:44:04.674453 24300 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 21:44:04.674461 24300 solver.cpp:244]     Train net output #1: loss = 0.661566 (* 1 = 0.661566 loss)
I0624 21:44:04.674466 24300 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0624 21:44:06.758333 24300 solver.cpp:228] Iteration 180, loss = 0.656221
I0624 21:44:06.758359 24300 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0624 21:44:06.758366 24300 solver.cpp:244]     Train net output #1: loss = 0.656221 (* 1 = 0.656221 loss)
I0624 21:44:06.758371 24300 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0624 21:44:08.817258 24300 solver.cpp:337] Iteration 200, Testing net (#0)
I0624 21:44:12.796932 24300 solver.cpp:404]     Test net output #0: accuracy = 0.668701
I0624 21:44:12.796964 24300 solver.cpp:404]     Test net output #1: loss = 0.619293 (* 1 = 0.619293 loss)
I0624 21:44:12.832695 24300 solver.cpp:228] Iteration 200, loss = 0.666833
I0624 21:44:12.832720 24300 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0624 21:44:12.832727 24300 solver.cpp:244]     Train net output #1: loss = 0.666833 (* 1 = 0.666833 loss)
I0624 21:44:12.832732 24300 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0624 21:44:14.932279 24300 solver.cpp:228] Iteration 220, loss = 0.575278
I0624 21:44:14.932306 24300 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 21:44:14.932323 24300 solver.cpp:244]     Train net output #1: loss = 0.575278 (* 1 = 0.575278 loss)
I0624 21:44:14.932327 24300 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0624 21:44:17.018540 24300 solver.cpp:228] Iteration 240, loss = 0.61442
I0624 21:44:17.018565 24300 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0624 21:44:17.018584 24300 solver.cpp:244]     Train net output #1: loss = 0.61442 (* 1 = 0.61442 loss)
I0624 21:44:17.018587 24300 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0624 21:44:19.110206 24300 solver.cpp:228] Iteration 260, loss = 0.556223
I0624 21:44:19.110235 24300 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0624 21:44:19.110242 24300 solver.cpp:244]     Train net output #1: loss = 0.556223 (* 1 = 0.556223 loss)
I0624 21:44:19.110246 24300 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0624 21:44:21.199450 24300 solver.cpp:228] Iteration 280, loss = 0.565081
I0624 21:44:21.199475 24300 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 21:44:21.199481 24300 solver.cpp:244]     Train net output #1: loss = 0.565081 (* 1 = 0.565081 loss)
I0624 21:44:21.199486 24300 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0624 21:44:23.265918 24300 solver.cpp:337] Iteration 300, Testing net (#0)
I0624 21:44:27.222332 24300 solver.cpp:404]     Test net output #0: accuracy = 0.679443
I0624 21:44:27.222360 24300 solver.cpp:404]     Test net output #1: loss = 0.597135 (* 1 = 0.597135 loss)
I0624 21:44:27.257625 24300 solver.cpp:228] Iteration 300, loss = 0.669673
I0624 21:44:27.257648 24300 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0624 21:44:27.257655 24300 solver.cpp:244]     Train net output #1: loss = 0.669673 (* 1 = 0.669673 loss)
I0624 21:44:27.257660 24300 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0624 21:44:29.357465 24300 solver.cpp:228] Iteration 320, loss = 0.623728
I0624 21:44:29.357491 24300 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 21:44:29.357497 24300 solver.cpp:244]     Train net output #1: loss = 0.623728 (* 1 = 0.623728 loss)
I0624 21:44:29.357501 24300 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0624 21:44:31.463362 24300 solver.cpp:228] Iteration 340, loss = 0.642521
I0624 21:44:31.463387 24300 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 21:44:31.463395 24300 solver.cpp:244]     Train net output #1: loss = 0.642521 (* 1 = 0.642521 loss)
I0624 21:44:31.463399 24300 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0624 21:44:33.558727 24300 solver.cpp:228] Iteration 360, loss = 0.556849
I0624 21:44:33.558750 24300 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 21:44:33.558758 24300 solver.cpp:244]     Train net output #1: loss = 0.556849 (* 1 = 0.556849 loss)
I0624 21:44:33.558763 24300 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0624 21:44:35.655452 24300 solver.cpp:228] Iteration 380, loss = 0.646892
I0624 21:44:35.655478 24300 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0624 21:44:35.655484 24300 solver.cpp:244]     Train net output #1: loss = 0.646892 (* 1 = 0.646892 loss)
I0624 21:44:35.655489 24300 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0624 21:44:37.711613 24300 solver.cpp:337] Iteration 400, Testing net (#0)
I0624 21:44:41.770836 24300 solver.cpp:404]     Test net output #0: accuracy = 0.695068
I0624 21:44:41.770973 24300 solver.cpp:404]     Test net output #1: loss = 0.584089 (* 1 = 0.584089 loss)
I0624 21:44:41.806107 24300 solver.cpp:228] Iteration 400, loss = 0.580568
I0624 21:44:41.806143 24300 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 21:44:41.806154 24300 solver.cpp:244]     Train net output #1: loss = 0.580568 (* 1 = 0.580568 loss)
I0624 21:44:41.806161 24300 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0624 21:44:43.909088 24300 solver.cpp:228] Iteration 420, loss = 0.557227
I0624 21:44:43.909112 24300 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 21:44:43.909119 24300 solver.cpp:244]     Train net output #1: loss = 0.557227 (* 1 = 0.557227 loss)
I0624 21:44:43.909124 24300 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0624 21:44:46.003957 24300 solver.cpp:228] Iteration 440, loss = 0.641199
I0624 21:44:46.003981 24300 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 21:44:46.003999 24300 solver.cpp:244]     Train net output #1: loss = 0.641199 (* 1 = 0.641199 loss)
I0624 21:44:46.004004 24300 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0624 21:44:48.103152 24300 solver.cpp:228] Iteration 460, loss = 0.643509
I0624 21:44:48.103175 24300 solver.cpp:244]     Train net output #0: accuracy = 0.46875
I0624 21:44:48.103181 24300 solver.cpp:244]     Train net output #1: loss = 0.643509 (* 1 = 0.643509 loss)
I0624 21:44:48.103188 24300 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0624 21:44:50.213429 24300 solver.cpp:228] Iteration 480, loss = 0.573692
I0624 21:44:50.213455 24300 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 21:44:50.213461 24300 solver.cpp:244]     Train net output #1: loss = 0.573692 (* 1 = 0.573692 loss)
I0624 21:44:50.213466 24300 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0624 21:44:52.282095 24300 solver.cpp:454] Snapshotting to binary proto file data/models/bpgnet_iter_500.caffemodel
I0624 21:44:52.312376 24300 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpgnet_iter_500.solverstate
I0624 21:44:52.323806 24300 solver.cpp:337] Iteration 500, Testing net (#0)
I0624 21:44:56.305503 24300 solver.cpp:404]     Test net output #0: accuracy = 0.712158
I0624 21:44:56.305534 24300 solver.cpp:404]     Test net output #1: loss = 0.56504 (* 1 = 0.56504 loss)
I0624 21:44:56.340924 24300 solver.cpp:228] Iteration 500, loss = 0.664233
I0624 21:44:56.340950 24300 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 21:44:56.340956 24300 solver.cpp:244]     Train net output #1: loss = 0.664233 (* 1 = 0.664233 loss)
I0624 21:44:56.340962 24300 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0624 21:44:58.452846 24300 solver.cpp:228] Iteration 520, loss = 0.615887
I0624 21:44:58.452883 24300 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 21:44:58.452889 24300 solver.cpp:244]     Train net output #1: loss = 0.615887 (* 1 = 0.615887 loss)
I0624 21:44:58.452894 24300 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0624 21:45:00.564398 24300 solver.cpp:228] Iteration 540, loss = 0.666911
I0624 21:45:00.564424 24300 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0624 21:45:00.564431 24300 solver.cpp:244]     Train net output #1: loss = 0.666911 (* 1 = 0.666911 loss)
I0624 21:45:00.564435 24300 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0624 21:45:02.672183 24300 solver.cpp:228] Iteration 560, loss = 0.611184
I0624 21:45:02.672209 24300 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 21:45:02.672216 24300 solver.cpp:244]     Train net output #1: loss = 0.611184 (* 1 = 0.611184 loss)
I0624 21:45:02.672221 24300 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0624 21:45:04.797655 24300 solver.cpp:228] Iteration 580, loss = 0.501636
I0624 21:45:04.797683 24300 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0624 21:45:04.797700 24300 solver.cpp:244]     Train net output #1: loss = 0.501636 (* 1 = 0.501636 loss)
I0624 21:45:04.797704 24300 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0624 21:45:06.888247 24300 solver.cpp:337] Iteration 600, Testing net (#0)
I0624 21:45:10.909122 24300 solver.cpp:404]     Test net output #0: accuracy = 0.712402
I0624 21:45:10.909160 24300 solver.cpp:404]     Test net output #1: loss = 0.563655 (* 1 = 0.563655 loss)
I0624 21:45:10.945163 24300 solver.cpp:228] Iteration 600, loss = 0.571878
I0624 21:45:10.945188 24300 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 21:45:10.945195 24300 solver.cpp:244]     Train net output #1: loss = 0.571878 (* 1 = 0.571878 loss)
I0624 21:45:10.945200 24300 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0624 21:45:13.062405 24300 solver.cpp:228] Iteration 620, loss = 0.55518
I0624 21:45:13.062508 24300 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 21:45:13.062518 24300 solver.cpp:244]     Train net output #1: loss = 0.55518 (* 1 = 0.55518 loss)
I0624 21:45:13.062523 24300 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0624 21:45:15.173226 24300 solver.cpp:228] Iteration 640, loss = 0.605739
I0624 21:45:15.173251 24300 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0624 21:45:15.173269 24300 solver.cpp:244]     Train net output #1: loss = 0.605739 (* 1 = 0.605739 loss)
I0624 21:45:15.173274 24300 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0624 21:45:17.304795 24300 solver.cpp:228] Iteration 660, loss = 0.532157
I0624 21:45:17.304818 24300 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 21:45:17.304826 24300 solver.cpp:244]     Train net output #1: loss = 0.532157 (* 1 = 0.532157 loss)
I0624 21:45:17.304831 24300 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0624 21:45:19.427070 24300 solver.cpp:228] Iteration 680, loss = 0.470531
I0624 21:45:19.427096 24300 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 21:45:19.427103 24300 solver.cpp:244]     Train net output #1: loss = 0.470531 (* 1 = 0.470531 loss)
I0624 21:45:19.427109 24300 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0624 21:45:21.518946 24300 solver.cpp:337] Iteration 700, Testing net (#0)
I0624 21:45:25.488299 24300 solver.cpp:404]     Test net output #0: accuracy = 0.73584
I0624 21:45:25.488327 24300 solver.cpp:404]     Test net output #1: loss = 0.530016 (* 1 = 0.530016 loss)
I0624 21:45:25.523932 24300 solver.cpp:228] Iteration 700, loss = 0.497652
I0624 21:45:25.523957 24300 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 21:45:25.523965 24300 solver.cpp:244]     Train net output #1: loss = 0.497652 (* 1 = 0.497652 loss)
I0624 21:45:25.523969 24300 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0624 21:45:27.673852 24300 solver.cpp:228] Iteration 720, loss = 0.438815
I0624 21:45:27.673877 24300 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 21:45:27.673884 24300 solver.cpp:244]     Train net output #1: loss = 0.438815 (* 1 = 0.438815 loss)
I0624 21:45:27.673889 24300 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0624 21:45:29.798137 24300 solver.cpp:228] Iteration 740, loss = 0.50201
I0624 21:45:29.798163 24300 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 21:45:29.798171 24300 solver.cpp:244]     Train net output #1: loss = 0.50201 (* 1 = 0.50201 loss)
I0624 21:45:29.798174 24300 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0624 21:45:31.913992 24300 solver.cpp:228] Iteration 760, loss = 0.526862
I0624 21:45:31.914027 24300 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 21:45:31.914034 24300 solver.cpp:244]     Train net output #1: loss = 0.526862 (* 1 = 0.526862 loss)
I0624 21:45:31.914039 24300 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0624 21:45:34.057412 24300 solver.cpp:228] Iteration 780, loss = 0.424013
I0624 21:45:34.057440 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:45:34.057446 24300 solver.cpp:244]     Train net output #1: loss = 0.424013 (* 1 = 0.424013 loss)
I0624 21:45:34.057451 24300 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0624 21:45:36.146950 24300 solver.cpp:337] Iteration 800, Testing net (#0)
I0624 21:45:40.243064 24300 solver.cpp:404]     Test net output #0: accuracy = 0.75
I0624 21:45:40.243093 24300 solver.cpp:404]     Test net output #1: loss = 0.516731 (* 1 = 0.516731 loss)
I0624 21:45:40.280212 24300 solver.cpp:228] Iteration 800, loss = 0.567276
I0624 21:45:40.280246 24300 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 21:45:40.280257 24300 solver.cpp:244]     Train net output #1: loss = 0.567276 (* 1 = 0.567276 loss)
I0624 21:45:40.280264 24300 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0624 21:45:42.392861 24300 solver.cpp:228] Iteration 820, loss = 0.396887
I0624 21:45:42.392887 24300 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 21:45:42.392894 24300 solver.cpp:244]     Train net output #1: loss = 0.396887 (* 1 = 0.396887 loss)
I0624 21:45:42.392921 24300 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0624 21:45:44.502527 24300 solver.cpp:228] Iteration 840, loss = 0.55748
I0624 21:45:44.502662 24300 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 21:45:44.502672 24300 solver.cpp:244]     Train net output #1: loss = 0.55748 (* 1 = 0.55748 loss)
I0624 21:45:44.502677 24300 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0624 21:45:46.620028 24300 solver.cpp:228] Iteration 860, loss = 0.468204
I0624 21:45:46.620064 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:45:46.620071 24300 solver.cpp:244]     Train net output #1: loss = 0.468204 (* 1 = 0.468204 loss)
I0624 21:45:46.620076 24300 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0624 21:45:48.734030 24300 solver.cpp:228] Iteration 880, loss = 0.415254
I0624 21:45:48.734055 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:45:48.734064 24300 solver.cpp:244]     Train net output #1: loss = 0.415254 (* 1 = 0.415254 loss)
I0624 21:45:48.734069 24300 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0624 21:45:50.817862 24300 solver.cpp:337] Iteration 900, Testing net (#0)
I0624 21:45:54.898813 24300 solver.cpp:404]     Test net output #0: accuracy = 0.745361
I0624 21:45:54.898841 24300 solver.cpp:404]     Test net output #1: loss = 0.507071 (* 1 = 0.507071 loss)
I0624 21:45:54.934655 24300 solver.cpp:228] Iteration 900, loss = 0.647958
I0624 21:45:54.934681 24300 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0624 21:45:54.934687 24300 solver.cpp:244]     Train net output #1: loss = 0.647958 (* 1 = 0.647958 loss)
I0624 21:45:54.934694 24300 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0624 21:45:57.052510 24300 solver.cpp:228] Iteration 920, loss = 0.579376
I0624 21:45:57.052532 24300 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 21:45:57.052539 24300 solver.cpp:244]     Train net output #1: loss = 0.579376 (* 1 = 0.579376 loss)
I0624 21:45:57.052543 24300 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0624 21:45:59.157153 24300 solver.cpp:228] Iteration 940, loss = 0.505775
I0624 21:45:59.157178 24300 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 21:45:59.157184 24300 solver.cpp:244]     Train net output #1: loss = 0.505775 (* 1 = 0.505775 loss)
I0624 21:45:59.157189 24300 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0624 21:46:01.262506 24300 solver.cpp:228] Iteration 960, loss = 0.507926
I0624 21:46:01.262531 24300 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 21:46:01.262537 24300 solver.cpp:244]     Train net output #1: loss = 0.507926 (* 1 = 0.507926 loss)
I0624 21:46:01.262542 24300 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0624 21:46:03.366211 24300 solver.cpp:228] Iteration 980, loss = 0.404358
I0624 21:46:03.366235 24300 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 21:46:03.366242 24300 solver.cpp:244]     Train net output #1: loss = 0.404358 (* 1 = 0.404358 loss)
I0624 21:46:03.366247 24300 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0624 21:46:05.439070 24300 solver.cpp:454] Snapshotting to binary proto file data/models/bpgnet_iter_1000.caffemodel
I0624 21:46:05.460705 24300 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpgnet_iter_1000.solverstate
I0624 21:46:05.472055 24300 solver.cpp:337] Iteration 1000, Testing net (#0)
I0624 21:46:09.463176 24300 solver.cpp:404]     Test net output #0: accuracy = 0.769775
I0624 21:46:09.463207 24300 solver.cpp:404]     Test net output #1: loss = 0.486973 (* 1 = 0.486973 loss)
I0624 21:46:09.498714 24300 solver.cpp:228] Iteration 1000, loss = 0.360307
I0624 21:46:09.498746 24300 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 21:46:09.498754 24300 solver.cpp:244]     Train net output #1: loss = 0.360307 (* 1 = 0.360307 loss)
I0624 21:46:09.498759 24300 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0624 21:46:11.632175 24300 solver.cpp:228] Iteration 1020, loss = 0.506637
I0624 21:46:11.632210 24300 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 21:46:11.632217 24300 solver.cpp:244]     Train net output #1: loss = 0.506637 (* 1 = 0.506637 loss)
I0624 21:46:11.632222 24300 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0624 21:46:13.765704 24300 solver.cpp:228] Iteration 1040, loss = 0.405086
I0624 21:46:13.765729 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:46:13.765736 24300 solver.cpp:244]     Train net output #1: loss = 0.405086 (* 1 = 0.405086 loss)
I0624 21:46:13.765741 24300 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0624 21:46:15.889521 24300 solver.cpp:228] Iteration 1060, loss = 0.615426
I0624 21:46:15.889644 24300 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0624 21:46:15.889655 24300 solver.cpp:244]     Train net output #1: loss = 0.615426 (* 1 = 0.615426 loss)
I0624 21:46:15.889659 24300 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0624 21:46:18.006580 24300 solver.cpp:228] Iteration 1080, loss = 0.411332
I0624 21:46:18.006605 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:46:18.006613 24300 solver.cpp:244]     Train net output #1: loss = 0.411332 (* 1 = 0.411332 loss)
I0624 21:46:18.006616 24300 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0624 21:46:20.088452 24300 solver.cpp:337] Iteration 1100, Testing net (#0)
I0624 21:46:24.078794 24300 solver.cpp:404]     Test net output #0: accuracy = 0.762695
I0624 21:46:24.078824 24300 solver.cpp:404]     Test net output #1: loss = 0.501403 (* 1 = 0.501403 loss)
I0624 21:46:24.114521 24300 solver.cpp:228] Iteration 1100, loss = 0.354946
I0624 21:46:24.114549 24300 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 21:46:24.114557 24300 solver.cpp:244]     Train net output #1: loss = 0.354946 (* 1 = 0.354946 loss)
I0624 21:46:24.114562 24300 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0624 21:46:26.242606 24300 solver.cpp:228] Iteration 1120, loss = 0.49194
I0624 21:46:26.242632 24300 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 21:46:26.242638 24300 solver.cpp:244]     Train net output #1: loss = 0.49194 (* 1 = 0.49194 loss)
I0624 21:46:26.242642 24300 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0624 21:46:28.355223 24300 solver.cpp:228] Iteration 1140, loss = 0.474324
I0624 21:46:28.355250 24300 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 21:46:28.355257 24300 solver.cpp:244]     Train net output #1: loss = 0.474324 (* 1 = 0.474324 loss)
I0624 21:46:28.355262 24300 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0624 21:46:30.486026 24300 solver.cpp:228] Iteration 1160, loss = 0.423535
I0624 21:46:30.486050 24300 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 21:46:30.486057 24300 solver.cpp:244]     Train net output #1: loss = 0.423535 (* 1 = 0.423535 loss)
I0624 21:46:30.486062 24300 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0624 21:46:32.599655 24300 solver.cpp:228] Iteration 1180, loss = 0.488813
I0624 21:46:32.599681 24300 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 21:46:32.599689 24300 solver.cpp:244]     Train net output #1: loss = 0.488813 (* 1 = 0.488813 loss)
I0624 21:46:32.599694 24300 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0624 21:46:34.687549 24300 solver.cpp:337] Iteration 1200, Testing net (#0)
I0624 21:46:38.742635 24300 solver.cpp:404]     Test net output #0: accuracy = 0.762939
I0624 21:46:38.742669 24300 solver.cpp:404]     Test net output #1: loss = 0.508054 (* 1 = 0.508054 loss)
I0624 21:46:38.778911 24300 solver.cpp:228] Iteration 1200, loss = 0.319485
I0624 21:46:38.778939 24300 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 21:46:38.778946 24300 solver.cpp:244]     Train net output #1: loss = 0.319485 (* 1 = 0.319485 loss)
I0624 21:46:38.778950 24300 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0624 21:46:40.888924 24300 solver.cpp:228] Iteration 1220, loss = 0.3793
I0624 21:46:40.888949 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:46:40.888957 24300 solver.cpp:244]     Train net output #1: loss = 0.3793 (* 1 = 0.3793 loss)
I0624 21:46:40.888962 24300 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0624 21:46:42.990167 24300 solver.cpp:228] Iteration 1240, loss = 0.502491
I0624 21:46:42.990195 24300 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 21:46:42.990202 24300 solver.cpp:244]     Train net output #1: loss = 0.502491 (* 1 = 0.502491 loss)
I0624 21:46:42.990208 24300 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0624 21:46:45.097126 24300 solver.cpp:228] Iteration 1260, loss = 0.34722
I0624 21:46:45.097162 24300 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 21:46:45.097168 24300 solver.cpp:244]     Train net output #1: loss = 0.34722 (* 1 = 0.34722 loss)
I0624 21:46:45.097195 24300 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0624 21:46:47.201321 24300 solver.cpp:228] Iteration 1280, loss = 0.5184
I0624 21:46:47.201442 24300 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 21:46:47.201450 24300 solver.cpp:244]     Train net output #1: loss = 0.5184 (* 1 = 0.5184 loss)
I0624 21:46:47.201457 24300 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0624 21:46:49.273402 24300 solver.cpp:337] Iteration 1300, Testing net (#0)
I0624 21:46:53.213125 24300 solver.cpp:404]     Test net output #0: accuracy = 0.790039
I0624 21:46:53.213163 24300 solver.cpp:404]     Test net output #1: loss = 0.464449 (* 1 = 0.464449 loss)
I0624 21:46:53.248380 24300 solver.cpp:228] Iteration 1300, loss = 0.459809
I0624 21:46:53.248405 24300 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 21:46:53.248412 24300 solver.cpp:244]     Train net output #1: loss = 0.459809 (* 1 = 0.459809 loss)
I0624 21:46:53.248417 24300 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0624 21:46:55.374347 24300 solver.cpp:228] Iteration 1320, loss = 0.385526
I0624 21:46:55.374372 24300 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 21:46:55.374390 24300 solver.cpp:244]     Train net output #1: loss = 0.385526 (* 1 = 0.385526 loss)
I0624 21:46:55.374395 24300 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0624 21:46:57.487661 24300 solver.cpp:228] Iteration 1340, loss = 0.391593
I0624 21:46:57.487684 24300 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 21:46:57.487691 24300 solver.cpp:244]     Train net output #1: loss = 0.391593 (* 1 = 0.391593 loss)
I0624 21:46:57.487695 24300 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0624 21:46:59.603600 24300 solver.cpp:228] Iteration 1360, loss = 0.470951
I0624 21:46:59.603624 24300 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 21:46:59.603631 24300 solver.cpp:244]     Train net output #1: loss = 0.470951 (* 1 = 0.470951 loss)
I0624 21:46:59.603636 24300 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0624 21:47:01.717155 24300 solver.cpp:228] Iteration 1380, loss = 0.445356
I0624 21:47:01.717180 24300 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 21:47:01.717187 24300 solver.cpp:244]     Train net output #1: loss = 0.445356 (* 1 = 0.445356 loss)
I0624 21:47:01.717191 24300 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0624 21:47:03.791386 24300 solver.cpp:337] Iteration 1400, Testing net (#0)
I0624 21:47:07.757365 24300 solver.cpp:404]     Test net output #0: accuracy = 0.781738
I0624 21:47:07.757395 24300 solver.cpp:404]     Test net output #1: loss = 0.484535 (* 1 = 0.484535 loss)
I0624 21:47:07.793057 24300 solver.cpp:228] Iteration 1400, loss = 0.477834
I0624 21:47:07.793092 24300 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 21:47:07.793104 24300 solver.cpp:244]     Train net output #1: loss = 0.477834 (* 1 = 0.477834 loss)
I0624 21:47:07.793112 24300 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0624 21:47:09.901376 24300 solver.cpp:228] Iteration 1420, loss = 0.455357
I0624 21:47:09.901402 24300 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 21:47:09.901412 24300 solver.cpp:244]     Train net output #1: loss = 0.455357 (* 1 = 0.455357 loss)
I0624 21:47:09.901418 24300 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0624 21:47:12.000069 24300 solver.cpp:228] Iteration 1440, loss = 0.424886
I0624 21:47:12.000095 24300 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 21:47:12.000105 24300 solver.cpp:244]     Train net output #1: loss = 0.424886 (* 1 = 0.424886 loss)
I0624 21:47:12.000111 24300 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0624 21:47:14.098728 24300 solver.cpp:228] Iteration 1460, loss = 0.323302
I0624 21:47:14.098754 24300 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 21:47:14.098764 24300 solver.cpp:244]     Train net output #1: loss = 0.323302 (* 1 = 0.323302 loss)
I0624 21:47:14.098770 24300 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0624 21:47:16.205126 24300 solver.cpp:228] Iteration 1480, loss = 0.396567
I0624 21:47:16.205152 24300 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 21:47:16.205163 24300 solver.cpp:244]     Train net output #1: loss = 0.396567 (* 1 = 0.396567 loss)
I0624 21:47:16.205191 24300 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0624 21:47:18.278164 24300 solver.cpp:454] Snapshotting to binary proto file data/models/bpgnet_iter_1500.caffemodel
I0624 21:47:18.299944 24300 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpgnet_iter_1500.solverstate
I0624 21:47:18.311727 24300 solver.cpp:337] Iteration 1500, Testing net (#0)
I0624 21:47:22.283351 24300 solver.cpp:404]     Test net output #0: accuracy = 0.779541
I0624 21:47:22.283390 24300 solver.cpp:404]     Test net output #1: loss = 0.477558 (* 1 = 0.477558 loss)
I0624 21:47:22.319093 24300 solver.cpp:228] Iteration 1500, loss = 0.44997
I0624 21:47:22.319118 24300 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 21:47:22.319124 24300 solver.cpp:244]     Train net output #1: loss = 0.44997 (* 1 = 0.44997 loss)
I0624 21:47:22.319129 24300 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0624 21:47:24.429167 24300 solver.cpp:228] Iteration 1520, loss = 0.407126
I0624 21:47:24.429193 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:47:24.429199 24300 solver.cpp:244]     Train net output #1: loss = 0.407126 (* 1 = 0.407126 loss)
I0624 21:47:24.429204 24300 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0624 21:47:26.532984 24300 solver.cpp:228] Iteration 1540, loss = 0.477608
I0624 21:47:26.533023 24300 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 21:47:26.533030 24300 solver.cpp:244]     Train net output #1: loss = 0.477608 (* 1 = 0.477608 loss)
I0624 21:47:26.533035 24300 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0624 21:47:28.636960 24300 solver.cpp:228] Iteration 1560, loss = 0.317968
I0624 21:47:28.636983 24300 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 21:47:28.637001 24300 solver.cpp:244]     Train net output #1: loss = 0.317968 (* 1 = 0.317968 loss)
I0624 21:47:28.637006 24300 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0624 21:47:30.741334 24300 solver.cpp:228] Iteration 1580, loss = 0.33482
I0624 21:47:30.741358 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:47:30.741365 24300 solver.cpp:244]     Train net output #1: loss = 0.33482 (* 1 = 0.33482 loss)
I0624 21:47:30.741369 24300 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0624 21:47:32.816118 24300 solver.cpp:337] Iteration 1600, Testing net (#0)
I0624 21:47:35.623347 24300 blocking_queue.cpp:50] Data layer prefetch queue empty
I0624 21:47:36.801674 24300 solver.cpp:404]     Test net output #0: accuracy = 0.792725
I0624 21:47:36.801723 24300 solver.cpp:404]     Test net output #1: loss = 0.464602 (* 1 = 0.464602 loss)
I0624 21:47:36.837738 24300 solver.cpp:228] Iteration 1600, loss = 0.620294
I0624 21:47:36.837762 24300 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 21:47:36.837769 24300 solver.cpp:244]     Train net output #1: loss = 0.620294 (* 1 = 0.620294 loss)
I0624 21:47:36.837774 24300 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0624 21:47:38.953011 24300 solver.cpp:228] Iteration 1620, loss = 0.548085
I0624 21:47:38.953047 24300 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 21:47:38.953053 24300 solver.cpp:244]     Train net output #1: loss = 0.548085 (* 1 = 0.548085 loss)
I0624 21:47:38.953058 24300 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0624 21:47:41.060617 24300 solver.cpp:228] Iteration 1640, loss = 0.396279
I0624 21:47:41.060642 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:47:41.060650 24300 solver.cpp:244]     Train net output #1: loss = 0.396279 (* 1 = 0.396279 loss)
I0624 21:47:41.060654 24300 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0624 21:47:43.167351 24300 solver.cpp:228] Iteration 1660, loss = 0.314307
I0624 21:47:43.167377 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:47:43.167384 24300 solver.cpp:244]     Train net output #1: loss = 0.314307 (* 1 = 0.314307 loss)
I0624 21:47:43.167389 24300 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0624 21:47:45.266782 24300 solver.cpp:228] Iteration 1680, loss = 0.301302
I0624 21:47:45.266809 24300 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 21:47:45.266816 24300 solver.cpp:244]     Train net output #1: loss = 0.301302 (* 1 = 0.301302 loss)
I0624 21:47:45.266844 24300 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0624 21:47:47.331841 24300 solver.cpp:337] Iteration 1700, Testing net (#0)
I0624 21:47:51.275401 24300 solver.cpp:404]     Test net output #0: accuracy = 0.783691
I0624 21:47:51.275539 24300 solver.cpp:404]     Test net output #1: loss = 0.483793 (* 1 = 0.483793 loss)
I0624 21:47:51.310920 24300 solver.cpp:228] Iteration 1700, loss = 0.490534
I0624 21:47:51.310945 24300 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 21:47:51.310951 24300 solver.cpp:244]     Train net output #1: loss = 0.490534 (* 1 = 0.490534 loss)
I0624 21:47:51.310956 24300 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0624 21:47:53.429935 24300 solver.cpp:228] Iteration 1720, loss = 0.406744
I0624 21:47:53.429961 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:47:53.429968 24300 solver.cpp:244]     Train net output #1: loss = 0.406744 (* 1 = 0.406744 loss)
I0624 21:47:53.429973 24300 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0624 21:47:55.536512 24300 solver.cpp:228] Iteration 1740, loss = 0.350831
I0624 21:47:55.536535 24300 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 21:47:55.536542 24300 solver.cpp:244]     Train net output #1: loss = 0.350831 (* 1 = 0.350831 loss)
I0624 21:47:55.536548 24300 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0624 21:47:57.644526 24300 solver.cpp:228] Iteration 1760, loss = 0.478102
I0624 21:47:57.644549 24300 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 21:47:57.644556 24300 solver.cpp:244]     Train net output #1: loss = 0.478102 (* 1 = 0.478102 loss)
I0624 21:47:57.644562 24300 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0624 21:47:59.754923 24300 solver.cpp:228] Iteration 1780, loss = 0.426004
I0624 21:47:59.754948 24300 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 21:47:59.754966 24300 solver.cpp:244]     Train net output #1: loss = 0.426004 (* 1 = 0.426004 loss)
I0624 21:47:59.754971 24300 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0624 21:48:01.832005 24300 solver.cpp:337] Iteration 1800, Testing net (#0)
I0624 21:48:05.816671 24300 solver.cpp:404]     Test net output #0: accuracy = 0.783203
I0624 21:48:05.816700 24300 solver.cpp:404]     Test net output #1: loss = 0.471603 (* 1 = 0.471603 loss)
I0624 21:48:05.851956 24300 solver.cpp:228] Iteration 1800, loss = 0.601001
I0624 21:48:05.851982 24300 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 21:48:05.851989 24300 solver.cpp:244]     Train net output #1: loss = 0.601001 (* 1 = 0.601001 loss)
I0624 21:48:05.851994 24300 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0624 21:48:07.968747 24300 solver.cpp:228] Iteration 1820, loss = 0.337971
I0624 21:48:07.968772 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:48:07.968780 24300 solver.cpp:244]     Train net output #1: loss = 0.337971 (* 1 = 0.337971 loss)
I0624 21:48:07.968785 24300 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0624 21:48:10.075073 24300 solver.cpp:228] Iteration 1840, loss = 0.469889
I0624 21:48:10.075109 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:48:10.075116 24300 solver.cpp:244]     Train net output #1: loss = 0.469889 (* 1 = 0.469889 loss)
I0624 21:48:10.075121 24300 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0624 21:48:12.190100 24300 solver.cpp:228] Iteration 1860, loss = 0.368881
I0624 21:48:12.190126 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:48:12.190132 24300 solver.cpp:244]     Train net output #1: loss = 0.368881 (* 1 = 0.368881 loss)
I0624 21:48:12.190138 24300 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0624 21:48:14.339067 24300 solver.cpp:228] Iteration 1880, loss = 0.4376
I0624 21:48:14.339093 24300 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 21:48:14.339100 24300 solver.cpp:244]     Train net output #1: loss = 0.4376 (* 1 = 0.4376 loss)
I0624 21:48:14.339105 24300 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0624 21:48:16.510064 24300 solver.cpp:337] Iteration 1900, Testing net (#0)
I0624 21:48:20.632889 24300 solver.cpp:404]     Test net output #0: accuracy = 0.780762
I0624 21:48:20.632925 24300 solver.cpp:404]     Test net output #1: loss = 0.471762 (* 1 = 0.471762 loss)
I0624 21:48:20.669092 24300 solver.cpp:228] Iteration 1900, loss = 0.366528
I0624 21:48:20.669137 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:48:20.669144 24300 solver.cpp:244]     Train net output #1: loss = 0.366528 (* 1 = 0.366528 loss)
I0624 21:48:20.669149 24300 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0624 21:48:22.816962 24300 solver.cpp:228] Iteration 1920, loss = 0.670077
I0624 21:48:22.817106 24300 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0624 21:48:22.817118 24300 solver.cpp:244]     Train net output #1: loss = 0.670077 (* 1 = 0.670077 loss)
I0624 21:48:22.817126 24300 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0624 21:48:24.957648 24300 solver.cpp:228] Iteration 1940, loss = 0.4602
I0624 21:48:24.957676 24300 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 21:48:24.957684 24300 solver.cpp:244]     Train net output #1: loss = 0.4602 (* 1 = 0.4602 loss)
I0624 21:48:24.957689 24300 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0624 21:48:27.063197 24300 solver.cpp:228] Iteration 1960, loss = 0.328658
I0624 21:48:27.063223 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:48:27.063230 24300 solver.cpp:244]     Train net output #1: loss = 0.328658 (* 1 = 0.328658 loss)
I0624 21:48:27.063236 24300 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0624 21:48:29.163255 24300 solver.cpp:228] Iteration 1980, loss = 0.313337
I0624 21:48:29.163280 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:48:29.163286 24300 solver.cpp:244]     Train net output #1: loss = 0.313337 (* 1 = 0.313337 loss)
I0624 21:48:29.163290 24300 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0624 21:48:31.250370 24300 solver.cpp:454] Snapshotting to binary proto file data/models/bpgnet_iter_2000.caffemodel
I0624 21:48:31.271965 24300 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpgnet_iter_2000.solverstate
I0624 21:48:31.288282 24300 solver.cpp:337] Iteration 2000, Testing net (#0)
I0624 21:48:35.273617 24300 solver.cpp:404]     Test net output #0: accuracy = 0.789307
I0624 21:48:35.273656 24300 solver.cpp:404]     Test net output #1: loss = 0.479178 (* 1 = 0.479178 loss)
I0624 21:48:35.310055 24300 solver.cpp:228] Iteration 2000, loss = 0.356056
I0624 21:48:35.310080 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:48:35.310087 24300 solver.cpp:244]     Train net output #1: loss = 0.356056 (* 1 = 0.356056 loss)
I0624 21:48:35.310091 24300 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0624 21:48:37.442026 24300 solver.cpp:228] Iteration 2020, loss = 0.485589
I0624 21:48:37.442052 24300 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 21:48:37.442060 24300 solver.cpp:244]     Train net output #1: loss = 0.485589 (* 1 = 0.485589 loss)
I0624 21:48:37.442065 24300 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0624 21:48:39.561841 24300 solver.cpp:228] Iteration 2040, loss = 0.260279
I0624 21:48:39.561867 24300 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 21:48:39.561874 24300 solver.cpp:244]     Train net output #1: loss = 0.260279 (* 1 = 0.260279 loss)
I0624 21:48:39.561879 24300 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0624 21:48:41.690376 24300 solver.cpp:228] Iteration 2060, loss = 0.258155
I0624 21:48:41.690402 24300 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 21:48:41.690408 24300 solver.cpp:244]     Train net output #1: loss = 0.258155 (* 1 = 0.258155 loss)
I0624 21:48:41.690413 24300 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0624 21:48:43.808722 24300 solver.cpp:228] Iteration 2080, loss = 0.41356
I0624 21:48:43.808758 24300 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 21:48:43.808764 24300 solver.cpp:244]     Train net output #1: loss = 0.41356 (* 1 = 0.41356 loss)
I0624 21:48:43.808769 24300 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0624 21:48:45.888152 24300 solver.cpp:337] Iteration 2100, Testing net (#0)
I0624 21:48:49.910406 24300 solver.cpp:404]     Test net output #0: accuracy = 0.778076
I0624 21:48:49.910445 24300 solver.cpp:404]     Test net output #1: loss = 0.490805 (* 1 = 0.490805 loss)
I0624 21:48:49.946326 24300 solver.cpp:228] Iteration 2100, loss = 0.595286
I0624 21:48:49.946352 24300 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 21:48:49.946358 24300 solver.cpp:244]     Train net output #1: loss = 0.595286 (* 1 = 0.595286 loss)
I0624 21:48:49.946363 24300 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0624 21:48:52.060520 24300 solver.cpp:228] Iteration 2120, loss = 0.348258
I0624 21:48:52.060545 24300 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 21:48:52.060564 24300 solver.cpp:244]     Train net output #1: loss = 0.348258 (* 1 = 0.348258 loss)
I0624 21:48:52.060567 24300 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0624 21:48:54.178505 24300 solver.cpp:228] Iteration 2140, loss = 0.337505
I0624 21:48:54.178637 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:48:54.178648 24300 solver.cpp:244]     Train net output #1: loss = 0.337505 (* 1 = 0.337505 loss)
I0624 21:48:54.178653 24300 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0624 21:48:56.293282 24300 solver.cpp:228] Iteration 2160, loss = 0.409747
I0624 21:48:56.293308 24300 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 21:48:56.293314 24300 solver.cpp:244]     Train net output #1: loss = 0.409747 (* 1 = 0.409747 loss)
I0624 21:48:56.293319 24300 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0624 21:48:58.402201 24300 solver.cpp:228] Iteration 2180, loss = 0.43428
I0624 21:48:58.402226 24300 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 21:48:58.402233 24300 solver.cpp:244]     Train net output #1: loss = 0.43428 (* 1 = 0.43428 loss)
I0624 21:48:58.402237 24300 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0624 21:49:00.478854 24300 solver.cpp:337] Iteration 2200, Testing net (#0)
I0624 21:49:04.427942 24300 solver.cpp:404]     Test net output #0: accuracy = 0.781006
I0624 21:49:04.427971 24300 solver.cpp:404]     Test net output #1: loss = 0.485074 (* 1 = 0.485074 loss)
I0624 21:49:04.463510 24300 solver.cpp:228] Iteration 2200, loss = 0.395523
I0624 21:49:04.463534 24300 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 21:49:04.463541 24300 solver.cpp:244]     Train net output #1: loss = 0.395523 (* 1 = 0.395523 loss)
I0624 21:49:04.463547 24300 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0624 21:49:06.577958 24300 solver.cpp:228] Iteration 2220, loss = 0.325282
I0624 21:49:06.577985 24300 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 21:49:06.577991 24300 solver.cpp:244]     Train net output #1: loss = 0.325282 (* 1 = 0.325282 loss)
I0624 21:49:06.577996 24300 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0624 21:49:08.687463 24300 solver.cpp:228] Iteration 2240, loss = 0.374918
I0624 21:49:08.687487 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:49:08.687494 24300 solver.cpp:244]     Train net output #1: loss = 0.374918 (* 1 = 0.374918 loss)
I0624 21:49:08.687499 24300 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0624 21:49:10.798408 24300 solver.cpp:228] Iteration 2260, loss = 0.337455
I0624 21:49:10.798434 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:49:10.798440 24300 solver.cpp:244]     Train net output #1: loss = 0.337455 (* 1 = 0.337455 loss)
I0624 21:49:10.798445 24300 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0624 21:49:12.906761 24300 solver.cpp:228] Iteration 2280, loss = 0.328386
I0624 21:49:12.906786 24300 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 21:49:12.906792 24300 solver.cpp:244]     Train net output #1: loss = 0.328386 (* 1 = 0.328386 loss)
I0624 21:49:12.906797 24300 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0624 21:49:14.987504 24300 solver.cpp:337] Iteration 2300, Testing net (#0)
I0624 21:49:19.028367 24300 solver.cpp:404]     Test net output #0: accuracy = 0.788574
I0624 21:49:19.028408 24300 solver.cpp:404]     Test net output #1: loss = 0.502054 (* 1 = 0.502054 loss)
I0624 21:49:19.064362 24300 solver.cpp:228] Iteration 2300, loss = 0.392643
I0624 21:49:19.064388 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:49:19.064396 24300 solver.cpp:244]     Train net output #1: loss = 0.392643 (* 1 = 0.392643 loss)
I0624 21:49:19.064400 24300 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0624 21:49:21.182032 24300 solver.cpp:228] Iteration 2320, loss = 0.279212
I0624 21:49:21.182059 24300 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 21:49:21.182065 24300 solver.cpp:244]     Train net output #1: loss = 0.279212 (* 1 = 0.279212 loss)
I0624 21:49:21.182070 24300 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0624 21:49:23.287483 24300 solver.cpp:228] Iteration 2340, loss = 0.438567
I0624 21:49:23.287509 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:49:23.287515 24300 solver.cpp:244]     Train net output #1: loss = 0.438567 (* 1 = 0.438567 loss)
I0624 21:49:23.287542 24300 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0624 21:49:25.396881 24300 solver.cpp:228] Iteration 2360, loss = 0.374504
I0624 21:49:25.397001 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:49:25.397017 24300 solver.cpp:244]     Train net output #1: loss = 0.374504 (* 1 = 0.374504 loss)
I0624 21:49:25.397024 24300 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0624 21:49:27.511144 24300 solver.cpp:228] Iteration 2380, loss = 0.388562
I0624 21:49:27.511175 24300 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 21:49:27.511181 24300 solver.cpp:244]     Train net output #1: loss = 0.388562 (* 1 = 0.388562 loss)
I0624 21:49:27.511186 24300 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0624 21:49:29.591239 24300 solver.cpp:337] Iteration 2400, Testing net (#0)
I0624 21:49:33.618393 24300 solver.cpp:404]     Test net output #0: accuracy = 0.776855
I0624 21:49:33.618420 24300 solver.cpp:404]     Test net output #1: loss = 0.51246 (* 1 = 0.51246 loss)
I0624 21:49:33.655212 24300 solver.cpp:228] Iteration 2400, loss = 0.413713
I0624 21:49:33.655247 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:49:33.655259 24300 solver.cpp:244]     Train net output #1: loss = 0.413713 (* 1 = 0.413713 loss)
I0624 21:49:33.655267 24300 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0624 21:49:35.779309 24300 solver.cpp:228] Iteration 2420, loss = 0.317075
I0624 21:49:35.779335 24300 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 21:49:35.779341 24300 solver.cpp:244]     Train net output #1: loss = 0.317075 (* 1 = 0.317075 loss)
I0624 21:49:35.779347 24300 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0624 21:49:37.897614 24300 solver.cpp:228] Iteration 2440, loss = 0.594203
I0624 21:49:37.897640 24300 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 21:49:37.897649 24300 solver.cpp:244]     Train net output #1: loss = 0.594203 (* 1 = 0.594203 loss)
I0624 21:49:37.897653 24300 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0624 21:49:40.017529 24300 solver.cpp:228] Iteration 2460, loss = 0.346917
I0624 21:49:40.017554 24300 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 21:49:40.017560 24300 solver.cpp:244]     Train net output #1: loss = 0.346917 (* 1 = 0.346917 loss)
I0624 21:49:40.017565 24300 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0624 21:49:42.171694 24300 solver.cpp:228] Iteration 2480, loss = 0.412066
I0624 21:49:42.171720 24300 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 21:49:42.171726 24300 solver.cpp:244]     Train net output #1: loss = 0.412066 (* 1 = 0.412066 loss)
I0624 21:49:42.171731 24300 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0624 21:49:44.253309 24300 solver.cpp:454] Snapshotting to binary proto file data/models/bpgnet_iter_2500.caffemodel
I0624 21:49:44.277047 24300 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpgnet_iter_2500.solverstate
I0624 21:49:44.291198 24300 solver.cpp:337] Iteration 2500, Testing net (#0)
I0624 21:49:48.476608 24300 solver.cpp:404]     Test net output #0: accuracy = 0.79248
I0624 21:49:48.476639 24300 solver.cpp:404]     Test net output #1: loss = 0.463704 (* 1 = 0.463704 loss)
I0624 21:49:48.511966 24300 solver.cpp:228] Iteration 2500, loss = 0.47089
I0624 21:49:48.511992 24300 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 21:49:48.511999 24300 solver.cpp:244]     Train net output #1: loss = 0.47089 (* 1 = 0.47089 loss)
I0624 21:49:48.512003 24300 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0624 21:49:50.659822 24300 solver.cpp:228] Iteration 2520, loss = 0.442135
I0624 21:49:50.659847 24300 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 21:49:50.659853 24300 solver.cpp:244]     Train net output #1: loss = 0.442135 (* 1 = 0.442135 loss)
I0624 21:49:50.659857 24300 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0624 21:49:52.801554 24300 solver.cpp:228] Iteration 2540, loss = 0.225607
I0624 21:49:52.801579 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:49:52.801586 24300 solver.cpp:244]     Train net output #1: loss = 0.225607 (* 1 = 0.225607 loss)
I0624 21:49:52.801590 24300 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0624 21:49:54.914167 24300 solver.cpp:228] Iteration 2560, loss = 0.284611
I0624 21:49:54.914193 24300 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 21:49:54.914201 24300 solver.cpp:244]     Train net output #1: loss = 0.284611 (* 1 = 0.284611 loss)
I0624 21:49:54.914206 24300 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0624 21:49:57.023100 24300 solver.cpp:228] Iteration 2580, loss = 0.393537
I0624 21:49:57.023231 24300 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 21:49:57.023241 24300 solver.cpp:244]     Train net output #1: loss = 0.393537 (* 1 = 0.393537 loss)
I0624 21:49:57.023247 24300 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0624 21:49:59.097501 24300 solver.cpp:337] Iteration 2600, Testing net (#0)
I0624 21:50:03.061272 24300 solver.cpp:404]     Test net output #0: accuracy = 0.772461
I0624 21:50:03.061302 24300 solver.cpp:404]     Test net output #1: loss = 0.501246 (* 1 = 0.501246 loss)
I0624 21:50:03.097308 24300 solver.cpp:228] Iteration 2600, loss = 0.436306
I0624 21:50:03.097333 24300 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 21:50:03.097344 24300 solver.cpp:244]     Train net output #1: loss = 0.436306 (* 1 = 0.436306 loss)
I0624 21:50:03.097352 24300 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0624 21:50:05.210371 24300 solver.cpp:228] Iteration 2620, loss = 0.223372
I0624 21:50:05.210397 24300 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 21:50:05.210403 24300 solver.cpp:244]     Train net output #1: loss = 0.223372 (* 1 = 0.223372 loss)
I0624 21:50:05.210409 24300 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0624 21:50:07.334163 24300 solver.cpp:228] Iteration 2640, loss = 0.387064
I0624 21:50:07.334188 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:50:07.334195 24300 solver.cpp:244]     Train net output #1: loss = 0.387064 (* 1 = 0.387064 loss)
I0624 21:50:07.334200 24300 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0624 21:50:09.451045 24300 solver.cpp:228] Iteration 2660, loss = 0.276523
I0624 21:50:09.451068 24300 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 21:50:09.451076 24300 solver.cpp:244]     Train net output #1: loss = 0.276523 (* 1 = 0.276523 loss)
I0624 21:50:09.451079 24300 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0624 21:50:11.561951 24300 solver.cpp:228] Iteration 2680, loss = 0.340779
I0624 21:50:11.561977 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:50:11.561985 24300 solver.cpp:244]     Train net output #1: loss = 0.340779 (* 1 = 0.340779 loss)
I0624 21:50:11.561990 24300 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0624 21:50:13.642330 24300 solver.cpp:337] Iteration 2700, Testing net (#0)
I0624 21:50:17.653337 24300 solver.cpp:404]     Test net output #0: accuracy = 0.779053
I0624 21:50:17.653365 24300 solver.cpp:404]     Test net output #1: loss = 0.515623 (* 1 = 0.515623 loss)
I0624 21:50:17.689174 24300 solver.cpp:228] Iteration 2700, loss = 0.29212
I0624 21:50:17.689199 24300 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 21:50:17.689206 24300 solver.cpp:244]     Train net output #1: loss = 0.29212 (* 1 = 0.29212 loss)
I0624 21:50:17.689211 24300 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0624 21:50:19.807286 24300 solver.cpp:228] Iteration 2720, loss = 0.280731
I0624 21:50:19.807312 24300 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 21:50:19.807329 24300 solver.cpp:244]     Train net output #1: loss = 0.280731 (* 1 = 0.280731 loss)
I0624 21:50:19.807333 24300 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0624 21:50:21.917737 24300 solver.cpp:228] Iteration 2740, loss = 0.356648
I0624 21:50:21.917762 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:50:21.917769 24300 solver.cpp:244]     Train net output #1: loss = 0.356648 (* 1 = 0.356648 loss)
I0624 21:50:21.917774 24300 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0624 21:50:24.027586 24300 solver.cpp:228] Iteration 2760, loss = 0.24367
I0624 21:50:24.027624 24300 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 21:50:24.027631 24300 solver.cpp:244]     Train net output #1: loss = 0.24367 (* 1 = 0.24367 loss)
I0624 21:50:24.027637 24300 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0624 21:50:26.137378 24300 solver.cpp:228] Iteration 2780, loss = 0.408566
I0624 21:50:26.137406 24300 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 21:50:26.137413 24300 solver.cpp:244]     Train net output #1: loss = 0.408566 (* 1 = 0.408566 loss)
I0624 21:50:26.137441 24300 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0624 21:50:28.215561 24300 solver.cpp:337] Iteration 2800, Testing net (#0)
I0624 21:50:32.233835 24300 solver.cpp:404]     Test net output #0: accuracy = 0.79126
I0624 21:50:32.233863 24300 solver.cpp:404]     Test net output #1: loss = 0.492729 (* 1 = 0.492729 loss)
I0624 21:50:32.269724 24300 solver.cpp:228] Iteration 2800, loss = 0.31022
I0624 21:50:32.269752 24300 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 21:50:32.269762 24300 solver.cpp:244]     Train net output #1: loss = 0.31022 (* 1 = 0.31022 loss)
I0624 21:50:32.269769 24300 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0624 21:50:34.378010 24300 solver.cpp:228] Iteration 2820, loss = 0.417597
I0624 21:50:34.378036 24300 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 21:50:34.378046 24300 solver.cpp:244]     Train net output #1: loss = 0.417597 (* 1 = 0.417597 loss)
I0624 21:50:34.378051 24300 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0624 21:50:36.475806 24300 solver.cpp:228] Iteration 2840, loss = 0.348147
I0624 21:50:36.475831 24300 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 21:50:36.475841 24300 solver.cpp:244]     Train net output #1: loss = 0.348147 (* 1 = 0.348147 loss)
I0624 21:50:36.475848 24300 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0624 21:50:38.575747 24300 solver.cpp:228] Iteration 2860, loss = 0.212747
I0624 21:50:38.575772 24300 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0624 21:50:38.575781 24300 solver.cpp:244]     Train net output #1: loss = 0.212747 (* 1 = 0.212747 loss)
I0624 21:50:38.575788 24300 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0624 21:50:40.674947 24300 solver.cpp:228] Iteration 2880, loss = 0.168703
I0624 21:50:40.674973 24300 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 21:50:40.674983 24300 solver.cpp:244]     Train net output #1: loss = 0.168703 (* 1 = 0.168703 loss)
I0624 21:50:40.674988 24300 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0624 21:50:42.743755 24300 solver.cpp:337] Iteration 2900, Testing net (#0)
I0624 21:50:46.739138 24300 solver.cpp:404]     Test net output #0: accuracy = 0.783203
I0624 21:50:46.739172 24300 solver.cpp:404]     Test net output #1: loss = 0.516464 (* 1 = 0.516464 loss)
I0624 21:50:46.774785 24300 solver.cpp:228] Iteration 2900, loss = 0.332175
I0624 21:50:46.774812 24300 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 21:50:46.774822 24300 solver.cpp:244]     Train net output #1: loss = 0.332175 (* 1 = 0.332175 loss)
I0624 21:50:46.774829 24300 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0624 21:50:48.880348 24300 solver.cpp:228] Iteration 2920, loss = 0.318201
I0624 21:50:48.880376 24300 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 21:50:48.880386 24300 solver.cpp:244]     Train net output #1: loss = 0.318201 (* 1 = 0.318201 loss)
I0624 21:50:48.880393 24300 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0624 21:50:50.980926 24300 solver.cpp:228] Iteration 2940, loss = 0.210578
I0624 21:50:50.980954 24300 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 21:50:50.980965 24300 solver.cpp:244]     Train net output #1: loss = 0.210578 (* 1 = 0.210578 loss)
I0624 21:50:50.980973 24300 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0624 21:50:53.080771 24300 solver.cpp:228] Iteration 2960, loss = 0.214182
I0624 21:50:53.080798 24300 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 21:50:53.080809 24300 solver.cpp:244]     Train net output #1: loss = 0.214182 (* 1 = 0.214182 loss)
I0624 21:50:53.080816 24300 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0624 21:50:55.180210 24300 solver.cpp:228] Iteration 2980, loss = 0.497354
I0624 21:50:55.180238 24300 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 21:50:55.180249 24300 solver.cpp:244]     Train net output #1: loss = 0.497354 (* 1 = 0.497354 loss)
I0624 21:50:55.180255 24300 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0624 21:50:57.249305 24300 solver.cpp:454] Snapshotting to binary proto file data/models/bpgnet_iter_3000.caffemodel
I0624 21:50:57.273344 24300 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpgnet_iter_3000.solverstate
I0624 21:50:57.320251 24300 solver.cpp:317] Iteration 3000, loss = 0.317369
I0624 21:50:57.320303 24300 solver.cpp:337] Iteration 3000, Testing net (#0)
I0624 21:51:01.337901 24300 solver.cpp:404]     Test net output #0: accuracy = 0.790039
I0624 21:51:01.338040 24300 solver.cpp:404]     Test net output #1: loss = 0.512499 (* 1 = 0.512499 loss)
I0624 21:51:01.338047 24300 solver.cpp:322] Optimization Done.
I0624 21:51:01.338049 24300 caffe.cpp:222] Optimization Done.
