I0627 16:24:59.669734  7639 caffe.cpp:185] Using GPUs 1
I0627 16:24:59.685817  7639 caffe.cpp:190] GPU 1: GeForce GTX TITAN X
I0627 16:25:00.038684  7639 solver.cpp:48] Initializing solver from parameters: 
test_iter: 64
test_interval: 100
base_lr: 0.001
display: 20
max_iter: 6000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 500
snapshot_prefix: "data/models/bpnet"
solver_mode: GPU
device_id: 1
net: "models/bpnet/train_val.prototxt"
test_initialization: true
iter_size: 1
I0627 16:25:00.038803  7639 solver.cpp:91] Creating training net from net file: models/bpnet/train_val.prototxt
I0627 16:25:00.039352  7639 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0627 16:25:00.039507  7639 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 100
    crop_h: 192
    crop_w: 256
    rotation_range: 10
    scale_jitter_range: 0.1
    contrast_jitter_range: 0.3
  }
  data_param {
    source: "data/train_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_1"
  top: "pool5"
  pooling_param {
    pool: AVE
    stride: 1
    kernel_h: 6
    kernel_w: 8
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0627 16:25:00.039636  7639 layer_factory.hpp:77] Creating layer data
I0627 16:25:00.040217  7639 net.cpp:91] Creating Layer data
I0627 16:25:00.040230  7639 net.cpp:399] data -> data
I0627 16:25:00.040251  7639 net.cpp:399] data -> label
I0627 16:25:00.041476  7643 db_lmdb.cpp:35] Opened lmdb data/train_lmdb
I0627 16:25:00.057879  7639 data_layer.cpp:42] output data size: 32,1,192,256
I0627 16:25:00.069926  7639 net.cpp:141] Setting up data
I0627 16:25:00.069954  7639 net.cpp:148] Top shape: 32 1 192 256 (1572864)
I0627 16:25:00.069958  7639 net.cpp:148] Top shape: 32 (32)
I0627 16:25:00.069962  7639 net.cpp:156] Memory required for data: 6291584
I0627 16:25:00.069968  7639 layer_factory.hpp:77] Creating layer label_data_1_split
I0627 16:25:00.069984  7639 net.cpp:91] Creating Layer label_data_1_split
I0627 16:25:00.069989  7639 net.cpp:425] label_data_1_split <- label
I0627 16:25:00.069999  7639 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0627 16:25:00.070008  7639 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0627 16:25:00.070086  7639 net.cpp:141] Setting up label_data_1_split
I0627 16:25:00.070094  7639 net.cpp:148] Top shape: 32 (32)
I0627 16:25:00.070098  7639 net.cpp:148] Top shape: 32 (32)
I0627 16:25:00.070101  7639 net.cpp:156] Memory required for data: 6291840
I0627 16:25:00.070102  7639 layer_factory.hpp:77] Creating layer conv1_1
I0627 16:25:00.070122  7639 net.cpp:91] Creating Layer conv1_1
I0627 16:25:00.070124  7639 net.cpp:425] conv1_1 <- data
I0627 16:25:00.070128  7639 net.cpp:399] conv1_1 -> conv1_1
I0627 16:25:00.438160  7639 net.cpp:141] Setting up conv1_1
I0627 16:25:00.438187  7639 net.cpp:148] Top shape: 32 32 96 128 (12582912)
I0627 16:25:00.438210  7639 net.cpp:156] Memory required for data: 56623488
I0627 16:25:00.438222  7639 layer_factory.hpp:77] Creating layer bn1_1
I0627 16:25:00.438236  7639 net.cpp:91] Creating Layer bn1_1
I0627 16:25:00.438241  7639 net.cpp:425] bn1_1 <- conv1_1
I0627 16:25:00.438244  7639 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0627 16:25:00.439013  7639 net.cpp:141] Setting up bn1_1
I0627 16:25:00.439024  7639 net.cpp:148] Top shape: 32 32 96 128 (12582912)
I0627 16:25:00.439026  7639 net.cpp:156] Memory required for data: 106955136
I0627 16:25:00.439038  7639 layer_factory.hpp:77] Creating layer scale1_1
I0627 16:25:00.439048  7639 net.cpp:91] Creating Layer scale1_1
I0627 16:25:00.439050  7639 net.cpp:425] scale1_1 <- conv1_1
I0627 16:25:00.439054  7639 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0627 16:25:00.439095  7639 layer_factory.hpp:77] Creating layer scale1_1
I0627 16:25:00.439196  7639 net.cpp:141] Setting up scale1_1
I0627 16:25:00.439203  7639 net.cpp:148] Top shape: 32 32 96 128 (12582912)
I0627 16:25:00.439205  7639 net.cpp:156] Memory required for data: 157286784
I0627 16:25:00.439211  7639 layer_factory.hpp:77] Creating layer relu1_1
I0627 16:25:00.439218  7639 net.cpp:91] Creating Layer relu1_1
I0627 16:25:00.439219  7639 net.cpp:425] relu1_1 <- conv1_1
I0627 16:25:00.439224  7639 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0627 16:25:00.439505  7639 net.cpp:141] Setting up relu1_1
I0627 16:25:00.439517  7639 net.cpp:148] Top shape: 32 32 96 128 (12582912)
I0627 16:25:00.439518  7639 net.cpp:156] Memory required for data: 207618432
I0627 16:25:00.439522  7639 layer_factory.hpp:77] Creating layer pool1
I0627 16:25:00.439527  7639 net.cpp:91] Creating Layer pool1
I0627 16:25:00.439529  7639 net.cpp:425] pool1 <- conv1_1
I0627 16:25:00.439535  7639 net.cpp:399] pool1 -> pool1
I0627 16:25:00.439582  7639 net.cpp:141] Setting up pool1
I0627 16:25:00.439589  7639 net.cpp:148] Top shape: 32 32 48 64 (3145728)
I0627 16:25:00.439591  7639 net.cpp:156] Memory required for data: 220201344
I0627 16:25:00.439594  7639 layer_factory.hpp:77] Creating layer conv2_1
I0627 16:25:00.439602  7639 net.cpp:91] Creating Layer conv2_1
I0627 16:25:00.439605  7639 net.cpp:425] conv2_1 <- pool1
I0627 16:25:00.439610  7639 net.cpp:399] conv2_1 -> conv2_1
I0627 16:25:00.441217  7639 net.cpp:141] Setting up conv2_1
I0627 16:25:00.441229  7639 net.cpp:148] Top shape: 32 64 48 64 (6291456)
I0627 16:25:00.441232  7639 net.cpp:156] Memory required for data: 245367168
I0627 16:25:00.441236  7639 layer_factory.hpp:77] Creating layer bn2_1
I0627 16:25:00.441246  7639 net.cpp:91] Creating Layer bn2_1
I0627 16:25:00.441247  7639 net.cpp:425] bn2_1 <- conv2_1
I0627 16:25:00.441252  7639 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0627 16:25:00.441408  7639 net.cpp:141] Setting up bn2_1
I0627 16:25:00.441416  7639 net.cpp:148] Top shape: 32 64 48 64 (6291456)
I0627 16:25:00.441418  7639 net.cpp:156] Memory required for data: 270532992
I0627 16:25:00.441426  7639 layer_factory.hpp:77] Creating layer scale2_1
I0627 16:25:00.441432  7639 net.cpp:91] Creating Layer scale2_1
I0627 16:25:00.441434  7639 net.cpp:425] scale2_1 <- conv2_1
I0627 16:25:00.441439  7639 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0627 16:25:00.441471  7639 layer_factory.hpp:77] Creating layer scale2_1
I0627 16:25:00.441561  7639 net.cpp:141] Setting up scale2_1
I0627 16:25:00.441568  7639 net.cpp:148] Top shape: 32 64 48 64 (6291456)
I0627 16:25:00.441571  7639 net.cpp:156] Memory required for data: 295698816
I0627 16:25:00.441576  7639 layer_factory.hpp:77] Creating layer relu2_1
I0627 16:25:00.441581  7639 net.cpp:91] Creating Layer relu2_1
I0627 16:25:00.441582  7639 net.cpp:425] relu2_1 <- conv2_1
I0627 16:25:00.441586  7639 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0627 16:25:00.441726  7639 net.cpp:141] Setting up relu2_1
I0627 16:25:00.441736  7639 net.cpp:148] Top shape: 32 64 48 64 (6291456)
I0627 16:25:00.441738  7639 net.cpp:156] Memory required for data: 320864640
I0627 16:25:00.441741  7639 layer_factory.hpp:77] Creating layer pool2
I0627 16:25:00.441756  7639 net.cpp:91] Creating Layer pool2
I0627 16:25:00.441759  7639 net.cpp:425] pool2 <- conv2_1
I0627 16:25:00.441763  7639 net.cpp:399] pool2 -> pool2
I0627 16:25:00.441799  7639 net.cpp:141] Setting up pool2
I0627 16:25:00.441807  7639 net.cpp:148] Top shape: 32 64 24 32 (1572864)
I0627 16:25:00.441808  7639 net.cpp:156] Memory required for data: 327156096
I0627 16:25:00.441810  7639 layer_factory.hpp:77] Creating layer conv3_1
I0627 16:25:00.441818  7639 net.cpp:91] Creating Layer conv3_1
I0627 16:25:00.441820  7639 net.cpp:425] conv3_1 <- pool2
I0627 16:25:00.441824  7639 net.cpp:399] conv3_1 -> conv3_1
I0627 16:25:00.443727  7639 net.cpp:141] Setting up conv3_1
I0627 16:25:00.443738  7639 net.cpp:148] Top shape: 32 128 24 32 (3145728)
I0627 16:25:00.443742  7639 net.cpp:156] Memory required for data: 339739008
I0627 16:25:00.443745  7639 layer_factory.hpp:77] Creating layer bn3_1
I0627 16:25:00.443753  7639 net.cpp:91] Creating Layer bn3_1
I0627 16:25:00.443755  7639 net.cpp:425] bn3_1 <- conv3_1
I0627 16:25:00.443760  7639 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0627 16:25:00.444488  7639 net.cpp:141] Setting up bn3_1
I0627 16:25:00.444499  7639 net.cpp:148] Top shape: 32 128 24 32 (3145728)
I0627 16:25:00.444500  7639 net.cpp:156] Memory required for data: 352321920
I0627 16:25:00.444506  7639 layer_factory.hpp:77] Creating layer scale3_1
I0627 16:25:00.444514  7639 net.cpp:91] Creating Layer scale3_1
I0627 16:25:00.444515  7639 net.cpp:425] scale3_1 <- conv3_1
I0627 16:25:00.444519  7639 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0627 16:25:00.444555  7639 layer_factory.hpp:77] Creating layer scale3_1
I0627 16:25:00.444628  7639 net.cpp:141] Setting up scale3_1
I0627 16:25:00.444634  7639 net.cpp:148] Top shape: 32 128 24 32 (3145728)
I0627 16:25:00.444638  7639 net.cpp:156] Memory required for data: 364904832
I0627 16:25:00.444644  7639 layer_factory.hpp:77] Creating layer relu3_1
I0627 16:25:00.444649  7639 net.cpp:91] Creating Layer relu3_1
I0627 16:25:00.444651  7639 net.cpp:425] relu3_1 <- conv3_1
I0627 16:25:00.444655  7639 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0627 16:25:00.444926  7639 net.cpp:141] Setting up relu3_1
I0627 16:25:00.444936  7639 net.cpp:148] Top shape: 32 128 24 32 (3145728)
I0627 16:25:00.444939  7639 net.cpp:156] Memory required for data: 377487744
I0627 16:25:00.444941  7639 layer_factory.hpp:77] Creating layer pool3
I0627 16:25:00.444949  7639 net.cpp:91] Creating Layer pool3
I0627 16:25:00.444952  7639 net.cpp:425] pool3 <- conv3_1
I0627 16:25:00.444957  7639 net.cpp:399] pool3 -> pool3
I0627 16:25:00.444993  7639 net.cpp:141] Setting up pool3
I0627 16:25:00.444998  7639 net.cpp:148] Top shape: 32 128 12 16 (786432)
I0627 16:25:00.445000  7639 net.cpp:156] Memory required for data: 380633472
I0627 16:25:00.445003  7639 layer_factory.hpp:77] Creating layer conv4_1
I0627 16:25:00.445009  7639 net.cpp:91] Creating Layer conv4_1
I0627 16:25:00.445013  7639 net.cpp:425] conv4_1 <- pool3
I0627 16:25:00.445017  7639 net.cpp:399] conv4_1 -> conv4_1
I0627 16:25:00.448107  7639 net.cpp:141] Setting up conv4_1
I0627 16:25:00.448118  7639 net.cpp:148] Top shape: 32 256 12 16 (1572864)
I0627 16:25:00.448122  7639 net.cpp:156] Memory required for data: 386924928
I0627 16:25:00.448127  7639 layer_factory.hpp:77] Creating layer bn4_1
I0627 16:25:00.448133  7639 net.cpp:91] Creating Layer bn4_1
I0627 16:25:00.448137  7639 net.cpp:425] bn4_1 <- conv4_1
I0627 16:25:00.448140  7639 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0627 16:25:00.448287  7639 net.cpp:141] Setting up bn4_1
I0627 16:25:00.448294  7639 net.cpp:148] Top shape: 32 256 12 16 (1572864)
I0627 16:25:00.448297  7639 net.cpp:156] Memory required for data: 393216384
I0627 16:25:00.448302  7639 layer_factory.hpp:77] Creating layer scale4_1
I0627 16:25:00.448308  7639 net.cpp:91] Creating Layer scale4_1
I0627 16:25:00.448312  7639 net.cpp:425] scale4_1 <- conv4_1
I0627 16:25:00.448314  7639 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0627 16:25:00.448348  7639 layer_factory.hpp:77] Creating layer scale4_1
I0627 16:25:00.448442  7639 net.cpp:141] Setting up scale4_1
I0627 16:25:00.448449  7639 net.cpp:148] Top shape: 32 256 12 16 (1572864)
I0627 16:25:00.448451  7639 net.cpp:156] Memory required for data: 399507840
I0627 16:25:00.448457  7639 layer_factory.hpp:77] Creating layer relu4_1
I0627 16:25:00.448462  7639 net.cpp:91] Creating Layer relu4_1
I0627 16:25:00.448464  7639 net.cpp:425] relu4_1 <- conv4_1
I0627 16:25:00.448467  7639 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0627 16:25:00.448731  7639 net.cpp:141] Setting up relu4_1
I0627 16:25:00.448741  7639 net.cpp:148] Top shape: 32 256 12 16 (1572864)
I0627 16:25:00.448745  7639 net.cpp:156] Memory required for data: 405799296
I0627 16:25:00.448747  7639 layer_factory.hpp:77] Creating layer pool4
I0627 16:25:00.448753  7639 net.cpp:91] Creating Layer pool4
I0627 16:25:00.448756  7639 net.cpp:425] pool4 <- conv4_1
I0627 16:25:00.448760  7639 net.cpp:399] pool4 -> pool4
I0627 16:25:00.448799  7639 net.cpp:141] Setting up pool4
I0627 16:25:00.448804  7639 net.cpp:148] Top shape: 32 256 6 8 (393216)
I0627 16:25:00.448807  7639 net.cpp:156] Memory required for data: 407372160
I0627 16:25:00.448808  7639 layer_factory.hpp:77] Creating layer conv5_1
I0627 16:25:00.448815  7639 net.cpp:91] Creating Layer conv5_1
I0627 16:25:00.448818  7639 net.cpp:425] conv5_1 <- pool4
I0627 16:25:00.448822  7639 net.cpp:399] conv5_1 -> conv5_1
I0627 16:25:00.454244  7639 net.cpp:141] Setting up conv5_1
I0627 16:25:00.454259  7639 net.cpp:148] Top shape: 32 256 6 8 (393216)
I0627 16:25:00.454262  7639 net.cpp:156] Memory required for data: 408945024
I0627 16:25:00.454268  7639 layer_factory.hpp:77] Creating layer bn5_1
I0627 16:25:00.454275  7639 net.cpp:91] Creating Layer bn5_1
I0627 16:25:00.454278  7639 net.cpp:425] bn5_1 <- conv5_1
I0627 16:25:00.454282  7639 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0627 16:25:00.454437  7639 net.cpp:141] Setting up bn5_1
I0627 16:25:00.454445  7639 net.cpp:148] Top shape: 32 256 6 8 (393216)
I0627 16:25:00.454447  7639 net.cpp:156] Memory required for data: 410517888
I0627 16:25:00.454452  7639 layer_factory.hpp:77] Creating layer scale5_1
I0627 16:25:00.454459  7639 net.cpp:91] Creating Layer scale5_1
I0627 16:25:00.454462  7639 net.cpp:425] scale5_1 <- conv5_1
I0627 16:25:00.454464  7639 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0627 16:25:00.454499  7639 layer_factory.hpp:77] Creating layer scale5_1
I0627 16:25:00.454583  7639 net.cpp:141] Setting up scale5_1
I0627 16:25:00.454589  7639 net.cpp:148] Top shape: 32 256 6 8 (393216)
I0627 16:25:00.454592  7639 net.cpp:156] Memory required for data: 412090752
I0627 16:25:00.454596  7639 layer_factory.hpp:77] Creating layer relu5_1
I0627 16:25:00.454602  7639 net.cpp:91] Creating Layer relu5_1
I0627 16:25:00.454603  7639 net.cpp:425] relu5_1 <- conv5_1
I0627 16:25:00.454607  7639 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0627 16:25:00.454751  7639 net.cpp:141] Setting up relu5_1
I0627 16:25:00.454758  7639 net.cpp:148] Top shape: 32 256 6 8 (393216)
I0627 16:25:00.454761  7639 net.cpp:156] Memory required for data: 413663616
I0627 16:25:00.454763  7639 layer_factory.hpp:77] Creating layer pool5
I0627 16:25:00.454769  7639 net.cpp:91] Creating Layer pool5
I0627 16:25:00.454771  7639 net.cpp:425] pool5 <- conv5_1
I0627 16:25:00.454776  7639 net.cpp:399] pool5 -> pool5
I0627 16:25:00.455062  7639 net.cpp:141] Setting up pool5
I0627 16:25:00.455073  7639 net.cpp:148] Top shape: 32 256 1 1 (8192)
I0627 16:25:00.455075  7639 net.cpp:156] Memory required for data: 413696384
I0627 16:25:00.455078  7639 layer_factory.hpp:77] Creating layer fc2
I0627 16:25:00.455085  7639 net.cpp:91] Creating Layer fc2
I0627 16:25:00.455087  7639 net.cpp:425] fc2 <- pool5
I0627 16:25:00.455092  7639 net.cpp:399] fc2 -> fc2
I0627 16:25:00.455178  7639 net.cpp:141] Setting up fc2
I0627 16:25:00.455185  7639 net.cpp:148] Top shape: 32 2 (64)
I0627 16:25:00.455188  7639 net.cpp:156] Memory required for data: 413696640
I0627 16:25:00.455193  7639 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0627 16:25:00.455207  7639 net.cpp:91] Creating Layer fc2_fc2_0_split
I0627 16:25:00.455210  7639 net.cpp:425] fc2_fc2_0_split <- fc2
I0627 16:25:00.455214  7639 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0627 16:25:00.455219  7639 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0627 16:25:00.455251  7639 net.cpp:141] Setting up fc2_fc2_0_split
I0627 16:25:00.455256  7639 net.cpp:148] Top shape: 32 2 (64)
I0627 16:25:00.455260  7639 net.cpp:148] Top shape: 32 2 (64)
I0627 16:25:00.455262  7639 net.cpp:156] Memory required for data: 413697152
I0627 16:25:00.455265  7639 layer_factory.hpp:77] Creating layer loss
I0627 16:25:00.455270  7639 net.cpp:91] Creating Layer loss
I0627 16:25:00.455271  7639 net.cpp:425] loss <- fc2_fc2_0_split_0
I0627 16:25:00.455274  7639 net.cpp:425] loss <- label_data_1_split_0
I0627 16:25:00.455278  7639 net.cpp:399] loss -> loss
I0627 16:25:00.455284  7639 layer_factory.hpp:77] Creating layer loss
I0627 16:25:00.455504  7639 net.cpp:141] Setting up loss
I0627 16:25:00.455514  7639 net.cpp:148] Top shape: (1)
I0627 16:25:00.455516  7639 net.cpp:151]     with loss weight 1
I0627 16:25:00.455533  7639 net.cpp:156] Memory required for data: 413697156
I0627 16:25:00.455535  7639 layer_factory.hpp:77] Creating layer accuracy
I0627 16:25:00.455539  7639 net.cpp:91] Creating Layer accuracy
I0627 16:25:00.455543  7639 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0627 16:25:00.455548  7639 net.cpp:425] accuracy <- label_data_1_split_1
I0627 16:25:00.455550  7639 net.cpp:399] accuracy -> accuracy
I0627 16:25:00.455556  7639 net.cpp:141] Setting up accuracy
I0627 16:25:00.455559  7639 net.cpp:148] Top shape: (1)
I0627 16:25:00.455561  7639 net.cpp:156] Memory required for data: 413697160
I0627 16:25:00.455564  7639 net.cpp:219] accuracy does not need backward computation.
I0627 16:25:00.455566  7639 net.cpp:217] loss needs backward computation.
I0627 16:25:00.455569  7639 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0627 16:25:00.455571  7639 net.cpp:217] fc2 needs backward computation.
I0627 16:25:00.455574  7639 net.cpp:217] pool5 needs backward computation.
I0627 16:25:00.455576  7639 net.cpp:217] relu5_1 needs backward computation.
I0627 16:25:00.455579  7639 net.cpp:217] scale5_1 needs backward computation.
I0627 16:25:00.455580  7639 net.cpp:217] bn5_1 needs backward computation.
I0627 16:25:00.455582  7639 net.cpp:217] conv5_1 needs backward computation.
I0627 16:25:00.455585  7639 net.cpp:217] pool4 needs backward computation.
I0627 16:25:00.455587  7639 net.cpp:217] relu4_1 needs backward computation.
I0627 16:25:00.455590  7639 net.cpp:217] scale4_1 needs backward computation.
I0627 16:25:00.455591  7639 net.cpp:217] bn4_1 needs backward computation.
I0627 16:25:00.455593  7639 net.cpp:217] conv4_1 needs backward computation.
I0627 16:25:00.455595  7639 net.cpp:217] pool3 needs backward computation.
I0627 16:25:00.455598  7639 net.cpp:217] relu3_1 needs backward computation.
I0627 16:25:00.455600  7639 net.cpp:217] scale3_1 needs backward computation.
I0627 16:25:00.455602  7639 net.cpp:217] bn3_1 needs backward computation.
I0627 16:25:00.455605  7639 net.cpp:217] conv3_1 needs backward computation.
I0627 16:25:00.455606  7639 net.cpp:217] pool2 needs backward computation.
I0627 16:25:00.455610  7639 net.cpp:217] relu2_1 needs backward computation.
I0627 16:25:00.455611  7639 net.cpp:217] scale2_1 needs backward computation.
I0627 16:25:00.455613  7639 net.cpp:217] bn2_1 needs backward computation.
I0627 16:25:00.455615  7639 net.cpp:217] conv2_1 needs backward computation.
I0627 16:25:00.455617  7639 net.cpp:217] pool1 needs backward computation.
I0627 16:25:00.455621  7639 net.cpp:217] relu1_1 needs backward computation.
I0627 16:25:00.455623  7639 net.cpp:217] scale1_1 needs backward computation.
I0627 16:25:00.455626  7639 net.cpp:217] bn1_1 needs backward computation.
I0627 16:25:00.455627  7639 net.cpp:217] conv1_1 needs backward computation.
I0627 16:25:00.455631  7639 net.cpp:219] label_data_1_split does not need backward computation.
I0627 16:25:00.455632  7639 net.cpp:219] data does not need backward computation.
I0627 16:25:00.455643  7639 net.cpp:261] This network produces output accuracy
I0627 16:25:00.455646  7639 net.cpp:261] This network produces output loss
I0627 16:25:00.455662  7639 net.cpp:274] Network initialization done.
I0627 16:25:00.456210  7639 solver.cpp:181] Creating test net (#0) specified by net file: models/bpnet/train_val.prototxt
I0627 16:25:00.456248  7639 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0627 16:25:00.456387  7639 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 100
    crop_h: 192
    crop_w: 256
  }
  data_param {
    source: "data/val_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_1"
  top: "pool5"
  pooling_param {
    pool: AVE
    stride: 1
    kernel_h: 6
    kernel_w: 8
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0627 16:25:00.456488  7639 layer_factory.hpp:77] Creating layer data
I0627 16:25:00.456562  7639 net.cpp:91] Creating Layer data
I0627 16:25:00.456569  7639 net.cpp:399] data -> data
I0627 16:25:00.456575  7639 net.cpp:399] data -> label
I0627 16:25:00.457896  7652 db_lmdb.cpp:35] Opened lmdb data/val_lmdb
I0627 16:25:00.458104  7639 data_layer.cpp:42] output data size: 64,1,192,256
I0627 16:25:00.484307  7639 net.cpp:141] Setting up data
I0627 16:25:00.484331  7639 net.cpp:148] Top shape: 64 1 192 256 (3145728)
I0627 16:25:00.484338  7639 net.cpp:148] Top shape: 64 (64)
I0627 16:25:00.484339  7639 net.cpp:156] Memory required for data: 12583168
I0627 16:25:00.484345  7639 layer_factory.hpp:77] Creating layer label_data_1_split
I0627 16:25:00.484356  7639 net.cpp:91] Creating Layer label_data_1_split
I0627 16:25:00.484359  7639 net.cpp:425] label_data_1_split <- label
I0627 16:25:00.484366  7639 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0627 16:25:00.484374  7639 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0627 16:25:00.484432  7639 net.cpp:141] Setting up label_data_1_split
I0627 16:25:00.484437  7639 net.cpp:148] Top shape: 64 (64)
I0627 16:25:00.484441  7639 net.cpp:148] Top shape: 64 (64)
I0627 16:25:00.484442  7639 net.cpp:156] Memory required for data: 12583680
I0627 16:25:00.484444  7639 layer_factory.hpp:77] Creating layer conv1_1
I0627 16:25:00.484457  7639 net.cpp:91] Creating Layer conv1_1
I0627 16:25:00.484458  7639 net.cpp:425] conv1_1 <- data
I0627 16:25:00.484463  7639 net.cpp:399] conv1_1 -> conv1_1
I0627 16:25:00.485713  7639 net.cpp:141] Setting up conv1_1
I0627 16:25:00.485725  7639 net.cpp:148] Top shape: 64 32 96 128 (25165824)
I0627 16:25:00.485728  7639 net.cpp:156] Memory required for data: 113246976
I0627 16:25:00.485735  7639 layer_factory.hpp:77] Creating layer bn1_1
I0627 16:25:00.485743  7639 net.cpp:91] Creating Layer bn1_1
I0627 16:25:00.485760  7639 net.cpp:425] bn1_1 <- conv1_1
I0627 16:25:00.485764  7639 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0627 16:25:00.485941  7639 net.cpp:141] Setting up bn1_1
I0627 16:25:00.485949  7639 net.cpp:148] Top shape: 64 32 96 128 (25165824)
I0627 16:25:00.485952  7639 net.cpp:156] Memory required for data: 213910272
I0627 16:25:00.485960  7639 layer_factory.hpp:77] Creating layer scale1_1
I0627 16:25:00.485968  7639 net.cpp:91] Creating Layer scale1_1
I0627 16:25:00.485970  7639 net.cpp:425] scale1_1 <- conv1_1
I0627 16:25:00.485976  7639 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0627 16:25:00.486012  7639 layer_factory.hpp:77] Creating layer scale1_1
I0627 16:25:00.486124  7639 net.cpp:141] Setting up scale1_1
I0627 16:25:00.486131  7639 net.cpp:148] Top shape: 64 32 96 128 (25165824)
I0627 16:25:00.486134  7639 net.cpp:156] Memory required for data: 314573568
I0627 16:25:00.486140  7639 layer_factory.hpp:77] Creating layer relu1_1
I0627 16:25:00.486145  7639 net.cpp:91] Creating Layer relu1_1
I0627 16:25:00.486147  7639 net.cpp:425] relu1_1 <- conv1_1
I0627 16:25:00.486151  7639 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0627 16:25:00.487490  7639 net.cpp:141] Setting up relu1_1
I0627 16:25:00.487504  7639 net.cpp:148] Top shape: 64 32 96 128 (25165824)
I0627 16:25:00.487505  7639 net.cpp:156] Memory required for data: 415236864
I0627 16:25:00.487509  7639 layer_factory.hpp:77] Creating layer pool1
I0627 16:25:00.487516  7639 net.cpp:91] Creating Layer pool1
I0627 16:25:00.487519  7639 net.cpp:425] pool1 <- conv1_1
I0627 16:25:00.487524  7639 net.cpp:399] pool1 -> pool1
I0627 16:25:00.487576  7639 net.cpp:141] Setting up pool1
I0627 16:25:00.487581  7639 net.cpp:148] Top shape: 64 32 48 64 (6291456)
I0627 16:25:00.487582  7639 net.cpp:156] Memory required for data: 440402688
I0627 16:25:00.487584  7639 layer_factory.hpp:77] Creating layer conv2_1
I0627 16:25:00.487593  7639 net.cpp:91] Creating Layer conv2_1
I0627 16:25:00.487596  7639 net.cpp:425] conv2_1 <- pool1
I0627 16:25:00.487599  7639 net.cpp:399] conv2_1 -> conv2_1
I0627 16:25:00.488567  7639 net.cpp:141] Setting up conv2_1
I0627 16:25:00.488579  7639 net.cpp:148] Top shape: 64 64 48 64 (12582912)
I0627 16:25:00.488582  7639 net.cpp:156] Memory required for data: 490734336
I0627 16:25:00.488586  7639 layer_factory.hpp:77] Creating layer bn2_1
I0627 16:25:00.488593  7639 net.cpp:91] Creating Layer bn2_1
I0627 16:25:00.488596  7639 net.cpp:425] bn2_1 <- conv2_1
I0627 16:25:00.488601  7639 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0627 16:25:00.488770  7639 net.cpp:141] Setting up bn2_1
I0627 16:25:00.488777  7639 net.cpp:148] Top shape: 64 64 48 64 (12582912)
I0627 16:25:00.488780  7639 net.cpp:156] Memory required for data: 541065984
I0627 16:25:00.488787  7639 layer_factory.hpp:77] Creating layer scale2_1
I0627 16:25:00.488795  7639 net.cpp:91] Creating Layer scale2_1
I0627 16:25:00.488796  7639 net.cpp:425] scale2_1 <- conv2_1
I0627 16:25:00.488800  7639 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0627 16:25:00.488834  7639 layer_factory.hpp:77] Creating layer scale2_1
I0627 16:25:00.488927  7639 net.cpp:141] Setting up scale2_1
I0627 16:25:00.488934  7639 net.cpp:148] Top shape: 64 64 48 64 (12582912)
I0627 16:25:00.488936  7639 net.cpp:156] Memory required for data: 591397632
I0627 16:25:00.488940  7639 layer_factory.hpp:77] Creating layer relu2_1
I0627 16:25:00.488945  7639 net.cpp:91] Creating Layer relu2_1
I0627 16:25:00.488947  7639 net.cpp:425] relu2_1 <- conv2_1
I0627 16:25:00.488951  7639 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0627 16:25:00.489214  7639 net.cpp:141] Setting up relu2_1
I0627 16:25:00.489225  7639 net.cpp:148] Top shape: 64 64 48 64 (12582912)
I0627 16:25:00.489228  7639 net.cpp:156] Memory required for data: 641729280
I0627 16:25:00.489230  7639 layer_factory.hpp:77] Creating layer pool2
I0627 16:25:00.489236  7639 net.cpp:91] Creating Layer pool2
I0627 16:25:00.489238  7639 net.cpp:425] pool2 <- conv2_1
I0627 16:25:00.489243  7639 net.cpp:399] pool2 -> pool2
I0627 16:25:00.489282  7639 net.cpp:141] Setting up pool2
I0627 16:25:00.489297  7639 net.cpp:148] Top shape: 64 64 24 32 (3145728)
I0627 16:25:00.489300  7639 net.cpp:156] Memory required for data: 654312192
I0627 16:25:00.489301  7639 layer_factory.hpp:77] Creating layer conv3_1
I0627 16:25:00.489310  7639 net.cpp:91] Creating Layer conv3_1
I0627 16:25:00.489312  7639 net.cpp:425] conv3_1 <- pool2
I0627 16:25:00.489316  7639 net.cpp:399] conv3_1 -> conv3_1
I0627 16:25:00.490689  7639 net.cpp:141] Setting up conv3_1
I0627 16:25:00.490701  7639 net.cpp:148] Top shape: 64 128 24 32 (6291456)
I0627 16:25:00.490703  7639 net.cpp:156] Memory required for data: 679478016
I0627 16:25:00.490708  7639 layer_factory.hpp:77] Creating layer bn3_1
I0627 16:25:00.490715  7639 net.cpp:91] Creating Layer bn3_1
I0627 16:25:00.490717  7639 net.cpp:425] bn3_1 <- conv3_1
I0627 16:25:00.490722  7639 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0627 16:25:00.490881  7639 net.cpp:141] Setting up bn3_1
I0627 16:25:00.490888  7639 net.cpp:148] Top shape: 64 128 24 32 (6291456)
I0627 16:25:00.490891  7639 net.cpp:156] Memory required for data: 704643840
I0627 16:25:00.490896  7639 layer_factory.hpp:77] Creating layer scale3_1
I0627 16:25:00.490902  7639 net.cpp:91] Creating Layer scale3_1
I0627 16:25:00.490905  7639 net.cpp:425] scale3_1 <- conv3_1
I0627 16:25:00.490909  7639 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0627 16:25:00.490943  7639 layer_factory.hpp:77] Creating layer scale3_1
I0627 16:25:00.491024  7639 net.cpp:141] Setting up scale3_1
I0627 16:25:00.491031  7639 net.cpp:148] Top shape: 64 128 24 32 (6291456)
I0627 16:25:00.491034  7639 net.cpp:156] Memory required for data: 729809664
I0627 16:25:00.491041  7639 layer_factory.hpp:77] Creating layer relu3_1
I0627 16:25:00.491045  7639 net.cpp:91] Creating Layer relu3_1
I0627 16:25:00.491049  7639 net.cpp:425] relu3_1 <- conv3_1
I0627 16:25:00.491051  7639 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0627 16:25:00.491195  7639 net.cpp:141] Setting up relu3_1
I0627 16:25:00.491204  7639 net.cpp:148] Top shape: 64 128 24 32 (6291456)
I0627 16:25:00.491205  7639 net.cpp:156] Memory required for data: 754975488
I0627 16:25:00.491209  7639 layer_factory.hpp:77] Creating layer pool3
I0627 16:25:00.491221  7639 net.cpp:91] Creating Layer pool3
I0627 16:25:00.491224  7639 net.cpp:425] pool3 <- conv3_1
I0627 16:25:00.491227  7639 net.cpp:399] pool3 -> pool3
I0627 16:25:00.491264  7639 net.cpp:141] Setting up pool3
I0627 16:25:00.491269  7639 net.cpp:148] Top shape: 64 128 12 16 (1572864)
I0627 16:25:00.491271  7639 net.cpp:156] Memory required for data: 761266944
I0627 16:25:00.491273  7639 layer_factory.hpp:77] Creating layer conv4_1
I0627 16:25:00.491282  7639 net.cpp:91] Creating Layer conv4_1
I0627 16:25:00.491284  7639 net.cpp:425] conv4_1 <- pool3
I0627 16:25:00.491288  7639 net.cpp:399] conv4_1 -> conv4_1
I0627 16:25:00.494518  7639 net.cpp:141] Setting up conv4_1
I0627 16:25:00.494530  7639 net.cpp:148] Top shape: 64 256 12 16 (3145728)
I0627 16:25:00.494534  7639 net.cpp:156] Memory required for data: 773849856
I0627 16:25:00.494539  7639 layer_factory.hpp:77] Creating layer bn4_1
I0627 16:25:00.494544  7639 net.cpp:91] Creating Layer bn4_1
I0627 16:25:00.494547  7639 net.cpp:425] bn4_1 <- conv4_1
I0627 16:25:00.494551  7639 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0627 16:25:00.494712  7639 net.cpp:141] Setting up bn4_1
I0627 16:25:00.494719  7639 net.cpp:148] Top shape: 64 256 12 16 (3145728)
I0627 16:25:00.494722  7639 net.cpp:156] Memory required for data: 786432768
I0627 16:25:00.494729  7639 layer_factory.hpp:77] Creating layer scale4_1
I0627 16:25:00.494734  7639 net.cpp:91] Creating Layer scale4_1
I0627 16:25:00.494735  7639 net.cpp:425] scale4_1 <- conv4_1
I0627 16:25:00.494738  7639 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0627 16:25:00.494773  7639 layer_factory.hpp:77] Creating layer scale4_1
I0627 16:25:00.494859  7639 net.cpp:141] Setting up scale4_1
I0627 16:25:00.494866  7639 net.cpp:148] Top shape: 64 256 12 16 (3145728)
I0627 16:25:00.494868  7639 net.cpp:156] Memory required for data: 799015680
I0627 16:25:00.494881  7639 layer_factory.hpp:77] Creating layer relu4_1
I0627 16:25:00.494889  7639 net.cpp:91] Creating Layer relu4_1
I0627 16:25:00.494890  7639 net.cpp:425] relu4_1 <- conv4_1
I0627 16:25:00.494894  7639 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0627 16:25:00.495169  7639 net.cpp:141] Setting up relu4_1
I0627 16:25:00.495179  7639 net.cpp:148] Top shape: 64 256 12 16 (3145728)
I0627 16:25:00.495182  7639 net.cpp:156] Memory required for data: 811598592
I0627 16:25:00.495185  7639 layer_factory.hpp:77] Creating layer pool4
I0627 16:25:00.495190  7639 net.cpp:91] Creating Layer pool4
I0627 16:25:00.495194  7639 net.cpp:425] pool4 <- conv4_1
I0627 16:25:00.495198  7639 net.cpp:399] pool4 -> pool4
I0627 16:25:00.495239  7639 net.cpp:141] Setting up pool4
I0627 16:25:00.495244  7639 net.cpp:148] Top shape: 64 256 6 8 (786432)
I0627 16:25:00.495246  7639 net.cpp:156] Memory required for data: 814744320
I0627 16:25:00.495249  7639 layer_factory.hpp:77] Creating layer conv5_1
I0627 16:25:00.495256  7639 net.cpp:91] Creating Layer conv5_1
I0627 16:25:00.495260  7639 net.cpp:425] conv5_1 <- pool4
I0627 16:25:00.495263  7639 net.cpp:399] conv5_1 -> conv5_1
I0627 16:25:00.500545  7639 net.cpp:141] Setting up conv5_1
I0627 16:25:00.500558  7639 net.cpp:148] Top shape: 64 256 6 8 (786432)
I0627 16:25:00.500561  7639 net.cpp:156] Memory required for data: 817890048
I0627 16:25:00.500566  7639 layer_factory.hpp:77] Creating layer bn5_1
I0627 16:25:00.500572  7639 net.cpp:91] Creating Layer bn5_1
I0627 16:25:00.500576  7639 net.cpp:425] bn5_1 <- conv5_1
I0627 16:25:00.500581  7639 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0627 16:25:00.500753  7639 net.cpp:141] Setting up bn5_1
I0627 16:25:00.500761  7639 net.cpp:148] Top shape: 64 256 6 8 (786432)
I0627 16:25:00.500763  7639 net.cpp:156] Memory required for data: 821035776
I0627 16:25:00.500769  7639 layer_factory.hpp:77] Creating layer scale5_1
I0627 16:25:00.500774  7639 net.cpp:91] Creating Layer scale5_1
I0627 16:25:00.500777  7639 net.cpp:425] scale5_1 <- conv5_1
I0627 16:25:00.500780  7639 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0627 16:25:00.500815  7639 layer_factory.hpp:77] Creating layer scale5_1
I0627 16:25:00.500912  7639 net.cpp:141] Setting up scale5_1
I0627 16:25:00.500919  7639 net.cpp:148] Top shape: 64 256 6 8 (786432)
I0627 16:25:00.500922  7639 net.cpp:156] Memory required for data: 824181504
I0627 16:25:00.500927  7639 layer_factory.hpp:77] Creating layer relu5_1
I0627 16:25:00.500931  7639 net.cpp:91] Creating Layer relu5_1
I0627 16:25:00.500933  7639 net.cpp:425] relu5_1 <- conv5_1
I0627 16:25:00.500938  7639 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0627 16:25:00.501199  7639 net.cpp:141] Setting up relu5_1
I0627 16:25:00.501209  7639 net.cpp:148] Top shape: 64 256 6 8 (786432)
I0627 16:25:00.501211  7639 net.cpp:156] Memory required for data: 827327232
I0627 16:25:00.501214  7639 layer_factory.hpp:77] Creating layer pool5
I0627 16:25:00.501219  7639 net.cpp:91] Creating Layer pool5
I0627 16:25:00.501222  7639 net.cpp:425] pool5 <- conv5_1
I0627 16:25:00.501227  7639 net.cpp:399] pool5 -> pool5
I0627 16:25:00.501512  7639 net.cpp:141] Setting up pool5
I0627 16:25:00.501523  7639 net.cpp:148] Top shape: 64 256 1 1 (16384)
I0627 16:25:00.501524  7639 net.cpp:156] Memory required for data: 827392768
I0627 16:25:00.501528  7639 layer_factory.hpp:77] Creating layer fc2
I0627 16:25:00.501533  7639 net.cpp:91] Creating Layer fc2
I0627 16:25:00.501536  7639 net.cpp:425] fc2 <- pool5
I0627 16:25:00.501545  7639 net.cpp:399] fc2 -> fc2
I0627 16:25:00.501639  7639 net.cpp:141] Setting up fc2
I0627 16:25:00.501646  7639 net.cpp:148] Top shape: 64 2 (128)
I0627 16:25:00.501648  7639 net.cpp:156] Memory required for data: 827393280
I0627 16:25:00.501653  7639 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0627 16:25:00.501660  7639 net.cpp:91] Creating Layer fc2_fc2_0_split
I0627 16:25:00.501662  7639 net.cpp:425] fc2_fc2_0_split <- fc2
I0627 16:25:00.501667  7639 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0627 16:25:00.501672  7639 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0627 16:25:00.501718  7639 net.cpp:141] Setting up fc2_fc2_0_split
I0627 16:25:00.501724  7639 net.cpp:148] Top shape: 64 2 (128)
I0627 16:25:00.501726  7639 net.cpp:148] Top shape: 64 2 (128)
I0627 16:25:00.501729  7639 net.cpp:156] Memory required for data: 827394304
I0627 16:25:00.501731  7639 layer_factory.hpp:77] Creating layer loss
I0627 16:25:00.501735  7639 net.cpp:91] Creating Layer loss
I0627 16:25:00.501737  7639 net.cpp:425] loss <- fc2_fc2_0_split_0
I0627 16:25:00.501741  7639 net.cpp:425] loss <- label_data_1_split_0
I0627 16:25:00.501744  7639 net.cpp:399] loss -> loss
I0627 16:25:00.501750  7639 layer_factory.hpp:77] Creating layer loss
I0627 16:25:00.501960  7639 net.cpp:141] Setting up loss
I0627 16:25:00.501968  7639 net.cpp:148] Top shape: (1)
I0627 16:25:00.501972  7639 net.cpp:151]     with loss weight 1
I0627 16:25:00.501981  7639 net.cpp:156] Memory required for data: 827394308
I0627 16:25:00.501983  7639 layer_factory.hpp:77] Creating layer accuracy
I0627 16:25:00.501989  7639 net.cpp:91] Creating Layer accuracy
I0627 16:25:00.501992  7639 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0627 16:25:00.501996  7639 net.cpp:425] accuracy <- label_data_1_split_1
I0627 16:25:00.501999  7639 net.cpp:399] accuracy -> accuracy
I0627 16:25:00.502005  7639 net.cpp:141] Setting up accuracy
I0627 16:25:00.502009  7639 net.cpp:148] Top shape: (1)
I0627 16:25:00.502012  7639 net.cpp:156] Memory required for data: 827394312
I0627 16:25:00.502013  7639 net.cpp:219] accuracy does not need backward computation.
I0627 16:25:00.502017  7639 net.cpp:217] loss needs backward computation.
I0627 16:25:00.502019  7639 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0627 16:25:00.502022  7639 net.cpp:217] fc2 needs backward computation.
I0627 16:25:00.502023  7639 net.cpp:217] pool5 needs backward computation.
I0627 16:25:00.502027  7639 net.cpp:217] relu5_1 needs backward computation.
I0627 16:25:00.502028  7639 net.cpp:217] scale5_1 needs backward computation.
I0627 16:25:00.502030  7639 net.cpp:217] bn5_1 needs backward computation.
I0627 16:25:00.502032  7639 net.cpp:217] conv5_1 needs backward computation.
I0627 16:25:00.502034  7639 net.cpp:217] pool4 needs backward computation.
I0627 16:25:00.502037  7639 net.cpp:217] relu4_1 needs backward computation.
I0627 16:25:00.502038  7639 net.cpp:217] scale4_1 needs backward computation.
I0627 16:25:00.502040  7639 net.cpp:217] bn4_1 needs backward computation.
I0627 16:25:00.502043  7639 net.cpp:217] conv4_1 needs backward computation.
I0627 16:25:00.502045  7639 net.cpp:217] pool3 needs backward computation.
I0627 16:25:00.502048  7639 net.cpp:217] relu3_1 needs backward computation.
I0627 16:25:00.502049  7639 net.cpp:217] scale3_1 needs backward computation.
I0627 16:25:00.502051  7639 net.cpp:217] bn3_1 needs backward computation.
I0627 16:25:00.502053  7639 net.cpp:217] conv3_1 needs backward computation.
I0627 16:25:00.502056  7639 net.cpp:217] pool2 needs backward computation.
I0627 16:25:00.502058  7639 net.cpp:217] relu2_1 needs backward computation.
I0627 16:25:00.502060  7639 net.cpp:217] scale2_1 needs backward computation.
I0627 16:25:00.502063  7639 net.cpp:217] bn2_1 needs backward computation.
I0627 16:25:00.502065  7639 net.cpp:217] conv2_1 needs backward computation.
I0627 16:25:00.502068  7639 net.cpp:217] pool1 needs backward computation.
I0627 16:25:00.502069  7639 net.cpp:217] relu1_1 needs backward computation.
I0627 16:25:00.502071  7639 net.cpp:217] scale1_1 needs backward computation.
I0627 16:25:00.502074  7639 net.cpp:217] bn1_1 needs backward computation.
I0627 16:25:00.502076  7639 net.cpp:217] conv1_1 needs backward computation.
I0627 16:25:00.502079  7639 net.cpp:219] label_data_1_split does not need backward computation.
I0627 16:25:00.502081  7639 net.cpp:219] data does not need backward computation.
I0627 16:25:00.502084  7639 net.cpp:261] This network produces output accuracy
I0627 16:25:00.502085  7639 net.cpp:261] This network produces output loss
I0627 16:25:00.502099  7639 net.cpp:274] Network initialization done.
I0627 16:25:00.502193  7639 solver.cpp:60] Solver scaffolding done.
I0627 16:25:00.503130  7639 caffe.cpp:219] Starting Optimization
I0627 16:25:00.503137  7639 solver.cpp:279] Solving BPnet
I0627 16:25:00.503139  7639 solver.cpp:280] Learning Rate Policy: step
I0627 16:25:00.504287  7639 solver.cpp:337] Iteration 0, Testing net (#0)
I0627 16:25:00.505170  7639 blocking_queue.cpp:50] Data layer prefetch queue empty
I0627 16:25:01.920346  7639 solver.cpp:404]     Test net output #0: accuracy = 0.471436
I0627 16:25:01.920378  7639 solver.cpp:404]     Test net output #1: loss = 0.693147 (* 1 = 0.693147 loss)
I0627 16:25:01.959956  7639 solver.cpp:228] Iteration 0, loss = 0.693147
I0627 16:25:01.959981  7639 solver.cpp:244]     Train net output #0: accuracy = 0.4375
I0627 16:25:01.959987  7639 solver.cpp:244]     Train net output #1: loss = 0.693147 (* 1 = 0.693147 loss)
I0627 16:25:01.960002  7639 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0627 16:25:02.730729  7639 solver.cpp:228] Iteration 20, loss = 0.63766
I0627 16:25:02.730752  7639 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 16:25:02.730770  7639 solver.cpp:244]     Train net output #1: loss = 0.63766 (* 1 = 0.63766 loss)
I0627 16:25:02.730774  7639 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0627 16:25:03.523820  7639 solver.cpp:228] Iteration 40, loss = 0.643502
I0627 16:25:03.523844  7639 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 16:25:03.523850  7639 solver.cpp:244]     Train net output #1: loss = 0.643502 (* 1 = 0.643502 loss)
I0627 16:25:03.523854  7639 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0627 16:25:04.317003  7639 solver.cpp:228] Iteration 60, loss = 0.710712
I0627 16:25:04.317025  7639 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0627 16:25:04.317044  7639 solver.cpp:244]     Train net output #1: loss = 0.710712 (* 1 = 0.710712 loss)
I0627 16:25:04.317047  7639 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0627 16:25:05.109462  7639 solver.cpp:228] Iteration 80, loss = 0.68817
I0627 16:25:05.109495  7639 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0627 16:25:05.109501  7639 solver.cpp:244]     Train net output #1: loss = 0.68817 (* 1 = 0.68817 loss)
I0627 16:25:05.109506  7639 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0627 16:25:05.889842  7639 solver.cpp:337] Iteration 100, Testing net (#0)
I0627 16:25:07.282382  7639 solver.cpp:404]     Test net output #0: accuracy = 0.526855
I0627 16:25:07.282408  7639 solver.cpp:404]     Test net output #1: loss = 0.68629 (* 1 = 0.68629 loss)
I0627 16:25:07.295598  7639 solver.cpp:228] Iteration 100, loss = 0.653794
I0627 16:25:07.295624  7639 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 16:25:07.295631  7639 solver.cpp:244]     Train net output #1: loss = 0.653794 (* 1 = 0.653794 loss)
I0627 16:25:07.295636  7639 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0627 16:25:08.087851  7639 solver.cpp:228] Iteration 120, loss = 0.68083
I0627 16:25:08.087874  7639 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0627 16:25:08.087882  7639 solver.cpp:244]     Train net output #1: loss = 0.68083 (* 1 = 0.68083 loss)
I0627 16:25:08.087885  7639 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0627 16:25:08.879467  7639 solver.cpp:228] Iteration 140, loss = 0.623758
I0627 16:25:08.879492  7639 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 16:25:08.879498  7639 solver.cpp:244]     Train net output #1: loss = 0.623758 (* 1 = 0.623758 loss)
I0627 16:25:08.879503  7639 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0627 16:25:09.673235  7639 solver.cpp:228] Iteration 160, loss = 0.652834
I0627 16:25:09.673257  7639 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 16:25:09.673275  7639 solver.cpp:244]     Train net output #1: loss = 0.652834 (* 1 = 0.652834 loss)
I0627 16:25:09.673280  7639 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0627 16:25:10.465275  7639 solver.cpp:228] Iteration 180, loss = 0.646784
I0627 16:25:10.465296  7639 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 16:25:10.465347  7639 solver.cpp:244]     Train net output #1: loss = 0.646784 (* 1 = 0.646784 loss)
I0627 16:25:10.465351  7639 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0627 16:25:11.247081  7639 solver.cpp:337] Iteration 200, Testing net (#0)
I0627 16:25:12.630498  7639 solver.cpp:404]     Test net output #0: accuracy = 0.526123
I0627 16:25:12.630538  7639 solver.cpp:404]     Test net output #1: loss = 0.673155 (* 1 = 0.673155 loss)
I0627 16:25:12.643719  7639 solver.cpp:228] Iteration 200, loss = 0.65433
I0627 16:25:12.643744  7639 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 16:25:12.643753  7639 solver.cpp:244]     Train net output #1: loss = 0.65433 (* 1 = 0.65433 loss)
I0627 16:25:12.643757  7639 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0627 16:25:13.436542  7639 solver.cpp:228] Iteration 220, loss = 0.682422
I0627 16:25:13.436563  7639 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 16:25:13.436583  7639 solver.cpp:244]     Train net output #1: loss = 0.682422 (* 1 = 0.682422 loss)
I0627 16:25:13.436586  7639 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0627 16:25:14.230044  7639 solver.cpp:228] Iteration 240, loss = 0.67877
I0627 16:25:14.230067  7639 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 16:25:14.230085  7639 solver.cpp:244]     Train net output #1: loss = 0.67877 (* 1 = 0.67877 loss)
I0627 16:25:14.230089  7639 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0627 16:25:15.023823  7639 solver.cpp:228] Iteration 260, loss = 0.682142
I0627 16:25:15.023856  7639 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0627 16:25:15.023864  7639 solver.cpp:244]     Train net output #1: loss = 0.682142 (* 1 = 0.682142 loss)
I0627 16:25:15.023867  7639 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0627 16:25:15.817464  7639 solver.cpp:228] Iteration 280, loss = 0.673256
I0627 16:25:15.817487  7639 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0627 16:25:15.817494  7639 solver.cpp:244]     Train net output #1: loss = 0.673256 (* 1 = 0.673256 loss)
I0627 16:25:15.817498  7639 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0627 16:25:16.598794  7639 solver.cpp:337] Iteration 300, Testing net (#0)
I0627 16:25:17.987521  7639 solver.cpp:404]     Test net output #0: accuracy = 0.5271
I0627 16:25:17.987550  7639 solver.cpp:404]     Test net output #1: loss = 0.678719 (* 1 = 0.678719 loss)
I0627 16:25:18.000738  7639 solver.cpp:228] Iteration 300, loss = 0.648656
I0627 16:25:18.000761  7639 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 16:25:18.000771  7639 solver.cpp:244]     Train net output #1: loss = 0.648656 (* 1 = 0.648656 loss)
I0627 16:25:18.000776  7639 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0627 16:25:18.794184  7639 solver.cpp:228] Iteration 320, loss = 0.627272
I0627 16:25:18.794208  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:25:18.794224  7639 solver.cpp:244]     Train net output #1: loss = 0.627272 (* 1 = 0.627272 loss)
I0627 16:25:18.794229  7639 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0627 16:25:19.588466  7639 solver.cpp:228] Iteration 340, loss = 0.595377
I0627 16:25:19.588493  7639 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 16:25:19.588500  7639 solver.cpp:244]     Train net output #1: loss = 0.595377 (* 1 = 0.595377 loss)
I0627 16:25:19.588505  7639 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0627 16:25:20.389647  7639 solver.cpp:228] Iteration 360, loss = 0.717201
I0627 16:25:20.389670  7639 solver.cpp:244]     Train net output #0: accuracy = 0.46875
I0627 16:25:20.389678  7639 solver.cpp:244]     Train net output #1: loss = 0.717201 (* 1 = 0.717201 loss)
I0627 16:25:20.389681  7639 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0627 16:25:21.190779  7639 solver.cpp:228] Iteration 380, loss = 0.660191
I0627 16:25:21.190803  7639 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 16:25:21.190820  7639 solver.cpp:244]     Train net output #1: loss = 0.660191 (* 1 = 0.660191 loss)
I0627 16:25:21.190845  7639 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0627 16:25:21.970304  7639 solver.cpp:337] Iteration 400, Testing net (#0)
I0627 16:25:23.352272  7639 solver.cpp:404]     Test net output #0: accuracy = 0.561279
I0627 16:25:23.352313  7639 solver.cpp:404]     Test net output #1: loss = 0.659111 (* 1 = 0.659111 loss)
I0627 16:25:23.365188  7639 solver.cpp:228] Iteration 400, loss = 0.646911
I0627 16:25:23.365206  7639 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 16:25:23.365212  7639 solver.cpp:244]     Train net output #1: loss = 0.646911 (* 1 = 0.646911 loss)
I0627 16:25:23.365217  7639 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0627 16:25:24.158061  7639 solver.cpp:228] Iteration 420, loss = 0.648534
I0627 16:25:24.158082  7639 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 16:25:24.158089  7639 solver.cpp:244]     Train net output #1: loss = 0.648534 (* 1 = 0.648534 loss)
I0627 16:25:24.158093  7639 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0627 16:25:24.958868  7639 solver.cpp:228] Iteration 440, loss = 0.614821
I0627 16:25:24.958889  7639 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 16:25:24.958896  7639 solver.cpp:244]     Train net output #1: loss = 0.614821 (* 1 = 0.614821 loss)
I0627 16:25:24.958900  7639 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0627 16:25:25.752334  7639 solver.cpp:228] Iteration 460, loss = 0.675524
I0627 16:25:25.752368  7639 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 16:25:25.752375  7639 solver.cpp:244]     Train net output #1: loss = 0.675524 (* 1 = 0.675524 loss)
I0627 16:25:25.752379  7639 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0627 16:25:26.546124  7639 solver.cpp:228] Iteration 480, loss = 0.611411
I0627 16:25:26.546150  7639 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 16:25:26.546157  7639 solver.cpp:244]     Train net output #1: loss = 0.611411 (* 1 = 0.611411 loss)
I0627 16:25:26.546161  7639 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0627 16:25:27.327505  7639 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_500.caffemodel
I0627 16:25:27.340427  7639 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_500.solverstate
I0627 16:25:27.345386  7639 solver.cpp:337] Iteration 500, Testing net (#0)
I0627 16:25:28.729723  7639 solver.cpp:404]     Test net output #0: accuracy = 0.580566
I0627 16:25:28.729760  7639 solver.cpp:404]     Test net output #1: loss = 0.652626 (* 1 = 0.652626 loss)
I0627 16:25:28.742911  7639 solver.cpp:228] Iteration 500, loss = 0.670509
I0627 16:25:28.742934  7639 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0627 16:25:28.742943  7639 solver.cpp:244]     Train net output #1: loss = 0.670509 (* 1 = 0.670509 loss)
I0627 16:25:28.742947  7639 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0627 16:25:29.537948  7639 solver.cpp:228] Iteration 520, loss = 0.645661
I0627 16:25:29.537971  7639 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 16:25:29.537977  7639 solver.cpp:244]     Train net output #1: loss = 0.645661 (* 1 = 0.645661 loss)
I0627 16:25:29.537982  7639 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0627 16:25:30.332479  7639 solver.cpp:228] Iteration 540, loss = 0.625837
I0627 16:25:30.332634  7639 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 16:25:30.332645  7639 solver.cpp:244]     Train net output #1: loss = 0.625837 (* 1 = 0.625837 loss)
I0627 16:25:30.332649  7639 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0627 16:25:31.127885  7639 solver.cpp:228] Iteration 560, loss = 0.698448
I0627 16:25:31.127910  7639 solver.cpp:244]     Train net output #0: accuracy = 0.46875
I0627 16:25:31.127918  7639 solver.cpp:244]     Train net output #1: loss = 0.698448 (* 1 = 0.698448 loss)
I0627 16:25:31.127923  7639 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0627 16:25:31.923754  7639 solver.cpp:228] Iteration 580, loss = 0.614926
I0627 16:25:31.923779  7639 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0627 16:25:31.923784  7639 solver.cpp:244]     Train net output #1: loss = 0.614926 (* 1 = 0.614926 loss)
I0627 16:25:31.923789  7639 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0627 16:25:32.707355  7639 solver.cpp:337] Iteration 600, Testing net (#0)
I0627 16:25:34.091177  7639 solver.cpp:404]     Test net output #0: accuracy = 0.581299
I0627 16:25:34.091205  7639 solver.cpp:404]     Test net output #1: loss = 0.666633 (* 1 = 0.666633 loss)
I0627 16:25:34.104259  7639 solver.cpp:228] Iteration 600, loss = 0.663329
I0627 16:25:34.104282  7639 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0627 16:25:34.104290  7639 solver.cpp:244]     Train net output #1: loss = 0.663329 (* 1 = 0.663329 loss)
I0627 16:25:34.104295  7639 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0627 16:25:34.900578  7639 solver.cpp:228] Iteration 620, loss = 0.623571
I0627 16:25:34.900600  7639 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 16:25:34.900607  7639 solver.cpp:244]     Train net output #1: loss = 0.623571 (* 1 = 0.623571 loss)
I0627 16:25:34.900611  7639 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0627 16:25:35.695107  7639 solver.cpp:228] Iteration 640, loss = 0.620055
I0627 16:25:35.695142  7639 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 16:25:35.695148  7639 solver.cpp:244]     Train net output #1: loss = 0.620055 (* 1 = 0.620055 loss)
I0627 16:25:35.695153  7639 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0627 16:25:36.488924  7639 solver.cpp:228] Iteration 660, loss = 0.667129
I0627 16:25:36.488947  7639 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 16:25:36.488955  7639 solver.cpp:244]     Train net output #1: loss = 0.667129 (* 1 = 0.667129 loss)
I0627 16:25:36.488958  7639 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0627 16:25:37.282667  7639 solver.cpp:228] Iteration 680, loss = 0.641261
I0627 16:25:37.282701  7639 solver.cpp:244]     Train net output #0: accuracy = 0.53125
I0627 16:25:37.282706  7639 solver.cpp:244]     Train net output #1: loss = 0.641261 (* 1 = 0.641261 loss)
I0627 16:25:37.282721  7639 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0627 16:25:38.065646  7639 solver.cpp:337] Iteration 700, Testing net (#0)
I0627 16:25:39.461601  7639 solver.cpp:404]     Test net output #0: accuracy = 0.619385
I0627 16:25:39.461639  7639 solver.cpp:404]     Test net output #1: loss = 0.656855 (* 1 = 0.656855 loss)
I0627 16:25:39.474856  7639 solver.cpp:228] Iteration 700, loss = 0.609042
I0627 16:25:39.474879  7639 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 16:25:39.474887  7639 solver.cpp:244]     Train net output #1: loss = 0.609042 (* 1 = 0.609042 loss)
I0627 16:25:39.474892  7639 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0627 16:25:40.270615  7639 solver.cpp:228] Iteration 720, loss = 0.579844
I0627 16:25:40.270651  7639 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 16:25:40.270659  7639 solver.cpp:244]     Train net output #1: loss = 0.579844 (* 1 = 0.579844 loss)
I0627 16:25:40.270663  7639 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0627 16:25:41.064371  7639 solver.cpp:228] Iteration 740, loss = 0.587813
I0627 16:25:41.064394  7639 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 16:25:41.064401  7639 solver.cpp:244]     Train net output #1: loss = 0.587813 (* 1 = 0.587813 loss)
I0627 16:25:41.064426  7639 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0627 16:25:41.859025  7639 solver.cpp:228] Iteration 760, loss = 0.584883
I0627 16:25:41.859050  7639 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 16:25:41.859057  7639 solver.cpp:244]     Train net output #1: loss = 0.584883 (* 1 = 0.584883 loss)
I0627 16:25:41.859061  7639 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0627 16:25:42.652667  7639 solver.cpp:228] Iteration 780, loss = 0.580345
I0627 16:25:42.652703  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:25:42.652709  7639 solver.cpp:244]     Train net output #1: loss = 0.580345 (* 1 = 0.580345 loss)
I0627 16:25:42.652714  7639 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0627 16:25:43.434819  7639 solver.cpp:337] Iteration 800, Testing net (#0)
I0627 16:25:44.834786  7639 solver.cpp:404]     Test net output #0: accuracy = 0.673828
I0627 16:25:44.834823  7639 solver.cpp:404]     Test net output #1: loss = 0.62779 (* 1 = 0.62779 loss)
I0627 16:25:44.848078  7639 solver.cpp:228] Iteration 800, loss = 0.586806
I0627 16:25:44.848104  7639 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 16:25:44.848110  7639 solver.cpp:244]     Train net output #1: loss = 0.586806 (* 1 = 0.586806 loss)
I0627 16:25:44.848116  7639 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0627 16:25:45.642832  7639 solver.cpp:228] Iteration 820, loss = 0.695017
I0627 16:25:45.642854  7639 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0627 16:25:45.642861  7639 solver.cpp:244]     Train net output #1: loss = 0.695017 (* 1 = 0.695017 loss)
I0627 16:25:45.642865  7639 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0627 16:25:46.437188  7639 solver.cpp:228] Iteration 840, loss = 0.647264
I0627 16:25:46.437211  7639 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0627 16:25:46.437228  7639 solver.cpp:244]     Train net output #1: loss = 0.647264 (* 1 = 0.647264 loss)
I0627 16:25:46.437233  7639 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0627 16:25:47.232899  7639 solver.cpp:228] Iteration 860, loss = 0.604979
I0627 16:25:47.232923  7639 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 16:25:47.232928  7639 solver.cpp:244]     Train net output #1: loss = 0.604979 (* 1 = 0.604979 loss)
I0627 16:25:47.232933  7639 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0627 16:25:48.027887  7639 solver.cpp:228] Iteration 880, loss = 0.549657
I0627 16:25:48.027911  7639 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 16:25:48.027917  7639 solver.cpp:244]     Train net output #1: loss = 0.549657 (* 1 = 0.549657 loss)
I0627 16:25:48.027921  7639 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0627 16:25:48.810859  7639 solver.cpp:337] Iteration 900, Testing net (#0)
I0627 16:25:50.187456  7639 solver.cpp:404]     Test net output #0: accuracy = 0.629395
I0627 16:25:50.187485  7639 solver.cpp:404]     Test net output #1: loss = 0.668834 (* 1 = 0.668834 loss)
I0627 16:25:50.200682  7639 solver.cpp:228] Iteration 900, loss = 0.634491
I0627 16:25:50.200706  7639 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0627 16:25:50.200724  7639 solver.cpp:244]     Train net output #1: loss = 0.634491 (* 1 = 0.634491 loss)
I0627 16:25:50.200729  7639 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0627 16:25:50.996126  7639 solver.cpp:228] Iteration 920, loss = 0.611686
I0627 16:25:50.996160  7639 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 16:25:50.996167  7639 solver.cpp:244]     Train net output #1: loss = 0.611686 (* 1 = 0.611686 loss)
I0627 16:25:50.996171  7639 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0627 16:25:51.791793  7639 solver.cpp:228] Iteration 940, loss = 0.594879
I0627 16:25:51.791826  7639 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 16:25:51.791833  7639 solver.cpp:244]     Train net output #1: loss = 0.594879 (* 1 = 0.594879 loss)
I0627 16:25:51.791837  7639 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0627 16:25:52.587294  7639 solver.cpp:228] Iteration 960, loss = 0.583632
I0627 16:25:52.587316  7639 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0627 16:25:52.587323  7639 solver.cpp:244]     Train net output #1: loss = 0.583632 (* 1 = 0.583632 loss)
I0627 16:25:52.587327  7639 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0627 16:25:53.383213  7639 solver.cpp:228] Iteration 980, loss = 0.619227
I0627 16:25:53.383239  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:25:53.383245  7639 solver.cpp:244]     Train net output #1: loss = 0.619227 (* 1 = 0.619227 loss)
I0627 16:25:53.383249  7639 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0627 16:25:54.166152  7639 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_1000.caffemodel
I0627 16:25:54.175344  7639 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_1000.solverstate
I0627 16:25:54.180166  7639 solver.cpp:337] Iteration 1000, Testing net (#0)
I0627 16:25:55.567467  7639 solver.cpp:404]     Test net output #0: accuracy = 0.70752
I0627 16:25:55.567505  7639 solver.cpp:404]     Test net output #1: loss = 0.593402 (* 1 = 0.593402 loss)
I0627 16:25:55.580759  7639 solver.cpp:228] Iteration 1000, loss = 0.573087
I0627 16:25:55.580785  7639 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 16:25:55.580792  7639 solver.cpp:244]     Train net output #1: loss = 0.573087 (* 1 = 0.573087 loss)
I0627 16:25:55.580797  7639 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0627 16:25:56.380213  7639 solver.cpp:228] Iteration 1020, loss = 0.581301
I0627 16:25:56.380236  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:25:56.380242  7639 solver.cpp:244]     Train net output #1: loss = 0.581301 (* 1 = 0.581301 loss)
I0627 16:25:56.380247  7639 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0627 16:25:57.178990  7639 solver.cpp:228] Iteration 1040, loss = 0.537822
I0627 16:25:57.179023  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:25:57.179041  7639 solver.cpp:244]     Train net output #1: loss = 0.537822 (* 1 = 0.537822 loss)
I0627 16:25:57.179045  7639 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0627 16:25:57.977169  7639 solver.cpp:228] Iteration 1060, loss = 0.573604
I0627 16:25:57.977195  7639 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 16:25:57.977201  7639 solver.cpp:244]     Train net output #1: loss = 0.573604 (* 1 = 0.573604 loss)
I0627 16:25:57.977205  7639 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0627 16:25:58.776108  7639 solver.cpp:228] Iteration 1080, loss = 0.561242
I0627 16:25:58.776130  7639 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 16:25:58.776137  7639 solver.cpp:244]     Train net output #1: loss = 0.561242 (* 1 = 0.561242 loss)
I0627 16:25:58.776141  7639 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0627 16:25:59.562865  7639 solver.cpp:337] Iteration 1100, Testing net (#0)
I0627 16:26:00.955138  7639 solver.cpp:404]     Test net output #0: accuracy = 0.711182
I0627 16:26:00.955299  7639 solver.cpp:404]     Test net output #1: loss = 0.592814 (* 1 = 0.592814 loss)
I0627 16:26:00.968438  7639 solver.cpp:228] Iteration 1100, loss = 0.616872
I0627 16:26:00.968462  7639 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 16:26:00.968469  7639 solver.cpp:244]     Train net output #1: loss = 0.616872 (* 1 = 0.616872 loss)
I0627 16:26:00.968475  7639 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0627 16:26:01.768048  7639 solver.cpp:228] Iteration 1120, loss = 0.714089
I0627 16:26:01.768071  7639 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0627 16:26:01.768077  7639 solver.cpp:244]     Train net output #1: loss = 0.714089 (* 1 = 0.714089 loss)
I0627 16:26:01.768082  7639 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0627 16:26:02.566690  7639 solver.cpp:228] Iteration 1140, loss = 0.63887
I0627 16:26:02.566714  7639 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 16:26:02.566720  7639 solver.cpp:244]     Train net output #1: loss = 0.63887 (* 1 = 0.63887 loss)
I0627 16:26:02.566725  7639 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0627 16:26:03.365332  7639 solver.cpp:228] Iteration 1160, loss = 0.541549
I0627 16:26:03.365355  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:26:03.365361  7639 solver.cpp:244]     Train net output #1: loss = 0.541549 (* 1 = 0.541549 loss)
I0627 16:26:03.365365  7639 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0627 16:26:04.163590  7639 solver.cpp:228] Iteration 1180, loss = 0.543749
I0627 16:26:04.163612  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:26:04.163630  7639 solver.cpp:244]     Train net output #1: loss = 0.543749 (* 1 = 0.543749 loss)
I0627 16:26:04.163635  7639 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0627 16:26:04.949681  7639 solver.cpp:337] Iteration 1200, Testing net (#0)
I0627 16:26:06.338662  7639 solver.cpp:404]     Test net output #0: accuracy = 0.697266
I0627 16:26:06.338693  7639 solver.cpp:404]     Test net output #1: loss = 0.615009 (* 1 = 0.615009 loss)
I0627 16:26:06.351943  7639 solver.cpp:228] Iteration 1200, loss = 0.669359
I0627 16:26:06.351969  7639 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0627 16:26:06.351976  7639 solver.cpp:244]     Train net output #1: loss = 0.669359 (* 1 = 0.669359 loss)
I0627 16:26:06.351981  7639 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0627 16:26:07.153920  7639 solver.cpp:228] Iteration 1220, loss = 0.527653
I0627 16:26:07.153954  7639 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 16:26:07.153961  7639 solver.cpp:244]     Train net output #1: loss = 0.527653 (* 1 = 0.527653 loss)
I0627 16:26:07.153964  7639 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0627 16:26:07.954872  7639 solver.cpp:228] Iteration 1240, loss = 0.563149
I0627 16:26:07.954896  7639 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 16:26:07.954905  7639 solver.cpp:244]     Train net output #1: loss = 0.563149 (* 1 = 0.563149 loss)
I0627 16:26:07.954907  7639 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0627 16:26:08.755326  7639 solver.cpp:228] Iteration 1260, loss = 0.554396
I0627 16:26:08.755349  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:26:08.755357  7639 solver.cpp:244]     Train net output #1: loss = 0.554396 (* 1 = 0.554396 loss)
I0627 16:26:08.755360  7639 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0627 16:26:09.554410  7639 solver.cpp:228] Iteration 1280, loss = 0.513188
I0627 16:26:09.554433  7639 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 16:26:09.554440  7639 solver.cpp:244]     Train net output #1: loss = 0.513188 (* 1 = 0.513188 loss)
I0627 16:26:09.554445  7639 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0627 16:26:10.343116  7639 solver.cpp:337] Iteration 1300, Testing net (#0)
I0627 16:26:11.735319  7639 solver.cpp:404]     Test net output #0: accuracy = 0.70459
I0627 16:26:11.735348  7639 solver.cpp:404]     Test net output #1: loss = 0.596895 (* 1 = 0.596895 loss)
I0627 16:26:11.748656  7639 solver.cpp:228] Iteration 1300, loss = 0.587797
I0627 16:26:11.748692  7639 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 16:26:11.748700  7639 solver.cpp:244]     Train net output #1: loss = 0.587797 (* 1 = 0.587797 loss)
I0627 16:26:11.748705  7639 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0627 16:26:12.551204  7639 solver.cpp:228] Iteration 1320, loss = 0.604596
I0627 16:26:12.551228  7639 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 16:26:12.551234  7639 solver.cpp:244]     Train net output #1: loss = 0.604596 (* 1 = 0.604596 loss)
I0627 16:26:12.551239  7639 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0627 16:26:13.352591  7639 solver.cpp:228] Iteration 1340, loss = 0.551347
I0627 16:26:13.352623  7639 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 16:26:13.352632  7639 solver.cpp:244]     Train net output #1: loss = 0.551347 (* 1 = 0.551347 loss)
I0627 16:26:13.352635  7639 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0627 16:26:14.154240  7639 solver.cpp:228] Iteration 1360, loss = 0.562762
I0627 16:26:14.154263  7639 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 16:26:14.154269  7639 solver.cpp:244]     Train net output #1: loss = 0.562762 (* 1 = 0.562762 loss)
I0627 16:26:14.154273  7639 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0627 16:26:14.955430  7639 solver.cpp:228] Iteration 1380, loss = 0.534654
I0627 16:26:14.955466  7639 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 16:26:14.955472  7639 solver.cpp:244]     Train net output #1: loss = 0.534654 (* 1 = 0.534654 loss)
I0627 16:26:14.955476  7639 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0627 16:26:15.745820  7639 solver.cpp:337] Iteration 1400, Testing net (#0)
I0627 16:26:17.140889  7639 solver.cpp:404]     Test net output #0: accuracy = 0.689941
I0627 16:26:17.140928  7639 solver.cpp:404]     Test net output #1: loss = 0.619691 (* 1 = 0.619691 loss)
I0627 16:26:17.154222  7639 solver.cpp:228] Iteration 1400, loss = 0.576568
I0627 16:26:17.154249  7639 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 16:26:17.154256  7639 solver.cpp:244]     Train net output #1: loss = 0.576568 (* 1 = 0.576568 loss)
I0627 16:26:17.154261  7639 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0627 16:26:17.955729  7639 solver.cpp:228] Iteration 1420, loss = 0.762165
I0627 16:26:17.955751  7639 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0627 16:26:17.955757  7639 solver.cpp:244]     Train net output #1: loss = 0.762165 (* 1 = 0.762165 loss)
I0627 16:26:17.955761  7639 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0627 16:26:18.757967  7639 solver.cpp:228] Iteration 1440, loss = 0.60267
I0627 16:26:18.757990  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:26:18.757997  7639 solver.cpp:244]     Train net output #1: loss = 0.60267 (* 1 = 0.60267 loss)
I0627 16:26:18.758002  7639 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0627 16:26:19.559607  7639 solver.cpp:228] Iteration 1460, loss = 0.571472
I0627 16:26:19.559629  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:26:19.559635  7639 solver.cpp:244]     Train net output #1: loss = 0.571472 (* 1 = 0.571472 loss)
I0627 16:26:19.559639  7639 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0627 16:26:20.361570  7639 solver.cpp:228] Iteration 1480, loss = 0.550337
I0627 16:26:20.361604  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:26:20.361611  7639 solver.cpp:244]     Train net output #1: loss = 0.550337 (* 1 = 0.550337 loss)
I0627 16:26:20.361615  7639 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0627 16:26:21.150866  7639 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_1500.caffemodel
I0627 16:26:21.159965  7639 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_1500.solverstate
I0627 16:26:21.164742  7639 solver.cpp:337] Iteration 1500, Testing net (#0)
I0627 16:26:22.559059  7639 solver.cpp:404]     Test net output #0: accuracy = 0.67749
I0627 16:26:22.559109  7639 solver.cpp:404]     Test net output #1: loss = 0.633626 (* 1 = 0.633626 loss)
I0627 16:26:22.572398  7639 solver.cpp:228] Iteration 1500, loss = 0.603704
I0627 16:26:22.572428  7639 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 16:26:22.572438  7639 solver.cpp:244]     Train net output #1: loss = 0.603704 (* 1 = 0.603704 loss)
I0627 16:26:22.572445  7639 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0627 16:26:23.376696  7639 solver.cpp:228] Iteration 1520, loss = 0.505073
I0627 16:26:23.376720  7639 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 16:26:23.376730  7639 solver.cpp:244]     Train net output #1: loss = 0.505073 (* 1 = 0.505073 loss)
I0627 16:26:23.376735  7639 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0627 16:26:24.179641  7639 solver.cpp:228] Iteration 1540, loss = 0.543424
I0627 16:26:24.179664  7639 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 16:26:24.179674  7639 solver.cpp:244]     Train net output #1: loss = 0.543424 (* 1 = 0.543424 loss)
I0627 16:26:24.179680  7639 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0627 16:26:24.982934  7639 solver.cpp:228] Iteration 1560, loss = 0.53611
I0627 16:26:24.982959  7639 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 16:26:24.982969  7639 solver.cpp:244]     Train net output #1: loss = 0.53611 (* 1 = 0.53611 loss)
I0627 16:26:24.982975  7639 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0627 16:26:25.786025  7639 solver.cpp:228] Iteration 1580, loss = 0.552819
I0627 16:26:25.786058  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:26:25.786067  7639 solver.cpp:244]     Train net output #1: loss = 0.552819 (* 1 = 0.552819 loss)
I0627 16:26:25.786073  7639 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0627 16:26:26.577654  7639 solver.cpp:337] Iteration 1600, Testing net (#0)
I0627 16:26:27.993307  7639 solver.cpp:404]     Test net output #0: accuracy = 0.685547
I0627 16:26:27.993337  7639 solver.cpp:404]     Test net output #1: loss = 0.615536 (* 1 = 0.615536 loss)
I0627 16:26:28.006381  7639 solver.cpp:228] Iteration 1600, loss = 0.531638
I0627 16:26:28.006408  7639 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 16:26:28.006418  7639 solver.cpp:244]     Train net output #1: loss = 0.531638 (* 1 = 0.531638 loss)
I0627 16:26:28.006425  7639 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0627 16:26:28.813163  7639 solver.cpp:228] Iteration 1620, loss = 0.601602
I0627 16:26:28.813186  7639 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 16:26:28.813196  7639 solver.cpp:244]     Train net output #1: loss = 0.601602 (* 1 = 0.601602 loss)
I0627 16:26:28.813202  7639 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0627 16:26:29.618293  7639 solver.cpp:228] Iteration 1640, loss = 0.566138
I0627 16:26:29.618316  7639 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0627 16:26:29.618336  7639 solver.cpp:244]     Train net output #1: loss = 0.566138 (* 1 = 0.566138 loss)
I0627 16:26:29.618342  7639 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0627 16:26:30.422360  7639 solver.cpp:228] Iteration 1660, loss = 0.491061
I0627 16:26:30.422384  7639 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 16:26:30.422394  7639 solver.cpp:244]     Train net output #1: loss = 0.491061 (* 1 = 0.491061 loss)
I0627 16:26:30.422400  7639 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0627 16:26:31.226994  7639 solver.cpp:228] Iteration 1680, loss = 0.546339
I0627 16:26:31.227131  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:26:31.227144  7639 solver.cpp:244]     Train net output #1: loss = 0.546339 (* 1 = 0.546339 loss)
I0627 16:26:31.227151  7639 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0627 16:26:32.019129  7639 solver.cpp:337] Iteration 1700, Testing net (#0)
I0627 16:26:33.413513  7639 solver.cpp:404]     Test net output #0: accuracy = 0.698975
I0627 16:26:33.413545  7639 solver.cpp:404]     Test net output #1: loss = 0.610168 (* 1 = 0.610168 loss)
I0627 16:26:33.426813  7639 solver.cpp:228] Iteration 1700, loss = 0.598306
I0627 16:26:33.426841  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:26:33.426849  7639 solver.cpp:244]     Train net output #1: loss = 0.598306 (* 1 = 0.598306 loss)
I0627 16:26:33.426857  7639 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0627 16:26:34.230082  7639 solver.cpp:228] Iteration 1720, loss = 0.614995
I0627 16:26:34.230105  7639 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 16:26:34.230115  7639 solver.cpp:244]     Train net output #1: loss = 0.614995 (* 1 = 0.614995 loss)
I0627 16:26:34.230120  7639 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0627 16:26:35.032647  7639 solver.cpp:228] Iteration 1740, loss = 0.784756
I0627 16:26:35.032671  7639 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 16:26:35.032681  7639 solver.cpp:244]     Train net output #1: loss = 0.784756 (* 1 = 0.784756 loss)
I0627 16:26:35.032687  7639 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0627 16:26:35.834918  7639 solver.cpp:228] Iteration 1760, loss = 0.653173
I0627 16:26:35.834940  7639 solver.cpp:244]     Train net output #0: accuracy = 0.53125
I0627 16:26:35.834950  7639 solver.cpp:244]     Train net output #1: loss = 0.653173 (* 1 = 0.653173 loss)
I0627 16:26:35.834956  7639 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0627 16:26:36.637650  7639 solver.cpp:228] Iteration 1780, loss = 0.628216
I0627 16:26:36.637676  7639 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 16:26:36.637686  7639 solver.cpp:244]     Train net output #1: loss = 0.628216 (* 1 = 0.628216 loss)
I0627 16:26:36.637692  7639 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0627 16:26:37.428963  7639 solver.cpp:337] Iteration 1800, Testing net (#0)
I0627 16:26:38.706380  7639 blocking_queue.cpp:50] Data layer prefetch queue empty
I0627 16:26:38.837371  7639 solver.cpp:404]     Test net output #0: accuracy = 0.702148
I0627 16:26:38.837400  7639 solver.cpp:404]     Test net output #1: loss = 0.602 (* 1 = 0.602 loss)
I0627 16:26:38.850632  7639 solver.cpp:228] Iteration 1800, loss = 0.678649
I0627 16:26:38.850656  7639 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 16:26:38.850666  7639 solver.cpp:244]     Train net output #1: loss = 0.678649 (* 1 = 0.678649 loss)
I0627 16:26:38.850673  7639 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0627 16:26:39.652501  7639 solver.cpp:228] Iteration 1820, loss = 0.525404
I0627 16:26:39.652525  7639 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 16:26:39.652535  7639 solver.cpp:244]     Train net output #1: loss = 0.525404 (* 1 = 0.525404 loss)
I0627 16:26:39.652541  7639 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0627 16:26:40.455852  7639 solver.cpp:228] Iteration 1840, loss = 0.65426
I0627 16:26:40.455876  7639 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 16:26:40.455885  7639 solver.cpp:244]     Train net output #1: loss = 0.65426 (* 1 = 0.65426 loss)
I0627 16:26:40.455891  7639 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0627 16:26:41.259811  7639 solver.cpp:228] Iteration 1860, loss = 0.586785
I0627 16:26:41.259835  7639 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 16:26:41.259845  7639 solver.cpp:244]     Train net output #1: loss = 0.586785 (* 1 = 0.586785 loss)
I0627 16:26:41.259850  7639 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0627 16:26:42.061861  7639 solver.cpp:228] Iteration 1880, loss = 0.562259
I0627 16:26:42.061887  7639 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 16:26:42.061935  7639 solver.cpp:244]     Train net output #1: loss = 0.562259 (* 1 = 0.562259 loss)
I0627 16:26:42.061944  7639 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0627 16:26:42.852210  7639 solver.cpp:337] Iteration 1900, Testing net (#0)
I0627 16:26:44.247998  7639 solver.cpp:404]     Test net output #0: accuracy = 0.691162
I0627 16:26:44.248039  7639 solver.cpp:404]     Test net output #1: loss = 0.611575 (* 1 = 0.611575 loss)
I0627 16:26:44.261276  7639 solver.cpp:228] Iteration 1900, loss = 0.531181
I0627 16:26:44.261301  7639 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 16:26:44.261307  7639 solver.cpp:244]     Train net output #1: loss = 0.531181 (* 1 = 0.531181 loss)
I0627 16:26:44.261312  7639 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0627 16:26:45.067178  7639 solver.cpp:228] Iteration 1920, loss = 0.60855
I0627 16:26:45.067199  7639 solver.cpp:244]     Train net output #0: accuracy = 0.53125
I0627 16:26:45.067206  7639 solver.cpp:244]     Train net output #1: loss = 0.60855 (* 1 = 0.60855 loss)
I0627 16:26:45.067210  7639 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0627 16:26:45.872489  7639 solver.cpp:228] Iteration 1940, loss = 0.602814
I0627 16:26:45.872511  7639 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 16:26:45.872529  7639 solver.cpp:244]     Train net output #1: loss = 0.602814 (* 1 = 0.602814 loss)
I0627 16:26:45.872534  7639 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0627 16:26:46.677062  7639 solver.cpp:228] Iteration 1960, loss = 0.539687
I0627 16:26:46.677085  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:26:46.677093  7639 solver.cpp:244]     Train net output #1: loss = 0.539687 (* 1 = 0.539687 loss)
I0627 16:26:46.677096  7639 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0627 16:26:47.479760  7639 solver.cpp:228] Iteration 1980, loss = 0.542212
I0627 16:26:47.479784  7639 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 16:26:47.479790  7639 solver.cpp:244]     Train net output #1: loss = 0.542212 (* 1 = 0.542212 loss)
I0627 16:26:47.479795  7639 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0627 16:26:48.284201  7639 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_2000.caffemodel
I0627 16:26:48.293694  7639 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_2000.solverstate
I0627 16:26:48.298496  7639 solver.cpp:337] Iteration 2000, Testing net (#0)
I0627 16:26:49.695176  7639 solver.cpp:404]     Test net output #0: accuracy = 0.685547
I0627 16:26:49.695205  7639 solver.cpp:404]     Test net output #1: loss = 0.621525 (* 1 = 0.621525 loss)
I0627 16:26:49.708534  7639 solver.cpp:228] Iteration 2000, loss = 0.542718
I0627 16:26:49.708559  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:26:49.708566  7639 solver.cpp:244]     Train net output #1: loss = 0.542718 (* 1 = 0.542718 loss)
I0627 16:26:49.708571  7639 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0627 16:26:50.512630  7639 solver.cpp:228] Iteration 2020, loss = 0.566491
I0627 16:26:50.512665  7639 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 16:26:50.512671  7639 solver.cpp:244]     Train net output #1: loss = 0.566491 (* 1 = 0.566491 loss)
I0627 16:26:50.512676  7639 sgd_solver.cpp:106] Iteration 2020, lr = 0.0001
I0627 16:26:51.316822  7639 solver.cpp:228] Iteration 2040, loss = 0.66646
I0627 16:26:51.316844  7639 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 16:26:51.316850  7639 solver.cpp:244]     Train net output #1: loss = 0.66646 (* 1 = 0.66646 loss)
I0627 16:26:51.316854  7639 sgd_solver.cpp:106] Iteration 2040, lr = 0.0001
I0627 16:26:52.121428  7639 solver.cpp:228] Iteration 2060, loss = 0.70131
I0627 16:26:52.121450  7639 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0627 16:26:52.121457  7639 solver.cpp:244]     Train net output #1: loss = 0.70131 (* 1 = 0.70131 loss)
I0627 16:26:52.121462  7639 sgd_solver.cpp:106] Iteration 2060, lr = 0.0001
I0627 16:26:52.925397  7639 solver.cpp:228] Iteration 2080, loss = 0.627963
I0627 16:26:52.925421  7639 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 16:26:52.925428  7639 solver.cpp:244]     Train net output #1: loss = 0.627963 (* 1 = 0.627963 loss)
I0627 16:26:52.925432  7639 sgd_solver.cpp:106] Iteration 2080, lr = 0.0001
I0627 16:26:53.717010  7639 solver.cpp:337] Iteration 2100, Testing net (#0)
I0627 16:26:55.117334  7639 solver.cpp:404]     Test net output #0: accuracy = 0.688965
I0627 16:26:55.117373  7639 solver.cpp:404]     Test net output #1: loss = 0.615415 (* 1 = 0.615415 loss)
I0627 16:26:55.130656  7639 solver.cpp:228] Iteration 2100, loss = 0.549807
I0627 16:26:55.130682  7639 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 16:26:55.130691  7639 solver.cpp:244]     Train net output #1: loss = 0.549807 (* 1 = 0.549807 loss)
I0627 16:26:55.130695  7639 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0627 16:26:55.933838  7639 solver.cpp:228] Iteration 2120, loss = 0.553981
I0627 16:26:55.933862  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:26:55.933869  7639 solver.cpp:244]     Train net output #1: loss = 0.553981 (* 1 = 0.553981 loss)
I0627 16:26:55.933873  7639 sgd_solver.cpp:106] Iteration 2120, lr = 0.0001
I0627 16:26:56.736691  7639 solver.cpp:228] Iteration 2140, loss = 0.651264
I0627 16:26:56.736714  7639 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 16:26:56.736722  7639 solver.cpp:244]     Train net output #1: loss = 0.651264 (* 1 = 0.651264 loss)
I0627 16:26:56.736726  7639 sgd_solver.cpp:106] Iteration 2140, lr = 0.0001
I0627 16:26:57.539680  7639 solver.cpp:228] Iteration 2160, loss = 0.597547
I0627 16:26:57.539703  7639 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 16:26:57.539710  7639 solver.cpp:244]     Train net output #1: loss = 0.597547 (* 1 = 0.597547 loss)
I0627 16:26:57.539715  7639 sgd_solver.cpp:106] Iteration 2160, lr = 0.0001
I0627 16:26:58.342375  7639 solver.cpp:228] Iteration 2180, loss = 0.600892
I0627 16:26:58.342398  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:26:58.342406  7639 solver.cpp:244]     Train net output #1: loss = 0.600892 (* 1 = 0.600892 loss)
I0627 16:26:58.342409  7639 sgd_solver.cpp:106] Iteration 2180, lr = 0.0001
I0627 16:26:59.132753  7639 solver.cpp:337] Iteration 2200, Testing net (#0)
I0627 16:27:00.528288  7639 solver.cpp:404]     Test net output #0: accuracy = 0.694092
I0627 16:27:00.528316  7639 solver.cpp:404]     Test net output #1: loss = 0.610773 (* 1 = 0.610773 loss)
I0627 16:27:00.541563  7639 solver.cpp:228] Iteration 2200, loss = 0.532972
I0627 16:27:00.541589  7639 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 16:27:00.541595  7639 solver.cpp:244]     Train net output #1: loss = 0.532972 (* 1 = 0.532972 loss)
I0627 16:27:00.541600  7639 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0627 16:27:01.343822  7639 solver.cpp:228] Iteration 2220, loss = 0.502427
I0627 16:27:01.343963  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:27:01.343974  7639 solver.cpp:244]     Train net output #1: loss = 0.502427 (* 1 = 0.502427 loss)
I0627 16:27:01.343978  7639 sgd_solver.cpp:106] Iteration 2220, lr = 0.0001
I0627 16:27:02.146651  7639 solver.cpp:228] Iteration 2240, loss = 0.716849
I0627 16:27:02.146685  7639 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0627 16:27:02.146692  7639 solver.cpp:244]     Train net output #1: loss = 0.716849 (* 1 = 0.716849 loss)
I0627 16:27:02.146697  7639 sgd_solver.cpp:106] Iteration 2240, lr = 0.0001
I0627 16:27:02.948655  7639 solver.cpp:228] Iteration 2260, loss = 0.575448
I0627 16:27:02.948689  7639 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 16:27:02.948695  7639 solver.cpp:244]     Train net output #1: loss = 0.575448 (* 1 = 0.575448 loss)
I0627 16:27:02.948699  7639 sgd_solver.cpp:106] Iteration 2260, lr = 0.0001
I0627 16:27:03.751073  7639 solver.cpp:228] Iteration 2280, loss = 0.568252
I0627 16:27:03.751096  7639 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 16:27:03.751103  7639 solver.cpp:244]     Train net output #1: loss = 0.568252 (* 1 = 0.568252 loss)
I0627 16:27:03.751107  7639 sgd_solver.cpp:106] Iteration 2280, lr = 0.0001
I0627 16:27:04.540824  7639 solver.cpp:337] Iteration 2300, Testing net (#0)
I0627 16:27:05.937110  7639 solver.cpp:404]     Test net output #0: accuracy = 0.688965
I0627 16:27:05.937149  7639 solver.cpp:404]     Test net output #1: loss = 0.61571 (* 1 = 0.61571 loss)
I0627 16:27:05.950465  7639 solver.cpp:228] Iteration 2300, loss = 0.561499
I0627 16:27:05.950489  7639 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 16:27:05.950495  7639 solver.cpp:244]     Train net output #1: loss = 0.561499 (* 1 = 0.561499 loss)
I0627 16:27:05.950500  7639 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0627 16:27:06.754736  7639 solver.cpp:228] Iteration 2320, loss = 0.524765
I0627 16:27:06.754760  7639 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 16:27:06.754766  7639 solver.cpp:244]     Train net output #1: loss = 0.524765 (* 1 = 0.524765 loss)
I0627 16:27:06.754770  7639 sgd_solver.cpp:106] Iteration 2320, lr = 0.0001
I0627 16:27:07.558428  7639 solver.cpp:228] Iteration 2340, loss = 0.715536
I0627 16:27:07.558450  7639 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 16:27:07.558457  7639 solver.cpp:244]     Train net output #1: loss = 0.715536 (* 1 = 0.715536 loss)
I0627 16:27:07.558461  7639 sgd_solver.cpp:106] Iteration 2340, lr = 0.0001
I0627 16:27:08.362274  7639 solver.cpp:228] Iteration 2360, loss = 0.734453
I0627 16:27:08.362296  7639 solver.cpp:244]     Train net output #0: accuracy = 0.53125
I0627 16:27:08.362303  7639 solver.cpp:244]     Train net output #1: loss = 0.734453 (* 1 = 0.734453 loss)
I0627 16:27:08.362308  7639 sgd_solver.cpp:106] Iteration 2360, lr = 0.0001
I0627 16:27:09.165439  7639 solver.cpp:228] Iteration 2380, loss = 0.578093
I0627 16:27:09.165463  7639 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 16:27:09.165470  7639 solver.cpp:244]     Train net output #1: loss = 0.578093 (* 1 = 0.578093 loss)
I0627 16:27:09.165474  7639 sgd_solver.cpp:106] Iteration 2380, lr = 0.0001
I0627 16:27:09.957165  7639 solver.cpp:337] Iteration 2400, Testing net (#0)
I0627 16:27:11.354650  7639 solver.cpp:404]     Test net output #0: accuracy = 0.681885
I0627 16:27:11.354677  7639 solver.cpp:404]     Test net output #1: loss = 0.635337 (* 1 = 0.635337 loss)
I0627 16:27:11.367949  7639 solver.cpp:228] Iteration 2400, loss = 0.539971
I0627 16:27:11.367977  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:27:11.367983  7639 solver.cpp:244]     Train net output #1: loss = 0.539971 (* 1 = 0.539971 loss)
I0627 16:27:11.367988  7639 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0627 16:27:12.171095  7639 solver.cpp:228] Iteration 2420, loss = 0.669331
I0627 16:27:12.171129  7639 solver.cpp:244]     Train net output #0: accuracy = 0.53125
I0627 16:27:12.171136  7639 solver.cpp:244]     Train net output #1: loss = 0.669331 (* 1 = 0.669331 loss)
I0627 16:27:12.171161  7639 sgd_solver.cpp:106] Iteration 2420, lr = 0.0001
I0627 16:27:12.976893  7639 solver.cpp:228] Iteration 2440, loss = 0.658692
I0627 16:27:12.976918  7639 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 16:27:12.976925  7639 solver.cpp:244]     Train net output #1: loss = 0.658692 (* 1 = 0.658692 loss)
I0627 16:27:12.976929  7639 sgd_solver.cpp:106] Iteration 2440, lr = 0.0001
I0627 16:27:13.780975  7639 solver.cpp:228] Iteration 2460, loss = 0.523414
I0627 16:27:13.780998  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:27:13.781004  7639 solver.cpp:244]     Train net output #1: loss = 0.523414 (* 1 = 0.523414 loss)
I0627 16:27:13.781008  7639 sgd_solver.cpp:106] Iteration 2460, lr = 0.0001
I0627 16:27:14.585146  7639 solver.cpp:228] Iteration 2480, loss = 0.60702
I0627 16:27:14.585170  7639 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 16:27:14.585177  7639 solver.cpp:244]     Train net output #1: loss = 0.60702 (* 1 = 0.60702 loss)
I0627 16:27:14.585181  7639 sgd_solver.cpp:106] Iteration 2480, lr = 0.0001
I0627 16:27:15.377849  7639 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_2500.caffemodel
I0627 16:27:15.386926  7639 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_2500.solverstate
I0627 16:27:15.391733  7639 solver.cpp:337] Iteration 2500, Testing net (#0)
I0627 16:27:16.805135  7639 solver.cpp:404]     Test net output #0: accuracy = 0.682861
I0627 16:27:16.805176  7639 solver.cpp:404]     Test net output #1: loss = 0.6177 (* 1 = 0.6177 loss)
I0627 16:27:16.818467  7639 solver.cpp:228] Iteration 2500, loss = 0.529012
I0627 16:27:16.818493  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:27:16.818500  7639 solver.cpp:244]     Train net output #1: loss = 0.529012 (* 1 = 0.529012 loss)
I0627 16:27:16.818506  7639 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0627 16:27:17.621860  7639 solver.cpp:228] Iteration 2520, loss = 0.511005
I0627 16:27:17.621882  7639 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 16:27:17.621888  7639 solver.cpp:244]     Train net output #1: loss = 0.511005 (* 1 = 0.511005 loss)
I0627 16:27:17.621892  7639 sgd_solver.cpp:106] Iteration 2520, lr = 0.0001
I0627 16:27:18.424127  7639 solver.cpp:228] Iteration 2540, loss = 0.60971
I0627 16:27:18.424150  7639 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 16:27:18.424156  7639 solver.cpp:244]     Train net output #1: loss = 0.60971 (* 1 = 0.60971 loss)
I0627 16:27:18.424160  7639 sgd_solver.cpp:106] Iteration 2540, lr = 0.0001
