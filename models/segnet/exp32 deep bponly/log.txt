I0624 13:54:12.918395 18353 caffe.cpp:185] Using GPUs 1
I0624 13:54:12.931835 18353 caffe.cpp:190] GPU 1: GeForce GTX TITAN X
I0624 13:54:13.263394 18353 solver.cpp:48] Initializing solver from parameters: 
test_iter: 16
test_interval: 100
base_lr: 0.01
display: 20
max_iter: 2000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 500
snapshot_prefix: "data/models/segnet"
solver_mode: GPU
device_id: 1
net: "models/segnet/train_val.prototxt"
test_initialization: true
iter_size: 1
I0624 13:54:13.263509 18353 solver.cpp:91] Creating training net from net file: models/segnet/train_val.prototxt
I0624 13:54:13.264941 18353 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0624 13:54:13.265372 18353 net.cpp:49] Initializing net from parameters: 
name: "segnet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "DenseImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 224
    mean_value: 100
  }
  dense_image_data_param {
    source: "data/train_seg.txt"
    batch_size: 32
    shuffle: true
    new_height: 224
    new_width: 310
    is_color: false
    root_folder: "data/raw/train/"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 14
    upsample_w: 14
  }
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2_D"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2_D"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1_D"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1_D"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 28
    upsample_w: 28
  }
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2_D"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2_D"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1_D"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1_D"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
    upsample_h: 56
    upsample_w: 56
  }
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn3_2_D"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2_D"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1_D"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1_D"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
    upsample_h: 112
    upsample_w: 112
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2_D"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2_D"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1_D"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1_D"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
    upsample_h: 224
    upsample_w: 224
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2_D"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2_D"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2
    bias_term: true
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "accuracy"
}
I0624 13:54:13.265650 18353 layer_factory.hpp:77] Creating layer data
I0624 13:54:13.265681 18353 net.cpp:91] Creating Layer data
I0624 13:54:13.265686 18353 net.cpp:399] data -> data
I0624 13:54:13.265707 18353 net.cpp:399] data -> label
I0624 13:54:13.266022 18353 dense_image_data_layer.cpp:38] Opening file data/train_seg.txt
I0624 13:54:13.266911 18353 dense_image_data_layer.cpp:48] Shuffling data
I0624 13:54:13.267125 18353 dense_image_data_layer.cpp:53] A total of 2024 examples.
I0624 13:54:13.513574 18353 dense_image_data_layer.cpp:92] output data size: 1,1,224,224
I0624 13:54:13.515386 18353 net.cpp:141] Setting up data
I0624 13:54:13.515404 18353 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 13:54:13.515409 18353 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 13:54:13.515413 18353 net.cpp:156] Memory required for data: 401408
I0624 13:54:13.515419 18353 layer_factory.hpp:77] Creating layer label_data_1_split
I0624 13:54:13.515434 18353 net.cpp:91] Creating Layer label_data_1_split
I0624 13:54:13.515437 18353 net.cpp:425] label_data_1_split <- label
I0624 13:54:13.515446 18353 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0624 13:54:13.515460 18353 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0624 13:54:13.515521 18353 net.cpp:141] Setting up label_data_1_split
I0624 13:54:13.515528 18353 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 13:54:13.515532 18353 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 13:54:13.515533 18353 net.cpp:156] Memory required for data: 802816
I0624 13:54:13.515537 18353 layer_factory.hpp:77] Creating layer conv1_1
I0624 13:54:13.515549 18353 net.cpp:91] Creating Layer conv1_1
I0624 13:54:13.515552 18353 net.cpp:425] conv1_1 <- data
I0624 13:54:13.515558 18353 net.cpp:399] conv1_1 -> conv1_1
I0624 13:54:13.701439 18353 net.cpp:141] Setting up conv1_1
I0624 13:54:13.701464 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.701467 18353 net.cpp:156] Memory required for data: 7225344
I0624 13:54:13.701480 18353 layer_factory.hpp:77] Creating layer bn1_1
I0624 13:54:13.701490 18353 net.cpp:91] Creating Layer bn1_1
I0624 13:54:13.701495 18353 net.cpp:425] bn1_1 <- conv1_1
I0624 13:54:13.701499 18353 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0624 13:54:13.701684 18353 net.cpp:141] Setting up bn1_1
I0624 13:54:13.701692 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.701694 18353 net.cpp:156] Memory required for data: 13647872
I0624 13:54:13.701704 18353 layer_factory.hpp:77] Creating layer scale1_1
I0624 13:54:13.701714 18353 net.cpp:91] Creating Layer scale1_1
I0624 13:54:13.701716 18353 net.cpp:425] scale1_1 <- conv1_1
I0624 13:54:13.701720 18353 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0624 13:54:13.701756 18353 layer_factory.hpp:77] Creating layer scale1_1
I0624 13:54:13.701912 18353 net.cpp:141] Setting up scale1_1
I0624 13:54:13.701920 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.701922 18353 net.cpp:156] Memory required for data: 20070400
I0624 13:54:13.701928 18353 layer_factory.hpp:77] Creating layer relu1_1
I0624 13:54:13.701933 18353 net.cpp:91] Creating Layer relu1_1
I0624 13:54:13.701936 18353 net.cpp:425] relu1_1 <- conv1_1
I0624 13:54:13.701939 18353 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0624 13:54:13.702198 18353 net.cpp:141] Setting up relu1_1
I0624 13:54:13.702209 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.702213 18353 net.cpp:156] Memory required for data: 26492928
I0624 13:54:13.702214 18353 layer_factory.hpp:77] Creating layer conv1_2
I0624 13:54:13.702224 18353 net.cpp:91] Creating Layer conv1_2
I0624 13:54:13.702226 18353 net.cpp:425] conv1_2 <- conv1_1
I0624 13:54:13.702230 18353 net.cpp:399] conv1_2 -> conv1_2
I0624 13:54:13.703775 18353 net.cpp:141] Setting up conv1_2
I0624 13:54:13.703788 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.703790 18353 net.cpp:156] Memory required for data: 32915456
I0624 13:54:13.703795 18353 layer_factory.hpp:77] Creating layer bn1_2
I0624 13:54:13.703801 18353 net.cpp:91] Creating Layer bn1_2
I0624 13:54:13.703804 18353 net.cpp:425] bn1_2 <- conv1_2
I0624 13:54:13.703809 18353 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0624 13:54:13.703979 18353 net.cpp:141] Setting up bn1_2
I0624 13:54:13.703986 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.703989 18353 net.cpp:156] Memory required for data: 39337984
I0624 13:54:13.703996 18353 layer_factory.hpp:77] Creating layer scale1_2
I0624 13:54:13.704020 18353 net.cpp:91] Creating Layer scale1_2
I0624 13:54:13.704022 18353 net.cpp:425] scale1_2 <- conv1_2
I0624 13:54:13.704027 18353 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0624 13:54:13.704058 18353 layer_factory.hpp:77] Creating layer scale1_2
I0624 13:54:13.704216 18353 net.cpp:141] Setting up scale1_2
I0624 13:54:13.704223 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.704226 18353 net.cpp:156] Memory required for data: 45760512
I0624 13:54:13.704231 18353 layer_factory.hpp:77] Creating layer relu1_2
I0624 13:54:13.704234 18353 net.cpp:91] Creating Layer relu1_2
I0624 13:54:13.704237 18353 net.cpp:425] relu1_2 <- conv1_2
I0624 13:54:13.704241 18353 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0624 13:54:13.704375 18353 net.cpp:141] Setting up relu1_2
I0624 13:54:13.704383 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.704385 18353 net.cpp:156] Memory required for data: 52183040
I0624 13:54:13.704388 18353 layer_factory.hpp:77] Creating layer pool1
I0624 13:54:13.704391 18353 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 13:54:13.704396 18353 net.cpp:91] Creating Layer pool1
I0624 13:54:13.704398 18353 net.cpp:425] pool1 <- conv1_2
I0624 13:54:13.704402 18353 net.cpp:399] pool1 -> pool1
I0624 13:54:13.704409 18353 net.cpp:399] pool1 -> pool1_mask
I0624 13:54:13.704450 18353 net.cpp:141] Setting up pool1
I0624 13:54:13.704457 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.704460 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.704463 18353 net.cpp:156] Memory required for data: 55394304
I0624 13:54:13.704464 18353 layer_factory.hpp:77] Creating layer conv2_1
I0624 13:54:13.704471 18353 net.cpp:91] Creating Layer conv2_1
I0624 13:54:13.704474 18353 net.cpp:425] conv2_1 <- pool1
I0624 13:54:13.704478 18353 net.cpp:399] conv2_1 -> conv2_1
I0624 13:54:13.706091 18353 net.cpp:141] Setting up conv2_1
I0624 13:54:13.706105 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.706109 18353 net.cpp:156] Memory required for data: 58605568
I0624 13:54:13.706112 18353 layer_factory.hpp:77] Creating layer bn2_1
I0624 13:54:13.706120 18353 net.cpp:91] Creating Layer bn2_1
I0624 13:54:13.706121 18353 net.cpp:425] bn2_1 <- conv2_1
I0624 13:54:13.706126 18353 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0624 13:54:13.706280 18353 net.cpp:141] Setting up bn2_1
I0624 13:54:13.706288 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.706290 18353 net.cpp:156] Memory required for data: 61816832
I0624 13:54:13.706295 18353 layer_factory.hpp:77] Creating layer scale2_1
I0624 13:54:13.706303 18353 net.cpp:91] Creating Layer scale2_1
I0624 13:54:13.706305 18353 net.cpp:425] scale2_1 <- conv2_1
I0624 13:54:13.706310 18353 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0624 13:54:13.706341 18353 layer_factory.hpp:77] Creating layer scale2_1
I0624 13:54:13.706439 18353 net.cpp:141] Setting up scale2_1
I0624 13:54:13.706445 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.706447 18353 net.cpp:156] Memory required for data: 65028096
I0624 13:54:13.706455 18353 layer_factory.hpp:77] Creating layer relu2_1
I0624 13:54:13.706460 18353 net.cpp:91] Creating Layer relu2_1
I0624 13:54:13.706462 18353 net.cpp:425] relu2_1 <- conv2_1
I0624 13:54:13.706467 18353 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0624 13:54:13.706728 18353 net.cpp:141] Setting up relu2_1
I0624 13:54:13.706740 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.706743 18353 net.cpp:156] Memory required for data: 68239360
I0624 13:54:13.706745 18353 layer_factory.hpp:77] Creating layer conv2_2
I0624 13:54:13.706754 18353 net.cpp:91] Creating Layer conv2_2
I0624 13:54:13.706758 18353 net.cpp:425] conv2_2 <- conv2_1
I0624 13:54:13.706763 18353 net.cpp:399] conv2_2 -> conv2_2
I0624 13:54:13.707770 18353 net.cpp:141] Setting up conv2_2
I0624 13:54:13.707783 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.707795 18353 net.cpp:156] Memory required for data: 71450624
I0624 13:54:13.707801 18353 layer_factory.hpp:77] Creating layer bn2_2
I0624 13:54:13.707809 18353 net.cpp:91] Creating Layer bn2_2
I0624 13:54:13.707813 18353 net.cpp:425] bn2_2 <- conv2_2
I0624 13:54:13.707818 18353 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0624 13:54:13.707973 18353 net.cpp:141] Setting up bn2_2
I0624 13:54:13.707980 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.707983 18353 net.cpp:156] Memory required for data: 74661888
I0624 13:54:13.707988 18353 layer_factory.hpp:77] Creating layer scale2_2
I0624 13:54:13.707994 18353 net.cpp:91] Creating Layer scale2_2
I0624 13:54:13.707998 18353 net.cpp:425] scale2_2 <- conv2_2
I0624 13:54:13.708001 18353 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0624 13:54:13.708031 18353 layer_factory.hpp:77] Creating layer scale2_2
I0624 13:54:13.708133 18353 net.cpp:141] Setting up scale2_2
I0624 13:54:13.708140 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.708142 18353 net.cpp:156] Memory required for data: 77873152
I0624 13:54:13.708148 18353 layer_factory.hpp:77] Creating layer relu2_2
I0624 13:54:13.708151 18353 net.cpp:91] Creating Layer relu2_2
I0624 13:54:13.708153 18353 net.cpp:425] relu2_2 <- conv2_2
I0624 13:54:13.708158 18353 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0624 13:54:13.708425 18353 net.cpp:141] Setting up relu2_2
I0624 13:54:13.708437 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.708441 18353 net.cpp:156] Memory required for data: 81084416
I0624 13:54:13.708443 18353 layer_factory.hpp:77] Creating layer pool2
I0624 13:54:13.708446 18353 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 13:54:13.708451 18353 net.cpp:91] Creating Layer pool2
I0624 13:54:13.708453 18353 net.cpp:425] pool2 <- conv2_2
I0624 13:54:13.708457 18353 net.cpp:399] pool2 -> pool2
I0624 13:54:13.708463 18353 net.cpp:399] pool2 -> pool2_mask
I0624 13:54:13.708498 18353 net.cpp:141] Setting up pool2
I0624 13:54:13.708505 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.708508 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.708510 18353 net.cpp:156] Memory required for data: 82690048
I0624 13:54:13.708513 18353 layer_factory.hpp:77] Creating layer conv3_1
I0624 13:54:13.708520 18353 net.cpp:91] Creating Layer conv3_1
I0624 13:54:13.708523 18353 net.cpp:425] conv3_1 <- pool2
I0624 13:54:13.708528 18353 net.cpp:399] conv3_1 -> conv3_1
I0624 13:54:13.710465 18353 net.cpp:141] Setting up conv3_1
I0624 13:54:13.710477 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.710480 18353 net.cpp:156] Memory required for data: 84295680
I0624 13:54:13.710485 18353 layer_factory.hpp:77] Creating layer bn3_1
I0624 13:54:13.710491 18353 net.cpp:91] Creating Layer bn3_1
I0624 13:54:13.710494 18353 net.cpp:425] bn3_1 <- conv3_1
I0624 13:54:13.710499 18353 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0624 13:54:13.711262 18353 net.cpp:141] Setting up bn3_1
I0624 13:54:13.711273 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.711277 18353 net.cpp:156] Memory required for data: 85901312
I0624 13:54:13.711282 18353 layer_factory.hpp:77] Creating layer scale3_1
I0624 13:54:13.711289 18353 net.cpp:91] Creating Layer scale3_1
I0624 13:54:13.711292 18353 net.cpp:425] scale3_1 <- conv3_1
I0624 13:54:13.711297 18353 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0624 13:54:13.711331 18353 layer_factory.hpp:77] Creating layer scale3_1
I0624 13:54:13.711422 18353 net.cpp:141] Setting up scale3_1
I0624 13:54:13.711428 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.711431 18353 net.cpp:156] Memory required for data: 87506944
I0624 13:54:13.711436 18353 layer_factory.hpp:77] Creating layer relu3_1
I0624 13:54:13.711441 18353 net.cpp:91] Creating Layer relu3_1
I0624 13:54:13.711443 18353 net.cpp:425] relu3_1 <- conv3_1
I0624 13:54:13.711447 18353 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0624 13:54:13.711591 18353 net.cpp:141] Setting up relu3_1
I0624 13:54:13.711601 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.711614 18353 net.cpp:156] Memory required for data: 89112576
I0624 13:54:13.711617 18353 layer_factory.hpp:77] Creating layer conv3_2
I0624 13:54:13.711627 18353 net.cpp:91] Creating Layer conv3_2
I0624 13:54:13.711633 18353 net.cpp:425] conv3_2 <- conv3_1
I0624 13:54:13.711638 18353 net.cpp:399] conv3_2 -> conv3_2
I0624 13:54:13.713397 18353 net.cpp:141] Setting up conv3_2
I0624 13:54:13.713412 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.713414 18353 net.cpp:156] Memory required for data: 90718208
I0624 13:54:13.713418 18353 layer_factory.hpp:77] Creating layer bn3_2
I0624 13:54:13.713424 18353 net.cpp:91] Creating Layer bn3_2
I0624 13:54:13.713428 18353 net.cpp:425] bn3_2 <- conv3_2
I0624 13:54:13.713431 18353 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0624 13:54:13.713583 18353 net.cpp:141] Setting up bn3_2
I0624 13:54:13.713590 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.713593 18353 net.cpp:156] Memory required for data: 92323840
I0624 13:54:13.713601 18353 layer_factory.hpp:77] Creating layer scale3_2
I0624 13:54:13.713608 18353 net.cpp:91] Creating Layer scale3_2
I0624 13:54:13.713611 18353 net.cpp:425] scale3_2 <- conv3_2
I0624 13:54:13.713614 18353 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0624 13:54:13.713649 18353 layer_factory.hpp:77] Creating layer scale3_2
I0624 13:54:13.713738 18353 net.cpp:141] Setting up scale3_2
I0624 13:54:13.713744 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.713747 18353 net.cpp:156] Memory required for data: 93929472
I0624 13:54:13.713752 18353 layer_factory.hpp:77] Creating layer relu3_2
I0624 13:54:13.713755 18353 net.cpp:91] Creating Layer relu3_2
I0624 13:54:13.713758 18353 net.cpp:425] relu3_2 <- conv3_2
I0624 13:54:13.713763 18353 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0624 13:54:13.714032 18353 net.cpp:141] Setting up relu3_2
I0624 13:54:13.714042 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.714046 18353 net.cpp:156] Memory required for data: 95535104
I0624 13:54:13.714047 18353 layer_factory.hpp:77] Creating layer pool3
I0624 13:54:13.714051 18353 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 13:54:13.714056 18353 net.cpp:91] Creating Layer pool3
I0624 13:54:13.714058 18353 net.cpp:425] pool3 <- conv3_2
I0624 13:54:13.714062 18353 net.cpp:399] pool3 -> pool3
I0624 13:54:13.714068 18353 net.cpp:399] pool3 -> pool3_mask
I0624 13:54:13.714105 18353 net.cpp:141] Setting up pool3
I0624 13:54:13.714114 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.714118 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.714119 18353 net.cpp:156] Memory required for data: 96337920
I0624 13:54:13.714121 18353 layer_factory.hpp:77] Creating layer conv4_1
I0624 13:54:13.714129 18353 net.cpp:91] Creating Layer conv4_1
I0624 13:54:13.714131 18353 net.cpp:425] conv4_1 <- pool3
I0624 13:54:13.714138 18353 net.cpp:399] conv4_1 -> conv4_1
I0624 13:54:13.717360 18353 net.cpp:141] Setting up conv4_1
I0624 13:54:13.717372 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.717375 18353 net.cpp:156] Memory required for data: 97140736
I0624 13:54:13.717381 18353 layer_factory.hpp:77] Creating layer bn4_1
I0624 13:54:13.717387 18353 net.cpp:91] Creating Layer bn4_1
I0624 13:54:13.717391 18353 net.cpp:425] bn4_1 <- conv4_1
I0624 13:54:13.717394 18353 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0624 13:54:13.717552 18353 net.cpp:141] Setting up bn4_1
I0624 13:54:13.717559 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.717562 18353 net.cpp:156] Memory required for data: 97943552
I0624 13:54:13.717567 18353 layer_factory.hpp:77] Creating layer scale4_1
I0624 13:54:13.717574 18353 net.cpp:91] Creating Layer scale4_1
I0624 13:54:13.717577 18353 net.cpp:425] scale4_1 <- conv4_1
I0624 13:54:13.717581 18353 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0624 13:54:13.717615 18353 layer_factory.hpp:77] Creating layer scale4_1
I0624 13:54:13.717716 18353 net.cpp:141] Setting up scale4_1
I0624 13:54:13.717732 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.717736 18353 net.cpp:156] Memory required for data: 98746368
I0624 13:54:13.717741 18353 layer_factory.hpp:77] Creating layer relu4_1
I0624 13:54:13.717748 18353 net.cpp:91] Creating Layer relu4_1
I0624 13:54:13.717751 18353 net.cpp:425] relu4_1 <- conv4_1
I0624 13:54:13.717756 18353 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0624 13:54:13.718031 18353 net.cpp:141] Setting up relu4_1
I0624 13:54:13.718044 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.718046 18353 net.cpp:156] Memory required for data: 99549184
I0624 13:54:13.718049 18353 layer_factory.hpp:77] Creating layer conv4_2
I0624 13:54:13.718057 18353 net.cpp:91] Creating Layer conv4_2
I0624 13:54:13.718060 18353 net.cpp:425] conv4_2 <- conv4_1
I0624 13:54:13.718065 18353 net.cpp:399] conv4_2 -> conv4_2
I0624 13:54:13.723716 18353 net.cpp:141] Setting up conv4_2
I0624 13:54:13.723728 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.723731 18353 net.cpp:156] Memory required for data: 100352000
I0624 13:54:13.723736 18353 layer_factory.hpp:77] Creating layer bn4_2
I0624 13:54:13.723743 18353 net.cpp:91] Creating Layer bn4_2
I0624 13:54:13.723747 18353 net.cpp:425] bn4_2 <- conv4_2
I0624 13:54:13.723750 18353 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0624 13:54:13.723914 18353 net.cpp:141] Setting up bn4_2
I0624 13:54:13.723922 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.723925 18353 net.cpp:156] Memory required for data: 101154816
I0624 13:54:13.723930 18353 layer_factory.hpp:77] Creating layer scale4_2
I0624 13:54:13.723937 18353 net.cpp:91] Creating Layer scale4_2
I0624 13:54:13.723939 18353 net.cpp:425] scale4_2 <- conv4_2
I0624 13:54:13.723944 18353 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0624 13:54:13.723978 18353 layer_factory.hpp:77] Creating layer scale4_2
I0624 13:54:13.724071 18353 net.cpp:141] Setting up scale4_2
I0624 13:54:13.724077 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.724081 18353 net.cpp:156] Memory required for data: 101957632
I0624 13:54:13.724084 18353 layer_factory.hpp:77] Creating layer relu4_2
I0624 13:54:13.724088 18353 net.cpp:91] Creating Layer relu4_2
I0624 13:54:13.724092 18353 net.cpp:425] relu4_2 <- conv4_2
I0624 13:54:13.724094 18353 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0624 13:54:13.724243 18353 net.cpp:141] Setting up relu4_2
I0624 13:54:13.724252 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.724254 18353 net.cpp:156] Memory required for data: 102760448
I0624 13:54:13.724257 18353 layer_factory.hpp:77] Creating layer pool4
I0624 13:54:13.724259 18353 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 13:54:13.724266 18353 net.cpp:91] Creating Layer pool4
I0624 13:54:13.724267 18353 net.cpp:425] pool4 <- conv4_2
I0624 13:54:13.724272 18353 net.cpp:399] pool4 -> pool4
I0624 13:54:13.724277 18353 net.cpp:399] pool4 -> pool4_mask
I0624 13:54:13.724315 18353 net.cpp:141] Setting up pool4
I0624 13:54:13.724321 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.724324 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.724326 18353 net.cpp:156] Memory required for data: 103161856
I0624 13:54:13.724328 18353 layer_factory.hpp:77] Creating layer conv5_1
I0624 13:54:13.724336 18353 net.cpp:91] Creating Layer conv5_1
I0624 13:54:13.724339 18353 net.cpp:425] conv5_1 <- pool4
I0624 13:54:13.724350 18353 net.cpp:399] conv5_1 -> conv5_1
I0624 13:54:13.729848 18353 net.cpp:141] Setting up conv5_1
I0624 13:54:13.729862 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.729866 18353 net.cpp:156] Memory required for data: 103362560
I0624 13:54:13.729869 18353 layer_factory.hpp:77] Creating layer bn5_1
I0624 13:54:13.729876 18353 net.cpp:91] Creating Layer bn5_1
I0624 13:54:13.729878 18353 net.cpp:425] bn5_1 <- conv5_1
I0624 13:54:13.729883 18353 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0624 13:54:13.730049 18353 net.cpp:141] Setting up bn5_1
I0624 13:54:13.730067 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.730069 18353 net.cpp:156] Memory required for data: 103563264
I0624 13:54:13.730075 18353 layer_factory.hpp:77] Creating layer scale5_1
I0624 13:54:13.730082 18353 net.cpp:91] Creating Layer scale5_1
I0624 13:54:13.730083 18353 net.cpp:425] scale5_1 <- conv5_1
I0624 13:54:13.730087 18353 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0624 13:54:13.730124 18353 layer_factory.hpp:77] Creating layer scale5_1
I0624 13:54:13.730216 18353 net.cpp:141] Setting up scale5_1
I0624 13:54:13.730222 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.730224 18353 net.cpp:156] Memory required for data: 103763968
I0624 13:54:13.730228 18353 layer_factory.hpp:77] Creating layer relu5_1
I0624 13:54:13.730233 18353 net.cpp:91] Creating Layer relu5_1
I0624 13:54:13.730237 18353 net.cpp:425] relu5_1 <- conv5_1
I0624 13:54:13.730239 18353 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0624 13:54:13.730514 18353 net.cpp:141] Setting up relu5_1
I0624 13:54:13.730525 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.730526 18353 net.cpp:156] Memory required for data: 103964672
I0624 13:54:13.730530 18353 layer_factory.hpp:77] Creating layer conv5_2
I0624 13:54:13.730537 18353 net.cpp:91] Creating Layer conv5_2
I0624 13:54:13.730540 18353 net.cpp:425] conv5_2 <- conv5_1
I0624 13:54:13.730545 18353 net.cpp:399] conv5_2 -> conv5_2
I0624 13:54:13.735982 18353 net.cpp:141] Setting up conv5_2
I0624 13:54:13.735998 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.736001 18353 net.cpp:156] Memory required for data: 104165376
I0624 13:54:13.736006 18353 layer_factory.hpp:77] Creating layer bn5_2
I0624 13:54:13.736012 18353 net.cpp:91] Creating Layer bn5_2
I0624 13:54:13.736016 18353 net.cpp:425] bn5_2 <- conv5_2
I0624 13:54:13.736021 18353 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0624 13:54:13.736181 18353 net.cpp:141] Setting up bn5_2
I0624 13:54:13.736188 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.736191 18353 net.cpp:156] Memory required for data: 104366080
I0624 13:54:13.736197 18353 layer_factory.hpp:77] Creating layer scale5_2
I0624 13:54:13.736204 18353 net.cpp:91] Creating Layer scale5_2
I0624 13:54:13.736207 18353 net.cpp:425] scale5_2 <- conv5_2
I0624 13:54:13.736210 18353 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0624 13:54:13.736249 18353 layer_factory.hpp:77] Creating layer scale5_2
I0624 13:54:13.736343 18353 net.cpp:141] Setting up scale5_2
I0624 13:54:13.736351 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.736352 18353 net.cpp:156] Memory required for data: 104566784
I0624 13:54:13.736356 18353 layer_factory.hpp:77] Creating layer relu5_2
I0624 13:54:13.736362 18353 net.cpp:91] Creating Layer relu5_2
I0624 13:54:13.736366 18353 net.cpp:425] relu5_2 <- conv5_2
I0624 13:54:13.736368 18353 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0624 13:54:13.736780 18353 net.cpp:141] Setting up relu5_2
I0624 13:54:13.736790 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.736793 18353 net.cpp:156] Memory required for data: 104767488
I0624 13:54:13.736795 18353 layer_factory.hpp:77] Creating layer pool5
I0624 13:54:13.736799 18353 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 13:54:13.736804 18353 net.cpp:91] Creating Layer pool5
I0624 13:54:13.736807 18353 net.cpp:425] pool5 <- conv5_2
I0624 13:54:13.736811 18353 net.cpp:399] pool5 -> pool5
I0624 13:54:13.736816 18353 net.cpp:399] pool5 -> pool5_mask
I0624 13:54:13.736857 18353 net.cpp:141] Setting up pool5
I0624 13:54:13.736865 18353 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 13:54:13.736868 18353 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 13:54:13.736871 18353 net.cpp:156] Memory required for data: 104867840
I0624 13:54:13.736873 18353 layer_factory.hpp:77] Creating layer upsample5
I0624 13:54:13.736881 18353 net.cpp:91] Creating Layer upsample5
I0624 13:54:13.736882 18353 net.cpp:425] upsample5 <- pool5
I0624 13:54:13.736886 18353 net.cpp:425] upsample5 <- pool5_mask
I0624 13:54:13.736901 18353 net.cpp:399] upsample5 -> pool5_D
I0624 13:54:13.736927 18353 net.cpp:141] Setting up upsample5
I0624 13:54:13.736934 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.736937 18353 net.cpp:156] Memory required for data: 105068544
I0624 13:54:13.736938 18353 layer_factory.hpp:77] Creating layer conv5_2_D
I0624 13:54:13.736948 18353 net.cpp:91] Creating Layer conv5_2_D
I0624 13:54:13.736951 18353 net.cpp:425] conv5_2_D <- pool5_D
I0624 13:54:13.736955 18353 net.cpp:399] conv5_2_D -> conv5_2_D
I0624 13:54:13.742444 18353 net.cpp:141] Setting up conv5_2_D
I0624 13:54:13.742456 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.742458 18353 net.cpp:156] Memory required for data: 105269248
I0624 13:54:13.742463 18353 layer_factory.hpp:77] Creating layer bn5_2_D
I0624 13:54:13.742470 18353 net.cpp:91] Creating Layer bn5_2_D
I0624 13:54:13.742473 18353 net.cpp:425] bn5_2_D <- conv5_2_D
I0624 13:54:13.742477 18353 net.cpp:386] bn5_2_D -> conv5_2_D (in-place)
I0624 13:54:13.742645 18353 net.cpp:141] Setting up bn5_2_D
I0624 13:54:13.742651 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.742655 18353 net.cpp:156] Memory required for data: 105469952
I0624 13:54:13.742660 18353 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 13:54:13.742666 18353 net.cpp:91] Creating Layer scale5_2_D
I0624 13:54:13.742669 18353 net.cpp:425] scale5_2_D <- conv5_2_D
I0624 13:54:13.742672 18353 net.cpp:386] scale5_2_D -> conv5_2_D (in-place)
I0624 13:54:13.742709 18353 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 13:54:13.742810 18353 net.cpp:141] Setting up scale5_2_D
I0624 13:54:13.742816 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.742820 18353 net.cpp:156] Memory required for data: 105670656
I0624 13:54:13.742832 18353 layer_factory.hpp:77] Creating layer relu5_2_D
I0624 13:54:13.742837 18353 net.cpp:91] Creating Layer relu5_2_D
I0624 13:54:13.742841 18353 net.cpp:425] relu5_2_D <- conv5_2_D
I0624 13:54:13.742844 18353 net.cpp:386] relu5_2_D -> conv5_2_D (in-place)
I0624 13:54:13.742990 18353 net.cpp:141] Setting up relu5_2_D
I0624 13:54:13.742998 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.743001 18353 net.cpp:156] Memory required for data: 105871360
I0624 13:54:13.743003 18353 layer_factory.hpp:77] Creating layer conv5_1_D
I0624 13:54:13.743011 18353 net.cpp:91] Creating Layer conv5_1_D
I0624 13:54:13.743015 18353 net.cpp:425] conv5_1_D <- conv5_2_D
I0624 13:54:13.743019 18353 net.cpp:399] conv5_1_D -> conv5_1_D
I0624 13:54:13.748525 18353 net.cpp:141] Setting up conv5_1_D
I0624 13:54:13.748538 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.748540 18353 net.cpp:156] Memory required for data: 106072064
I0624 13:54:13.748545 18353 layer_factory.hpp:77] Creating layer bn5_1_D
I0624 13:54:13.748551 18353 net.cpp:91] Creating Layer bn5_1_D
I0624 13:54:13.748553 18353 net.cpp:425] bn5_1_D <- conv5_1_D
I0624 13:54:13.748559 18353 net.cpp:386] bn5_1_D -> conv5_1_D (in-place)
I0624 13:54:13.748738 18353 net.cpp:141] Setting up bn5_1_D
I0624 13:54:13.748745 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.748747 18353 net.cpp:156] Memory required for data: 106272768
I0624 13:54:13.748754 18353 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 13:54:13.748759 18353 net.cpp:91] Creating Layer scale5_1_D
I0624 13:54:13.748761 18353 net.cpp:425] scale5_1_D <- conv5_1_D
I0624 13:54:13.748764 18353 net.cpp:386] scale5_1_D -> conv5_1_D (in-place)
I0624 13:54:13.748798 18353 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 13:54:13.748896 18353 net.cpp:141] Setting up scale5_1_D
I0624 13:54:13.748903 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.748905 18353 net.cpp:156] Memory required for data: 106473472
I0624 13:54:13.748909 18353 layer_factory.hpp:77] Creating layer relu5_1_D
I0624 13:54:13.748914 18353 net.cpp:91] Creating Layer relu5_1_D
I0624 13:54:13.748917 18353 net.cpp:425] relu5_1_D <- conv5_1_D
I0624 13:54:13.748920 18353 net.cpp:386] relu5_1_D -> conv5_1_D (in-place)
I0624 13:54:13.749228 18353 net.cpp:141] Setting up relu5_1_D
I0624 13:54:13.749240 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.749243 18353 net.cpp:156] Memory required for data: 106674176
I0624 13:54:13.749246 18353 layer_factory.hpp:77] Creating layer upsample4
I0624 13:54:13.749253 18353 net.cpp:91] Creating Layer upsample4
I0624 13:54:13.749258 18353 net.cpp:425] upsample4 <- conv5_1_D
I0624 13:54:13.749261 18353 net.cpp:425] upsample4 <- pool4_mask
I0624 13:54:13.749264 18353 net.cpp:399] upsample4 -> pool4_D
I0624 13:54:13.749297 18353 net.cpp:141] Setting up upsample4
I0624 13:54:13.749303 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.749305 18353 net.cpp:156] Memory required for data: 107476992
I0624 13:54:13.749308 18353 layer_factory.hpp:77] Creating layer conv4_2_D
I0624 13:54:13.749316 18353 net.cpp:91] Creating Layer conv4_2_D
I0624 13:54:13.749320 18353 net.cpp:425] conv4_2_D <- pool4_D
I0624 13:54:13.749325 18353 net.cpp:399] conv4_2_D -> conv4_2_D
I0624 13:54:13.754690 18353 net.cpp:141] Setting up conv4_2_D
I0624 13:54:13.754703 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.754705 18353 net.cpp:156] Memory required for data: 108279808
I0624 13:54:13.754710 18353 layer_factory.hpp:77] Creating layer bn4_2_D
I0624 13:54:13.754717 18353 net.cpp:91] Creating Layer bn4_2_D
I0624 13:54:13.754720 18353 net.cpp:425] bn4_2_D <- conv4_2_D
I0624 13:54:13.754725 18353 net.cpp:386] bn4_2_D -> conv4_2_D (in-place)
I0624 13:54:13.754904 18353 net.cpp:141] Setting up bn4_2_D
I0624 13:54:13.754912 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.754914 18353 net.cpp:156] Memory required for data: 109082624
I0624 13:54:13.754920 18353 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 13:54:13.754926 18353 net.cpp:91] Creating Layer scale4_2_D
I0624 13:54:13.754930 18353 net.cpp:425] scale4_2_D <- conv4_2_D
I0624 13:54:13.754932 18353 net.cpp:386] scale4_2_D -> conv4_2_D (in-place)
I0624 13:54:13.754966 18353 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 13:54:13.755067 18353 net.cpp:141] Setting up scale4_2_D
I0624 13:54:13.755074 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.755076 18353 net.cpp:156] Memory required for data: 109885440
I0624 13:54:13.755081 18353 layer_factory.hpp:77] Creating layer relu4_2_D
I0624 13:54:13.755085 18353 net.cpp:91] Creating Layer relu4_2_D
I0624 13:54:13.755087 18353 net.cpp:425] relu4_2_D <- conv4_2_D
I0624 13:54:13.755092 18353 net.cpp:386] relu4_2_D -> conv4_2_D (in-place)
I0624 13:54:13.755380 18353 net.cpp:141] Setting up relu4_2_D
I0624 13:54:13.755391 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.755394 18353 net.cpp:156] Memory required for data: 110688256
I0624 13:54:13.755396 18353 layer_factory.hpp:77] Creating layer conv4_1_D
I0624 13:54:13.755408 18353 net.cpp:91] Creating Layer conv4_1_D
I0624 13:54:13.755410 18353 net.cpp:425] conv4_1_D <- conv4_2_D
I0624 13:54:13.755416 18353 net.cpp:399] conv4_1_D -> conv4_1_D
I0624 13:54:13.758676 18353 net.cpp:141] Setting up conv4_1_D
I0624 13:54:13.758687 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.758688 18353 net.cpp:156] Memory required for data: 111089664
I0624 13:54:13.758693 18353 layer_factory.hpp:77] Creating layer bn4_1_D
I0624 13:54:13.758700 18353 net.cpp:91] Creating Layer bn4_1_D
I0624 13:54:13.758703 18353 net.cpp:425] bn4_1_D <- conv4_1_D
I0624 13:54:13.758708 18353 net.cpp:386] bn4_1_D -> conv4_1_D (in-place)
I0624 13:54:13.758882 18353 net.cpp:141] Setting up bn4_1_D
I0624 13:54:13.758889 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.758893 18353 net.cpp:156] Memory required for data: 111491072
I0624 13:54:13.758898 18353 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 13:54:13.758903 18353 net.cpp:91] Creating Layer scale4_1_D
I0624 13:54:13.758905 18353 net.cpp:425] scale4_1_D <- conv4_1_D
I0624 13:54:13.758913 18353 net.cpp:386] scale4_1_D -> conv4_1_D (in-place)
I0624 13:54:13.758949 18353 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 13:54:13.759066 18353 net.cpp:141] Setting up scale4_1_D
I0624 13:54:13.759073 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.759076 18353 net.cpp:156] Memory required for data: 111892480
I0624 13:54:13.759080 18353 layer_factory.hpp:77] Creating layer relu4_1_D
I0624 13:54:13.759090 18353 net.cpp:91] Creating Layer relu4_1_D
I0624 13:54:13.759095 18353 net.cpp:425] relu4_1_D <- conv4_1_D
I0624 13:54:13.759099 18353 net.cpp:386] relu4_1_D -> conv4_1_D (in-place)
I0624 13:54:13.759265 18353 net.cpp:141] Setting up relu4_1_D
I0624 13:54:13.759274 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.759277 18353 net.cpp:156] Memory required for data: 112293888
I0624 13:54:13.759280 18353 layer_factory.hpp:77] Creating layer upsample3
I0624 13:54:13.759285 18353 net.cpp:91] Creating Layer upsample3
I0624 13:54:13.759289 18353 net.cpp:425] upsample3 <- conv4_1_D
I0624 13:54:13.759292 18353 net.cpp:425] upsample3 <- pool3_mask
I0624 13:54:13.759296 18353 net.cpp:399] upsample3 -> pool3_D
I0624 13:54:13.759325 18353 net.cpp:141] Setting up upsample3
I0624 13:54:13.759331 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.759333 18353 net.cpp:156] Memory required for data: 113899520
I0624 13:54:13.759335 18353 layer_factory.hpp:77] Creating layer conv3_2_D
I0624 13:54:13.759343 18353 net.cpp:91] Creating Layer conv3_2_D
I0624 13:54:13.759346 18353 net.cpp:425] conv3_2_D <- pool3_D
I0624 13:54:13.759351 18353 net.cpp:399] conv3_2_D -> conv3_2_D
I0624 13:54:13.761837 18353 net.cpp:141] Setting up conv3_2_D
I0624 13:54:13.761850 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.761853 18353 net.cpp:156] Memory required for data: 115505152
I0624 13:54:13.761858 18353 layer_factory.hpp:77] Creating layer bn3_2_D
I0624 13:54:13.761868 18353 net.cpp:91] Creating Layer bn3_2_D
I0624 13:54:13.761871 18353 net.cpp:425] bn3_2_D <- conv3_2_D
I0624 13:54:13.761875 18353 net.cpp:386] bn3_2_D -> conv3_2_D (in-place)
I0624 13:54:13.762058 18353 net.cpp:141] Setting up bn3_2_D
I0624 13:54:13.762066 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.762069 18353 net.cpp:156] Memory required for data: 117110784
I0624 13:54:13.762075 18353 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 13:54:13.762082 18353 net.cpp:91] Creating Layer scale3_2_D
I0624 13:54:13.762084 18353 net.cpp:425] scale3_2_D <- conv3_2_D
I0624 13:54:13.762089 18353 net.cpp:386] scale3_2_D -> conv3_2_D (in-place)
I0624 13:54:13.762125 18353 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 13:54:13.762230 18353 net.cpp:141] Setting up scale3_2_D
I0624 13:54:13.762238 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.762240 18353 net.cpp:156] Memory required for data: 118716416
I0624 13:54:13.762244 18353 layer_factory.hpp:77] Creating layer relu3_2_D
I0624 13:54:13.762249 18353 net.cpp:91] Creating Layer relu3_2_D
I0624 13:54:13.762253 18353 net.cpp:425] relu3_2_D <- conv3_2_D
I0624 13:54:13.762255 18353 net.cpp:386] relu3_2_D -> conv3_2_D (in-place)
I0624 13:54:13.762543 18353 net.cpp:141] Setting up relu3_2_D
I0624 13:54:13.762554 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.762557 18353 net.cpp:156] Memory required for data: 120322048
I0624 13:54:13.762559 18353 layer_factory.hpp:77] Creating layer conv3_1_D
I0624 13:54:13.762568 18353 net.cpp:91] Creating Layer conv3_1_D
I0624 13:54:13.762572 18353 net.cpp:425] conv3_1_D <- conv3_2_D
I0624 13:54:13.762575 18353 net.cpp:399] conv3_1_D -> conv3_1_D
I0624 13:54:13.763978 18353 net.cpp:141] Setting up conv3_1_D
I0624 13:54:13.763990 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.763993 18353 net.cpp:156] Memory required for data: 121124864
I0624 13:54:13.763998 18353 layer_factory.hpp:77] Creating layer bn3_1_D
I0624 13:54:13.764004 18353 net.cpp:91] Creating Layer bn3_1_D
I0624 13:54:13.764008 18353 net.cpp:425] bn3_1_D <- conv3_1_D
I0624 13:54:13.764011 18353 net.cpp:386] bn3_1_D -> conv3_1_D (in-place)
I0624 13:54:13.764202 18353 net.cpp:141] Setting up bn3_1_D
I0624 13:54:13.764219 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.764221 18353 net.cpp:156] Memory required for data: 121927680
I0624 13:54:13.764226 18353 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 13:54:13.764232 18353 net.cpp:91] Creating Layer scale3_1_D
I0624 13:54:13.764235 18353 net.cpp:425] scale3_1_D <- conv3_1_D
I0624 13:54:13.764240 18353 net.cpp:386] scale3_1_D -> conv3_1_D (in-place)
I0624 13:54:13.764282 18353 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 13:54:13.764396 18353 net.cpp:141] Setting up scale3_1_D
I0624 13:54:13.764403 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.764406 18353 net.cpp:156] Memory required for data: 122730496
I0624 13:54:13.764410 18353 layer_factory.hpp:77] Creating layer relu3_1_D
I0624 13:54:13.764415 18353 net.cpp:91] Creating Layer relu3_1_D
I0624 13:54:13.764417 18353 net.cpp:425] relu3_1_D <- conv3_1_D
I0624 13:54:13.764421 18353 net.cpp:386] relu3_1_D -> conv3_1_D (in-place)
I0624 13:54:13.764737 18353 net.cpp:141] Setting up relu3_1_D
I0624 13:54:13.764750 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.764752 18353 net.cpp:156] Memory required for data: 123533312
I0624 13:54:13.764755 18353 layer_factory.hpp:77] Creating layer upsample2
I0624 13:54:13.764760 18353 net.cpp:91] Creating Layer upsample2
I0624 13:54:13.764763 18353 net.cpp:425] upsample2 <- conv3_1_D
I0624 13:54:13.764766 18353 net.cpp:425] upsample2 <- pool2_mask
I0624 13:54:13.764770 18353 net.cpp:399] upsample2 -> pool2_D
I0624 13:54:13.764803 18353 net.cpp:141] Setting up upsample2
I0624 13:54:13.764809 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.764811 18353 net.cpp:156] Memory required for data: 126744576
I0624 13:54:13.764814 18353 layer_factory.hpp:77] Creating layer conv2_2_D
I0624 13:54:13.764822 18353 net.cpp:91] Creating Layer conv2_2_D
I0624 13:54:13.764824 18353 net.cpp:425] conv2_2_D <- pool2_D
I0624 13:54:13.764828 18353 net.cpp:399] conv2_2_D -> conv2_2_D
I0624 13:54:13.766047 18353 net.cpp:141] Setting up conv2_2_D
I0624 13:54:13.766062 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.766065 18353 net.cpp:156] Memory required for data: 129955840
I0624 13:54:13.766072 18353 layer_factory.hpp:77] Creating layer bn2_2_D
I0624 13:54:13.766083 18353 net.cpp:91] Creating Layer bn2_2_D
I0624 13:54:13.766088 18353 net.cpp:425] bn2_2_D <- conv2_2_D
I0624 13:54:13.766098 18353 net.cpp:386] bn2_2_D -> conv2_2_D (in-place)
I0624 13:54:13.766311 18353 net.cpp:141] Setting up bn2_2_D
I0624 13:54:13.766321 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.766326 18353 net.cpp:156] Memory required for data: 133167104
I0624 13:54:13.766335 18353 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 13:54:13.766347 18353 net.cpp:91] Creating Layer scale2_2_D
I0624 13:54:13.766353 18353 net.cpp:425] scale2_2_D <- conv2_2_D
I0624 13:54:13.766360 18353 net.cpp:386] scale2_2_D -> conv2_2_D (in-place)
I0624 13:54:13.766410 18353 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 13:54:13.766551 18353 net.cpp:141] Setting up scale2_2_D
I0624 13:54:13.766561 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.766566 18353 net.cpp:156] Memory required for data: 136378368
I0624 13:54:13.766572 18353 layer_factory.hpp:77] Creating layer relu2_2_D
I0624 13:54:13.766580 18353 net.cpp:91] Creating Layer relu2_2_D
I0624 13:54:13.766584 18353 net.cpp:425] relu2_2_D <- conv2_2_D
I0624 13:54:13.766593 18353 net.cpp:386] relu2_2_D -> conv2_2_D (in-place)
I0624 13:54:13.766755 18353 net.cpp:141] Setting up relu2_2_D
I0624 13:54:13.766768 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.766773 18353 net.cpp:156] Memory required for data: 139589632
I0624 13:54:13.766777 18353 layer_factory.hpp:77] Creating layer conv2_1_D
I0624 13:54:13.766788 18353 net.cpp:91] Creating Layer conv2_1_D
I0624 13:54:13.766793 18353 net.cpp:425] conv2_1_D <- conv2_2_D
I0624 13:54:13.766801 18353 net.cpp:399] conv2_1_D -> conv2_1_D
I0624 13:54:13.768007 18353 net.cpp:141] Setting up conv2_1_D
I0624 13:54:13.768029 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.768034 18353 net.cpp:156] Memory required for data: 141195264
I0624 13:54:13.768041 18353 layer_factory.hpp:77] Creating layer bn2_1_D
I0624 13:54:13.768052 18353 net.cpp:91] Creating Layer bn2_1_D
I0624 13:54:13.768059 18353 net.cpp:425] bn2_1_D <- conv2_1_D
I0624 13:54:13.768069 18353 net.cpp:386] bn2_1_D -> conv2_1_D (in-place)
I0624 13:54:13.768271 18353 net.cpp:141] Setting up bn2_1_D
I0624 13:54:13.768282 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.768286 18353 net.cpp:156] Memory required for data: 142800896
I0624 13:54:13.768296 18353 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 13:54:13.768307 18353 net.cpp:91] Creating Layer scale2_1_D
I0624 13:54:13.768312 18353 net.cpp:425] scale2_1_D <- conv2_1_D
I0624 13:54:13.768319 18353 net.cpp:386] scale2_1_D -> conv2_1_D (in-place)
I0624 13:54:13.768369 18353 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 13:54:13.768512 18353 net.cpp:141] Setting up scale2_1_D
I0624 13:54:13.768522 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.768527 18353 net.cpp:156] Memory required for data: 144406528
I0624 13:54:13.768534 18353 layer_factory.hpp:77] Creating layer relu2_1_D
I0624 13:54:13.768542 18353 net.cpp:91] Creating Layer relu2_1_D
I0624 13:54:13.768546 18353 net.cpp:425] relu2_1_D <- conv2_1_D
I0624 13:54:13.768555 18353 net.cpp:386] relu2_1_D -> conv2_1_D (in-place)
I0624 13:54:13.768847 18353 net.cpp:141] Setting up relu2_1_D
I0624 13:54:13.768860 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.768864 18353 net.cpp:156] Memory required for data: 146012160
I0624 13:54:13.768936 18353 layer_factory.hpp:77] Creating layer upsample1
I0624 13:54:13.768947 18353 net.cpp:91] Creating Layer upsample1
I0624 13:54:13.768954 18353 net.cpp:425] upsample1 <- conv2_1_D
I0624 13:54:13.768959 18353 net.cpp:425] upsample1 <- pool1_mask
I0624 13:54:13.768966 18353 net.cpp:399] upsample1 -> pool1_D
I0624 13:54:13.769006 18353 net.cpp:141] Setting up upsample1
I0624 13:54:13.769016 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.769019 18353 net.cpp:156] Memory required for data: 152434688
I0624 13:54:13.769023 18353 layer_factory.hpp:77] Creating layer conv1_2_D
I0624 13:54:13.769035 18353 net.cpp:91] Creating Layer conv1_2_D
I0624 13:54:13.769042 18353 net.cpp:425] conv1_2_D <- pool1_D
I0624 13:54:13.769050 18353 net.cpp:399] conv1_2_D -> conv1_2_D
I0624 13:54:13.770006 18353 net.cpp:141] Setting up conv1_2_D
I0624 13:54:13.770020 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.770025 18353 net.cpp:156] Memory required for data: 158857216
I0624 13:54:13.770033 18353 layer_factory.hpp:77] Creating layer bn1_2_D
I0624 13:54:13.770045 18353 net.cpp:91] Creating Layer bn1_2_D
I0624 13:54:13.770051 18353 net.cpp:425] bn1_2_D <- conv1_2_D
I0624 13:54:13.770057 18353 net.cpp:386] bn1_2_D -> conv1_2_D (in-place)
I0624 13:54:13.770301 18353 net.cpp:141] Setting up bn1_2_D
I0624 13:54:13.770313 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.770316 18353 net.cpp:156] Memory required for data: 165279744
I0624 13:54:13.770326 18353 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 13:54:13.770337 18353 net.cpp:91] Creating Layer scale1_2_D
I0624 13:54:13.770344 18353 net.cpp:425] scale1_2_D <- conv1_2_D
I0624 13:54:13.770350 18353 net.cpp:386] scale1_2_D -> conv1_2_D (in-place)
I0624 13:54:13.770401 18353 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 13:54:13.770606 18353 net.cpp:141] Setting up scale1_2_D
I0624 13:54:13.770615 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.770619 18353 net.cpp:156] Memory required for data: 171702272
I0624 13:54:13.770627 18353 layer_factory.hpp:77] Creating layer relu1_2_D
I0624 13:54:13.770634 18353 net.cpp:91] Creating Layer relu1_2_D
I0624 13:54:13.770638 18353 net.cpp:425] relu1_2_D <- conv1_2_D
I0624 13:54:13.770647 18353 net.cpp:386] relu1_2_D -> conv1_2_D (in-place)
I0624 13:54:13.770954 18353 net.cpp:141] Setting up relu1_2_D
I0624 13:54:13.770967 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.770972 18353 net.cpp:156] Memory required for data: 178124800
I0624 13:54:13.770975 18353 layer_factory.hpp:77] Creating layer conv1_1_D
I0624 13:54:13.770993 18353 net.cpp:91] Creating Layer conv1_1_D
I0624 13:54:13.771000 18353 net.cpp:425] conv1_1_D <- conv1_2_D
I0624 13:54:13.771009 18353 net.cpp:399] conv1_1_D -> conv1_1_D
I0624 13:54:13.773851 18353 net.cpp:141] Setting up conv1_1_D
I0624 13:54:13.773866 18353 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 13:54:13.773870 18353 net.cpp:156] Memory required for data: 178526208
I0624 13:54:13.773880 18353 layer_factory.hpp:77] Creating layer conv1_1_D_conv1_1_D_0_split
I0624 13:54:13.773890 18353 net.cpp:91] Creating Layer conv1_1_D_conv1_1_D_0_split
I0624 13:54:13.773895 18353 net.cpp:425] conv1_1_D_conv1_1_D_0_split <- conv1_1_D
I0624 13:54:13.773902 18353 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_0
I0624 13:54:13.773911 18353 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_1
I0624 13:54:13.773965 18353 net.cpp:141] Setting up conv1_1_D_conv1_1_D_0_split
I0624 13:54:13.773975 18353 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 13:54:13.773980 18353 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 13:54:13.773984 18353 net.cpp:156] Memory required for data: 179329024
I0624 13:54:13.773988 18353 layer_factory.hpp:77] Creating layer loss
I0624 13:54:13.773998 18353 net.cpp:91] Creating Layer loss
I0624 13:54:13.774003 18353 net.cpp:425] loss <- conv1_1_D_conv1_1_D_0_split_0
I0624 13:54:13.774008 18353 net.cpp:425] loss <- label_data_1_split_0
I0624 13:54:13.774014 18353 net.cpp:399] loss -> loss
I0624 13:54:13.774026 18353 layer_factory.hpp:77] Creating layer loss
I0624 13:54:13.774971 18353 net.cpp:141] Setting up loss
I0624 13:54:13.774983 18353 net.cpp:148] Top shape: (1)
I0624 13:54:13.774987 18353 net.cpp:151]     with loss weight 1
I0624 13:54:13.775012 18353 net.cpp:156] Memory required for data: 179329028
I0624 13:54:13.775017 18353 layer_factory.hpp:77] Creating layer accuracy
I0624 13:54:13.775027 18353 net.cpp:91] Creating Layer accuracy
I0624 13:54:13.775032 18353 net.cpp:425] accuracy <- conv1_1_D_conv1_1_D_0_split_1
I0624 13:54:13.775038 18353 net.cpp:425] accuracy <- label_data_1_split_1
I0624 13:54:13.775045 18353 net.cpp:399] accuracy -> accuracy
I0624 13:54:13.775056 18353 net.cpp:141] Setting up accuracy
I0624 13:54:13.775064 18353 net.cpp:148] Top shape: (1)
I0624 13:54:13.775068 18353 net.cpp:156] Memory required for data: 179329032
I0624 13:54:13.775073 18353 net.cpp:219] accuracy does not need backward computation.
I0624 13:54:13.775077 18353 net.cpp:217] loss needs backward computation.
I0624 13:54:13.775082 18353 net.cpp:217] conv1_1_D_conv1_1_D_0_split needs backward computation.
I0624 13:54:13.775086 18353 net.cpp:217] conv1_1_D needs backward computation.
I0624 13:54:13.775091 18353 net.cpp:217] relu1_2_D needs backward computation.
I0624 13:54:13.775094 18353 net.cpp:217] scale1_2_D needs backward computation.
I0624 13:54:13.775099 18353 net.cpp:217] bn1_2_D needs backward computation.
I0624 13:54:13.775102 18353 net.cpp:217] conv1_2_D needs backward computation.
I0624 13:54:13.775106 18353 net.cpp:217] upsample1 needs backward computation.
I0624 13:54:13.775110 18353 net.cpp:217] relu2_1_D needs backward computation.
I0624 13:54:13.775115 18353 net.cpp:217] scale2_1_D needs backward computation.
I0624 13:54:13.775118 18353 net.cpp:217] bn2_1_D needs backward computation.
I0624 13:54:13.775121 18353 net.cpp:217] conv2_1_D needs backward computation.
I0624 13:54:13.775125 18353 net.cpp:217] relu2_2_D needs backward computation.
I0624 13:54:13.775130 18353 net.cpp:217] scale2_2_D needs backward computation.
I0624 13:54:13.775133 18353 net.cpp:217] bn2_2_D needs backward computation.
I0624 13:54:13.775137 18353 net.cpp:217] conv2_2_D needs backward computation.
I0624 13:54:13.775141 18353 net.cpp:217] upsample2 needs backward computation.
I0624 13:54:13.775166 18353 net.cpp:217] relu3_1_D needs backward computation.
I0624 13:54:13.775171 18353 net.cpp:217] scale3_1_D needs backward computation.
I0624 13:54:13.775174 18353 net.cpp:217] bn3_1_D needs backward computation.
I0624 13:54:13.775178 18353 net.cpp:217] conv3_1_D needs backward computation.
I0624 13:54:13.775182 18353 net.cpp:217] relu3_2_D needs backward computation.
I0624 13:54:13.775188 18353 net.cpp:217] scale3_2_D needs backward computation.
I0624 13:54:13.775192 18353 net.cpp:217] bn3_2_D needs backward computation.
I0624 13:54:13.775197 18353 net.cpp:217] conv3_2_D needs backward computation.
I0624 13:54:13.775202 18353 net.cpp:217] upsample3 needs backward computation.
I0624 13:54:13.775207 18353 net.cpp:217] relu4_1_D needs backward computation.
I0624 13:54:13.775210 18353 net.cpp:217] scale4_1_D needs backward computation.
I0624 13:54:13.775214 18353 net.cpp:217] bn4_1_D needs backward computation.
I0624 13:54:13.775218 18353 net.cpp:217] conv4_1_D needs backward computation.
I0624 13:54:13.775223 18353 net.cpp:217] relu4_2_D needs backward computation.
I0624 13:54:13.775226 18353 net.cpp:217] scale4_2_D needs backward computation.
I0624 13:54:13.775230 18353 net.cpp:217] bn4_2_D needs backward computation.
I0624 13:54:13.775234 18353 net.cpp:217] conv4_2_D needs backward computation.
I0624 13:54:13.775238 18353 net.cpp:217] upsample4 needs backward computation.
I0624 13:54:13.775243 18353 net.cpp:217] relu5_1_D needs backward computation.
I0624 13:54:13.775248 18353 net.cpp:217] scale5_1_D needs backward computation.
I0624 13:54:13.775251 18353 net.cpp:217] bn5_1_D needs backward computation.
I0624 13:54:13.775255 18353 net.cpp:217] conv5_1_D needs backward computation.
I0624 13:54:13.775259 18353 net.cpp:217] relu5_2_D needs backward computation.
I0624 13:54:13.775264 18353 net.cpp:217] scale5_2_D needs backward computation.
I0624 13:54:13.775267 18353 net.cpp:217] bn5_2_D needs backward computation.
I0624 13:54:13.775271 18353 net.cpp:217] conv5_2_D needs backward computation.
I0624 13:54:13.775275 18353 net.cpp:217] upsample5 needs backward computation.
I0624 13:54:13.775280 18353 net.cpp:217] pool5 needs backward computation.
I0624 13:54:13.775285 18353 net.cpp:217] relu5_2 needs backward computation.
I0624 13:54:13.775290 18353 net.cpp:217] scale5_2 needs backward computation.
I0624 13:54:13.775293 18353 net.cpp:217] bn5_2 needs backward computation.
I0624 13:54:13.775296 18353 net.cpp:217] conv5_2 needs backward computation.
I0624 13:54:13.775300 18353 net.cpp:217] relu5_1 needs backward computation.
I0624 13:54:13.775305 18353 net.cpp:217] scale5_1 needs backward computation.
I0624 13:54:13.775308 18353 net.cpp:217] bn5_1 needs backward computation.
I0624 13:54:13.775312 18353 net.cpp:217] conv5_1 needs backward computation.
I0624 13:54:13.775316 18353 net.cpp:217] pool4 needs backward computation.
I0624 13:54:13.775323 18353 net.cpp:217] relu4_2 needs backward computation.
I0624 13:54:13.775327 18353 net.cpp:217] scale4_2 needs backward computation.
I0624 13:54:13.775331 18353 net.cpp:217] bn4_2 needs backward computation.
I0624 13:54:13.775336 18353 net.cpp:217] conv4_2 needs backward computation.
I0624 13:54:13.775339 18353 net.cpp:217] relu4_1 needs backward computation.
I0624 13:54:13.775343 18353 net.cpp:217] scale4_1 needs backward computation.
I0624 13:54:13.775347 18353 net.cpp:217] bn4_1 needs backward computation.
I0624 13:54:13.775352 18353 net.cpp:217] conv4_1 needs backward computation.
I0624 13:54:13.775355 18353 net.cpp:217] pool3 needs backward computation.
I0624 13:54:13.775359 18353 net.cpp:217] relu3_2 needs backward computation.
I0624 13:54:13.775363 18353 net.cpp:217] scale3_2 needs backward computation.
I0624 13:54:13.775367 18353 net.cpp:217] bn3_2 needs backward computation.
I0624 13:54:13.775372 18353 net.cpp:217] conv3_2 needs backward computation.
I0624 13:54:13.775375 18353 net.cpp:217] relu3_1 needs backward computation.
I0624 13:54:13.775379 18353 net.cpp:217] scale3_1 needs backward computation.
I0624 13:54:13.775383 18353 net.cpp:217] bn3_1 needs backward computation.
I0624 13:54:13.776978 18353 net.cpp:217] conv3_1 needs backward computation.
I0624 13:54:13.776996 18353 net.cpp:217] pool2 needs backward computation.
I0624 13:54:13.777005 18353 net.cpp:217] relu2_2 needs backward computation.
I0624 13:54:13.777015 18353 net.cpp:217] scale2_2 needs backward computation.
I0624 13:54:13.777024 18353 net.cpp:217] bn2_2 needs backward computation.
I0624 13:54:13.777029 18353 net.cpp:217] conv2_2 needs backward computation.
I0624 13:54:13.777036 18353 net.cpp:217] relu2_1 needs backward computation.
I0624 13:54:13.777042 18353 net.cpp:217] scale2_1 needs backward computation.
I0624 13:54:13.777050 18353 net.cpp:217] bn2_1 needs backward computation.
I0624 13:54:13.777055 18353 net.cpp:217] conv2_1 needs backward computation.
I0624 13:54:13.777060 18353 net.cpp:217] pool1 needs backward computation.
I0624 13:54:13.777068 18353 net.cpp:217] relu1_2 needs backward computation.
I0624 13:54:13.777076 18353 net.cpp:217] scale1_2 needs backward computation.
I0624 13:54:13.777082 18353 net.cpp:217] bn1_2 needs backward computation.
I0624 13:54:13.777087 18353 net.cpp:217] conv1_2 needs backward computation.
I0624 13:54:13.777096 18353 net.cpp:217] relu1_1 needs backward computation.
I0624 13:54:13.777101 18353 net.cpp:217] scale1_1 needs backward computation.
I0624 13:54:13.777107 18353 net.cpp:217] bn1_1 needs backward computation.
I0624 13:54:13.777113 18353 net.cpp:217] conv1_1 needs backward computation.
I0624 13:54:13.777122 18353 net.cpp:219] label_data_1_split does not need backward computation.
I0624 13:54:13.777132 18353 net.cpp:219] data does not need backward computation.
I0624 13:54:13.777138 18353 net.cpp:261] This network produces output accuracy
I0624 13:54:13.777146 18353 net.cpp:261] This network produces output loss
I0624 13:54:13.777241 18353 net.cpp:274] Network initialization done.
I0624 13:54:13.781112 18353 solver.cpp:181] Creating test net (#0) specified by net file: models/segnet/train_val.prototxt
I0624 13:54:13.781314 18353 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0624 13:54:13.782488 18353 net.cpp:49] Initializing net from parameters: 
name: "segnet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "DenseImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 224
    mean_value: 100
  }
  dense_image_data_param {
    source: "data/val_seg.txt"
    batch_size: 1
    shuffle: true
    new_height: 224
    new_width: 310
    is_color: false
    root_folder: "data/raw/train/"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 14
    upsample_w: 14
  }
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2_D"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2_D"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1_D"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1_D"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 28
    upsample_w: 28
  }
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2_D"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2_D"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1_D"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1_D"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
    upsample_h: 56
    upsample_w: 56
  }
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn3_2_D"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2_D"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1_D"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1_D"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
    upsample_h: 112
    upsample_w: 112
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2_D"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2_D"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1_D"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1_D"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
    upsample_h: 224
    upsample_w: 224
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2_D"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2_D"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2
    bias_term: true
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "accuracy"
}
I0624 13:54:13.783102 18353 layer_factory.hpp:77] Creating layer data
I0624 13:54:13.783130 18353 net.cpp:91] Creating Layer data
I0624 13:54:13.783139 18353 net.cpp:399] data -> data
I0624 13:54:13.783165 18353 net.cpp:399] data -> label
I0624 13:54:13.783186 18353 dense_image_data_layer.cpp:38] Opening file data/val_seg.txt
I0624 13:54:13.784307 18353 dense_image_data_layer.cpp:48] Shuffling data
I0624 13:54:13.784400 18353 dense_image_data_layer.cpp:53] A total of 299 examples.
I0624 13:54:13.795824 18353 dense_image_data_layer.cpp:92] output data size: 1,1,224,224
I0624 13:54:13.796893 18353 net.cpp:141] Setting up data
I0624 13:54:13.796916 18353 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 13:54:13.796929 18353 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 13:54:13.796936 18353 net.cpp:156] Memory required for data: 401408
I0624 13:54:13.796946 18353 layer_factory.hpp:77] Creating layer label_data_1_split
I0624 13:54:13.796963 18353 net.cpp:91] Creating Layer label_data_1_split
I0624 13:54:13.796975 18353 net.cpp:425] label_data_1_split <- label
I0624 13:54:13.796986 18353 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0624 13:54:13.797003 18353 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0624 13:54:13.797103 18353 net.cpp:141] Setting up label_data_1_split
I0624 13:54:13.797116 18353 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 13:54:13.797130 18353 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 13:54:13.797137 18353 net.cpp:156] Memory required for data: 802816
I0624 13:54:13.797143 18353 layer_factory.hpp:77] Creating layer conv1_1
I0624 13:54:13.797163 18353 net.cpp:91] Creating Layer conv1_1
I0624 13:54:13.797171 18353 net.cpp:425] conv1_1 <- data
I0624 13:54:13.797180 18353 net.cpp:399] conv1_1 -> conv1_1
I0624 13:54:13.799989 18353 net.cpp:141] Setting up conv1_1
I0624 13:54:13.800020 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.800034 18353 net.cpp:156] Memory required for data: 7225344
I0624 13:54:13.800057 18353 layer_factory.hpp:77] Creating layer bn1_1
I0624 13:54:13.800073 18353 net.cpp:91] Creating Layer bn1_1
I0624 13:54:13.800086 18353 net.cpp:425] bn1_1 <- conv1_1
I0624 13:54:13.800098 18353 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0624 13:54:13.802209 18353 net.cpp:141] Setting up bn1_1
I0624 13:54:13.802243 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.802259 18353 net.cpp:156] Memory required for data: 13647872
I0624 13:54:13.802294 18353 layer_factory.hpp:77] Creating layer scale1_1
I0624 13:54:13.802322 18353 net.cpp:91] Creating Layer scale1_1
I0624 13:54:13.802337 18353 net.cpp:425] scale1_1 <- conv1_1
I0624 13:54:13.802356 18353 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0624 13:54:13.802507 18353 layer_factory.hpp:77] Creating layer scale1_1
I0624 13:54:13.803035 18353 net.cpp:141] Setting up scale1_1
I0624 13:54:13.803059 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.803066 18353 net.cpp:156] Memory required for data: 20070400
I0624 13:54:13.803105 18353 layer_factory.hpp:77] Creating layer relu1_1
I0624 13:54:13.803119 18353 net.cpp:91] Creating Layer relu1_1
I0624 13:54:13.803127 18353 net.cpp:425] relu1_1 <- conv1_1
I0624 13:54:13.803135 18353 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0624 13:54:13.803726 18353 net.cpp:141] Setting up relu1_1
I0624 13:54:13.803747 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.803755 18353 net.cpp:156] Memory required for data: 26492928
I0624 13:54:13.803761 18353 layer_factory.hpp:77] Creating layer conv1_2
I0624 13:54:13.803778 18353 net.cpp:91] Creating Layer conv1_2
I0624 13:54:13.803786 18353 net.cpp:425] conv1_2 <- conv1_1
I0624 13:54:13.803795 18353 net.cpp:399] conv1_2 -> conv1_2
I0624 13:54:13.805663 18353 net.cpp:141] Setting up conv1_2
I0624 13:54:13.805686 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.805693 18353 net.cpp:156] Memory required for data: 32915456
I0624 13:54:13.805703 18353 layer_factory.hpp:77] Creating layer bn1_2
I0624 13:54:13.805716 18353 net.cpp:91] Creating Layer bn1_2
I0624 13:54:13.805723 18353 net.cpp:425] bn1_2 <- conv1_2
I0624 13:54:13.805732 18353 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0624 13:54:13.806192 18353 net.cpp:141] Setting up bn1_2
I0624 13:54:13.806205 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.806210 18353 net.cpp:156] Memory required for data: 39337984
I0624 13:54:13.806227 18353 layer_factory.hpp:77] Creating layer scale1_2
I0624 13:54:13.806241 18353 net.cpp:91] Creating Layer scale1_2
I0624 13:54:13.806247 18353 net.cpp:425] scale1_2 <- conv1_2
I0624 13:54:13.806255 18353 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0624 13:54:13.806336 18353 layer_factory.hpp:77] Creating layer scale1_2
I0624 13:54:13.807588 18353 net.cpp:141] Setting up scale1_2
I0624 13:54:13.807610 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.807615 18353 net.cpp:156] Memory required for data: 45760512
I0624 13:54:13.807626 18353 layer_factory.hpp:77] Creating layer relu1_2
I0624 13:54:13.807638 18353 net.cpp:91] Creating Layer relu1_2
I0624 13:54:13.807646 18353 net.cpp:425] relu1_2 <- conv1_2
I0624 13:54:13.807653 18353 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0624 13:54:13.808190 18353 net.cpp:141] Setting up relu1_2
I0624 13:54:13.808210 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.808215 18353 net.cpp:156] Memory required for data: 52183040
I0624 13:54:13.808221 18353 layer_factory.hpp:77] Creating layer pool1
I0624 13:54:13.808228 18353 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 13:54:13.808236 18353 net.cpp:91] Creating Layer pool1
I0624 13:54:13.808243 18353 net.cpp:425] pool1 <- conv1_2
I0624 13:54:13.808254 18353 net.cpp:399] pool1 -> pool1
I0624 13:54:13.808264 18353 net.cpp:399] pool1 -> pool1_mask
I0624 13:54:13.808352 18353 net.cpp:141] Setting up pool1
I0624 13:54:13.808363 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.808369 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.808374 18353 net.cpp:156] Memory required for data: 55394304
I0624 13:54:13.808379 18353 layer_factory.hpp:77] Creating layer conv2_1
I0624 13:54:13.808393 18353 net.cpp:91] Creating Layer conv2_1
I0624 13:54:13.808398 18353 net.cpp:425] conv2_1 <- pool1
I0624 13:54:13.808408 18353 net.cpp:399] conv2_1 -> conv2_1
I0624 13:54:13.810555 18353 net.cpp:141] Setting up conv2_1
I0624 13:54:13.810577 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.810583 18353 net.cpp:156] Memory required for data: 58605568
I0624 13:54:13.810592 18353 layer_factory.hpp:77] Creating layer bn2_1
I0624 13:54:13.810602 18353 net.cpp:91] Creating Layer bn2_1
I0624 13:54:13.810608 18353 net.cpp:425] bn2_1 <- conv2_1
I0624 13:54:13.810617 18353 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0624 13:54:13.811063 18353 net.cpp:141] Setting up bn2_1
I0624 13:54:13.811075 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.811080 18353 net.cpp:156] Memory required for data: 61816832
I0624 13:54:13.811112 18353 layer_factory.hpp:77] Creating layer scale2_1
I0624 13:54:13.811125 18353 net.cpp:91] Creating Layer scale2_1
I0624 13:54:13.811131 18353 net.cpp:425] scale2_1 <- conv2_1
I0624 13:54:13.811138 18353 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0624 13:54:13.811235 18353 layer_factory.hpp:77] Creating layer scale2_1
I0624 13:54:13.811573 18353 net.cpp:141] Setting up scale2_1
I0624 13:54:13.811589 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.811594 18353 net.cpp:156] Memory required for data: 65028096
I0624 13:54:13.811610 18353 layer_factory.hpp:77] Creating layer relu2_1
I0624 13:54:13.811619 18353 net.cpp:91] Creating Layer relu2_1
I0624 13:54:13.811625 18353 net.cpp:425] relu2_1 <- conv2_1
I0624 13:54:13.811633 18353 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0624 13:54:13.811961 18353 net.cpp:141] Setting up relu2_1
I0624 13:54:13.811976 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.811981 18353 net.cpp:156] Memory required for data: 68239360
I0624 13:54:13.811986 18353 layer_factory.hpp:77] Creating layer conv2_2
I0624 13:54:13.812000 18353 net.cpp:91] Creating Layer conv2_2
I0624 13:54:13.812005 18353 net.cpp:425] conv2_2 <- conv2_1
I0624 13:54:13.812013 18353 net.cpp:399] conv2_2 -> conv2_2
I0624 13:54:13.814687 18353 net.cpp:141] Setting up conv2_2
I0624 13:54:13.814709 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.814715 18353 net.cpp:156] Memory required for data: 71450624
I0624 13:54:13.814724 18353 layer_factory.hpp:77] Creating layer bn2_2
I0624 13:54:13.814738 18353 net.cpp:91] Creating Layer bn2_2
I0624 13:54:13.814743 18353 net.cpp:425] bn2_2 <- conv2_2
I0624 13:54:13.814751 18353 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0624 13:54:13.815163 18353 net.cpp:141] Setting up bn2_2
I0624 13:54:13.815176 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.815181 18353 net.cpp:156] Memory required for data: 74661888
I0624 13:54:13.815192 18353 layer_factory.hpp:77] Creating layer scale2_2
I0624 13:54:13.815203 18353 net.cpp:91] Creating Layer scale2_2
I0624 13:54:13.815207 18353 net.cpp:425] scale2_2 <- conv2_2
I0624 13:54:13.815215 18353 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0624 13:54:13.815290 18353 layer_factory.hpp:77] Creating layer scale2_2
I0624 13:54:13.815554 18353 net.cpp:141] Setting up scale2_2
I0624 13:54:13.815567 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.815572 18353 net.cpp:156] Memory required for data: 77873152
I0624 13:54:13.815579 18353 layer_factory.hpp:77] Creating layer relu2_2
I0624 13:54:13.815587 18353 net.cpp:91] Creating Layer relu2_2
I0624 13:54:13.815593 18353 net.cpp:425] relu2_2 <- conv2_2
I0624 13:54:13.815599 18353 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0624 13:54:13.816112 18353 net.cpp:141] Setting up relu2_2
I0624 13:54:13.816131 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.816136 18353 net.cpp:156] Memory required for data: 81084416
I0624 13:54:13.816141 18353 layer_factory.hpp:77] Creating layer pool2
I0624 13:54:13.816148 18353 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 13:54:13.816155 18353 net.cpp:91] Creating Layer pool2
I0624 13:54:13.816160 18353 net.cpp:425] pool2 <- conv2_2
I0624 13:54:13.816169 18353 net.cpp:399] pool2 -> pool2
I0624 13:54:13.816179 18353 net.cpp:399] pool2 -> pool2_mask
I0624 13:54:13.816258 18353 net.cpp:141] Setting up pool2
I0624 13:54:13.816269 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.816277 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.816280 18353 net.cpp:156] Memory required for data: 82690048
I0624 13:54:13.816285 18353 layer_factory.hpp:77] Creating layer conv3_1
I0624 13:54:13.816298 18353 net.cpp:91] Creating Layer conv3_1
I0624 13:54:13.816303 18353 net.cpp:425] conv3_1 <- pool2
I0624 13:54:13.816310 18353 net.cpp:399] conv3_1 -> conv3_1
I0624 13:54:13.818828 18353 net.cpp:141] Setting up conv3_1
I0624 13:54:13.818848 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.818871 18353 net.cpp:156] Memory required for data: 84295680
I0624 13:54:13.818881 18353 layer_factory.hpp:77] Creating layer bn3_1
I0624 13:54:13.818892 18353 net.cpp:91] Creating Layer bn3_1
I0624 13:54:13.818897 18353 net.cpp:425] bn3_1 <- conv3_1
I0624 13:54:13.818904 18353 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0624 13:54:13.819308 18353 net.cpp:141] Setting up bn3_1
I0624 13:54:13.819320 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.819325 18353 net.cpp:156] Memory required for data: 85901312
I0624 13:54:13.819336 18353 layer_factory.hpp:77] Creating layer scale3_1
I0624 13:54:13.819347 18353 net.cpp:91] Creating Layer scale3_1
I0624 13:54:13.819352 18353 net.cpp:425] scale3_1 <- conv3_1
I0624 13:54:13.819360 18353 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0624 13:54:13.819443 18353 layer_factory.hpp:77] Creating layer scale3_1
I0624 13:54:13.819669 18353 net.cpp:141] Setting up scale3_1
I0624 13:54:13.819681 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.819685 18353 net.cpp:156] Memory required for data: 87506944
I0624 13:54:13.819694 18353 layer_factory.hpp:77] Creating layer relu3_1
I0624 13:54:13.819702 18353 net.cpp:91] Creating Layer relu3_1
I0624 13:54:13.819707 18353 net.cpp:425] relu3_1 <- conv3_1
I0624 13:54:13.819715 18353 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0624 13:54:13.820235 18353 net.cpp:141] Setting up relu3_1
I0624 13:54:13.820255 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.820261 18353 net.cpp:156] Memory required for data: 89112576
I0624 13:54:13.820266 18353 layer_factory.hpp:77] Creating layer conv3_2
I0624 13:54:13.820278 18353 net.cpp:91] Creating Layer conv3_2
I0624 13:54:13.820284 18353 net.cpp:425] conv3_2 <- conv3_1
I0624 13:54:13.820293 18353 net.cpp:399] conv3_2 -> conv3_2
I0624 13:54:13.824807 18353 net.cpp:141] Setting up conv3_2
I0624 13:54:13.824829 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.824834 18353 net.cpp:156] Memory required for data: 90718208
I0624 13:54:13.824843 18353 layer_factory.hpp:77] Creating layer bn3_2
I0624 13:54:13.824853 18353 net.cpp:91] Creating Layer bn3_2
I0624 13:54:13.824858 18353 net.cpp:425] bn3_2 <- conv3_2
I0624 13:54:13.824867 18353 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0624 13:54:13.825243 18353 net.cpp:141] Setting up bn3_2
I0624 13:54:13.825254 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.825259 18353 net.cpp:156] Memory required for data: 92323840
I0624 13:54:13.825278 18353 layer_factory.hpp:77] Creating layer scale3_2
I0624 13:54:13.825287 18353 net.cpp:91] Creating Layer scale3_2
I0624 13:54:13.825292 18353 net.cpp:425] scale3_2 <- conv3_2
I0624 13:54:13.825299 18353 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0624 13:54:13.825390 18353 layer_factory.hpp:77] Creating layer scale3_2
I0624 13:54:13.825623 18353 net.cpp:141] Setting up scale3_2
I0624 13:54:13.825634 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.825639 18353 net.cpp:156] Memory required for data: 93929472
I0624 13:54:13.825647 18353 layer_factory.hpp:77] Creating layer relu3_2
I0624 13:54:13.825655 18353 net.cpp:91] Creating Layer relu3_2
I0624 13:54:13.825660 18353 net.cpp:425] relu3_2 <- conv3_2
I0624 13:54:13.825667 18353 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0624 13:54:13.825971 18353 net.cpp:141] Setting up relu3_2
I0624 13:54:13.825986 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.825990 18353 net.cpp:156] Memory required for data: 95535104
I0624 13:54:13.825995 18353 layer_factory.hpp:77] Creating layer pool3
I0624 13:54:13.826000 18353 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 13:54:13.826009 18353 net.cpp:91] Creating Layer pool3
I0624 13:54:13.826014 18353 net.cpp:425] pool3 <- conv3_2
I0624 13:54:13.826020 18353 net.cpp:399] pool3 -> pool3
I0624 13:54:13.826030 18353 net.cpp:399] pool3 -> pool3_mask
I0624 13:54:13.826105 18353 net.cpp:141] Setting up pool3
I0624 13:54:13.826115 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.826139 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.826144 18353 net.cpp:156] Memory required for data: 96337920
I0624 13:54:13.826148 18353 layer_factory.hpp:77] Creating layer conv4_1
I0624 13:54:13.826160 18353 net.cpp:91] Creating Layer conv4_1
I0624 13:54:13.826165 18353 net.cpp:425] conv4_1 <- pool3
I0624 13:54:13.826174 18353 net.cpp:399] conv4_1 -> conv4_1
I0624 13:54:13.833130 18353 net.cpp:141] Setting up conv4_1
I0624 13:54:13.833155 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.833160 18353 net.cpp:156] Memory required for data: 97140736
I0624 13:54:13.833170 18353 layer_factory.hpp:77] Creating layer bn4_1
I0624 13:54:13.833184 18353 net.cpp:91] Creating Layer bn4_1
I0624 13:54:13.833189 18353 net.cpp:425] bn4_1 <- conv4_1
I0624 13:54:13.833197 18353 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0624 13:54:13.833585 18353 net.cpp:141] Setting up bn4_1
I0624 13:54:13.833596 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.833600 18353 net.cpp:156] Memory required for data: 97943552
I0624 13:54:13.833611 18353 layer_factory.hpp:77] Creating layer scale4_1
I0624 13:54:13.833622 18353 net.cpp:91] Creating Layer scale4_1
I0624 13:54:13.833627 18353 net.cpp:425] scale4_1 <- conv4_1
I0624 13:54:13.833634 18353 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0624 13:54:13.833717 18353 layer_factory.hpp:77] Creating layer scale4_1
I0624 13:54:13.833947 18353 net.cpp:141] Setting up scale4_1
I0624 13:54:13.833961 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.833964 18353 net.cpp:156] Memory required for data: 98746368
I0624 13:54:13.833972 18353 layer_factory.hpp:77] Creating layer relu4_1
I0624 13:54:13.833986 18353 net.cpp:91] Creating Layer relu4_1
I0624 13:54:13.833992 18353 net.cpp:425] relu4_1 <- conv4_1
I0624 13:54:13.833998 18353 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0624 13:54:13.834502 18353 net.cpp:141] Setting up relu4_1
I0624 13:54:13.834522 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.834527 18353 net.cpp:156] Memory required for data: 99549184
I0624 13:54:13.834532 18353 layer_factory.hpp:77] Creating layer conv4_2
I0624 13:54:13.834547 18353 net.cpp:91] Creating Layer conv4_2
I0624 13:54:13.834553 18353 net.cpp:425] conv4_2 <- conv4_1
I0624 13:54:13.834563 18353 net.cpp:399] conv4_2 -> conv4_2
I0624 13:54:13.844169 18353 net.cpp:141] Setting up conv4_2
I0624 13:54:13.844193 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.844198 18353 net.cpp:156] Memory required for data: 100352000
I0624 13:54:13.844207 18353 layer_factory.hpp:77] Creating layer bn4_2
I0624 13:54:13.844219 18353 net.cpp:91] Creating Layer bn4_2
I0624 13:54:13.844225 18353 net.cpp:425] bn4_2 <- conv4_2
I0624 13:54:13.844233 18353 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0624 13:54:13.844595 18353 net.cpp:141] Setting up bn4_2
I0624 13:54:13.844606 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.844610 18353 net.cpp:156] Memory required for data: 101154816
I0624 13:54:13.844620 18353 layer_factory.hpp:77] Creating layer scale4_2
I0624 13:54:13.844630 18353 net.cpp:91] Creating Layer scale4_2
I0624 13:54:13.844635 18353 net.cpp:425] scale4_2 <- conv4_2
I0624 13:54:13.844642 18353 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0624 13:54:13.844708 18353 layer_factory.hpp:77] Creating layer scale4_2
I0624 13:54:13.844924 18353 net.cpp:141] Setting up scale4_2
I0624 13:54:13.844935 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.844939 18353 net.cpp:156] Memory required for data: 101957632
I0624 13:54:13.844947 18353 layer_factory.hpp:77] Creating layer relu4_2
I0624 13:54:13.844955 18353 net.cpp:91] Creating Layer relu4_2
I0624 13:54:13.844959 18353 net.cpp:425] relu4_2 <- conv4_2
I0624 13:54:13.844966 18353 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0624 13:54:13.845439 18353 net.cpp:141] Setting up relu4_2
I0624 13:54:13.845459 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.845464 18353 net.cpp:156] Memory required for data: 102760448
I0624 13:54:13.845468 18353 layer_factory.hpp:77] Creating layer pool4
I0624 13:54:13.845492 18353 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 13:54:13.845500 18353 net.cpp:91] Creating Layer pool4
I0624 13:54:13.845506 18353 net.cpp:425] pool4 <- conv4_2
I0624 13:54:13.845513 18353 net.cpp:399] pool4 -> pool4
I0624 13:54:13.845526 18353 net.cpp:399] pool4 -> pool4_mask
I0624 13:54:13.845610 18353 net.cpp:141] Setting up pool4
I0624 13:54:13.845621 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.845626 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.845630 18353 net.cpp:156] Memory required for data: 103161856
I0624 13:54:13.845634 18353 layer_factory.hpp:77] Creating layer conv5_1
I0624 13:54:13.845652 18353 net.cpp:91] Creating Layer conv5_1
I0624 13:54:13.845657 18353 net.cpp:425] conv5_1 <- pool4
I0624 13:54:13.845669 18353 net.cpp:399] conv5_1 -> conv5_1
I0624 13:54:13.854955 18353 net.cpp:141] Setting up conv5_1
I0624 13:54:13.854975 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.854981 18353 net.cpp:156] Memory required for data: 103362560
I0624 13:54:13.854990 18353 layer_factory.hpp:77] Creating layer bn5_1
I0624 13:54:13.855002 18353 net.cpp:91] Creating Layer bn5_1
I0624 13:54:13.855008 18353 net.cpp:425] bn5_1 <- conv5_1
I0624 13:54:13.855015 18353 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0624 13:54:13.855370 18353 net.cpp:141] Setting up bn5_1
I0624 13:54:13.855381 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.855384 18353 net.cpp:156] Memory required for data: 103563264
I0624 13:54:13.855394 18353 layer_factory.hpp:77] Creating layer scale5_1
I0624 13:54:13.855406 18353 net.cpp:91] Creating Layer scale5_1
I0624 13:54:13.855412 18353 net.cpp:425] scale5_1 <- conv5_1
I0624 13:54:13.855417 18353 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0624 13:54:13.855484 18353 layer_factory.hpp:77] Creating layer scale5_1
I0624 13:54:13.855679 18353 net.cpp:141] Setting up scale5_1
I0624 13:54:13.855689 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.855692 18353 net.cpp:156] Memory required for data: 103763968
I0624 13:54:13.855700 18353 layer_factory.hpp:77] Creating layer relu5_1
I0624 13:54:13.855708 18353 net.cpp:91] Creating Layer relu5_1
I0624 13:54:13.855712 18353 net.cpp:425] relu5_1 <- conv5_1
I0624 13:54:13.855718 18353 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0624 13:54:13.856005 18353 net.cpp:141] Setting up relu5_1
I0624 13:54:13.856019 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.856022 18353 net.cpp:156] Memory required for data: 103964672
I0624 13:54:13.856026 18353 layer_factory.hpp:77] Creating layer conv5_2
I0624 13:54:13.856040 18353 net.cpp:91] Creating Layer conv5_2
I0624 13:54:13.856043 18353 net.cpp:425] conv5_2 <- conv5_1
I0624 13:54:13.856052 18353 net.cpp:399] conv5_2 -> conv5_2
I0624 13:54:13.865741 18353 net.cpp:141] Setting up conv5_2
I0624 13:54:13.865767 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.865773 18353 net.cpp:156] Memory required for data: 104165376
I0624 13:54:13.865782 18353 layer_factory.hpp:77] Creating layer bn5_2
I0624 13:54:13.865792 18353 net.cpp:91] Creating Layer bn5_2
I0624 13:54:13.865798 18353 net.cpp:425] bn5_2 <- conv5_2
I0624 13:54:13.865808 18353 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0624 13:54:13.866147 18353 net.cpp:141] Setting up bn5_2
I0624 13:54:13.866158 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.866161 18353 net.cpp:156] Memory required for data: 104366080
I0624 13:54:13.866170 18353 layer_factory.hpp:77] Creating layer scale5_2
I0624 13:54:13.866179 18353 net.cpp:91] Creating Layer scale5_2
I0624 13:54:13.866184 18353 net.cpp:425] scale5_2 <- conv5_2
I0624 13:54:13.866190 18353 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0624 13:54:13.866255 18353 layer_factory.hpp:77] Creating layer scale5_2
I0624 13:54:13.866466 18353 net.cpp:141] Setting up scale5_2
I0624 13:54:13.866475 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.866479 18353 net.cpp:156] Memory required for data: 104566784
I0624 13:54:13.866504 18353 layer_factory.hpp:77] Creating layer relu5_2
I0624 13:54:13.866514 18353 net.cpp:91] Creating Layer relu5_2
I0624 13:54:13.866519 18353 net.cpp:425] relu5_2 <- conv5_2
I0624 13:54:13.866524 18353 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0624 13:54:13.866982 18353 net.cpp:141] Setting up relu5_2
I0624 13:54:13.866998 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.867002 18353 net.cpp:156] Memory required for data: 104767488
I0624 13:54:13.867007 18353 layer_factory.hpp:77] Creating layer pool5
I0624 13:54:13.867012 18353 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 13:54:13.867018 18353 net.cpp:91] Creating Layer pool5
I0624 13:54:13.867025 18353 net.cpp:425] pool5 <- conv5_2
I0624 13:54:13.867033 18353 net.cpp:399] pool5 -> pool5
I0624 13:54:13.867040 18353 net.cpp:399] pool5 -> pool5_mask
I0624 13:54:13.867125 18353 net.cpp:141] Setting up pool5
I0624 13:54:13.867135 18353 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 13:54:13.867139 18353 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 13:54:13.867143 18353 net.cpp:156] Memory required for data: 104867840
I0624 13:54:13.867147 18353 layer_factory.hpp:77] Creating layer upsample5
I0624 13:54:13.867163 18353 net.cpp:91] Creating Layer upsample5
I0624 13:54:13.867167 18353 net.cpp:425] upsample5 <- pool5
I0624 13:54:13.867173 18353 net.cpp:425] upsample5 <- pool5_mask
I0624 13:54:13.867179 18353 net.cpp:399] upsample5 -> pool5_D
I0624 13:54:13.867223 18353 net.cpp:141] Setting up upsample5
I0624 13:54:13.867233 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.867235 18353 net.cpp:156] Memory required for data: 105068544
I0624 13:54:13.867239 18353 layer_factory.hpp:77] Creating layer conv5_2_D
I0624 13:54:13.867252 18353 net.cpp:91] Creating Layer conv5_2_D
I0624 13:54:13.867256 18353 net.cpp:425] conv5_2_D <- pool5_D
I0624 13:54:13.867264 18353 net.cpp:399] conv5_2_D -> conv5_2_D
I0624 13:54:13.875785 18353 net.cpp:141] Setting up conv5_2_D
I0624 13:54:13.875803 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.875808 18353 net.cpp:156] Memory required for data: 105269248
I0624 13:54:13.875815 18353 layer_factory.hpp:77] Creating layer bn5_2_D
I0624 13:54:13.875825 18353 net.cpp:91] Creating Layer bn5_2_D
I0624 13:54:13.875830 18353 net.cpp:425] bn5_2_D <- conv5_2_D
I0624 13:54:13.875836 18353 net.cpp:386] bn5_2_D -> conv5_2_D (in-place)
I0624 13:54:13.876157 18353 net.cpp:141] Setting up bn5_2_D
I0624 13:54:13.876168 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.876170 18353 net.cpp:156] Memory required for data: 105469952
I0624 13:54:13.876179 18353 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 13:54:13.876189 18353 net.cpp:91] Creating Layer scale5_2_D
I0624 13:54:13.876194 18353 net.cpp:425] scale5_2_D <- conv5_2_D
I0624 13:54:13.876199 18353 net.cpp:386] scale5_2_D -> conv5_2_D (in-place)
I0624 13:54:13.876261 18353 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 13:54:13.876440 18353 net.cpp:141] Setting up scale5_2_D
I0624 13:54:13.876448 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.876452 18353 net.cpp:156] Memory required for data: 105670656
I0624 13:54:13.876471 18353 layer_factory.hpp:77] Creating layer relu5_2_D
I0624 13:54:13.876479 18353 net.cpp:91] Creating Layer relu5_2_D
I0624 13:54:13.876484 18353 net.cpp:425] relu5_2_D <- conv5_2_D
I0624 13:54:13.876489 18353 net.cpp:386] relu5_2_D -> conv5_2_D (in-place)
I0624 13:54:13.876909 18353 net.cpp:141] Setting up relu5_2_D
I0624 13:54:13.876924 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.876929 18353 net.cpp:156] Memory required for data: 105871360
I0624 13:54:13.876932 18353 layer_factory.hpp:77] Creating layer conv5_1_D
I0624 13:54:13.876945 18353 net.cpp:91] Creating Layer conv5_1_D
I0624 13:54:13.876955 18353 net.cpp:425] conv5_1_D <- conv5_2_D
I0624 13:54:13.876961 18353 net.cpp:399] conv5_1_D -> conv5_1_D
I0624 13:54:13.885561 18353 net.cpp:141] Setting up conv5_1_D
I0624 13:54:13.885596 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.885599 18353 net.cpp:156] Memory required for data: 106072064
I0624 13:54:13.885607 18353 layer_factory.hpp:77] Creating layer bn5_1_D
I0624 13:54:13.885615 18353 net.cpp:91] Creating Layer bn5_1_D
I0624 13:54:13.885619 18353 net.cpp:425] bn5_1_D <- conv5_1_D
I0624 13:54:13.885627 18353 net.cpp:386] bn5_1_D -> conv5_1_D (in-place)
I0624 13:54:13.885937 18353 net.cpp:141] Setting up bn5_1_D
I0624 13:54:13.885947 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.885951 18353 net.cpp:156] Memory required for data: 106272768
I0624 13:54:13.885959 18353 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 13:54:13.885967 18353 net.cpp:91] Creating Layer scale5_1_D
I0624 13:54:13.885970 18353 net.cpp:425] scale5_1_D <- conv5_1_D
I0624 13:54:13.885977 18353 net.cpp:386] scale5_1_D -> conv5_1_D (in-place)
I0624 13:54:13.886036 18353 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 13:54:13.886211 18353 net.cpp:141] Setting up scale5_1_D
I0624 13:54:13.886221 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.886224 18353 net.cpp:156] Memory required for data: 106473472
I0624 13:54:13.886231 18353 layer_factory.hpp:77] Creating layer relu5_1_D
I0624 13:54:13.886240 18353 net.cpp:91] Creating Layer relu5_1_D
I0624 13:54:13.886242 18353 net.cpp:425] relu5_1_D <- conv5_1_D
I0624 13:54:13.886248 18353 net.cpp:386] relu5_1_D -> conv5_1_D (in-place)
I0624 13:54:13.886488 18353 net.cpp:141] Setting up relu5_1_D
I0624 13:54:13.886500 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.886503 18353 net.cpp:156] Memory required for data: 106674176
I0624 13:54:13.886507 18353 layer_factory.hpp:77] Creating layer upsample4
I0624 13:54:13.886517 18353 net.cpp:91] Creating Layer upsample4
I0624 13:54:13.886520 18353 net.cpp:425] upsample4 <- conv5_1_D
I0624 13:54:13.886525 18353 net.cpp:425] upsample4 <- pool4_mask
I0624 13:54:13.886533 18353 net.cpp:399] upsample4 -> pool4_D
I0624 13:54:13.886574 18353 net.cpp:141] Setting up upsample4
I0624 13:54:13.886581 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.886584 18353 net.cpp:156] Memory required for data: 107476992
I0624 13:54:13.886587 18353 layer_factory.hpp:77] Creating layer conv4_2_D
I0624 13:54:13.886600 18353 net.cpp:91] Creating Layer conv4_2_D
I0624 13:54:13.886602 18353 net.cpp:425] conv4_2_D <- pool4_D
I0624 13:54:13.886612 18353 net.cpp:399] conv4_2_D -> conv4_2_D
I0624 13:54:13.895184 18353 net.cpp:141] Setting up conv4_2_D
I0624 13:54:13.895205 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.895208 18353 net.cpp:156] Memory required for data: 108279808
I0624 13:54:13.895215 18353 layer_factory.hpp:77] Creating layer bn4_2_D
I0624 13:54:13.895226 18353 net.cpp:91] Creating Layer bn4_2_D
I0624 13:54:13.895231 18353 net.cpp:425] bn4_2_D <- conv4_2_D
I0624 13:54:13.895236 18353 net.cpp:386] bn4_2_D -> conv4_2_D (in-place)
I0624 13:54:13.895558 18353 net.cpp:141] Setting up bn4_2_D
I0624 13:54:13.895567 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.895571 18353 net.cpp:156] Memory required for data: 109082624
I0624 13:54:13.895579 18353 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 13:54:13.895587 18353 net.cpp:91] Creating Layer scale4_2_D
I0624 13:54:13.895591 18353 net.cpp:425] scale4_2_D <- conv4_2_D
I0624 13:54:13.895598 18353 net.cpp:386] scale4_2_D -> conv4_2_D (in-place)
I0624 13:54:13.895655 18353 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 13:54:13.895838 18353 net.cpp:141] Setting up scale4_2_D
I0624 13:54:13.895846 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.895849 18353 net.cpp:156] Memory required for data: 109885440
I0624 13:54:13.895855 18353 layer_factory.hpp:77] Creating layer relu4_2_D
I0624 13:54:13.895862 18353 net.cpp:91] Creating Layer relu4_2_D
I0624 13:54:13.895865 18353 net.cpp:425] relu4_2_D <- conv4_2_D
I0624 13:54:13.895870 18353 net.cpp:386] relu4_2_D -> conv4_2_D (in-place)
I0624 13:54:13.896275 18353 net.cpp:141] Setting up relu4_2_D
I0624 13:54:13.896306 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.896311 18353 net.cpp:156] Memory required for data: 110688256
I0624 13:54:13.896316 18353 layer_factory.hpp:77] Creating layer conv4_1_D
I0624 13:54:13.896325 18353 net.cpp:91] Creating Layer conv4_1_D
I0624 13:54:13.896329 18353 net.cpp:425] conv4_1_D <- conv4_2_D
I0624 13:54:13.896337 18353 net.cpp:399] conv4_1_D -> conv4_1_D
I0624 13:54:13.900950 18353 net.cpp:141] Setting up conv4_1_D
I0624 13:54:13.900966 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.900970 18353 net.cpp:156] Memory required for data: 111089664
I0624 13:54:13.900977 18353 layer_factory.hpp:77] Creating layer bn4_1_D
I0624 13:54:13.900986 18353 net.cpp:91] Creating Layer bn4_1_D
I0624 13:54:13.900991 18353 net.cpp:425] bn4_1_D <- conv4_1_D
I0624 13:54:13.900998 18353 net.cpp:386] bn4_1_D -> conv4_1_D (in-place)
I0624 13:54:13.901309 18353 net.cpp:141] Setting up bn4_1_D
I0624 13:54:13.901317 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.901320 18353 net.cpp:156] Memory required for data: 111491072
I0624 13:54:13.901329 18353 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 13:54:13.901336 18353 net.cpp:91] Creating Layer scale4_1_D
I0624 13:54:13.901340 18353 net.cpp:425] scale4_1_D <- conv4_1_D
I0624 13:54:13.901346 18353 net.cpp:386] scale4_1_D -> conv4_1_D (in-place)
I0624 13:54:13.901404 18353 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 13:54:13.901582 18353 net.cpp:141] Setting up scale4_1_D
I0624 13:54:13.901590 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.901593 18353 net.cpp:156] Memory required for data: 111892480
I0624 13:54:13.901599 18353 layer_factory.hpp:77] Creating layer relu4_1_D
I0624 13:54:13.901614 18353 net.cpp:91] Creating Layer relu4_1_D
I0624 13:54:13.901618 18353 net.cpp:425] relu4_1_D <- conv4_1_D
I0624 13:54:13.901623 18353 net.cpp:386] relu4_1_D -> conv4_1_D (in-place)
I0624 13:54:13.902020 18353 net.cpp:141] Setting up relu4_1_D
I0624 13:54:13.902035 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.902040 18353 net.cpp:156] Memory required for data: 112293888
I0624 13:54:13.902045 18353 layer_factory.hpp:77] Creating layer upsample3
I0624 13:54:13.902051 18353 net.cpp:91] Creating Layer upsample3
I0624 13:54:13.902055 18353 net.cpp:425] upsample3 <- conv4_1_D
I0624 13:54:13.902061 18353 net.cpp:425] upsample3 <- pool3_mask
I0624 13:54:13.902066 18353 net.cpp:399] upsample3 -> pool3_D
I0624 13:54:13.902112 18353 net.cpp:141] Setting up upsample3
I0624 13:54:13.902118 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.902122 18353 net.cpp:156] Memory required for data: 113899520
I0624 13:54:13.902125 18353 layer_factory.hpp:77] Creating layer conv3_2_D
I0624 13:54:13.902137 18353 net.cpp:91] Creating Layer conv3_2_D
I0624 13:54:13.902142 18353 net.cpp:425] conv3_2_D <- pool3_D
I0624 13:54:13.902148 18353 net.cpp:399] conv3_2_D -> conv3_2_D
I0624 13:54:13.905632 18353 net.cpp:141] Setting up conv3_2_D
I0624 13:54:13.905649 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.905653 18353 net.cpp:156] Memory required for data: 115505152
I0624 13:54:13.905661 18353 layer_factory.hpp:77] Creating layer bn3_2_D
I0624 13:54:13.905670 18353 net.cpp:91] Creating Layer bn3_2_D
I0624 13:54:13.905675 18353 net.cpp:425] bn3_2_D <- conv3_2_D
I0624 13:54:13.905683 18353 net.cpp:386] bn3_2_D -> conv3_2_D (in-place)
I0624 13:54:13.905995 18353 net.cpp:141] Setting up bn3_2_D
I0624 13:54:13.906007 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.906009 18353 net.cpp:156] Memory required for data: 117110784
I0624 13:54:13.906018 18353 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 13:54:13.906026 18353 net.cpp:91] Creating Layer scale3_2_D
I0624 13:54:13.906030 18353 net.cpp:425] scale3_2_D <- conv3_2_D
I0624 13:54:13.906036 18353 net.cpp:386] scale3_2_D -> conv3_2_D (in-place)
I0624 13:54:13.906096 18353 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 13:54:13.906270 18353 net.cpp:141] Setting up scale3_2_D
I0624 13:54:13.906291 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.906296 18353 net.cpp:156] Memory required for data: 118716416
I0624 13:54:13.906301 18353 layer_factory.hpp:77] Creating layer relu3_2_D
I0624 13:54:13.906308 18353 net.cpp:91] Creating Layer relu3_2_D
I0624 13:54:13.906311 18353 net.cpp:425] relu3_2_D <- conv3_2_D
I0624 13:54:13.906318 18353 net.cpp:386] relu3_2_D -> conv3_2_D (in-place)
I0624 13:54:13.906553 18353 net.cpp:141] Setting up relu3_2_D
I0624 13:54:13.906566 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.906569 18353 net.cpp:156] Memory required for data: 120322048
I0624 13:54:13.906574 18353 layer_factory.hpp:77] Creating layer conv3_1_D
I0624 13:54:13.906584 18353 net.cpp:91] Creating Layer conv3_1_D
I0624 13:54:13.906586 18353 net.cpp:425] conv3_1_D <- conv3_2_D
I0624 13:54:13.906594 18353 net.cpp:399] conv3_1_D -> conv3_1_D
I0624 13:54:13.908701 18353 net.cpp:141] Setting up conv3_1_D
I0624 13:54:13.908718 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.908722 18353 net.cpp:156] Memory required for data: 121124864
I0624 13:54:13.908728 18353 layer_factory.hpp:77] Creating layer bn3_1_D
I0624 13:54:13.908735 18353 net.cpp:91] Creating Layer bn3_1_D
I0624 13:54:13.908740 18353 net.cpp:425] bn3_1_D <- conv3_1_D
I0624 13:54:13.908746 18353 net.cpp:386] bn3_1_D -> conv3_1_D (in-place)
I0624 13:54:13.909061 18353 net.cpp:141] Setting up bn3_1_D
I0624 13:54:13.909070 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.909073 18353 net.cpp:156] Memory required for data: 121927680
I0624 13:54:13.909081 18353 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 13:54:13.909088 18353 net.cpp:91] Creating Layer scale3_1_D
I0624 13:54:13.909091 18353 net.cpp:425] scale3_1_D <- conv3_1_D
I0624 13:54:13.909098 18353 net.cpp:386] scale3_1_D -> conv3_1_D (in-place)
I0624 13:54:13.909157 18353 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 13:54:13.909399 18353 net.cpp:141] Setting up scale3_1_D
I0624 13:54:13.909409 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.909412 18353 net.cpp:156] Memory required for data: 122730496
I0624 13:54:13.909420 18353 layer_factory.hpp:77] Creating layer relu3_1_D
I0624 13:54:13.909425 18353 net.cpp:91] Creating Layer relu3_1_D
I0624 13:54:13.909430 18353 net.cpp:425] relu3_1_D <- conv3_1_D
I0624 13:54:13.909435 18353 net.cpp:386] relu3_1_D -> conv3_1_D (in-place)
I0624 13:54:13.909842 18353 net.cpp:141] Setting up relu3_1_D
I0624 13:54:13.909855 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.909858 18353 net.cpp:156] Memory required for data: 123533312
I0624 13:54:13.909862 18353 layer_factory.hpp:77] Creating layer upsample2
I0624 13:54:13.909871 18353 net.cpp:91] Creating Layer upsample2
I0624 13:54:13.909875 18353 net.cpp:425] upsample2 <- conv3_1_D
I0624 13:54:13.909880 18353 net.cpp:425] upsample2 <- pool2_mask
I0624 13:54:13.909885 18353 net.cpp:399] upsample2 -> pool2_D
I0624 13:54:13.909931 18353 net.cpp:141] Setting up upsample2
I0624 13:54:13.909937 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.909940 18353 net.cpp:156] Memory required for data: 126744576
I0624 13:54:13.909943 18353 layer_factory.hpp:77] Creating layer conv2_2_D
I0624 13:54:13.909953 18353 net.cpp:91] Creating Layer conv2_2_D
I0624 13:54:13.909957 18353 net.cpp:425] conv2_2_D <- pool2_D
I0624 13:54:13.909965 18353 net.cpp:399] conv2_2_D -> conv2_2_D
I0624 13:54:13.911561 18353 net.cpp:141] Setting up conv2_2_D
I0624 13:54:13.911577 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.911581 18353 net.cpp:156] Memory required for data: 129955840
I0624 13:54:13.911588 18353 layer_factory.hpp:77] Creating layer bn2_2_D
I0624 13:54:13.911597 18353 net.cpp:91] Creating Layer bn2_2_D
I0624 13:54:13.911602 18353 net.cpp:425] bn2_2_D <- conv2_2_D
I0624 13:54:13.911607 18353 net.cpp:386] bn2_2_D -> conv2_2_D (in-place)
I0624 13:54:13.912679 18353 net.cpp:141] Setting up bn2_2_D
I0624 13:54:13.912696 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.912713 18353 net.cpp:156] Memory required for data: 133167104
I0624 13:54:13.912721 18353 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 13:54:13.912730 18353 net.cpp:91] Creating Layer scale2_2_D
I0624 13:54:13.912734 18353 net.cpp:425] scale2_2_D <- conv2_2_D
I0624 13:54:13.912740 18353 net.cpp:386] scale2_2_D -> conv2_2_D (in-place)
I0624 13:54:13.912834 18353 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 13:54:13.913141 18353 net.cpp:141] Setting up scale2_2_D
I0624 13:54:13.913158 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.913164 18353 net.cpp:156] Memory required for data: 136378368
I0624 13:54:13.913174 18353 layer_factory.hpp:77] Creating layer relu2_2_D
I0624 13:54:13.913183 18353 net.cpp:91] Creating Layer relu2_2_D
I0624 13:54:13.913189 18353 net.cpp:425] relu2_2_D <- conv2_2_D
I0624 13:54:13.913197 18353 net.cpp:386] relu2_2_D -> conv2_2_D (in-place)
I0624 13:54:13.913735 18353 net.cpp:141] Setting up relu2_2_D
I0624 13:54:13.913755 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.913761 18353 net.cpp:156] Memory required for data: 139589632
I0624 13:54:13.913767 18353 layer_factory.hpp:77] Creating layer conv2_1_D
I0624 13:54:13.913784 18353 net.cpp:91] Creating Layer conv2_1_D
I0624 13:54:13.913792 18353 net.cpp:425] conv2_1_D <- conv2_2_D
I0624 13:54:13.913803 18353 net.cpp:399] conv2_1_D -> conv2_1_D
I0624 13:54:13.915731 18353 net.cpp:141] Setting up conv2_1_D
I0624 13:54:13.915745 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.915748 18353 net.cpp:156] Memory required for data: 141195264
I0624 13:54:13.915753 18353 layer_factory.hpp:77] Creating layer bn2_1_D
I0624 13:54:13.915761 18353 net.cpp:91] Creating Layer bn2_1_D
I0624 13:54:13.915765 18353 net.cpp:425] bn2_1_D <- conv2_1_D
I0624 13:54:13.915769 18353 net.cpp:386] bn2_1_D -> conv2_1_D (in-place)
I0624 13:54:13.916023 18353 net.cpp:141] Setting up bn2_1_D
I0624 13:54:13.916031 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.916034 18353 net.cpp:156] Memory required for data: 142800896
I0624 13:54:13.916040 18353 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 13:54:13.916046 18353 net.cpp:91] Creating Layer scale2_1_D
I0624 13:54:13.916049 18353 net.cpp:425] scale2_1_D <- conv2_1_D
I0624 13:54:13.916055 18353 net.cpp:386] scale2_1_D -> conv2_1_D (in-place)
I0624 13:54:13.916106 18353 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 13:54:13.916259 18353 net.cpp:141] Setting up scale2_1_D
I0624 13:54:13.916266 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.916268 18353 net.cpp:156] Memory required for data: 144406528
I0624 13:54:13.916273 18353 layer_factory.hpp:77] Creating layer relu2_1_D
I0624 13:54:13.916278 18353 net.cpp:91] Creating Layer relu2_1_D
I0624 13:54:13.916281 18353 net.cpp:425] relu2_1_D <- conv2_1_D
I0624 13:54:13.916286 18353 net.cpp:386] relu2_1_D -> conv2_1_D (in-place)
I0624 13:54:13.916463 18353 net.cpp:141] Setting up relu2_1_D
I0624 13:54:13.916472 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.916474 18353 net.cpp:156] Memory required for data: 146012160
I0624 13:54:13.916478 18353 layer_factory.hpp:77] Creating layer upsample1
I0624 13:54:13.916484 18353 net.cpp:91] Creating Layer upsample1
I0624 13:54:13.916487 18353 net.cpp:425] upsample1 <- conv2_1_D
I0624 13:54:13.916491 18353 net.cpp:425] upsample1 <- pool1_mask
I0624 13:54:13.916496 18353 net.cpp:399] upsample1 -> pool1_D
I0624 13:54:13.916532 18353 net.cpp:141] Setting up upsample1
I0624 13:54:13.916538 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.916540 18353 net.cpp:156] Memory required for data: 152434688
I0624 13:54:13.916543 18353 layer_factory.hpp:77] Creating layer conv1_2_D
I0624 13:54:13.916551 18353 net.cpp:91] Creating Layer conv1_2_D
I0624 13:54:13.916554 18353 net.cpp:425] conv1_2_D <- pool1_D
I0624 13:54:13.916559 18353 net.cpp:399] conv1_2_D -> conv1_2_D
I0624 13:54:13.917834 18353 net.cpp:141] Setting up conv1_2_D
I0624 13:54:13.917847 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.917860 18353 net.cpp:156] Memory required for data: 158857216
I0624 13:54:13.917866 18353 layer_factory.hpp:77] Creating layer bn1_2_D
I0624 13:54:13.917875 18353 net.cpp:91] Creating Layer bn1_2_D
I0624 13:54:13.917878 18353 net.cpp:425] bn1_2_D <- conv1_2_D
I0624 13:54:13.917883 18353 net.cpp:386] bn1_2_D -> conv1_2_D (in-place)
I0624 13:54:13.918175 18353 net.cpp:141] Setting up bn1_2_D
I0624 13:54:13.918184 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.918186 18353 net.cpp:156] Memory required for data: 165279744
I0624 13:54:13.918192 18353 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 13:54:13.918198 18353 net.cpp:91] Creating Layer scale1_2_D
I0624 13:54:13.918201 18353 net.cpp:425] scale1_2_D <- conv1_2_D
I0624 13:54:13.918205 18353 net.cpp:386] scale1_2_D -> conv1_2_D (in-place)
I0624 13:54:13.918256 18353 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 13:54:13.919188 18353 net.cpp:141] Setting up scale1_2_D
I0624 13:54:13.919203 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.919205 18353 net.cpp:156] Memory required for data: 171702272
I0624 13:54:13.919211 18353 layer_factory.hpp:77] Creating layer relu1_2_D
I0624 13:54:13.919216 18353 net.cpp:91] Creating Layer relu1_2_D
I0624 13:54:13.919219 18353 net.cpp:425] relu1_2_D <- conv1_2_D
I0624 13:54:13.919224 18353 net.cpp:386] relu1_2_D -> conv1_2_D (in-place)
I0624 13:54:13.919584 18353 net.cpp:141] Setting up relu1_2_D
I0624 13:54:13.919596 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.919600 18353 net.cpp:156] Memory required for data: 178124800
I0624 13:54:13.919603 18353 layer_factory.hpp:77] Creating layer conv1_1_D
I0624 13:54:13.919613 18353 net.cpp:91] Creating Layer conv1_1_D
I0624 13:54:13.919616 18353 net.cpp:425] conv1_1_D <- conv1_2_D
I0624 13:54:13.919621 18353 net.cpp:399] conv1_1_D -> conv1_1_D
I0624 13:54:13.920965 18353 net.cpp:141] Setting up conv1_1_D
I0624 13:54:13.920979 18353 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 13:54:13.920981 18353 net.cpp:156] Memory required for data: 178526208
I0624 13:54:13.920989 18353 layer_factory.hpp:77] Creating layer conv1_1_D_conv1_1_D_0_split
I0624 13:54:13.920994 18353 net.cpp:91] Creating Layer conv1_1_D_conv1_1_D_0_split
I0624 13:54:13.920997 18353 net.cpp:425] conv1_1_D_conv1_1_D_0_split <- conv1_1_D
I0624 13:54:13.921003 18353 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_0
I0624 13:54:13.921010 18353 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_1
I0624 13:54:13.921066 18353 net.cpp:141] Setting up conv1_1_D_conv1_1_D_0_split
I0624 13:54:13.921072 18353 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 13:54:13.921077 18353 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 13:54:13.921078 18353 net.cpp:156] Memory required for data: 179329024
I0624 13:54:13.921082 18353 layer_factory.hpp:77] Creating layer loss
I0624 13:54:13.921087 18353 net.cpp:91] Creating Layer loss
I0624 13:54:13.921090 18353 net.cpp:425] loss <- conv1_1_D_conv1_1_D_0_split_0
I0624 13:54:13.921094 18353 net.cpp:425] loss <- label_data_1_split_0
I0624 13:54:13.921098 18353 net.cpp:399] loss -> loss
I0624 13:54:13.921104 18353 layer_factory.hpp:77] Creating layer loss
I0624 13:54:13.921669 18353 net.cpp:141] Setting up loss
I0624 13:54:13.921681 18353 net.cpp:148] Top shape: (1)
I0624 13:54:13.921684 18353 net.cpp:151]     with loss weight 1
I0624 13:54:13.921694 18353 net.cpp:156] Memory required for data: 179329028
I0624 13:54:13.921696 18353 layer_factory.hpp:77] Creating layer accuracy
I0624 13:54:13.921703 18353 net.cpp:91] Creating Layer accuracy
I0624 13:54:13.921706 18353 net.cpp:425] accuracy <- conv1_1_D_conv1_1_D_0_split_1
I0624 13:54:13.921710 18353 net.cpp:425] accuracy <- label_data_1_split_1
I0624 13:54:13.921715 18353 net.cpp:399] accuracy -> accuracy
I0624 13:54:13.921721 18353 net.cpp:141] Setting up accuracy
I0624 13:54:13.921725 18353 net.cpp:148] Top shape: (1)
I0624 13:54:13.921727 18353 net.cpp:156] Memory required for data: 179329032
I0624 13:54:13.921742 18353 net.cpp:219] accuracy does not need backward computation.
I0624 13:54:13.921746 18353 net.cpp:217] loss needs backward computation.
I0624 13:54:13.921749 18353 net.cpp:217] conv1_1_D_conv1_1_D_0_split needs backward computation.
I0624 13:54:13.921752 18353 net.cpp:217] conv1_1_D needs backward computation.
I0624 13:54:13.921754 18353 net.cpp:217] relu1_2_D needs backward computation.
I0624 13:54:13.921757 18353 net.cpp:217] scale1_2_D needs backward computation.
I0624 13:54:13.921759 18353 net.cpp:217] bn1_2_D needs backward computation.
I0624 13:54:13.921761 18353 net.cpp:217] conv1_2_D needs backward computation.
I0624 13:54:13.921764 18353 net.cpp:217] upsample1 needs backward computation.
I0624 13:54:13.921769 18353 net.cpp:217] relu2_1_D needs backward computation.
I0624 13:54:13.921772 18353 net.cpp:217] scale2_1_D needs backward computation.
I0624 13:54:13.921774 18353 net.cpp:217] bn2_1_D needs backward computation.
I0624 13:54:13.921777 18353 net.cpp:217] conv2_1_D needs backward computation.
I0624 13:54:13.921779 18353 net.cpp:217] relu2_2_D needs backward computation.
I0624 13:54:13.921782 18353 net.cpp:217] scale2_2_D needs backward computation.
I0624 13:54:13.921783 18353 net.cpp:217] bn2_2_D needs backward computation.
I0624 13:54:13.921787 18353 net.cpp:217] conv2_2_D needs backward computation.
I0624 13:54:13.921789 18353 net.cpp:217] upsample2 needs backward computation.
I0624 13:54:13.921792 18353 net.cpp:217] relu3_1_D needs backward computation.
I0624 13:54:13.921794 18353 net.cpp:217] scale3_1_D needs backward computation.
I0624 13:54:13.921798 18353 net.cpp:217] bn3_1_D needs backward computation.
I0624 13:54:13.921802 18353 net.cpp:217] conv3_1_D needs backward computation.
I0624 13:54:13.921804 18353 net.cpp:217] relu3_2_D needs backward computation.
I0624 13:54:13.921807 18353 net.cpp:217] scale3_2_D needs backward computation.
I0624 13:54:13.921809 18353 net.cpp:217] bn3_2_D needs backward computation.
I0624 13:54:13.921811 18353 net.cpp:217] conv3_2_D needs backward computation.
I0624 13:54:13.921814 18353 net.cpp:217] upsample3 needs backward computation.
I0624 13:54:13.921818 18353 net.cpp:217] relu4_1_D needs backward computation.
I0624 13:54:13.921820 18353 net.cpp:217] scale4_1_D needs backward computation.
I0624 13:54:13.921823 18353 net.cpp:217] bn4_1_D needs backward computation.
I0624 13:54:13.921825 18353 net.cpp:217] conv4_1_D needs backward computation.
I0624 13:54:13.921828 18353 net.cpp:217] relu4_2_D needs backward computation.
I0624 13:54:13.921831 18353 net.cpp:217] scale4_2_D needs backward computation.
I0624 13:54:13.921833 18353 net.cpp:217] bn4_2_D needs backward computation.
I0624 13:54:13.921836 18353 net.cpp:217] conv4_2_D needs backward computation.
I0624 13:54:13.921839 18353 net.cpp:217] upsample4 needs backward computation.
I0624 13:54:13.921843 18353 net.cpp:217] relu5_1_D needs backward computation.
I0624 13:54:13.921844 18353 net.cpp:217] scale5_1_D needs backward computation.
I0624 13:54:13.921849 18353 net.cpp:217] bn5_1_D needs backward computation.
I0624 13:54:13.921850 18353 net.cpp:217] conv5_1_D needs backward computation.
I0624 13:54:13.921854 18353 net.cpp:217] relu5_2_D needs backward computation.
I0624 13:54:13.921856 18353 net.cpp:217] scale5_2_D needs backward computation.
I0624 13:54:13.921859 18353 net.cpp:217] bn5_2_D needs backward computation.
I0624 13:54:13.921860 18353 net.cpp:217] conv5_2_D needs backward computation.
I0624 13:54:13.921864 18353 net.cpp:217] upsample5 needs backward computation.
I0624 13:54:13.921867 18353 net.cpp:217] pool5 needs backward computation.
I0624 13:54:13.921870 18353 net.cpp:217] relu5_2 needs backward computation.
I0624 13:54:13.921874 18353 net.cpp:217] scale5_2 needs backward computation.
I0624 13:54:13.921875 18353 net.cpp:217] bn5_2 needs backward computation.
I0624 13:54:13.921877 18353 net.cpp:217] conv5_2 needs backward computation.
I0624 13:54:13.921880 18353 net.cpp:217] relu5_1 needs backward computation.
I0624 13:54:13.921883 18353 net.cpp:217] scale5_1 needs backward computation.
I0624 13:54:13.921890 18353 net.cpp:217] bn5_1 needs backward computation.
I0624 13:54:13.921893 18353 net.cpp:217] conv5_1 needs backward computation.
I0624 13:54:13.921896 18353 net.cpp:217] pool4 needs backward computation.
I0624 13:54:13.921900 18353 net.cpp:217] relu4_2 needs backward computation.
I0624 13:54:13.921901 18353 net.cpp:217] scale4_2 needs backward computation.
I0624 13:54:13.921905 18353 net.cpp:217] bn4_2 needs backward computation.
I0624 13:54:13.921906 18353 net.cpp:217] conv4_2 needs backward computation.
I0624 13:54:13.921911 18353 net.cpp:217] relu4_1 needs backward computation.
I0624 13:54:13.921914 18353 net.cpp:217] scale4_1 needs backward computation.
I0624 13:54:13.921917 18353 net.cpp:217] bn4_1 needs backward computation.
I0624 13:54:13.921919 18353 net.cpp:217] conv4_1 needs backward computation.
I0624 13:54:13.921922 18353 net.cpp:217] pool3 needs backward computation.
I0624 13:54:13.921924 18353 net.cpp:217] relu3_2 needs backward computation.
I0624 13:54:13.921927 18353 net.cpp:217] scale3_2 needs backward computation.
I0624 13:54:13.921929 18353 net.cpp:217] bn3_2 needs backward computation.
I0624 13:54:13.921932 18353 net.cpp:217] conv3_2 needs backward computation.
I0624 13:54:13.921934 18353 net.cpp:217] relu3_1 needs backward computation.
I0624 13:54:13.921937 18353 net.cpp:217] scale3_1 needs backward computation.
I0624 13:54:13.921939 18353 net.cpp:217] bn3_1 needs backward computation.
I0624 13:54:13.921942 18353 net.cpp:217] conv3_1 needs backward computation.
I0624 13:54:13.921946 18353 net.cpp:217] pool2 needs backward computation.
I0624 13:54:13.921947 18353 net.cpp:217] relu2_2 needs backward computation.
I0624 13:54:13.921950 18353 net.cpp:217] scale2_2 needs backward computation.
I0624 13:54:13.921952 18353 net.cpp:217] bn2_2 needs backward computation.
I0624 13:54:13.921955 18353 net.cpp:217] conv2_2 needs backward computation.
I0624 13:54:13.921957 18353 net.cpp:217] relu2_1 needs backward computation.
I0624 13:54:13.921960 18353 net.cpp:217] scale2_1 needs backward computation.
I0624 13:54:13.921963 18353 net.cpp:217] bn2_1 needs backward computation.
I0624 13:54:13.921965 18353 net.cpp:217] conv2_1 needs backward computation.
I0624 13:54:13.921968 18353 net.cpp:217] pool1 needs backward computation.
I0624 13:54:13.921972 18353 net.cpp:217] relu1_2 needs backward computation.
I0624 13:54:13.921973 18353 net.cpp:217] scale1_2 needs backward computation.
I0624 13:54:13.921977 18353 net.cpp:217] bn1_2 needs backward computation.
I0624 13:54:13.921978 18353 net.cpp:217] conv1_2 needs backward computation.
I0624 13:54:13.921982 18353 net.cpp:217] relu1_1 needs backward computation.
I0624 13:54:13.921983 18353 net.cpp:217] scale1_1 needs backward computation.
I0624 13:54:13.921986 18353 net.cpp:217] bn1_1 needs backward computation.
I0624 13:54:13.921989 18353 net.cpp:217] conv1_1 needs backward computation.
I0624 13:54:13.921993 18353 net.cpp:219] label_data_1_split does not need backward computation.
I0624 13:54:13.921995 18353 net.cpp:219] data does not need backward computation.
I0624 13:54:13.921998 18353 net.cpp:261] This network produces output accuracy
I0624 13:54:13.922001 18353 net.cpp:261] This network produces output loss
I0624 13:54:13.922051 18353 net.cpp:274] Network initialization done.
I0624 13:54:13.922327 18353 solver.cpp:60] Solver scaffolding done.
I0624 13:54:13.927279 18353 caffe.cpp:219] Starting Optimization
I0624 13:54:13.927287 18353 solver.cpp:279] Solving segnet
I0624 13:54:13.927290 18353 solver.cpp:280] Learning Rate Policy: step
I0624 13:54:13.932564 18353 solver.cpp:337] Iteration 0, Testing net (#0)
I0624 13:54:14.301425 18353 solver.cpp:404]     Test net output #0: accuracy = 0.537452
I0624 13:54:14.301452 18353 solver.cpp:404]     Test net output #1: loss = 0.725279 (* 1 = 0.725279 loss)
I0624 13:54:15.058629 18353 solver.cpp:228] Iteration 0, loss = 0.724146
I0624 13:54:15.058655 18353 solver.cpp:244]     Train net output #0: accuracy = 0.536619
I0624 13:54:15.058663 18353 solver.cpp:244]     Train net output #1: loss = 0.724146 (* 1 = 0.724146 loss)
I0624 13:54:15.058693 18353 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0624 13:54:29.378131 18353 solver.cpp:228] Iteration 20, loss = 0.279161
I0624 13:54:29.378157 18353 solver.cpp:244]     Train net output #0: accuracy = 0.957215
I0624 13:54:29.378165 18353 solver.cpp:244]     Train net output #1: loss = 0.279161 (* 1 = 0.279161 loss)
I0624 13:54:29.378170 18353 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0624 13:54:44.031246 18353 solver.cpp:228] Iteration 40, loss = 0.184418
I0624 13:54:44.031307 18353 solver.cpp:244]     Train net output #0: accuracy = 0.959128
I0624 13:54:44.031316 18353 solver.cpp:244]     Train net output #1: loss = 0.184418 (* 1 = 0.184418 loss)
I0624 13:54:44.031322 18353 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0624 13:54:58.649756 18353 solver.cpp:228] Iteration 60, loss = 0.164278
I0624 13:54:58.649780 18353 solver.cpp:244]     Train net output #0: accuracy = 0.961961
I0624 13:54:58.649788 18353 solver.cpp:244]     Train net output #1: loss = 0.164278 (* 1 = 0.164278 loss)
I0624 13:54:58.649793 18353 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0624 13:55:13.267417 18353 solver.cpp:228] Iteration 80, loss = 0.170846
I0624 13:55:13.267444 18353 solver.cpp:244]     Train net output #0: accuracy = 0.9594
I0624 13:55:13.267452 18353 solver.cpp:244]     Train net output #1: loss = 0.170846 (* 1 = 0.170846 loss)
I0624 13:55:13.267457 18353 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0624 13:55:27.485368 18353 solver.cpp:337] Iteration 100, Testing net (#0)
I0624 13:55:27.821208 18353 solver.cpp:404]     Test net output #0: accuracy = 0.960021
I0624 13:55:27.821243 18353 solver.cpp:404]     Test net output #1: loss = 0.167101 (* 1 = 0.167101 loss)
I0624 13:55:28.230455 18353 solver.cpp:228] Iteration 100, loss = 0.159109
I0624 13:55:28.230479 18353 solver.cpp:244]     Train net output #0: accuracy = 0.962868
I0624 13:55:28.230485 18353 solver.cpp:244]     Train net output #1: loss = 0.159109 (* 1 = 0.159109 loss)
I0624 13:55:28.230490 18353 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0624 13:55:42.847285 18353 solver.cpp:228] Iteration 120, loss = 0.155371
I0624 13:55:42.847308 18353 solver.cpp:244]     Train net output #0: accuracy = 0.962933
I0624 13:55:42.847316 18353 solver.cpp:244]     Train net output #1: loss = 0.155371 (* 1 = 0.155371 loss)
I0624 13:55:42.847321 18353 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0624 13:55:57.479846 18353 solver.cpp:228] Iteration 140, loss = 0.17061
I0624 13:55:57.479881 18353 solver.cpp:244]     Train net output #0: accuracy = 0.957796
I0624 13:55:57.479887 18353 solver.cpp:244]     Train net output #1: loss = 0.17061 (* 1 = 0.17061 loss)
I0624 13:55:57.479892 18353 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0624 13:56:12.129005 18353 solver.cpp:228] Iteration 160, loss = 0.155859
I0624 13:56:12.129109 18353 solver.cpp:244]     Train net output #0: accuracy = 0.961909
I0624 13:56:12.129118 18353 solver.cpp:244]     Train net output #1: loss = 0.155859 (* 1 = 0.155859 loss)
I0624 13:56:12.129123 18353 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0624 13:56:26.818622 18353 solver.cpp:228] Iteration 180, loss = 0.155052
I0624 13:56:26.818648 18353 solver.cpp:244]     Train net output #0: accuracy = 0.960647
I0624 13:56:26.818666 18353 solver.cpp:244]     Train net output #1: loss = 0.155052 (* 1 = 0.155052 loss)
I0624 13:56:26.818671 18353 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0624 13:56:41.064301 18353 solver.cpp:337] Iteration 200, Testing net (#0)
I0624 13:56:41.400609 18353 solver.cpp:404]     Test net output #0: accuracy = 0.956742
I0624 13:56:41.400632 18353 solver.cpp:404]     Test net output #1: loss = 0.162979 (* 1 = 0.162979 loss)
I0624 13:56:41.810281 18353 solver.cpp:228] Iteration 200, loss = 0.145909
I0624 13:56:41.810305 18353 solver.cpp:244]     Train net output #0: accuracy = 0.961393
I0624 13:56:41.810312 18353 solver.cpp:244]     Train net output #1: loss = 0.145909 (* 1 = 0.145909 loss)
I0624 13:56:41.810317 18353 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0624 13:56:56.456368 18353 solver.cpp:228] Iteration 220, loss = 0.156049
I0624 13:56:56.456470 18353 solver.cpp:244]     Train net output #0: accuracy = 0.95873
I0624 13:56:56.456480 18353 solver.cpp:244]     Train net output #1: loss = 0.156049 (* 1 = 0.156049 loss)
I0624 13:56:56.456486 18353 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0624 13:57:11.101212 18353 solver.cpp:228] Iteration 240, loss = 0.145085
I0624 13:57:11.101234 18353 solver.cpp:244]     Train net output #0: accuracy = 0.959492
I0624 13:57:11.101241 18353 solver.cpp:244]     Train net output #1: loss = 0.145085 (* 1 = 0.145085 loss)
I0624 13:57:11.101246 18353 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0624 13:57:25.741889 18353 solver.cpp:228] Iteration 260, loss = 0.148975
I0624 13:57:25.741912 18353 solver.cpp:244]     Train net output #0: accuracy = 0.957047
I0624 13:57:25.741919 18353 solver.cpp:244]     Train net output #1: loss = 0.148975 (* 1 = 0.148975 loss)
I0624 13:57:25.741924 18353 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0624 13:57:40.381590 18353 solver.cpp:228] Iteration 280, loss = 0.133317
I0624 13:57:40.381692 18353 solver.cpp:244]     Train net output #0: accuracy = 0.960251
I0624 13:57:40.381702 18353 solver.cpp:244]     Train net output #1: loss = 0.133317 (* 1 = 0.133317 loss)
I0624 13:57:40.381706 18353 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0624 13:57:54.601105 18353 solver.cpp:337] Iteration 300, Testing net (#0)
I0624 13:57:54.937306 18353 solver.cpp:404]     Test net output #0: accuracy = 0.961045
I0624 13:57:54.937340 18353 solver.cpp:404]     Test net output #1: loss = 0.12165 (* 1 = 0.12165 loss)
I0624 13:57:55.345929 18353 solver.cpp:228] Iteration 300, loss = 0.128392
I0624 13:57:55.345954 18353 solver.cpp:244]     Train net output #0: accuracy = 0.962344
I0624 13:57:55.345963 18353 solver.cpp:244]     Train net output #1: loss = 0.128392 (* 1 = 0.128392 loss)
I0624 13:57:55.345966 18353 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0624 13:58:09.978418 18353 solver.cpp:228] Iteration 320, loss = 0.119978
I0624 13:58:09.978453 18353 solver.cpp:244]     Train net output #0: accuracy = 0.961506
I0624 13:58:09.978461 18353 solver.cpp:244]     Train net output #1: loss = 0.119978 (* 1 = 0.119978 loss)
I0624 13:58:09.978466 18353 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0624 13:58:24.607568 18353 solver.cpp:228] Iteration 340, loss = 0.121553
I0624 13:58:24.607673 18353 solver.cpp:244]     Train net output #0: accuracy = 0.960828
I0624 13:58:24.607682 18353 solver.cpp:244]     Train net output #1: loss = 0.121553 (* 1 = 0.121553 loss)
I0624 13:58:24.607687 18353 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0624 13:58:39.295615 18353 solver.cpp:228] Iteration 360, loss = 0.113908
I0624 13:58:39.295640 18353 solver.cpp:244]     Train net output #0: accuracy = 0.959678
I0624 13:58:39.295649 18353 solver.cpp:244]     Train net output #1: loss = 0.113908 (* 1 = 0.113908 loss)
I0624 13:58:39.295652 18353 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0624 13:58:53.936630 18353 solver.cpp:228] Iteration 380, loss = 0.105754
I0624 13:58:53.936655 18353 solver.cpp:244]     Train net output #0: accuracy = 0.962382
I0624 13:58:53.936661 18353 solver.cpp:244]     Train net output #1: loss = 0.105754 (* 1 = 0.105754 loss)
I0624 13:58:53.936666 18353 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0624 13:59:08.154316 18353 solver.cpp:337] Iteration 400, Testing net (#0)
I0624 13:59:08.490871 18353 solver.cpp:404]     Test net output #0: accuracy = 0.960308
I0624 13:59:08.490906 18353 solver.cpp:404]     Test net output #1: loss = 0.110345 (* 1 = 0.110345 loss)
I0624 13:59:08.901298 18353 solver.cpp:228] Iteration 400, loss = 0.100459
I0624 13:59:08.901322 18353 solver.cpp:244]     Train net output #0: accuracy = 0.960776
I0624 13:59:08.901329 18353 solver.cpp:244]     Train net output #1: loss = 0.100459 (* 1 = 0.100459 loss)
I0624 13:59:08.901335 18353 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0624 13:59:23.517493 18353 solver.cpp:228] Iteration 420, loss = 0.0900748
I0624 13:59:23.517518 18353 solver.cpp:244]     Train net output #0: accuracy = 0.960089
I0624 13:59:23.517524 18353 solver.cpp:244]     Train net output #1: loss = 0.0900748 (* 1 = 0.0900748 loss)
I0624 13:59:23.517529 18353 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0624 13:59:38.141052 18353 solver.cpp:228] Iteration 440, loss = 0.0900009
I0624 13:59:38.141077 18353 solver.cpp:244]     Train net output #0: accuracy = 0.961223
I0624 13:59:38.141083 18353 solver.cpp:244]     Train net output #1: loss = 0.0900009 (* 1 = 0.0900009 loss)
I0624 13:59:38.141088 18353 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0624 13:59:52.759651 18353 solver.cpp:228] Iteration 460, loss = 0.0928793
I0624 13:59:52.759785 18353 solver.cpp:244]     Train net output #0: accuracy = 0.957468
I0624 13:59:52.759796 18353 solver.cpp:244]     Train net output #1: loss = 0.0928793 (* 1 = 0.0928793 loss)
I0624 13:59:52.759801 18353 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0624 14:00:07.383680 18353 solver.cpp:228] Iteration 480, loss = 0.0791099
I0624 14:00:07.383704 18353 solver.cpp:244]     Train net output #0: accuracy = 0.958579
I0624 14:00:07.383711 18353 solver.cpp:244]     Train net output #1: loss = 0.0791099 (* 1 = 0.0791099 loss)
I0624 14:00:07.383728 18353 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0624 14:00:21.659811 18353 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_500.caffemodel
I0624 14:00:21.723325 18353 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_500.solverstate
I0624 14:00:21.746764 18353 solver.cpp:337] Iteration 500, Testing net (#0)
I0624 14:00:22.085218 18353 solver.cpp:404]     Test net output #0: accuracy = 0.962007
I0624 14:00:22.085243 18353 solver.cpp:404]     Test net output #1: loss = 0.0745117 (* 1 = 0.0745117 loss)
I0624 14:00:22.494601 18353 solver.cpp:228] Iteration 500, loss = 0.0748195
I0624 14:00:22.494638 18353 solver.cpp:244]     Train net output #0: accuracy = 0.957714
I0624 14:00:22.494647 18353 solver.cpp:244]     Train net output #1: loss = 0.0748195 (* 1 = 0.0748195 loss)
I0624 14:00:22.494652 18353 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0624 14:00:37.145248 18353 solver.cpp:228] Iteration 520, loss = 0.0715747
I0624 14:00:37.145351 18353 solver.cpp:244]     Train net output #0: accuracy = 0.957573
I0624 14:00:37.145361 18353 solver.cpp:244]     Train net output #1: loss = 0.0715747 (* 1 = 0.0715747 loss)
I0624 14:00:37.145366 18353 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0624 14:00:51.765321 18353 solver.cpp:228] Iteration 540, loss = 0.0927644
I0624 14:00:51.765347 18353 solver.cpp:244]     Train net output #0: accuracy = 0.954369
I0624 14:00:51.765354 18353 solver.cpp:244]     Train net output #1: loss = 0.0927644 (* 1 = 0.0927644 loss)
I0624 14:00:51.765358 18353 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0624 14:01:06.395365 18353 solver.cpp:228] Iteration 560, loss = 0.0703689
I0624 14:01:06.395401 18353 solver.cpp:244]     Train net output #0: accuracy = 0.960642
I0624 14:01:06.395408 18353 solver.cpp:244]     Train net output #1: loss = 0.0703689 (* 1 = 0.0703689 loss)
I0624 14:01:06.395413 18353 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0624 14:01:21.005295 18353 solver.cpp:228] Iteration 580, loss = 0.0766441
I0624 14:01:21.005408 18353 solver.cpp:244]     Train net output #0: accuracy = 0.97085
I0624 14:01:21.005417 18353 solver.cpp:244]     Train net output #1: loss = 0.0766441 (* 1 = 0.0766441 loss)
I0624 14:01:21.005422 18353 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0624 14:01:35.231122 18353 solver.cpp:337] Iteration 600, Testing net (#0)
I0624 14:01:35.566961 18353 solver.cpp:404]     Test net output #0: accuracy = 0.970754
I0624 14:01:35.566995 18353 solver.cpp:404]     Test net output #1: loss = 0.0682377 (* 1 = 0.0682377 loss)
I0624 14:01:35.976045 18353 solver.cpp:228] Iteration 600, loss = 0.0677918
I0624 14:01:35.976069 18353 solver.cpp:244]     Train net output #0: accuracy = 0.973175
I0624 14:01:35.976076 18353 solver.cpp:244]     Train net output #1: loss = 0.0677918 (* 1 = 0.0677918 loss)
I0624 14:01:35.976081 18353 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0624 14:01:50.593183 18353 solver.cpp:228] Iteration 620, loss = 0.0692086
I0624 14:01:50.593210 18353 solver.cpp:244]     Train net output #0: accuracy = 0.972835
I0624 14:01:50.593217 18353 solver.cpp:244]     Train net output #1: loss = 0.0692086 (* 1 = 0.0692086 loss)
I0624 14:01:50.593222 18353 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0624 14:02:05.216209 18353 solver.cpp:228] Iteration 640, loss = 0.0615178
I0624 14:02:05.216326 18353 solver.cpp:244]     Train net output #0: accuracy = 0.975331
I0624 14:02:05.216337 18353 solver.cpp:244]     Train net output #1: loss = 0.0615178 (* 1 = 0.0615178 loss)
I0624 14:02:05.216342 18353 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0624 14:02:19.827494 18353 solver.cpp:228] Iteration 660, loss = 0.0608139
I0624 14:02:19.827520 18353 solver.cpp:244]     Train net output #0: accuracy = 0.977397
I0624 14:02:19.827527 18353 solver.cpp:244]     Train net output #1: loss = 0.0608139 (* 1 = 0.0608139 loss)
I0624 14:02:19.827531 18353 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0624 14:02:34.498422 18353 solver.cpp:228] Iteration 680, loss = 0.0630502
I0624 14:02:34.498446 18353 solver.cpp:244]     Train net output #0: accuracy = 0.978152
I0624 14:02:34.498453 18353 solver.cpp:244]     Train net output #1: loss = 0.0630502 (* 1 = 0.0630502 loss)
I0624 14:02:34.498458 18353 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0624 14:02:48.710953 18353 solver.cpp:337] Iteration 700, Testing net (#0)
I0624 14:02:49.046722 18353 solver.cpp:404]     Test net output #0: accuracy = 0.979673
I0624 14:02:49.046756 18353 solver.cpp:404]     Test net output #1: loss = 0.0580773 (* 1 = 0.0580773 loss)
I0624 14:02:49.456470 18353 solver.cpp:228] Iteration 700, loss = 0.0669421
I0624 14:02:49.456495 18353 solver.cpp:244]     Train net output #0: accuracy = 0.975812
I0624 14:02:49.456501 18353 solver.cpp:244]     Train net output #1: loss = 0.0669421 (* 1 = 0.0669421 loss)
I0624 14:02:49.456506 18353 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0624 14:03:04.084933 18353 solver.cpp:228] Iteration 720, loss = 0.059609
I0624 14:03:04.084957 18353 solver.cpp:244]     Train net output #0: accuracy = 0.976417
I0624 14:03:04.084965 18353 solver.cpp:244]     Train net output #1: loss = 0.059609 (* 1 = 0.059609 loss)
I0624 14:03:04.084970 18353 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0624 14:03:18.701774 18353 solver.cpp:228] Iteration 740, loss = 0.0555766
I0624 14:03:18.701810 18353 solver.cpp:244]     Train net output #0: accuracy = 0.980132
I0624 14:03:18.701818 18353 solver.cpp:244]     Train net output #1: loss = 0.0555766 (* 1 = 0.0555766 loss)
I0624 14:03:18.701823 18353 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0624 14:03:33.318568 18353 solver.cpp:228] Iteration 760, loss = 0.0614597
I0624 14:03:33.318660 18353 solver.cpp:244]     Train net output #0: accuracy = 0.978646
I0624 14:03:33.318670 18353 solver.cpp:244]     Train net output #1: loss = 0.0614597 (* 1 = 0.0614597 loss)
I0624 14:03:33.318675 18353 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0624 14:03:47.938019 18353 solver.cpp:228] Iteration 780, loss = 0.0689755
I0624 14:03:47.938042 18353 solver.cpp:244]     Train net output #0: accuracy = 0.976782
I0624 14:03:47.938050 18353 solver.cpp:244]     Train net output #1: loss = 0.0689755 (* 1 = 0.0689755 loss)
I0624 14:03:47.938055 18353 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0624 14:04:02.152492 18353 solver.cpp:337] Iteration 800, Testing net (#0)
I0624 14:04:02.488809 18353 solver.cpp:404]     Test net output #0: accuracy = 0.974548
I0624 14:04:02.488844 18353 solver.cpp:404]     Test net output #1: loss = 0.0645146 (* 1 = 0.0645146 loss)
I0624 14:04:02.898685 18353 solver.cpp:228] Iteration 800, loss = 0.0618737
I0624 14:04:02.898710 18353 solver.cpp:244]     Train net output #0: accuracy = 0.977544
I0624 14:04:02.898716 18353 solver.cpp:244]     Train net output #1: loss = 0.0618737 (* 1 = 0.0618737 loss)
I0624 14:04:02.898720 18353 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0624 14:04:17.525995 18353 solver.cpp:228] Iteration 820, loss = 0.0513541
I0624 14:04:17.526115 18353 solver.cpp:244]     Train net output #0: accuracy = 0.980827
I0624 14:04:17.526126 18353 solver.cpp:244]     Train net output #1: loss = 0.0513541 (* 1 = 0.0513541 loss)
I0624 14:04:17.526131 18353 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0624 14:04:32.166388 18353 solver.cpp:228] Iteration 840, loss = 0.0534772
I0624 14:04:32.166425 18353 solver.cpp:244]     Train net output #0: accuracy = 0.983084
I0624 14:04:32.166434 18353 solver.cpp:244]     Train net output #1: loss = 0.0534772 (* 1 = 0.0534772 loss)
I0624 14:04:32.166440 18353 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0624 14:04:46.802911 18353 solver.cpp:228] Iteration 860, loss = 0.0491241
I0624 14:04:46.802937 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982268
I0624 14:04:46.802943 18353 solver.cpp:244]     Train net output #1: loss = 0.0491241 (* 1 = 0.0491241 loss)
I0624 14:04:46.802948 18353 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0624 14:05:01.427945 18353 solver.cpp:228] Iteration 880, loss = 0.0542038
I0624 14:05:01.428045 18353 solver.cpp:244]     Train net output #0: accuracy = 0.978663
I0624 14:05:01.428055 18353 solver.cpp:244]     Train net output #1: loss = 0.0542038 (* 1 = 0.0542038 loss)
I0624 14:05:01.428059 18353 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0624 14:05:15.646544 18353 solver.cpp:337] Iteration 900, Testing net (#0)
I0624 14:05:15.983731 18353 solver.cpp:404]     Test net output #0: accuracy = 0.978232
I0624 14:05:15.983757 18353 solver.cpp:404]     Test net output #1: loss = 0.0545115 (* 1 = 0.0545115 loss)
I0624 14:05:16.393128 18353 solver.cpp:228] Iteration 900, loss = 0.0582187
I0624 14:05:16.393152 18353 solver.cpp:244]     Train net output #0: accuracy = 0.978857
I0624 14:05:16.393159 18353 solver.cpp:244]     Train net output #1: loss = 0.0582187 (* 1 = 0.0582187 loss)
I0624 14:05:16.393164 18353 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0624 14:05:31.015259 18353 solver.cpp:228] Iteration 920, loss = 0.0482975
I0624 14:05:31.015283 18353 solver.cpp:244]     Train net output #0: accuracy = 0.981586
I0624 14:05:31.015291 18353 solver.cpp:244]     Train net output #1: loss = 0.0482975 (* 1 = 0.0482975 loss)
I0624 14:05:31.015295 18353 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0624 14:05:45.640573 18353 solver.cpp:228] Iteration 940, loss = 0.0511484
I0624 14:05:45.640669 18353 solver.cpp:244]     Train net output #0: accuracy = 0.981192
I0624 14:05:45.640678 18353 solver.cpp:244]     Train net output #1: loss = 0.0511484 (* 1 = 0.0511484 loss)
I0624 14:05:45.640683 18353 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0624 14:06:00.271034 18353 solver.cpp:228] Iteration 960, loss = 0.0463565
I0624 14:06:00.271059 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982266
I0624 14:06:00.271065 18353 solver.cpp:244]     Train net output #1: loss = 0.0463565 (* 1 = 0.0463565 loss)
I0624 14:06:00.271070 18353 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0624 14:06:14.901949 18353 solver.cpp:228] Iteration 980, loss = 0.0550168
I0624 14:06:14.901974 18353 solver.cpp:244]     Train net output #0: accuracy = 0.979388
I0624 14:06:14.901983 18353 solver.cpp:244]     Train net output #1: loss = 0.0550168 (* 1 = 0.0550168 loss)
I0624 14:06:14.901988 18353 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0624 14:06:29.097652 18353 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_1000.caffemodel
I0624 14:06:29.144742 18353 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_1000.solverstate
I0624 14:06:29.167605 18353 solver.cpp:337] Iteration 1000, Testing net (#0)
I0624 14:06:29.505873 18353 solver.cpp:404]     Test net output #0: accuracy = 0.979678
I0624 14:06:29.505908 18353 solver.cpp:404]     Test net output #1: loss = 0.053645 (* 1 = 0.053645 loss)
I0624 14:06:29.925745 18353 solver.cpp:228] Iteration 1000, loss = 0.0567826
I0624 14:06:29.925771 18353 solver.cpp:244]     Train net output #0: accuracy = 0.978521
I0624 14:06:29.925778 18353 solver.cpp:244]     Train net output #1: loss = 0.0567826 (* 1 = 0.0567826 loss)
I0624 14:06:29.925782 18353 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0624 14:06:44.579529 18353 solver.cpp:228] Iteration 1020, loss = 0.047306
I0624 14:06:44.579555 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982656
I0624 14:06:44.579562 18353 solver.cpp:244]     Train net output #1: loss = 0.047306 (* 1 = 0.047306 loss)
I0624 14:06:44.579567 18353 sgd_solver.cpp:106] Iteration 1020, lr = 0.01
I0624 14:06:59.203131 18353 solver.cpp:228] Iteration 1040, loss = 0.0472528
I0624 14:06:59.203245 18353 solver.cpp:244]     Train net output #0: accuracy = 0.981992
I0624 14:06:59.203256 18353 solver.cpp:244]     Train net output #1: loss = 0.0472528 (* 1 = 0.0472528 loss)
I0624 14:06:59.203261 18353 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I0624 14:07:13.823009 18353 solver.cpp:228] Iteration 1060, loss = 0.0463792
I0624 14:07:13.823035 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982299
I0624 14:07:13.823041 18353 solver.cpp:244]     Train net output #1: loss = 0.0463792 (* 1 = 0.0463792 loss)
I0624 14:07:13.823046 18353 sgd_solver.cpp:106] Iteration 1060, lr = 0.01
I0624 14:07:28.442375 18353 solver.cpp:228] Iteration 1080, loss = 0.0453115
I0624 14:07:28.442401 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982542
I0624 14:07:28.442409 18353 solver.cpp:244]     Train net output #1: loss = 0.0453115 (* 1 = 0.0453115 loss)
I0624 14:07:28.442412 18353 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I0624 14:07:42.650655 18353 solver.cpp:337] Iteration 1100, Testing net (#0)
I0624 14:07:42.987040 18353 solver.cpp:404]     Test net output #0: accuracy = 0.980983
I0624 14:07:42.987074 18353 solver.cpp:404]     Test net output #1: loss = 0.04705 (* 1 = 0.04705 loss)
I0624 14:07:43.395676 18353 solver.cpp:228] Iteration 1100, loss = 0.0443787
I0624 14:07:43.395704 18353 solver.cpp:244]     Train net output #0: accuracy = 0.98394
I0624 14:07:43.395711 18353 solver.cpp:244]     Train net output #1: loss = 0.0443787 (* 1 = 0.0443787 loss)
I0624 14:07:43.395715 18353 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0624 14:07:58.002928 18353 solver.cpp:228] Iteration 1120, loss = 0.0506252
I0624 14:07:58.002954 18353 solver.cpp:244]     Train net output #0: accuracy = 0.981632
I0624 14:07:58.002961 18353 solver.cpp:244]     Train net output #1: loss = 0.0506252 (* 1 = 0.0506252 loss)
I0624 14:07:58.002966 18353 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I0624 14:08:12.624084 18353 solver.cpp:228] Iteration 1140, loss = 0.0549
I0624 14:08:12.624109 18353 solver.cpp:244]     Train net output #0: accuracy = 0.98195
I0624 14:08:12.624115 18353 solver.cpp:244]     Train net output #1: loss = 0.0549 (* 1 = 0.0549 loss)
I0624 14:08:12.624119 18353 sgd_solver.cpp:106] Iteration 1140, lr = 0.01
I0624 14:08:27.242965 18353 solver.cpp:228] Iteration 1160, loss = 0.0477591
I0624 14:08:27.243062 18353 solver.cpp:244]     Train net output #0: accuracy = 0.981922
I0624 14:08:27.243072 18353 solver.cpp:244]     Train net output #1: loss = 0.0477591 (* 1 = 0.0477591 loss)
I0624 14:08:27.243077 18353 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I0624 14:08:41.926856 18353 solver.cpp:228] Iteration 1180, loss = 0.0486042
I0624 14:08:41.926882 18353 solver.cpp:244]     Train net output #0: accuracy = 0.980324
I0624 14:08:41.926889 18353 solver.cpp:244]     Train net output #1: loss = 0.0486042 (* 1 = 0.0486042 loss)
I0624 14:08:41.926894 18353 sgd_solver.cpp:106] Iteration 1180, lr = 0.01
I0624 14:08:56.136394 18353 solver.cpp:337] Iteration 1200, Testing net (#0)
I0624 14:08:56.473107 18353 solver.cpp:404]     Test net output #0: accuracy = 0.980338
I0624 14:08:56.473142 18353 solver.cpp:404]     Test net output #1: loss = 0.0515377 (* 1 = 0.0515377 loss)
I0624 14:08:56.883250 18353 solver.cpp:228] Iteration 1200, loss = 0.0528292
I0624 14:08:56.883275 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982535
I0624 14:08:56.883282 18353 solver.cpp:244]     Train net output #1: loss = 0.0528292 (* 1 = 0.0528292 loss)
I0624 14:08:56.883287 18353 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0624 14:09:11.504889 18353 solver.cpp:228] Iteration 1220, loss = 0.0447128
I0624 14:09:11.505008 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982673
I0624 14:09:11.505018 18353 solver.cpp:244]     Train net output #1: loss = 0.0447128 (* 1 = 0.0447128 loss)
I0624 14:09:11.505023 18353 sgd_solver.cpp:106] Iteration 1220, lr = 0.01
I0624 14:09:26.132289 18353 solver.cpp:228] Iteration 1240, loss = 0.0476316
I0624 14:09:26.132316 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982242
I0624 14:09:26.132334 18353 solver.cpp:244]     Train net output #1: loss = 0.0476316 (* 1 = 0.0476316 loss)
I0624 14:09:26.132339 18353 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I0624 14:09:40.755981 18353 solver.cpp:228] Iteration 1260, loss = 0.0463768
I0624 14:09:40.756005 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982215
I0624 14:09:40.756011 18353 solver.cpp:244]     Train net output #1: loss = 0.0463768 (* 1 = 0.0463768 loss)
I0624 14:09:40.756016 18353 sgd_solver.cpp:106] Iteration 1260, lr = 0.01
I0624 14:09:55.375607 18353 solver.cpp:228] Iteration 1280, loss = 0.0446028
I0624 14:09:55.375705 18353 solver.cpp:244]     Train net output #0: accuracy = 0.983164
I0624 14:09:55.375715 18353 solver.cpp:244]     Train net output #1: loss = 0.0446028 (* 1 = 0.0446028 loss)
I0624 14:09:55.375720 18353 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I0624 14:10:09.593077 18353 solver.cpp:337] Iteration 1300, Testing net (#0)
I0624 14:10:09.929332 18353 solver.cpp:404]     Test net output #0: accuracy = 0.982333
I0624 14:10:09.929357 18353 solver.cpp:404]     Test net output #1: loss = 0.0520042 (* 1 = 0.0520042 loss)
I0624 14:10:10.339445 18353 solver.cpp:228] Iteration 1300, loss = 0.0445654
I0624 14:10:10.339470 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982638
I0624 14:10:10.339478 18353 solver.cpp:244]     Train net output #1: loss = 0.0445654 (* 1 = 0.0445654 loss)
I0624 14:10:10.339483 18353 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0624 14:10:24.968092 18353 solver.cpp:228] Iteration 1320, loss = 0.04075
I0624 14:10:24.968128 18353 solver.cpp:244]     Train net output #0: accuracy = 0.98477
I0624 14:10:24.968137 18353 solver.cpp:244]     Train net output #1: loss = 0.04075 (* 1 = 0.04075 loss)
I0624 14:10:24.968142 18353 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I0624 14:10:39.625999 18353 solver.cpp:228] Iteration 1340, loss = 0.0494391
I0624 14:10:39.626102 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982535
I0624 14:10:39.626112 18353 solver.cpp:244]     Train net output #1: loss = 0.0494391 (* 1 = 0.0494391 loss)
I0624 14:10:39.626117 18353 sgd_solver.cpp:106] Iteration 1340, lr = 0.01
I0624 14:10:54.244520 18353 solver.cpp:228] Iteration 1360, loss = 0.0454086
I0624 14:10:54.244545 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982199
I0624 14:10:54.244552 18353 solver.cpp:244]     Train net output #1: loss = 0.0454086 (* 1 = 0.0454086 loss)
I0624 14:10:54.244556 18353 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I0624 14:11:08.872153 18353 solver.cpp:228] Iteration 1380, loss = 0.0379164
I0624 14:11:08.872179 18353 solver.cpp:244]     Train net output #0: accuracy = 0.985763
I0624 14:11:08.872185 18353 solver.cpp:244]     Train net output #1: loss = 0.0379164 (* 1 = 0.0379164 loss)
I0624 14:11:08.872190 18353 sgd_solver.cpp:106] Iteration 1380, lr = 0.01
I0624 14:11:23.094391 18353 solver.cpp:337] Iteration 1400, Testing net (#0)
I0624 14:11:23.430480 18353 solver.cpp:404]     Test net output #0: accuracy = 0.981691
I0624 14:11:23.430515 18353 solver.cpp:404]     Test net output #1: loss = 0.0530297 (* 1 = 0.0530297 loss)
I0624 14:11:23.839520 18353 solver.cpp:228] Iteration 1400, loss = 0.0418028
I0624 14:11:23.839545 18353 solver.cpp:244]     Train net output #0: accuracy = 0.984113
I0624 14:11:23.839553 18353 solver.cpp:244]     Train net output #1: loss = 0.0418028 (* 1 = 0.0418028 loss)
I0624 14:11:23.839558 18353 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0624 14:11:38.477931 18353 solver.cpp:228] Iteration 1420, loss = 0.0426751
I0624 14:11:38.477954 18353 solver.cpp:244]     Train net output #0: accuracy = 0.984827
I0624 14:11:38.477962 18353 solver.cpp:244]     Train net output #1: loss = 0.0426751 (* 1 = 0.0426751 loss)
I0624 14:11:38.477967 18353 sgd_solver.cpp:106] Iteration 1420, lr = 0.01
I0624 14:11:53.101079 18353 solver.cpp:228] Iteration 1440, loss = 0.0448359
I0624 14:11:53.101192 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982584
I0624 14:11:53.101202 18353 solver.cpp:244]     Train net output #1: loss = 0.0448359 (* 1 = 0.0448359 loss)
I0624 14:11:53.101207 18353 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I0624 14:12:07.723986 18353 solver.cpp:228] Iteration 1460, loss = 0.0396116
I0624 14:12:07.724011 18353 solver.cpp:244]     Train net output #0: accuracy = 0.984612
I0624 14:12:07.724019 18353 solver.cpp:244]     Train net output #1: loss = 0.0396116 (* 1 = 0.0396116 loss)
I0624 14:12:07.724025 18353 sgd_solver.cpp:106] Iteration 1460, lr = 0.01
I0624 14:12:22.348093 18353 solver.cpp:228] Iteration 1480, loss = 0.0478724
I0624 14:12:22.348119 18353 solver.cpp:244]     Train net output #0: accuracy = 0.981321
I0624 14:12:22.348125 18353 solver.cpp:244]     Train net output #1: loss = 0.0478724 (* 1 = 0.0478724 loss)
I0624 14:12:22.348130 18353 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I0624 14:12:36.577867 18353 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_1500.caffemodel
I0624 14:12:36.642369 18353 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_1500.solverstate
I0624 14:12:36.689146 18353 solver.cpp:337] Iteration 1500, Testing net (#0)
I0624 14:12:37.044914 18353 solver.cpp:404]     Test net output #0: accuracy = 0.978975
I0624 14:12:37.044941 18353 solver.cpp:404]     Test net output #1: loss = 0.060757 (* 1 = 0.060757 loss)
I0624 14:12:37.466497 18353 solver.cpp:228] Iteration 1500, loss = 0.0379697
I0624 14:12:37.466526 18353 solver.cpp:244]     Train net output #0: accuracy = 0.985349
I0624 14:12:37.466534 18353 solver.cpp:244]     Train net output #1: loss = 0.0379697 (* 1 = 0.0379697 loss)
I0624 14:12:37.466539 18353 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0624 14:12:52.099280 18353 solver.cpp:228] Iteration 1520, loss = 0.0380289
I0624 14:12:52.099306 18353 solver.cpp:244]     Train net output #0: accuracy = 0.985502
I0624 14:12:52.099313 18353 solver.cpp:244]     Train net output #1: loss = 0.0380289 (* 1 = 0.0380289 loss)
I0624 14:12:52.099318 18353 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I0624 14:13:06.732216 18353 solver.cpp:228] Iteration 1540, loss = 0.0412049
I0624 14:13:06.732318 18353 solver.cpp:244]     Train net output #0: accuracy = 0.984427
I0624 14:13:06.732328 18353 solver.cpp:244]     Train net output #1: loss = 0.0412049 (* 1 = 0.0412049 loss)
I0624 14:13:06.732333 18353 sgd_solver.cpp:106] Iteration 1540, lr = 0.01
I0624 14:13:21.346871 18353 solver.cpp:228] Iteration 1560, loss = 0.0373822
I0624 14:13:21.346895 18353 solver.cpp:244]     Train net output #0: accuracy = 0.985454
I0624 14:13:21.346902 18353 solver.cpp:244]     Train net output #1: loss = 0.0373822 (* 1 = 0.0373822 loss)
I0624 14:13:21.346907 18353 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I0624 14:13:35.968839 18353 solver.cpp:228] Iteration 1580, loss = 0.039261
I0624 14:13:35.968863 18353 solver.cpp:244]     Train net output #0: accuracy = 0.984336
I0624 14:13:35.968871 18353 solver.cpp:244]     Train net output #1: loss = 0.039261 (* 1 = 0.039261 loss)
I0624 14:13:35.968876 18353 sgd_solver.cpp:106] Iteration 1580, lr = 0.01
I0624 14:13:50.175360 18353 solver.cpp:337] Iteration 1600, Testing net (#0)
I0624 14:13:50.511725 18353 solver.cpp:404]     Test net output #0: accuracy = 0.971328
I0624 14:13:50.511760 18353 solver.cpp:404]     Test net output #1: loss = 0.0877981 (* 1 = 0.0877981 loss)
I0624 14:13:50.921253 18353 solver.cpp:228] Iteration 1600, loss = 0.0380583
I0624 14:13:50.921278 18353 solver.cpp:244]     Train net output #0: accuracy = 0.984896
I0624 14:13:50.921285 18353 solver.cpp:244]     Train net output #1: loss = 0.0380583 (* 1 = 0.0380583 loss)
I0624 14:13:50.921290 18353 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0624 14:14:05.545501 18353 solver.cpp:228] Iteration 1620, loss = 0.0395639
I0624 14:14:05.545526 18353 solver.cpp:244]     Train net output #0: accuracy = 0.985533
I0624 14:14:05.545533 18353 solver.cpp:244]     Train net output #1: loss = 0.0395639 (* 1 = 0.0395639 loss)
I0624 14:14:05.545538 18353 sgd_solver.cpp:106] Iteration 1620, lr = 0.01
I0624 14:14:20.177366 18353 solver.cpp:228] Iteration 1640, loss = 0.0411933
I0624 14:14:20.177482 18353 solver.cpp:244]     Train net output #0: accuracy = 0.985011
I0624 14:14:20.177491 18353 solver.cpp:244]     Train net output #1: loss = 0.0411933 (* 1 = 0.0411933 loss)
I0624 14:14:20.177496 18353 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I0624 14:14:34.822425 18353 solver.cpp:228] Iteration 1660, loss = 0.0393753
I0624 14:14:34.822460 18353 solver.cpp:244]     Train net output #0: accuracy = 0.984305
I0624 14:14:34.822468 18353 solver.cpp:244]     Train net output #1: loss = 0.0393753 (* 1 = 0.0393753 loss)
I0624 14:14:34.822471 18353 sgd_solver.cpp:106] Iteration 1660, lr = 0.01
I0624 14:14:49.453811 18353 solver.cpp:228] Iteration 1680, loss = 0.0354045
I0624 14:14:49.453836 18353 solver.cpp:244]     Train net output #0: accuracy = 0.986833
I0624 14:14:49.453845 18353 solver.cpp:244]     Train net output #1: loss = 0.0354045 (* 1 = 0.0354045 loss)
I0624 14:14:49.453850 18353 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I0624 14:15:03.681876 18353 solver.cpp:337] Iteration 1700, Testing net (#0)
I0624 14:15:04.018290 18353 solver.cpp:404]     Test net output #0: accuracy = 0.979318
I0624 14:15:04.018323 18353 solver.cpp:404]     Test net output #1: loss = 0.0570952 (* 1 = 0.0570952 loss)
I0624 14:15:04.428544 18353 solver.cpp:228] Iteration 1700, loss = 0.0378261
I0624 14:15:04.428567 18353 solver.cpp:244]     Train net output #0: accuracy = 0.98534
I0624 14:15:04.428575 18353 solver.cpp:244]     Train net output #1: loss = 0.0378261 (* 1 = 0.0378261 loss)
I0624 14:15:04.428580 18353 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0624 14:15:19.067670 18353 solver.cpp:228] Iteration 1720, loss = 0.0363023
I0624 14:15:19.067706 18353 solver.cpp:244]     Train net output #0: accuracy = 0.986233
I0624 14:15:19.067714 18353 solver.cpp:244]     Train net output #1: loss = 0.0363023 (* 1 = 0.0363023 loss)
I0624 14:15:19.067719 18353 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I0624 14:15:33.707140 18353 solver.cpp:228] Iteration 1740, loss = 0.0383459
I0624 14:15:33.707247 18353 solver.cpp:244]     Train net output #0: accuracy = 0.985731
I0624 14:15:33.707255 18353 solver.cpp:244]     Train net output #1: loss = 0.0383459 (* 1 = 0.0383459 loss)
I0624 14:15:33.707260 18353 sgd_solver.cpp:106] Iteration 1740, lr = 0.01
I0624 14:15:48.350531 18353 solver.cpp:228] Iteration 1760, loss = 0.0368736
I0624 14:15:48.350567 18353 solver.cpp:244]     Train net output #0: accuracy = 0.985698
I0624 14:15:48.350574 18353 solver.cpp:244]     Train net output #1: loss = 0.0368736 (* 1 = 0.0368736 loss)
I0624 14:15:48.350579 18353 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I0624 14:16:02.997864 18353 solver.cpp:228] Iteration 1780, loss = 0.0323696
I0624 14:16:02.997896 18353 solver.cpp:244]     Train net output #0: accuracy = 0.988004
I0624 14:16:02.997905 18353 solver.cpp:244]     Train net output #1: loss = 0.0323696 (* 1 = 0.0323696 loss)
I0624 14:16:02.997908 18353 sgd_solver.cpp:106] Iteration 1780, lr = 0.01
I0624 14:16:17.227628 18353 solver.cpp:337] Iteration 1800, Testing net (#0)
I0624 14:16:17.564254 18353 solver.cpp:404]     Test net output #0: accuracy = 0.981612
I0624 14:16:17.564287 18353 solver.cpp:404]     Test net output #1: loss = 0.0441892 (* 1 = 0.0441892 loss)
I0624 14:16:17.973635 18353 solver.cpp:228] Iteration 1800, loss = 0.0353707
I0624 14:16:17.973670 18353 solver.cpp:244]     Train net output #0: accuracy = 0.986
I0624 14:16:17.973676 18353 solver.cpp:244]     Train net output #1: loss = 0.0353707 (* 1 = 0.0353707 loss)
I0624 14:16:17.973680 18353 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0624 14:16:32.612193 18353 solver.cpp:228] Iteration 1820, loss = 0.0354224
I0624 14:16:32.612229 18353 solver.cpp:244]     Train net output #0: accuracy = 0.986203
I0624 14:16:32.612236 18353 solver.cpp:244]     Train net output #1: loss = 0.0354224 (* 1 = 0.0354224 loss)
I0624 14:16:32.612241 18353 sgd_solver.cpp:106] Iteration 1820, lr = 0.01
I0624 14:16:47.246500 18353 solver.cpp:228] Iteration 1840, loss = 0.032245
I0624 14:16:47.246610 18353 solver.cpp:244]     Train net output #0: accuracy = 0.988051
I0624 14:16:47.246620 18353 solver.cpp:244]     Train net output #1: loss = 0.032245 (* 1 = 0.032245 loss)
I0624 14:16:47.246625 18353 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I0624 14:17:01.872440 18353 solver.cpp:228] Iteration 1860, loss = 0.0344382
I0624 14:17:01.872463 18353 solver.cpp:244]     Train net output #0: accuracy = 0.987042
I0624 14:17:01.872470 18353 solver.cpp:244]     Train net output #1: loss = 0.0344382 (* 1 = 0.0344382 loss)
I0624 14:17:01.872475 18353 sgd_solver.cpp:106] Iteration 1860, lr = 0.01
I0624 14:17:16.503384 18353 solver.cpp:228] Iteration 1880, loss = 0.0424625
I0624 14:17:16.503407 18353 solver.cpp:244]     Train net output #0: accuracy = 0.986786
I0624 14:17:16.503414 18353 solver.cpp:244]     Train net output #1: loss = 0.0424625 (* 1 = 0.0424625 loss)
I0624 14:17:16.503419 18353 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I0624 14:17:30.721786 18353 solver.cpp:337] Iteration 1900, Testing net (#0)
I0624 14:17:31.058409 18353 solver.cpp:404]     Test net output #0: accuracy = 0.9802
I0624 14:17:31.058434 18353 solver.cpp:404]     Test net output #1: loss = 0.0526123 (* 1 = 0.0526123 loss)
I0624 14:17:31.469099 18353 solver.cpp:228] Iteration 1900, loss = 0.0359345
I0624 14:17:31.469125 18353 solver.cpp:244]     Train net output #0: accuracy = 0.987274
I0624 14:17:31.469131 18353 solver.cpp:244]     Train net output #1: loss = 0.0359345 (* 1 = 0.0359345 loss)
I0624 14:17:31.469136 18353 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0624 14:17:46.100793 18353 solver.cpp:228] Iteration 1920, loss = 0.0330293
I0624 14:17:46.100816 18353 solver.cpp:244]     Train net output #0: accuracy = 0.987419
I0624 14:17:46.100823 18353 solver.cpp:244]     Train net output #1: loss = 0.0330293 (* 1 = 0.0330293 loss)
I0624 14:17:46.100828 18353 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I0624 14:18:00.743013 18353 solver.cpp:228] Iteration 1940, loss = 0.0329473
I0624 14:18:00.743127 18353 solver.cpp:244]     Train net output #0: accuracy = 0.986966
I0624 14:18:00.743139 18353 solver.cpp:244]     Train net output #1: loss = 0.0329473 (* 1 = 0.0329473 loss)
I0624 14:18:00.743144 18353 sgd_solver.cpp:106] Iteration 1940, lr = 0.01
I0624 14:18:15.376183 18353 solver.cpp:228] Iteration 1960, loss = 0.031651
I0624 14:18:15.376206 18353 solver.cpp:244]     Train net output #0: accuracy = 0.987665
I0624 14:18:15.376214 18353 solver.cpp:244]     Train net output #1: loss = 0.031651 (* 1 = 0.031651 loss)
I0624 14:18:15.376219 18353 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I0624 14:18:30.009703 18353 solver.cpp:228] Iteration 1980, loss = 0.0346759
I0624 14:18:30.009727 18353 solver.cpp:244]     Train net output #0: accuracy = 0.986469
I0624 14:18:30.009734 18353 solver.cpp:244]     Train net output #1: loss = 0.0346759 (* 1 = 0.0346759 loss)
I0624 14:18:30.009738 18353 sgd_solver.cpp:106] Iteration 1980, lr = 0.01
I0624 14:18:44.246991 18353 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_2000.caffemodel
I0624 14:18:44.293891 18353 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_2000.solverstate
I0624 14:18:44.653373 18353 solver.cpp:317] Iteration 2000, loss = 0.0353529
I0624 14:18:44.653396 18353 solver.cpp:337] Iteration 2000, Testing net (#0)
I0624 14:18:44.991438 18353 solver.cpp:404]     Test net output #0: accuracy = 0.977843
I0624 14:18:44.991461 18353 solver.cpp:404]     Test net output #1: loss = 0.0576193 (* 1 = 0.0576193 loss)
I0624 14:18:44.991466 18353 solver.cpp:322] Optimization Done.
I0624 14:18:44.991468 18353 caffe.cpp:222] Optimization Done.
I0624 14:20:05.943852 18728 caffe.cpp:185] Using GPUs 1
I0624 14:20:05.959584 18728 caffe.cpp:190] GPU 1: GeForce GTX TITAN X
I0624 14:20:06.313060 18728 solver.cpp:48] Initializing solver from parameters: 
test_iter: 16
test_interval: 100
base_lr: 0.01
display: 20
max_iter: 4000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 500
snapshot_prefix: "data/models/segnet"
solver_mode: GPU
device_id: 1
net: "models/segnet/train_val.prototxt"
test_initialization: true
iter_size: 1
I0624 14:20:06.313172 18728 solver.cpp:91] Creating training net from net file: models/segnet/train_val.prototxt
I0624 14:20:06.314604 18728 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0624 14:20:06.315026 18728 net.cpp:49] Initializing net from parameters: 
name: "segnet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "DenseImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 224
    mean_value: 100
  }
  dense_image_data_param {
    source: "data/train_seg.txt"
    batch_size: 32
    shuffle: true
    new_height: 224
    new_width: 310
    is_color: false
    root_folder: "data/raw/train/"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 14
    upsample_w: 14
  }
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2_D"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2_D"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1_D"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1_D"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 28
    upsample_w: 28
  }
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2_D"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2_D"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1_D"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1_D"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
    upsample_h: 56
    upsample_w: 56
  }
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn3_2_D"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2_D"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1_D"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1_D"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
    upsample_h: 112
    upsample_w: 112
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2_D"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2_D"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1_D"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1_D"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
    upsample_h: 224
    upsample_w: 224
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2_D"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2_D"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2
    bias_term: true
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "accuracy"
}
I0624 14:20:06.315304 18728 layer_factory.hpp:77] Creating layer data
I0624 14:20:06.315336 18728 net.cpp:91] Creating Layer data
I0624 14:20:06.315341 18728 net.cpp:399] data -> data
I0624 14:20:06.315361 18728 net.cpp:399] data -> label
I0624 14:20:06.315675 18728 dense_image_data_layer.cpp:38] Opening file data/train_seg.txt
I0624 14:20:06.316576 18728 dense_image_data_layer.cpp:48] Shuffling data
I0624 14:20:06.316787 18728 dense_image_data_layer.cpp:53] A total of 2024 examples.
I0624 14:20:06.566215 18728 dense_image_data_layer.cpp:92] output data size: 1,1,224,224
I0624 14:20:06.568034 18728 net.cpp:141] Setting up data
I0624 14:20:06.568053 18728 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 14:20:06.568058 18728 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 14:20:06.568059 18728 net.cpp:156] Memory required for data: 401408
I0624 14:20:06.568066 18728 layer_factory.hpp:77] Creating layer label_data_1_split
I0624 14:20:06.568080 18728 net.cpp:91] Creating Layer label_data_1_split
I0624 14:20:06.568084 18728 net.cpp:425] label_data_1_split <- label
I0624 14:20:06.568094 18728 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0624 14:20:06.568102 18728 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0624 14:20:06.568183 18728 net.cpp:141] Setting up label_data_1_split
I0624 14:20:06.568192 18728 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 14:20:06.568194 18728 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 14:20:06.568197 18728 net.cpp:156] Memory required for data: 802816
I0624 14:20:06.568198 18728 layer_factory.hpp:77] Creating layer conv1_1
I0624 14:20:06.568213 18728 net.cpp:91] Creating Layer conv1_1
I0624 14:20:06.568218 18728 net.cpp:425] conv1_1 <- data
I0624 14:20:06.568223 18728 net.cpp:399] conv1_1 -> conv1_1
I0624 14:20:06.755383 18728 net.cpp:141] Setting up conv1_1
I0624 14:20:06.755409 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.755411 18728 net.cpp:156] Memory required for data: 7225344
I0624 14:20:06.755424 18728 layer_factory.hpp:77] Creating layer bn1_1
I0624 14:20:06.755439 18728 net.cpp:91] Creating Layer bn1_1
I0624 14:20:06.755444 18728 net.cpp:425] bn1_1 <- conv1_1
I0624 14:20:06.755448 18728 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0624 14:20:06.755633 18728 net.cpp:141] Setting up bn1_1
I0624 14:20:06.755641 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.755645 18728 net.cpp:156] Memory required for data: 13647872
I0624 14:20:06.755652 18728 layer_factory.hpp:77] Creating layer scale1_1
I0624 14:20:06.755661 18728 net.cpp:91] Creating Layer scale1_1
I0624 14:20:06.755664 18728 net.cpp:425] scale1_1 <- conv1_1
I0624 14:20:06.755667 18728 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0624 14:20:06.755702 18728 layer_factory.hpp:77] Creating layer scale1_1
I0624 14:20:06.755859 18728 net.cpp:141] Setting up scale1_1
I0624 14:20:06.755867 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.755869 18728 net.cpp:156] Memory required for data: 20070400
I0624 14:20:06.755875 18728 layer_factory.hpp:77] Creating layer relu1_1
I0624 14:20:06.755880 18728 net.cpp:91] Creating Layer relu1_1
I0624 14:20:06.755883 18728 net.cpp:425] relu1_1 <- conv1_1
I0624 14:20:06.755887 18728 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0624 14:20:06.756150 18728 net.cpp:141] Setting up relu1_1
I0624 14:20:06.756161 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.756163 18728 net.cpp:156] Memory required for data: 26492928
I0624 14:20:06.756166 18728 layer_factory.hpp:77] Creating layer conv1_2
I0624 14:20:06.756175 18728 net.cpp:91] Creating Layer conv1_2
I0624 14:20:06.756177 18728 net.cpp:425] conv1_2 <- conv1_1
I0624 14:20:06.756182 18728 net.cpp:399] conv1_2 -> conv1_2
I0624 14:20:06.757727 18728 net.cpp:141] Setting up conv1_2
I0624 14:20:06.757740 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.757742 18728 net.cpp:156] Memory required for data: 32915456
I0624 14:20:06.757746 18728 layer_factory.hpp:77] Creating layer bn1_2
I0624 14:20:06.757752 18728 net.cpp:91] Creating Layer bn1_2
I0624 14:20:06.757755 18728 net.cpp:425] bn1_2 <- conv1_2
I0624 14:20:06.757760 18728 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0624 14:20:06.757932 18728 net.cpp:141] Setting up bn1_2
I0624 14:20:06.757941 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.757942 18728 net.cpp:156] Memory required for data: 39337984
I0624 14:20:06.757951 18728 layer_factory.hpp:77] Creating layer scale1_2
I0624 14:20:06.757972 18728 net.cpp:91] Creating Layer scale1_2
I0624 14:20:06.757974 18728 net.cpp:425] scale1_2 <- conv1_2
I0624 14:20:06.757978 18728 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0624 14:20:06.758010 18728 layer_factory.hpp:77] Creating layer scale1_2
I0624 14:20:06.758167 18728 net.cpp:141] Setting up scale1_2
I0624 14:20:06.758173 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.758175 18728 net.cpp:156] Memory required for data: 45760512
I0624 14:20:06.758180 18728 layer_factory.hpp:77] Creating layer relu1_2
I0624 14:20:06.758184 18728 net.cpp:91] Creating Layer relu1_2
I0624 14:20:06.758188 18728 net.cpp:425] relu1_2 <- conv1_2
I0624 14:20:06.758190 18728 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0624 14:20:06.758322 18728 net.cpp:141] Setting up relu1_2
I0624 14:20:06.758330 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.758333 18728 net.cpp:156] Memory required for data: 52183040
I0624 14:20:06.758335 18728 layer_factory.hpp:77] Creating layer pool1
I0624 14:20:06.758338 18728 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 14:20:06.758343 18728 net.cpp:91] Creating Layer pool1
I0624 14:20:06.758345 18728 net.cpp:425] pool1 <- conv1_2
I0624 14:20:06.758349 18728 net.cpp:399] pool1 -> pool1
I0624 14:20:06.758357 18728 net.cpp:399] pool1 -> pool1_mask
I0624 14:20:06.758399 18728 net.cpp:141] Setting up pool1
I0624 14:20:06.758404 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.758405 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.758407 18728 net.cpp:156] Memory required for data: 55394304
I0624 14:20:06.758410 18728 layer_factory.hpp:77] Creating layer conv2_1
I0624 14:20:06.758417 18728 net.cpp:91] Creating Layer conv2_1
I0624 14:20:06.758419 18728 net.cpp:425] conv2_1 <- pool1
I0624 14:20:06.758424 18728 net.cpp:399] conv2_1 -> conv2_1
I0624 14:20:06.760037 18728 net.cpp:141] Setting up conv2_1
I0624 14:20:06.760049 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.760052 18728 net.cpp:156] Memory required for data: 58605568
I0624 14:20:06.760057 18728 layer_factory.hpp:77] Creating layer bn2_1
I0624 14:20:06.760063 18728 net.cpp:91] Creating Layer bn2_1
I0624 14:20:06.760066 18728 net.cpp:425] bn2_1 <- conv2_1
I0624 14:20:06.760071 18728 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0624 14:20:06.760227 18728 net.cpp:141] Setting up bn2_1
I0624 14:20:06.760236 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.760238 18728 net.cpp:156] Memory required for data: 61816832
I0624 14:20:06.760243 18728 layer_factory.hpp:77] Creating layer scale2_1
I0624 14:20:06.760249 18728 net.cpp:91] Creating Layer scale2_1
I0624 14:20:06.760251 18728 net.cpp:425] scale2_1 <- conv2_1
I0624 14:20:06.760257 18728 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0624 14:20:06.760293 18728 layer_factory.hpp:77] Creating layer scale2_1
I0624 14:20:06.760392 18728 net.cpp:141] Setting up scale2_1
I0624 14:20:06.760401 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.760402 18728 net.cpp:156] Memory required for data: 65028096
I0624 14:20:06.760411 18728 layer_factory.hpp:77] Creating layer relu2_1
I0624 14:20:06.760416 18728 net.cpp:91] Creating Layer relu2_1
I0624 14:20:06.760417 18728 net.cpp:425] relu2_1 <- conv2_1
I0624 14:20:06.760421 18728 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0624 14:20:06.760691 18728 net.cpp:141] Setting up relu2_1
I0624 14:20:06.760702 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.760705 18728 net.cpp:156] Memory required for data: 68239360
I0624 14:20:06.760709 18728 layer_factory.hpp:77] Creating layer conv2_2
I0624 14:20:06.760716 18728 net.cpp:91] Creating Layer conv2_2
I0624 14:20:06.760720 18728 net.cpp:425] conv2_2 <- conv2_1
I0624 14:20:06.760723 18728 net.cpp:399] conv2_2 -> conv2_2
I0624 14:20:06.761735 18728 net.cpp:141] Setting up conv2_2
I0624 14:20:06.761746 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.761759 18728 net.cpp:156] Memory required for data: 71450624
I0624 14:20:06.761764 18728 layer_factory.hpp:77] Creating layer bn2_2
I0624 14:20:06.761771 18728 net.cpp:91] Creating Layer bn2_2
I0624 14:20:06.761775 18728 net.cpp:425] bn2_2 <- conv2_2
I0624 14:20:06.761780 18728 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0624 14:20:06.761934 18728 net.cpp:141] Setting up bn2_2
I0624 14:20:06.761940 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.761942 18728 net.cpp:156] Memory required for data: 74661888
I0624 14:20:06.761948 18728 layer_factory.hpp:77] Creating layer scale2_2
I0624 14:20:06.761955 18728 net.cpp:91] Creating Layer scale2_2
I0624 14:20:06.761958 18728 net.cpp:425] scale2_2 <- conv2_2
I0624 14:20:06.761961 18728 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0624 14:20:06.761993 18728 layer_factory.hpp:77] Creating layer scale2_2
I0624 14:20:06.762089 18728 net.cpp:141] Setting up scale2_2
I0624 14:20:06.762095 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.762097 18728 net.cpp:156] Memory required for data: 77873152
I0624 14:20:06.762101 18728 layer_factory.hpp:77] Creating layer relu2_2
I0624 14:20:06.762106 18728 net.cpp:91] Creating Layer relu2_2
I0624 14:20:06.762109 18728 net.cpp:425] relu2_2 <- conv2_2
I0624 14:20:06.762115 18728 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0624 14:20:06.762380 18728 net.cpp:141] Setting up relu2_2
I0624 14:20:06.762390 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.762393 18728 net.cpp:156] Memory required for data: 81084416
I0624 14:20:06.762397 18728 layer_factory.hpp:77] Creating layer pool2
I0624 14:20:06.762399 18728 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 14:20:06.762404 18728 net.cpp:91] Creating Layer pool2
I0624 14:20:06.762408 18728 net.cpp:425] pool2 <- conv2_2
I0624 14:20:06.762411 18728 net.cpp:399] pool2 -> pool2
I0624 14:20:06.762415 18728 net.cpp:399] pool2 -> pool2_mask
I0624 14:20:06.762452 18728 net.cpp:141] Setting up pool2
I0624 14:20:06.762457 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.762460 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.762462 18728 net.cpp:156] Memory required for data: 82690048
I0624 14:20:06.762465 18728 layer_factory.hpp:77] Creating layer conv3_1
I0624 14:20:06.762471 18728 net.cpp:91] Creating Layer conv3_1
I0624 14:20:06.762475 18728 net.cpp:425] conv3_1 <- pool2
I0624 14:20:06.762478 18728 net.cpp:399] conv3_1 -> conv3_1
I0624 14:20:06.764432 18728 net.cpp:141] Setting up conv3_1
I0624 14:20:06.764446 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.764448 18728 net.cpp:156] Memory required for data: 84295680
I0624 14:20:06.764452 18728 layer_factory.hpp:77] Creating layer bn3_1
I0624 14:20:06.764458 18728 net.cpp:91] Creating Layer bn3_1
I0624 14:20:06.764461 18728 net.cpp:425] bn3_1 <- conv3_1
I0624 14:20:06.764466 18728 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0624 14:20:06.765233 18728 net.cpp:141] Setting up bn3_1
I0624 14:20:06.765244 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.765245 18728 net.cpp:156] Memory required for data: 85901312
I0624 14:20:06.765251 18728 layer_factory.hpp:77] Creating layer scale3_1
I0624 14:20:06.765257 18728 net.cpp:91] Creating Layer scale3_1
I0624 14:20:06.765260 18728 net.cpp:425] scale3_1 <- conv3_1
I0624 14:20:06.765270 18728 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0624 14:20:06.765305 18728 layer_factory.hpp:77] Creating layer scale3_1
I0624 14:20:06.765393 18728 net.cpp:141] Setting up scale3_1
I0624 14:20:06.765400 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.765403 18728 net.cpp:156] Memory required for data: 87506944
I0624 14:20:06.765406 18728 layer_factory.hpp:77] Creating layer relu3_1
I0624 14:20:06.765411 18728 net.cpp:91] Creating Layer relu3_1
I0624 14:20:06.765413 18728 net.cpp:425] relu3_1 <- conv3_1
I0624 14:20:06.765418 18728 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0624 14:20:06.765561 18728 net.cpp:141] Setting up relu3_1
I0624 14:20:06.765570 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.765581 18728 net.cpp:156] Memory required for data: 89112576
I0624 14:20:06.765584 18728 layer_factory.hpp:77] Creating layer conv3_2
I0624 14:20:06.765594 18728 net.cpp:91] Creating Layer conv3_2
I0624 14:20:06.765595 18728 net.cpp:425] conv3_2 <- conv3_1
I0624 14:20:06.765600 18728 net.cpp:399] conv3_2 -> conv3_2
I0624 14:20:06.767554 18728 net.cpp:141] Setting up conv3_2
I0624 14:20:06.767566 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.767570 18728 net.cpp:156] Memory required for data: 90718208
I0624 14:20:06.767573 18728 layer_factory.hpp:77] Creating layer bn3_2
I0624 14:20:06.767581 18728 net.cpp:91] Creating Layer bn3_2
I0624 14:20:06.767583 18728 net.cpp:425] bn3_2 <- conv3_2
I0624 14:20:06.767590 18728 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0624 14:20:06.767782 18728 net.cpp:141] Setting up bn3_2
I0624 14:20:06.767796 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.767798 18728 net.cpp:156] Memory required for data: 92323840
I0624 14:20:06.767812 18728 layer_factory.hpp:77] Creating layer scale3_2
I0624 14:20:06.767817 18728 net.cpp:91] Creating Layer scale3_2
I0624 14:20:06.767820 18728 net.cpp:425] scale3_2 <- conv3_2
I0624 14:20:06.767824 18728 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0624 14:20:06.767860 18728 layer_factory.hpp:77] Creating layer scale3_2
I0624 14:20:06.767956 18728 net.cpp:141] Setting up scale3_2
I0624 14:20:06.767962 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.767964 18728 net.cpp:156] Memory required for data: 93929472
I0624 14:20:06.767969 18728 layer_factory.hpp:77] Creating layer relu3_2
I0624 14:20:06.767973 18728 net.cpp:91] Creating Layer relu3_2
I0624 14:20:06.767976 18728 net.cpp:425] relu3_2 <- conv3_2
I0624 14:20:06.767981 18728 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0624 14:20:06.768259 18728 net.cpp:141] Setting up relu3_2
I0624 14:20:06.768270 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.768272 18728 net.cpp:156] Memory required for data: 95535104
I0624 14:20:06.768275 18728 layer_factory.hpp:77] Creating layer pool3
I0624 14:20:06.768277 18728 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 14:20:06.768282 18728 net.cpp:91] Creating Layer pool3
I0624 14:20:06.768285 18728 net.cpp:425] pool3 <- conv3_2
I0624 14:20:06.768290 18728 net.cpp:399] pool3 -> pool3
I0624 14:20:06.768296 18728 net.cpp:399] pool3 -> pool3_mask
I0624 14:20:06.768332 18728 net.cpp:141] Setting up pool3
I0624 14:20:06.768338 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.768342 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.768343 18728 net.cpp:156] Memory required for data: 96337920
I0624 14:20:06.768345 18728 layer_factory.hpp:77] Creating layer conv4_1
I0624 14:20:06.768353 18728 net.cpp:91] Creating Layer conv4_1
I0624 14:20:06.768355 18728 net.cpp:425] conv4_1 <- pool3
I0624 14:20:06.768359 18728 net.cpp:399] conv4_1 -> conv4_1
I0624 14:20:06.772145 18728 net.cpp:141] Setting up conv4_1
I0624 14:20:06.772161 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.772163 18728 net.cpp:156] Memory required for data: 97140736
I0624 14:20:06.772168 18728 layer_factory.hpp:77] Creating layer bn4_1
I0624 14:20:06.772174 18728 net.cpp:91] Creating Layer bn4_1
I0624 14:20:06.772176 18728 net.cpp:425] bn4_1 <- conv4_1
I0624 14:20:06.772183 18728 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0624 14:20:06.772346 18728 net.cpp:141] Setting up bn4_1
I0624 14:20:06.772354 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.772357 18728 net.cpp:156] Memory required for data: 97943552
I0624 14:20:06.772363 18728 layer_factory.hpp:77] Creating layer scale4_1
I0624 14:20:06.772369 18728 net.cpp:91] Creating Layer scale4_1
I0624 14:20:06.772372 18728 net.cpp:425] scale4_1 <- conv4_1
I0624 14:20:06.772375 18728 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0624 14:20:06.772409 18728 layer_factory.hpp:77] Creating layer scale4_1
I0624 14:20:06.772501 18728 net.cpp:141] Setting up scale4_1
I0624 14:20:06.772518 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.772521 18728 net.cpp:156] Memory required for data: 98746368
I0624 14:20:06.772526 18728 layer_factory.hpp:77] Creating layer relu4_1
I0624 14:20:06.772533 18728 net.cpp:91] Creating Layer relu4_1
I0624 14:20:06.772536 18728 net.cpp:425] relu4_1 <- conv4_1
I0624 14:20:06.772541 18728 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0624 14:20:06.772822 18728 net.cpp:141] Setting up relu4_1
I0624 14:20:06.772835 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.772837 18728 net.cpp:156] Memory required for data: 99549184
I0624 14:20:06.772840 18728 layer_factory.hpp:77] Creating layer conv4_2
I0624 14:20:06.772848 18728 net.cpp:91] Creating Layer conv4_2
I0624 14:20:06.772851 18728 net.cpp:425] conv4_2 <- conv4_1
I0624 14:20:06.772856 18728 net.cpp:399] conv4_2 -> conv4_2
I0624 14:20:06.778498 18728 net.cpp:141] Setting up conv4_2
I0624 14:20:06.778511 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.778513 18728 net.cpp:156] Memory required for data: 100352000
I0624 14:20:06.778518 18728 layer_factory.hpp:77] Creating layer bn4_2
I0624 14:20:06.778527 18728 net.cpp:91] Creating Layer bn4_2
I0624 14:20:06.778528 18728 net.cpp:425] bn4_2 <- conv4_2
I0624 14:20:06.778532 18728 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0624 14:20:06.778694 18728 net.cpp:141] Setting up bn4_2
I0624 14:20:06.778702 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.778704 18728 net.cpp:156] Memory required for data: 101154816
I0624 14:20:06.778710 18728 layer_factory.hpp:77] Creating layer scale4_2
I0624 14:20:06.778717 18728 net.cpp:91] Creating Layer scale4_2
I0624 14:20:06.778720 18728 net.cpp:425] scale4_2 <- conv4_2
I0624 14:20:06.778724 18728 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0624 14:20:06.778758 18728 layer_factory.hpp:77] Creating layer scale4_2
I0624 14:20:06.778852 18728 net.cpp:141] Setting up scale4_2
I0624 14:20:06.778859 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.778861 18728 net.cpp:156] Memory required for data: 101957632
I0624 14:20:06.778866 18728 layer_factory.hpp:77] Creating layer relu4_2
I0624 14:20:06.778870 18728 net.cpp:91] Creating Layer relu4_2
I0624 14:20:06.778873 18728 net.cpp:425] relu4_2 <- conv4_2
I0624 14:20:06.778877 18728 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0624 14:20:06.779021 18728 net.cpp:141] Setting up relu4_2
I0624 14:20:06.779031 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.779032 18728 net.cpp:156] Memory required for data: 102760448
I0624 14:20:06.779036 18728 layer_factory.hpp:77] Creating layer pool4
I0624 14:20:06.779038 18728 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 14:20:06.779043 18728 net.cpp:91] Creating Layer pool4
I0624 14:20:06.779045 18728 net.cpp:425] pool4 <- conv4_2
I0624 14:20:06.779050 18728 net.cpp:399] pool4 -> pool4
I0624 14:20:06.779055 18728 net.cpp:399] pool4 -> pool4_mask
I0624 14:20:06.779094 18728 net.cpp:141] Setting up pool4
I0624 14:20:06.779099 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.779101 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.779103 18728 net.cpp:156] Memory required for data: 103161856
I0624 14:20:06.779106 18728 layer_factory.hpp:77] Creating layer conv5_1
I0624 14:20:06.779114 18728 net.cpp:91] Creating Layer conv5_1
I0624 14:20:06.779117 18728 net.cpp:425] conv5_1 <- pool4
I0624 14:20:06.779121 18728 net.cpp:399] conv5_1 -> conv5_1
I0624 14:20:06.784559 18728 net.cpp:141] Setting up conv5_1
I0624 14:20:06.784572 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.784574 18728 net.cpp:156] Memory required for data: 103362560
I0624 14:20:06.784579 18728 layer_factory.hpp:77] Creating layer bn5_1
I0624 14:20:06.784586 18728 net.cpp:91] Creating Layer bn5_1
I0624 14:20:06.784590 18728 net.cpp:425] bn5_1 <- conv5_1
I0624 14:20:06.784595 18728 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0624 14:20:06.784767 18728 net.cpp:141] Setting up bn5_1
I0624 14:20:06.784785 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.784787 18728 net.cpp:156] Memory required for data: 103563264
I0624 14:20:06.784793 18728 layer_factory.hpp:77] Creating layer scale5_1
I0624 14:20:06.784800 18728 net.cpp:91] Creating Layer scale5_1
I0624 14:20:06.784801 18728 net.cpp:425] scale5_1 <- conv5_1
I0624 14:20:06.784808 18728 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0624 14:20:06.784845 18728 layer_factory.hpp:77] Creating layer scale5_1
I0624 14:20:06.784939 18728 net.cpp:141] Setting up scale5_1
I0624 14:20:06.784946 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.784948 18728 net.cpp:156] Memory required for data: 103763968
I0624 14:20:06.784953 18728 layer_factory.hpp:77] Creating layer relu5_1
I0624 14:20:06.784957 18728 net.cpp:91] Creating Layer relu5_1
I0624 14:20:06.784960 18728 net.cpp:425] relu5_1 <- conv5_1
I0624 14:20:06.784965 18728 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0624 14:20:06.785238 18728 net.cpp:141] Setting up relu5_1
I0624 14:20:06.785250 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.785253 18728 net.cpp:156] Memory required for data: 103964672
I0624 14:20:06.785255 18728 layer_factory.hpp:77] Creating layer conv5_2
I0624 14:20:06.785264 18728 net.cpp:91] Creating Layer conv5_2
I0624 14:20:06.785267 18728 net.cpp:425] conv5_2 <- conv5_1
I0624 14:20:06.785271 18728 net.cpp:399] conv5_2 -> conv5_2
I0624 14:20:06.790653 18728 net.cpp:141] Setting up conv5_2
I0624 14:20:06.790669 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.790673 18728 net.cpp:156] Memory required for data: 104165376
I0624 14:20:06.790676 18728 layer_factory.hpp:77] Creating layer bn5_2
I0624 14:20:06.790683 18728 net.cpp:91] Creating Layer bn5_2
I0624 14:20:06.790686 18728 net.cpp:425] bn5_2 <- conv5_2
I0624 14:20:06.790691 18728 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0624 14:20:06.790856 18728 net.cpp:141] Setting up bn5_2
I0624 14:20:06.790863 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.790866 18728 net.cpp:156] Memory required for data: 104366080
I0624 14:20:06.790871 18728 layer_factory.hpp:77] Creating layer scale5_2
I0624 14:20:06.790877 18728 net.cpp:91] Creating Layer scale5_2
I0624 14:20:06.790880 18728 net.cpp:425] scale5_2 <- conv5_2
I0624 14:20:06.790884 18728 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0624 14:20:06.790920 18728 layer_factory.hpp:77] Creating layer scale5_2
I0624 14:20:06.791013 18728 net.cpp:141] Setting up scale5_2
I0624 14:20:06.791019 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.791021 18728 net.cpp:156] Memory required for data: 104566784
I0624 14:20:06.791025 18728 layer_factory.hpp:77] Creating layer relu5_2
I0624 14:20:06.791031 18728 net.cpp:91] Creating Layer relu5_2
I0624 14:20:06.791033 18728 net.cpp:425] relu5_2 <- conv5_2
I0624 14:20:06.791038 18728 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0624 14:20:06.791321 18728 net.cpp:141] Setting up relu5_2
I0624 14:20:06.791332 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.791333 18728 net.cpp:156] Memory required for data: 104767488
I0624 14:20:06.791337 18728 layer_factory.hpp:77] Creating layer pool5
I0624 14:20:06.791339 18728 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 14:20:06.791344 18728 net.cpp:91] Creating Layer pool5
I0624 14:20:06.791348 18728 net.cpp:425] pool5 <- conv5_2
I0624 14:20:06.791352 18728 net.cpp:399] pool5 -> pool5
I0624 14:20:06.791357 18728 net.cpp:399] pool5 -> pool5_mask
I0624 14:20:06.791399 18728 net.cpp:141] Setting up pool5
I0624 14:20:06.791409 18728 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 14:20:06.791412 18728 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 14:20:06.791414 18728 net.cpp:156] Memory required for data: 104867840
I0624 14:20:06.791416 18728 layer_factory.hpp:77] Creating layer upsample5
I0624 14:20:06.791422 18728 net.cpp:91] Creating Layer upsample5
I0624 14:20:06.791424 18728 net.cpp:425] upsample5 <- pool5
I0624 14:20:06.791427 18728 net.cpp:425] upsample5 <- pool5_mask
I0624 14:20:06.791443 18728 net.cpp:399] upsample5 -> pool5_D
I0624 14:20:06.791473 18728 net.cpp:141] Setting up upsample5
I0624 14:20:06.791477 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.791479 18728 net.cpp:156] Memory required for data: 105068544
I0624 14:20:06.791481 18728 layer_factory.hpp:77] Creating layer conv5_2_D
I0624 14:20:06.791489 18728 net.cpp:91] Creating Layer conv5_2_D
I0624 14:20:06.791492 18728 net.cpp:425] conv5_2_D <- pool5_D
I0624 14:20:06.791497 18728 net.cpp:399] conv5_2_D -> conv5_2_D
I0624 14:20:06.797046 18728 net.cpp:141] Setting up conv5_2_D
I0624 14:20:06.797058 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.797061 18728 net.cpp:156] Memory required for data: 105269248
I0624 14:20:06.797065 18728 layer_factory.hpp:77] Creating layer bn5_2_D
I0624 14:20:06.797072 18728 net.cpp:91] Creating Layer bn5_2_D
I0624 14:20:06.797075 18728 net.cpp:425] bn5_2_D <- conv5_2_D
I0624 14:20:06.797080 18728 net.cpp:386] bn5_2_D -> conv5_2_D (in-place)
I0624 14:20:06.797256 18728 net.cpp:141] Setting up bn5_2_D
I0624 14:20:06.797263 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.797266 18728 net.cpp:156] Memory required for data: 105469952
I0624 14:20:06.797271 18728 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 14:20:06.797277 18728 net.cpp:91] Creating Layer scale5_2_D
I0624 14:20:06.797281 18728 net.cpp:425] scale5_2_D <- conv5_2_D
I0624 14:20:06.797284 18728 net.cpp:386] scale5_2_D -> conv5_2_D (in-place)
I0624 14:20:06.797319 18728 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 14:20:06.797415 18728 net.cpp:141] Setting up scale5_2_D
I0624 14:20:06.797422 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.797425 18728 net.cpp:156] Memory required for data: 105670656
I0624 14:20:06.797437 18728 layer_factory.hpp:77] Creating layer relu5_2_D
I0624 14:20:06.797444 18728 net.cpp:91] Creating Layer relu5_2_D
I0624 14:20:06.797447 18728 net.cpp:425] relu5_2_D <- conv5_2_D
I0624 14:20:06.797451 18728 net.cpp:386] relu5_2_D -> conv5_2_D (in-place)
I0624 14:20:06.797601 18728 net.cpp:141] Setting up relu5_2_D
I0624 14:20:06.797610 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.797613 18728 net.cpp:156] Memory required for data: 105871360
I0624 14:20:06.797616 18728 layer_factory.hpp:77] Creating layer conv5_1_D
I0624 14:20:06.797626 18728 net.cpp:91] Creating Layer conv5_1_D
I0624 14:20:06.797629 18728 net.cpp:425] conv5_1_D <- conv5_2_D
I0624 14:20:06.797633 18728 net.cpp:399] conv5_1_D -> conv5_1_D
I0624 14:20:06.803158 18728 net.cpp:141] Setting up conv5_1_D
I0624 14:20:06.803171 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.803174 18728 net.cpp:156] Memory required for data: 106072064
I0624 14:20:06.803179 18728 layer_factory.hpp:77] Creating layer bn5_1_D
I0624 14:20:06.803185 18728 net.cpp:91] Creating Layer bn5_1_D
I0624 14:20:06.803189 18728 net.cpp:425] bn5_1_D <- conv5_1_D
I0624 14:20:06.803194 18728 net.cpp:386] bn5_1_D -> conv5_1_D (in-place)
I0624 14:20:06.803375 18728 net.cpp:141] Setting up bn5_1_D
I0624 14:20:06.803382 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.803385 18728 net.cpp:156] Memory required for data: 106272768
I0624 14:20:06.803390 18728 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 14:20:06.803396 18728 net.cpp:91] Creating Layer scale5_1_D
I0624 14:20:06.803398 18728 net.cpp:425] scale5_1_D <- conv5_1_D
I0624 14:20:06.803403 18728 net.cpp:386] scale5_1_D -> conv5_1_D (in-place)
I0624 14:20:06.803442 18728 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 14:20:06.803544 18728 net.cpp:141] Setting up scale5_1_D
I0624 14:20:06.803550 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.803552 18728 net.cpp:156] Memory required for data: 106473472
I0624 14:20:06.803557 18728 layer_factory.hpp:77] Creating layer relu5_1_D
I0624 14:20:06.803561 18728 net.cpp:91] Creating Layer relu5_1_D
I0624 14:20:06.803565 18728 net.cpp:425] relu5_1_D <- conv5_1_D
I0624 14:20:06.803568 18728 net.cpp:386] relu5_1_D -> conv5_1_D (in-place)
I0624 14:20:06.803861 18728 net.cpp:141] Setting up relu5_1_D
I0624 14:20:06.803872 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.803875 18728 net.cpp:156] Memory required for data: 106674176
I0624 14:20:06.803877 18728 layer_factory.hpp:77] Creating layer upsample4
I0624 14:20:06.803884 18728 net.cpp:91] Creating Layer upsample4
I0624 14:20:06.803886 18728 net.cpp:425] upsample4 <- conv5_1_D
I0624 14:20:06.803890 18728 net.cpp:425] upsample4 <- pool4_mask
I0624 14:20:06.803895 18728 net.cpp:399] upsample4 -> pool4_D
I0624 14:20:06.803925 18728 net.cpp:141] Setting up upsample4
I0624 14:20:06.803930 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.803932 18728 net.cpp:156] Memory required for data: 107476992
I0624 14:20:06.803935 18728 layer_factory.hpp:77] Creating layer conv4_2_D
I0624 14:20:06.803941 18728 net.cpp:91] Creating Layer conv4_2_D
I0624 14:20:06.803944 18728 net.cpp:425] conv4_2_D <- pool4_D
I0624 14:20:06.803949 18728 net.cpp:399] conv4_2_D -> conv4_2_D
I0624 14:20:06.809365 18728 net.cpp:141] Setting up conv4_2_D
I0624 14:20:06.809378 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.809381 18728 net.cpp:156] Memory required for data: 108279808
I0624 14:20:06.809386 18728 layer_factory.hpp:77] Creating layer bn4_2_D
I0624 14:20:06.809392 18728 net.cpp:91] Creating Layer bn4_2_D
I0624 14:20:06.809396 18728 net.cpp:425] bn4_2_D <- conv4_2_D
I0624 14:20:06.809401 18728 net.cpp:386] bn4_2_D -> conv4_2_D (in-place)
I0624 14:20:06.809581 18728 net.cpp:141] Setting up bn4_2_D
I0624 14:20:06.809587 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.809590 18728 net.cpp:156] Memory required for data: 109082624
I0624 14:20:06.809595 18728 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 14:20:06.809602 18728 net.cpp:91] Creating Layer scale4_2_D
I0624 14:20:06.809605 18728 net.cpp:425] scale4_2_D <- conv4_2_D
I0624 14:20:06.809608 18728 net.cpp:386] scale4_2_D -> conv4_2_D (in-place)
I0624 14:20:06.809644 18728 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 14:20:06.809743 18728 net.cpp:141] Setting up scale4_2_D
I0624 14:20:06.809751 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.809752 18728 net.cpp:156] Memory required for data: 109885440
I0624 14:20:06.809757 18728 layer_factory.hpp:77] Creating layer relu4_2_D
I0624 14:20:06.809762 18728 net.cpp:91] Creating Layer relu4_2_D
I0624 14:20:06.809763 18728 net.cpp:425] relu4_2_D <- conv4_2_D
I0624 14:20:06.809769 18728 net.cpp:386] relu4_2_D -> conv4_2_D (in-place)
I0624 14:20:06.810048 18728 net.cpp:141] Setting up relu4_2_D
I0624 14:20:06.810060 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.810062 18728 net.cpp:156] Memory required for data: 110688256
I0624 14:20:06.810065 18728 layer_factory.hpp:77] Creating layer conv4_1_D
I0624 14:20:06.810075 18728 net.cpp:91] Creating Layer conv4_1_D
I0624 14:20:06.810076 18728 net.cpp:425] conv4_1_D <- conv4_2_D
I0624 14:20:06.810082 18728 net.cpp:399] conv4_1_D -> conv4_1_D
I0624 14:20:06.813397 18728 net.cpp:141] Setting up conv4_1_D
I0624 14:20:06.813410 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.813411 18728 net.cpp:156] Memory required for data: 111089664
I0624 14:20:06.813417 18728 layer_factory.hpp:77] Creating layer bn4_1_D
I0624 14:20:06.813423 18728 net.cpp:91] Creating Layer bn4_1_D
I0624 14:20:06.813426 18728 net.cpp:425] bn4_1_D <- conv4_1_D
I0624 14:20:06.813431 18728 net.cpp:386] bn4_1_D -> conv4_1_D (in-place)
I0624 14:20:06.813607 18728 net.cpp:141] Setting up bn4_1_D
I0624 14:20:06.813614 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.813617 18728 net.cpp:156] Memory required for data: 111491072
I0624 14:20:06.813622 18728 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 14:20:06.813629 18728 net.cpp:91] Creating Layer scale4_1_D
I0624 14:20:06.813632 18728 net.cpp:425] scale4_1_D <- conv4_1_D
I0624 14:20:06.813635 18728 net.cpp:386] scale4_1_D -> conv4_1_D (in-place)
I0624 14:20:06.813671 18728 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 14:20:06.813784 18728 net.cpp:141] Setting up scale4_1_D
I0624 14:20:06.813792 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.813794 18728 net.cpp:156] Memory required for data: 111892480
I0624 14:20:06.813798 18728 layer_factory.hpp:77] Creating layer relu4_1_D
I0624 14:20:06.813812 18728 net.cpp:91] Creating Layer relu4_1_D
I0624 14:20:06.813815 18728 net.cpp:425] relu4_1_D <- conv4_1_D
I0624 14:20:06.813819 18728 net.cpp:386] relu4_1_D -> conv4_1_D (in-place)
I0624 14:20:06.813972 18728 net.cpp:141] Setting up relu4_1_D
I0624 14:20:06.813980 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.813983 18728 net.cpp:156] Memory required for data: 112293888
I0624 14:20:06.813987 18728 layer_factory.hpp:77] Creating layer upsample3
I0624 14:20:06.813992 18728 net.cpp:91] Creating Layer upsample3
I0624 14:20:06.813995 18728 net.cpp:425] upsample3 <- conv4_1_D
I0624 14:20:06.813998 18728 net.cpp:425] upsample3 <- pool3_mask
I0624 14:20:06.814002 18728 net.cpp:399] upsample3 -> pool3_D
I0624 14:20:06.814029 18728 net.cpp:141] Setting up upsample3
I0624 14:20:06.814034 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.814036 18728 net.cpp:156] Memory required for data: 113899520
I0624 14:20:06.814038 18728 layer_factory.hpp:77] Creating layer conv3_2_D
I0624 14:20:06.814045 18728 net.cpp:91] Creating Layer conv3_2_D
I0624 14:20:06.814049 18728 net.cpp:425] conv3_2_D <- pool3_D
I0624 14:20:06.814054 18728 net.cpp:399] conv3_2_D -> conv3_2_D
I0624 14:20:06.816643 18728 net.cpp:141] Setting up conv3_2_D
I0624 14:20:06.816656 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.816659 18728 net.cpp:156] Memory required for data: 115505152
I0624 14:20:06.816664 18728 layer_factory.hpp:77] Creating layer bn3_2_D
I0624 14:20:06.816679 18728 net.cpp:91] Creating Layer bn3_2_D
I0624 14:20:06.816682 18728 net.cpp:425] bn3_2_D <- conv3_2_D
I0624 14:20:06.816686 18728 net.cpp:386] bn3_2_D -> conv3_2_D (in-place)
I0624 14:20:06.820010 18728 net.cpp:141] Setting up bn3_2_D
I0624 14:20:06.820024 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.820027 18728 net.cpp:156] Memory required for data: 117110784
I0624 14:20:06.820035 18728 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 14:20:06.820044 18728 net.cpp:91] Creating Layer scale3_2_D
I0624 14:20:06.820046 18728 net.cpp:425] scale3_2_D <- conv3_2_D
I0624 14:20:06.820052 18728 net.cpp:386] scale3_2_D -> conv3_2_D (in-place)
I0624 14:20:06.820093 18728 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 14:20:06.820205 18728 net.cpp:141] Setting up scale3_2_D
I0624 14:20:06.820212 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.820214 18728 net.cpp:156] Memory required for data: 118716416
I0624 14:20:06.820219 18728 layer_factory.hpp:77] Creating layer relu3_2_D
I0624 14:20:06.820225 18728 net.cpp:91] Creating Layer relu3_2_D
I0624 14:20:06.820227 18728 net.cpp:425] relu3_2_D <- conv3_2_D
I0624 14:20:06.820230 18728 net.cpp:386] relu3_2_D -> conv3_2_D (in-place)
I0624 14:20:06.823710 18728 net.cpp:141] Setting up relu3_2_D
I0624 14:20:06.823726 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.823729 18728 net.cpp:156] Memory required for data: 120322048
I0624 14:20:06.823734 18728 layer_factory.hpp:77] Creating layer conv3_1_D
I0624 14:20:06.823745 18728 net.cpp:91] Creating Layer conv3_1_D
I0624 14:20:06.823748 18728 net.cpp:425] conv3_1_D <- conv3_2_D
I0624 14:20:06.823755 18728 net.cpp:399] conv3_1_D -> conv3_1_D
I0624 14:20:06.825373 18728 net.cpp:141] Setting up conv3_1_D
I0624 14:20:06.825387 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.825388 18728 net.cpp:156] Memory required for data: 121124864
I0624 14:20:06.825393 18728 layer_factory.hpp:77] Creating layer bn3_1_D
I0624 14:20:06.825399 18728 net.cpp:91] Creating Layer bn3_1_D
I0624 14:20:06.825402 18728 net.cpp:425] bn3_1_D <- conv3_1_D
I0624 14:20:06.825407 18728 net.cpp:386] bn3_1_D -> conv3_1_D (in-place)
I0624 14:20:06.825604 18728 net.cpp:141] Setting up bn3_1_D
I0624 14:20:06.825623 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.825625 18728 net.cpp:156] Memory required for data: 121927680
I0624 14:20:06.825631 18728 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 14:20:06.825639 18728 net.cpp:91] Creating Layer scale3_1_D
I0624 14:20:06.825640 18728 net.cpp:425] scale3_1_D <- conv3_1_D
I0624 14:20:06.825645 18728 net.cpp:386] scale3_1_D -> conv3_1_D (in-place)
I0624 14:20:06.825688 18728 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 14:20:06.825806 18728 net.cpp:141] Setting up scale3_1_D
I0624 14:20:06.825814 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.825816 18728 net.cpp:156] Memory required for data: 122730496
I0624 14:20:06.825820 18728 layer_factory.hpp:77] Creating layer relu3_1_D
I0624 14:20:06.825827 18728 net.cpp:91] Creating Layer relu3_1_D
I0624 14:20:06.825830 18728 net.cpp:425] relu3_1_D <- conv3_1_D
I0624 14:20:06.825834 18728 net.cpp:386] relu3_1_D -> conv3_1_D (in-place)
I0624 14:20:06.826127 18728 net.cpp:141] Setting up relu3_1_D
I0624 14:20:06.826138 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.826140 18728 net.cpp:156] Memory required for data: 123533312
I0624 14:20:06.826143 18728 layer_factory.hpp:77] Creating layer upsample2
I0624 14:20:06.826150 18728 net.cpp:91] Creating Layer upsample2
I0624 14:20:06.826153 18728 net.cpp:425] upsample2 <- conv3_1_D
I0624 14:20:06.826158 18728 net.cpp:425] upsample2 <- pool2_mask
I0624 14:20:06.826160 18728 net.cpp:399] upsample2 -> pool2_D
I0624 14:20:06.826191 18728 net.cpp:141] Setting up upsample2
I0624 14:20:06.826196 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.826198 18728 net.cpp:156] Memory required for data: 126744576
I0624 14:20:06.826200 18728 layer_factory.hpp:77] Creating layer conv2_2_D
I0624 14:20:06.826210 18728 net.cpp:91] Creating Layer conv2_2_D
I0624 14:20:06.826212 18728 net.cpp:425] conv2_2_D <- pool2_D
I0624 14:20:06.826217 18728 net.cpp:399] conv2_2_D -> conv2_2_D
I0624 14:20:06.827476 18728 net.cpp:141] Setting up conv2_2_D
I0624 14:20:06.827487 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.827491 18728 net.cpp:156] Memory required for data: 129955840
I0624 14:20:06.827494 18728 layer_factory.hpp:77] Creating layer bn2_2_D
I0624 14:20:06.827502 18728 net.cpp:91] Creating Layer bn2_2_D
I0624 14:20:06.827504 18728 net.cpp:425] bn2_2_D <- conv2_2_D
I0624 14:20:06.827509 18728 net.cpp:386] bn2_2_D -> conv2_2_D (in-place)
I0624 14:20:06.827709 18728 net.cpp:141] Setting up bn2_2_D
I0624 14:20:06.827718 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.827719 18728 net.cpp:156] Memory required for data: 133167104
I0624 14:20:06.827724 18728 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 14:20:06.827730 18728 net.cpp:91] Creating Layer scale2_2_D
I0624 14:20:06.827733 18728 net.cpp:425] scale2_2_D <- conv2_2_D
I0624 14:20:06.827738 18728 net.cpp:386] scale2_2_D -> conv2_2_D (in-place)
I0624 14:20:06.827775 18728 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 14:20:06.827898 18728 net.cpp:141] Setting up scale2_2_D
I0624 14:20:06.827904 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.827906 18728 net.cpp:156] Memory required for data: 136378368
I0624 14:20:06.827911 18728 layer_factory.hpp:77] Creating layer relu2_2_D
I0624 14:20:06.827916 18728 net.cpp:91] Creating Layer relu2_2_D
I0624 14:20:06.827919 18728 net.cpp:425] relu2_2_D <- conv2_2_D
I0624 14:20:06.827922 18728 net.cpp:386] relu2_2_D -> conv2_2_D (in-place)
I0624 14:20:06.828076 18728 net.cpp:141] Setting up relu2_2_D
I0624 14:20:06.828085 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.828088 18728 net.cpp:156] Memory required for data: 139589632
I0624 14:20:06.828090 18728 layer_factory.hpp:77] Creating layer conv2_1_D
I0624 14:20:06.828100 18728 net.cpp:91] Creating Layer conv2_1_D
I0624 14:20:06.828104 18728 net.cpp:425] conv2_1_D <- conv2_2_D
I0624 14:20:06.828109 18728 net.cpp:399] conv2_1_D -> conv2_1_D
I0624 14:20:06.829138 18728 net.cpp:141] Setting up conv2_1_D
I0624 14:20:06.829157 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.829160 18728 net.cpp:156] Memory required for data: 141195264
I0624 14:20:06.829164 18728 layer_factory.hpp:77] Creating layer bn2_1_D
I0624 14:20:06.829172 18728 net.cpp:91] Creating Layer bn2_1_D
I0624 14:20:06.829174 18728 net.cpp:425] bn2_1_D <- conv2_1_D
I0624 14:20:06.829180 18728 net.cpp:386] bn2_1_D -> conv2_1_D (in-place)
I0624 14:20:06.829376 18728 net.cpp:141] Setting up bn2_1_D
I0624 14:20:06.829383 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.829386 18728 net.cpp:156] Memory required for data: 142800896
I0624 14:20:06.829391 18728 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 14:20:06.829397 18728 net.cpp:91] Creating Layer scale2_1_D
I0624 14:20:06.829399 18728 net.cpp:425] scale2_1_D <- conv2_1_D
I0624 14:20:06.829403 18728 net.cpp:386] scale2_1_D -> conv2_1_D (in-place)
I0624 14:20:06.829442 18728 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 14:20:06.829568 18728 net.cpp:141] Setting up scale2_1_D
I0624 14:20:06.829576 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.829578 18728 net.cpp:156] Memory required for data: 144406528
I0624 14:20:06.829582 18728 layer_factory.hpp:77] Creating layer relu2_1_D
I0624 14:20:06.829588 18728 net.cpp:91] Creating Layer relu2_1_D
I0624 14:20:06.829591 18728 net.cpp:425] relu2_1_D <- conv2_1_D
I0624 14:20:06.829594 18728 net.cpp:386] relu2_1_D -> conv2_1_D (in-place)
I0624 14:20:06.829893 18728 net.cpp:141] Setting up relu2_1_D
I0624 14:20:06.829905 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.829906 18728 net.cpp:156] Memory required for data: 146012160
I0624 14:20:06.829910 18728 layer_factory.hpp:77] Creating layer upsample1
I0624 14:20:06.829916 18728 net.cpp:91] Creating Layer upsample1
I0624 14:20:06.829918 18728 net.cpp:425] upsample1 <- conv2_1_D
I0624 14:20:06.829921 18728 net.cpp:425] upsample1 <- pool1_mask
I0624 14:20:06.829926 18728 net.cpp:399] upsample1 -> pool1_D
I0624 14:20:06.829955 18728 net.cpp:141] Setting up upsample1
I0624 14:20:06.829960 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.829962 18728 net.cpp:156] Memory required for data: 152434688
I0624 14:20:06.829965 18728 layer_factory.hpp:77] Creating layer conv1_2_D
I0624 14:20:06.829973 18728 net.cpp:91] Creating Layer conv1_2_D
I0624 14:20:06.829975 18728 net.cpp:425] conv1_2_D <- pool1_D
I0624 14:20:06.829979 18728 net.cpp:399] conv1_2_D -> conv1_2_D
I0624 14:20:06.830921 18728 net.cpp:141] Setting up conv1_2_D
I0624 14:20:06.830934 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.830936 18728 net.cpp:156] Memory required for data: 158857216
I0624 14:20:06.830940 18728 layer_factory.hpp:77] Creating layer bn1_2_D
I0624 14:20:06.830946 18728 net.cpp:91] Creating Layer bn1_2_D
I0624 14:20:06.830950 18728 net.cpp:425] bn1_2_D <- conv1_2_D
I0624 14:20:06.830956 18728 net.cpp:386] bn1_2_D -> conv1_2_D (in-place)
I0624 14:20:06.831207 18728 net.cpp:141] Setting up bn1_2_D
I0624 14:20:06.831215 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.831218 18728 net.cpp:156] Memory required for data: 165279744
I0624 14:20:06.831224 18728 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 14:20:06.831229 18728 net.cpp:91] Creating Layer scale1_2_D
I0624 14:20:06.831233 18728 net.cpp:425] scale1_2_D <- conv1_2_D
I0624 14:20:06.831238 18728 net.cpp:386] scale1_2_D -> conv1_2_D (in-place)
I0624 14:20:06.831275 18728 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 14:20:06.831465 18728 net.cpp:141] Setting up scale1_2_D
I0624 14:20:06.831473 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.831475 18728 net.cpp:156] Memory required for data: 171702272
I0624 14:20:06.831480 18728 layer_factory.hpp:77] Creating layer relu1_2_D
I0624 14:20:06.831483 18728 net.cpp:91] Creating Layer relu1_2_D
I0624 14:20:06.831486 18728 net.cpp:425] relu1_2_D <- conv1_2_D
I0624 14:20:06.831490 18728 net.cpp:386] relu1_2_D -> conv1_2_D (in-place)
I0624 14:20:06.831840 18728 net.cpp:141] Setting up relu1_2_D
I0624 14:20:06.831852 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.831856 18728 net.cpp:156] Memory required for data: 178124800
I0624 14:20:06.831858 18728 layer_factory.hpp:77] Creating layer conv1_1_D
I0624 14:20:06.831869 18728 net.cpp:91] Creating Layer conv1_1_D
I0624 14:20:06.831873 18728 net.cpp:425] conv1_1_D <- conv1_2_D
I0624 14:20:06.831878 18728 net.cpp:399] conv1_1_D -> conv1_1_D
I0624 14:20:06.833044 18728 net.cpp:141] Setting up conv1_1_D
I0624 14:20:06.833055 18728 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 14:20:06.833058 18728 net.cpp:156] Memory required for data: 178526208
I0624 14:20:06.833063 18728 layer_factory.hpp:77] Creating layer conv1_1_D_conv1_1_D_0_split
I0624 14:20:06.833070 18728 net.cpp:91] Creating Layer conv1_1_D_conv1_1_D_0_split
I0624 14:20:06.833073 18728 net.cpp:425] conv1_1_D_conv1_1_D_0_split <- conv1_1_D
I0624 14:20:06.833077 18728 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_0
I0624 14:20:06.833083 18728 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_1
I0624 14:20:06.833127 18728 net.cpp:141] Setting up conv1_1_D_conv1_1_D_0_split
I0624 14:20:06.833134 18728 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 14:20:06.833137 18728 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 14:20:06.833139 18728 net.cpp:156] Memory required for data: 179329024
I0624 14:20:06.833142 18728 layer_factory.hpp:77] Creating layer loss
I0624 14:20:06.833148 18728 net.cpp:91] Creating Layer loss
I0624 14:20:06.833150 18728 net.cpp:425] loss <- conv1_1_D_conv1_1_D_0_split_0
I0624 14:20:06.833153 18728 net.cpp:425] loss <- label_data_1_split_0
I0624 14:20:06.833156 18728 net.cpp:399] loss -> loss
I0624 14:20:06.833164 18728 layer_factory.hpp:77] Creating layer loss
I0624 14:20:06.834095 18728 net.cpp:141] Setting up loss
I0624 14:20:06.834106 18728 net.cpp:148] Top shape: (1)
I0624 14:20:06.834108 18728 net.cpp:151]     with loss weight 1
I0624 14:20:06.834125 18728 net.cpp:156] Memory required for data: 179329028
I0624 14:20:06.834127 18728 layer_factory.hpp:77] Creating layer accuracy
I0624 14:20:06.834134 18728 net.cpp:91] Creating Layer accuracy
I0624 14:20:06.834136 18728 net.cpp:425] accuracy <- conv1_1_D_conv1_1_D_0_split_1
I0624 14:20:06.834141 18728 net.cpp:425] accuracy <- label_data_1_split_1
I0624 14:20:06.834144 18728 net.cpp:399] accuracy -> accuracy
I0624 14:20:06.834151 18728 net.cpp:141] Setting up accuracy
I0624 14:20:06.834154 18728 net.cpp:148] Top shape: (1)
I0624 14:20:06.834156 18728 net.cpp:156] Memory required for data: 179329032
I0624 14:20:06.834158 18728 net.cpp:219] accuracy does not need backward computation.
I0624 14:20:06.834161 18728 net.cpp:217] loss needs backward computation.
I0624 14:20:06.834164 18728 net.cpp:217] conv1_1_D_conv1_1_D_0_split needs backward computation.
I0624 14:20:06.834167 18728 net.cpp:217] conv1_1_D needs backward computation.
I0624 14:20:06.834169 18728 net.cpp:217] relu1_2_D needs backward computation.
I0624 14:20:06.834172 18728 net.cpp:217] scale1_2_D needs backward computation.
I0624 14:20:06.834173 18728 net.cpp:217] bn1_2_D needs backward computation.
I0624 14:20:06.834175 18728 net.cpp:217] conv1_2_D needs backward computation.
I0624 14:20:06.834177 18728 net.cpp:217] upsample1 needs backward computation.
I0624 14:20:06.834180 18728 net.cpp:217] relu2_1_D needs backward computation.
I0624 14:20:06.834182 18728 net.cpp:217] scale2_1_D needs backward computation.
I0624 14:20:06.834184 18728 net.cpp:217] bn2_1_D needs backward computation.
I0624 14:20:06.834187 18728 net.cpp:217] conv2_1_D needs backward computation.
I0624 14:20:06.834188 18728 net.cpp:217] relu2_2_D needs backward computation.
I0624 14:20:06.834190 18728 net.cpp:217] scale2_2_D needs backward computation.
I0624 14:20:06.834192 18728 net.cpp:217] bn2_2_D needs backward computation.
I0624 14:20:06.834194 18728 net.cpp:217] conv2_2_D needs backward computation.
I0624 14:20:06.834197 18728 net.cpp:217] upsample2 needs backward computation.
I0624 14:20:06.834208 18728 net.cpp:217] relu3_1_D needs backward computation.
I0624 14:20:06.834210 18728 net.cpp:217] scale3_1_D needs backward computation.
I0624 14:20:06.834213 18728 net.cpp:217] bn3_1_D needs backward computation.
I0624 14:20:06.834214 18728 net.cpp:217] conv3_1_D needs backward computation.
I0624 14:20:06.834216 18728 net.cpp:217] relu3_2_D needs backward computation.
I0624 14:20:06.834219 18728 net.cpp:217] scale3_2_D needs backward computation.
I0624 14:20:06.834221 18728 net.cpp:217] bn3_2_D needs backward computation.
I0624 14:20:06.834223 18728 net.cpp:217] conv3_2_D needs backward computation.
I0624 14:20:06.834226 18728 net.cpp:217] upsample3 needs backward computation.
I0624 14:20:06.834229 18728 net.cpp:217] relu4_1_D needs backward computation.
I0624 14:20:06.834231 18728 net.cpp:217] scale4_1_D needs backward computation.
I0624 14:20:06.834233 18728 net.cpp:217] bn4_1_D needs backward computation.
I0624 14:20:06.834236 18728 net.cpp:217] conv4_1_D needs backward computation.
I0624 14:20:06.834239 18728 net.cpp:217] relu4_2_D needs backward computation.
I0624 14:20:06.834241 18728 net.cpp:217] scale4_2_D needs backward computation.
I0624 14:20:06.834244 18728 net.cpp:217] bn4_2_D needs backward computation.
I0624 14:20:06.834245 18728 net.cpp:217] conv4_2_D needs backward computation.
I0624 14:20:06.834249 18728 net.cpp:217] upsample4 needs backward computation.
I0624 14:20:06.834250 18728 net.cpp:217] relu5_1_D needs backward computation.
I0624 14:20:06.834254 18728 net.cpp:217] scale5_1_D needs backward computation.
I0624 14:20:06.834255 18728 net.cpp:217] bn5_1_D needs backward computation.
I0624 14:20:06.834257 18728 net.cpp:217] conv5_1_D needs backward computation.
I0624 14:20:06.834260 18728 net.cpp:217] relu5_2_D needs backward computation.
I0624 14:20:06.834262 18728 net.cpp:217] scale5_2_D needs backward computation.
I0624 14:20:06.834265 18728 net.cpp:217] bn5_2_D needs backward computation.
I0624 14:20:06.834267 18728 net.cpp:217] conv5_2_D needs backward computation.
I0624 14:20:06.834270 18728 net.cpp:217] upsample5 needs backward computation.
I0624 14:20:06.834272 18728 net.cpp:217] pool5 needs backward computation.
I0624 14:20:06.834275 18728 net.cpp:217] relu5_2 needs backward computation.
I0624 14:20:06.834277 18728 net.cpp:217] scale5_2 needs backward computation.
I0624 14:20:06.834280 18728 net.cpp:217] bn5_2 needs backward computation.
I0624 14:20:06.834282 18728 net.cpp:217] conv5_2 needs backward computation.
I0624 14:20:06.834285 18728 net.cpp:217] relu5_1 needs backward computation.
I0624 14:20:06.834288 18728 net.cpp:217] scale5_1 needs backward computation.
I0624 14:20:06.834291 18728 net.cpp:217] bn5_1 needs backward computation.
I0624 14:20:06.834293 18728 net.cpp:217] conv5_1 needs backward computation.
I0624 14:20:06.834296 18728 net.cpp:217] pool4 needs backward computation.
I0624 14:20:06.834300 18728 net.cpp:217] relu4_2 needs backward computation.
I0624 14:20:06.834301 18728 net.cpp:217] scale4_2 needs backward computation.
I0624 14:20:06.834303 18728 net.cpp:217] bn4_2 needs backward computation.
I0624 14:20:06.834306 18728 net.cpp:217] conv4_2 needs backward computation.
I0624 14:20:06.834308 18728 net.cpp:217] relu4_1 needs backward computation.
I0624 14:20:06.834311 18728 net.cpp:217] scale4_1 needs backward computation.
I0624 14:20:06.834313 18728 net.cpp:217] bn4_1 needs backward computation.
I0624 14:20:06.834316 18728 net.cpp:217] conv4_1 needs backward computation.
I0624 14:20:06.834317 18728 net.cpp:217] pool3 needs backward computation.
I0624 14:20:06.834321 18728 net.cpp:217] relu3_2 needs backward computation.
I0624 14:20:06.834322 18728 net.cpp:217] scale3_2 needs backward computation.
I0624 14:20:06.834324 18728 net.cpp:217] bn3_2 needs backward computation.
I0624 14:20:06.834327 18728 net.cpp:217] conv3_2 needs backward computation.
I0624 14:20:06.834329 18728 net.cpp:217] relu3_1 needs backward computation.
I0624 14:20:06.834331 18728 net.cpp:217] scale3_1 needs backward computation.
I0624 14:20:06.834333 18728 net.cpp:217] bn3_1 needs backward computation.
I0624 14:20:06.834341 18728 net.cpp:217] conv3_1 needs backward computation.
I0624 14:20:06.834343 18728 net.cpp:217] pool2 needs backward computation.
I0624 14:20:06.834345 18728 net.cpp:217] relu2_2 needs backward computation.
I0624 14:20:06.834347 18728 net.cpp:217] scale2_2 needs backward computation.
I0624 14:20:06.834349 18728 net.cpp:217] bn2_2 needs backward computation.
I0624 14:20:06.834352 18728 net.cpp:217] conv2_2 needs backward computation.
I0624 14:20:06.834354 18728 net.cpp:217] relu2_1 needs backward computation.
I0624 14:20:06.834357 18728 net.cpp:217] scale2_1 needs backward computation.
I0624 14:20:06.834359 18728 net.cpp:217] bn2_1 needs backward computation.
I0624 14:20:06.834362 18728 net.cpp:217] conv2_1 needs backward computation.
I0624 14:20:06.834363 18728 net.cpp:217] pool1 needs backward computation.
I0624 14:20:06.834365 18728 net.cpp:217] relu1_2 needs backward computation.
I0624 14:20:06.834368 18728 net.cpp:217] scale1_2 needs backward computation.
I0624 14:20:06.834370 18728 net.cpp:217] bn1_2 needs backward computation.
I0624 14:20:06.834373 18728 net.cpp:217] conv1_2 needs backward computation.
I0624 14:20:06.834375 18728 net.cpp:217] relu1_1 needs backward computation.
I0624 14:20:06.834378 18728 net.cpp:217] scale1_1 needs backward computation.
I0624 14:20:06.834380 18728 net.cpp:217] bn1_1 needs backward computation.
I0624 14:20:06.834383 18728 net.cpp:217] conv1_1 needs backward computation.
I0624 14:20:06.834385 18728 net.cpp:219] label_data_1_split does not need backward computation.
I0624 14:20:06.834388 18728 net.cpp:219] data does not need backward computation.
I0624 14:20:06.834390 18728 net.cpp:261] This network produces output accuracy
I0624 14:20:06.834393 18728 net.cpp:261] This network produces output loss
I0624 14:20:06.834425 18728 net.cpp:274] Network initialization done.
I0624 14:20:06.835929 18728 solver.cpp:181] Creating test net (#0) specified by net file: models/segnet/train_val.prototxt
I0624 14:20:06.836017 18728 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0624 14:20:06.836416 18728 net.cpp:49] Initializing net from parameters: 
name: "segnet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "DenseImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 224
    mean_value: 100
  }
  dense_image_data_param {
    source: "data/val_seg.txt"
    batch_size: 1
    shuffle: true
    new_height: 224
    new_width: 310
    is_color: false
    root_folder: "data/raw/train/"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 14
    upsample_w: 14
  }
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2_D"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2_D"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1_D"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1_D"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 28
    upsample_w: 28
  }
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2_D"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2_D"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1_D"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1_D"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
    upsample_h: 56
    upsample_w: 56
  }
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn3_2_D"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2_D"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1_D"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1_D"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
    upsample_h: 112
    upsample_w: 112
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2_D"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2_D"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1_D"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1_D"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
    upsample_h: 224
    upsample_w: 224
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2_D"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2_D"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2
    bias_term: true
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "accuracy"
}
I0624 14:20:06.836655 18728 layer_factory.hpp:77] Creating layer data
I0624 14:20:06.836668 18728 net.cpp:91] Creating Layer data
I0624 14:20:06.836671 18728 net.cpp:399] data -> data
I0624 14:20:06.836678 18728 net.cpp:399] data -> label
I0624 14:20:06.836688 18728 dense_image_data_layer.cpp:38] Opening file data/val_seg.txt
I0624 14:20:06.836840 18728 dense_image_data_layer.cpp:48] Shuffling data
I0624 14:20:06.836875 18728 dense_image_data_layer.cpp:53] A total of 299 examples.
I0624 14:20:06.841410 18728 dense_image_data_layer.cpp:92] output data size: 1,1,224,224
I0624 14:20:06.842622 18728 net.cpp:141] Setting up data
I0624 14:20:06.842633 18728 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 14:20:06.842638 18728 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 14:20:06.842639 18728 net.cpp:156] Memory required for data: 401408
I0624 14:20:06.842643 18728 layer_factory.hpp:77] Creating layer label_data_1_split
I0624 14:20:06.842649 18728 net.cpp:91] Creating Layer label_data_1_split
I0624 14:20:06.842651 18728 net.cpp:425] label_data_1_split <- label
I0624 14:20:06.842655 18728 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0624 14:20:06.842661 18728 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0624 14:20:06.842710 18728 net.cpp:141] Setting up label_data_1_split
I0624 14:20:06.842720 18728 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 14:20:06.842722 18728 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 14:20:06.842725 18728 net.cpp:156] Memory required for data: 802816
I0624 14:20:06.842726 18728 layer_factory.hpp:77] Creating layer conv1_1
I0624 14:20:06.842735 18728 net.cpp:91] Creating Layer conv1_1
I0624 14:20:06.842736 18728 net.cpp:425] conv1_1 <- data
I0624 14:20:06.842741 18728 net.cpp:399] conv1_1 -> conv1_1
I0624 14:20:06.844161 18728 net.cpp:141] Setting up conv1_1
I0624 14:20:06.844174 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.844177 18728 net.cpp:156] Memory required for data: 7225344
I0624 14:20:06.844182 18728 layer_factory.hpp:77] Creating layer bn1_1
I0624 14:20:06.844188 18728 net.cpp:91] Creating Layer bn1_1
I0624 14:20:06.844190 18728 net.cpp:425] bn1_1 <- conv1_1
I0624 14:20:06.844194 18728 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0624 14:20:06.845082 18728 net.cpp:141] Setting up bn1_1
I0624 14:20:06.845093 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.845095 18728 net.cpp:156] Memory required for data: 13647872
I0624 14:20:06.845104 18728 layer_factory.hpp:77] Creating layer scale1_1
I0624 14:20:06.845111 18728 net.cpp:91] Creating Layer scale1_1
I0624 14:20:06.845114 18728 net.cpp:425] scale1_1 <- conv1_1
I0624 14:20:06.845118 18728 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0624 14:20:06.845161 18728 layer_factory.hpp:77] Creating layer scale1_1
I0624 14:20:06.845315 18728 net.cpp:141] Setting up scale1_1
I0624 14:20:06.845322 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.845324 18728 net.cpp:156] Memory required for data: 20070400
I0624 14:20:06.845341 18728 layer_factory.hpp:77] Creating layer relu1_1
I0624 14:20:06.845346 18728 net.cpp:91] Creating Layer relu1_1
I0624 14:20:06.845350 18728 net.cpp:425] relu1_1 <- conv1_1
I0624 14:20:06.845352 18728 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0624 14:20:06.845649 18728 net.cpp:141] Setting up relu1_1
I0624 14:20:06.845660 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.845664 18728 net.cpp:156] Memory required for data: 26492928
I0624 14:20:06.845666 18728 layer_factory.hpp:77] Creating layer conv1_2
I0624 14:20:06.845674 18728 net.cpp:91] Creating Layer conv1_2
I0624 14:20:06.845676 18728 net.cpp:425] conv1_2 <- conv1_1
I0624 14:20:06.845680 18728 net.cpp:399] conv1_2 -> conv1_2
I0624 14:20:06.846595 18728 net.cpp:141] Setting up conv1_2
I0624 14:20:06.846606 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.846608 18728 net.cpp:156] Memory required for data: 32915456
I0624 14:20:06.846612 18728 layer_factory.hpp:77] Creating layer bn1_2
I0624 14:20:06.846618 18728 net.cpp:91] Creating Layer bn1_2
I0624 14:20:06.846621 18728 net.cpp:425] bn1_2 <- conv1_2
I0624 14:20:06.846624 18728 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0624 14:20:06.846833 18728 net.cpp:141] Setting up bn1_2
I0624 14:20:06.846840 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.846843 18728 net.cpp:156] Memory required for data: 39337984
I0624 14:20:06.846851 18728 layer_factory.hpp:77] Creating layer scale1_2
I0624 14:20:06.846858 18728 net.cpp:91] Creating Layer scale1_2
I0624 14:20:06.846861 18728 net.cpp:425] scale1_2 <- conv1_2
I0624 14:20:06.846865 18728 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0624 14:20:06.846904 18728 layer_factory.hpp:77] Creating layer scale1_2
I0624 14:20:06.847654 18728 net.cpp:141] Setting up scale1_2
I0624 14:20:06.847666 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.847669 18728 net.cpp:156] Memory required for data: 45760512
I0624 14:20:06.847674 18728 layer_factory.hpp:77] Creating layer relu1_2
I0624 14:20:06.847679 18728 net.cpp:91] Creating Layer relu1_2
I0624 14:20:06.847681 18728 net.cpp:425] relu1_2 <- conv1_2
I0624 14:20:06.847686 18728 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0624 14:20:06.847968 18728 net.cpp:141] Setting up relu1_2
I0624 14:20:06.847980 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.847981 18728 net.cpp:156] Memory required for data: 52183040
I0624 14:20:06.847985 18728 layer_factory.hpp:77] Creating layer pool1
I0624 14:20:06.847987 18728 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 14:20:06.847991 18728 net.cpp:91] Creating Layer pool1
I0624 14:20:06.847995 18728 net.cpp:425] pool1 <- conv1_2
I0624 14:20:06.847998 18728 net.cpp:399] pool1 -> pool1
I0624 14:20:06.848003 18728 net.cpp:399] pool1 -> pool1_mask
I0624 14:20:06.848047 18728 net.cpp:141] Setting up pool1
I0624 14:20:06.848053 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.848057 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.848058 18728 net.cpp:156] Memory required for data: 55394304
I0624 14:20:06.848060 18728 layer_factory.hpp:77] Creating layer conv2_1
I0624 14:20:06.848067 18728 net.cpp:91] Creating Layer conv2_1
I0624 14:20:06.848069 18728 net.cpp:425] conv2_1 <- pool1
I0624 14:20:06.848073 18728 net.cpp:399] conv2_1 -> conv2_1
I0624 14:20:06.849161 18728 net.cpp:141] Setting up conv2_1
I0624 14:20:06.849174 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.849175 18728 net.cpp:156] Memory required for data: 58605568
I0624 14:20:06.849179 18728 layer_factory.hpp:77] Creating layer bn2_1
I0624 14:20:06.849185 18728 net.cpp:91] Creating Layer bn2_1
I0624 14:20:06.849187 18728 net.cpp:425] bn2_1 <- conv2_1
I0624 14:20:06.849191 18728 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0624 14:20:06.849385 18728 net.cpp:141] Setting up bn2_1
I0624 14:20:06.849391 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.849393 18728 net.cpp:156] Memory required for data: 61816832
I0624 14:20:06.849411 18728 layer_factory.hpp:77] Creating layer scale2_1
I0624 14:20:06.849417 18728 net.cpp:91] Creating Layer scale2_1
I0624 14:20:06.849421 18728 net.cpp:425] scale2_1 <- conv2_1
I0624 14:20:06.849423 18728 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0624 14:20:06.849465 18728 layer_factory.hpp:77] Creating layer scale2_1
I0624 14:20:06.849587 18728 net.cpp:141] Setting up scale2_1
I0624 14:20:06.849593 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.849596 18728 net.cpp:156] Memory required for data: 65028096
I0624 14:20:06.849602 18728 layer_factory.hpp:77] Creating layer relu2_1
I0624 14:20:06.849607 18728 net.cpp:91] Creating Layer relu2_1
I0624 14:20:06.849609 18728 net.cpp:425] relu2_1 <- conv2_1
I0624 14:20:06.849613 18728 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0624 14:20:06.849766 18728 net.cpp:141] Setting up relu2_1
I0624 14:20:06.849781 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.849783 18728 net.cpp:156] Memory required for data: 68239360
I0624 14:20:06.849786 18728 layer_factory.hpp:77] Creating layer conv2_2
I0624 14:20:06.849793 18728 net.cpp:91] Creating Layer conv2_2
I0624 14:20:06.849797 18728 net.cpp:425] conv2_2 <- conv2_1
I0624 14:20:06.849800 18728 net.cpp:399] conv2_2 -> conv2_2
I0624 14:20:06.851125 18728 net.cpp:141] Setting up conv2_2
I0624 14:20:06.851136 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.851138 18728 net.cpp:156] Memory required for data: 71450624
I0624 14:20:06.851143 18728 layer_factory.hpp:77] Creating layer bn2_2
I0624 14:20:06.851157 18728 net.cpp:91] Creating Layer bn2_2
I0624 14:20:06.851161 18728 net.cpp:425] bn2_2 <- conv2_2
I0624 14:20:06.851166 18728 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0624 14:20:06.851363 18728 net.cpp:141] Setting up bn2_2
I0624 14:20:06.851371 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.851372 18728 net.cpp:156] Memory required for data: 74661888
I0624 14:20:06.851378 18728 layer_factory.hpp:77] Creating layer scale2_2
I0624 14:20:06.851383 18728 net.cpp:91] Creating Layer scale2_2
I0624 14:20:06.851387 18728 net.cpp:425] scale2_2 <- conv2_2
I0624 14:20:06.851389 18728 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0624 14:20:06.851429 18728 layer_factory.hpp:77] Creating layer scale2_2
I0624 14:20:06.851567 18728 net.cpp:141] Setting up scale2_2
I0624 14:20:06.851574 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.851577 18728 net.cpp:156] Memory required for data: 77873152
I0624 14:20:06.851582 18728 layer_factory.hpp:77] Creating layer relu2_2
I0624 14:20:06.851588 18728 net.cpp:91] Creating Layer relu2_2
I0624 14:20:06.851589 18728 net.cpp:425] relu2_2 <- conv2_2
I0624 14:20:06.851593 18728 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0624 14:20:06.851884 18728 net.cpp:141] Setting up relu2_2
I0624 14:20:06.851896 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.851897 18728 net.cpp:156] Memory required for data: 81084416
I0624 14:20:06.851900 18728 layer_factory.hpp:77] Creating layer pool2
I0624 14:20:06.851902 18728 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 14:20:06.851907 18728 net.cpp:91] Creating Layer pool2
I0624 14:20:06.851910 18728 net.cpp:425] pool2 <- conv2_2
I0624 14:20:06.851914 18728 net.cpp:399] pool2 -> pool2
I0624 14:20:06.851919 18728 net.cpp:399] pool2 -> pool2_mask
I0624 14:20:06.851963 18728 net.cpp:141] Setting up pool2
I0624 14:20:06.851969 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.851974 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.851975 18728 net.cpp:156] Memory required for data: 82690048
I0624 14:20:06.851977 18728 layer_factory.hpp:77] Creating layer conv3_1
I0624 14:20:06.851984 18728 net.cpp:91] Creating Layer conv3_1
I0624 14:20:06.851986 18728 net.cpp:425] conv3_1 <- pool2
I0624 14:20:06.851990 18728 net.cpp:399] conv3_1 -> conv3_1
I0624 14:20:06.853356 18728 net.cpp:141] Setting up conv3_1
I0624 14:20:06.853368 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.853380 18728 net.cpp:156] Memory required for data: 84295680
I0624 14:20:06.853385 18728 layer_factory.hpp:77] Creating layer bn3_1
I0624 14:20:06.853391 18728 net.cpp:91] Creating Layer bn3_1
I0624 14:20:06.853394 18728 net.cpp:425] bn3_1 <- conv3_1
I0624 14:20:06.853399 18728 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0624 14:20:06.853592 18728 net.cpp:141] Setting up bn3_1
I0624 14:20:06.853600 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.853601 18728 net.cpp:156] Memory required for data: 85901312
I0624 14:20:06.853607 18728 layer_factory.hpp:77] Creating layer scale3_1
I0624 14:20:06.853612 18728 net.cpp:91] Creating Layer scale3_1
I0624 14:20:06.853615 18728 net.cpp:425] scale3_1 <- conv3_1
I0624 14:20:06.853618 18728 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0624 14:20:06.853657 18728 layer_factory.hpp:77] Creating layer scale3_1
I0624 14:20:06.853780 18728 net.cpp:141] Setting up scale3_1
I0624 14:20:06.853786 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.853788 18728 net.cpp:156] Memory required for data: 87506944
I0624 14:20:06.853793 18728 layer_factory.hpp:77] Creating layer relu3_1
I0624 14:20:06.853797 18728 net.cpp:91] Creating Layer relu3_1
I0624 14:20:06.853801 18728 net.cpp:425] relu3_1 <- conv3_1
I0624 14:20:06.853803 18728 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0624 14:20:06.854090 18728 net.cpp:141] Setting up relu3_1
I0624 14:20:06.854101 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.854105 18728 net.cpp:156] Memory required for data: 89112576
I0624 14:20:06.854107 18728 layer_factory.hpp:77] Creating layer conv3_2
I0624 14:20:06.854115 18728 net.cpp:91] Creating Layer conv3_2
I0624 14:20:06.854118 18728 net.cpp:425] conv3_2 <- conv3_1
I0624 14:20:06.854123 18728 net.cpp:399] conv3_2 -> conv3_2
I0624 14:20:06.856575 18728 net.cpp:141] Setting up conv3_2
I0624 14:20:06.856588 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.856590 18728 net.cpp:156] Memory required for data: 90718208
I0624 14:20:06.856595 18728 layer_factory.hpp:77] Creating layer bn3_2
I0624 14:20:06.856601 18728 net.cpp:91] Creating Layer bn3_2
I0624 14:20:06.856604 18728 net.cpp:425] bn3_2 <- conv3_2
I0624 14:20:06.856608 18728 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0624 14:20:06.856801 18728 net.cpp:141] Setting up bn3_2
I0624 14:20:06.856808 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.856812 18728 net.cpp:156] Memory required for data: 92323840
I0624 14:20:06.856820 18728 layer_factory.hpp:77] Creating layer scale3_2
I0624 14:20:06.856829 18728 net.cpp:91] Creating Layer scale3_2
I0624 14:20:06.856832 18728 net.cpp:425] scale3_2 <- conv3_2
I0624 14:20:06.856837 18728 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0624 14:20:06.856876 18728 layer_factory.hpp:77] Creating layer scale3_2
I0624 14:20:06.856984 18728 net.cpp:141] Setting up scale3_2
I0624 14:20:06.856992 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.856994 18728 net.cpp:156] Memory required for data: 93929472
I0624 14:20:06.856998 18728 layer_factory.hpp:77] Creating layer relu3_2
I0624 14:20:06.857003 18728 net.cpp:91] Creating Layer relu3_2
I0624 14:20:06.857005 18728 net.cpp:425] relu3_2 <- conv3_2
I0624 14:20:06.857009 18728 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0624 14:20:06.857166 18728 net.cpp:141] Setting up relu3_2
I0624 14:20:06.857174 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.857177 18728 net.cpp:156] Memory required for data: 95535104
I0624 14:20:06.857179 18728 layer_factory.hpp:77] Creating layer pool3
I0624 14:20:06.857182 18728 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 14:20:06.857187 18728 net.cpp:91] Creating Layer pool3
I0624 14:20:06.857188 18728 net.cpp:425] pool3 <- conv3_2
I0624 14:20:06.857192 18728 net.cpp:399] pool3 -> pool3
I0624 14:20:06.857197 18728 net.cpp:399] pool3 -> pool3_mask
I0624 14:20:06.857240 18728 net.cpp:141] Setting up pool3
I0624 14:20:06.857244 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.857257 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.857259 18728 net.cpp:156] Memory required for data: 96337920
I0624 14:20:06.857262 18728 layer_factory.hpp:77] Creating layer conv4_1
I0624 14:20:06.857269 18728 net.cpp:91] Creating Layer conv4_1
I0624 14:20:06.857271 18728 net.cpp:425] conv4_1 <- pool3
I0624 14:20:06.857275 18728 net.cpp:399] conv4_1 -> conv4_1
I0624 14:20:06.860647 18728 net.cpp:141] Setting up conv4_1
I0624 14:20:06.860659 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.860662 18728 net.cpp:156] Memory required for data: 97140736
I0624 14:20:06.860666 18728 layer_factory.hpp:77] Creating layer bn4_1
I0624 14:20:06.860673 18728 net.cpp:91] Creating Layer bn4_1
I0624 14:20:06.860677 18728 net.cpp:425] bn4_1 <- conv4_1
I0624 14:20:06.860680 18728 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0624 14:20:06.860885 18728 net.cpp:141] Setting up bn4_1
I0624 14:20:06.860893 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.860895 18728 net.cpp:156] Memory required for data: 97943552
I0624 14:20:06.860901 18728 layer_factory.hpp:77] Creating layer scale4_1
I0624 14:20:06.860908 18728 net.cpp:91] Creating Layer scale4_1
I0624 14:20:06.860910 18728 net.cpp:425] scale4_1 <- conv4_1
I0624 14:20:06.860914 18728 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0624 14:20:06.860955 18728 layer_factory.hpp:77] Creating layer scale4_1
I0624 14:20:06.861075 18728 net.cpp:141] Setting up scale4_1
I0624 14:20:06.861083 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.861084 18728 net.cpp:156] Memory required for data: 98746368
I0624 14:20:06.861088 18728 layer_factory.hpp:77] Creating layer relu4_1
I0624 14:20:06.861096 18728 net.cpp:91] Creating Layer relu4_1
I0624 14:20:06.861099 18728 net.cpp:425] relu4_1 <- conv4_1
I0624 14:20:06.861104 18728 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0624 14:20:06.861400 18728 net.cpp:141] Setting up relu4_1
I0624 14:20:06.861410 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.861413 18728 net.cpp:156] Memory required for data: 99549184
I0624 14:20:06.861416 18728 layer_factory.hpp:77] Creating layer conv4_2
I0624 14:20:06.861424 18728 net.cpp:91] Creating Layer conv4_2
I0624 14:20:06.861428 18728 net.cpp:425] conv4_2 <- conv4_1
I0624 14:20:06.861431 18728 net.cpp:399] conv4_2 -> conv4_2
I0624 14:20:06.866891 18728 net.cpp:141] Setting up conv4_2
I0624 14:20:06.866904 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.866907 18728 net.cpp:156] Memory required for data: 100352000
I0624 14:20:06.866912 18728 layer_factory.hpp:77] Creating layer bn4_2
I0624 14:20:06.866919 18728 net.cpp:91] Creating Layer bn4_2
I0624 14:20:06.866922 18728 net.cpp:425] bn4_2 <- conv4_2
I0624 14:20:06.866926 18728 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0624 14:20:06.867126 18728 net.cpp:141] Setting up bn4_2
I0624 14:20:06.867135 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.867136 18728 net.cpp:156] Memory required for data: 101154816
I0624 14:20:06.867142 18728 layer_factory.hpp:77] Creating layer scale4_2
I0624 14:20:06.867159 18728 net.cpp:91] Creating Layer scale4_2
I0624 14:20:06.867163 18728 net.cpp:425] scale4_2 <- conv4_2
I0624 14:20:06.867167 18728 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0624 14:20:06.867218 18728 layer_factory.hpp:77] Creating layer scale4_2
I0624 14:20:06.867336 18728 net.cpp:141] Setting up scale4_2
I0624 14:20:06.867344 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.867347 18728 net.cpp:156] Memory required for data: 101957632
I0624 14:20:06.867352 18728 layer_factory.hpp:77] Creating layer relu4_2
I0624 14:20:06.867357 18728 net.cpp:91] Creating Layer relu4_2
I0624 14:20:06.867359 18728 net.cpp:425] relu4_2 <- conv4_2
I0624 14:20:06.867363 18728 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0624 14:20:06.867669 18728 net.cpp:141] Setting up relu4_2
I0624 14:20:06.867681 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.867683 18728 net.cpp:156] Memory required for data: 102760448
I0624 14:20:06.867686 18728 layer_factory.hpp:77] Creating layer pool4
I0624 14:20:06.867697 18728 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 14:20:06.867703 18728 net.cpp:91] Creating Layer pool4
I0624 14:20:06.867707 18728 net.cpp:425] pool4 <- conv4_2
I0624 14:20:06.867712 18728 net.cpp:399] pool4 -> pool4
I0624 14:20:06.867717 18728 net.cpp:399] pool4 -> pool4_mask
I0624 14:20:06.867766 18728 net.cpp:141] Setting up pool4
I0624 14:20:06.867771 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.867774 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.867776 18728 net.cpp:156] Memory required for data: 103161856
I0624 14:20:06.867779 18728 layer_factory.hpp:77] Creating layer conv5_1
I0624 14:20:06.867787 18728 net.cpp:91] Creating Layer conv5_1
I0624 14:20:06.867790 18728 net.cpp:425] conv5_1 <- pool4
I0624 14:20:06.867794 18728 net.cpp:399] conv5_1 -> conv5_1
I0624 14:20:06.873347 18728 net.cpp:141] Setting up conv5_1
I0624 14:20:06.873359 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.873363 18728 net.cpp:156] Memory required for data: 103362560
I0624 14:20:06.873366 18728 layer_factory.hpp:77] Creating layer bn5_1
I0624 14:20:06.873373 18728 net.cpp:91] Creating Layer bn5_1
I0624 14:20:06.873376 18728 net.cpp:425] bn5_1 <- conv5_1
I0624 14:20:06.873381 18728 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0624 14:20:06.873589 18728 net.cpp:141] Setting up bn5_1
I0624 14:20:06.873597 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.873600 18728 net.cpp:156] Memory required for data: 103563264
I0624 14:20:06.873605 18728 layer_factory.hpp:77] Creating layer scale5_1
I0624 14:20:06.873611 18728 net.cpp:91] Creating Layer scale5_1
I0624 14:20:06.873613 18728 net.cpp:425] scale5_1 <- conv5_1
I0624 14:20:06.873618 18728 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0624 14:20:06.873661 18728 layer_factory.hpp:77] Creating layer scale5_1
I0624 14:20:06.873775 18728 net.cpp:141] Setting up scale5_1
I0624 14:20:06.873781 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.873785 18728 net.cpp:156] Memory required for data: 103763968
I0624 14:20:06.873788 18728 layer_factory.hpp:77] Creating layer relu5_1
I0624 14:20:06.873792 18728 net.cpp:91] Creating Layer relu5_1
I0624 14:20:06.873795 18728 net.cpp:425] relu5_1 <- conv5_1
I0624 14:20:06.873800 18728 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0624 14:20:06.873965 18728 net.cpp:141] Setting up relu5_1
I0624 14:20:06.873975 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.873976 18728 net.cpp:156] Memory required for data: 103964672
I0624 14:20:06.873980 18728 layer_factory.hpp:77] Creating layer conv5_2
I0624 14:20:06.873987 18728 net.cpp:91] Creating Layer conv5_2
I0624 14:20:06.873991 18728 net.cpp:425] conv5_2 <- conv5_1
I0624 14:20:06.873996 18728 net.cpp:399] conv5_2 -> conv5_2
I0624 14:20:06.879627 18728 net.cpp:141] Setting up conv5_2
I0624 14:20:06.879642 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.879644 18728 net.cpp:156] Memory required for data: 104165376
I0624 14:20:06.879649 18728 layer_factory.hpp:77] Creating layer bn5_2
I0624 14:20:06.879657 18728 net.cpp:91] Creating Layer bn5_2
I0624 14:20:06.879660 18728 net.cpp:425] bn5_2 <- conv5_2
I0624 14:20:06.879665 18728 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0624 14:20:06.879873 18728 net.cpp:141] Setting up bn5_2
I0624 14:20:06.879881 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.879884 18728 net.cpp:156] Memory required for data: 104366080
I0624 14:20:06.879890 18728 layer_factory.hpp:77] Creating layer scale5_2
I0624 14:20:06.879896 18728 net.cpp:91] Creating Layer scale5_2
I0624 14:20:06.879899 18728 net.cpp:425] scale5_2 <- conv5_2
I0624 14:20:06.879904 18728 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0624 14:20:06.879947 18728 layer_factory.hpp:77] Creating layer scale5_2
I0624 14:20:06.880066 18728 net.cpp:141] Setting up scale5_2
I0624 14:20:06.880072 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.880075 18728 net.cpp:156] Memory required for data: 104566784
I0624 14:20:06.880089 18728 layer_factory.hpp:77] Creating layer relu5_2
I0624 14:20:06.880095 18728 net.cpp:91] Creating Layer relu5_2
I0624 14:20:06.880096 18728 net.cpp:425] relu5_2 <- conv5_2
I0624 14:20:06.880100 18728 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0624 14:20:06.880419 18728 net.cpp:141] Setting up relu5_2
I0624 14:20:06.880429 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.880431 18728 net.cpp:156] Memory required for data: 104767488
I0624 14:20:06.880434 18728 layer_factory.hpp:77] Creating layer pool5
I0624 14:20:06.880437 18728 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 14:20:06.880442 18728 net.cpp:91] Creating Layer pool5
I0624 14:20:06.880445 18728 net.cpp:425] pool5 <- conv5_2
I0624 14:20:06.880452 18728 net.cpp:399] pool5 -> pool5
I0624 14:20:06.880458 18728 net.cpp:399] pool5 -> pool5_mask
I0624 14:20:06.880509 18728 net.cpp:141] Setting up pool5
I0624 14:20:06.880517 18728 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 14:20:06.880519 18728 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 14:20:06.880522 18728 net.cpp:156] Memory required for data: 104867840
I0624 14:20:06.880523 18728 layer_factory.hpp:77] Creating layer upsample5
I0624 14:20:06.880530 18728 net.cpp:91] Creating Layer upsample5
I0624 14:20:06.880533 18728 net.cpp:425] upsample5 <- pool5
I0624 14:20:06.880537 18728 net.cpp:425] upsample5 <- pool5_mask
I0624 14:20:06.880539 18728 net.cpp:399] upsample5 -> pool5_D
I0624 14:20:06.880568 18728 net.cpp:141] Setting up upsample5
I0624 14:20:06.880573 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.880575 18728 net.cpp:156] Memory required for data: 105068544
I0624 14:20:06.880578 18728 layer_factory.hpp:77] Creating layer conv5_2_D
I0624 14:20:06.880586 18728 net.cpp:91] Creating Layer conv5_2_D
I0624 14:20:06.880589 18728 net.cpp:425] conv5_2_D <- pool5_D
I0624 14:20:06.880594 18728 net.cpp:399] conv5_2_D -> conv5_2_D
I0624 14:20:06.886281 18728 net.cpp:141] Setting up conv5_2_D
I0624 14:20:06.886296 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.886299 18728 net.cpp:156] Memory required for data: 105269248
I0624 14:20:06.886306 18728 layer_factory.hpp:77] Creating layer bn5_2_D
I0624 14:20:06.886312 18728 net.cpp:91] Creating Layer bn5_2_D
I0624 14:20:06.886315 18728 net.cpp:425] bn5_2_D <- conv5_2_D
I0624 14:20:06.886322 18728 net.cpp:386] bn5_2_D -> conv5_2_D (in-place)
I0624 14:20:06.886533 18728 net.cpp:141] Setting up bn5_2_D
I0624 14:20:06.886539 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.886543 18728 net.cpp:156] Memory required for data: 105469952
I0624 14:20:06.886548 18728 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 14:20:06.886554 18728 net.cpp:91] Creating Layer scale5_2_D
I0624 14:20:06.886557 18728 net.cpp:425] scale5_2_D <- conv5_2_D
I0624 14:20:06.886561 18728 net.cpp:386] scale5_2_D -> conv5_2_D (in-place)
I0624 14:20:06.886605 18728 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 14:20:06.886720 18728 net.cpp:141] Setting up scale5_2_D
I0624 14:20:06.886729 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.886730 18728 net.cpp:156] Memory required for data: 105670656
I0624 14:20:06.886744 18728 layer_factory.hpp:77] Creating layer relu5_2_D
I0624 14:20:06.886750 18728 net.cpp:91] Creating Layer relu5_2_D
I0624 14:20:06.886752 18728 net.cpp:425] relu5_2_D <- conv5_2_D
I0624 14:20:06.886756 18728 net.cpp:386] relu5_2_D -> conv5_2_D (in-place)
I0624 14:20:06.887053 18728 net.cpp:141] Setting up relu5_2_D
I0624 14:20:06.887064 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.887066 18728 net.cpp:156] Memory required for data: 105871360
I0624 14:20:06.887069 18728 layer_factory.hpp:77] Creating layer conv5_1_D
I0624 14:20:06.887079 18728 net.cpp:91] Creating Layer conv5_1_D
I0624 14:20:06.887081 18728 net.cpp:425] conv5_1_D <- conv5_2_D
I0624 14:20:06.887087 18728 net.cpp:399] conv5_1_D -> conv5_1_D
I0624 14:20:06.893002 18728 net.cpp:141] Setting up conv5_1_D
I0624 14:20:06.893026 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.893029 18728 net.cpp:156] Memory required for data: 106072064
I0624 14:20:06.893034 18728 layer_factory.hpp:77] Creating layer bn5_1_D
I0624 14:20:06.893043 18728 net.cpp:91] Creating Layer bn5_1_D
I0624 14:20:06.893045 18728 net.cpp:425] bn5_1_D <- conv5_1_D
I0624 14:20:06.893050 18728 net.cpp:386] bn5_1_D -> conv5_1_D (in-place)
I0624 14:20:06.893261 18728 net.cpp:141] Setting up bn5_1_D
I0624 14:20:06.893270 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.893272 18728 net.cpp:156] Memory required for data: 106272768
I0624 14:20:06.893277 18728 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 14:20:06.893283 18728 net.cpp:91] Creating Layer scale5_1_D
I0624 14:20:06.893286 18728 net.cpp:425] scale5_1_D <- conv5_1_D
I0624 14:20:06.893290 18728 net.cpp:386] scale5_1_D -> conv5_1_D (in-place)
I0624 14:20:06.893337 18728 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 14:20:06.893461 18728 net.cpp:141] Setting up scale5_1_D
I0624 14:20:06.893468 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.893471 18728 net.cpp:156] Memory required for data: 106473472
I0624 14:20:06.893474 18728 layer_factory.hpp:77] Creating layer relu5_1_D
I0624 14:20:06.893479 18728 net.cpp:91] Creating Layer relu5_1_D
I0624 14:20:06.893482 18728 net.cpp:425] relu5_1_D <- conv5_1_D
I0624 14:20:06.893486 18728 net.cpp:386] relu5_1_D -> conv5_1_D (in-place)
I0624 14:20:06.893646 18728 net.cpp:141] Setting up relu5_1_D
I0624 14:20:06.893654 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.893656 18728 net.cpp:156] Memory required for data: 106674176
I0624 14:20:06.893659 18728 layer_factory.hpp:77] Creating layer upsample4
I0624 14:20:06.893666 18728 net.cpp:91] Creating Layer upsample4
I0624 14:20:06.893668 18728 net.cpp:425] upsample4 <- conv5_1_D
I0624 14:20:06.893672 18728 net.cpp:425] upsample4 <- pool4_mask
I0624 14:20:06.893676 18728 net.cpp:399] upsample4 -> pool4_D
I0624 14:20:06.893713 18728 net.cpp:141] Setting up upsample4
I0624 14:20:06.893720 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.893723 18728 net.cpp:156] Memory required for data: 107476992
I0624 14:20:06.893724 18728 layer_factory.hpp:77] Creating layer conv4_2_D
I0624 14:20:06.893733 18728 net.cpp:91] Creating Layer conv4_2_D
I0624 14:20:06.893735 18728 net.cpp:425] conv4_2_D <- pool4_D
I0624 14:20:06.893739 18728 net.cpp:399] conv4_2_D -> conv4_2_D
I0624 14:20:06.899406 18728 net.cpp:141] Setting up conv4_2_D
I0624 14:20:06.899420 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.899422 18728 net.cpp:156] Memory required for data: 108279808
I0624 14:20:06.899428 18728 layer_factory.hpp:77] Creating layer bn4_2_D
I0624 14:20:06.899435 18728 net.cpp:91] Creating Layer bn4_2_D
I0624 14:20:06.899438 18728 net.cpp:425] bn4_2_D <- conv4_2_D
I0624 14:20:06.899442 18728 net.cpp:386] bn4_2_D -> conv4_2_D (in-place)
I0624 14:20:06.899677 18728 net.cpp:141] Setting up bn4_2_D
I0624 14:20:06.899685 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.899688 18728 net.cpp:156] Memory required for data: 109082624
I0624 14:20:06.899694 18728 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 14:20:06.899701 18728 net.cpp:91] Creating Layer scale4_2_D
I0624 14:20:06.899704 18728 net.cpp:425] scale4_2_D <- conv4_2_D
I0624 14:20:06.899708 18728 net.cpp:386] scale4_2_D -> conv4_2_D (in-place)
I0624 14:20:06.899752 18728 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 14:20:06.899888 18728 net.cpp:141] Setting up scale4_2_D
I0624 14:20:06.899895 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.899899 18728 net.cpp:156] Memory required for data: 109885440
I0624 14:20:06.899902 18728 layer_factory.hpp:77] Creating layer relu4_2_D
I0624 14:20:06.899909 18728 net.cpp:91] Creating Layer relu4_2_D
I0624 14:20:06.899911 18728 net.cpp:425] relu4_2_D <- conv4_2_D
I0624 14:20:06.899915 18728 net.cpp:386] relu4_2_D -> conv4_2_D (in-place)
I0624 14:20:06.900233 18728 net.cpp:141] Setting up relu4_2_D
I0624 14:20:06.900251 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.900254 18728 net.cpp:156] Memory required for data: 110688256
I0624 14:20:06.900256 18728 layer_factory.hpp:77] Creating layer conv4_1_D
I0624 14:20:06.900266 18728 net.cpp:91] Creating Layer conv4_1_D
I0624 14:20:06.900269 18728 net.cpp:425] conv4_1_D <- conv4_2_D
I0624 14:20:06.900274 18728 net.cpp:399] conv4_1_D -> conv4_1_D
I0624 14:20:06.903528 18728 net.cpp:141] Setting up conv4_1_D
I0624 14:20:06.903539 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.903542 18728 net.cpp:156] Memory required for data: 111089664
I0624 14:20:06.903548 18728 layer_factory.hpp:77] Creating layer bn4_1_D
I0624 14:20:06.903558 18728 net.cpp:91] Creating Layer bn4_1_D
I0624 14:20:06.903561 18728 net.cpp:425] bn4_1_D <- conv4_1_D
I0624 14:20:06.903565 18728 net.cpp:386] bn4_1_D -> conv4_1_D (in-place)
I0624 14:20:06.903784 18728 net.cpp:141] Setting up bn4_1_D
I0624 14:20:06.903791 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.903794 18728 net.cpp:156] Memory required for data: 111491072
I0624 14:20:06.903800 18728 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 14:20:06.903805 18728 net.cpp:91] Creating Layer scale4_1_D
I0624 14:20:06.903807 18728 net.cpp:425] scale4_1_D <- conv4_1_D
I0624 14:20:06.903812 18728 net.cpp:386] scale4_1_D -> conv4_1_D (in-place)
I0624 14:20:06.903856 18728 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 14:20:06.903977 18728 net.cpp:141] Setting up scale4_1_D
I0624 14:20:06.903985 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.903986 18728 net.cpp:156] Memory required for data: 111892480
I0624 14:20:06.903990 18728 layer_factory.hpp:77] Creating layer relu4_1_D
I0624 14:20:06.904001 18728 net.cpp:91] Creating Layer relu4_1_D
I0624 14:20:06.904005 18728 net.cpp:425] relu4_1_D <- conv4_1_D
I0624 14:20:06.904008 18728 net.cpp:386] relu4_1_D -> conv4_1_D (in-place)
I0624 14:20:06.904314 18728 net.cpp:141] Setting up relu4_1_D
I0624 14:20:06.904325 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.904328 18728 net.cpp:156] Memory required for data: 112293888
I0624 14:20:06.904331 18728 layer_factory.hpp:77] Creating layer upsample3
I0624 14:20:06.904336 18728 net.cpp:91] Creating Layer upsample3
I0624 14:20:06.904340 18728 net.cpp:425] upsample3 <- conv4_1_D
I0624 14:20:06.904343 18728 net.cpp:425] upsample3 <- pool3_mask
I0624 14:20:06.904348 18728 net.cpp:399] upsample3 -> pool3_D
I0624 14:20:06.904393 18728 net.cpp:141] Setting up upsample3
I0624 14:20:06.904398 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.904400 18728 net.cpp:156] Memory required for data: 113899520
I0624 14:20:06.904403 18728 layer_factory.hpp:77] Creating layer conv3_2_D
I0624 14:20:06.904412 18728 net.cpp:91] Creating Layer conv3_2_D
I0624 14:20:06.904414 18728 net.cpp:425] conv3_2_D <- pool3_D
I0624 14:20:06.904420 18728 net.cpp:399] conv3_2_D -> conv3_2_D
I0624 14:20:06.907090 18728 net.cpp:141] Setting up conv3_2_D
I0624 14:20:06.907104 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.907105 18728 net.cpp:156] Memory required for data: 115505152
I0624 14:20:06.907111 18728 layer_factory.hpp:77] Creating layer bn3_2_D
I0624 14:20:06.907119 18728 net.cpp:91] Creating Layer bn3_2_D
I0624 14:20:06.907121 18728 net.cpp:425] bn3_2_D <- conv3_2_D
I0624 14:20:06.907125 18728 net.cpp:386] bn3_2_D -> conv3_2_D (in-place)
I0624 14:20:06.907361 18728 net.cpp:141] Setting up bn3_2_D
I0624 14:20:06.907369 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.907372 18728 net.cpp:156] Memory required for data: 117110784
I0624 14:20:06.907377 18728 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 14:20:06.907384 18728 net.cpp:91] Creating Layer scale3_2_D
I0624 14:20:06.907387 18728 net.cpp:425] scale3_2_D <- conv3_2_D
I0624 14:20:06.907392 18728 net.cpp:386] scale3_2_D -> conv3_2_D (in-place)
I0624 14:20:06.907438 18728 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 14:20:06.907562 18728 net.cpp:141] Setting up scale3_2_D
I0624 14:20:06.907578 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.907582 18728 net.cpp:156] Memory required for data: 118716416
I0624 14:20:06.907585 18728 layer_factory.hpp:77] Creating layer relu3_2_D
I0624 14:20:06.907590 18728 net.cpp:91] Creating Layer relu3_2_D
I0624 14:20:06.907593 18728 net.cpp:425] relu3_2_D <- conv3_2_D
I0624 14:20:06.907600 18728 net.cpp:386] relu3_2_D -> conv3_2_D (in-place)
I0624 14:20:06.907768 18728 net.cpp:141] Setting up relu3_2_D
I0624 14:20:06.907776 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.907778 18728 net.cpp:156] Memory required for data: 120322048
I0624 14:20:06.907781 18728 layer_factory.hpp:77] Creating layer conv3_1_D
I0624 14:20:06.907789 18728 net.cpp:91] Creating Layer conv3_1_D
I0624 14:20:06.907793 18728 net.cpp:425] conv3_1_D <- conv3_2_D
I0624 14:20:06.907799 18728 net.cpp:399] conv3_1_D -> conv3_1_D
I0624 14:20:06.909358 18728 net.cpp:141] Setting up conv3_1_D
I0624 14:20:06.909370 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.909373 18728 net.cpp:156] Memory required for data: 121124864
I0624 14:20:06.909378 18728 layer_factory.hpp:77] Creating layer bn3_1_D
I0624 14:20:06.909384 18728 net.cpp:91] Creating Layer bn3_1_D
I0624 14:20:06.909386 18728 net.cpp:425] bn3_1_D <- conv3_1_D
I0624 14:20:06.909390 18728 net.cpp:386] bn3_1_D -> conv3_1_D (in-place)
I0624 14:20:06.909622 18728 net.cpp:141] Setting up bn3_1_D
I0624 14:20:06.909631 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.909632 18728 net.cpp:156] Memory required for data: 121927680
I0624 14:20:06.909638 18728 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 14:20:06.909644 18728 net.cpp:91] Creating Layer scale3_1_D
I0624 14:20:06.909647 18728 net.cpp:425] scale3_1_D <- conv3_1_D
I0624 14:20:06.909651 18728 net.cpp:386] scale3_1_D -> conv3_1_D (in-place)
I0624 14:20:06.909696 18728 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 14:20:06.909832 18728 net.cpp:141] Setting up scale3_1_D
I0624 14:20:06.909838 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.909842 18728 net.cpp:156] Memory required for data: 122730496
I0624 14:20:06.909845 18728 layer_factory.hpp:77] Creating layer relu3_1_D
I0624 14:20:06.909850 18728 net.cpp:91] Creating Layer relu3_1_D
I0624 14:20:06.909852 18728 net.cpp:425] relu3_1_D <- conv3_1_D
I0624 14:20:06.909857 18728 net.cpp:386] relu3_1_D -> conv3_1_D (in-place)
I0624 14:20:06.910178 18728 net.cpp:141] Setting up relu3_1_D
I0624 14:20:06.910187 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.910190 18728 net.cpp:156] Memory required for data: 123533312
I0624 14:20:06.910193 18728 layer_factory.hpp:77] Creating layer upsample2
I0624 14:20:06.910198 18728 net.cpp:91] Creating Layer upsample2
I0624 14:20:06.910202 18728 net.cpp:425] upsample2 <- conv3_1_D
I0624 14:20:06.910205 18728 net.cpp:425] upsample2 <- pool2_mask
I0624 14:20:06.910212 18728 net.cpp:399] upsample2 -> pool2_D
I0624 14:20:06.910248 18728 net.cpp:141] Setting up upsample2
I0624 14:20:06.910254 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.910255 18728 net.cpp:156] Memory required for data: 126744576
I0624 14:20:06.910257 18728 layer_factory.hpp:77] Creating layer conv2_2_D
I0624 14:20:06.910267 18728 net.cpp:91] Creating Layer conv2_2_D
I0624 14:20:06.910269 18728 net.cpp:425] conv2_2_D <- pool2_D
I0624 14:20:06.910274 18728 net.cpp:399] conv2_2_D -> conv2_2_D
I0624 14:20:06.911478 18728 net.cpp:141] Setting up conv2_2_D
I0624 14:20:06.911492 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.911495 18728 net.cpp:156] Memory required for data: 129955840
I0624 14:20:06.911499 18728 layer_factory.hpp:77] Creating layer bn2_2_D
I0624 14:20:06.911506 18728 net.cpp:91] Creating Layer bn2_2_D
I0624 14:20:06.911509 18728 net.cpp:425] bn2_2_D <- conv2_2_D
I0624 14:20:06.911514 18728 net.cpp:386] bn2_2_D -> conv2_2_D (in-place)
I0624 14:20:06.912395 18728 net.cpp:141] Setting up bn2_2_D
I0624 14:20:06.912407 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.912418 18728 net.cpp:156] Memory required for data: 133167104
I0624 14:20:06.912425 18728 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 14:20:06.912433 18728 net.cpp:91] Creating Layer scale2_2_D
I0624 14:20:06.912436 18728 net.cpp:425] scale2_2_D <- conv2_2_D
I0624 14:20:06.912441 18728 net.cpp:386] scale2_2_D -> conv2_2_D (in-place)
I0624 14:20:06.912492 18728 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 14:20:06.912628 18728 net.cpp:141] Setting up scale2_2_D
I0624 14:20:06.912636 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.912639 18728 net.cpp:156] Memory required for data: 136378368
I0624 14:20:06.912643 18728 layer_factory.hpp:77] Creating layer relu2_2_D
I0624 14:20:06.912649 18728 net.cpp:91] Creating Layer relu2_2_D
I0624 14:20:06.912652 18728 net.cpp:425] relu2_2_D <- conv2_2_D
I0624 14:20:06.912655 18728 net.cpp:386] relu2_2_D -> conv2_2_D (in-place)
I0624 14:20:06.912968 18728 net.cpp:141] Setting up relu2_2_D
I0624 14:20:06.912979 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.912982 18728 net.cpp:156] Memory required for data: 139589632
I0624 14:20:06.912986 18728 layer_factory.hpp:77] Creating layer conv2_1_D
I0624 14:20:06.912993 18728 net.cpp:91] Creating Layer conv2_1_D
I0624 14:20:06.913002 18728 net.cpp:425] conv2_1_D <- conv2_2_D
I0624 14:20:06.913005 18728 net.cpp:399] conv2_1_D -> conv2_1_D
I0624 14:20:06.914232 18728 net.cpp:141] Setting up conv2_1_D
I0624 14:20:06.914243 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.914247 18728 net.cpp:156] Memory required for data: 141195264
I0624 14:20:06.914250 18728 layer_factory.hpp:77] Creating layer bn2_1_D
I0624 14:20:06.914258 18728 net.cpp:91] Creating Layer bn2_1_D
I0624 14:20:06.914260 18728 net.cpp:425] bn2_1_D <- conv2_1_D
I0624 14:20:06.914266 18728 net.cpp:386] bn2_1_D -> conv2_1_D (in-place)
I0624 14:20:06.914501 18728 net.cpp:141] Setting up bn2_1_D
I0624 14:20:06.914510 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.914511 18728 net.cpp:156] Memory required for data: 142800896
I0624 14:20:06.914517 18728 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 14:20:06.914525 18728 net.cpp:91] Creating Layer scale2_1_D
I0624 14:20:06.914527 18728 net.cpp:425] scale2_1_D <- conv2_1_D
I0624 14:20:06.914530 18728 net.cpp:386] scale2_1_D -> conv2_1_D (in-place)
I0624 14:20:06.914577 18728 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 14:20:06.914716 18728 net.cpp:141] Setting up scale2_1_D
I0624 14:20:06.914723 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.914726 18728 net.cpp:156] Memory required for data: 144406528
I0624 14:20:06.914731 18728 layer_factory.hpp:77] Creating layer relu2_1_D
I0624 14:20:06.914736 18728 net.cpp:91] Creating Layer relu2_1_D
I0624 14:20:06.914739 18728 net.cpp:425] relu2_1_D <- conv2_1_D
I0624 14:20:06.914742 18728 net.cpp:386] relu2_1_D -> conv2_1_D (in-place)
I0624 14:20:06.914903 18728 net.cpp:141] Setting up relu2_1_D
I0624 14:20:06.914912 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.914914 18728 net.cpp:156] Memory required for data: 146012160
I0624 14:20:06.914917 18728 layer_factory.hpp:77] Creating layer upsample1
I0624 14:20:06.914922 18728 net.cpp:91] Creating Layer upsample1
I0624 14:20:06.914924 18728 net.cpp:425] upsample1 <- conv2_1_D
I0624 14:20:06.914928 18728 net.cpp:425] upsample1 <- pool1_mask
I0624 14:20:06.914932 18728 net.cpp:399] upsample1 -> pool1_D
I0624 14:20:06.914965 18728 net.cpp:141] Setting up upsample1
I0624 14:20:06.914973 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.914975 18728 net.cpp:156] Memory required for data: 152434688
I0624 14:20:06.914978 18728 layer_factory.hpp:77] Creating layer conv1_2_D
I0624 14:20:06.914984 18728 net.cpp:91] Creating Layer conv1_2_D
I0624 14:20:06.914986 18728 net.cpp:425] conv1_2_D <- pool1_D
I0624 14:20:06.914991 18728 net.cpp:399] conv1_2_D -> conv1_2_D
I0624 14:20:06.916174 18728 net.cpp:141] Setting up conv1_2_D
I0624 14:20:06.916188 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.916198 18728 net.cpp:156] Memory required for data: 158857216
I0624 14:20:06.916203 18728 layer_factory.hpp:77] Creating layer bn1_2_D
I0624 14:20:06.916211 18728 net.cpp:91] Creating Layer bn1_2_D
I0624 14:20:06.916214 18728 net.cpp:425] bn1_2_D <- conv1_2_D
I0624 14:20:06.916218 18728 net.cpp:386] bn1_2_D -> conv1_2_D (in-place)
I0624 14:20:06.916493 18728 net.cpp:141] Setting up bn1_2_D
I0624 14:20:06.916501 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.916504 18728 net.cpp:156] Memory required for data: 165279744
I0624 14:20:06.916509 18728 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 14:20:06.916515 18728 net.cpp:91] Creating Layer scale1_2_D
I0624 14:20:06.916517 18728 net.cpp:425] scale1_2_D <- conv1_2_D
I0624 14:20:06.916522 18728 net.cpp:386] scale1_2_D -> conv1_2_D (in-place)
I0624 14:20:06.916574 18728 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 14:20:06.917505 18728 net.cpp:141] Setting up scale1_2_D
I0624 14:20:06.917516 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.917520 18728 net.cpp:156] Memory required for data: 171702272
I0624 14:20:06.917524 18728 layer_factory.hpp:77] Creating layer relu1_2_D
I0624 14:20:06.917529 18728 net.cpp:91] Creating Layer relu1_2_D
I0624 14:20:06.917532 18728 net.cpp:425] relu1_2_D <- conv1_2_D
I0624 14:20:06.917537 18728 net.cpp:386] relu1_2_D -> conv1_2_D (in-place)
I0624 14:20:06.917871 18728 net.cpp:141] Setting up relu1_2_D
I0624 14:20:06.917882 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.917886 18728 net.cpp:156] Memory required for data: 178124800
I0624 14:20:06.917887 18728 layer_factory.hpp:77] Creating layer conv1_1_D
I0624 14:20:06.917897 18728 net.cpp:91] Creating Layer conv1_1_D
I0624 14:20:06.917901 18728 net.cpp:425] conv1_1_D <- conv1_2_D
I0624 14:20:06.917906 18728 net.cpp:399] conv1_1_D -> conv1_1_D
I0624 14:20:06.919154 18728 net.cpp:141] Setting up conv1_1_D
I0624 14:20:06.919167 18728 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 14:20:06.919168 18728 net.cpp:156] Memory required for data: 178526208
I0624 14:20:06.919175 18728 layer_factory.hpp:77] Creating layer conv1_1_D_conv1_1_D_0_split
I0624 14:20:06.919181 18728 net.cpp:91] Creating Layer conv1_1_D_conv1_1_D_0_split
I0624 14:20:06.919184 18728 net.cpp:425] conv1_1_D_conv1_1_D_0_split <- conv1_1_D
I0624 14:20:06.919188 18728 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_0
I0624 14:20:06.919193 18728 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_1
I0624 14:20:06.919247 18728 net.cpp:141] Setting up conv1_1_D_conv1_1_D_0_split
I0624 14:20:06.919255 18728 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 14:20:06.919257 18728 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 14:20:06.919260 18728 net.cpp:156] Memory required for data: 179329024
I0624 14:20:06.919262 18728 layer_factory.hpp:77] Creating layer loss
I0624 14:20:06.919267 18728 net.cpp:91] Creating Layer loss
I0624 14:20:06.919270 18728 net.cpp:425] loss <- conv1_1_D_conv1_1_D_0_split_0
I0624 14:20:06.919272 18728 net.cpp:425] loss <- label_data_1_split_0
I0624 14:20:06.919277 18728 net.cpp:399] loss -> loss
I0624 14:20:06.919286 18728 layer_factory.hpp:77] Creating layer loss
I0624 14:20:06.919781 18728 net.cpp:141] Setting up loss
I0624 14:20:06.919792 18728 net.cpp:148] Top shape: (1)
I0624 14:20:06.919795 18728 net.cpp:151]     with loss weight 1
I0624 14:20:06.919802 18728 net.cpp:156] Memory required for data: 179329028
I0624 14:20:06.919805 18728 layer_factory.hpp:77] Creating layer accuracy
I0624 14:20:06.919809 18728 net.cpp:91] Creating Layer accuracy
I0624 14:20:06.919812 18728 net.cpp:425] accuracy <- conv1_1_D_conv1_1_D_0_split_1
I0624 14:20:06.919816 18728 net.cpp:425] accuracy <- label_data_1_split_1
I0624 14:20:06.919821 18728 net.cpp:399] accuracy -> accuracy
I0624 14:20:06.919827 18728 net.cpp:141] Setting up accuracy
I0624 14:20:06.919831 18728 net.cpp:148] Top shape: (1)
I0624 14:20:06.919832 18728 net.cpp:156] Memory required for data: 179329032
I0624 14:20:06.919843 18728 net.cpp:219] accuracy does not need backward computation.
I0624 14:20:06.919847 18728 net.cpp:217] loss needs backward computation.
I0624 14:20:06.919849 18728 net.cpp:217] conv1_1_D_conv1_1_D_0_split needs backward computation.
I0624 14:20:06.919852 18728 net.cpp:217] conv1_1_D needs backward computation.
I0624 14:20:06.919854 18728 net.cpp:217] relu1_2_D needs backward computation.
I0624 14:20:06.919857 18728 net.cpp:217] scale1_2_D needs backward computation.
I0624 14:20:06.919858 18728 net.cpp:217] bn1_2_D needs backward computation.
I0624 14:20:06.919860 18728 net.cpp:217] conv1_2_D needs backward computation.
I0624 14:20:06.919863 18728 net.cpp:217] upsample1 needs backward computation.
I0624 14:20:06.919865 18728 net.cpp:217] relu2_1_D needs backward computation.
I0624 14:20:06.919867 18728 net.cpp:217] scale2_1_D needs backward computation.
I0624 14:20:06.919869 18728 net.cpp:217] bn2_1_D needs backward computation.
I0624 14:20:06.919872 18728 net.cpp:217] conv2_1_D needs backward computation.
I0624 14:20:06.919874 18728 net.cpp:217] relu2_2_D needs backward computation.
I0624 14:20:06.919877 18728 net.cpp:217] scale2_2_D needs backward computation.
I0624 14:20:06.919878 18728 net.cpp:217] bn2_2_D needs backward computation.
I0624 14:20:06.919880 18728 net.cpp:217] conv2_2_D needs backward computation.
I0624 14:20:06.919883 18728 net.cpp:217] upsample2 needs backward computation.
I0624 14:20:06.919885 18728 net.cpp:217] relu3_1_D needs backward computation.
I0624 14:20:06.919888 18728 net.cpp:217] scale3_1_D needs backward computation.
I0624 14:20:06.919890 18728 net.cpp:217] bn3_1_D needs backward computation.
I0624 14:20:06.919893 18728 net.cpp:217] conv3_1_D needs backward computation.
I0624 14:20:06.919894 18728 net.cpp:217] relu3_2_D needs backward computation.
I0624 14:20:06.919898 18728 net.cpp:217] scale3_2_D needs backward computation.
I0624 14:20:06.919899 18728 net.cpp:217] bn3_2_D needs backward computation.
I0624 14:20:06.919901 18728 net.cpp:217] conv3_2_D needs backward computation.
I0624 14:20:06.919904 18728 net.cpp:217] upsample3 needs backward computation.
I0624 14:20:06.919908 18728 net.cpp:217] relu4_1_D needs backward computation.
I0624 14:20:06.919910 18728 net.cpp:217] scale4_1_D needs backward computation.
I0624 14:20:06.919912 18728 net.cpp:217] bn4_1_D needs backward computation.
I0624 14:20:06.919914 18728 net.cpp:217] conv4_1_D needs backward computation.
I0624 14:20:06.919917 18728 net.cpp:217] relu4_2_D needs backward computation.
I0624 14:20:06.919920 18728 net.cpp:217] scale4_2_D needs backward computation.
I0624 14:20:06.919922 18728 net.cpp:217] bn4_2_D needs backward computation.
I0624 14:20:06.919924 18728 net.cpp:217] conv4_2_D needs backward computation.
I0624 14:20:06.919927 18728 net.cpp:217] upsample4 needs backward computation.
I0624 14:20:06.919930 18728 net.cpp:217] relu5_1_D needs backward computation.
I0624 14:20:06.919934 18728 net.cpp:217] scale5_1_D needs backward computation.
I0624 14:20:06.919935 18728 net.cpp:217] bn5_1_D needs backward computation.
I0624 14:20:06.919937 18728 net.cpp:217] conv5_1_D needs backward computation.
I0624 14:20:06.919940 18728 net.cpp:217] relu5_2_D needs backward computation.
I0624 14:20:06.919942 18728 net.cpp:217] scale5_2_D needs backward computation.
I0624 14:20:06.919945 18728 net.cpp:217] bn5_2_D needs backward computation.
I0624 14:20:06.919946 18728 net.cpp:217] conv5_2_D needs backward computation.
I0624 14:20:06.919950 18728 net.cpp:217] upsample5 needs backward computation.
I0624 14:20:06.919952 18728 net.cpp:217] pool5 needs backward computation.
I0624 14:20:06.919955 18728 net.cpp:217] relu5_2 needs backward computation.
I0624 14:20:06.919957 18728 net.cpp:217] scale5_2 needs backward computation.
I0624 14:20:06.919960 18728 net.cpp:217] bn5_2 needs backward computation.
I0624 14:20:06.919961 18728 net.cpp:217] conv5_2 needs backward computation.
I0624 14:20:06.919965 18728 net.cpp:217] relu5_1 needs backward computation.
I0624 14:20:06.919967 18728 net.cpp:217] scale5_1 needs backward computation.
I0624 14:20:06.919975 18728 net.cpp:217] bn5_1 needs backward computation.
I0624 14:20:06.919978 18728 net.cpp:217] conv5_1 needs backward computation.
I0624 14:20:06.919981 18728 net.cpp:217] pool4 needs backward computation.
I0624 14:20:06.919983 18728 net.cpp:217] relu4_2 needs backward computation.
I0624 14:20:06.919986 18728 net.cpp:217] scale4_2 needs backward computation.
I0624 14:20:06.919988 18728 net.cpp:217] bn4_2 needs backward computation.
I0624 14:20:06.919991 18728 net.cpp:217] conv4_2 needs backward computation.
I0624 14:20:06.919994 18728 net.cpp:217] relu4_1 needs backward computation.
I0624 14:20:06.919996 18728 net.cpp:217] scale4_1 needs backward computation.
I0624 14:20:06.919998 18728 net.cpp:217] bn4_1 needs backward computation.
I0624 14:20:06.920001 18728 net.cpp:217] conv4_1 needs backward computation.
I0624 14:20:06.920003 18728 net.cpp:217] pool3 needs backward computation.
I0624 14:20:06.920006 18728 net.cpp:217] relu3_2 needs backward computation.
I0624 14:20:06.920008 18728 net.cpp:217] scale3_2 needs backward computation.
I0624 14:20:06.920011 18728 net.cpp:217] bn3_2 needs backward computation.
I0624 14:20:06.920013 18728 net.cpp:217] conv3_2 needs backward computation.
I0624 14:20:06.920016 18728 net.cpp:217] relu3_1 needs backward computation.
I0624 14:20:06.920018 18728 net.cpp:217] scale3_1 needs backward computation.
I0624 14:20:06.920020 18728 net.cpp:217] bn3_1 needs backward computation.
I0624 14:20:06.920022 18728 net.cpp:217] conv3_1 needs backward computation.
I0624 14:20:06.920024 18728 net.cpp:217] pool2 needs backward computation.
I0624 14:20:06.920027 18728 net.cpp:217] relu2_2 needs backward computation.
I0624 14:20:06.920029 18728 net.cpp:217] scale2_2 needs backward computation.
I0624 14:20:06.920032 18728 net.cpp:217] bn2_2 needs backward computation.
I0624 14:20:06.920034 18728 net.cpp:217] conv2_2 needs backward computation.
I0624 14:20:06.920037 18728 net.cpp:217] relu2_1 needs backward computation.
I0624 14:20:06.920039 18728 net.cpp:217] scale2_1 needs backward computation.
I0624 14:20:06.920042 18728 net.cpp:217] bn2_1 needs backward computation.
I0624 14:20:06.920043 18728 net.cpp:217] conv2_1 needs backward computation.
I0624 14:20:06.920047 18728 net.cpp:217] pool1 needs backward computation.
I0624 14:20:06.920048 18728 net.cpp:217] relu1_2 needs backward computation.
I0624 14:20:06.920053 18728 net.cpp:217] scale1_2 needs backward computation.
I0624 14:20:06.920054 18728 net.cpp:217] bn1_2 needs backward computation.
I0624 14:20:06.920056 18728 net.cpp:217] conv1_2 needs backward computation.
I0624 14:20:06.920059 18728 net.cpp:217] relu1_1 needs backward computation.
I0624 14:20:06.920061 18728 net.cpp:217] scale1_1 needs backward computation.
I0624 14:20:06.920063 18728 net.cpp:217] bn1_1 needs backward computation.
I0624 14:20:06.920066 18728 net.cpp:217] conv1_1 needs backward computation.
I0624 14:20:06.920069 18728 net.cpp:219] label_data_1_split does not need backward computation.
I0624 14:20:06.920073 18728 net.cpp:219] data does not need backward computation.
I0624 14:20:06.920074 18728 net.cpp:261] This network produces output accuracy
I0624 14:20:06.920076 18728 net.cpp:261] This network produces output loss
I0624 14:20:06.920109 18728 net.cpp:274] Network initialization done.
I0624 14:20:06.920368 18728 solver.cpp:60] Solver scaffolding done.
I0624 14:20:06.924808 18728 caffe.cpp:209] Resuming from data/models/segnet_iter_2000.solverstate
I0624 14:20:06.975622 18728 sgd_solver.cpp:318] SGDSolver: restoring history
I0624 14:20:06.997273 18728 caffe.cpp:219] Starting Optimization
I0624 14:20:06.997292 18728 solver.cpp:279] Solving segnet
I0624 14:20:06.997294 18728 solver.cpp:280] Learning Rate Policy: step
I0624 14:20:07.001029 18728 solver.cpp:337] Iteration 2000, Testing net (#0)
I0624 14:20:07.370817 18728 solver.cpp:404]     Test net output #0: accuracy = 0.983462
I0624 14:20:07.370842 18728 solver.cpp:404]     Test net output #1: loss = 0.0397269 (* 1 = 0.0397269 loss)
I0624 14:20:08.115504 18728 solver.cpp:228] Iteration 2000, loss = 0.0317226
I0624 14:20:08.115547 18728 solver.cpp:244]     Train net output #0: accuracy = 0.98713
I0624 14:20:08.115556 18728 solver.cpp:244]     Train net output #1: loss = 0.0317226 (* 1 = 0.0317226 loss)
I0624 14:20:08.115567 18728 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0624 14:20:22.424351 18728 solver.cpp:228] Iteration 2020, loss = 0.0298896
I0624 14:20:22.424388 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988878
I0624 14:20:22.424396 18728 solver.cpp:244]     Train net output #1: loss = 0.0298896 (* 1 = 0.0298896 loss)
I0624 14:20:22.424401 18728 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0624 14:20:37.055152 18728 solver.cpp:228] Iteration 2040, loss = 0.0333588
I0624 14:20:37.055220 18728 solver.cpp:244]     Train net output #0: accuracy = 0.986766
I0624 14:20:37.055230 18728 solver.cpp:244]     Train net output #1: loss = 0.0333588 (* 1 = 0.0333588 loss)
I0624 14:20:37.055234 18728 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0624 14:20:51.648465 18728 solver.cpp:228] Iteration 2060, loss = 0.0344136
I0624 14:20:51.648490 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987344
I0624 14:20:51.648499 18728 solver.cpp:244]     Train net output #1: loss = 0.0344136 (* 1 = 0.0344136 loss)
I0624 14:20:51.648504 18728 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0624 14:21:06.277082 18728 solver.cpp:228] Iteration 2080, loss = 0.0336114
I0624 14:21:06.277107 18728 solver.cpp:244]     Train net output #0: accuracy = 0.986308
I0624 14:21:06.277113 18728 solver.cpp:244]     Train net output #1: loss = 0.0336114 (* 1 = 0.0336114 loss)
I0624 14:21:06.277118 18728 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0624 14:21:20.513067 18728 solver.cpp:337] Iteration 2100, Testing net (#0)
I0624 14:21:20.848759 18728 solver.cpp:404]     Test net output #0: accuracy = 0.980658
I0624 14:21:20.848794 18728 solver.cpp:404]     Test net output #1: loss = 0.0627742 (* 1 = 0.0627742 loss)
I0624 14:21:21.258731 18728 solver.cpp:228] Iteration 2100, loss = 0.034273
I0624 14:21:21.258754 18728 solver.cpp:244]     Train net output #0: accuracy = 0.986999
I0624 14:21:21.258762 18728 solver.cpp:244]     Train net output #1: loss = 0.034273 (* 1 = 0.034273 loss)
I0624 14:21:21.258766 18728 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0624 14:21:35.901690 18728 solver.cpp:228] Iteration 2120, loss = 0.0307616
I0624 14:21:35.901713 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988964
I0624 14:21:35.901721 18728 solver.cpp:244]     Train net output #1: loss = 0.0307616 (* 1 = 0.0307616 loss)
I0624 14:21:35.901724 18728 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0624 14:21:50.720986 18728 solver.cpp:228] Iteration 2140, loss = 0.0426208
I0624 14:21:50.721084 18728 solver.cpp:244]     Train net output #0: accuracy = 0.986144
I0624 14:21:50.721094 18728 solver.cpp:244]     Train net output #1: loss = 0.0426208 (* 1 = 0.0426208 loss)
I0624 14:21:50.721099 18728 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0624 14:22:05.365671 18728 solver.cpp:228] Iteration 2160, loss = 0.0330436
I0624 14:22:05.365697 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987595
I0624 14:22:05.365705 18728 solver.cpp:244]     Train net output #1: loss = 0.0330436 (* 1 = 0.0330436 loss)
I0624 14:22:05.365710 18728 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0624 14:22:20.013093 18728 solver.cpp:228] Iteration 2180, loss = 0.0294458
I0624 14:22:20.013119 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989177
I0624 14:22:20.013126 18728 solver.cpp:244]     Train net output #1: loss = 0.0294458 (* 1 = 0.0294458 loss)
I0624 14:22:20.013131 18728 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0624 14:22:34.292227 18728 solver.cpp:337] Iteration 2200, Testing net (#0)
I0624 14:22:34.633185 18728 solver.cpp:404]     Test net output #0: accuracy = 0.982104
I0624 14:22:34.633220 18728 solver.cpp:404]     Test net output #1: loss = 0.0417979 (* 1 = 0.0417979 loss)
I0624 14:22:35.041831 18728 solver.cpp:228] Iteration 2200, loss = 0.0310358
I0624 14:22:35.041857 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988397
I0624 14:22:35.041863 18728 solver.cpp:244]     Train net output #1: loss = 0.0310358 (* 1 = 0.0310358 loss)
I0624 14:22:35.041868 18728 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0624 14:22:49.691501 18728 solver.cpp:228] Iteration 2220, loss = 0.0299741
I0624 14:22:49.691539 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988794
I0624 14:22:49.691546 18728 solver.cpp:244]     Train net output #1: loss = 0.0299741 (* 1 = 0.0299741 loss)
I0624 14:22:49.691551 18728 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0624 14:23:04.328893 18728 solver.cpp:228] Iteration 2240, loss = 0.0320167
I0624 14:23:04.329016 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988016
I0624 14:23:04.329027 18728 solver.cpp:244]     Train net output #1: loss = 0.0320167 (* 1 = 0.0320167 loss)
I0624 14:23:04.329032 18728 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0624 14:23:18.985420 18728 solver.cpp:228] Iteration 2260, loss = 0.0313044
I0624 14:23:18.985445 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988634
I0624 14:23:18.985452 18728 solver.cpp:244]     Train net output #1: loss = 0.0313044 (* 1 = 0.0313044 loss)
I0624 14:23:18.985457 18728 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0624 14:23:33.628046 18728 solver.cpp:228] Iteration 2280, loss = 0.0313787
I0624 14:23:33.628070 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989053
I0624 14:23:33.628077 18728 solver.cpp:244]     Train net output #1: loss = 0.0313787 (* 1 = 0.0313787 loss)
I0624 14:23:33.628082 18728 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0624 14:23:47.869063 18728 solver.cpp:337] Iteration 2300, Testing net (#0)
I0624 14:23:48.204766 18728 solver.cpp:404]     Test net output #0: accuracy = 0.977892
I0624 14:23:48.204790 18728 solver.cpp:404]     Test net output #1: loss = 0.0605657 (* 1 = 0.0605657 loss)
I0624 14:23:48.614558 18728 solver.cpp:228] Iteration 2300, loss = 0.0331856
I0624 14:23:48.614585 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987714
I0624 14:23:48.614593 18728 solver.cpp:244]     Train net output #1: loss = 0.0331856 (* 1 = 0.0331856 loss)
I0624 14:23:48.614598 18728 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0624 14:24:03.259907 18728 solver.cpp:228] Iteration 2320, loss = 0.0343364
I0624 14:24:03.259943 18728 solver.cpp:244]     Train net output #0: accuracy = 0.986205
I0624 14:24:03.259949 18728 solver.cpp:244]     Train net output #1: loss = 0.0343364 (* 1 = 0.0343364 loss)
I0624 14:24:03.259954 18728 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0624 14:24:17.897599 18728 solver.cpp:228] Iteration 2340, loss = 0.0304078
I0624 14:24:17.897693 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988684
I0624 14:24:17.897702 18728 solver.cpp:244]     Train net output #1: loss = 0.0304078 (* 1 = 0.0304078 loss)
I0624 14:24:17.897706 18728 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0624 14:24:32.552338 18728 solver.cpp:228] Iteration 2360, loss = 0.0286672
I0624 14:24:32.552372 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989297
I0624 14:24:32.552391 18728 solver.cpp:244]     Train net output #1: loss = 0.0286672 (* 1 = 0.0286672 loss)
I0624 14:24:32.552395 18728 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0624 14:24:47.209746 18728 solver.cpp:228] Iteration 2380, loss = 0.0308837
I0624 14:24:47.209774 18728 solver.cpp:244]     Train net output #0: accuracy = 0.98862
I0624 14:24:47.209780 18728 solver.cpp:244]     Train net output #1: loss = 0.0308837 (* 1 = 0.0308837 loss)
I0624 14:24:47.209785 18728 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0624 14:25:01.444952 18728 solver.cpp:337] Iteration 2400, Testing net (#0)
I0624 14:25:01.780772 18728 solver.cpp:404]     Test net output #0: accuracy = 0.979872
I0624 14:25:01.780797 18728 solver.cpp:404]     Test net output #1: loss = 0.0669868 (* 1 = 0.0669868 loss)
I0624 14:25:02.191479 18728 solver.cpp:228] Iteration 2400, loss = 0.0305465
I0624 14:25:02.191514 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988893
I0624 14:25:02.191522 18728 solver.cpp:244]     Train net output #1: loss = 0.0305465 (* 1 = 0.0305465 loss)
I0624 14:25:02.191526 18728 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0624 14:25:16.832619 18728 solver.cpp:228] Iteration 2420, loss = 0.0368938
I0624 14:25:16.832646 18728 solver.cpp:244]     Train net output #0: accuracy = 0.985576
I0624 14:25:16.832653 18728 solver.cpp:244]     Train net output #1: loss = 0.0368938 (* 1 = 0.0368938 loss)
I0624 14:25:16.832659 18728 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0624 14:25:31.479349 18728 solver.cpp:228] Iteration 2440, loss = 0.0330062
I0624 14:25:31.479465 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987242
I0624 14:25:31.479476 18728 solver.cpp:244]     Train net output #1: loss = 0.0330062 (* 1 = 0.0330062 loss)
I0624 14:25:31.479481 18728 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0624 14:25:46.127055 18728 solver.cpp:228] Iteration 2460, loss = 0.0321805
I0624 14:25:46.127081 18728 solver.cpp:244]     Train net output #0: accuracy = 0.98811
I0624 14:25:46.127089 18728 solver.cpp:244]     Train net output #1: loss = 0.0321805 (* 1 = 0.0321805 loss)
I0624 14:25:46.127092 18728 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0624 14:26:00.804774 18728 solver.cpp:228] Iteration 2480, loss = 0.0287155
I0624 14:26:00.804802 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989527
I0624 14:26:00.804811 18728 solver.cpp:244]     Train net output #1: loss = 0.0287155 (* 1 = 0.0287155 loss)
I0624 14:26:00.804816 18728 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0624 14:26:15.043617 18728 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_2500.caffemodel
I0624 14:26:15.085929 18728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_2500.solverstate
I0624 14:26:15.105268 18728 solver.cpp:337] Iteration 2500, Testing net (#0)
I0624 14:26:15.443189 18728 solver.cpp:404]     Test net output #0: accuracy = 0.979984
I0624 14:26:15.443213 18728 solver.cpp:404]     Test net output #1: loss = 0.0514456 (* 1 = 0.0514456 loss)
I0624 14:26:15.853430 18728 solver.cpp:228] Iteration 2500, loss = 0.0332934
I0624 14:26:15.853456 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987084
I0624 14:26:15.853462 18728 solver.cpp:244]     Train net output #1: loss = 0.0332934 (* 1 = 0.0332934 loss)
I0624 14:26:15.853466 18728 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0624 14:26:30.504237 18728 solver.cpp:228] Iteration 2520, loss = 0.0326524
I0624 14:26:30.504261 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987535
I0624 14:26:30.504279 18728 solver.cpp:244]     Train net output #1: loss = 0.0326524 (* 1 = 0.0326524 loss)
I0624 14:26:30.504284 18728 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0624 14:26:45.160706 18728 solver.cpp:228] Iteration 2540, loss = 0.0303533
I0624 14:26:45.160809 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988347
I0624 14:26:45.160820 18728 solver.cpp:244]     Train net output #1: loss = 0.0303533 (* 1 = 0.0303533 loss)
I0624 14:26:45.160825 18728 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0624 14:26:59.809756 18728 solver.cpp:228] Iteration 2560, loss = 0.030792
I0624 14:26:59.809780 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989018
I0624 14:26:59.809787 18728 solver.cpp:244]     Train net output #1: loss = 0.030792 (* 1 = 0.030792 loss)
I0624 14:26:59.809792 18728 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0624 14:27:14.478257 18728 solver.cpp:228] Iteration 2580, loss = 0.0322687
I0624 14:27:14.478282 18728 solver.cpp:244]     Train net output #0: accuracy = 0.98748
I0624 14:27:14.478291 18728 solver.cpp:244]     Train net output #1: loss = 0.0322687 (* 1 = 0.0322687 loss)
I0624 14:27:14.478296 18728 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0624 14:27:28.725553 18728 solver.cpp:337] Iteration 2600, Testing net (#0)
I0624 14:27:29.060778 18728 solver.cpp:404]     Test net output #0: accuracy = 0.980506
I0624 14:27:29.060813 18728 solver.cpp:404]     Test net output #1: loss = 0.0549367 (* 1 = 0.0549367 loss)
I0624 14:27:29.471688 18728 solver.cpp:228] Iteration 2600, loss = 0.0323618
I0624 14:27:29.471712 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987846
I0624 14:27:29.471720 18728 solver.cpp:244]     Train net output #1: loss = 0.0323618 (* 1 = 0.0323618 loss)
I0624 14:27:29.471725 18728 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0624 14:27:44.119618 18728 solver.cpp:228] Iteration 2620, loss = 0.0321162
I0624 14:27:44.119644 18728 solver.cpp:244]     Train net output #0: accuracy = 0.98763
I0624 14:27:44.119652 18728 solver.cpp:244]     Train net output #1: loss = 0.0321162 (* 1 = 0.0321162 loss)
I0624 14:27:44.119657 18728 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0624 14:27:58.786159 18728 solver.cpp:228] Iteration 2640, loss = 0.0320101
I0624 14:27:58.786247 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988434
I0624 14:27:58.786257 18728 solver.cpp:244]     Train net output #1: loss = 0.0320101 (* 1 = 0.0320101 loss)
I0624 14:27:58.786262 18728 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0624 14:28:13.439697 18728 solver.cpp:228] Iteration 2660, loss = 0.0293895
I0624 14:28:13.439723 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989667
I0624 14:28:13.439730 18728 solver.cpp:244]     Train net output #1: loss = 0.0293895 (* 1 = 0.0293895 loss)
I0624 14:28:13.439734 18728 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0624 14:28:28.075433 18728 solver.cpp:228] Iteration 2680, loss = 0.0297104
I0624 14:28:28.075458 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988534
I0624 14:28:28.075465 18728 solver.cpp:244]     Train net output #1: loss = 0.0297104 (* 1 = 0.0297104 loss)
I0624 14:28:28.075470 18728 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0624 14:28:42.344488 18728 solver.cpp:337] Iteration 2700, Testing net (#0)
I0624 14:28:42.679868 18728 solver.cpp:404]     Test net output #0: accuracy = 0.983454
I0624 14:28:42.679903 18728 solver.cpp:404]     Test net output #1: loss = 0.0447403 (* 1 = 0.0447403 loss)
I0624 14:28:43.090044 18728 solver.cpp:228] Iteration 2700, loss = 0.0320494
I0624 14:28:43.090077 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987382
I0624 14:28:43.090085 18728 solver.cpp:244]     Train net output #1: loss = 0.0320494 (* 1 = 0.0320494 loss)
I0624 14:28:43.090090 18728 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0624 14:28:57.725275 18728 solver.cpp:228] Iteration 2720, loss = 0.0294747
I0624 14:28:57.725299 18728 solver.cpp:244]     Train net output #0: accuracy = 0.98947
I0624 14:28:57.725307 18728 solver.cpp:244]     Train net output #1: loss = 0.0294747 (* 1 = 0.0294747 loss)
I0624 14:28:57.725312 18728 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0624 14:29:12.361052 18728 solver.cpp:228] Iteration 2740, loss = 0.0304899
I0624 14:29:12.361150 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988651
I0624 14:29:12.361160 18728 solver.cpp:244]     Train net output #1: loss = 0.0304899 (* 1 = 0.0304899 loss)
I0624 14:29:12.361165 18728 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0624 14:29:27.007299 18728 solver.cpp:228] Iteration 2760, loss = 0.0337582
I0624 14:29:27.007325 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987621
I0624 14:29:27.007333 18728 solver.cpp:244]     Train net output #1: loss = 0.0337582 (* 1 = 0.0337582 loss)
I0624 14:29:27.007339 18728 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0624 14:29:41.643795 18728 solver.cpp:228] Iteration 2780, loss = 0.0312958
I0624 14:29:41.643821 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988855
I0624 14:29:41.643827 18728 solver.cpp:244]     Train net output #1: loss = 0.0312958 (* 1 = 0.0312958 loss)
I0624 14:29:41.643832 18728 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0624 14:29:55.885380 18728 solver.cpp:337] Iteration 2800, Testing net (#0)
I0624 14:29:56.221424 18728 solver.cpp:404]     Test net output #0: accuracy = 0.977479
I0624 14:29:56.221449 18728 solver.cpp:404]     Test net output #1: loss = 0.0648069 (* 1 = 0.0648069 loss)
I0624 14:29:56.633036 18728 solver.cpp:228] Iteration 2800, loss = 0.0273738
I0624 14:29:56.633072 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989919
I0624 14:29:56.633080 18728 solver.cpp:244]     Train net output #1: loss = 0.0273738 (* 1 = 0.0273738 loss)
I0624 14:29:56.633086 18728 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0624 14:30:11.281976 18728 solver.cpp:228] Iteration 2820, loss = 0.0307217
I0624 14:30:11.282001 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987974
I0624 14:30:11.282011 18728 solver.cpp:244]     Train net output #1: loss = 0.0307217 (* 1 = 0.0307217 loss)
I0624 14:30:11.282014 18728 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0624 14:30:25.921934 18728 solver.cpp:228] Iteration 2840, loss = 0.0295506
I0624 14:30:25.922040 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989234
I0624 14:30:25.922050 18728 solver.cpp:244]     Train net output #1: loss = 0.0295506 (* 1 = 0.0295506 loss)
I0624 14:30:25.922055 18728 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0624 14:30:40.598812 18728 solver.cpp:228] Iteration 2860, loss = 0.0286551
I0624 14:30:40.598847 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989531
I0624 14:30:40.598855 18728 solver.cpp:244]     Train net output #1: loss = 0.0286551 (* 1 = 0.0286551 loss)
I0624 14:30:40.598860 18728 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0624 14:30:55.237862 18728 solver.cpp:228] Iteration 2880, loss = 0.0289909
I0624 14:30:55.237886 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989258
I0624 14:30:55.237893 18728 solver.cpp:244]     Train net output #1: loss = 0.0289909 (* 1 = 0.0289909 loss)
I0624 14:30:55.237898 18728 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0624 14:31:09.473880 18728 solver.cpp:337] Iteration 2900, Testing net (#0)
I0624 14:31:09.809751 18728 solver.cpp:404]     Test net output #0: accuracy = 0.979597
I0624 14:31:09.809787 18728 solver.cpp:404]     Test net output #1: loss = 0.0582538 (* 1 = 0.0582538 loss)
I0624 14:31:10.219909 18728 solver.cpp:228] Iteration 2900, loss = 0.0298889
I0624 14:31:10.219934 18728 solver.cpp:244]     Train net output #0: accuracy = 0.98925
I0624 14:31:10.219941 18728 solver.cpp:244]     Train net output #1: loss = 0.0298889 (* 1 = 0.0298889 loss)
I0624 14:31:10.219946 18728 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0624 14:31:24.868592 18728 solver.cpp:228] Iteration 2920, loss = 0.0337292
I0624 14:31:24.868616 18728 solver.cpp:244]     Train net output #0: accuracy = 0.986671
I0624 14:31:24.868624 18728 solver.cpp:244]     Train net output #1: loss = 0.0337292 (* 1 = 0.0337292 loss)
I0624 14:31:24.868629 18728 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0624 14:31:39.506940 18728 solver.cpp:228] Iteration 2940, loss = 0.0328489
I0624 14:31:39.507038 18728 solver.cpp:244]     Train net output #0: accuracy = 0.986701
I0624 14:31:39.507047 18728 solver.cpp:244]     Train net output #1: loss = 0.0328489 (* 1 = 0.0328489 loss)
I0624 14:31:39.507053 18728 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0624 14:31:54.149323 18728 solver.cpp:228] Iteration 2960, loss = 0.0283015
I0624 14:31:54.149348 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989597
I0624 14:31:54.149356 18728 solver.cpp:244]     Train net output #1: loss = 0.0283015 (* 1 = 0.0283015 loss)
I0624 14:31:54.149361 18728 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0624 14:32:08.805663 18728 solver.cpp:228] Iteration 2980, loss = 0.0315007
I0624 14:32:08.805701 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988378
I0624 14:32:08.805708 18728 solver.cpp:244]     Train net output #1: loss = 0.0315007 (* 1 = 0.0315007 loss)
I0624 14:32:08.805713 18728 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0624 14:32:23.058611 18728 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_3000.caffemodel
I0624 14:32:23.101297 18728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_3000.solverstate
I0624 14:32:23.120932 18728 solver.cpp:337] Iteration 3000, Testing net (#0)
I0624 14:32:23.459411 18728 solver.cpp:404]     Test net output #0: accuracy = 0.973141
I0624 14:32:23.459435 18728 solver.cpp:404]     Test net output #1: loss = 0.0841991 (* 1 = 0.0841991 loss)
I0624 14:32:23.869161 18728 solver.cpp:228] Iteration 3000, loss = 0.0315932
I0624 14:32:23.869187 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988852
I0624 14:32:23.869194 18728 solver.cpp:244]     Train net output #1: loss = 0.0315932 (* 1 = 0.0315932 loss)
I0624 14:32:23.869199 18728 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0624 14:32:38.564853 18728 solver.cpp:228] Iteration 3020, loss = 0.0274211
I0624 14:32:38.564890 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989916
I0624 14:32:38.564898 18728 solver.cpp:244]     Train net output #1: loss = 0.0274211 (* 1 = 0.0274211 loss)
I0624 14:32:38.564903 18728 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0624 14:32:53.222456 18728 solver.cpp:228] Iteration 3040, loss = 0.0294709
I0624 14:32:53.222579 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988824
I0624 14:32:53.222589 18728 solver.cpp:244]     Train net output #1: loss = 0.0294709 (* 1 = 0.0294709 loss)
I0624 14:32:53.222594 18728 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0624 14:33:07.884918 18728 solver.cpp:228] Iteration 3060, loss = 0.028989
I0624 14:33:07.884945 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989346
I0624 14:33:07.884953 18728 solver.cpp:244]     Train net output #1: loss = 0.028989 (* 1 = 0.028989 loss)
I0624 14:33:07.884958 18728 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0624 14:33:22.542104 18728 solver.cpp:228] Iteration 3080, loss = 0.0284576
I0624 14:33:22.542129 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988983
I0624 14:33:22.542135 18728 solver.cpp:244]     Train net output #1: loss = 0.0284576 (* 1 = 0.0284576 loss)
I0624 14:33:22.542140 18728 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0624 14:33:36.773969 18728 solver.cpp:337] Iteration 3100, Testing net (#0)
I0624 14:33:37.109563 18728 solver.cpp:404]     Test net output #0: accuracy = 0.983428
I0624 14:33:37.109597 18728 solver.cpp:404]     Test net output #1: loss = 0.0509554 (* 1 = 0.0509554 loss)
I0624 14:33:37.519773 18728 solver.cpp:228] Iteration 3100, loss = 0.0318339
I0624 14:33:37.519798 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988854
I0624 14:33:37.519805 18728 solver.cpp:244]     Train net output #1: loss = 0.0318339 (* 1 = 0.0318339 loss)
I0624 14:33:37.519810 18728 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0624 14:33:52.167330 18728 solver.cpp:228] Iteration 3120, loss = 0.0323391
I0624 14:33:52.167356 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987329
I0624 14:33:52.167363 18728 solver.cpp:244]     Train net output #1: loss = 0.0323391 (* 1 = 0.0323391 loss)
I0624 14:33:52.167369 18728 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0624 14:34:06.816234 18728 solver.cpp:228] Iteration 3140, loss = 0.0317778
I0624 14:34:06.816334 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988009
I0624 14:34:06.816342 18728 solver.cpp:244]     Train net output #1: loss = 0.0317778 (* 1 = 0.0317778 loss)
I0624 14:34:06.816346 18728 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0624 14:34:21.533946 18728 solver.cpp:228] Iteration 3160, loss = 0.0302634
I0624 14:34:21.533970 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988563
I0624 14:34:21.533978 18728 solver.cpp:244]     Train net output #1: loss = 0.0302634 (* 1 = 0.0302634 loss)
I0624 14:34:21.533983 18728 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0624 14:34:36.213848 18728 solver.cpp:228] Iteration 3180, loss = 0.0309452
I0624 14:34:36.213882 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988403
I0624 14:34:36.213891 18728 solver.cpp:244]     Train net output #1: loss = 0.0309452 (* 1 = 0.0309452 loss)
I0624 14:34:36.213896 18728 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0624 14:34:50.470705 18728 solver.cpp:337] Iteration 3200, Testing net (#0)
I0624 14:34:50.806445 18728 solver.cpp:404]     Test net output #0: accuracy = 0.980993
I0624 14:34:50.806470 18728 solver.cpp:404]     Test net output #1: loss = 0.0659193 (* 1 = 0.0659193 loss)
I0624 14:34:51.217998 18728 solver.cpp:228] Iteration 3200, loss = 0.0369511
I0624 14:34:51.218034 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987984
I0624 14:34:51.218042 18728 solver.cpp:244]     Train net output #1: loss = 0.0369511 (* 1 = 0.0369511 loss)
I0624 14:34:51.218047 18728 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0624 14:35:05.890123 18728 solver.cpp:228] Iteration 3220, loss = 0.0314893
I0624 14:35:05.890151 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988073
I0624 14:35:05.890169 18728 solver.cpp:244]     Train net output #1: loss = 0.0314893 (* 1 = 0.0314893 loss)
I0624 14:35:05.890175 18728 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0624 14:35:20.535902 18728 solver.cpp:228] Iteration 3240, loss = 0.0299134
I0624 14:35:20.536005 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988626
I0624 14:35:20.536015 18728 solver.cpp:244]     Train net output #1: loss = 0.0299134 (* 1 = 0.0299134 loss)
I0624 14:35:20.536020 18728 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0624 14:35:35.191922 18728 solver.cpp:228] Iteration 3260, loss = 0.0336353
I0624 14:35:35.191948 18728 solver.cpp:244]     Train net output #0: accuracy = 0.986309
I0624 14:35:35.191956 18728 solver.cpp:244]     Train net output #1: loss = 0.0336353 (* 1 = 0.0336353 loss)
I0624 14:35:35.191961 18728 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0624 14:35:49.825247 18728 solver.cpp:228] Iteration 3280, loss = 0.0288521
I0624 14:35:49.825270 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988816
I0624 14:35:49.825278 18728 solver.cpp:244]     Train net output #1: loss = 0.0288521 (* 1 = 0.0288521 loss)
I0624 14:35:49.825284 18728 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0624 14:36:04.053778 18728 solver.cpp:337] Iteration 3300, Testing net (#0)
I0624 14:36:04.389535 18728 solver.cpp:404]     Test net output #0: accuracy = 0.978965
I0624 14:36:04.389570 18728 solver.cpp:404]     Test net output #1: loss = 0.0644335 (* 1 = 0.0644335 loss)
I0624 14:36:04.798710 18728 solver.cpp:228] Iteration 3300, loss = 0.0299188
I0624 14:36:04.798734 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988323
I0624 14:36:04.798743 18728 solver.cpp:244]     Train net output #1: loss = 0.0299188 (* 1 = 0.0299188 loss)
I0624 14:36:04.798748 18728 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0624 14:36:19.436672 18728 solver.cpp:228] Iteration 3320, loss = 0.0292175
I0624 14:36:19.436697 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989072
I0624 14:36:19.436704 18728 solver.cpp:244]     Train net output #1: loss = 0.0292175 (* 1 = 0.0292175 loss)
I0624 14:36:19.436709 18728 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0624 14:36:34.132333 18728 solver.cpp:228] Iteration 3340, loss = 0.0253796
I0624 14:36:34.132433 18728 solver.cpp:244]     Train net output #0: accuracy = 0.990725
I0624 14:36:34.132442 18728 solver.cpp:244]     Train net output #1: loss = 0.0253796 (* 1 = 0.0253796 loss)
I0624 14:36:34.132447 18728 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0624 14:36:48.769639 18728 solver.cpp:228] Iteration 3360, loss = 0.0309913
I0624 14:36:48.769665 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988347
I0624 14:36:48.769671 18728 solver.cpp:244]     Train net output #1: loss = 0.0309913 (* 1 = 0.0309913 loss)
I0624 14:36:48.769676 18728 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0624 14:37:03.404404 18728 solver.cpp:228] Iteration 3380, loss = 0.0297397
I0624 14:37:03.404429 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988971
I0624 14:37:03.404436 18728 solver.cpp:244]     Train net output #1: loss = 0.0297397 (* 1 = 0.0297397 loss)
I0624 14:37:03.404440 18728 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0624 14:37:17.628885 18728 solver.cpp:337] Iteration 3400, Testing net (#0)
I0624 14:37:17.964864 18728 solver.cpp:404]     Test net output #0: accuracy = 0.983119
I0624 14:37:17.964887 18728 solver.cpp:404]     Test net output #1: loss = 0.05091 (* 1 = 0.05091 loss)
I0624 14:37:18.375226 18728 solver.cpp:228] Iteration 3400, loss = 0.0290371
I0624 14:37:18.375262 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989399
I0624 14:37:18.375269 18728 solver.cpp:244]     Train net output #1: loss = 0.0290371 (* 1 = 0.0290371 loss)
I0624 14:37:18.375274 18728 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0624 14:37:33.005058 18728 solver.cpp:228] Iteration 3420, loss = 0.0320369
I0624 14:37:33.005084 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987749
I0624 14:37:33.005090 18728 solver.cpp:244]     Train net output #1: loss = 0.0320369 (* 1 = 0.0320369 loss)
I0624 14:37:33.005095 18728 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0624 14:37:47.630008 18728 solver.cpp:228] Iteration 3440, loss = 0.0305586
I0624 14:37:47.630110 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988712
I0624 14:37:47.630118 18728 solver.cpp:244]     Train net output #1: loss = 0.0305586 (* 1 = 0.0305586 loss)
I0624 14:37:47.630123 18728 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0624 14:38:02.269814 18728 solver.cpp:228] Iteration 3460, loss = 0.0288126
I0624 14:38:02.269840 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989516
I0624 14:38:02.269846 18728 solver.cpp:244]     Train net output #1: loss = 0.0288126 (* 1 = 0.0288126 loss)
I0624 14:38:02.269852 18728 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0624 14:38:16.909931 18728 solver.cpp:228] Iteration 3480, loss = 0.0325279
I0624 14:38:16.909955 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987791
I0624 14:38:16.909963 18728 solver.cpp:244]     Train net output #1: loss = 0.0325279 (* 1 = 0.0325279 loss)
I0624 14:38:16.909968 18728 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0624 14:38:31.178711 18728 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_3500.caffemodel
I0624 14:38:31.225046 18728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_3500.solverstate
I0624 14:38:31.244412 18728 solver.cpp:337] Iteration 3500, Testing net (#0)
I0624 14:38:31.583062 18728 solver.cpp:404]     Test net output #0: accuracy = 0.978727
I0624 14:38:31.583098 18728 solver.cpp:404]     Test net output #1: loss = 0.0646643 (* 1 = 0.0646643 loss)
I0624 14:38:31.997580 18728 solver.cpp:228] Iteration 3500, loss = 0.0292591
I0624 14:38:31.997603 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989345
I0624 14:38:31.997611 18728 solver.cpp:244]     Train net output #1: loss = 0.0292591 (* 1 = 0.0292591 loss)
I0624 14:38:31.997617 18728 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0624 14:38:46.648941 18728 solver.cpp:228] Iteration 3520, loss = 0.0303442
I0624 14:38:46.648964 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988631
I0624 14:38:46.648983 18728 solver.cpp:244]     Train net output #1: loss = 0.0303442 (* 1 = 0.0303442 loss)
I0624 14:38:46.648988 18728 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0624 14:39:01.300587 18728 solver.cpp:228] Iteration 3540, loss = 0.0289428
I0624 14:39:01.300683 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989156
I0624 14:39:01.300691 18728 solver.cpp:244]     Train net output #1: loss = 0.0289428 (* 1 = 0.0289428 loss)
I0624 14:39:01.300696 18728 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0624 14:39:15.951899 18728 solver.cpp:228] Iteration 3560, loss = 0.0306273
I0624 14:39:15.951934 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988342
I0624 14:39:15.951941 18728 solver.cpp:244]     Train net output #1: loss = 0.0306273 (* 1 = 0.0306273 loss)
I0624 14:39:15.951946 18728 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0624 14:39:30.631451 18728 solver.cpp:228] Iteration 3580, loss = 0.0299322
I0624 14:39:30.631476 18728 solver.cpp:244]     Train net output #0: accuracy = 0.98869
I0624 14:39:30.631484 18728 solver.cpp:244]     Train net output #1: loss = 0.0299322 (* 1 = 0.0299322 loss)
I0624 14:39:30.631489 18728 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0624 14:39:44.871708 18728 solver.cpp:337] Iteration 3600, Testing net (#0)
I0624 14:39:45.207295 18728 solver.cpp:404]     Test net output #0: accuracy = 0.983765
I0624 14:39:45.207319 18728 solver.cpp:404]     Test net output #1: loss = 0.053445 (* 1 = 0.053445 loss)
I0624 14:39:45.616375 18728 solver.cpp:228] Iteration 3600, loss = 0.0302645
I0624 14:39:45.616401 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989032
I0624 14:39:45.616410 18728 solver.cpp:244]     Train net output #1: loss = 0.0302645 (* 1 = 0.0302645 loss)
I0624 14:39:45.616415 18728 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0624 14:40:00.266024 18728 solver.cpp:228] Iteration 3620, loss = 0.0306041
I0624 14:40:00.266049 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988506
I0624 14:40:00.266057 18728 solver.cpp:244]     Train net output #1: loss = 0.0306041 (* 1 = 0.0306041 loss)
I0624 14:40:00.266062 18728 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0624 14:40:14.915181 18728 solver.cpp:228] Iteration 3640, loss = 0.0309513
I0624 14:40:14.915285 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987666
I0624 14:40:14.915295 18728 solver.cpp:244]     Train net output #1: loss = 0.0309513 (* 1 = 0.0309513 loss)
I0624 14:40:14.915300 18728 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0624 14:40:29.562108 18728 solver.cpp:228] Iteration 3660, loss = 0.0305484
I0624 14:40:29.562131 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988634
I0624 14:40:29.562139 18728 solver.cpp:244]     Train net output #1: loss = 0.0305484 (* 1 = 0.0305484 loss)
I0624 14:40:29.562144 18728 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0624 14:40:44.263381 18728 solver.cpp:228] Iteration 3680, loss = 0.0298361
I0624 14:40:44.263404 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988422
I0624 14:40:44.263411 18728 solver.cpp:244]     Train net output #1: loss = 0.0298361 (* 1 = 0.0298361 loss)
I0624 14:40:44.263417 18728 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0624 14:40:58.498114 18728 solver.cpp:337] Iteration 3700, Testing net (#0)
I0624 14:40:58.834102 18728 solver.cpp:404]     Test net output #0: accuracy = 0.981582
I0624 14:40:58.834137 18728 solver.cpp:404]     Test net output #1: loss = 0.0468329 (* 1 = 0.0468329 loss)
I0624 14:40:59.243199 18728 solver.cpp:228] Iteration 3700, loss = 0.0309392
I0624 14:40:59.243224 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988101
I0624 14:40:59.243232 18728 solver.cpp:244]     Train net output #1: loss = 0.0309392 (* 1 = 0.0309392 loss)
I0624 14:40:59.243237 18728 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0624 14:41:13.875063 18728 solver.cpp:228] Iteration 3720, loss = 0.0303671
I0624 14:41:13.875088 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987521
I0624 14:41:13.875097 18728 solver.cpp:244]     Train net output #1: loss = 0.0303671 (* 1 = 0.0303671 loss)
I0624 14:41:13.875102 18728 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0624 14:41:28.506929 18728 solver.cpp:228] Iteration 3740, loss = 0.0311839
I0624 14:41:28.507030 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988753
I0624 14:41:28.507038 18728 solver.cpp:244]     Train net output #1: loss = 0.0311839 (* 1 = 0.0311839 loss)
I0624 14:41:28.507043 18728 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0624 14:41:43.140282 18728 solver.cpp:228] Iteration 3760, loss = 0.0295377
I0624 14:41:43.140305 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988982
I0624 14:41:43.140312 18728 solver.cpp:244]     Train net output #1: loss = 0.0295377 (* 1 = 0.0295377 loss)
I0624 14:41:43.140317 18728 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0624 14:41:57.796167 18728 solver.cpp:228] Iteration 3780, loss = 0.0307578
I0624 14:41:57.796192 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988339
I0624 14:41:57.796200 18728 solver.cpp:244]     Train net output #1: loss = 0.0307578 (* 1 = 0.0307578 loss)
I0624 14:41:57.796205 18728 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0624 14:42:12.039404 18728 solver.cpp:337] Iteration 3800, Testing net (#0)
I0624 14:42:12.375279 18728 solver.cpp:404]     Test net output #0: accuracy = 0.983232
I0624 14:42:12.375304 18728 solver.cpp:404]     Test net output #1: loss = 0.0498639 (* 1 = 0.0498639 loss)
I0624 14:42:12.785820 18728 solver.cpp:228] Iteration 3800, loss = 0.0262013
I0624 14:42:12.785848 18728 solver.cpp:244]     Train net output #0: accuracy = 0.990301
I0624 14:42:12.785856 18728 solver.cpp:244]     Train net output #1: loss = 0.0262013 (* 1 = 0.0262013 loss)
I0624 14:42:12.785861 18728 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0624 14:42:27.432337 18728 solver.cpp:228] Iteration 3820, loss = 0.0323588
I0624 14:42:27.432374 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987526
I0624 14:42:27.432381 18728 solver.cpp:244]     Train net output #1: loss = 0.0323588 (* 1 = 0.0323588 loss)
I0624 14:42:27.432385 18728 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0624 14:42:42.142011 18728 solver.cpp:228] Iteration 3840, loss = 0.0296228
I0624 14:42:42.142112 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988794
I0624 14:42:42.142122 18728 solver.cpp:244]     Train net output #1: loss = 0.0296228 (* 1 = 0.0296228 loss)
I0624 14:42:42.142127 18728 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0624 14:42:56.773892 18728 solver.cpp:228] Iteration 3860, loss = 0.0263012
I0624 14:42:56.773919 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989802
I0624 14:42:56.773927 18728 solver.cpp:244]     Train net output #1: loss = 0.0263012 (* 1 = 0.0263012 loss)
I0624 14:42:56.773931 18728 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0624 14:43:11.433778 18728 solver.cpp:228] Iteration 3880, loss = 0.0280846
I0624 14:43:11.433804 18728 solver.cpp:244]     Train net output #0: accuracy = 0.98983
I0624 14:43:11.433812 18728 solver.cpp:244]     Train net output #1: loss = 0.0280846 (* 1 = 0.0280846 loss)
I0624 14:43:11.433816 18728 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0624 14:43:25.693490 18728 solver.cpp:337] Iteration 3900, Testing net (#0)
I0624 14:43:26.030292 18728 solver.cpp:404]     Test net output #0: accuracy = 0.980901
I0624 14:43:26.030315 18728 solver.cpp:404]     Test net output #1: loss = 0.0501452 (* 1 = 0.0501452 loss)
I0624 14:43:26.440155 18728 solver.cpp:228] Iteration 3900, loss = 0.0247121
I0624 14:43:26.440178 18728 solver.cpp:244]     Train net output #0: accuracy = 0.991136
I0624 14:43:26.440186 18728 solver.cpp:244]     Train net output #1: loss = 0.0247121 (* 1 = 0.0247121 loss)
I0624 14:43:26.440191 18728 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0624 14:43:41.088313 18728 solver.cpp:228] Iteration 3920, loss = 0.0302876
I0624 14:43:41.088340 18728 solver.cpp:244]     Train net output #0: accuracy = 0.9892
I0624 14:43:41.088346 18728 solver.cpp:244]     Train net output #1: loss = 0.0302876 (* 1 = 0.0302876 loss)
I0624 14:43:41.088351 18728 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0624 14:43:55.743484 18728 solver.cpp:228] Iteration 3940, loss = 0.0283625
I0624 14:43:55.743587 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989316
I0624 14:43:55.743597 18728 solver.cpp:244]     Train net output #1: loss = 0.0283625 (* 1 = 0.0283625 loss)
I0624 14:43:55.743602 18728 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0624 14:44:10.401749 18728 solver.cpp:228] Iteration 3960, loss = 0.0316653
I0624 14:44:10.401774 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987885
I0624 14:44:10.401782 18728 solver.cpp:244]     Train net output #1: loss = 0.0316653 (* 1 = 0.0316653 loss)
I0624 14:44:10.401787 18728 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0624 14:44:25.055371 18728 solver.cpp:228] Iteration 3980, loss = 0.0318505
I0624 14:44:25.055394 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988198
I0624 14:44:25.055402 18728 solver.cpp:244]     Train net output #1: loss = 0.0318505 (* 1 = 0.0318505 loss)
I0624 14:44:25.055407 18728 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0624 14:44:39.320749 18728 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_4000.caffemodel
I0624 14:44:39.363015 18728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_4000.solverstate
I0624 14:44:39.708937 18728 solver.cpp:317] Iteration 4000, loss = 0.0305756
I0624 14:44:39.708963 18728 solver.cpp:337] Iteration 4000, Testing net (#0)
I0624 14:44:40.047065 18728 solver.cpp:404]     Test net output #0: accuracy = 0.976249
I0624 14:44:40.047101 18728 solver.cpp:404]     Test net output #1: loss = 0.0839578 (* 1 = 0.0839578 loss)
I0624 14:44:40.047103 18728 solver.cpp:322] Optimization Done.
I0624 14:44:40.047106 18728 caffe.cpp:222] Optimization Done.
