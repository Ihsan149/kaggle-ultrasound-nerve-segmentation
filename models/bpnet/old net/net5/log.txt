I0624 17:04:37.194638 21347 caffe.cpp:185] Using GPUs 0
I0624 17:04:37.210605 21347 caffe.cpp:190] GPU 0: Graphics Device
I0624 17:04:37.720809 21347 solver.cpp:48] Initializing solver from parameters: 
test_iter: 8
test_interval: 100
base_lr: 0.01
display: 20
max_iter: 3000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 1000
snapshot: 500
snapshot_prefix: "data/models/bpgnet"
solver_mode: GPU
device_id: 0
net: "models/bpnet/train_val.prototxt"
test_initialization: true
iter_size: 1
I0624 17:04:37.720930 21347 solver.cpp:91] Creating training net from net file: models/bpnet/train_val.prototxt
I0624 17:04:37.721771 21347 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0624 17:04:37.722018 21347 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 100
    contrast_jitter_range: 0.1
  }
  data_param {
    source: "data/train_lmdb"
    batch_size: 16
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 7
    stride: 1
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0624 17:04:37.722219 21347 layer_factory.hpp:77] Creating layer data
I0624 17:04:37.722625 21347 net.cpp:91] Creating Layer data
I0624 17:04:37.722635 21347 net.cpp:399] data -> data
I0624 17:04:37.722657 21347 net.cpp:399] data -> label
I0624 17:04:37.724484 21351 db_lmdb.cpp:35] Opened lmdb data/train_lmdb
I0624 17:04:37.747520 21347 data_layer.cpp:42] output data size: 16,3,224,224
I0624 17:04:37.767390 21347 net.cpp:141] Setting up data
I0624 17:04:37.767421 21347 net.cpp:148] Top shape: 16 3 224 224 (2408448)
I0624 17:04:37.767426 21347 net.cpp:148] Top shape: 16 (16)
I0624 17:04:37.767427 21347 net.cpp:156] Memory required for data: 9633856
I0624 17:04:37.767436 21347 layer_factory.hpp:77] Creating layer label_data_1_split
I0624 17:04:37.767452 21347 net.cpp:91] Creating Layer label_data_1_split
I0624 17:04:37.767457 21347 net.cpp:425] label_data_1_split <- label
I0624 17:04:37.767467 21347 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0624 17:04:37.767475 21347 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0624 17:04:37.767637 21347 net.cpp:141] Setting up label_data_1_split
I0624 17:04:37.767644 21347 net.cpp:148] Top shape: 16 (16)
I0624 17:04:37.767647 21347 net.cpp:148] Top shape: 16 (16)
I0624 17:04:37.767649 21347 net.cpp:156] Memory required for data: 9633984
I0624 17:04:37.767652 21347 layer_factory.hpp:77] Creating layer conv1_1
I0624 17:04:37.767668 21347 net.cpp:91] Creating Layer conv1_1
I0624 17:04:37.767670 21347 net.cpp:425] conv1_1 <- data
I0624 17:04:37.767674 21347 net.cpp:399] conv1_1 -> conv1_1
I0624 17:04:37.946848 21347 net.cpp:141] Setting up conv1_1
I0624 17:04:37.946882 21347 net.cpp:148] Top shape: 16 32 112 112 (6422528)
I0624 17:04:37.946884 21347 net.cpp:156] Memory required for data: 35324096
I0624 17:04:37.946895 21347 layer_factory.hpp:77] Creating layer bn1_1
I0624 17:04:37.946913 21347 net.cpp:91] Creating Layer bn1_1
I0624 17:04:37.946916 21347 net.cpp:425] bn1_1 <- conv1_1
I0624 17:04:37.946921 21347 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0624 17:04:37.947074 21347 net.cpp:141] Setting up bn1_1
I0624 17:04:37.947082 21347 net.cpp:148] Top shape: 16 32 112 112 (6422528)
I0624 17:04:37.947085 21347 net.cpp:156] Memory required for data: 61014208
I0624 17:04:37.947094 21347 layer_factory.hpp:77] Creating layer scale1_1
I0624 17:04:37.947103 21347 net.cpp:91] Creating Layer scale1_1
I0624 17:04:37.947105 21347 net.cpp:425] scale1_1 <- conv1_1
I0624 17:04:37.947109 21347 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0624 17:04:37.947144 21347 layer_factory.hpp:77] Creating layer scale1_1
I0624 17:04:37.947260 21347 net.cpp:141] Setting up scale1_1
I0624 17:04:37.947268 21347 net.cpp:148] Top shape: 16 32 112 112 (6422528)
I0624 17:04:37.947271 21347 net.cpp:156] Memory required for data: 86704320
I0624 17:04:37.947278 21347 layer_factory.hpp:77] Creating layer relu1_1
I0624 17:04:37.947283 21347 net.cpp:91] Creating Layer relu1_1
I0624 17:04:37.947286 21347 net.cpp:425] relu1_1 <- conv1_1
I0624 17:04:37.947290 21347 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0624 17:04:37.947427 21347 net.cpp:141] Setting up relu1_1
I0624 17:04:37.947437 21347 net.cpp:148] Top shape: 16 32 112 112 (6422528)
I0624 17:04:37.947438 21347 net.cpp:156] Memory required for data: 112394432
I0624 17:04:37.947441 21347 layer_factory.hpp:77] Creating layer conv1_2
I0624 17:04:37.947450 21347 net.cpp:91] Creating Layer conv1_2
I0624 17:04:37.947453 21347 net.cpp:425] conv1_2 <- conv1_1
I0624 17:04:37.947458 21347 net.cpp:399] conv1_2 -> conv1_2
I0624 17:04:37.948225 21347 net.cpp:141] Setting up conv1_2
I0624 17:04:37.948236 21347 net.cpp:148] Top shape: 16 32 112 112 (6422528)
I0624 17:04:37.948240 21347 net.cpp:156] Memory required for data: 138084544
I0624 17:04:37.948245 21347 layer_factory.hpp:77] Creating layer bn1_2
I0624 17:04:37.948249 21347 net.cpp:91] Creating Layer bn1_2
I0624 17:04:37.948252 21347 net.cpp:425] bn1_2 <- conv1_2
I0624 17:04:37.948256 21347 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0624 17:04:37.948390 21347 net.cpp:141] Setting up bn1_2
I0624 17:04:37.948396 21347 net.cpp:148] Top shape: 16 32 112 112 (6422528)
I0624 17:04:37.948400 21347 net.cpp:156] Memory required for data: 163774656
I0624 17:04:37.948407 21347 layer_factory.hpp:77] Creating layer scale1_2
I0624 17:04:37.948415 21347 net.cpp:91] Creating Layer scale1_2
I0624 17:04:37.948416 21347 net.cpp:425] scale1_2 <- conv1_2
I0624 17:04:37.948421 21347 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0624 17:04:37.948449 21347 layer_factory.hpp:77] Creating layer scale1_2
I0624 17:04:37.948540 21347 net.cpp:141] Setting up scale1_2
I0624 17:04:37.948547 21347 net.cpp:148] Top shape: 16 32 112 112 (6422528)
I0624 17:04:37.948549 21347 net.cpp:156] Memory required for data: 189464768
I0624 17:04:37.948554 21347 layer_factory.hpp:77] Creating layer relu1_2
I0624 17:04:37.948557 21347 net.cpp:91] Creating Layer relu1_2
I0624 17:04:37.948560 21347 net.cpp:425] relu1_2 <- conv1_2
I0624 17:04:37.948564 21347 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0624 17:04:37.948685 21347 net.cpp:141] Setting up relu1_2
I0624 17:04:37.948694 21347 net.cpp:148] Top shape: 16 32 112 112 (6422528)
I0624 17:04:37.948696 21347 net.cpp:156] Memory required for data: 215154880
I0624 17:04:37.948699 21347 layer_factory.hpp:77] Creating layer pool1
I0624 17:04:37.948705 21347 net.cpp:91] Creating Layer pool1
I0624 17:04:37.948707 21347 net.cpp:425] pool1 <- conv1_2
I0624 17:04:37.948711 21347 net.cpp:399] pool1 -> pool1
I0624 17:04:37.948753 21347 net.cpp:141] Setting up pool1
I0624 17:04:37.948758 21347 net.cpp:148] Top shape: 16 32 56 56 (1605632)
I0624 17:04:37.948779 21347 net.cpp:156] Memory required for data: 221577408
I0624 17:04:37.948782 21347 layer_factory.hpp:77] Creating layer conv2_1
I0624 17:04:37.948789 21347 net.cpp:91] Creating Layer conv2_1
I0624 17:04:37.948792 21347 net.cpp:425] conv2_1 <- pool1
I0624 17:04:37.948796 21347 net.cpp:399] conv2_1 -> conv2_1
I0624 17:04:37.949553 21347 net.cpp:141] Setting up conv2_1
I0624 17:04:37.949565 21347 net.cpp:148] Top shape: 16 32 56 56 (1605632)
I0624 17:04:37.949568 21347 net.cpp:156] Memory required for data: 227999936
I0624 17:04:37.949573 21347 layer_factory.hpp:77] Creating layer bn2_1
I0624 17:04:37.949579 21347 net.cpp:91] Creating Layer bn2_1
I0624 17:04:37.949581 21347 net.cpp:425] bn2_1 <- conv2_1
I0624 17:04:37.949585 21347 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0624 17:04:37.950852 21347 net.cpp:141] Setting up bn2_1
I0624 17:04:37.950865 21347 net.cpp:148] Top shape: 16 32 56 56 (1605632)
I0624 17:04:37.950866 21347 net.cpp:156] Memory required for data: 234422464
I0624 17:04:37.950873 21347 layer_factory.hpp:77] Creating layer scale2_1
I0624 17:04:37.950880 21347 net.cpp:91] Creating Layer scale2_1
I0624 17:04:37.950882 21347 net.cpp:425] scale2_1 <- conv2_1
I0624 17:04:37.950886 21347 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0624 17:04:37.950917 21347 layer_factory.hpp:77] Creating layer scale2_1
I0624 17:04:37.951007 21347 net.cpp:141] Setting up scale2_1
I0624 17:04:37.951014 21347 net.cpp:148] Top shape: 16 32 56 56 (1605632)
I0624 17:04:37.951016 21347 net.cpp:156] Memory required for data: 240844992
I0624 17:04:37.951025 21347 layer_factory.hpp:77] Creating layer relu2_1
I0624 17:04:37.951031 21347 net.cpp:91] Creating Layer relu2_1
I0624 17:04:37.951035 21347 net.cpp:425] relu2_1 <- conv2_1
I0624 17:04:37.951037 21347 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0624 17:04:37.951396 21347 net.cpp:141] Setting up relu2_1
I0624 17:04:37.951408 21347 net.cpp:148] Top shape: 16 32 56 56 (1605632)
I0624 17:04:37.951411 21347 net.cpp:156] Memory required for data: 247267520
I0624 17:04:37.951413 21347 layer_factory.hpp:77] Creating layer conv2_2
I0624 17:04:37.951421 21347 net.cpp:91] Creating Layer conv2_2
I0624 17:04:37.951424 21347 net.cpp:425] conv2_2 <- conv2_1
I0624 17:04:37.951431 21347 net.cpp:399] conv2_2 -> conv2_2
I0624 17:04:37.952018 21347 net.cpp:141] Setting up conv2_2
I0624 17:04:37.952029 21347 net.cpp:148] Top shape: 16 32 56 56 (1605632)
I0624 17:04:37.952033 21347 net.cpp:156] Memory required for data: 253690048
I0624 17:04:37.952036 21347 layer_factory.hpp:77] Creating layer bn2_2
I0624 17:04:37.952044 21347 net.cpp:91] Creating Layer bn2_2
I0624 17:04:37.952046 21347 net.cpp:425] bn2_2 <- conv2_2
I0624 17:04:37.952051 21347 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0624 17:04:37.952190 21347 net.cpp:141] Setting up bn2_2
I0624 17:04:37.952198 21347 net.cpp:148] Top shape: 16 32 56 56 (1605632)
I0624 17:04:37.952199 21347 net.cpp:156] Memory required for data: 260112576
I0624 17:04:37.952204 21347 layer_factory.hpp:77] Creating layer scale2_2
I0624 17:04:37.952211 21347 net.cpp:91] Creating Layer scale2_2
I0624 17:04:37.952214 21347 net.cpp:425] scale2_2 <- conv2_2
I0624 17:04:37.952217 21347 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0624 17:04:37.952250 21347 layer_factory.hpp:77] Creating layer scale2_2
I0624 17:04:37.952332 21347 net.cpp:141] Setting up scale2_2
I0624 17:04:37.952340 21347 net.cpp:148] Top shape: 16 32 56 56 (1605632)
I0624 17:04:37.952342 21347 net.cpp:156] Memory required for data: 266535104
I0624 17:04:37.952347 21347 layer_factory.hpp:77] Creating layer relu2_2
I0624 17:04:37.952352 21347 net.cpp:91] Creating Layer relu2_2
I0624 17:04:37.952353 21347 net.cpp:425] relu2_2 <- conv2_2
I0624 17:04:37.952356 21347 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0624 17:04:37.952704 21347 net.cpp:141] Setting up relu2_2
I0624 17:04:37.952714 21347 net.cpp:148] Top shape: 16 32 56 56 (1605632)
I0624 17:04:37.952718 21347 net.cpp:156] Memory required for data: 272957632
I0624 17:04:37.952720 21347 layer_factory.hpp:77] Creating layer pool2
I0624 17:04:37.952735 21347 net.cpp:91] Creating Layer pool2
I0624 17:04:37.952739 21347 net.cpp:425] pool2 <- conv2_2
I0624 17:04:37.952744 21347 net.cpp:399] pool2 -> pool2
I0624 17:04:37.952778 21347 net.cpp:141] Setting up pool2
I0624 17:04:37.952782 21347 net.cpp:148] Top shape: 16 32 28 28 (401408)
I0624 17:04:37.952785 21347 net.cpp:156] Memory required for data: 274563264
I0624 17:04:37.952786 21347 layer_factory.hpp:77] Creating layer conv3_1
I0624 17:04:37.952795 21347 net.cpp:91] Creating Layer conv3_1
I0624 17:04:37.952797 21347 net.cpp:425] conv3_1 <- pool2
I0624 17:04:37.952802 21347 net.cpp:399] conv3_1 -> conv3_1
I0624 17:04:37.953605 21347 net.cpp:141] Setting up conv3_1
I0624 17:04:37.953619 21347 net.cpp:148] Top shape: 16 32 28 28 (401408)
I0624 17:04:37.953620 21347 net.cpp:156] Memory required for data: 276168896
I0624 17:04:37.953625 21347 layer_factory.hpp:77] Creating layer bn3_1
I0624 17:04:37.953632 21347 net.cpp:91] Creating Layer bn3_1
I0624 17:04:37.953635 21347 net.cpp:425] bn3_1 <- conv3_1
I0624 17:04:37.953640 21347 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0624 17:04:37.954898 21347 net.cpp:141] Setting up bn3_1
I0624 17:04:37.954910 21347 net.cpp:148] Top shape: 16 32 28 28 (401408)
I0624 17:04:37.954911 21347 net.cpp:156] Memory required for data: 277774528
I0624 17:04:37.954918 21347 layer_factory.hpp:77] Creating layer scale3_1
I0624 17:04:37.954924 21347 net.cpp:91] Creating Layer scale3_1
I0624 17:04:37.954927 21347 net.cpp:425] scale3_1 <- conv3_1
I0624 17:04:37.954932 21347 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0624 17:04:37.954967 21347 layer_factory.hpp:77] Creating layer scale3_1
I0624 17:04:37.955055 21347 net.cpp:141] Setting up scale3_1
I0624 17:04:37.955062 21347 net.cpp:148] Top shape: 16 32 28 28 (401408)
I0624 17:04:37.955065 21347 net.cpp:156] Memory required for data: 279380160
I0624 17:04:37.955070 21347 layer_factory.hpp:77] Creating layer relu3_1
I0624 17:04:37.955075 21347 net.cpp:91] Creating Layer relu3_1
I0624 17:04:37.955077 21347 net.cpp:425] relu3_1 <- conv3_1
I0624 17:04:37.955080 21347 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0624 17:04:37.955222 21347 net.cpp:141] Setting up relu3_1
I0624 17:04:37.955231 21347 net.cpp:148] Top shape: 16 32 28 28 (401408)
I0624 17:04:37.955235 21347 net.cpp:156] Memory required for data: 280985792
I0624 17:04:37.955236 21347 layer_factory.hpp:77] Creating layer conv3_2
I0624 17:04:37.955245 21347 net.cpp:91] Creating Layer conv3_2
I0624 17:04:37.955248 21347 net.cpp:425] conv3_2 <- conv3_1
I0624 17:04:37.955252 21347 net.cpp:399] conv3_2 -> conv3_2
I0624 17:04:37.956069 21347 net.cpp:141] Setting up conv3_2
I0624 17:04:37.956084 21347 net.cpp:148] Top shape: 16 32 28 28 (401408)
I0624 17:04:37.956085 21347 net.cpp:156] Memory required for data: 282591424
I0624 17:04:37.956089 21347 layer_factory.hpp:77] Creating layer bn3_2
I0624 17:04:37.956095 21347 net.cpp:91] Creating Layer bn3_2
I0624 17:04:37.956099 21347 net.cpp:425] bn3_2 <- conv3_2
I0624 17:04:37.956104 21347 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0624 17:04:37.956246 21347 net.cpp:141] Setting up bn3_2
I0624 17:04:37.956254 21347 net.cpp:148] Top shape: 16 32 28 28 (401408)
I0624 17:04:37.956256 21347 net.cpp:156] Memory required for data: 284197056
I0624 17:04:37.956266 21347 layer_factory.hpp:77] Creating layer scale3_2
I0624 17:04:37.956271 21347 net.cpp:91] Creating Layer scale3_2
I0624 17:04:37.956274 21347 net.cpp:425] scale3_2 <- conv3_2
I0624 17:04:37.956279 21347 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0624 17:04:37.956311 21347 layer_factory.hpp:77] Creating layer scale3_2
I0624 17:04:37.956398 21347 net.cpp:141] Setting up scale3_2
I0624 17:04:37.956404 21347 net.cpp:148] Top shape: 16 32 28 28 (401408)
I0624 17:04:37.956406 21347 net.cpp:156] Memory required for data: 285802688
I0624 17:04:37.956410 21347 layer_factory.hpp:77] Creating layer relu3_2
I0624 17:04:37.956416 21347 net.cpp:91] Creating Layer relu3_2
I0624 17:04:37.956418 21347 net.cpp:425] relu3_2 <- conv3_2
I0624 17:04:37.956421 21347 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0624 17:04:37.956564 21347 net.cpp:141] Setting up relu3_2
I0624 17:04:37.956573 21347 net.cpp:148] Top shape: 16 32 28 28 (401408)
I0624 17:04:37.956576 21347 net.cpp:156] Memory required for data: 287408320
I0624 17:04:37.956578 21347 layer_factory.hpp:77] Creating layer pool3
I0624 17:04:37.956584 21347 net.cpp:91] Creating Layer pool3
I0624 17:04:37.956588 21347 net.cpp:425] pool3 <- conv3_2
I0624 17:04:37.956591 21347 net.cpp:399] pool3 -> pool3
I0624 17:04:37.956624 21347 net.cpp:141] Setting up pool3
I0624 17:04:37.956629 21347 net.cpp:148] Top shape: 16 32 14 14 (100352)
I0624 17:04:37.956630 21347 net.cpp:156] Memory required for data: 287809728
I0624 17:04:37.956634 21347 layer_factory.hpp:77] Creating layer conv4_1
I0624 17:04:37.956641 21347 net.cpp:91] Creating Layer conv4_1
I0624 17:04:37.956645 21347 net.cpp:425] conv4_1 <- pool3
I0624 17:04:37.956648 21347 net.cpp:399] conv4_1 -> conv4_1
I0624 17:04:37.958631 21347 net.cpp:141] Setting up conv4_1
I0624 17:04:37.958643 21347 net.cpp:148] Top shape: 16 64 14 14 (200704)
I0624 17:04:37.958645 21347 net.cpp:156] Memory required for data: 288612544
I0624 17:04:37.958649 21347 layer_factory.hpp:77] Creating layer bn4_1
I0624 17:04:37.958657 21347 net.cpp:91] Creating Layer bn4_1
I0624 17:04:37.958660 21347 net.cpp:425] bn4_1 <- conv4_1
I0624 17:04:37.958664 21347 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0624 17:04:37.958809 21347 net.cpp:141] Setting up bn4_1
I0624 17:04:37.958817 21347 net.cpp:148] Top shape: 16 64 14 14 (200704)
I0624 17:04:37.958819 21347 net.cpp:156] Memory required for data: 289415360
I0624 17:04:37.958824 21347 layer_factory.hpp:77] Creating layer scale4_1
I0624 17:04:37.958830 21347 net.cpp:91] Creating Layer scale4_1
I0624 17:04:37.958832 21347 net.cpp:425] scale4_1 <- conv4_1
I0624 17:04:37.958837 21347 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0624 17:04:37.958870 21347 layer_factory.hpp:77] Creating layer scale4_1
I0624 17:04:37.958957 21347 net.cpp:141] Setting up scale4_1
I0624 17:04:37.958966 21347 net.cpp:148] Top shape: 16 64 14 14 (200704)
I0624 17:04:37.958967 21347 net.cpp:156] Memory required for data: 290218176
I0624 17:04:37.958971 21347 layer_factory.hpp:77] Creating layer relu4_1
I0624 17:04:37.958977 21347 net.cpp:91] Creating Layer relu4_1
I0624 17:04:37.958981 21347 net.cpp:425] relu4_1 <- conv4_1
I0624 17:04:37.958984 21347 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0624 17:04:37.959117 21347 net.cpp:141] Setting up relu4_1
I0624 17:04:37.959125 21347 net.cpp:148] Top shape: 16 64 14 14 (200704)
I0624 17:04:37.959128 21347 net.cpp:156] Memory required for data: 291020992
I0624 17:04:37.959131 21347 layer_factory.hpp:77] Creating layer conv4_2
I0624 17:04:37.959141 21347 net.cpp:91] Creating Layer conv4_2
I0624 17:04:37.959143 21347 net.cpp:425] conv4_2 <- conv4_1
I0624 17:04:37.959153 21347 net.cpp:399] conv4_2 -> conv4_2
I0624 17:04:37.960141 21347 net.cpp:141] Setting up conv4_2
I0624 17:04:37.960155 21347 net.cpp:148] Top shape: 16 64 14 14 (200704)
I0624 17:04:37.960157 21347 net.cpp:156] Memory required for data: 291823808
I0624 17:04:37.960161 21347 layer_factory.hpp:77] Creating layer bn4_2
I0624 17:04:37.960167 21347 net.cpp:91] Creating Layer bn4_2
I0624 17:04:37.960170 21347 net.cpp:425] bn4_2 <- conv4_2
I0624 17:04:37.960175 21347 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0624 17:04:37.960322 21347 net.cpp:141] Setting up bn4_2
I0624 17:04:37.960330 21347 net.cpp:148] Top shape: 16 64 14 14 (200704)
I0624 17:04:37.960331 21347 net.cpp:156] Memory required for data: 292626624
I0624 17:04:37.960337 21347 layer_factory.hpp:77] Creating layer scale4_2
I0624 17:04:37.960342 21347 net.cpp:91] Creating Layer scale4_2
I0624 17:04:37.960345 21347 net.cpp:425] scale4_2 <- conv4_2
I0624 17:04:37.960350 21347 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0624 17:04:37.960381 21347 layer_factory.hpp:77] Creating layer scale4_2
I0624 17:04:37.960465 21347 net.cpp:141] Setting up scale4_2
I0624 17:04:37.960472 21347 net.cpp:148] Top shape: 16 64 14 14 (200704)
I0624 17:04:37.960474 21347 net.cpp:156] Memory required for data: 293429440
I0624 17:04:37.960489 21347 layer_factory.hpp:77] Creating layer relu4_2
I0624 17:04:37.960494 21347 net.cpp:91] Creating Layer relu4_2
I0624 17:04:37.960495 21347 net.cpp:425] relu4_2 <- conv4_2
I0624 17:04:37.960500 21347 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0624 17:04:37.960634 21347 net.cpp:141] Setting up relu4_2
I0624 17:04:37.960644 21347 net.cpp:148] Top shape: 16 64 14 14 (200704)
I0624 17:04:37.960647 21347 net.cpp:156] Memory required for data: 294232256
I0624 17:04:37.960649 21347 layer_factory.hpp:77] Creating layer pool4
I0624 17:04:37.960654 21347 net.cpp:91] Creating Layer pool4
I0624 17:04:37.960657 21347 net.cpp:425] pool4 <- conv4_2
I0624 17:04:37.960661 21347 net.cpp:399] pool4 -> pool4
I0624 17:04:37.960695 21347 net.cpp:141] Setting up pool4
I0624 17:04:37.960700 21347 net.cpp:148] Top shape: 16 64 7 7 (50176)
I0624 17:04:37.960702 21347 net.cpp:156] Memory required for data: 294432960
I0624 17:04:37.960705 21347 layer_factory.hpp:77] Creating layer conv5_1
I0624 17:04:37.960711 21347 net.cpp:91] Creating Layer conv5_1
I0624 17:04:37.960714 21347 net.cpp:425] conv5_1 <- pool4
I0624 17:04:37.960721 21347 net.cpp:399] conv5_1 -> conv5_1
I0624 17:04:37.961686 21347 net.cpp:141] Setting up conv5_1
I0624 17:04:37.961699 21347 net.cpp:148] Top shape: 16 64 7 7 (50176)
I0624 17:04:37.961701 21347 net.cpp:156] Memory required for data: 294633664
I0624 17:04:37.961706 21347 layer_factory.hpp:77] Creating layer bn5_1
I0624 17:04:37.961714 21347 net.cpp:91] Creating Layer bn5_1
I0624 17:04:37.961716 21347 net.cpp:425] bn5_1 <- conv5_1
I0624 17:04:37.961721 21347 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0624 17:04:37.961866 21347 net.cpp:141] Setting up bn5_1
I0624 17:04:37.961874 21347 net.cpp:148] Top shape: 16 64 7 7 (50176)
I0624 17:04:37.961875 21347 net.cpp:156] Memory required for data: 294834368
I0624 17:04:37.961881 21347 layer_factory.hpp:77] Creating layer scale5_1
I0624 17:04:37.961887 21347 net.cpp:91] Creating Layer scale5_1
I0624 17:04:37.961890 21347 net.cpp:425] scale5_1 <- conv5_1
I0624 17:04:37.961894 21347 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0624 17:04:37.961927 21347 layer_factory.hpp:77] Creating layer scale5_1
I0624 17:04:37.962013 21347 net.cpp:141] Setting up scale5_1
I0624 17:04:37.962019 21347 net.cpp:148] Top shape: 16 64 7 7 (50176)
I0624 17:04:37.962021 21347 net.cpp:156] Memory required for data: 295035072
I0624 17:04:37.962025 21347 layer_factory.hpp:77] Creating layer relu5_1
I0624 17:04:37.962029 21347 net.cpp:91] Creating Layer relu5_1
I0624 17:04:37.962033 21347 net.cpp:425] relu5_1 <- conv5_1
I0624 17:04:37.962036 21347 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0624 17:04:37.962396 21347 net.cpp:141] Setting up relu5_1
I0624 17:04:37.962409 21347 net.cpp:148] Top shape: 16 64 7 7 (50176)
I0624 17:04:37.962410 21347 net.cpp:156] Memory required for data: 295235776
I0624 17:04:37.962414 21347 layer_factory.hpp:77] Creating layer conv5_2
I0624 17:04:37.962424 21347 net.cpp:91] Creating Layer conv5_2
I0624 17:04:37.962426 21347 net.cpp:425] conv5_2 <- conv5_1
I0624 17:04:37.962431 21347 net.cpp:399] conv5_2 -> conv5_2
I0624 17:04:37.963405 21347 net.cpp:141] Setting up conv5_2
I0624 17:04:37.963418 21347 net.cpp:148] Top shape: 16 64 7 7 (50176)
I0624 17:04:37.963419 21347 net.cpp:156] Memory required for data: 295436480
I0624 17:04:37.963424 21347 layer_factory.hpp:77] Creating layer bn5_2
I0624 17:04:37.963430 21347 net.cpp:91] Creating Layer bn5_2
I0624 17:04:37.963433 21347 net.cpp:425] bn5_2 <- conv5_2
I0624 17:04:37.963438 21347 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0624 17:04:37.963592 21347 net.cpp:141] Setting up bn5_2
I0624 17:04:37.963598 21347 net.cpp:148] Top shape: 16 64 7 7 (50176)
I0624 17:04:37.963600 21347 net.cpp:156] Memory required for data: 295637184
I0624 17:04:37.963606 21347 layer_factory.hpp:77] Creating layer scale5_2
I0624 17:04:37.963613 21347 net.cpp:91] Creating Layer scale5_2
I0624 17:04:37.963615 21347 net.cpp:425] scale5_2 <- conv5_2
I0624 17:04:37.963619 21347 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0624 17:04:37.963665 21347 layer_factory.hpp:77] Creating layer scale5_2
I0624 17:04:37.963752 21347 net.cpp:141] Setting up scale5_2
I0624 17:04:37.963758 21347 net.cpp:148] Top shape: 16 64 7 7 (50176)
I0624 17:04:37.963760 21347 net.cpp:156] Memory required for data: 295837888
I0624 17:04:37.963764 21347 layer_factory.hpp:77] Creating layer relu5_2
I0624 17:04:37.963770 21347 net.cpp:91] Creating Layer relu5_2
I0624 17:04:37.963773 21347 net.cpp:425] relu5_2 <- conv5_2
I0624 17:04:37.963775 21347 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0624 17:04:37.964128 21347 net.cpp:141] Setting up relu5_2
I0624 17:04:37.964138 21347 net.cpp:148] Top shape: 16 64 7 7 (50176)
I0624 17:04:37.964141 21347 net.cpp:156] Memory required for data: 296038592
I0624 17:04:37.964145 21347 layer_factory.hpp:77] Creating layer pool5
I0624 17:04:37.964150 21347 net.cpp:91] Creating Layer pool5
I0624 17:04:37.964154 21347 net.cpp:425] pool5 <- conv5_2
I0624 17:04:37.964159 21347 net.cpp:399] pool5 -> pool5
I0624 17:04:37.964314 21347 net.cpp:141] Setting up pool5
I0624 17:04:37.964324 21347 net.cpp:148] Top shape: 16 64 1 1 (1024)
I0624 17:04:37.964328 21347 net.cpp:156] Memory required for data: 296042688
I0624 17:04:37.964330 21347 layer_factory.hpp:77] Creating layer fc2
I0624 17:04:37.964339 21347 net.cpp:91] Creating Layer fc2
I0624 17:04:37.964342 21347 net.cpp:425] fc2 <- pool5
I0624 17:04:37.964345 21347 net.cpp:399] fc2 -> fc2
I0624 17:04:37.964428 21347 net.cpp:141] Setting up fc2
I0624 17:04:37.964435 21347 net.cpp:148] Top shape: 16 2 (32)
I0624 17:04:37.964437 21347 net.cpp:156] Memory required for data: 296042816
I0624 17:04:37.964442 21347 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0624 17:04:37.964447 21347 net.cpp:91] Creating Layer fc2_fc2_0_split
I0624 17:04:37.964449 21347 net.cpp:425] fc2_fc2_0_split <- fc2
I0624 17:04:37.964453 21347 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0624 17:04:37.964458 21347 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0624 17:04:37.964486 21347 net.cpp:141] Setting up fc2_fc2_0_split
I0624 17:04:37.964490 21347 net.cpp:148] Top shape: 16 2 (32)
I0624 17:04:37.964493 21347 net.cpp:148] Top shape: 16 2 (32)
I0624 17:04:37.964495 21347 net.cpp:156] Memory required for data: 296043072
I0624 17:04:37.964498 21347 layer_factory.hpp:77] Creating layer loss
I0624 17:04:37.964505 21347 net.cpp:91] Creating Layer loss
I0624 17:04:37.964509 21347 net.cpp:425] loss <- fc2_fc2_0_split_0
I0624 17:04:37.964511 21347 net.cpp:425] loss <- label_data_1_split_0
I0624 17:04:37.964515 21347 net.cpp:399] loss -> loss
I0624 17:04:37.964522 21347 layer_factory.hpp:77] Creating layer loss
I0624 17:04:37.964730 21347 net.cpp:141] Setting up loss
I0624 17:04:37.964738 21347 net.cpp:148] Top shape: (1)
I0624 17:04:37.964740 21347 net.cpp:151]     with loss weight 1
I0624 17:04:37.964754 21347 net.cpp:156] Memory required for data: 296043076
I0624 17:04:37.964756 21347 layer_factory.hpp:77] Creating layer accuracy
I0624 17:04:37.964761 21347 net.cpp:91] Creating Layer accuracy
I0624 17:04:37.964764 21347 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0624 17:04:37.964768 21347 net.cpp:425] accuracy <- label_data_1_split_1
I0624 17:04:37.964772 21347 net.cpp:399] accuracy -> accuracy
I0624 17:04:37.964778 21347 net.cpp:141] Setting up accuracy
I0624 17:04:37.964782 21347 net.cpp:148] Top shape: (1)
I0624 17:04:37.964784 21347 net.cpp:156] Memory required for data: 296043080
I0624 17:04:37.964787 21347 net.cpp:219] accuracy does not need backward computation.
I0624 17:04:37.964788 21347 net.cpp:217] loss needs backward computation.
I0624 17:04:37.964792 21347 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0624 17:04:37.964793 21347 net.cpp:217] fc2 needs backward computation.
I0624 17:04:37.964795 21347 net.cpp:217] pool5 needs backward computation.
I0624 17:04:37.964798 21347 net.cpp:217] relu5_2 needs backward computation.
I0624 17:04:37.964800 21347 net.cpp:217] scale5_2 needs backward computation.
I0624 17:04:37.964802 21347 net.cpp:217] bn5_2 needs backward computation.
I0624 17:04:37.964813 21347 net.cpp:217] conv5_2 needs backward computation.
I0624 17:04:37.964815 21347 net.cpp:217] relu5_1 needs backward computation.
I0624 17:04:37.964818 21347 net.cpp:217] scale5_1 needs backward computation.
I0624 17:04:37.964819 21347 net.cpp:217] bn5_1 needs backward computation.
I0624 17:04:37.964821 21347 net.cpp:217] conv5_1 needs backward computation.
I0624 17:04:37.964823 21347 net.cpp:217] pool4 needs backward computation.
I0624 17:04:37.964826 21347 net.cpp:217] relu4_2 needs backward computation.
I0624 17:04:37.964828 21347 net.cpp:217] scale4_2 needs backward computation.
I0624 17:04:37.964829 21347 net.cpp:217] bn4_2 needs backward computation.
I0624 17:04:37.964831 21347 net.cpp:217] conv4_2 needs backward computation.
I0624 17:04:37.964833 21347 net.cpp:217] relu4_1 needs backward computation.
I0624 17:04:37.964835 21347 net.cpp:217] scale4_1 needs backward computation.
I0624 17:04:37.964838 21347 net.cpp:217] bn4_1 needs backward computation.
I0624 17:04:37.964839 21347 net.cpp:217] conv4_1 needs backward computation.
I0624 17:04:37.964841 21347 net.cpp:217] pool3 needs backward computation.
I0624 17:04:37.964843 21347 net.cpp:217] relu3_2 needs backward computation.
I0624 17:04:37.964845 21347 net.cpp:217] scale3_2 needs backward computation.
I0624 17:04:37.964848 21347 net.cpp:217] bn3_2 needs backward computation.
I0624 17:04:37.964849 21347 net.cpp:217] conv3_2 needs backward computation.
I0624 17:04:37.964851 21347 net.cpp:217] relu3_1 needs backward computation.
I0624 17:04:37.964854 21347 net.cpp:217] scale3_1 needs backward computation.
I0624 17:04:37.964856 21347 net.cpp:217] bn3_1 needs backward computation.
I0624 17:04:37.964859 21347 net.cpp:217] conv3_1 needs backward computation.
I0624 17:04:37.964860 21347 net.cpp:217] pool2 needs backward computation.
I0624 17:04:37.964862 21347 net.cpp:217] relu2_2 needs backward computation.
I0624 17:04:37.964864 21347 net.cpp:217] scale2_2 needs backward computation.
I0624 17:04:37.964866 21347 net.cpp:217] bn2_2 needs backward computation.
I0624 17:04:37.964869 21347 net.cpp:217] conv2_2 needs backward computation.
I0624 17:04:37.964870 21347 net.cpp:217] relu2_1 needs backward computation.
I0624 17:04:37.964874 21347 net.cpp:217] scale2_1 needs backward computation.
I0624 17:04:37.964875 21347 net.cpp:217] bn2_1 needs backward computation.
I0624 17:04:37.964877 21347 net.cpp:217] conv2_1 needs backward computation.
I0624 17:04:37.964879 21347 net.cpp:217] pool1 needs backward computation.
I0624 17:04:37.964881 21347 net.cpp:217] relu1_2 needs backward computation.
I0624 17:04:37.964884 21347 net.cpp:217] scale1_2 needs backward computation.
I0624 17:04:37.964885 21347 net.cpp:217] bn1_2 needs backward computation.
I0624 17:04:37.964887 21347 net.cpp:217] conv1_2 needs backward computation.
I0624 17:04:37.964890 21347 net.cpp:217] relu1_1 needs backward computation.
I0624 17:04:37.964891 21347 net.cpp:217] scale1_1 needs backward computation.
I0624 17:04:37.964893 21347 net.cpp:217] bn1_1 needs backward computation.
I0624 17:04:37.964895 21347 net.cpp:217] conv1_1 needs backward computation.
I0624 17:04:37.964898 21347 net.cpp:219] label_data_1_split does not need backward computation.
I0624 17:04:37.964902 21347 net.cpp:219] data does not need backward computation.
I0624 17:04:37.964905 21347 net.cpp:261] This network produces output accuracy
I0624 17:04:37.964906 21347 net.cpp:261] This network produces output loss
I0624 17:04:37.964926 21347 net.cpp:274] Network initialization done.
I0624 17:04:37.965751 21347 solver.cpp:181] Creating test net (#0) specified by net file: models/bpnet/train_val.prototxt
I0624 17:04:37.965804 21347 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0624 17:04:37.966034 21347 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 100
    contrast_jitter_range: 0.1
  }
  data_param {
    source: "data/val_lmdb"
    batch_size: 16
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 7
    stride: 1
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0624 17:04:37.966179 21347 layer_factory.hpp:77] Creating layer data
I0624 17:04:37.966235 21347 net.cpp:91] Creating Layer data
I0624 17:04:37.966241 21347 net.cpp:399] data -> data
I0624 17:04:37.966248 21347 net.cpp:399] data -> label
I0624 17:04:37.967483 21353 db_lmdb.cpp:35] Opened lmdb data/val_lmdb
I0624 17:04:37.967865 21347 data_layer.cpp:42] output data size: 16,3,224,224
I0624 17:04:37.988971 21347 net.cpp:141] Setting up data
I0624 17:04:37.988994 21347 net.cpp:148] Top shape: 16 3 224 224 (2408448)
I0624 17:04:37.988998 21347 net.cpp:148] Top shape: 16 (16)
I0624 17:04:37.989001 21347 net.cpp:156] Memory required for data: 9633856
I0624 17:04:37.989006 21347 layer_factory.hpp:77] Creating layer label_data_1_split
I0624 17:04:37.989030 21347 net.cpp:91] Creating Layer label_data_1_split
I0624 17:04:37.989034 21347 net.cpp:425] label_data_1_split <- label
I0624 17:04:37.989040 21347 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0624 17:04:37.989048 21347 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0624 17:04:37.989094 21347 net.cpp:141] Setting up label_data_1_split
I0624 17:04:37.989102 21347 net.cpp:148] Top shape: 16 (16)
I0624 17:04:37.989105 21347 net.cpp:148] Top shape: 16 (16)
I0624 17:04:37.989107 21347 net.cpp:156] Memory required for data: 9633984
I0624 17:04:37.989109 21347 layer_factory.hpp:77] Creating layer conv1_1
I0624 17:04:37.989120 21347 net.cpp:91] Creating Layer conv1_1
I0624 17:04:37.989125 21347 net.cpp:425] conv1_1 <- data
I0624 17:04:37.989130 21347 net.cpp:399] conv1_1 -> conv1_1
I0624 17:04:37.990277 21347 net.cpp:141] Setting up conv1_1
I0624 17:04:37.990288 21347 net.cpp:148] Top shape: 16 32 112 112 (6422528)
I0624 17:04:37.990291 21347 net.cpp:156] Memory required for data: 35324096
I0624 17:04:37.990298 21347 layer_factory.hpp:77] Creating layer bn1_1
I0624 17:04:37.990306 21347 net.cpp:91] Creating Layer bn1_1
I0624 17:04:37.990309 21347 net.cpp:425] bn1_1 <- conv1_1
I0624 17:04:37.990312 21347 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0624 17:04:37.990481 21347 net.cpp:141] Setting up bn1_1
I0624 17:04:37.990489 21347 net.cpp:148] Top shape: 16 32 112 112 (6422528)
I0624 17:04:37.990491 21347 net.cpp:156] Memory required for data: 61014208
I0624 17:04:37.990499 21347 layer_factory.hpp:77] Creating layer scale1_1
I0624 17:04:37.990509 21347 net.cpp:91] Creating Layer scale1_1
I0624 17:04:37.990510 21347 net.cpp:425] scale1_1 <- conv1_1
I0624 17:04:37.990514 21347 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0624 17:04:37.990550 21347 layer_factory.hpp:77] Creating layer scale1_1
I0624 17:04:37.990756 21347 net.cpp:141] Setting up scale1_1
I0624 17:04:37.990764 21347 net.cpp:148] Top shape: 16 32 112 112 (6422528)
I0624 17:04:37.990767 21347 net.cpp:156] Memory required for data: 86704320
I0624 17:04:37.990773 21347 layer_factory.hpp:77] Creating layer relu1_1
I0624 17:04:37.990780 21347 net.cpp:91] Creating Layer relu1_1
I0624 17:04:37.990783 21347 net.cpp:425] relu1_1 <- conv1_1
I0624 17:04:37.990787 21347 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0624 17:04:37.991695 21347 net.cpp:141] Setting up relu1_1
I0624 17:04:37.991706 21347 net.cpp:148] Top shape: 16 32 112 112 (6422528)
I0624 17:04:37.991708 21347 net.cpp:156] Memory required for data: 112394432
I0624 17:04:37.991711 21347 layer_factory.hpp:77] Creating layer conv1_2
I0624 17:04:37.991720 21347 net.cpp:91] Creating Layer conv1_2
I0624 17:04:37.991724 21347 net.cpp:425] conv1_2 <- conv1_1
I0624 17:04:37.991727 21347 net.cpp:399] conv1_2 -> conv1_2
I0624 17:04:37.992604 21347 net.cpp:141] Setting up conv1_2
I0624 17:04:37.992615 21347 net.cpp:148] Top shape: 16 32 112 112 (6422528)
I0624 17:04:37.992619 21347 net.cpp:156] Memory required for data: 138084544
I0624 17:04:37.992622 21347 layer_factory.hpp:77] Creating layer bn1_2
I0624 17:04:37.992630 21347 net.cpp:91] Creating Layer bn1_2
I0624 17:04:37.992633 21347 net.cpp:425] bn1_2 <- conv1_2
I0624 17:04:37.992638 21347 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0624 17:04:37.992795 21347 net.cpp:141] Setting up bn1_2
I0624 17:04:37.992804 21347 net.cpp:148] Top shape: 16 32 112 112 (6422528)
I0624 17:04:37.992805 21347 net.cpp:156] Memory required for data: 163774656
I0624 17:04:37.992813 21347 layer_factory.hpp:77] Creating layer scale1_2
I0624 17:04:37.992820 21347 net.cpp:91] Creating Layer scale1_2
I0624 17:04:37.992823 21347 net.cpp:425] scale1_2 <- conv1_2
I0624 17:04:37.992826 21347 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0624 17:04:37.992861 21347 layer_factory.hpp:77] Creating layer scale1_2
I0624 17:04:37.992969 21347 net.cpp:141] Setting up scale1_2
I0624 17:04:37.992975 21347 net.cpp:148] Top shape: 16 32 112 112 (6422528)
I0624 17:04:37.992977 21347 net.cpp:156] Memory required for data: 189464768
I0624 17:04:37.992982 21347 layer_factory.hpp:77] Creating layer relu1_2
I0624 17:04:37.992987 21347 net.cpp:91] Creating Layer relu1_2
I0624 17:04:37.992990 21347 net.cpp:425] relu1_2 <- conv1_2
I0624 17:04:37.992993 21347 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0624 17:04:37.993362 21347 net.cpp:141] Setting up relu1_2
I0624 17:04:37.993374 21347 net.cpp:148] Top shape: 16 32 112 112 (6422528)
I0624 17:04:37.993376 21347 net.cpp:156] Memory required for data: 215154880
I0624 17:04:37.993379 21347 layer_factory.hpp:77] Creating layer pool1
I0624 17:04:37.993386 21347 net.cpp:91] Creating Layer pool1
I0624 17:04:37.993388 21347 net.cpp:425] pool1 <- conv1_2
I0624 17:04:37.993393 21347 net.cpp:399] pool1 -> pool1
I0624 17:04:37.993432 21347 net.cpp:141] Setting up pool1
I0624 17:04:37.993438 21347 net.cpp:148] Top shape: 16 32 56 56 (1605632)
I0624 17:04:37.993440 21347 net.cpp:156] Memory required for data: 221577408
I0624 17:04:37.993443 21347 layer_factory.hpp:77] Creating layer conv2_1
I0624 17:04:37.993449 21347 net.cpp:91] Creating Layer conv2_1
I0624 17:04:37.993453 21347 net.cpp:425] conv2_1 <- pool1
I0624 17:04:37.993456 21347 net.cpp:399] conv2_1 -> conv2_1
I0624 17:04:37.994307 21347 net.cpp:141] Setting up conv2_1
I0624 17:04:37.994319 21347 net.cpp:148] Top shape: 16 32 56 56 (1605632)
I0624 17:04:37.994321 21347 net.cpp:156] Memory required for data: 227999936
I0624 17:04:37.994326 21347 layer_factory.hpp:77] Creating layer bn2_1
I0624 17:04:37.994333 21347 net.cpp:91] Creating Layer bn2_1
I0624 17:04:37.994336 21347 net.cpp:425] bn2_1 <- conv2_1
I0624 17:04:37.994340 21347 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0624 17:04:37.994499 21347 net.cpp:141] Setting up bn2_1
I0624 17:04:37.994506 21347 net.cpp:148] Top shape: 16 32 56 56 (1605632)
I0624 17:04:37.994508 21347 net.cpp:156] Memory required for data: 234422464
I0624 17:04:37.994524 21347 layer_factory.hpp:77] Creating layer scale2_1
I0624 17:04:37.994531 21347 net.cpp:91] Creating Layer scale2_1
I0624 17:04:37.994534 21347 net.cpp:425] scale2_1 <- conv2_1
I0624 17:04:37.994539 21347 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0624 17:04:37.994576 21347 layer_factory.hpp:77] Creating layer scale2_1
I0624 17:04:37.994680 21347 net.cpp:141] Setting up scale2_1
I0624 17:04:37.994688 21347 net.cpp:148] Top shape: 16 32 56 56 (1605632)
I0624 17:04:37.994689 21347 net.cpp:156] Memory required for data: 240844992
I0624 17:04:37.994696 21347 layer_factory.hpp:77] Creating layer relu2_1
I0624 17:04:37.994702 21347 net.cpp:91] Creating Layer relu2_1
I0624 17:04:37.994706 21347 net.cpp:425] relu2_1 <- conv2_1
I0624 17:04:37.994709 21347 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0624 17:04:37.994848 21347 net.cpp:141] Setting up relu2_1
I0624 17:04:37.994858 21347 net.cpp:148] Top shape: 16 32 56 56 (1605632)
I0624 17:04:37.994859 21347 net.cpp:156] Memory required for data: 247267520
I0624 17:04:37.994863 21347 layer_factory.hpp:77] Creating layer conv2_2
I0624 17:04:37.994870 21347 net.cpp:91] Creating Layer conv2_2
I0624 17:04:37.994874 21347 net.cpp:425] conv2_2 <- conv2_1
I0624 17:04:37.994879 21347 net.cpp:399] conv2_2 -> conv2_2
I0624 17:04:37.995754 21347 net.cpp:141] Setting up conv2_2
I0624 17:04:37.995765 21347 net.cpp:148] Top shape: 16 32 56 56 (1605632)
I0624 17:04:37.995769 21347 net.cpp:156] Memory required for data: 253690048
I0624 17:04:37.995772 21347 layer_factory.hpp:77] Creating layer bn2_2
I0624 17:04:37.995780 21347 net.cpp:91] Creating Layer bn2_2
I0624 17:04:37.995784 21347 net.cpp:425] bn2_2 <- conv2_2
I0624 17:04:37.995789 21347 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0624 17:04:37.995945 21347 net.cpp:141] Setting up bn2_2
I0624 17:04:37.995952 21347 net.cpp:148] Top shape: 16 32 56 56 (1605632)
I0624 17:04:37.995955 21347 net.cpp:156] Memory required for data: 260112576
I0624 17:04:37.995960 21347 layer_factory.hpp:77] Creating layer scale2_2
I0624 17:04:37.995967 21347 net.cpp:91] Creating Layer scale2_2
I0624 17:04:37.995970 21347 net.cpp:425] scale2_2 <- conv2_2
I0624 17:04:37.995973 21347 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0624 17:04:37.996007 21347 layer_factory.hpp:77] Creating layer scale2_2
I0624 17:04:37.996106 21347 net.cpp:141] Setting up scale2_2
I0624 17:04:37.996114 21347 net.cpp:148] Top shape: 16 32 56 56 (1605632)
I0624 17:04:37.996116 21347 net.cpp:156] Memory required for data: 266535104
I0624 17:04:37.996120 21347 layer_factory.hpp:77] Creating layer relu2_2
I0624 17:04:37.996125 21347 net.cpp:91] Creating Layer relu2_2
I0624 17:04:37.996129 21347 net.cpp:425] relu2_2 <- conv2_2
I0624 17:04:37.996131 21347 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0624 17:04:37.996289 21347 net.cpp:141] Setting up relu2_2
I0624 17:04:37.996297 21347 net.cpp:148] Top shape: 16 32 56 56 (1605632)
I0624 17:04:37.996300 21347 net.cpp:156] Memory required for data: 272957632
I0624 17:04:37.996304 21347 layer_factory.hpp:77] Creating layer pool2
I0624 17:04:37.996309 21347 net.cpp:91] Creating Layer pool2
I0624 17:04:37.996310 21347 net.cpp:425] pool2 <- conv2_2
I0624 17:04:37.996315 21347 net.cpp:399] pool2 -> pool2
I0624 17:04:37.996351 21347 net.cpp:141] Setting up pool2
I0624 17:04:37.996356 21347 net.cpp:148] Top shape: 16 32 28 28 (401408)
I0624 17:04:37.996358 21347 net.cpp:156] Memory required for data: 274563264
I0624 17:04:37.996361 21347 layer_factory.hpp:77] Creating layer conv3_1
I0624 17:04:37.996368 21347 net.cpp:91] Creating Layer conv3_1
I0624 17:04:37.996371 21347 net.cpp:425] conv3_1 <- pool2
I0624 17:04:37.996376 21347 net.cpp:399] conv3_1 -> conv3_1
I0624 17:04:37.997673 21347 net.cpp:141] Setting up conv3_1
I0624 17:04:37.997684 21347 net.cpp:148] Top shape: 16 32 28 28 (401408)
I0624 17:04:37.997686 21347 net.cpp:156] Memory required for data: 276168896
I0624 17:04:37.997691 21347 layer_factory.hpp:77] Creating layer bn3_1
I0624 17:04:37.997699 21347 net.cpp:91] Creating Layer bn3_1
I0624 17:04:37.997701 21347 net.cpp:425] bn3_1 <- conv3_1
I0624 17:04:37.997714 21347 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0624 17:04:37.997889 21347 net.cpp:141] Setting up bn3_1
I0624 17:04:37.997895 21347 net.cpp:148] Top shape: 16 32 28 28 (401408)
I0624 17:04:37.997898 21347 net.cpp:156] Memory required for data: 277774528
I0624 17:04:37.997903 21347 layer_factory.hpp:77] Creating layer scale3_1
I0624 17:04:37.997910 21347 net.cpp:91] Creating Layer scale3_1
I0624 17:04:37.997913 21347 net.cpp:425] scale3_1 <- conv3_1
I0624 17:04:37.997916 21347 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0624 17:04:37.997949 21347 layer_factory.hpp:77] Creating layer scale3_1
I0624 17:04:37.998046 21347 net.cpp:141] Setting up scale3_1
I0624 17:04:37.998052 21347 net.cpp:148] Top shape: 16 32 28 28 (401408)
I0624 17:04:37.998055 21347 net.cpp:156] Memory required for data: 279380160
I0624 17:04:37.998059 21347 layer_factory.hpp:77] Creating layer relu3_1
I0624 17:04:37.998064 21347 net.cpp:91] Creating Layer relu3_1
I0624 17:04:37.998065 21347 net.cpp:425] relu3_1 <- conv3_1
I0624 17:04:37.998070 21347 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0624 17:04:37.998215 21347 net.cpp:141] Setting up relu3_1
I0624 17:04:37.998224 21347 net.cpp:148] Top shape: 16 32 28 28 (401408)
I0624 17:04:37.998226 21347 net.cpp:156] Memory required for data: 280985792
I0624 17:04:37.998229 21347 layer_factory.hpp:77] Creating layer conv3_2
I0624 17:04:37.998237 21347 net.cpp:91] Creating Layer conv3_2
I0624 17:04:37.998240 21347 net.cpp:425] conv3_2 <- conv3_1
I0624 17:04:37.998245 21347 net.cpp:399] conv3_2 -> conv3_2
I0624 17:04:37.999111 21347 net.cpp:141] Setting up conv3_2
I0624 17:04:37.999124 21347 net.cpp:148] Top shape: 16 32 28 28 (401408)
I0624 17:04:37.999126 21347 net.cpp:156] Memory required for data: 282591424
I0624 17:04:37.999130 21347 layer_factory.hpp:77] Creating layer bn3_2
I0624 17:04:37.999140 21347 net.cpp:91] Creating Layer bn3_2
I0624 17:04:37.999142 21347 net.cpp:425] bn3_2 <- conv3_2
I0624 17:04:37.999153 21347 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0624 17:04:37.999312 21347 net.cpp:141] Setting up bn3_2
I0624 17:04:37.999320 21347 net.cpp:148] Top shape: 16 32 28 28 (401408)
I0624 17:04:37.999322 21347 net.cpp:156] Memory required for data: 284197056
I0624 17:04:37.999332 21347 layer_factory.hpp:77] Creating layer scale3_2
I0624 17:04:37.999338 21347 net.cpp:91] Creating Layer scale3_2
I0624 17:04:37.999341 21347 net.cpp:425] scale3_2 <- conv3_2
I0624 17:04:37.999346 21347 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0624 17:04:37.999379 21347 layer_factory.hpp:77] Creating layer scale3_2
I0624 17:04:37.999476 21347 net.cpp:141] Setting up scale3_2
I0624 17:04:37.999482 21347 net.cpp:148] Top shape: 16 32 28 28 (401408)
I0624 17:04:37.999485 21347 net.cpp:156] Memory required for data: 285802688
I0624 17:04:37.999490 21347 layer_factory.hpp:77] Creating layer relu3_2
I0624 17:04:37.999493 21347 net.cpp:91] Creating Layer relu3_2
I0624 17:04:37.999495 21347 net.cpp:425] relu3_2 <- conv3_2
I0624 17:04:37.999500 21347 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0624 17:04:37.999634 21347 net.cpp:141] Setting up relu3_2
I0624 17:04:37.999642 21347 net.cpp:148] Top shape: 16 32 28 28 (401408)
I0624 17:04:37.999644 21347 net.cpp:156] Memory required for data: 287408320
I0624 17:04:37.999647 21347 layer_factory.hpp:77] Creating layer pool3
I0624 17:04:37.999653 21347 net.cpp:91] Creating Layer pool3
I0624 17:04:37.999656 21347 net.cpp:425] pool3 <- conv3_2
I0624 17:04:37.999660 21347 net.cpp:399] pool3 -> pool3
I0624 17:04:37.999696 21347 net.cpp:141] Setting up pool3
I0624 17:04:37.999701 21347 net.cpp:148] Top shape: 16 32 14 14 (100352)
I0624 17:04:37.999703 21347 net.cpp:156] Memory required for data: 287809728
I0624 17:04:37.999706 21347 layer_factory.hpp:77] Creating layer conv4_1
I0624 17:04:37.999713 21347 net.cpp:91] Creating Layer conv4_1
I0624 17:04:37.999716 21347 net.cpp:425] conv4_1 <- pool3
I0624 17:04:37.999722 21347 net.cpp:399] conv4_1 -> conv4_1
I0624 17:04:38.000619 21347 net.cpp:141] Setting up conv4_1
I0624 17:04:38.000632 21347 net.cpp:148] Top shape: 16 64 14 14 (200704)
I0624 17:04:38.000645 21347 net.cpp:156] Memory required for data: 288612544
I0624 17:04:38.000649 21347 layer_factory.hpp:77] Creating layer bn4_1
I0624 17:04:38.000655 21347 net.cpp:91] Creating Layer bn4_1
I0624 17:04:38.000658 21347 net.cpp:425] bn4_1 <- conv4_1
I0624 17:04:38.000664 21347 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0624 17:04:38.000828 21347 net.cpp:141] Setting up bn4_1
I0624 17:04:38.000834 21347 net.cpp:148] Top shape: 16 64 14 14 (200704)
I0624 17:04:38.000836 21347 net.cpp:156] Memory required for data: 289415360
I0624 17:04:38.000843 21347 layer_factory.hpp:77] Creating layer scale4_1
I0624 17:04:38.000849 21347 net.cpp:91] Creating Layer scale4_1
I0624 17:04:38.000851 21347 net.cpp:425] scale4_1 <- conv4_1
I0624 17:04:38.000854 21347 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0624 17:04:38.000890 21347 layer_factory.hpp:77] Creating layer scale4_1
I0624 17:04:38.000982 21347 net.cpp:141] Setting up scale4_1
I0624 17:04:38.000989 21347 net.cpp:148] Top shape: 16 64 14 14 (200704)
I0624 17:04:38.000991 21347 net.cpp:156] Memory required for data: 290218176
I0624 17:04:38.000995 21347 layer_factory.hpp:77] Creating layer relu4_1
I0624 17:04:38.001003 21347 net.cpp:91] Creating Layer relu4_1
I0624 17:04:38.001006 21347 net.cpp:425] relu4_1 <- conv4_1
I0624 17:04:38.001010 21347 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0624 17:04:38.001144 21347 net.cpp:141] Setting up relu4_1
I0624 17:04:38.001152 21347 net.cpp:148] Top shape: 16 64 14 14 (200704)
I0624 17:04:38.001155 21347 net.cpp:156] Memory required for data: 291020992
I0624 17:04:38.001157 21347 layer_factory.hpp:77] Creating layer conv4_2
I0624 17:04:38.001165 21347 net.cpp:91] Creating Layer conv4_2
I0624 17:04:38.001168 21347 net.cpp:425] conv4_2 <- conv4_1
I0624 17:04:38.001173 21347 net.cpp:399] conv4_2 -> conv4_2
I0624 17:04:38.002192 21347 net.cpp:141] Setting up conv4_2
I0624 17:04:38.002203 21347 net.cpp:148] Top shape: 16 64 14 14 (200704)
I0624 17:04:38.002207 21347 net.cpp:156] Memory required for data: 291823808
I0624 17:04:38.002210 21347 layer_factory.hpp:77] Creating layer bn4_2
I0624 17:04:38.002218 21347 net.cpp:91] Creating Layer bn4_2
I0624 17:04:38.002221 21347 net.cpp:425] bn4_2 <- conv4_2
I0624 17:04:38.002225 21347 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0624 17:04:38.002382 21347 net.cpp:141] Setting up bn4_2
I0624 17:04:38.002389 21347 net.cpp:148] Top shape: 16 64 14 14 (200704)
I0624 17:04:38.002391 21347 net.cpp:156] Memory required for data: 292626624
I0624 17:04:38.002396 21347 layer_factory.hpp:77] Creating layer scale4_2
I0624 17:04:38.002403 21347 net.cpp:91] Creating Layer scale4_2
I0624 17:04:38.002406 21347 net.cpp:425] scale4_2 <- conv4_2
I0624 17:04:38.002409 21347 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0624 17:04:38.002444 21347 layer_factory.hpp:77] Creating layer scale4_2
I0624 17:04:38.002534 21347 net.cpp:141] Setting up scale4_2
I0624 17:04:38.002540 21347 net.cpp:148] Top shape: 16 64 14 14 (200704)
I0624 17:04:38.002542 21347 net.cpp:156] Memory required for data: 293429440
I0624 17:04:38.002547 21347 layer_factory.hpp:77] Creating layer relu4_2
I0624 17:04:38.002552 21347 net.cpp:91] Creating Layer relu4_2
I0624 17:04:38.002554 21347 net.cpp:425] relu4_2 <- conv4_2
I0624 17:04:38.002557 21347 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0624 17:04:38.002930 21347 net.cpp:141] Setting up relu4_2
I0624 17:04:38.002941 21347 net.cpp:148] Top shape: 16 64 14 14 (200704)
I0624 17:04:38.002944 21347 net.cpp:156] Memory required for data: 294232256
I0624 17:04:38.002948 21347 layer_factory.hpp:77] Creating layer pool4
I0624 17:04:38.002953 21347 net.cpp:91] Creating Layer pool4
I0624 17:04:38.002955 21347 net.cpp:425] pool4 <- conv4_2
I0624 17:04:38.002960 21347 net.cpp:399] pool4 -> pool4
I0624 17:04:38.003000 21347 net.cpp:141] Setting up pool4
I0624 17:04:38.003005 21347 net.cpp:148] Top shape: 16 64 7 7 (50176)
I0624 17:04:38.003007 21347 net.cpp:156] Memory required for data: 294432960
I0624 17:04:38.003010 21347 layer_factory.hpp:77] Creating layer conv5_1
I0624 17:04:38.003026 21347 net.cpp:91] Creating Layer conv5_1
I0624 17:04:38.003029 21347 net.cpp:425] conv5_1 <- pool4
I0624 17:04:38.003034 21347 net.cpp:399] conv5_1 -> conv5_1
I0624 17:04:38.004068 21347 net.cpp:141] Setting up conv5_1
I0624 17:04:38.004081 21347 net.cpp:148] Top shape: 16 64 7 7 (50176)
I0624 17:04:38.004084 21347 net.cpp:156] Memory required for data: 294633664
I0624 17:04:38.004088 21347 layer_factory.hpp:77] Creating layer bn5_1
I0624 17:04:38.004096 21347 net.cpp:91] Creating Layer bn5_1
I0624 17:04:38.004098 21347 net.cpp:425] bn5_1 <- conv5_1
I0624 17:04:38.004103 21347 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0624 17:04:38.004264 21347 net.cpp:141] Setting up bn5_1
I0624 17:04:38.004271 21347 net.cpp:148] Top shape: 16 64 7 7 (50176)
I0624 17:04:38.004273 21347 net.cpp:156] Memory required for data: 294834368
I0624 17:04:38.004279 21347 layer_factory.hpp:77] Creating layer scale5_1
I0624 17:04:38.004286 21347 net.cpp:91] Creating Layer scale5_1
I0624 17:04:38.004288 21347 net.cpp:425] scale5_1 <- conv5_1
I0624 17:04:38.004292 21347 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0624 17:04:38.004328 21347 layer_factory.hpp:77] Creating layer scale5_1
I0624 17:04:38.004420 21347 net.cpp:141] Setting up scale5_1
I0624 17:04:38.004426 21347 net.cpp:148] Top shape: 16 64 7 7 (50176)
I0624 17:04:38.004429 21347 net.cpp:156] Memory required for data: 295035072
I0624 17:04:38.004433 21347 layer_factory.hpp:77] Creating layer relu5_1
I0624 17:04:38.004438 21347 net.cpp:91] Creating Layer relu5_1
I0624 17:04:38.004441 21347 net.cpp:425] relu5_1 <- conv5_1
I0624 17:04:38.004443 21347 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0624 17:04:38.004581 21347 net.cpp:141] Setting up relu5_1
I0624 17:04:38.004590 21347 net.cpp:148] Top shape: 16 64 7 7 (50176)
I0624 17:04:38.004592 21347 net.cpp:156] Memory required for data: 295235776
I0624 17:04:38.004595 21347 layer_factory.hpp:77] Creating layer conv5_2
I0624 17:04:38.004604 21347 net.cpp:91] Creating Layer conv5_2
I0624 17:04:38.004607 21347 net.cpp:425] conv5_2 <- conv5_1
I0624 17:04:38.004611 21347 net.cpp:399] conv5_2 -> conv5_2
I0624 17:04:38.005642 21347 net.cpp:141] Setting up conv5_2
I0624 17:04:38.005655 21347 net.cpp:148] Top shape: 16 64 7 7 (50176)
I0624 17:04:38.005656 21347 net.cpp:156] Memory required for data: 295436480
I0624 17:04:38.005661 21347 layer_factory.hpp:77] Creating layer bn5_2
I0624 17:04:38.005668 21347 net.cpp:91] Creating Layer bn5_2
I0624 17:04:38.005671 21347 net.cpp:425] bn5_2 <- conv5_2
I0624 17:04:38.005676 21347 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0624 17:04:38.005836 21347 net.cpp:141] Setting up bn5_2
I0624 17:04:38.005842 21347 net.cpp:148] Top shape: 16 64 7 7 (50176)
I0624 17:04:38.005846 21347 net.cpp:156] Memory required for data: 295637184
I0624 17:04:38.005851 21347 layer_factory.hpp:77] Creating layer scale5_2
I0624 17:04:38.005856 21347 net.cpp:91] Creating Layer scale5_2
I0624 17:04:38.005858 21347 net.cpp:425] scale5_2 <- conv5_2
I0624 17:04:38.005861 21347 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0624 17:04:38.005897 21347 layer_factory.hpp:77] Creating layer scale5_2
I0624 17:04:38.005991 21347 net.cpp:141] Setting up scale5_2
I0624 17:04:38.006000 21347 net.cpp:148] Top shape: 16 64 7 7 (50176)
I0624 17:04:38.006001 21347 net.cpp:156] Memory required for data: 295837888
I0624 17:04:38.006006 21347 layer_factory.hpp:77] Creating layer relu5_2
I0624 17:04:38.006011 21347 net.cpp:91] Creating Layer relu5_2
I0624 17:04:38.006012 21347 net.cpp:425] relu5_2 <- conv5_2
I0624 17:04:38.006016 21347 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0624 17:04:38.006158 21347 net.cpp:141] Setting up relu5_2
I0624 17:04:38.006166 21347 net.cpp:148] Top shape: 16 64 7 7 (50176)
I0624 17:04:38.006170 21347 net.cpp:156] Memory required for data: 296038592
I0624 17:04:38.006171 21347 layer_factory.hpp:77] Creating layer pool5
I0624 17:04:38.006176 21347 net.cpp:91] Creating Layer pool5
I0624 17:04:38.006180 21347 net.cpp:425] pool5 <- conv5_2
I0624 17:04:38.006184 21347 net.cpp:399] pool5 -> pool5
I0624 17:04:38.006346 21347 net.cpp:141] Setting up pool5
I0624 17:04:38.006356 21347 net.cpp:148] Top shape: 16 64 1 1 (1024)
I0624 17:04:38.006358 21347 net.cpp:156] Memory required for data: 296042688
I0624 17:04:38.006361 21347 layer_factory.hpp:77] Creating layer fc2
I0624 17:04:38.006368 21347 net.cpp:91] Creating Layer fc2
I0624 17:04:38.006371 21347 net.cpp:425] fc2 <- pool5
I0624 17:04:38.006376 21347 net.cpp:399] fc2 -> fc2
I0624 17:04:38.006459 21347 net.cpp:141] Setting up fc2
I0624 17:04:38.006465 21347 net.cpp:148] Top shape: 16 2 (32)
I0624 17:04:38.006469 21347 net.cpp:156] Memory required for data: 296042816
I0624 17:04:38.006472 21347 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0624 17:04:38.006477 21347 net.cpp:91] Creating Layer fc2_fc2_0_split
I0624 17:04:38.006479 21347 net.cpp:425] fc2_fc2_0_split <- fc2
I0624 17:04:38.006484 21347 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0624 17:04:38.006489 21347 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0624 17:04:38.006517 21347 net.cpp:141] Setting up fc2_fc2_0_split
I0624 17:04:38.006523 21347 net.cpp:148] Top shape: 16 2 (32)
I0624 17:04:38.006526 21347 net.cpp:148] Top shape: 16 2 (32)
I0624 17:04:38.006528 21347 net.cpp:156] Memory required for data: 296043072
I0624 17:04:38.006531 21347 layer_factory.hpp:77] Creating layer loss
I0624 17:04:38.006536 21347 net.cpp:91] Creating Layer loss
I0624 17:04:38.006538 21347 net.cpp:425] loss <- fc2_fc2_0_split_0
I0624 17:04:38.006541 21347 net.cpp:425] loss <- label_data_1_split_0
I0624 17:04:38.006546 21347 net.cpp:399] loss -> loss
I0624 17:04:38.006551 21347 layer_factory.hpp:77] Creating layer loss
I0624 17:04:38.007002 21347 net.cpp:141] Setting up loss
I0624 17:04:38.007014 21347 net.cpp:148] Top shape: (1)
I0624 17:04:38.007015 21347 net.cpp:151]     with loss weight 1
I0624 17:04:38.007024 21347 net.cpp:156] Memory required for data: 296043076
I0624 17:04:38.007025 21347 layer_factory.hpp:77] Creating layer accuracy
I0624 17:04:38.007032 21347 net.cpp:91] Creating Layer accuracy
I0624 17:04:38.007035 21347 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0624 17:04:38.007038 21347 net.cpp:425] accuracy <- label_data_1_split_1
I0624 17:04:38.007042 21347 net.cpp:399] accuracy -> accuracy
I0624 17:04:38.007048 21347 net.cpp:141] Setting up accuracy
I0624 17:04:38.007051 21347 net.cpp:148] Top shape: (1)
I0624 17:04:38.007053 21347 net.cpp:156] Memory required for data: 296043080
I0624 17:04:38.007056 21347 net.cpp:219] accuracy does not need backward computation.
I0624 17:04:38.007058 21347 net.cpp:217] loss needs backward computation.
I0624 17:04:38.007061 21347 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0624 17:04:38.007063 21347 net.cpp:217] fc2 needs backward computation.
I0624 17:04:38.007066 21347 net.cpp:217] pool5 needs backward computation.
I0624 17:04:38.007067 21347 net.cpp:217] relu5_2 needs backward computation.
I0624 17:04:38.007069 21347 net.cpp:217] scale5_2 needs backward computation.
I0624 17:04:38.007071 21347 net.cpp:217] bn5_2 needs backward computation.
I0624 17:04:38.007073 21347 net.cpp:217] conv5_2 needs backward computation.
I0624 17:04:38.007076 21347 net.cpp:217] relu5_1 needs backward computation.
I0624 17:04:38.007077 21347 net.cpp:217] scale5_1 needs backward computation.
I0624 17:04:38.007079 21347 net.cpp:217] bn5_1 needs backward computation.
I0624 17:04:38.007081 21347 net.cpp:217] conv5_1 needs backward computation.
I0624 17:04:38.007083 21347 net.cpp:217] pool4 needs backward computation.
I0624 17:04:38.007086 21347 net.cpp:217] relu4_2 needs backward computation.
I0624 17:04:38.007088 21347 net.cpp:217] scale4_2 needs backward computation.
I0624 17:04:38.007091 21347 net.cpp:217] bn4_2 needs backward computation.
I0624 17:04:38.007091 21347 net.cpp:217] conv4_2 needs backward computation.
I0624 17:04:38.007094 21347 net.cpp:217] relu4_1 needs backward computation.
I0624 17:04:38.007096 21347 net.cpp:217] scale4_1 needs backward computation.
I0624 17:04:38.007097 21347 net.cpp:217] bn4_1 needs backward computation.
I0624 17:04:38.007099 21347 net.cpp:217] conv4_1 needs backward computation.
I0624 17:04:38.007112 21347 net.cpp:217] pool3 needs backward computation.
I0624 17:04:38.007113 21347 net.cpp:217] relu3_2 needs backward computation.
I0624 17:04:38.007115 21347 net.cpp:217] scale3_2 needs backward computation.
I0624 17:04:38.007117 21347 net.cpp:217] bn3_2 needs backward computation.
I0624 17:04:38.007119 21347 net.cpp:217] conv3_2 needs backward computation.
I0624 17:04:38.007122 21347 net.cpp:217] relu3_1 needs backward computation.
I0624 17:04:38.007124 21347 net.cpp:217] scale3_1 needs backward computation.
I0624 17:04:38.007125 21347 net.cpp:217] bn3_1 needs backward computation.
I0624 17:04:38.007128 21347 net.cpp:217] conv3_1 needs backward computation.
I0624 17:04:38.007130 21347 net.cpp:217] pool2 needs backward computation.
I0624 17:04:38.007133 21347 net.cpp:217] relu2_2 needs backward computation.
I0624 17:04:38.007134 21347 net.cpp:217] scale2_2 needs backward computation.
I0624 17:04:38.007136 21347 net.cpp:217] bn2_2 needs backward computation.
I0624 17:04:38.007138 21347 net.cpp:217] conv2_2 needs backward computation.
I0624 17:04:38.007140 21347 net.cpp:217] relu2_1 needs backward computation.
I0624 17:04:38.007143 21347 net.cpp:217] scale2_1 needs backward computation.
I0624 17:04:38.007144 21347 net.cpp:217] bn2_1 needs backward computation.
I0624 17:04:38.007148 21347 net.cpp:217] conv2_1 needs backward computation.
I0624 17:04:38.007156 21347 net.cpp:217] pool1 needs backward computation.
I0624 17:04:38.007160 21347 net.cpp:217] relu1_2 needs backward computation.
I0624 17:04:38.007164 21347 net.cpp:217] scale1_2 needs backward computation.
I0624 17:04:38.007167 21347 net.cpp:217] bn1_2 needs backward computation.
I0624 17:04:38.007171 21347 net.cpp:217] conv1_2 needs backward computation.
I0624 17:04:38.007175 21347 net.cpp:217] relu1_1 needs backward computation.
I0624 17:04:38.007179 21347 net.cpp:217] scale1_1 needs backward computation.
I0624 17:04:38.007182 21347 net.cpp:217] bn1_1 needs backward computation.
I0624 17:04:38.007184 21347 net.cpp:217] conv1_1 needs backward computation.
I0624 17:04:38.007187 21347 net.cpp:219] label_data_1_split does not need backward computation.
I0624 17:04:38.007190 21347 net.cpp:219] data does not need backward computation.
I0624 17:04:38.007192 21347 net.cpp:261] This network produces output accuracy
I0624 17:04:38.007195 21347 net.cpp:261] This network produces output loss
I0624 17:04:38.007215 21347 net.cpp:274] Network initialization done.
I0624 17:04:38.007351 21347 solver.cpp:60] Solver scaffolding done.
I0624 17:04:38.009004 21347 caffe.cpp:219] Starting Optimization
I0624 17:04:38.009011 21347 solver.cpp:279] Solving BPnet
I0624 17:04:38.009013 21347 solver.cpp:280] Learning Rate Policy: step
I0624 17:04:38.009905 21347 solver.cpp:337] Iteration 0, Testing net (#0)
I0624 17:04:38.010526 21347 blocking_queue.cpp:50] Data layer prefetch queue empty
I0624 17:04:38.123004 21347 solver.cpp:404]     Test net output #0: accuracy = 0.421875
I0624 17:04:38.123036 21347 solver.cpp:404]     Test net output #1: loss = 0.693147 (* 1 = 0.693147 loss)
I0624 17:04:38.157618 21347 solver.cpp:228] Iteration 0, loss = 0.693147
I0624 17:04:38.157649 21347 solver.cpp:244]     Train net output #0: accuracy = 0.3125
I0624 17:04:38.157656 21347 solver.cpp:244]     Train net output #1: loss = 0.693147 (* 1 = 0.693147 loss)
I0624 17:04:38.157672 21347 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0624 17:04:38.738750 21347 solver.cpp:228] Iteration 20, loss = 0.636638
I0624 17:04:38.738775 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:04:38.738783 21347 solver.cpp:244]     Train net output #1: loss = 0.636638 (* 1 = 0.636638 loss)
I0624 17:04:38.738787 21347 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0624 17:04:39.336899 21347 solver.cpp:228] Iteration 40, loss = 0.661187
I0624 17:04:39.336935 21347 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0624 17:04:39.336942 21347 solver.cpp:244]     Train net output #1: loss = 0.661187 (* 1 = 0.661187 loss)
I0624 17:04:39.336966 21347 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0624 17:04:39.932616 21347 solver.cpp:228] Iteration 60, loss = 0.627547
I0624 17:04:39.932642 21347 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0624 17:04:39.932648 21347 solver.cpp:244]     Train net output #1: loss = 0.627547 (* 1 = 0.627547 loss)
I0624 17:04:39.932652 21347 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0624 17:04:40.532215 21347 solver.cpp:228] Iteration 80, loss = 0.670404
I0624 17:04:40.532241 21347 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0624 17:04:40.532248 21347 solver.cpp:244]     Train net output #1: loss = 0.670404 (* 1 = 0.670404 loss)
I0624 17:04:40.532253 21347 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0624 17:04:41.119815 21347 solver.cpp:337] Iteration 100, Testing net (#0)
I0624 17:04:41.225963 21347 solver.cpp:404]     Test net output #0: accuracy = 0.6875
I0624 17:04:41.225991 21347 solver.cpp:404]     Test net output #1: loss = 0.587083 (* 1 = 0.587083 loss)
I0624 17:04:41.236843 21347 solver.cpp:228] Iteration 100, loss = 0.543848
I0624 17:04:41.236868 21347 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:04:41.236876 21347 solver.cpp:244]     Train net output #1: loss = 0.543848 (* 1 = 0.543848 loss)
I0624 17:04:41.236881 21347 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0624 17:04:41.835934 21347 solver.cpp:228] Iteration 120, loss = 0.827616
I0624 17:04:41.835959 21347 solver.cpp:244]     Train net output #0: accuracy = 0.375
I0624 17:04:41.835978 21347 solver.cpp:244]     Train net output #1: loss = 0.827616 (* 1 = 0.827616 loss)
I0624 17:04:41.835983 21347 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0624 17:04:42.431246 21347 solver.cpp:228] Iteration 140, loss = 0.814486
I0624 17:04:42.431269 21347 solver.cpp:244]     Train net output #0: accuracy = 0.25
I0624 17:04:42.431277 21347 solver.cpp:244]     Train net output #1: loss = 0.814486 (* 1 = 0.814486 loss)
I0624 17:04:42.431282 21347 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0624 17:04:43.021345 21347 solver.cpp:228] Iteration 160, loss = 0.761289
I0624 17:04:43.021371 21347 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0624 17:04:43.021378 21347 solver.cpp:244]     Train net output #1: loss = 0.761289 (* 1 = 0.761289 loss)
I0624 17:04:43.021384 21347 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0624 17:04:43.617146 21347 solver.cpp:228] Iteration 180, loss = 0.552073
I0624 17:04:43.617172 21347 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:04:43.617178 21347 solver.cpp:244]     Train net output #1: loss = 0.552073 (* 1 = 0.552073 loss)
I0624 17:04:43.617182 21347 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0624 17:04:44.205796 21347 solver.cpp:337] Iteration 200, Testing net (#0)
I0624 17:04:44.312520 21347 solver.cpp:404]     Test net output #0: accuracy = 0.75
I0624 17:04:44.312549 21347 solver.cpp:404]     Test net output #1: loss = 0.51546 (* 1 = 0.51546 loss)
I0624 17:04:44.323312 21347 solver.cpp:228] Iteration 200, loss = 0.519745
I0624 17:04:44.323334 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:04:44.323341 21347 solver.cpp:244]     Train net output #1: loss = 0.519745 (* 1 = 0.519745 loss)
I0624 17:04:44.323346 21347 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0624 17:04:44.922569 21347 solver.cpp:228] Iteration 220, loss = 0.556342
I0624 17:04:44.922595 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:04:44.922602 21347 solver.cpp:244]     Train net output #1: loss = 0.556342 (* 1 = 0.556342 loss)
I0624 17:04:44.922606 21347 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0624 17:04:45.520185 21347 solver.cpp:228] Iteration 240, loss = 0.603327
I0624 17:04:45.520212 21347 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:04:45.520220 21347 solver.cpp:244]     Train net output #1: loss = 0.603327 (* 1 = 0.603327 loss)
I0624 17:04:45.520225 21347 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0624 17:04:46.118646 21347 solver.cpp:228] Iteration 260, loss = 0.81489
I0624 17:04:46.118671 21347 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 17:04:46.118700 21347 solver.cpp:244]     Train net output #1: loss = 0.81489 (* 1 = 0.81489 loss)
I0624 17:04:46.118703 21347 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0624 17:04:46.718575 21347 solver.cpp:228] Iteration 280, loss = 0.636858
I0624 17:04:46.718602 21347 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 17:04:46.718611 21347 solver.cpp:244]     Train net output #1: loss = 0.636858 (* 1 = 0.636858 loss)
I0624 17:04:46.718614 21347 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0624 17:04:47.306882 21347 solver.cpp:337] Iteration 300, Testing net (#0)
I0624 17:04:47.417279 21347 solver.cpp:404]     Test net output #0: accuracy = 0.710938
I0624 17:04:47.417309 21347 solver.cpp:404]     Test net output #1: loss = 0.549073 (* 1 = 0.549073 loss)
I0624 17:04:47.428066 21347 solver.cpp:228] Iteration 300, loss = 0.547062
I0624 17:04:47.428088 21347 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:04:47.428095 21347 solver.cpp:244]     Train net output #1: loss = 0.547062 (* 1 = 0.547062 loss)
I0624 17:04:47.428100 21347 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0624 17:04:48.026967 21347 solver.cpp:228] Iteration 320, loss = 0.509685
I0624 17:04:48.027003 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:04:48.027010 21347 solver.cpp:244]     Train net output #1: loss = 0.509685 (* 1 = 0.509685 loss)
I0624 17:04:48.027014 21347 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0624 17:04:48.624332 21347 solver.cpp:228] Iteration 340, loss = 0.514281
I0624 17:04:48.624358 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:04:48.624377 21347 solver.cpp:244]     Train net output #1: loss = 0.514281 (* 1 = 0.514281 loss)
I0624 17:04:48.624382 21347 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0624 17:04:49.221789 21347 solver.cpp:228] Iteration 360, loss = 0.426433
I0624 17:04:49.221824 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:04:49.221832 21347 solver.cpp:244]     Train net output #1: loss = 0.426433 (* 1 = 0.426433 loss)
I0624 17:04:49.221837 21347 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0624 17:04:49.819519 21347 solver.cpp:228] Iteration 380, loss = 0.690591
I0624 17:04:49.819545 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:04:49.819555 21347 solver.cpp:244]     Train net output #1: loss = 0.690591 (* 1 = 0.690591 loss)
I0624 17:04:49.819558 21347 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0624 17:04:50.407048 21347 solver.cpp:337] Iteration 400, Testing net (#0)
I0624 17:04:50.516465 21347 solver.cpp:404]     Test net output #0: accuracy = 0.703125
I0624 17:04:50.516492 21347 solver.cpp:404]     Test net output #1: loss = 0.545642 (* 1 = 0.545642 loss)
I0624 17:04:50.527281 21347 solver.cpp:228] Iteration 400, loss = 0.474339
I0624 17:04:50.527307 21347 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:04:50.527315 21347 solver.cpp:244]     Train net output #1: loss = 0.474339 (* 1 = 0.474339 loss)
I0624 17:04:50.527320 21347 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0624 17:04:51.125645 21347 solver.cpp:228] Iteration 420, loss = 0.345988
I0624 17:04:51.125674 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:04:51.125679 21347 solver.cpp:244]     Train net output #1: loss = 0.345988 (* 1 = 0.345988 loss)
I0624 17:04:51.125684 21347 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0624 17:04:51.723634 21347 solver.cpp:228] Iteration 440, loss = 0.566831
I0624 17:04:51.723659 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:04:51.723665 21347 solver.cpp:244]     Train net output #1: loss = 0.566831 (* 1 = 0.566831 loss)
I0624 17:04:51.723670 21347 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0624 17:04:52.323307 21347 solver.cpp:228] Iteration 460, loss = 0.740148
I0624 17:04:52.323345 21347 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0624 17:04:52.323351 21347 solver.cpp:244]     Train net output #1: loss = 0.740148 (* 1 = 0.740148 loss)
I0624 17:04:52.323377 21347 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0624 17:04:52.920681 21347 solver.cpp:228] Iteration 480, loss = 0.843989
I0624 17:04:52.920706 21347 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 17:04:52.920713 21347 solver.cpp:244]     Train net output #1: loss = 0.843989 (* 1 = 0.843989 loss)
I0624 17:04:52.920717 21347 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0624 17:04:53.508821 21347 solver.cpp:454] Snapshotting to binary proto file data/models/bpgnet_iter_500.caffemodel
I0624 17:04:53.512639 21347 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpgnet_iter_500.solverstate
I0624 17:04:53.513733 21347 solver.cpp:337] Iteration 500, Testing net (#0)
I0624 17:04:53.621279 21347 solver.cpp:404]     Test net output #0: accuracy = 0.78125
I0624 17:04:53.621307 21347 solver.cpp:404]     Test net output #1: loss = 0.471354 (* 1 = 0.471354 loss)
I0624 17:04:53.632073 21347 solver.cpp:228] Iteration 500, loss = 0.547198
I0624 17:04:53.632098 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:04:53.632107 21347 solver.cpp:244]     Train net output #1: loss = 0.547198 (* 1 = 0.547198 loss)
I0624 17:04:53.632112 21347 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0624 17:04:54.232678 21347 solver.cpp:228] Iteration 520, loss = 0.452756
I0624 17:04:54.232704 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:04:54.232712 21347 solver.cpp:244]     Train net output #1: loss = 0.452756 (* 1 = 0.452756 loss)
I0624 17:04:54.232717 21347 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0624 17:04:54.830670 21347 solver.cpp:228] Iteration 540, loss = 0.362394
I0624 17:04:54.830698 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:04:54.830706 21347 solver.cpp:244]     Train net output #1: loss = 0.362394 (* 1 = 0.362394 loss)
I0624 17:04:54.830711 21347 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0624 17:04:55.427603 21347 solver.cpp:228] Iteration 560, loss = 0.393674
I0624 17:04:55.427631 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:04:55.427639 21347 solver.cpp:244]     Train net output #1: loss = 0.393674 (* 1 = 0.393674 loss)
I0624 17:04:55.427644 21347 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0624 17:04:56.023846 21347 solver.cpp:228] Iteration 580, loss = 0.679915
I0624 17:04:56.023871 21347 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:04:56.023879 21347 solver.cpp:244]     Train net output #1: loss = 0.679915 (* 1 = 0.679915 loss)
I0624 17:04:56.023882 21347 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0624 17:04:56.610908 21347 solver.cpp:337] Iteration 600, Testing net (#0)
I0624 17:04:56.714021 21347 solver.cpp:404]     Test net output #0: accuracy = 0.726562
I0624 17:04:56.714053 21347 solver.cpp:404]     Test net output #1: loss = 0.573587 (* 1 = 0.573587 loss)
I0624 17:04:56.725848 21347 solver.cpp:228] Iteration 600, loss = 0.728648
I0624 17:04:56.725884 21347 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 17:04:56.725895 21347 solver.cpp:244]     Train net output #1: loss = 0.728648 (* 1 = 0.728648 loss)
I0624 17:04:56.725903 21347 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0624 17:04:57.326402 21347 solver.cpp:228] Iteration 620, loss = 0.814991
I0624 17:04:57.326431 21347 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0624 17:04:57.326438 21347 solver.cpp:244]     Train net output #1: loss = 0.814991 (* 1 = 0.814991 loss)
I0624 17:04:57.326443 21347 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0624 17:04:57.924182 21347 solver.cpp:228] Iteration 640, loss = 0.40738
I0624 17:04:57.924214 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:04:57.924222 21347 solver.cpp:244]     Train net output #1: loss = 0.40738 (* 1 = 0.40738 loss)
I0624 17:04:57.924227 21347 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0624 17:04:58.520779 21347 solver.cpp:228] Iteration 660, loss = 0.339218
I0624 17:04:58.520803 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:04:58.520843 21347 solver.cpp:244]     Train net output #1: loss = 0.339218 (* 1 = 0.339218 loss)
I0624 17:04:58.520848 21347 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0624 17:04:59.118881 21347 solver.cpp:228] Iteration 680, loss = 0.731247
I0624 17:04:59.118907 21347 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 17:04:59.118916 21347 solver.cpp:244]     Train net output #1: loss = 0.731247 (* 1 = 0.731247 loss)
I0624 17:04:59.118919 21347 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0624 17:04:59.707171 21347 solver.cpp:337] Iteration 700, Testing net (#0)
I0624 17:04:59.813020 21347 solver.cpp:404]     Test net output #0: accuracy = 0.734375
I0624 17:04:59.813050 21347 solver.cpp:404]     Test net output #1: loss = 0.538417 (* 1 = 0.538417 loss)
I0624 17:04:59.823827 21347 solver.cpp:228] Iteration 700, loss = 0.618799
I0624 17:04:59.823848 21347 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 17:04:59.823854 21347 solver.cpp:244]     Train net output #1: loss = 0.618799 (* 1 = 0.618799 loss)
I0624 17:04:59.823860 21347 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0624 17:05:00.426337 21347 solver.cpp:228] Iteration 720, loss = 0.578614
I0624 17:05:00.426374 21347 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:05:00.426380 21347 solver.cpp:244]     Train net output #1: loss = 0.578614 (* 1 = 0.578614 loss)
I0624 17:05:00.426385 21347 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0624 17:05:01.024382 21347 solver.cpp:228] Iteration 740, loss = 0.578991
I0624 17:05:01.024420 21347 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:05:01.024427 21347 solver.cpp:244]     Train net output #1: loss = 0.578991 (* 1 = 0.578991 loss)
I0624 17:05:01.024432 21347 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0624 17:05:01.619659 21347 solver.cpp:228] Iteration 760, loss = 0.47822
I0624 17:05:01.619684 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:05:01.619691 21347 solver.cpp:244]     Train net output #1: loss = 0.47822 (* 1 = 0.47822 loss)
I0624 17:05:01.619695 21347 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0624 17:05:02.211995 21347 solver.cpp:228] Iteration 780, loss = 0.445013
I0624 17:05:02.212023 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:05:02.212029 21347 solver.cpp:244]     Train net output #1: loss = 0.445013 (* 1 = 0.445013 loss)
I0624 17:05:02.212034 21347 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0624 17:05:02.799448 21347 solver.cpp:337] Iteration 800, Testing net (#0)
I0624 17:05:02.905586 21347 solver.cpp:404]     Test net output #0: accuracy = 0.734375
I0624 17:05:02.905612 21347 solver.cpp:404]     Test net output #1: loss = 0.510272 (* 1 = 0.510272 loss)
I0624 17:05:02.916369 21347 solver.cpp:228] Iteration 800, loss = 0.391006
I0624 17:05:02.916393 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:05:02.916399 21347 solver.cpp:244]     Train net output #1: loss = 0.391006 (* 1 = 0.391006 loss)
I0624 17:05:02.916404 21347 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0624 17:05:03.511416 21347 solver.cpp:228] Iteration 820, loss = 0.751645
I0624 17:05:03.511441 21347 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:05:03.511448 21347 solver.cpp:244]     Train net output #1: loss = 0.751645 (* 1 = 0.751645 loss)
I0624 17:05:03.511452 21347 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0624 17:05:04.108500 21347 solver.cpp:228] Iteration 840, loss = 0.514208
I0624 17:05:04.108528 21347 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 17:05:04.108536 21347 solver.cpp:244]     Train net output #1: loss = 0.514208 (* 1 = 0.514208 loss)
I0624 17:05:04.108541 21347 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0624 17:05:04.706533 21347 solver.cpp:228] Iteration 860, loss = 0.32175
I0624 17:05:04.706558 21347 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:05:04.706567 21347 solver.cpp:244]     Train net output #1: loss = 0.32175 (* 1 = 0.32175 loss)
I0624 17:05:04.706570 21347 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0624 17:05:05.304934 21347 solver.cpp:228] Iteration 880, loss = 0.509131
I0624 17:05:05.304960 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:05:05.304968 21347 solver.cpp:244]     Train net output #1: loss = 0.509131 (* 1 = 0.509131 loss)
I0624 17:05:05.304972 21347 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0624 17:05:05.892794 21347 solver.cpp:337] Iteration 900, Testing net (#0)
I0624 17:05:05.994649 21347 solver.cpp:404]     Test net output #0: accuracy = 0.75
I0624 17:05:05.994680 21347 solver.cpp:404]     Test net output #1: loss = 0.556966 (* 1 = 0.556966 loss)
I0624 17:05:06.005416 21347 solver.cpp:228] Iteration 900, loss = 0.472424
I0624 17:05:06.005439 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:05:06.005445 21347 solver.cpp:244]     Train net output #1: loss = 0.472424 (* 1 = 0.472424 loss)
I0624 17:05:06.005450 21347 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0624 17:05:06.606631 21347 solver.cpp:228] Iteration 920, loss = 0.635987
I0624 17:05:06.606657 21347 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 17:05:06.606664 21347 solver.cpp:244]     Train net output #1: loss = 0.635987 (* 1 = 0.635987 loss)
I0624 17:05:06.606669 21347 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0624 17:05:07.204912 21347 solver.cpp:228] Iteration 940, loss = 0.473729
I0624 17:05:07.205086 21347 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:05:07.205097 21347 solver.cpp:244]     Train net output #1: loss = 0.473729 (* 1 = 0.473729 loss)
I0624 17:05:07.205101 21347 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0624 17:05:07.803264 21347 solver.cpp:228] Iteration 960, loss = 0.423235
I0624 17:05:07.803299 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:05:07.803306 21347 solver.cpp:244]     Train net output #1: loss = 0.423235 (* 1 = 0.423235 loss)
I0624 17:05:07.803310 21347 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0624 17:05:08.401365 21347 solver.cpp:228] Iteration 980, loss = 0.701067
I0624 17:05:08.401391 21347 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:05:08.401397 21347 solver.cpp:244]     Train net output #1: loss = 0.701067 (* 1 = 0.701067 loss)
I0624 17:05:08.401401 21347 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0624 17:05:08.989466 21347 solver.cpp:454] Snapshotting to binary proto file data/models/bpgnet_iter_1000.caffemodel
I0624 17:05:08.992106 21347 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpgnet_iter_1000.solverstate
I0624 17:05:08.993191 21347 solver.cpp:337] Iteration 1000, Testing net (#0)
I0624 17:05:09.101560 21347 solver.cpp:404]     Test net output #0: accuracy = 0.804688
I0624 17:05:09.101598 21347 solver.cpp:404]     Test net output #1: loss = 0.455729 (* 1 = 0.455729 loss)
I0624 17:05:09.112378 21347 solver.cpp:228] Iteration 1000, loss = 0.416927
I0624 17:05:09.112402 21347 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:05:09.112412 21347 solver.cpp:244]     Train net output #1: loss = 0.416926 (* 1 = 0.416926 loss)
I0624 17:05:09.112419 21347 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0624 17:05:09.713425 21347 solver.cpp:228] Iteration 1020, loss = 0.71973
I0624 17:05:09.713454 21347 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0624 17:05:09.713464 21347 solver.cpp:244]     Train net output #1: loss = 0.71973 (* 1 = 0.71973 loss)
I0624 17:05:09.713470 21347 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0624 17:05:10.312964 21347 solver.cpp:228] Iteration 1040, loss = 0.448866
I0624 17:05:10.312990 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:05:10.313000 21347 solver.cpp:244]     Train net output #1: loss = 0.448866 (* 1 = 0.448866 loss)
I0624 17:05:10.313007 21347 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0624 17:05:10.910863 21347 solver.cpp:228] Iteration 1060, loss = 0.478663
I0624 17:05:10.910900 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:05:10.910910 21347 solver.cpp:244]     Train net output #1: loss = 0.478663 (* 1 = 0.478663 loss)
I0624 17:05:10.910917 21347 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0624 17:05:11.509588 21347 solver.cpp:228] Iteration 1080, loss = 0.514816
I0624 17:05:11.509626 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:05:11.509636 21347 solver.cpp:244]     Train net output #1: loss = 0.514815 (* 1 = 0.514815 loss)
I0624 17:05:11.509644 21347 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0624 17:05:12.098013 21347 solver.cpp:337] Iteration 1100, Testing net (#0)
I0624 17:05:12.205196 21347 solver.cpp:404]     Test net output #0: accuracy = 0.78125
I0624 17:05:12.205226 21347 solver.cpp:404]     Test net output #1: loss = 0.46922 (* 1 = 0.46922 loss)
I0624 17:05:12.216009 21347 solver.cpp:228] Iteration 1100, loss = 0.385322
I0624 17:05:12.216032 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:05:12.216042 21347 solver.cpp:244]     Train net output #1: loss = 0.385322 (* 1 = 0.385322 loss)
I0624 17:05:12.216049 21347 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0624 17:05:12.816804 21347 solver.cpp:228] Iteration 1120, loss = 0.548341
I0624 17:05:12.816833 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:05:12.816843 21347 solver.cpp:244]     Train net output #1: loss = 0.548341 (* 1 = 0.548341 loss)
I0624 17:05:12.816848 21347 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0624 17:05:13.415086 21347 solver.cpp:228] Iteration 1140, loss = 0.326502
I0624 17:05:13.415123 21347 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:05:13.415130 21347 solver.cpp:244]     Train net output #1: loss = 0.326502 (* 1 = 0.326502 loss)
I0624 17:05:13.415134 21347 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0624 17:05:14.014370 21347 solver.cpp:228] Iteration 1160, loss = 0.494706
I0624 17:05:14.014397 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:05:14.014405 21347 solver.cpp:244]     Train net output #1: loss = 0.494706 (* 1 = 0.494706 loss)
I0624 17:05:14.014408 21347 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0624 17:05:14.613662 21347 solver.cpp:228] Iteration 1180, loss = 0.438621
I0624 17:05:14.613689 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:05:14.613698 21347 solver.cpp:244]     Train net output #1: loss = 0.438621 (* 1 = 0.438621 loss)
I0624 17:05:14.613701 21347 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0624 17:05:15.203657 21347 solver.cpp:337] Iteration 1200, Testing net (#0)
I0624 17:05:15.290258 21347 solver.cpp:404]     Test net output #0: accuracy = 0.796875
I0624 17:05:15.290287 21347 solver.cpp:404]     Test net output #1: loss = 0.425005 (* 1 = 0.425005 loss)
I0624 17:05:15.301075 21347 solver.cpp:228] Iteration 1200, loss = 0.311875
I0624 17:05:15.301096 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:05:15.301103 21347 solver.cpp:244]     Train net output #1: loss = 0.311874 (* 1 = 0.311874 loss)
I0624 17:05:15.301107 21347 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0624 17:05:15.901895 21347 solver.cpp:228] Iteration 1220, loss = 0.319755
I0624 17:05:15.901922 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:05:15.901931 21347 solver.cpp:244]     Train net output #1: loss = 0.319755 (* 1 = 0.319755 loss)
I0624 17:05:15.901934 21347 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0624 17:05:16.498821 21347 solver.cpp:228] Iteration 1240, loss = 0.253681
I0624 17:05:16.498847 21347 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:05:16.498855 21347 solver.cpp:244]     Train net output #1: loss = 0.253681 (* 1 = 0.253681 loss)
I0624 17:05:16.498859 21347 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0624 17:05:17.097534 21347 solver.cpp:228] Iteration 1260, loss = 0.504094
I0624 17:05:17.097563 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:05:17.097571 21347 solver.cpp:244]     Train net output #1: loss = 0.504094 (* 1 = 0.504094 loss)
I0624 17:05:17.097575 21347 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0624 17:05:17.700289 21347 solver.cpp:228] Iteration 1280, loss = 0.612458
I0624 17:05:17.700326 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:05:17.700333 21347 solver.cpp:244]     Train net output #1: loss = 0.612458 (* 1 = 0.612458 loss)
I0624 17:05:17.700338 21347 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0624 17:05:18.288789 21347 solver.cpp:337] Iteration 1300, Testing net (#0)
I0624 17:05:18.397536 21347 solver.cpp:404]     Test net output #0: accuracy = 0.8125
I0624 17:05:18.397565 21347 solver.cpp:404]     Test net output #1: loss = 0.455503 (* 1 = 0.455503 loss)
I0624 17:05:18.408347 21347 solver.cpp:228] Iteration 1300, loss = 0.403532
I0624 17:05:18.408370 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:05:18.408377 21347 solver.cpp:244]     Train net output #1: loss = 0.403532 (* 1 = 0.403532 loss)
I0624 17:05:18.408382 21347 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0624 17:05:19.009115 21347 solver.cpp:228] Iteration 1320, loss = 0.342938
I0624 17:05:19.009152 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:05:19.009160 21347 solver.cpp:244]     Train net output #1: loss = 0.342938 (* 1 = 0.342938 loss)
I0624 17:05:19.009165 21347 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0624 17:05:19.608536 21347 solver.cpp:228] Iteration 1340, loss = 0.492574
I0624 17:05:19.608593 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:05:19.608602 21347 solver.cpp:244]     Train net output #1: loss = 0.492574 (* 1 = 0.492574 loss)
I0624 17:05:19.608606 21347 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0624 17:05:20.207080 21347 solver.cpp:228] Iteration 1360, loss = 0.349336
I0624 17:05:20.207106 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:05:20.207113 21347 solver.cpp:244]     Train net output #1: loss = 0.349336 (* 1 = 0.349336 loss)
I0624 17:05:20.207118 21347 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0624 17:05:20.806169 21347 solver.cpp:228] Iteration 1380, loss = 0.349687
I0624 17:05:20.806195 21347 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:05:20.806203 21347 solver.cpp:244]     Train net output #1: loss = 0.349687 (* 1 = 0.349687 loss)
I0624 17:05:20.806206 21347 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0624 17:05:21.395429 21347 solver.cpp:337] Iteration 1400, Testing net (#0)
I0624 17:05:21.506695 21347 solver.cpp:404]     Test net output #0: accuracy = 0.71875
I0624 17:05:21.506732 21347 solver.cpp:404]     Test net output #1: loss = 0.554098 (* 1 = 0.554098 loss)
I0624 17:05:21.517575 21347 solver.cpp:228] Iteration 1400, loss = 0.403021
I0624 17:05:21.517602 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:05:21.517609 21347 solver.cpp:244]     Train net output #1: loss = 0.403021 (* 1 = 0.403021 loss)
I0624 17:05:21.517614 21347 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0624 17:05:22.117888 21347 solver.cpp:228] Iteration 1420, loss = 0.314652
I0624 17:05:22.117913 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:05:22.117920 21347 solver.cpp:244]     Train net output #1: loss = 0.314652 (* 1 = 0.314652 loss)
I0624 17:05:22.117924 21347 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0624 17:05:22.716374 21347 solver.cpp:228] Iteration 1440, loss = 0.225229
I0624 17:05:22.716403 21347 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:05:22.716409 21347 solver.cpp:244]     Train net output #1: loss = 0.225229 (* 1 = 0.225229 loss)
I0624 17:05:22.716413 21347 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0624 17:05:23.314113 21347 solver.cpp:228] Iteration 1460, loss = 0.384655
I0624 17:05:23.314141 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:05:23.314147 21347 solver.cpp:244]     Train net output #1: loss = 0.384655 (* 1 = 0.384655 loss)
I0624 17:05:23.314152 21347 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0624 17:05:23.912803 21347 solver.cpp:228] Iteration 1480, loss = 0.30155
I0624 17:05:23.912830 21347 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:05:23.912848 21347 solver.cpp:244]     Train net output #1: loss = 0.30155 (* 1 = 0.30155 loss)
I0624 17:05:23.912853 21347 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0624 17:05:24.500707 21347 solver.cpp:454] Snapshotting to binary proto file data/models/bpgnet_iter_1500.caffemodel
I0624 17:05:24.503304 21347 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpgnet_iter_1500.solverstate
I0624 17:05:24.504376 21347 solver.cpp:337] Iteration 1500, Testing net (#0)
I0624 17:05:24.605316 21347 solver.cpp:404]     Test net output #0: accuracy = 0.75
I0624 17:05:24.605343 21347 solver.cpp:404]     Test net output #1: loss = 0.487681 (* 1 = 0.487681 loss)
I0624 17:05:24.616199 21347 solver.cpp:228] Iteration 1500, loss = 0.333925
I0624 17:05:24.616224 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:05:24.616231 21347 solver.cpp:244]     Train net output #1: loss = 0.333925 (* 1 = 0.333925 loss)
I0624 17:05:24.616236 21347 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0624 17:05:25.217463 21347 solver.cpp:228] Iteration 1520, loss = 0.418991
I0624 17:05:25.217488 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:05:25.217495 21347 solver.cpp:244]     Train net output #1: loss = 0.418991 (* 1 = 0.418991 loss)
I0624 17:05:25.217499 21347 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0624 17:05:25.817196 21347 solver.cpp:228] Iteration 1540, loss = 0.656911
I0624 17:05:25.817232 21347 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:05:25.817239 21347 solver.cpp:244]     Train net output #1: loss = 0.656911 (* 1 = 0.656911 loss)
I0624 17:05:25.817242 21347 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0624 17:05:26.416728 21347 solver.cpp:228] Iteration 1560, loss = 0.314657
I0624 17:05:26.416764 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:05:26.416771 21347 solver.cpp:244]     Train net output #1: loss = 0.314657 (* 1 = 0.314657 loss)
I0624 17:05:26.416776 21347 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0624 17:05:27.016341 21347 solver.cpp:228] Iteration 1580, loss = 0.258518
I0624 17:05:27.016367 21347 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:05:27.016374 21347 solver.cpp:244]     Train net output #1: loss = 0.258518 (* 1 = 0.258518 loss)
I0624 17:05:27.016378 21347 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0624 17:05:27.604652 21347 solver.cpp:337] Iteration 1600, Testing net (#0)
I0624 17:05:27.711886 21347 solver.cpp:404]     Test net output #0: accuracy = 0.84375
I0624 17:05:27.711915 21347 solver.cpp:404]     Test net output #1: loss = 0.376008 (* 1 = 0.376008 loss)
I0624 17:05:27.722695 21347 solver.cpp:228] Iteration 1600, loss = 0.425209
I0624 17:05:27.722718 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:05:27.722725 21347 solver.cpp:244]     Train net output #1: loss = 0.425209 (* 1 = 0.425209 loss)
I0624 17:05:27.722729 21347 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0624 17:05:28.321517 21347 solver.cpp:228] Iteration 1620, loss = 0.239282
I0624 17:05:28.321554 21347 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:05:28.321562 21347 solver.cpp:244]     Train net output #1: loss = 0.239282 (* 1 = 0.239282 loss)
I0624 17:05:28.321566 21347 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0624 17:05:28.920581 21347 solver.cpp:228] Iteration 1640, loss = 0.522343
I0624 17:05:28.920608 21347 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 17:05:28.920615 21347 solver.cpp:244]     Train net output #1: loss = 0.522343 (* 1 = 0.522343 loss)
I0624 17:05:28.920619 21347 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0624 17:05:29.521411 21347 solver.cpp:228] Iteration 1660, loss = 0.599017
I0624 17:05:29.521436 21347 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 17:05:29.521443 21347 solver.cpp:244]     Train net output #1: loss = 0.599017 (* 1 = 0.599017 loss)
I0624 17:05:29.521447 21347 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0624 17:05:30.122061 21347 solver.cpp:228] Iteration 1680, loss = 0.6102
I0624 17:05:30.122107 21347 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:05:30.122113 21347 solver.cpp:244]     Train net output #1: loss = 0.6102 (* 1 = 0.6102 loss)
I0624 17:05:30.122117 21347 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0624 17:05:30.712546 21347 solver.cpp:337] Iteration 1700, Testing net (#0)
I0624 17:05:30.793505 21347 solver.cpp:404]     Test net output #0: accuracy = 0.75
I0624 17:05:30.793536 21347 solver.cpp:404]     Test net output #1: loss = 0.488942 (* 1 = 0.488942 loss)
I0624 17:05:30.804426 21347 solver.cpp:228] Iteration 1700, loss = 0.433433
I0624 17:05:30.804451 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:05:30.804458 21347 solver.cpp:244]     Train net output #1: loss = 0.433433 (* 1 = 0.433433 loss)
I0624 17:05:30.804463 21347 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0624 17:05:31.405467 21347 solver.cpp:228] Iteration 1720, loss = 0.446028
I0624 17:05:31.405503 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:05:31.405520 21347 solver.cpp:244]     Train net output #1: loss = 0.446028 (* 1 = 0.446028 loss)
I0624 17:05:31.405524 21347 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0624 17:05:32.005869 21347 solver.cpp:228] Iteration 1740, loss = 0.500794
I0624 17:05:32.005916 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:05:32.005924 21347 solver.cpp:244]     Train net output #1: loss = 0.500794 (* 1 = 0.500794 loss)
I0624 17:05:32.005929 21347 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0624 17:05:32.606215 21347 solver.cpp:228] Iteration 1760, loss = 0.450558
I0624 17:05:32.606241 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:05:32.606248 21347 solver.cpp:244]     Train net output #1: loss = 0.450558 (* 1 = 0.450558 loss)
I0624 17:05:32.606252 21347 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0624 17:05:33.204977 21347 solver.cpp:228] Iteration 1780, loss = 0.307439
I0624 17:05:33.205003 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:05:33.205011 21347 solver.cpp:244]     Train net output #1: loss = 0.307439 (* 1 = 0.307439 loss)
I0624 17:05:33.205015 21347 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0624 17:05:33.794991 21347 solver.cpp:337] Iteration 1800, Testing net (#0)
I0624 17:05:33.871526 21347 solver.cpp:404]     Test net output #0: accuracy = 0.8125
I0624 17:05:33.871556 21347 solver.cpp:404]     Test net output #1: loss = 0.438106 (* 1 = 0.438106 loss)
I0624 17:05:33.882695 21347 solver.cpp:228] Iteration 1800, loss = 0.801485
I0624 17:05:33.882725 21347 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0624 17:05:33.882731 21347 solver.cpp:244]     Train net output #1: loss = 0.801485 (* 1 = 0.801485 loss)
I0624 17:05:33.882737 21347 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0624 17:05:34.483922 21347 solver.cpp:228] Iteration 1820, loss = 0.379512
I0624 17:05:34.483957 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:05:34.483964 21347 solver.cpp:244]     Train net output #1: loss = 0.379512 (* 1 = 0.379512 loss)
I0624 17:05:34.483968 21347 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0624 17:05:35.084882 21347 solver.cpp:228] Iteration 1840, loss = 0.465674
I0624 17:05:35.084930 21347 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 17:05:35.084938 21347 solver.cpp:244]     Train net output #1: loss = 0.465674 (* 1 = 0.465674 loss)
I0624 17:05:35.084942 21347 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0624 17:05:35.684957 21347 solver.cpp:228] Iteration 1860, loss = 0.683167
I0624 17:05:35.684983 21347 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0624 17:05:35.684990 21347 solver.cpp:244]     Train net output #1: loss = 0.683167 (* 1 = 0.683167 loss)
I0624 17:05:35.684994 21347 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0624 17:05:36.284437 21347 solver.cpp:228] Iteration 1880, loss = 0.415975
I0624 17:05:36.284462 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:05:36.284469 21347 solver.cpp:244]     Train net output #1: loss = 0.415975 (* 1 = 0.415975 loss)
I0624 17:05:36.284473 21347 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0624 17:05:36.876102 21347 solver.cpp:337] Iteration 1900, Testing net (#0)
I0624 17:05:36.964128 21347 solver.cpp:404]     Test net output #0: accuracy = 0.75
I0624 17:05:36.964156 21347 solver.cpp:404]     Test net output #1: loss = 0.511597 (* 1 = 0.511597 loss)
I0624 17:05:36.974990 21347 solver.cpp:228] Iteration 1900, loss = 0.616295
I0624 17:05:36.975014 21347 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 17:05:36.975021 21347 solver.cpp:244]     Train net output #1: loss = 0.616295 (* 1 = 0.616295 loss)
I0624 17:05:36.975026 21347 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0624 17:05:37.568801 21347 solver.cpp:228] Iteration 1920, loss = 0.375991
I0624 17:05:37.568969 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:05:37.568979 21347 solver.cpp:244]     Train net output #1: loss = 0.375991 (* 1 = 0.375991 loss)
I0624 17:05:37.568984 21347 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0624 17:05:38.169369 21347 solver.cpp:228] Iteration 1940, loss = 0.258136
I0624 17:05:38.169396 21347 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:05:38.169404 21347 solver.cpp:244]     Train net output #1: loss = 0.258136 (* 1 = 0.258136 loss)
I0624 17:05:38.169409 21347 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0624 17:05:38.769047 21347 solver.cpp:228] Iteration 1960, loss = 0.345417
I0624 17:05:38.769083 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:05:38.769089 21347 solver.cpp:244]     Train net output #1: loss = 0.345417 (* 1 = 0.345417 loss)
I0624 17:05:38.769093 21347 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0624 17:05:39.370151 21347 solver.cpp:228] Iteration 1980, loss = 0.510558
I0624 17:05:39.370177 21347 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:05:39.370184 21347 solver.cpp:244]     Train net output #1: loss = 0.510558 (* 1 = 0.510558 loss)
I0624 17:05:39.370188 21347 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0624 17:05:39.959717 21347 solver.cpp:454] Snapshotting to binary proto file data/models/bpgnet_iter_2000.caffemodel
I0624 17:05:39.962302 21347 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpgnet_iter_2000.solverstate
I0624 17:05:39.963418 21347 solver.cpp:337] Iteration 2000, Testing net (#0)
I0624 17:05:40.041347 21347 solver.cpp:404]     Test net output #0: accuracy = 0.757812
I0624 17:05:40.041385 21347 solver.cpp:404]     Test net output #1: loss = 0.532455 (* 1 = 0.532455 loss)
I0624 17:05:40.052561 21347 solver.cpp:228] Iteration 2000, loss = 0.222568
I0624 17:05:40.052584 21347 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:05:40.052592 21347 solver.cpp:244]     Train net output #1: loss = 0.222568 (* 1 = 0.222568 loss)
I0624 17:05:40.052597 21347 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0624 17:05:40.651926 21347 solver.cpp:228] Iteration 2020, loss = 0.483982
I0624 17:05:40.651952 21347 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:05:40.651959 21347 solver.cpp:244]     Train net output #1: loss = 0.483982 (* 1 = 0.483982 loss)
I0624 17:05:40.651963 21347 sgd_solver.cpp:106] Iteration 2020, lr = 0.0001
I0624 17:05:41.251912 21347 solver.cpp:228] Iteration 2040, loss = 0.53453
I0624 17:05:41.251938 21347 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 17:05:41.251946 21347 solver.cpp:244]     Train net output #1: loss = 0.53453 (* 1 = 0.53453 loss)
I0624 17:05:41.251950 21347 sgd_solver.cpp:106] Iteration 2040, lr = 0.0001
I0624 17:05:41.851275 21347 solver.cpp:228] Iteration 2060, loss = 0.814853
I0624 17:05:41.851312 21347 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0624 17:05:41.851320 21347 solver.cpp:244]     Train net output #1: loss = 0.814853 (* 1 = 0.814853 loss)
I0624 17:05:41.851325 21347 sgd_solver.cpp:106] Iteration 2060, lr = 0.0001
I0624 17:05:42.451951 21347 solver.cpp:228] Iteration 2080, loss = 0.302038
I0624 17:05:42.451977 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:05:42.451994 21347 solver.cpp:244]     Train net output #1: loss = 0.302038 (* 1 = 0.302038 loss)
I0624 17:05:42.451998 21347 sgd_solver.cpp:106] Iteration 2080, lr = 0.0001
I0624 17:05:43.041275 21347 solver.cpp:337] Iteration 2100, Testing net (#0)
I0624 17:05:43.119048 21347 solver.cpp:404]     Test net output #0: accuracy = 0.851562
I0624 17:05:43.119078 21347 solver.cpp:404]     Test net output #1: loss = 0.37998 (* 1 = 0.37998 loss)
I0624 17:05:43.129781 21347 solver.cpp:228] Iteration 2100, loss = 0.204498
I0624 17:05:43.129808 21347 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:05:43.129818 21347 solver.cpp:244]     Train net output #1: loss = 0.204498 (* 1 = 0.204498 loss)
I0624 17:05:43.129823 21347 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0624 17:05:43.734581 21347 solver.cpp:228] Iteration 2120, loss = 0.423528
I0624 17:05:43.734606 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:05:43.734614 21347 solver.cpp:244]     Train net output #1: loss = 0.423528 (* 1 = 0.423528 loss)
I0624 17:05:43.734618 21347 sgd_solver.cpp:106] Iteration 2120, lr = 0.0001
I0624 17:05:44.333895 21347 solver.cpp:228] Iteration 2140, loss = 0.58385
I0624 17:05:44.333921 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:05:44.333928 21347 solver.cpp:244]     Train net output #1: loss = 0.58385 (* 1 = 0.58385 loss)
I0624 17:05:44.333932 21347 sgd_solver.cpp:106] Iteration 2140, lr = 0.0001
I0624 17:05:44.932981 21347 solver.cpp:228] Iteration 2160, loss = 0.235425
I0624 17:05:44.933008 21347 solver.cpp:244]     Train net output #0: accuracy = 1
I0624 17:05:44.933015 21347 solver.cpp:244]     Train net output #1: loss = 0.235425 (* 1 = 0.235425 loss)
I0624 17:05:44.933019 21347 sgd_solver.cpp:106] Iteration 2160, lr = 0.0001
I0624 17:05:45.532366 21347 solver.cpp:228] Iteration 2180, loss = 0.292479
I0624 17:05:45.532392 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:05:45.532398 21347 solver.cpp:244]     Train net output #1: loss = 0.292479 (* 1 = 0.292479 loss)
I0624 17:05:45.532402 21347 sgd_solver.cpp:106] Iteration 2180, lr = 0.0001
I0624 17:05:46.121860 21347 solver.cpp:337] Iteration 2200, Testing net (#0)
I0624 17:05:46.198873 21347 solver.cpp:404]     Test net output #0: accuracy = 0.78125
I0624 17:05:46.198912 21347 solver.cpp:404]     Test net output #1: loss = 0.449106 (* 1 = 0.449106 loss)
I0624 17:05:46.210062 21347 solver.cpp:228] Iteration 2200, loss = 0.387698
I0624 17:05:46.210088 21347 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:05:46.210096 21347 solver.cpp:244]     Train net output #1: loss = 0.387698 (* 1 = 0.387698 loss)
I0624 17:05:46.210103 21347 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0624 17:05:46.809198 21347 solver.cpp:228] Iteration 2220, loss = 0.351879
I0624 17:05:46.809224 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:05:46.809231 21347 solver.cpp:244]     Train net output #1: loss = 0.351879 (* 1 = 0.351879 loss)
I0624 17:05:46.809237 21347 sgd_solver.cpp:106] Iteration 2220, lr = 0.0001
I0624 17:05:47.409895 21347 solver.cpp:228] Iteration 2240, loss = 0.457445
I0624 17:05:47.409920 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:05:47.409927 21347 solver.cpp:244]     Train net output #1: loss = 0.457445 (* 1 = 0.457445 loss)
I0624 17:05:47.409931 21347 sgd_solver.cpp:106] Iteration 2240, lr = 0.0001
I0624 17:05:48.009868 21347 solver.cpp:228] Iteration 2260, loss = 0.428457
I0624 17:05:48.009903 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:05:48.009910 21347 solver.cpp:244]     Train net output #1: loss = 0.428457 (* 1 = 0.428457 loss)
I0624 17:05:48.009914 21347 sgd_solver.cpp:106] Iteration 2260, lr = 0.0001
I0624 17:05:48.610301 21347 solver.cpp:228] Iteration 2280, loss = 0.288951
I0624 17:05:48.610338 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:05:48.610345 21347 solver.cpp:244]     Train net output #1: loss = 0.288951 (* 1 = 0.288951 loss)
I0624 17:05:48.610348 21347 sgd_solver.cpp:106] Iteration 2280, lr = 0.0001
I0624 17:05:49.201606 21347 solver.cpp:337] Iteration 2300, Testing net (#0)
I0624 17:05:49.304656 21347 solver.cpp:404]     Test net output #0: accuracy = 0.789062
I0624 17:05:49.304684 21347 solver.cpp:404]     Test net output #1: loss = 0.425795 (* 1 = 0.425795 loss)
I0624 17:05:49.315469 21347 solver.cpp:228] Iteration 2300, loss = 0.675461
I0624 17:05:49.315492 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:05:49.315500 21347 solver.cpp:244]     Train net output #1: loss = 0.675461 (* 1 = 0.675461 loss)
I0624 17:05:49.315505 21347 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0624 17:05:49.916894 21347 solver.cpp:228] Iteration 2320, loss = 0.367796
I0624 17:05:49.916951 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:05:49.916959 21347 solver.cpp:244]     Train net output #1: loss = 0.367796 (* 1 = 0.367796 loss)
I0624 17:05:49.916962 21347 sgd_solver.cpp:106] Iteration 2320, lr = 0.0001
I0624 17:05:50.516948 21347 solver.cpp:228] Iteration 2340, loss = 0.304592
I0624 17:05:50.516974 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:05:50.516993 21347 solver.cpp:244]     Train net output #1: loss = 0.304592 (* 1 = 0.304592 loss)
I0624 17:05:50.516996 21347 sgd_solver.cpp:106] Iteration 2340, lr = 0.0001
I0624 17:05:51.117373 21347 solver.cpp:228] Iteration 2360, loss = 0.49325
I0624 17:05:51.117408 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:05:51.117415 21347 solver.cpp:244]     Train net output #1: loss = 0.49325 (* 1 = 0.49325 loss)
I0624 17:05:51.117420 21347 sgd_solver.cpp:106] Iteration 2360, lr = 0.0001
I0624 17:05:51.717640 21347 solver.cpp:228] Iteration 2380, loss = 0.430762
I0624 17:05:51.717667 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:05:51.717674 21347 solver.cpp:244]     Train net output #1: loss = 0.430762 (* 1 = 0.430762 loss)
I0624 17:05:51.717679 21347 sgd_solver.cpp:106] Iteration 2380, lr = 0.0001
I0624 17:05:52.308418 21347 solver.cpp:337] Iteration 2400, Testing net (#0)
I0624 17:05:52.410363 21347 solver.cpp:404]     Test net output #0: accuracy = 0.789062
I0624 17:05:52.410392 21347 solver.cpp:404]     Test net output #1: loss = 0.46923 (* 1 = 0.46923 loss)
I0624 17:05:52.421145 21347 solver.cpp:228] Iteration 2400, loss = 0.21515
I0624 17:05:52.421169 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:05:52.421175 21347 solver.cpp:244]     Train net output #1: loss = 0.21515 (* 1 = 0.21515 loss)
I0624 17:05:52.421180 21347 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0624 17:05:53.022001 21347 solver.cpp:228] Iteration 2420, loss = 0.232797
I0624 17:05:53.022038 21347 solver.cpp:244]     Train net output #0: accuracy = 1
I0624 17:05:53.022045 21347 solver.cpp:244]     Train net output #1: loss = 0.232797 (* 1 = 0.232797 loss)
I0624 17:05:53.022050 21347 sgd_solver.cpp:106] Iteration 2420, lr = 0.0001
I0624 17:05:53.622542 21347 solver.cpp:228] Iteration 2440, loss = 0.355338
I0624 17:05:53.622581 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:05:53.622587 21347 solver.cpp:244]     Train net output #1: loss = 0.355338 (* 1 = 0.355338 loss)
I0624 17:05:53.622591 21347 sgd_solver.cpp:106] Iteration 2440, lr = 0.0001
I0624 17:05:54.218700 21347 solver.cpp:228] Iteration 2460, loss = 0.281523
I0624 17:05:54.218734 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:05:54.218742 21347 solver.cpp:244]     Train net output #1: loss = 0.281523 (* 1 = 0.281523 loss)
I0624 17:05:54.218746 21347 sgd_solver.cpp:106] Iteration 2460, lr = 0.0001
I0624 17:05:54.819144 21347 solver.cpp:228] Iteration 2480, loss = 0.360879
I0624 17:05:54.819175 21347 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:05:54.819181 21347 solver.cpp:244]     Train net output #1: loss = 0.360879 (* 1 = 0.360879 loss)
I0624 17:05:54.819186 21347 sgd_solver.cpp:106] Iteration 2480, lr = 0.0001
I0624 17:05:55.406827 21347 solver.cpp:454] Snapshotting to binary proto file data/models/bpgnet_iter_2500.caffemodel
I0624 17:05:55.409402 21347 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpgnet_iter_2500.solverstate
I0624 17:05:55.410486 21347 solver.cpp:337] Iteration 2500, Testing net (#0)
I0624 17:05:55.521893 21347 solver.cpp:404]     Test net output #0: accuracy = 0.679688
I0624 17:05:55.521932 21347 solver.cpp:404]     Test net output #1: loss = 0.573089 (* 1 = 0.573089 loss)
I0624 17:05:55.532745 21347 solver.cpp:228] Iteration 2500, loss = 0.323371
I0624 17:05:55.532769 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:05:55.532778 21347 solver.cpp:244]     Train net output #1: loss = 0.323371 (* 1 = 0.323371 loss)
I0624 17:05:55.532804 21347 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0624 17:05:56.133448 21347 solver.cpp:228] Iteration 2520, loss = 0.362896
I0624 17:05:56.133474 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:05:56.133482 21347 solver.cpp:244]     Train net output #1: loss = 0.362896 (* 1 = 0.362896 loss)
I0624 17:05:56.133486 21347 sgd_solver.cpp:106] Iteration 2520, lr = 0.0001
I0624 17:05:56.731010 21347 solver.cpp:228] Iteration 2540, loss = 0.177974
I0624 17:05:56.731037 21347 solver.cpp:244]     Train net output #0: accuracy = 1
I0624 17:05:56.731045 21347 solver.cpp:244]     Train net output #1: loss = 0.177974 (* 1 = 0.177974 loss)
I0624 17:05:56.731048 21347 sgd_solver.cpp:106] Iteration 2540, lr = 0.0001
I0624 17:05:57.331094 21347 solver.cpp:228] Iteration 2560, loss = 0.604354
I0624 17:05:57.331120 21347 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 17:05:57.331138 21347 solver.cpp:244]     Train net output #1: loss = 0.604354 (* 1 = 0.604354 loss)
I0624 17:05:57.331142 21347 sgd_solver.cpp:106] Iteration 2560, lr = 0.0001
I0624 17:05:57.931990 21347 solver.cpp:228] Iteration 2580, loss = 0.380395
I0624 17:05:57.932016 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:05:57.932024 21347 solver.cpp:244]     Train net output #1: loss = 0.380395 (* 1 = 0.380395 loss)
I0624 17:05:57.932029 21347 sgd_solver.cpp:106] Iteration 2580, lr = 0.0001
I0624 17:05:58.523134 21347 solver.cpp:337] Iteration 2600, Testing net (#0)
I0624 17:05:58.599007 21347 solver.cpp:404]     Test net output #0: accuracy = 0.773438
I0624 17:05:58.599036 21347 solver.cpp:404]     Test net output #1: loss = 0.454108 (* 1 = 0.454108 loss)
I0624 17:05:58.610141 21347 solver.cpp:228] Iteration 2600, loss = 0.443055
I0624 17:05:58.610167 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:05:58.610174 21347 solver.cpp:244]     Train net output #1: loss = 0.443055 (* 1 = 0.443055 loss)
I0624 17:05:58.610179 21347 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0624 17:05:59.213485 21347 solver.cpp:228] Iteration 2620, loss = 0.484673
I0624 17:05:59.213512 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:05:59.213520 21347 solver.cpp:244]     Train net output #1: loss = 0.484673 (* 1 = 0.484673 loss)
I0624 17:05:59.213524 21347 sgd_solver.cpp:106] Iteration 2620, lr = 0.0001
I0624 17:05:59.816541 21347 solver.cpp:228] Iteration 2640, loss = 0.297292
I0624 17:05:59.816567 21347 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:05:59.816586 21347 solver.cpp:244]     Train net output #1: loss = 0.297292 (* 1 = 0.297292 loss)
I0624 17:05:59.816589 21347 sgd_solver.cpp:106] Iteration 2640, lr = 0.0001
I0624 17:06:00.417958 21347 solver.cpp:228] Iteration 2660, loss = 0.543682
I0624 17:06:00.417994 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:06:00.418001 21347 solver.cpp:244]     Train net output #1: loss = 0.543682 (* 1 = 0.543682 loss)
I0624 17:06:00.418005 21347 sgd_solver.cpp:106] Iteration 2660, lr = 0.0001
I0624 17:06:01.018183 21347 solver.cpp:228] Iteration 2680, loss = 0.532444
I0624 17:06:01.018211 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:06:01.018218 21347 solver.cpp:244]     Train net output #1: loss = 0.532444 (* 1 = 0.532444 loss)
I0624 17:06:01.018223 21347 sgd_solver.cpp:106] Iteration 2680, lr = 0.0001
I0624 17:06:01.609009 21347 solver.cpp:337] Iteration 2700, Testing net (#0)
I0624 17:06:01.715718 21347 solver.cpp:404]     Test net output #0: accuracy = 0.828125
I0624 17:06:01.715749 21347 solver.cpp:404]     Test net output #1: loss = 0.369412 (* 1 = 0.369412 loss)
I0624 17:06:01.726512 21347 solver.cpp:228] Iteration 2700, loss = 0.328511
I0624 17:06:01.726534 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:06:01.726542 21347 solver.cpp:244]     Train net output #1: loss = 0.328511 (* 1 = 0.328511 loss)
I0624 17:06:01.726547 21347 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0624 17:06:02.328804 21347 solver.cpp:228] Iteration 2720, loss = 0.413144
I0624 17:06:02.328855 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:06:02.328863 21347 solver.cpp:244]     Train net output #1: loss = 0.413144 (* 1 = 0.413144 loss)
I0624 17:06:02.328868 21347 sgd_solver.cpp:106] Iteration 2720, lr = 0.0001
I0624 17:06:02.927606 21347 solver.cpp:228] Iteration 2740, loss = 0.440963
I0624 17:06:02.927635 21347 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:06:02.927642 21347 solver.cpp:244]     Train net output #1: loss = 0.440963 (* 1 = 0.440963 loss)
I0624 17:06:02.927647 21347 sgd_solver.cpp:106] Iteration 2740, lr = 0.0001
I0624 17:06:03.527217 21347 solver.cpp:228] Iteration 2760, loss = 0.350863
I0624 17:06:03.527253 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:06:03.527261 21347 solver.cpp:244]     Train net output #1: loss = 0.350863 (* 1 = 0.350863 loss)
I0624 17:06:03.527266 21347 sgd_solver.cpp:106] Iteration 2760, lr = 0.0001
I0624 17:06:04.127394 21347 solver.cpp:228] Iteration 2780, loss = 0.457446
I0624 17:06:04.127420 21347 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:06:04.127427 21347 solver.cpp:244]     Train net output #1: loss = 0.457446 (* 1 = 0.457446 loss)
I0624 17:06:04.127431 21347 sgd_solver.cpp:106] Iteration 2780, lr = 0.0001
I0624 17:06:04.715677 21347 solver.cpp:337] Iteration 2800, Testing net (#0)
I0624 17:06:04.794164 21347 solver.cpp:404]     Test net output #0: accuracy = 0.78125
I0624 17:06:04.794198 21347 solver.cpp:404]     Test net output #1: loss = 0.472067 (* 1 = 0.472067 loss)
I0624 17:06:04.805728 21347 solver.cpp:228] Iteration 2800, loss = 0.293281
I0624 17:06:04.805758 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:06:04.805769 21347 solver.cpp:244]     Train net output #1: loss = 0.293281 (* 1 = 0.293281 loss)
I0624 17:06:04.805775 21347 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0624 17:06:05.407693 21347 solver.cpp:228] Iteration 2820, loss = 0.521895
I0624 17:06:05.407721 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:06:05.407732 21347 solver.cpp:244]     Train net output #1: loss = 0.521895 (* 1 = 0.521895 loss)
I0624 17:06:05.407738 21347 sgd_solver.cpp:106] Iteration 2820, lr = 0.0001
I0624 17:06:06.008760 21347 solver.cpp:228] Iteration 2840, loss = 0.406138
I0624 17:06:06.008786 21347 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:06:06.008796 21347 solver.cpp:244]     Train net output #1: loss = 0.406138 (* 1 = 0.406138 loss)
I0624 17:06:06.008803 21347 sgd_solver.cpp:106] Iteration 2840, lr = 0.0001
I0624 17:06:06.607400 21347 solver.cpp:228] Iteration 2860, loss = 0.352665
I0624 17:06:06.607426 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:06:06.607435 21347 solver.cpp:244]     Train net output #1: loss = 0.352665 (* 1 = 0.352665 loss)
I0624 17:06:06.607441 21347 sgd_solver.cpp:106] Iteration 2860, lr = 0.0001
I0624 17:06:07.206895 21347 solver.cpp:228] Iteration 2880, loss = 0.313733
I0624 17:06:07.206923 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:06:07.206933 21347 solver.cpp:244]     Train net output #1: loss = 0.313733 (* 1 = 0.313733 loss)
I0624 17:06:07.206939 21347 sgd_solver.cpp:106] Iteration 2880, lr = 0.0001
I0624 17:06:07.794783 21347 solver.cpp:337] Iteration 2900, Testing net (#0)
I0624 17:06:07.900881 21347 solver.cpp:404]     Test net output #0: accuracy = 0.804688
I0624 17:06:07.900912 21347 solver.cpp:404]     Test net output #1: loss = 0.421747 (* 1 = 0.421747 loss)
I0624 17:06:07.911763 21347 solver.cpp:228] Iteration 2900, loss = 0.326048
I0624 17:06:07.911788 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:06:07.911798 21347 solver.cpp:244]     Train net output #1: loss = 0.326048 (* 1 = 0.326048 loss)
I0624 17:06:07.911805 21347 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0624 17:06:08.513440 21347 solver.cpp:228] Iteration 2920, loss = 0.206986
I0624 17:06:08.513468 21347 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:06:08.513478 21347 solver.cpp:244]     Train net output #1: loss = 0.206986 (* 1 = 0.206986 loss)
I0624 17:06:08.513484 21347 sgd_solver.cpp:106] Iteration 2920, lr = 0.0001
I0624 17:06:09.113668 21347 solver.cpp:228] Iteration 2940, loss = 0.265983
I0624 17:06:09.113695 21347 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:06:09.113705 21347 solver.cpp:244]     Train net output #1: loss = 0.265983 (* 1 = 0.265983 loss)
I0624 17:06:09.113711 21347 sgd_solver.cpp:106] Iteration 2940, lr = 0.0001
I0624 17:06:09.711701 21347 solver.cpp:228] Iteration 2960, loss = 0.294674
I0624 17:06:09.711730 21347 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:06:09.711740 21347 solver.cpp:244]     Train net output #1: loss = 0.294674 (* 1 = 0.294674 loss)
I0624 17:06:09.711746 21347 sgd_solver.cpp:106] Iteration 2960, lr = 0.0001
I0624 17:06:10.311497 21347 solver.cpp:228] Iteration 2980, loss = 0.451603
I0624 17:06:10.311527 21347 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:06:10.311537 21347 solver.cpp:244]     Train net output #1: loss = 0.451603 (* 1 = 0.451603 loss)
I0624 17:06:10.311543 21347 sgd_solver.cpp:106] Iteration 2980, lr = 0.0001
I0624 17:06:10.901172 21347 solver.cpp:454] Snapshotting to binary proto file data/models/bpgnet_iter_3000.caffemodel
I0624 17:06:10.903848 21347 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpgnet_iter_3000.solverstate
I0624 17:06:10.913888 21347 solver.cpp:317] Iteration 3000, loss = 0.251949
I0624 17:06:10.913910 21347 solver.cpp:337] Iteration 3000, Testing net (#0)
I0624 17:06:11.023669 21347 solver.cpp:404]     Test net output #0: accuracy = 0.71875
I0624 17:06:11.023699 21347 solver.cpp:404]     Test net output #1: loss = 0.551849 (* 1 = 0.551849 loss)
I0624 17:06:11.023705 21347 solver.cpp:322] Optimization Done.
I0624 17:06:11.023707 21347 caffe.cpp:222] Optimization Done.
