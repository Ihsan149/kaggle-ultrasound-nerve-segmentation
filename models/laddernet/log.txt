I0705 11:39:11.404809 14303 caffe.cpp:185] Using GPUs 1
I0705 11:39:11.420882 14303 caffe.cpp:190] GPU 1: GeForce GTX TITAN X
I0705 11:39:11.820327 14303 solver.cpp:48] Initializing solver from parameters: 
train_net: "models/laddernet/train.prototxt"
test_net: "models/laddernet/val.prototxt"
test_iter: 16
test_interval: 100
base_lr: 0.01
display: 20
max_iter: 12000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 4000
snapshot: 500
snapshot_prefix: "data/models/segnet"
solver_mode: GPU
device_id: 1
test_initialization: true
iter_size: 1
I0705 11:39:11.820446 14303 solver.cpp:81] Creating training net from train_net file: models/laddernet/train.prototxt
I0705 11:39:11.822218 14303 net.cpp:49] Initializing net from parameters: 
name: "LadderNet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    scale: 0.0039215
    mirror: true
    mean_value: 100
    crop_h: 192
    crop_w: 256
    rotation_range: 10
    scale_jitter_range: 0.1
    contrast_jitter_range: 0.3
  }
  data_param {
    source: "data/train_lmdb"
    batch_size: 16
    backend: LMDB
  }
}
layer {
  name: "noisy_data"
  type: "Noise"
  bottom: "data"
  top: "noisy_data"
  noise_param {
    sigma: 0.05
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  bottom: "noisy_data"
  top: "z1_pre"
  top: "z1_n"
  param {
    name: "conv1_w"
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "z1_pre"
  top: "z1"
  top: "bn1_param"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "z1"
  top: "h1"
  param {
    name: "scale1_w"
  }
  param {
    name: "scale1_b"
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "h1"
  top: "h1"
}
layer {
  name: "bn1_n"
  type: "BatchNorm"
  bottom: "z1_n"
  top: "z1_n"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
}
layer {
  name: "noisy_z1_n"
  type: "Noise"
  bottom: "z1_n"
  top: "z1_n"
  noise_param {
    sigma: 0.05
  }
}
layer {
  name: "scale1_n"
  type: "Scale"
  bottom: "z1_n"
  top: "h1_n"
  param {
    name: "scale1_w"
  }
  param {
    name: "scale1_b"
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_n"
  type: "ReLU"
  bottom: "h1_n"
  top: "h1_n"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "h1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "pool1_n"
  type: "Pooling"
  bottom: "h1_n"
  top: "pool1_n"
  top: "pool1_n_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  bottom: "pool1_n"
  top: "z2_pre"
  top: "z2_n"
  param {
    name: "conv2_w"
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "z2_pre"
  top: "z2"
  top: "bn2_param"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "z2"
  top: "h2"
  param {
    name: "scale2_w"
  }
  param {
    name: "scale2_b"
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "h2"
  top: "h2"
}
layer {
  name: "bn2_n"
  type: "BatchNorm"
  bottom: "z2_n"
  top: "z2_n"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
}
layer {
  name: "noisy_z2_n"
  type: "Noise"
  bottom: "z2_n"
  top: "z2_n"
  noise_param {
    sigma: 0.05
  }
}
layer {
  name: "scale2_n"
  type: "Scale"
  bottom: "z2_n"
  top: "h2_n"
  param {
    name: "scale2_w"
  }
  param {
    name: "scale2_b"
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_n"
  type: "ReLU"
  bottom: "h2_n"
  top: "h2_n"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "h2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "pool2_n"
  type: "Pooling"
  bottom: "h2_n"
  top: "pool2_n"
  top: "pool2_n_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  bottom: "pool2_n"
  top: "z3_pre"
  top: "z3_n"
  param {
    name: "conv3_w"
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "z3_pre"
  top: "z3"
  top: "bn3_param"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "z3"
  top: "h3"
  param {
    name: "scale3_w"
  }
  param {
    name: "scale3_b"
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "h3"
  top: "h3"
}
layer {
  name: "bn3_n"
  type: "BatchNorm"
  bottom: "z3_n"
  top: "z3_n"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
}
layer {
  name: "noisy_z3_n"
  type: "Noise"
  bottom: "z3_n"
  top: "z3_n"
  noise_param {
    sigma: 0.05
  }
}
layer {
  name: "scale3_n"
  type: "Scale"
  bottom: "z3_n"
  top: "h3_n"
  param {
    name: "scale3_w"
  }
  param {
    name: "scale3_b"
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_n"
  type: "ReLU"
  bottom: "h3_n"
  top: "h3_n"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "h3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "pool3_n"
  type: "Pooling"
  bottom: "h3_n"
  top: "pool3_n"
  top: "pool3_n_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  bottom: "pool3_n"
  top: "z4_pre"
  top: "z4_n"
  param {
    name: "conv4_w"
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "z4_pre"
  top: "z4"
  top: "bn4_param"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "z4"
  top: "h4"
  param {
    name: "scale4_w"
  }
  param {
    name: "scale4_b"
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "h4"
  top: "h4"
}
layer {
  name: "bn4_n"
  type: "BatchNorm"
  bottom: "z4_n"
  top: "z4_n"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
}
layer {
  name: "noisy_z4_n"
  type: "Noise"
  bottom: "z4_n"
  top: "z4_n"
  noise_param {
    sigma: 0.05
  }
}
layer {
  name: "scale4_n"
  type: "Scale"
  bottom: "z4_n"
  top: "h4_n"
  param {
    name: "scale4_w"
  }
  param {
    name: "scale4_b"
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_n"
  type: "ReLU"
  bottom: "h4_n"
  top: "h4_n"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "h4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "pool4_n"
  type: "Pooling"
  bottom: "h4_n"
  top: "pool4_n"
  top: "pool4_n_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "pool4"
  bottom: "pool4_n"
  top: "z5_pre"
  top: "z5_n"
  param {
    name: "conv5_w"
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "z5_pre"
  top: "z5"
  top: "bn5_param"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "z5"
  top: "h5"
  param {
    name: "scale5_w"
  }
  param {
    name: "scale5_b"
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "h5"
  top: "h5"
}
layer {
  name: "bn5_n"
  type: "BatchNorm"
  bottom: "z5_n"
  top: "z5_n"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
}
layer {
  name: "noisy_z5_n"
  type: "Noise"
  bottom: "z5_n"
  top: "z5_n"
  noise_param {
    sigma: 0.05
  }
}
layer {
  name: "scale5_n"
  type: "Scale"
  bottom: "z5_n"
  top: "h5_n"
  param {
    name: "scale5_w"
  }
  param {
    name: "scale5_b"
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_n"
  type: "ReLU"
  bottom: "h5_n"
  top: "h5_n"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "h5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "pool5_n"
  type: "Pooling"
  bottom: "h5_n"
  top: "pool5_n"
  top: "pool5_n_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "pool5"
  bottom: "pool5_n"
  top: "z6_pre"
  top: "z6_n"
  param {
    name: "conv6_w"
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "z6_pre"
  top: "z6"
  top: "bn6_param"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "z6"
  top: "h6"
  param {
    name: "scale6_w"
  }
  param {
    name: "scale6_b"
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "h6"
  top: "h6"
}
layer {
  name: "bn6_n"
  type: "BatchNorm"
  bottom: "z6_n"
  top: "z6_n"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
}
layer {
  name: "noisy_z6_n"
  type: "Noise"
  bottom: "z6_n"
  top: "z6_n"
  noise_param {
    sigma: 0.05
  }
}
layer {
  name: "scale6_n"
  type: "Scale"
  bottom: "z6_n"
  top: "h6_n"
  param {
    name: "scale6_w"
  }
  param {
    name: "scale6_b"
  }
  scale_param {
    filler {
      type: "constant"
      value: 1
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu6_n"
  type: "ReLU"
  bottom: "h6_n"
  top: "h6_n"
}
layer {
  name: "u6"
  type: "BatchNorm"
  bottom: "h6_n"
  top: "u6"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
}
layer {
  name: "comb6"
  type: "VanillaLadderCombinator"
  bottom: "z6_n"
  bottom: "u6"
  top: "z6_r"
}
layer {
  name: "recon6"
  type: "Deconvolution"
  bottom: "z6_r"
  top: "h6_r"
  param {
    name: "conv6_w"
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn6_r"
  type: "BatchNorm"
  bottom: "h6_r"
  top: "h6_r"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "h6_r"
  bottom: "pool5_n_mask"
  top: "upsample5"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "comb5"
  type: "VanillaLadderCombinator"
  bottom: "z5_n"
  bottom: "upsample5"
  top: "z5_r"
}
layer {
  name: "recon5"
  type: "Deconvolution"
  bottom: "z5_r"
  top: "h5_r"
  param {
    name: "conv5_w"
    lr_mult: 0
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_r"
  type: "BatchNorm"
  bottom: "h5_r"
  top: "h5_r"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "h5_r"
  bottom: "pool4_n_mask"
  top: "upsample4"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "comb4"
  type: "VanillaLadderCombinator"
  bottom: "z4_n"
  bottom: "upsample4"
  top: "z4_r"
}
layer {
  name: "recon4"
  type: "Deconvolution"
  bottom: "z4_r"
  top: "h4_r"
  param {
    name: "conv4_w"
    lr_mult: 0
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_r"
  type: "BatchNorm"
  bottom: "h4_r"
  top: "h4_r"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "h4_r"
  bottom: "pool3_n_mask"
  top: "upsample3"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "comb3"
  type: "VanillaLadderCombinator"
  bottom: "z3_n"
  bottom: "upsample3"
  top: "z3_r"
}
layer {
  name: "recon3"
  type: "Deconvolution"
  bottom: "z3_r"
  top: "h3_r"
  param {
    name: "conv3_w"
    lr_mult: 0
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_r"
  type: "BatchNorm"
  bottom: "h3_r"
  top: "h3_r"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "h3_r"
  bottom: "pool2_n_mask"
  top: "upsample2"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "comb2"
  type: "VanillaLadderCombinator"
  bottom: "z2_n"
  bottom: "upsample2"
  top: "z2_r"
}
layer {
  name: "recon2"
  type: "Deconvolution"
  bottom: "z2_r"
  top: "h2_r"
  param {
    name: "conv2_w"
    lr_mult: 0
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_r"
  type: "BatchNorm"
  bottom: "h2_r"
  top: "h2_r"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "h2_r"
  bottom: "pool1_n_mask"
  top: "upsample1"
  upsample_param {
    scale: 2
  }
}
layer {
  name: "comb1"
  type: "VanillaLadderCombinator"
  bottom: "z1_n"
  bottom: "upsample1"
  top: "z1_r"
}
layer {
  name: "recon1"
  type: "Deconvolution"
  bottom: "z1_r"
  top: "h1_r"
  param {
    name: "conv1_w"
    lr_mult: 0
  }
  convolution_param {
    num_output: 1
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_r"
  type: "BatchNorm"
  bottom: "h1_r"
  top: "h1_r"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
    eps: 0.001
  }
}
layer {
  name: "comb0"
  type: "VanillaLadderCombinator"
  bottom: "noisy_data"
  bottom: "h1_r"
  top: "z0_r"
}
layer {
  name: "loss_ladder_6"
  type: "LadderLoss"
  bottom: "z6"
  bottom: "z6_r"
  bottom: "bn6_param"
  top: "loss_ladder_6"
  loss_weight: 0.1
}
layer {
  name: "loss_ladder_5"
  type: "LadderLoss"
  bottom: "z5"
  bottom: "z5_r"
  bottom: "bn5_param"
  top: "loss_ladder_5"
  loss_weight: 0.1
}
layer {
  name: "loss_ladder_4"
  type: "LadderLoss"
  bottom: "z4"
  bottom: "z4_r"
  bottom: "bn4_param"
  top: "loss_ladder_4"
  loss_weight: 0.1
}
layer {
  name: "loss_ladder_3"
  type: "LadderLoss"
  bottom: "z3"
  bottom: "z3_r"
  bottom: "bn3_param"
  top: "loss_ladder_3"
  loss_weight: 0.1
}
layer {
  name: "loss_ladder_2"
  type: "LadderLoss"
  bottom: "z2"
  bottom: "z2_r"
  bottom: "bn2_param"
  top: "loss_ladder_2"
  loss_weight: 0.1
}
layer {
  name: "loss_ladder_1"
  type: "LadderLoss"
  bottom: "z1"
  bottom: "z1_r"
  bottom: "bn1_param"
  top: "loss_ladder_1"
  loss_weight: 0.1
}
layer {
  name: "loss_ladder_0"
  type: "LadderLoss"
  bottom: "noisy_data"
  bottom: "z0_r"
  top: "loss_ladder_0"
  loss_weight: 0.1
}
layer {
  name: "pool_final"
  type: "Pooling"
  bottom: "h6"
  top: "pool_final"
  pooling_param {
    pool: AVE
    stride: 1
    kernel_h: 6
    kernel_w: 8
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "pool_final"
  top: "score"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "loss_supervised"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "loss_supervised"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
}
I0705 11:39:11.822640 14303 layer_factory.hpp:77] Creating layer data
I0705 11:39:11.823027 14303 net.cpp:91] Creating Layer data
I0705 11:39:11.823038 14303 net.cpp:399] data -> data
I0705 11:39:11.823060 14303 net.cpp:399] data -> label
I0705 11:39:11.824411 14307 db_lmdb.cpp:35] Opened lmdb data/train_lmdb
I0705 11:39:11.840886 14303 data_layer.cpp:42] output data size: 16,1,192,256
I0705 11:39:11.847194 14303 net.cpp:141] Setting up data
I0705 11:39:11.847216 14303 net.cpp:148] Top shape: 16 1 192 256 (786432)
I0705 11:39:11.847220 14303 net.cpp:148] Top shape: 16 (16)
I0705 11:39:11.847223 14303 net.cpp:156] Memory required for data: 3145792
I0705 11:39:11.847232 14303 layer_factory.hpp:77] Creating layer data_data_0_split
I0705 11:39:11.847267 14303 net.cpp:91] Creating Layer data_data_0_split
I0705 11:39:11.847273 14303 net.cpp:425] data_data_0_split <- data
I0705 11:39:11.847285 14303 net.cpp:399] data_data_0_split -> data_data_0_split_0
I0705 11:39:11.847293 14303 net.cpp:399] data_data_0_split -> data_data_0_split_1
I0705 11:39:11.847431 14303 net.cpp:141] Setting up data_data_0_split
I0705 11:39:11.847441 14303 net.cpp:148] Top shape: 16 1 192 256 (786432)
I0705 11:39:11.847445 14303 net.cpp:148] Top shape: 16 1 192 256 (786432)
I0705 11:39:11.847446 14303 net.cpp:156] Memory required for data: 9437248
I0705 11:39:11.847462 14303 layer_factory.hpp:77] Creating layer label_data_1_split
I0705 11:39:11.847468 14303 net.cpp:91] Creating Layer label_data_1_split
I0705 11:39:11.847470 14303 net.cpp:425] label_data_1_split <- label
I0705 11:39:11.847476 14303 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0705 11:39:11.847481 14303 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0705 11:39:11.847522 14303 net.cpp:141] Setting up label_data_1_split
I0705 11:39:11.847527 14303 net.cpp:148] Top shape: 16 (16)
I0705 11:39:11.847529 14303 net.cpp:148] Top shape: 16 (16)
I0705 11:39:11.847532 14303 net.cpp:156] Memory required for data: 9437376
I0705 11:39:11.847533 14303 layer_factory.hpp:77] Creating layer noisy_data
I0705 11:39:11.847539 14303 net.cpp:91] Creating Layer noisy_data
I0705 11:39:11.847542 14303 net.cpp:425] noisy_data <- data_data_0_split_0
I0705 11:39:11.847545 14303 net.cpp:399] noisy_data -> noisy_data
I0705 11:39:11.847576 14303 net.cpp:141] Setting up noisy_data
I0705 11:39:11.847581 14303 net.cpp:148] Top shape: 16 1 192 256 (786432)
I0705 11:39:11.847584 14303 net.cpp:156] Memory required for data: 12583104
I0705 11:39:11.847585 14303 layer_factory.hpp:77] Creating layer noisy_data_noisy_data_0_split
I0705 11:39:11.847590 14303 net.cpp:91] Creating Layer noisy_data_noisy_data_0_split
I0705 11:39:11.847592 14303 net.cpp:425] noisy_data_noisy_data_0_split <- noisy_data
I0705 11:39:11.847596 14303 net.cpp:399] noisy_data_noisy_data_0_split -> noisy_data_noisy_data_0_split_0
I0705 11:39:11.847600 14303 net.cpp:399] noisy_data_noisy_data_0_split -> noisy_data_noisy_data_0_split_1
I0705 11:39:11.847605 14303 net.cpp:399] noisy_data_noisy_data_0_split -> noisy_data_noisy_data_0_split_2
I0705 11:39:11.847635 14303 net.cpp:141] Setting up noisy_data_noisy_data_0_split
I0705 11:39:11.847638 14303 net.cpp:148] Top shape: 16 1 192 256 (786432)
I0705 11:39:11.847642 14303 net.cpp:148] Top shape: 16 1 192 256 (786432)
I0705 11:39:11.847645 14303 net.cpp:148] Top shape: 16 1 192 256 (786432)
I0705 11:39:11.847647 14303 net.cpp:156] Memory required for data: 22020288
I0705 11:39:11.847650 14303 layer_factory.hpp:77] Creating layer conv1
I0705 11:39:11.847669 14303 net.cpp:91] Creating Layer conv1
I0705 11:39:11.847672 14303 net.cpp:425] conv1 <- data_data_0_split_1
I0705 11:39:11.847676 14303 net.cpp:425] conv1 <- noisy_data_noisy_data_0_split_0
I0705 11:39:11.847679 14303 net.cpp:399] conv1 -> z1_pre
I0705 11:39:11.847683 14303 net.cpp:399] conv1 -> z1_n
I0705 11:39:12.219290 14303 net.cpp:141] Setting up conv1
I0705 11:39:12.219321 14303 net.cpp:148] Top shape: 16 32 192 256 (25165824)
I0705 11:39:12.219326 14303 net.cpp:148] Top shape: 16 32 192 256 (25165824)
I0705 11:39:12.219329 14303 net.cpp:156] Memory required for data: 223346880
I0705 11:39:12.219344 14303 layer_factory.hpp:77] Creating layer bn1
I0705 11:39:12.219363 14303 net.cpp:91] Creating Layer bn1
I0705 11:39:12.219373 14303 net.cpp:425] bn1 <- z1_pre
I0705 11:39:12.219393 14303 net.cpp:399] bn1 -> z1
I0705 11:39:12.219410 14303 net.cpp:399] bn1 -> bn1_param
I0705 11:39:12.220484 14303 net.cpp:141] Setting up bn1
I0705 11:39:12.220500 14303 net.cpp:148] Top shape: 16 32 192 256 (25165824)
I0705 11:39:12.220505 14303 net.cpp:148] Top shape: 2 32 (64)
I0705 11:39:12.220507 14303 net.cpp:156] Memory required for data: 324010432
I0705 11:39:12.220520 14303 layer_factory.hpp:77] Creating layer z1_bn1_0_split
I0705 11:39:12.220528 14303 net.cpp:91] Creating Layer z1_bn1_0_split
I0705 11:39:12.220531 14303 net.cpp:425] z1_bn1_0_split <- z1
I0705 11:39:12.220537 14303 net.cpp:399] z1_bn1_0_split -> z1_bn1_0_split_0
I0705 11:39:12.220543 14303 net.cpp:399] z1_bn1_0_split -> z1_bn1_0_split_1
I0705 11:39:12.220587 14303 net.cpp:141] Setting up z1_bn1_0_split
I0705 11:39:12.220602 14303 net.cpp:148] Top shape: 16 32 192 256 (25165824)
I0705 11:39:12.220609 14303 net.cpp:148] Top shape: 16 32 192 256 (25165824)
I0705 11:39:12.220613 14303 net.cpp:156] Memory required for data: 525337024
I0705 11:39:12.220618 14303 layer_factory.hpp:77] Creating layer scale1
I0705 11:39:12.220648 14303 net.cpp:91] Creating Layer scale1
I0705 11:39:12.220659 14303 net.cpp:425] scale1 <- z1_bn1_0_split_0
I0705 11:39:12.220669 14303 net.cpp:399] scale1 -> h1
I0705 11:39:12.220738 14303 layer_factory.hpp:77] Creating layer scale1
I0705 11:39:12.220932 14303 net.cpp:141] Setting up scale1
I0705 11:39:12.220945 14303 net.cpp:148] Top shape: 16 32 192 256 (25165824)
I0705 11:39:12.220948 14303 net.cpp:156] Memory required for data: 626000320
I0705 11:39:12.220963 14303 layer_factory.hpp:77] Creating layer relu1
I0705 11:39:12.220973 14303 net.cpp:91] Creating Layer relu1
I0705 11:39:12.220978 14303 net.cpp:425] relu1 <- h1
I0705 11:39:12.220985 14303 net.cpp:386] relu1 -> h1 (in-place)
I0705 11:39:12.221371 14303 net.cpp:141] Setting up relu1
I0705 11:39:12.221387 14303 net.cpp:148] Top shape: 16 32 192 256 (25165824)
I0705 11:39:12.221390 14303 net.cpp:156] Memory required for data: 726663616
I0705 11:39:12.221395 14303 layer_factory.hpp:77] Creating layer bn1_n
I0705 11:39:12.221401 14303 net.cpp:91] Creating Layer bn1_n
I0705 11:39:12.221405 14303 net.cpp:425] bn1_n <- z1_n
I0705 11:39:12.221410 14303 net.cpp:386] bn1_n -> z1_n (in-place)
I0705 11:39:12.221657 14303 net.cpp:141] Setting up bn1_n
I0705 11:39:12.221669 14303 net.cpp:148] Top shape: 16 32 192 256 (25165824)
I0705 11:39:12.221673 14303 net.cpp:156] Memory required for data: 827326912
I0705 11:39:12.221688 14303 layer_factory.hpp:77] Creating layer noisy_z1_n
I0705 11:39:12.221698 14303 net.cpp:91] Creating Layer noisy_z1_n
I0705 11:39:12.221704 14303 net.cpp:425] noisy_z1_n <- z1_n
I0705 11:39:12.221711 14303 net.cpp:386] noisy_z1_n -> z1_n (in-place)
I0705 11:39:12.221750 14303 net.cpp:141] Setting up noisy_z1_n
I0705 11:39:12.221766 14303 net.cpp:148] Top shape: 16 32 192 256 (25165824)
I0705 11:39:12.221771 14303 net.cpp:156] Memory required for data: 927990208
I0705 11:39:12.221776 14303 layer_factory.hpp:77] Creating layer z1_n_noisy_z1_n_0_split
I0705 11:39:12.221784 14303 net.cpp:91] Creating Layer z1_n_noisy_z1_n_0_split
I0705 11:39:12.221791 14303 net.cpp:425] z1_n_noisy_z1_n_0_split <- z1_n
I0705 11:39:12.221798 14303 net.cpp:399] z1_n_noisy_z1_n_0_split -> z1_n_noisy_z1_n_0_split_0
I0705 11:39:12.221807 14303 net.cpp:399] z1_n_noisy_z1_n_0_split -> z1_n_noisy_z1_n_0_split_1
I0705 11:39:12.221860 14303 net.cpp:141] Setting up z1_n_noisy_z1_n_0_split
I0705 11:39:12.221869 14303 net.cpp:148] Top shape: 16 32 192 256 (25165824)
I0705 11:39:12.221873 14303 net.cpp:148] Top shape: 16 32 192 256 (25165824)
I0705 11:39:12.221876 14303 net.cpp:156] Memory required for data: 1129316800
I0705 11:39:12.221881 14303 layer_factory.hpp:77] Creating layer scale1_n
I0705 11:39:12.221892 14303 net.cpp:91] Creating Layer scale1_n
I0705 11:39:12.221899 14303 net.cpp:425] scale1_n <- z1_n_noisy_z1_n_0_split_0
I0705 11:39:12.221906 14303 net.cpp:399] scale1_n -> h1_n
I0705 11:39:12.221953 14303 layer_factory.hpp:77] Creating layer scale1_n
I0705 11:39:12.222887 14303 net.cpp:141] Setting up scale1_n
I0705 11:39:12.222903 14303 net.cpp:148] Top shape: 16 32 192 256 (25165824)
I0705 11:39:12.222905 14303 net.cpp:156] Memory required for data: 1229980096
I0705 11:39:12.222910 14303 net.cpp:484] Sharing parameters 'scale1_w' owned by layer 'scale1', param index 0
I0705 11:39:12.222914 14303 net.cpp:484] Sharing parameters 'scale1_b' owned by layer 'scale1', param index 1
I0705 11:39:12.222918 14303 layer_factory.hpp:77] Creating layer relu1_n
I0705 11:39:12.222923 14303 net.cpp:91] Creating Layer relu1_n
I0705 11:39:12.222926 14303 net.cpp:425] relu1_n <- h1_n
I0705 11:39:12.222931 14303 net.cpp:386] relu1_n -> h1_n (in-place)
I0705 11:39:12.223104 14303 net.cpp:141] Setting up relu1_n
I0705 11:39:12.223115 14303 net.cpp:148] Top shape: 16 32 192 256 (25165824)
I0705 11:39:12.223119 14303 net.cpp:156] Memory required for data: 1330643392
I0705 11:39:12.223122 14303 layer_factory.hpp:77] Creating layer pool1
I0705 11:39:12.223129 14303 net.cpp:91] Creating Layer pool1
I0705 11:39:12.223132 14303 net.cpp:425] pool1 <- h1
I0705 11:39:12.223150 14303 net.cpp:399] pool1 -> pool1
I0705 11:39:12.223212 14303 net.cpp:141] Setting up pool1
I0705 11:39:12.223222 14303 net.cpp:148] Top shape: 16 32 96 128 (6291456)
I0705 11:39:12.223224 14303 net.cpp:156] Memory required for data: 1355809216
I0705 11:39:12.223227 14303 layer_factory.hpp:77] Creating layer pool1_n
I0705 11:39:12.223230 14303 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0705 11:39:12.223237 14303 net.cpp:91] Creating Layer pool1_n
I0705 11:39:12.223240 14303 net.cpp:425] pool1_n <- h1_n
I0705 11:39:12.223245 14303 net.cpp:399] pool1_n -> pool1_n
I0705 11:39:12.223251 14303 net.cpp:399] pool1_n -> pool1_n_mask
I0705 11:39:12.223284 14303 net.cpp:141] Setting up pool1_n
I0705 11:39:12.223289 14303 net.cpp:148] Top shape: 16 32 96 128 (6291456)
I0705 11:39:12.223294 14303 net.cpp:148] Top shape: 16 32 96 128 (6291456)
I0705 11:39:12.223295 14303 net.cpp:156] Memory required for data: 1406140864
I0705 11:39:12.223299 14303 layer_factory.hpp:77] Creating layer conv2
I0705 11:39:12.223309 14303 net.cpp:91] Creating Layer conv2
I0705 11:39:12.223312 14303 net.cpp:425] conv2 <- pool1
I0705 11:39:12.223316 14303 net.cpp:425] conv2 <- pool1_n
I0705 11:39:12.223320 14303 net.cpp:399] conv2 -> z2_pre
I0705 11:39:12.223327 14303 net.cpp:399] conv2 -> z2_n
I0705 11:39:12.224596 14303 net.cpp:141] Setting up conv2
I0705 11:39:12.224611 14303 net.cpp:148] Top shape: 16 64 96 128 (12582912)
I0705 11:39:12.224616 14303 net.cpp:148] Top shape: 16 64 96 128 (12582912)
I0705 11:39:12.224618 14303 net.cpp:156] Memory required for data: 1506804160
I0705 11:39:12.224624 14303 layer_factory.hpp:77] Creating layer bn2
I0705 11:39:12.224632 14303 net.cpp:91] Creating Layer bn2
I0705 11:39:12.224637 14303 net.cpp:425] bn2 <- z2_pre
I0705 11:39:12.224642 14303 net.cpp:399] bn2 -> z2
I0705 11:39:12.224647 14303 net.cpp:399] bn2 -> bn2_param
I0705 11:39:12.225585 14303 net.cpp:141] Setting up bn2
I0705 11:39:12.225599 14303 net.cpp:148] Top shape: 16 64 96 128 (12582912)
I0705 11:39:12.225602 14303 net.cpp:148] Top shape: 2 64 (128)
I0705 11:39:12.225605 14303 net.cpp:156] Memory required for data: 1557136320
I0705 11:39:12.225613 14303 layer_factory.hpp:77] Creating layer z2_bn2_0_split
I0705 11:39:12.225620 14303 net.cpp:91] Creating Layer z2_bn2_0_split
I0705 11:39:12.225622 14303 net.cpp:425] z2_bn2_0_split <- z2
I0705 11:39:12.225630 14303 net.cpp:399] z2_bn2_0_split -> z2_bn2_0_split_0
I0705 11:39:12.225636 14303 net.cpp:399] z2_bn2_0_split -> z2_bn2_0_split_1
I0705 11:39:12.225673 14303 net.cpp:141] Setting up z2_bn2_0_split
I0705 11:39:12.225678 14303 net.cpp:148] Top shape: 16 64 96 128 (12582912)
I0705 11:39:12.225682 14303 net.cpp:148] Top shape: 16 64 96 128 (12582912)
I0705 11:39:12.225684 14303 net.cpp:156] Memory required for data: 1657799616
I0705 11:39:12.225687 14303 layer_factory.hpp:77] Creating layer scale2
I0705 11:39:12.225695 14303 net.cpp:91] Creating Layer scale2
I0705 11:39:12.225698 14303 net.cpp:425] scale2 <- z2_bn2_0_split_0
I0705 11:39:12.225704 14303 net.cpp:399] scale2 -> h2
I0705 11:39:12.225745 14303 layer_factory.hpp:77] Creating layer scale2
I0705 11:39:12.225859 14303 net.cpp:141] Setting up scale2
I0705 11:39:12.225868 14303 net.cpp:148] Top shape: 16 64 96 128 (12582912)
I0705 11:39:12.225872 14303 net.cpp:156] Memory required for data: 1708131264
I0705 11:39:12.225879 14303 layer_factory.hpp:77] Creating layer relu2
I0705 11:39:12.225884 14303 net.cpp:91] Creating Layer relu2
I0705 11:39:12.225888 14303 net.cpp:425] relu2 <- h2
I0705 11:39:12.225893 14303 net.cpp:386] relu2 -> h2 (in-place)
I0705 11:39:12.226222 14303 net.cpp:141] Setting up relu2
I0705 11:39:12.226235 14303 net.cpp:148] Top shape: 16 64 96 128 (12582912)
I0705 11:39:12.226238 14303 net.cpp:156] Memory required for data: 1758462912
I0705 11:39:12.226241 14303 layer_factory.hpp:77] Creating layer bn2_n
I0705 11:39:12.226249 14303 net.cpp:91] Creating Layer bn2_n
I0705 11:39:12.226253 14303 net.cpp:425] bn2_n <- z2_n
I0705 11:39:12.226258 14303 net.cpp:386] bn2_n -> z2_n (in-place)
I0705 11:39:12.226469 14303 net.cpp:141] Setting up bn2_n
I0705 11:39:12.226478 14303 net.cpp:148] Top shape: 16 64 96 128 (12582912)
I0705 11:39:12.226481 14303 net.cpp:156] Memory required for data: 1808794560
I0705 11:39:12.226490 14303 layer_factory.hpp:77] Creating layer noisy_z2_n
I0705 11:39:12.226495 14303 net.cpp:91] Creating Layer noisy_z2_n
I0705 11:39:12.226498 14303 net.cpp:425] noisy_z2_n <- z2_n
I0705 11:39:12.226503 14303 net.cpp:386] noisy_z2_n -> z2_n (in-place)
I0705 11:39:12.226527 14303 net.cpp:141] Setting up noisy_z2_n
I0705 11:39:12.226532 14303 net.cpp:148] Top shape: 16 64 96 128 (12582912)
I0705 11:39:12.226534 14303 net.cpp:156] Memory required for data: 1859126208
I0705 11:39:12.226537 14303 layer_factory.hpp:77] Creating layer z2_n_noisy_z2_n_0_split
I0705 11:39:12.226542 14303 net.cpp:91] Creating Layer z2_n_noisy_z2_n_0_split
I0705 11:39:12.226546 14303 net.cpp:425] z2_n_noisy_z2_n_0_split <- z2_n
I0705 11:39:12.226550 14303 net.cpp:399] z2_n_noisy_z2_n_0_split -> z2_n_noisy_z2_n_0_split_0
I0705 11:39:12.226555 14303 net.cpp:399] z2_n_noisy_z2_n_0_split -> z2_n_noisy_z2_n_0_split_1
I0705 11:39:12.226586 14303 net.cpp:141] Setting up z2_n_noisy_z2_n_0_split
I0705 11:39:12.226593 14303 net.cpp:148] Top shape: 16 64 96 128 (12582912)
I0705 11:39:12.226596 14303 net.cpp:148] Top shape: 16 64 96 128 (12582912)
I0705 11:39:12.226598 14303 net.cpp:156] Memory required for data: 1959789504
I0705 11:39:12.226601 14303 layer_factory.hpp:77] Creating layer scale2_n
I0705 11:39:12.226608 14303 net.cpp:91] Creating Layer scale2_n
I0705 11:39:12.226610 14303 net.cpp:425] scale2_n <- z2_n_noisy_z2_n_0_split_0
I0705 11:39:12.226616 14303 net.cpp:399] scale2_n -> h2_n
I0705 11:39:12.226658 14303 layer_factory.hpp:77] Creating layer scale2_n
I0705 11:39:12.226771 14303 net.cpp:141] Setting up scale2_n
I0705 11:39:12.226780 14303 net.cpp:148] Top shape: 16 64 96 128 (12582912)
I0705 11:39:12.226783 14303 net.cpp:156] Memory required for data: 2010121152
I0705 11:39:12.226788 14303 net.cpp:484] Sharing parameters 'scale2_w' owned by layer 'scale2', param index 0
I0705 11:39:12.226790 14303 net.cpp:484] Sharing parameters 'scale2_b' owned by layer 'scale2', param index 1
I0705 11:39:12.226794 14303 layer_factory.hpp:77] Creating layer relu2_n
I0705 11:39:12.226801 14303 net.cpp:91] Creating Layer relu2_n
I0705 11:39:12.226804 14303 net.cpp:425] relu2_n <- h2_n
I0705 11:39:12.226809 14303 net.cpp:386] relu2_n -> h2_n (in-place)
I0705 11:39:12.226981 14303 net.cpp:141] Setting up relu2_n
I0705 11:39:12.226994 14303 net.cpp:148] Top shape: 16 64 96 128 (12582912)
I0705 11:39:12.226996 14303 net.cpp:156] Memory required for data: 2060452800
I0705 11:39:12.226999 14303 layer_factory.hpp:77] Creating layer pool2
I0705 11:39:12.227005 14303 net.cpp:91] Creating Layer pool2
I0705 11:39:12.227008 14303 net.cpp:425] pool2 <- h2
I0705 11:39:12.227013 14303 net.cpp:399] pool2 -> pool2
I0705 11:39:12.227056 14303 net.cpp:141] Setting up pool2
I0705 11:39:12.227064 14303 net.cpp:148] Top shape: 16 64 48 64 (3145728)
I0705 11:39:12.227066 14303 net.cpp:156] Memory required for data: 2073035712
I0705 11:39:12.227069 14303 layer_factory.hpp:77] Creating layer pool2_n
I0705 11:39:12.227072 14303 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0705 11:39:12.227078 14303 net.cpp:91] Creating Layer pool2_n
I0705 11:39:12.227082 14303 net.cpp:425] pool2_n <- h2_n
I0705 11:39:12.227085 14303 net.cpp:399] pool2_n -> pool2_n
I0705 11:39:12.227090 14303 net.cpp:399] pool2_n -> pool2_n_mask
I0705 11:39:12.227124 14303 net.cpp:141] Setting up pool2_n
I0705 11:39:12.227129 14303 net.cpp:148] Top shape: 16 64 48 64 (3145728)
I0705 11:39:12.227133 14303 net.cpp:148] Top shape: 16 64 48 64 (3145728)
I0705 11:39:12.227135 14303 net.cpp:156] Memory required for data: 2098201536
I0705 11:39:12.227138 14303 layer_factory.hpp:77] Creating layer conv3
I0705 11:39:12.227147 14303 net.cpp:91] Creating Layer conv3
I0705 11:39:12.227150 14303 net.cpp:425] conv3 <- pool2
I0705 11:39:12.227165 14303 net.cpp:425] conv3 <- pool2_n
I0705 11:39:12.227172 14303 net.cpp:399] conv3 -> z3_pre
I0705 11:39:12.227179 14303 net.cpp:399] conv3 -> z3_n
I0705 11:39:12.229545 14303 net.cpp:141] Setting up conv3
I0705 11:39:12.229562 14303 net.cpp:148] Top shape: 16 128 48 64 (6291456)
I0705 11:39:12.229567 14303 net.cpp:148] Top shape: 16 128 48 64 (6291456)
I0705 11:39:12.229569 14303 net.cpp:156] Memory required for data: 2148533184
I0705 11:39:12.229575 14303 layer_factory.hpp:77] Creating layer bn3
I0705 11:39:12.229585 14303 net.cpp:91] Creating Layer bn3
I0705 11:39:12.229590 14303 net.cpp:425] bn3 <- z3_pre
I0705 11:39:12.229598 14303 net.cpp:399] bn3 -> z3
I0705 11:39:12.229605 14303 net.cpp:399] bn3 -> bn3_param
I0705 11:39:12.230655 14303 net.cpp:141] Setting up bn3
I0705 11:39:12.230675 14303 net.cpp:148] Top shape: 16 128 48 64 (6291456)
I0705 11:39:12.230684 14303 net.cpp:148] Top shape: 2 128 (256)
I0705 11:39:12.230690 14303 net.cpp:156] Memory required for data: 2173700032
I0705 11:39:12.230703 14303 layer_factory.hpp:77] Creating layer z3_bn3_0_split
I0705 11:39:12.230713 14303 net.cpp:91] Creating Layer z3_bn3_0_split
I0705 11:39:12.230721 14303 net.cpp:425] z3_bn3_0_split <- z3
I0705 11:39:12.230733 14303 net.cpp:399] z3_bn3_0_split -> z3_bn3_0_split_0
I0705 11:39:12.230744 14303 net.cpp:399] z3_bn3_0_split -> z3_bn3_0_split_1
I0705 11:39:12.230800 14303 net.cpp:141] Setting up z3_bn3_0_split
I0705 11:39:12.230813 14303 net.cpp:148] Top shape: 16 128 48 64 (6291456)
I0705 11:39:12.230821 14303 net.cpp:148] Top shape: 16 128 48 64 (6291456)
I0705 11:39:12.230828 14303 net.cpp:156] Memory required for data: 2224031680
I0705 11:39:12.230832 14303 layer_factory.hpp:77] Creating layer scale3
I0705 11:39:12.230849 14303 net.cpp:91] Creating Layer scale3
I0705 11:39:12.230857 14303 net.cpp:425] scale3 <- z3_bn3_0_split_0
I0705 11:39:12.230868 14303 net.cpp:399] scale3 -> h3
I0705 11:39:12.230934 14303 layer_factory.hpp:77] Creating layer scale3
I0705 11:39:12.231084 14303 net.cpp:141] Setting up scale3
I0705 11:39:12.231096 14303 net.cpp:148] Top shape: 16 128 48 64 (6291456)
I0705 11:39:12.231103 14303 net.cpp:156] Memory required for data: 2249197504
I0705 11:39:12.231112 14303 layer_factory.hpp:77] Creating layer relu3
I0705 11:39:12.231119 14303 net.cpp:91] Creating Layer relu3
I0705 11:39:12.231127 14303 net.cpp:425] relu3 <- h3
I0705 11:39:12.231133 14303 net.cpp:386] relu3 -> h3 (in-place)
I0705 11:39:12.231609 14303 net.cpp:141] Setting up relu3
I0705 11:39:12.231627 14303 net.cpp:148] Top shape: 16 128 48 64 (6291456)
I0705 11:39:12.231634 14303 net.cpp:156] Memory required for data: 2274363328
I0705 11:39:12.231642 14303 layer_factory.hpp:77] Creating layer bn3_n
I0705 11:39:12.231652 14303 net.cpp:91] Creating Layer bn3_n
I0705 11:39:12.231658 14303 net.cpp:425] bn3_n <- z3_n
I0705 11:39:12.231669 14303 net.cpp:386] bn3_n -> z3_n (in-place)
I0705 11:39:12.231848 14303 net.cpp:141] Setting up bn3_n
I0705 11:39:12.231861 14303 net.cpp:148] Top shape: 16 128 48 64 (6291456)
I0705 11:39:12.231868 14303 net.cpp:156] Memory required for data: 2299529152
I0705 11:39:12.231878 14303 layer_factory.hpp:77] Creating layer noisy_z3_n
I0705 11:39:12.231887 14303 net.cpp:91] Creating Layer noisy_z3_n
I0705 11:39:12.231894 14303 net.cpp:425] noisy_z3_n <- z3_n
I0705 11:39:12.231901 14303 net.cpp:386] noisy_z3_n -> z3_n (in-place)
I0705 11:39:12.231938 14303 net.cpp:141] Setting up noisy_z3_n
I0705 11:39:12.231950 14303 net.cpp:148] Top shape: 16 128 48 64 (6291456)
I0705 11:39:12.231956 14303 net.cpp:156] Memory required for data: 2324694976
I0705 11:39:12.231961 14303 layer_factory.hpp:77] Creating layer z3_n_noisy_z3_n_0_split
I0705 11:39:12.231971 14303 net.cpp:91] Creating Layer z3_n_noisy_z3_n_0_split
I0705 11:39:12.231978 14303 net.cpp:425] z3_n_noisy_z3_n_0_split <- z3_n
I0705 11:39:12.231984 14303 net.cpp:399] z3_n_noisy_z3_n_0_split -> z3_n_noisy_z3_n_0_split_0
I0705 11:39:12.231993 14303 net.cpp:399] z3_n_noisy_z3_n_0_split -> z3_n_noisy_z3_n_0_split_1
I0705 11:39:12.232046 14303 net.cpp:141] Setting up z3_n_noisy_z3_n_0_split
I0705 11:39:12.232074 14303 net.cpp:148] Top shape: 16 128 48 64 (6291456)
I0705 11:39:12.232081 14303 net.cpp:148] Top shape: 16 128 48 64 (6291456)
I0705 11:39:12.232086 14303 net.cpp:156] Memory required for data: 2375026624
I0705 11:39:12.232091 14303 layer_factory.hpp:77] Creating layer scale3_n
I0705 11:39:12.232105 14303 net.cpp:91] Creating Layer scale3_n
I0705 11:39:12.232112 14303 net.cpp:425] scale3_n <- z3_n_noisy_z3_n_0_split_0
I0705 11:39:12.232125 14303 net.cpp:399] scale3_n -> h3_n
I0705 11:39:12.232195 14303 layer_factory.hpp:77] Creating layer scale3_n
I0705 11:39:12.232317 14303 net.cpp:141] Setting up scale3_n
I0705 11:39:12.232327 14303 net.cpp:148] Top shape: 16 128 48 64 (6291456)
I0705 11:39:12.232331 14303 net.cpp:156] Memory required for data: 2400192448
I0705 11:39:12.232334 14303 net.cpp:484] Sharing parameters 'scale3_w' owned by layer 'scale3', param index 0
I0705 11:39:12.232342 14303 net.cpp:484] Sharing parameters 'scale3_b' owned by layer 'scale3', param index 1
I0705 11:39:12.232347 14303 layer_factory.hpp:77] Creating layer relu3_n
I0705 11:39:12.232350 14303 net.cpp:91] Creating Layer relu3_n
I0705 11:39:12.232354 14303 net.cpp:425] relu3_n <- h3_n
I0705 11:39:12.232358 14303 net.cpp:386] relu3_n -> h3_n (in-place)
I0705 11:39:12.232516 14303 net.cpp:141] Setting up relu3_n
I0705 11:39:12.232524 14303 net.cpp:148] Top shape: 16 128 48 64 (6291456)
I0705 11:39:12.232527 14303 net.cpp:156] Memory required for data: 2425358272
I0705 11:39:12.232529 14303 layer_factory.hpp:77] Creating layer pool3
I0705 11:39:12.232537 14303 net.cpp:91] Creating Layer pool3
I0705 11:39:12.232540 14303 net.cpp:425] pool3 <- h3
I0705 11:39:12.232545 14303 net.cpp:399] pool3 -> pool3
I0705 11:39:12.232588 14303 net.cpp:141] Setting up pool3
I0705 11:39:12.232594 14303 net.cpp:148] Top shape: 16 128 24 32 (1572864)
I0705 11:39:12.232596 14303 net.cpp:156] Memory required for data: 2431649728
I0705 11:39:12.232599 14303 layer_factory.hpp:77] Creating layer pool3_n
I0705 11:39:12.232601 14303 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0705 11:39:12.232605 14303 net.cpp:91] Creating Layer pool3_n
I0705 11:39:12.232609 14303 net.cpp:425] pool3_n <- h3_n
I0705 11:39:12.232612 14303 net.cpp:399] pool3_n -> pool3_n
I0705 11:39:12.232617 14303 net.cpp:399] pool3_n -> pool3_n_mask
I0705 11:39:12.232646 14303 net.cpp:141] Setting up pool3_n
I0705 11:39:12.232653 14303 net.cpp:148] Top shape: 16 128 24 32 (1572864)
I0705 11:39:12.232656 14303 net.cpp:148] Top shape: 16 128 24 32 (1572864)
I0705 11:39:12.232658 14303 net.cpp:156] Memory required for data: 2444232640
I0705 11:39:12.232661 14303 layer_factory.hpp:77] Creating layer conv4
I0705 11:39:12.232669 14303 net.cpp:91] Creating Layer conv4
I0705 11:39:12.232672 14303 net.cpp:425] conv4 <- pool3
I0705 11:39:12.232676 14303 net.cpp:425] conv4 <- pool3_n
I0705 11:39:12.232681 14303 net.cpp:399] conv4 -> z4_pre
I0705 11:39:12.232686 14303 net.cpp:399] conv4 -> z4_n
I0705 11:39:12.236098 14303 net.cpp:141] Setting up conv4
I0705 11:39:12.236112 14303 net.cpp:148] Top shape: 16 256 24 32 (3145728)
I0705 11:39:12.236116 14303 net.cpp:148] Top shape: 16 256 24 32 (3145728)
I0705 11:39:12.236119 14303 net.cpp:156] Memory required for data: 2469398464
I0705 11:39:12.236124 14303 layer_factory.hpp:77] Creating layer bn4
I0705 11:39:12.236129 14303 net.cpp:91] Creating Layer bn4
I0705 11:39:12.236132 14303 net.cpp:425] bn4 <- z4_pre
I0705 11:39:12.236137 14303 net.cpp:399] bn4 -> z4
I0705 11:39:12.236143 14303 net.cpp:399] bn4 -> bn4_param
I0705 11:39:12.236321 14303 net.cpp:141] Setting up bn4
I0705 11:39:12.236328 14303 net.cpp:148] Top shape: 16 256 24 32 (3145728)
I0705 11:39:12.236331 14303 net.cpp:148] Top shape: 2 256 (512)
I0705 11:39:12.236333 14303 net.cpp:156] Memory required for data: 2481983424
I0705 11:39:12.236340 14303 layer_factory.hpp:77] Creating layer z4_bn4_0_split
I0705 11:39:12.236345 14303 net.cpp:91] Creating Layer z4_bn4_0_split
I0705 11:39:12.236348 14303 net.cpp:425] z4_bn4_0_split <- z4
I0705 11:39:12.236363 14303 net.cpp:399] z4_bn4_0_split -> z4_bn4_0_split_0
I0705 11:39:12.236368 14303 net.cpp:399] z4_bn4_0_split -> z4_bn4_0_split_1
I0705 11:39:12.236402 14303 net.cpp:141] Setting up z4_bn4_0_split
I0705 11:39:12.236409 14303 net.cpp:148] Top shape: 16 256 24 32 (3145728)
I0705 11:39:12.236413 14303 net.cpp:148] Top shape: 16 256 24 32 (3145728)
I0705 11:39:12.236414 14303 net.cpp:156] Memory required for data: 2507149248
I0705 11:39:12.236416 14303 layer_factory.hpp:77] Creating layer scale4
I0705 11:39:12.236425 14303 net.cpp:91] Creating Layer scale4
I0705 11:39:12.236428 14303 net.cpp:425] scale4 <- z4_bn4_0_split_0
I0705 11:39:12.236433 14303 net.cpp:399] scale4 -> h4
I0705 11:39:12.236469 14303 layer_factory.hpp:77] Creating layer scale4
I0705 11:39:12.236555 14303 net.cpp:141] Setting up scale4
I0705 11:39:12.236562 14303 net.cpp:148] Top shape: 16 256 24 32 (3145728)
I0705 11:39:12.236564 14303 net.cpp:156] Memory required for data: 2519732160
I0705 11:39:12.236569 14303 layer_factory.hpp:77] Creating layer relu4
I0705 11:39:12.236573 14303 net.cpp:91] Creating Layer relu4
I0705 11:39:12.236577 14303 net.cpp:425] relu4 <- h4
I0705 11:39:12.236582 14303 net.cpp:386] relu4 -> h4 (in-place)
I0705 11:39:12.236732 14303 net.cpp:141] Setting up relu4
I0705 11:39:12.236740 14303 net.cpp:148] Top shape: 16 256 24 32 (3145728)
I0705 11:39:12.236743 14303 net.cpp:156] Memory required for data: 2532315072
I0705 11:39:12.236747 14303 layer_factory.hpp:77] Creating layer bn4_n
I0705 11:39:12.236752 14303 net.cpp:91] Creating Layer bn4_n
I0705 11:39:12.236755 14303 net.cpp:425] bn4_n <- z4_n
I0705 11:39:12.236759 14303 net.cpp:386] bn4_n -> z4_n (in-place)
I0705 11:39:12.236909 14303 net.cpp:141] Setting up bn4_n
I0705 11:39:12.236917 14303 net.cpp:148] Top shape: 16 256 24 32 (3145728)
I0705 11:39:12.236919 14303 net.cpp:156] Memory required for data: 2544897984
I0705 11:39:12.236924 14303 layer_factory.hpp:77] Creating layer noisy_z4_n
I0705 11:39:12.236932 14303 net.cpp:91] Creating Layer noisy_z4_n
I0705 11:39:12.236934 14303 net.cpp:425] noisy_z4_n <- z4_n
I0705 11:39:12.236937 14303 net.cpp:386] noisy_z4_n -> z4_n (in-place)
I0705 11:39:12.236956 14303 net.cpp:141] Setting up noisy_z4_n
I0705 11:39:12.236963 14303 net.cpp:148] Top shape: 16 256 24 32 (3145728)
I0705 11:39:12.236964 14303 net.cpp:156] Memory required for data: 2557480896
I0705 11:39:12.236966 14303 layer_factory.hpp:77] Creating layer z4_n_noisy_z4_n_0_split
I0705 11:39:12.236970 14303 net.cpp:91] Creating Layer z4_n_noisy_z4_n_0_split
I0705 11:39:12.236973 14303 net.cpp:425] z4_n_noisy_z4_n_0_split <- z4_n
I0705 11:39:12.236979 14303 net.cpp:399] z4_n_noisy_z4_n_0_split -> z4_n_noisy_z4_n_0_split_0
I0705 11:39:12.236982 14303 net.cpp:399] z4_n_noisy_z4_n_0_split -> z4_n_noisy_z4_n_0_split_1
I0705 11:39:12.237010 14303 net.cpp:141] Setting up z4_n_noisy_z4_n_0_split
I0705 11:39:12.237016 14303 net.cpp:148] Top shape: 16 256 24 32 (3145728)
I0705 11:39:12.237020 14303 net.cpp:148] Top shape: 16 256 24 32 (3145728)
I0705 11:39:12.237021 14303 net.cpp:156] Memory required for data: 2582646720
I0705 11:39:12.237023 14303 layer_factory.hpp:77] Creating layer scale4_n
I0705 11:39:12.237030 14303 net.cpp:91] Creating Layer scale4_n
I0705 11:39:12.237033 14303 net.cpp:425] scale4_n <- z4_n_noisy_z4_n_0_split_0
I0705 11:39:12.237038 14303 net.cpp:399] scale4_n -> h4_n
I0705 11:39:12.237074 14303 layer_factory.hpp:77] Creating layer scale4_n
I0705 11:39:12.237157 14303 net.cpp:141] Setting up scale4_n
I0705 11:39:12.237164 14303 net.cpp:148] Top shape: 16 256 24 32 (3145728)
I0705 11:39:12.237166 14303 net.cpp:156] Memory required for data: 2595229632
I0705 11:39:12.237169 14303 net.cpp:484] Sharing parameters 'scale4_w' owned by layer 'scale4', param index 0
I0705 11:39:12.237171 14303 net.cpp:484] Sharing parameters 'scale4_b' owned by layer 'scale4', param index 1
I0705 11:39:12.237174 14303 layer_factory.hpp:77] Creating layer relu4_n
I0705 11:39:12.237180 14303 net.cpp:91] Creating Layer relu4_n
I0705 11:39:12.237195 14303 net.cpp:425] relu4_n <- h4_n
I0705 11:39:12.237200 14303 net.cpp:386] relu4_n -> h4_n (in-place)
I0705 11:39:12.237475 14303 net.cpp:141] Setting up relu4_n
I0705 11:39:12.237486 14303 net.cpp:148] Top shape: 16 256 24 32 (3145728)
I0705 11:39:12.237489 14303 net.cpp:156] Memory required for data: 2607812544
I0705 11:39:12.237493 14303 layer_factory.hpp:77] Creating layer pool4
I0705 11:39:12.237499 14303 net.cpp:91] Creating Layer pool4
I0705 11:39:12.237503 14303 net.cpp:425] pool4 <- h4
I0705 11:39:12.237506 14303 net.cpp:399] pool4 -> pool4
I0705 11:39:12.237548 14303 net.cpp:141] Setting up pool4
I0705 11:39:12.237555 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.237557 14303 net.cpp:156] Memory required for data: 2610958272
I0705 11:39:12.237560 14303 layer_factory.hpp:77] Creating layer pool4_n
I0705 11:39:12.237562 14303 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0705 11:39:12.237566 14303 net.cpp:91] Creating Layer pool4_n
I0705 11:39:12.237568 14303 net.cpp:425] pool4_n <- h4_n
I0705 11:39:12.237573 14303 net.cpp:399] pool4_n -> pool4_n
I0705 11:39:12.237578 14303 net.cpp:399] pool4_n -> pool4_n_mask
I0705 11:39:12.237609 14303 net.cpp:141] Setting up pool4_n
I0705 11:39:12.237614 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.237617 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.237619 14303 net.cpp:156] Memory required for data: 2617249728
I0705 11:39:12.237622 14303 layer_factory.hpp:77] Creating layer conv5
I0705 11:39:12.237629 14303 net.cpp:91] Creating Layer conv5
I0705 11:39:12.237632 14303 net.cpp:425] conv5 <- pool4
I0705 11:39:12.237635 14303 net.cpp:425] conv5 <- pool4_n
I0705 11:39:12.237639 14303 net.cpp:399] conv5 -> z5_pre
I0705 11:39:12.237645 14303 net.cpp:399] conv5 -> z5_n
I0705 11:39:12.243247 14303 net.cpp:141] Setting up conv5
I0705 11:39:12.243262 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.243264 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.243266 14303 net.cpp:156] Memory required for data: 2623541184
I0705 11:39:12.243271 14303 layer_factory.hpp:77] Creating layer bn5
I0705 11:39:12.243278 14303 net.cpp:91] Creating Layer bn5
I0705 11:39:12.243281 14303 net.cpp:425] bn5 <- z5_pre
I0705 11:39:12.243288 14303 net.cpp:399] bn5 -> z5
I0705 11:39:12.243300 14303 net.cpp:399] bn5 -> bn5_param
I0705 11:39:12.243481 14303 net.cpp:141] Setting up bn5
I0705 11:39:12.243489 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.243494 14303 net.cpp:148] Top shape: 2 256 (512)
I0705 11:39:12.243494 14303 net.cpp:156] Memory required for data: 2626688960
I0705 11:39:12.243500 14303 layer_factory.hpp:77] Creating layer z5_bn5_0_split
I0705 11:39:12.243505 14303 net.cpp:91] Creating Layer z5_bn5_0_split
I0705 11:39:12.243508 14303 net.cpp:425] z5_bn5_0_split <- z5
I0705 11:39:12.243513 14303 net.cpp:399] z5_bn5_0_split -> z5_bn5_0_split_0
I0705 11:39:12.243518 14303 net.cpp:399] z5_bn5_0_split -> z5_bn5_0_split_1
I0705 11:39:12.243548 14303 net.cpp:141] Setting up z5_bn5_0_split
I0705 11:39:12.243552 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.243556 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.243557 14303 net.cpp:156] Memory required for data: 2632980416
I0705 11:39:12.243561 14303 layer_factory.hpp:77] Creating layer scale5
I0705 11:39:12.243566 14303 net.cpp:91] Creating Layer scale5
I0705 11:39:12.243569 14303 net.cpp:425] scale5 <- z5_bn5_0_split_0
I0705 11:39:12.243574 14303 net.cpp:399] scale5 -> h5
I0705 11:39:12.243609 14303 layer_factory.hpp:77] Creating layer scale5
I0705 11:39:12.243696 14303 net.cpp:141] Setting up scale5
I0705 11:39:12.243703 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.243705 14303 net.cpp:156] Memory required for data: 2636126144
I0705 11:39:12.243710 14303 layer_factory.hpp:77] Creating layer relu5
I0705 11:39:12.243715 14303 net.cpp:91] Creating Layer relu5
I0705 11:39:12.243717 14303 net.cpp:425] relu5 <- h5
I0705 11:39:12.243731 14303 net.cpp:386] relu5 -> h5 (in-place)
I0705 11:39:12.243883 14303 net.cpp:141] Setting up relu5
I0705 11:39:12.243893 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.243896 14303 net.cpp:156] Memory required for data: 2639271872
I0705 11:39:12.243898 14303 layer_factory.hpp:77] Creating layer bn5_n
I0705 11:39:12.243904 14303 net.cpp:91] Creating Layer bn5_n
I0705 11:39:12.243907 14303 net.cpp:425] bn5_n <- z5_n
I0705 11:39:12.243913 14303 net.cpp:386] bn5_n -> z5_n (in-place)
I0705 11:39:12.244066 14303 net.cpp:141] Setting up bn5_n
I0705 11:39:12.244073 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.244076 14303 net.cpp:156] Memory required for data: 2642417600
I0705 11:39:12.244081 14303 layer_factory.hpp:77] Creating layer noisy_z5_n
I0705 11:39:12.244086 14303 net.cpp:91] Creating Layer noisy_z5_n
I0705 11:39:12.244089 14303 net.cpp:425] noisy_z5_n <- z5_n
I0705 11:39:12.244092 14303 net.cpp:386] noisy_z5_n -> z5_n (in-place)
I0705 11:39:12.244113 14303 net.cpp:141] Setting up noisy_z5_n
I0705 11:39:12.244117 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.244119 14303 net.cpp:156] Memory required for data: 2645563328
I0705 11:39:12.244122 14303 layer_factory.hpp:77] Creating layer z5_n_noisy_z5_n_0_split
I0705 11:39:12.244127 14303 net.cpp:91] Creating Layer z5_n_noisy_z5_n_0_split
I0705 11:39:12.244128 14303 net.cpp:425] z5_n_noisy_z5_n_0_split <- z5_n
I0705 11:39:12.244132 14303 net.cpp:399] z5_n_noisy_z5_n_0_split -> z5_n_noisy_z5_n_0_split_0
I0705 11:39:12.244138 14303 net.cpp:399] z5_n_noisy_z5_n_0_split -> z5_n_noisy_z5_n_0_split_1
I0705 11:39:12.244166 14303 net.cpp:141] Setting up z5_n_noisy_z5_n_0_split
I0705 11:39:12.244170 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.244173 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.244174 14303 net.cpp:156] Memory required for data: 2651854784
I0705 11:39:12.244177 14303 layer_factory.hpp:77] Creating layer scale5_n
I0705 11:39:12.244184 14303 net.cpp:91] Creating Layer scale5_n
I0705 11:39:12.244186 14303 net.cpp:425] scale5_n <- z5_n_noisy_z5_n_0_split_0
I0705 11:39:12.244189 14303 net.cpp:399] scale5_n -> h5_n
I0705 11:39:12.244225 14303 layer_factory.hpp:77] Creating layer scale5_n
I0705 11:39:12.244307 14303 net.cpp:141] Setting up scale5_n
I0705 11:39:12.244314 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.244316 14303 net.cpp:156] Memory required for data: 2655000512
I0705 11:39:12.244319 14303 net.cpp:484] Sharing parameters 'scale5_w' owned by layer 'scale5', param index 0
I0705 11:39:12.244323 14303 net.cpp:484] Sharing parameters 'scale5_b' owned by layer 'scale5', param index 1
I0705 11:39:12.244324 14303 layer_factory.hpp:77] Creating layer relu5_n
I0705 11:39:12.244329 14303 net.cpp:91] Creating Layer relu5_n
I0705 11:39:12.244331 14303 net.cpp:425] relu5_n <- h5_n
I0705 11:39:12.244336 14303 net.cpp:386] relu5_n -> h5_n (in-place)
I0705 11:39:12.244616 14303 net.cpp:141] Setting up relu5_n
I0705 11:39:12.244627 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.244631 14303 net.cpp:156] Memory required for data: 2658146240
I0705 11:39:12.244633 14303 layer_factory.hpp:77] Creating layer pool5
I0705 11:39:12.244638 14303 net.cpp:91] Creating Layer pool5
I0705 11:39:12.244642 14303 net.cpp:425] pool5 <- h5
I0705 11:39:12.244647 14303 net.cpp:399] pool5 -> pool5
I0705 11:39:12.244688 14303 net.cpp:141] Setting up pool5
I0705 11:39:12.244693 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.244694 14303 net.cpp:156] Memory required for data: 2658932672
I0705 11:39:12.244696 14303 layer_factory.hpp:77] Creating layer pool5_n
I0705 11:39:12.244699 14303 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0705 11:39:12.244711 14303 net.cpp:91] Creating Layer pool5_n
I0705 11:39:12.244714 14303 net.cpp:425] pool5_n <- h5_n
I0705 11:39:12.244719 14303 net.cpp:399] pool5_n -> pool5_n
I0705 11:39:12.244722 14303 net.cpp:399] pool5_n -> pool5_n_mask
I0705 11:39:12.244771 14303 net.cpp:141] Setting up pool5_n
I0705 11:39:12.244776 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.244779 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.244781 14303 net.cpp:156] Memory required for data: 2660505536
I0705 11:39:12.244784 14303 layer_factory.hpp:77] Creating layer conv6
I0705 11:39:12.244792 14303 net.cpp:91] Creating Layer conv6
I0705 11:39:12.244796 14303 net.cpp:425] conv6 <- pool5
I0705 11:39:12.244798 14303 net.cpp:425] conv6 <- pool5_n
I0705 11:39:12.244803 14303 net.cpp:399] conv6 -> z6_pre
I0705 11:39:12.244809 14303 net.cpp:399] conv6 -> z6_n
I0705 11:39:12.250888 14303 net.cpp:141] Setting up conv6
I0705 11:39:12.250902 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.250906 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.250908 14303 net.cpp:156] Memory required for data: 2662078400
I0705 11:39:12.250913 14303 layer_factory.hpp:77] Creating layer bn6
I0705 11:39:12.250921 14303 net.cpp:91] Creating Layer bn6
I0705 11:39:12.250923 14303 net.cpp:425] bn6 <- z6_pre
I0705 11:39:12.250928 14303 net.cpp:399] bn6 -> z6
I0705 11:39:12.250936 14303 net.cpp:399] bn6 -> bn6_param
I0705 11:39:12.251119 14303 net.cpp:141] Setting up bn6
I0705 11:39:12.251127 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.251130 14303 net.cpp:148] Top shape: 2 256 (512)
I0705 11:39:12.251132 14303 net.cpp:156] Memory required for data: 2662866880
I0705 11:39:12.251137 14303 layer_factory.hpp:77] Creating layer z6_bn6_0_split
I0705 11:39:12.251142 14303 net.cpp:91] Creating Layer z6_bn6_0_split
I0705 11:39:12.251145 14303 net.cpp:425] z6_bn6_0_split <- z6
I0705 11:39:12.251149 14303 net.cpp:399] z6_bn6_0_split -> z6_bn6_0_split_0
I0705 11:39:12.251153 14303 net.cpp:399] z6_bn6_0_split -> z6_bn6_0_split_1
I0705 11:39:12.251185 14303 net.cpp:141] Setting up z6_bn6_0_split
I0705 11:39:12.251189 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.251193 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.251194 14303 net.cpp:156] Memory required for data: 2664439744
I0705 11:39:12.251196 14303 layer_factory.hpp:77] Creating layer scale6
I0705 11:39:12.251202 14303 net.cpp:91] Creating Layer scale6
I0705 11:39:12.251204 14303 net.cpp:425] scale6 <- z6_bn6_0_split_0
I0705 11:39:12.251210 14303 net.cpp:399] scale6 -> h6
I0705 11:39:12.251252 14303 layer_factory.hpp:77] Creating layer scale6
I0705 11:39:12.251340 14303 net.cpp:141] Setting up scale6
I0705 11:39:12.251348 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.251349 14303 net.cpp:156] Memory required for data: 2665226176
I0705 11:39:12.251354 14303 layer_factory.hpp:77] Creating layer relu6
I0705 11:39:12.251358 14303 net.cpp:91] Creating Layer relu6
I0705 11:39:12.251361 14303 net.cpp:425] relu6 <- h6
I0705 11:39:12.251366 14303 net.cpp:386] relu6 -> h6 (in-place)
I0705 11:39:12.251533 14303 net.cpp:141] Setting up relu6
I0705 11:39:12.251543 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.251545 14303 net.cpp:156] Memory required for data: 2666012608
I0705 11:39:12.251549 14303 layer_factory.hpp:77] Creating layer bn6_n
I0705 11:39:12.251556 14303 net.cpp:91] Creating Layer bn6_n
I0705 11:39:12.251559 14303 net.cpp:425] bn6_n <- z6_n
I0705 11:39:12.251564 14303 net.cpp:386] bn6_n -> z6_n (in-place)
I0705 11:39:12.251718 14303 net.cpp:141] Setting up bn6_n
I0705 11:39:12.251725 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.251729 14303 net.cpp:156] Memory required for data: 2666799040
I0705 11:39:12.251734 14303 layer_factory.hpp:77] Creating layer noisy_z6_n
I0705 11:39:12.251739 14303 net.cpp:91] Creating Layer noisy_z6_n
I0705 11:39:12.251740 14303 net.cpp:425] noisy_z6_n <- z6_n
I0705 11:39:12.251744 14303 net.cpp:386] noisy_z6_n -> z6_n (in-place)
I0705 11:39:12.251763 14303 net.cpp:141] Setting up noisy_z6_n
I0705 11:39:12.251767 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.251770 14303 net.cpp:156] Memory required for data: 2667585472
I0705 11:39:12.251772 14303 layer_factory.hpp:77] Creating layer z6_n_noisy_z6_n_0_split
I0705 11:39:12.251793 14303 net.cpp:91] Creating Layer z6_n_noisy_z6_n_0_split
I0705 11:39:12.251796 14303 net.cpp:425] z6_n_noisy_z6_n_0_split <- z6_n
I0705 11:39:12.251801 14303 net.cpp:399] z6_n_noisy_z6_n_0_split -> z6_n_noisy_z6_n_0_split_0
I0705 11:39:12.251806 14303 net.cpp:399] z6_n_noisy_z6_n_0_split -> z6_n_noisy_z6_n_0_split_1
I0705 11:39:12.251840 14303 net.cpp:141] Setting up z6_n_noisy_z6_n_0_split
I0705 11:39:12.251844 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.251847 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.251849 14303 net.cpp:156] Memory required for data: 2669158336
I0705 11:39:12.251852 14303 layer_factory.hpp:77] Creating layer scale6_n
I0705 11:39:12.251858 14303 net.cpp:91] Creating Layer scale6_n
I0705 11:39:12.251860 14303 net.cpp:425] scale6_n <- z6_n_noisy_z6_n_0_split_0
I0705 11:39:12.251864 14303 net.cpp:399] scale6_n -> h6_n
I0705 11:39:12.251899 14303 layer_factory.hpp:77] Creating layer scale6_n
I0705 11:39:12.251984 14303 net.cpp:141] Setting up scale6_n
I0705 11:39:12.251991 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.251993 14303 net.cpp:156] Memory required for data: 2669944768
I0705 11:39:12.252002 14303 net.cpp:484] Sharing parameters 'scale6_w' owned by layer 'scale6', param index 0
I0705 11:39:12.252007 14303 net.cpp:484] Sharing parameters 'scale6_b' owned by layer 'scale6', param index 1
I0705 11:39:12.252009 14303 layer_factory.hpp:77] Creating layer relu6_n
I0705 11:39:12.252013 14303 net.cpp:91] Creating Layer relu6_n
I0705 11:39:12.252017 14303 net.cpp:425] relu6_n <- h6_n
I0705 11:39:12.252019 14303 net.cpp:386] relu6_n -> h6_n (in-place)
I0705 11:39:12.252419 14303 net.cpp:141] Setting up relu6_n
I0705 11:39:12.252430 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.252432 14303 net.cpp:156] Memory required for data: 2670731200
I0705 11:39:12.252435 14303 layer_factory.hpp:77] Creating layer u6
I0705 11:39:12.252442 14303 net.cpp:91] Creating Layer u6
I0705 11:39:12.252445 14303 net.cpp:425] u6 <- h6_n
I0705 11:39:12.252454 14303 net.cpp:399] u6 -> u6
I0705 11:39:12.252624 14303 net.cpp:141] Setting up u6
I0705 11:39:12.252631 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.252634 14303 net.cpp:156] Memory required for data: 2671517632
I0705 11:39:12.252640 14303 layer_factory.hpp:77] Creating layer comb6
I0705 11:39:12.252645 14303 net.cpp:91] Creating Layer comb6
I0705 11:39:12.252648 14303 net.cpp:425] comb6 <- z6_n_noisy_z6_n_0_split_1
I0705 11:39:12.252651 14303 net.cpp:425] comb6 <- u6
I0705 11:39:12.252656 14303 net.cpp:399] comb6 -> z6_r
I0705 11:39:12.252954 14303 net.cpp:141] Setting up comb6
I0705 11:39:12.252961 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.252964 14303 net.cpp:156] Memory required for data: 2672304064
I0705 11:39:12.252979 14303 layer_factory.hpp:77] Creating layer z6_r_comb6_0_split
I0705 11:39:12.252985 14303 net.cpp:91] Creating Layer z6_r_comb6_0_split
I0705 11:39:12.252986 14303 net.cpp:425] z6_r_comb6_0_split <- z6_r
I0705 11:39:12.252990 14303 net.cpp:399] z6_r_comb6_0_split -> z6_r_comb6_0_split_0
I0705 11:39:12.252995 14303 net.cpp:399] z6_r_comb6_0_split -> z6_r_comb6_0_split_1
I0705 11:39:12.253029 14303 net.cpp:141] Setting up z6_r_comb6_0_split
I0705 11:39:12.253033 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.253036 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.253038 14303 net.cpp:156] Memory required for data: 2673876928
I0705 11:39:12.253041 14303 layer_factory.hpp:77] Creating layer recon6
I0705 11:39:12.253052 14303 net.cpp:91] Creating Layer recon6
I0705 11:39:12.253056 14303 net.cpp:425] recon6 <- z6_r_comb6_0_split_0
I0705 11:39:12.253060 14303 net.cpp:399] recon6 -> h6_r
I0705 11:39:12.257720 14303 net.cpp:141] Setting up recon6
I0705 11:39:12.257732 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.257735 14303 net.cpp:156] Memory required for data: 2674663360
I0705 11:39:12.257738 14303 net.cpp:484] Sharing parameters 'conv6_w' owned by layer 'conv6', param index 0
I0705 11:39:12.257750 14303 layer_factory.hpp:77] Creating layer bn6_r
I0705 11:39:12.257756 14303 net.cpp:91] Creating Layer bn6_r
I0705 11:39:12.257760 14303 net.cpp:425] bn6_r <- h6_r
I0705 11:39:12.257764 14303 net.cpp:386] bn6_r -> h6_r (in-place)
I0705 11:39:12.257925 14303 net.cpp:141] Setting up bn6_r
I0705 11:39:12.257931 14303 net.cpp:148] Top shape: 16 256 6 8 (196608)
I0705 11:39:12.257933 14303 net.cpp:156] Memory required for data: 2675449792
I0705 11:39:12.257939 14303 layer_factory.hpp:77] Creating layer upsample5
I0705 11:39:12.257946 14303 net.cpp:91] Creating Layer upsample5
I0705 11:39:12.257947 14303 net.cpp:425] upsample5 <- h6_r
I0705 11:39:12.257951 14303 net.cpp:425] upsample5 <- pool5_n_mask
I0705 11:39:12.257956 14303 net.cpp:399] upsample5 -> upsample5
I0705 11:39:12.257962 14303 upsample_layer.cpp:31] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0705 11:39:12.257984 14303 net.cpp:141] Setting up upsample5
I0705 11:39:12.257988 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.257990 14303 net.cpp:156] Memory required for data: 2678595520
I0705 11:39:12.257993 14303 layer_factory.hpp:77] Creating layer comb5
I0705 11:39:12.257997 14303 net.cpp:91] Creating Layer comb5
I0705 11:39:12.258000 14303 net.cpp:425] comb5 <- z5_n_noisy_z5_n_0_split_1
I0705 11:39:12.258004 14303 net.cpp:425] comb5 <- upsample5
I0705 11:39:12.258008 14303 net.cpp:399] comb5 -> z5_r
I0705 11:39:12.259752 14303 net.cpp:141] Setting up comb5
I0705 11:39:12.259764 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.259766 14303 net.cpp:156] Memory required for data: 2681741248
I0705 11:39:12.259776 14303 layer_factory.hpp:77] Creating layer z5_r_comb5_0_split
I0705 11:39:12.259781 14303 net.cpp:91] Creating Layer z5_r_comb5_0_split
I0705 11:39:12.259784 14303 net.cpp:425] z5_r_comb5_0_split <- z5_r
I0705 11:39:12.259788 14303 net.cpp:399] z5_r_comb5_0_split -> z5_r_comb5_0_split_0
I0705 11:39:12.259794 14303 net.cpp:399] z5_r_comb5_0_split -> z5_r_comb5_0_split_1
I0705 11:39:12.259829 14303 net.cpp:141] Setting up z5_r_comb5_0_split
I0705 11:39:12.259832 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.259835 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.259837 14303 net.cpp:156] Memory required for data: 2688032704
I0705 11:39:12.259840 14303 layer_factory.hpp:77] Creating layer recon5
I0705 11:39:12.259846 14303 net.cpp:91] Creating Layer recon5
I0705 11:39:12.259850 14303 net.cpp:425] recon5 <- z5_r_comb5_0_split_0
I0705 11:39:12.259855 14303 net.cpp:399] recon5 -> h5_r
I0705 11:39:12.264417 14303 net.cpp:141] Setting up recon5
I0705 11:39:12.264430 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.264431 14303 net.cpp:156] Memory required for data: 2691178432
I0705 11:39:12.264436 14303 net.cpp:484] Sharing parameters 'conv5_w' owned by layer 'conv5', param index 0
I0705 11:39:12.264438 14303 layer_factory.hpp:77] Creating layer bn5_r
I0705 11:39:12.264446 14303 net.cpp:91] Creating Layer bn5_r
I0705 11:39:12.264448 14303 net.cpp:425] bn5_r <- h5_r
I0705 11:39:12.264452 14303 net.cpp:386] bn5_r -> h5_r (in-place)
I0705 11:39:12.264607 14303 net.cpp:141] Setting up bn5_r
I0705 11:39:12.264614 14303 net.cpp:148] Top shape: 16 256 12 16 (786432)
I0705 11:39:12.264617 14303 net.cpp:156] Memory required for data: 2694324160
I0705 11:39:12.264622 14303 layer_factory.hpp:77] Creating layer upsample4
I0705 11:39:12.264627 14303 net.cpp:91] Creating Layer upsample4
I0705 11:39:12.264631 14303 net.cpp:425] upsample4 <- h5_r
I0705 11:39:12.264634 14303 net.cpp:425] upsample4 <- pool4_n_mask
I0705 11:39:12.264638 14303 net.cpp:399] upsample4 -> upsample4
I0705 11:39:12.264643 14303 upsample_layer.cpp:31] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0705 11:39:12.264663 14303 net.cpp:141] Setting up upsample4
I0705 11:39:12.264678 14303 net.cpp:148] Top shape: 16 256 24 32 (3145728)
I0705 11:39:12.264680 14303 net.cpp:156] Memory required for data: 2706907072
I0705 11:39:12.264683 14303 layer_factory.hpp:77] Creating layer comb4
I0705 11:39:12.264686 14303 net.cpp:91] Creating Layer comb4
I0705 11:39:12.264690 14303 net.cpp:425] comb4 <- z4_n_noisy_z4_n_0_split_1
I0705 11:39:12.264693 14303 net.cpp:425] comb4 <- upsample4
I0705 11:39:12.264698 14303 net.cpp:399] comb4 -> z4_r
I0705 11:39:12.271090 14303 net.cpp:141] Setting up comb4
I0705 11:39:12.271105 14303 net.cpp:148] Top shape: 16 256 24 32 (3145728)
I0705 11:39:12.271107 14303 net.cpp:156] Memory required for data: 2719489984
I0705 11:39:12.271118 14303 layer_factory.hpp:77] Creating layer z4_r_comb4_0_split
I0705 11:39:12.271123 14303 net.cpp:91] Creating Layer z4_r_comb4_0_split
I0705 11:39:12.271127 14303 net.cpp:425] z4_r_comb4_0_split <- z4_r
I0705 11:39:12.271133 14303 net.cpp:399] z4_r_comb4_0_split -> z4_r_comb4_0_split_0
I0705 11:39:12.271138 14303 net.cpp:399] z4_r_comb4_0_split -> z4_r_comb4_0_split_1
I0705 11:39:12.271174 14303 net.cpp:141] Setting up z4_r_comb4_0_split
I0705 11:39:12.271178 14303 net.cpp:148] Top shape: 16 256 24 32 (3145728)
I0705 11:39:12.271181 14303 net.cpp:148] Top shape: 16 256 24 32 (3145728)
I0705 11:39:12.271183 14303 net.cpp:156] Memory required for data: 2744655808
I0705 11:39:12.271185 14303 layer_factory.hpp:77] Creating layer recon4
I0705 11:39:12.271193 14303 net.cpp:91] Creating Layer recon4
I0705 11:39:12.271196 14303 net.cpp:425] recon4 <- z4_r_comb4_0_split_0
I0705 11:39:12.271201 14303 net.cpp:399] recon4 -> h4_r
I0705 11:39:12.273608 14303 net.cpp:141] Setting up recon4
I0705 11:39:12.273619 14303 net.cpp:148] Top shape: 16 128 24 32 (1572864)
I0705 11:39:12.273622 14303 net.cpp:156] Memory required for data: 2750947264
I0705 11:39:12.273627 14303 net.cpp:484] Sharing parameters 'conv4_w' owned by layer 'conv4', param index 0
I0705 11:39:12.273629 14303 layer_factory.hpp:77] Creating layer bn4_r
I0705 11:39:12.273635 14303 net.cpp:91] Creating Layer bn4_r
I0705 11:39:12.273638 14303 net.cpp:425] bn4_r <- h4_r
I0705 11:39:12.273641 14303 net.cpp:386] bn4_r -> h4_r (in-place)
I0705 11:39:12.273807 14303 net.cpp:141] Setting up bn4_r
I0705 11:39:12.273814 14303 net.cpp:148] Top shape: 16 128 24 32 (1572864)
I0705 11:39:12.273818 14303 net.cpp:156] Memory required for data: 2757238720
I0705 11:39:12.273823 14303 layer_factory.hpp:77] Creating layer upsample3
I0705 11:39:12.273829 14303 net.cpp:91] Creating Layer upsample3
I0705 11:39:12.273831 14303 net.cpp:425] upsample3 <- h4_r
I0705 11:39:12.273835 14303 net.cpp:425] upsample3 <- pool3_n_mask
I0705 11:39:12.273839 14303 net.cpp:399] upsample3 -> upsample3
I0705 11:39:12.273844 14303 upsample_layer.cpp:31] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0705 11:39:12.273866 14303 net.cpp:141] Setting up upsample3
I0705 11:39:12.273870 14303 net.cpp:148] Top shape: 16 128 48 64 (6291456)
I0705 11:39:12.273874 14303 net.cpp:156] Memory required for data: 2782404544
I0705 11:39:12.273875 14303 layer_factory.hpp:77] Creating layer comb3
I0705 11:39:12.273880 14303 net.cpp:91] Creating Layer comb3
I0705 11:39:12.273885 14303 net.cpp:425] comb3 <- z3_n_noisy_z3_n_0_split_1
I0705 11:39:12.273887 14303 net.cpp:425] comb3 <- upsample3
I0705 11:39:12.273890 14303 net.cpp:399] comb3 -> z3_r
I0705 11:39:12.283831 14303 net.cpp:141] Setting up comb3
I0705 11:39:12.283851 14303 net.cpp:148] Top shape: 16 128 48 64 (6291456)
I0705 11:39:12.283854 14303 net.cpp:156] Memory required for data: 2807570368
I0705 11:39:12.283867 14303 layer_factory.hpp:77] Creating layer z3_r_comb3_0_split
I0705 11:39:12.283876 14303 net.cpp:91] Creating Layer z3_r_comb3_0_split
I0705 11:39:12.283880 14303 net.cpp:425] z3_r_comb3_0_split <- z3_r
I0705 11:39:12.283885 14303 net.cpp:399] z3_r_comb3_0_split -> z3_r_comb3_0_split_0
I0705 11:39:12.283892 14303 net.cpp:399] z3_r_comb3_0_split -> z3_r_comb3_0_split_1
I0705 11:39:12.283934 14303 net.cpp:141] Setting up z3_r_comb3_0_split
I0705 11:39:12.283951 14303 net.cpp:148] Top shape: 16 128 48 64 (6291456)
I0705 11:39:12.283953 14303 net.cpp:148] Top shape: 16 128 48 64 (6291456)
I0705 11:39:12.283956 14303 net.cpp:156] Memory required for data: 2857902016
I0705 11:39:12.283958 14303 layer_factory.hpp:77] Creating layer recon3
I0705 11:39:12.283965 14303 net.cpp:91] Creating Layer recon3
I0705 11:39:12.283968 14303 net.cpp:425] recon3 <- z3_r_comb3_0_split_0
I0705 11:39:12.283974 14303 net.cpp:399] recon3 -> h3_r
I0705 11:39:12.284579 14303 net.cpp:141] Setting up recon3
I0705 11:39:12.284586 14303 net.cpp:148] Top shape: 16 64 48 64 (3145728)
I0705 11:39:12.284589 14303 net.cpp:156] Memory required for data: 2870484928
I0705 11:39:12.284592 14303 net.cpp:484] Sharing parameters 'conv3_w' owned by layer 'conv3', param index 0
I0705 11:39:12.284595 14303 layer_factory.hpp:77] Creating layer bn3_r
I0705 11:39:12.284602 14303 net.cpp:91] Creating Layer bn3_r
I0705 11:39:12.284605 14303 net.cpp:425] bn3_r <- h3_r
I0705 11:39:12.284608 14303 net.cpp:386] bn3_r -> h3_r (in-place)
I0705 11:39:12.284790 14303 net.cpp:141] Setting up bn3_r
I0705 11:39:12.284797 14303 net.cpp:148] Top shape: 16 64 48 64 (3145728)
I0705 11:39:12.284800 14303 net.cpp:156] Memory required for data: 2883067840
I0705 11:39:12.284804 14303 layer_factory.hpp:77] Creating layer upsample2
I0705 11:39:12.284811 14303 net.cpp:91] Creating Layer upsample2
I0705 11:39:12.284814 14303 net.cpp:425] upsample2 <- h3_r
I0705 11:39:12.284818 14303 net.cpp:425] upsample2 <- pool2_n_mask
I0705 11:39:12.284822 14303 net.cpp:399] upsample2 -> upsample2
I0705 11:39:12.284827 14303 upsample_layer.cpp:31] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0705 11:39:12.284848 14303 net.cpp:141] Setting up upsample2
I0705 11:39:12.284853 14303 net.cpp:148] Top shape: 16 64 96 128 (12582912)
I0705 11:39:12.284855 14303 net.cpp:156] Memory required for data: 2933399488
I0705 11:39:12.284857 14303 layer_factory.hpp:77] Creating layer comb2
I0705 11:39:12.284862 14303 net.cpp:91] Creating Layer comb2
I0705 11:39:12.284867 14303 net.cpp:425] comb2 <- z2_n_noisy_z2_n_0_split_1
I0705 11:39:12.284869 14303 net.cpp:425] comb2 <- upsample2
I0705 11:39:12.284873 14303 net.cpp:399] comb2 -> z2_r
I0705 11:39:12.302453 14303 net.cpp:141] Setting up comb2
I0705 11:39:12.302480 14303 net.cpp:148] Top shape: 16 64 96 128 (12582912)
I0705 11:39:12.302484 14303 net.cpp:156] Memory required for data: 2983731136
I0705 11:39:12.302511 14303 layer_factory.hpp:77] Creating layer z2_r_comb2_0_split
I0705 11:39:12.302521 14303 net.cpp:91] Creating Layer z2_r_comb2_0_split
I0705 11:39:12.302525 14303 net.cpp:425] z2_r_comb2_0_split <- z2_r
I0705 11:39:12.302531 14303 net.cpp:399] z2_r_comb2_0_split -> z2_r_comb2_0_split_0
I0705 11:39:12.302539 14303 net.cpp:399] z2_r_comb2_0_split -> z2_r_comb2_0_split_1
I0705 11:39:12.302583 14303 net.cpp:141] Setting up z2_r_comb2_0_split
I0705 11:39:12.302587 14303 net.cpp:148] Top shape: 16 64 96 128 (12582912)
I0705 11:39:12.302590 14303 net.cpp:148] Top shape: 16 64 96 128 (12582912)
I0705 11:39:12.302592 14303 net.cpp:156] Memory required for data: 3084394432
I0705 11:39:12.302595 14303 layer_factory.hpp:77] Creating layer recon2
I0705 11:39:12.302603 14303 net.cpp:91] Creating Layer recon2
I0705 11:39:12.302606 14303 net.cpp:425] recon2 <- z2_r_comb2_0_split_0
I0705 11:39:12.302613 14303 net.cpp:399] recon2 -> h2_r
I0705 11:39:12.302904 14303 net.cpp:141] Setting up recon2
I0705 11:39:12.302911 14303 net.cpp:148] Top shape: 16 32 96 128 (6291456)
I0705 11:39:12.302913 14303 net.cpp:156] Memory required for data: 3109560256
I0705 11:39:12.302917 14303 net.cpp:484] Sharing parameters 'conv2_w' owned by layer 'conv2', param index 0
I0705 11:39:12.302920 14303 layer_factory.hpp:77] Creating layer bn2_r
I0705 11:39:12.302927 14303 net.cpp:91] Creating Layer bn2_r
I0705 11:39:12.302928 14303 net.cpp:425] bn2_r <- h2_r
I0705 11:39:12.302932 14303 net.cpp:386] bn2_r -> h2_r (in-place)
I0705 11:39:12.303144 14303 net.cpp:141] Setting up bn2_r
I0705 11:39:12.303153 14303 net.cpp:148] Top shape: 16 32 96 128 (6291456)
I0705 11:39:12.303154 14303 net.cpp:156] Memory required for data: 3134726080
I0705 11:39:12.303160 14303 layer_factory.hpp:77] Creating layer upsample1
I0705 11:39:12.303166 14303 net.cpp:91] Creating Layer upsample1
I0705 11:39:12.303169 14303 net.cpp:425] upsample1 <- h2_r
I0705 11:39:12.303174 14303 net.cpp:425] upsample1 <- pool1_n_mask
I0705 11:39:12.303179 14303 net.cpp:399] upsample1 -> upsample1
I0705 11:39:12.303184 14303 upsample_layer.cpp:31] Params 'pad_out_{}_' are deprecated. Please declare upsample height and width useing the upsample_h, upsample_w parameters.
I0705 11:39:12.303205 14303 net.cpp:141] Setting up upsample1
I0705 11:39:12.303210 14303 net.cpp:148] Top shape: 16 32 192 256 (25165824)
I0705 11:39:12.303212 14303 net.cpp:156] Memory required for data: 3235389376
I0705 11:39:12.303215 14303 layer_factory.hpp:77] Creating layer comb1
I0705 11:39:12.303220 14303 net.cpp:91] Creating Layer comb1
I0705 11:39:12.303222 14303 net.cpp:425] comb1 <- z1_n_noisy_z1_n_0_split_1
I0705 11:39:12.303225 14303 net.cpp:425] comb1 <- upsample1
I0705 11:39:12.303231 14303 net.cpp:399] comb1 -> z1_r
I0705 11:39:12.337678 14303 net.cpp:141] Setting up comb1
I0705 11:39:12.337703 14303 net.cpp:148] Top shape: 16 32 192 256 (25165824)
I0705 11:39:12.337707 14303 net.cpp:156] Memory required for data: 3336052672
I0705 11:39:12.337723 14303 layer_factory.hpp:77] Creating layer z1_r_comb1_0_split
I0705 11:39:12.337733 14303 net.cpp:91] Creating Layer z1_r_comb1_0_split
I0705 11:39:12.337736 14303 net.cpp:425] z1_r_comb1_0_split <- z1_r
I0705 11:39:12.337743 14303 net.cpp:399] z1_r_comb1_0_split -> z1_r_comb1_0_split_0
I0705 11:39:12.337749 14303 net.cpp:399] z1_r_comb1_0_split -> z1_r_comb1_0_split_1
I0705 11:39:12.337795 14303 net.cpp:141] Setting up z1_r_comb1_0_split
I0705 11:39:12.337800 14303 net.cpp:148] Top shape: 16 32 192 256 (25165824)
I0705 11:39:12.337802 14303 net.cpp:148] Top shape: 16 32 192 256 (25165824)
I0705 11:39:12.337805 14303 net.cpp:156] Memory required for data: 3537379264
I0705 11:39:12.337806 14303 layer_factory.hpp:77] Creating layer recon1
I0705 11:39:12.337815 14303 net.cpp:91] Creating Layer recon1
I0705 11:39:12.337817 14303 net.cpp:425] recon1 <- z1_r_comb1_0_split_0
I0705 11:39:12.337822 14303 net.cpp:399] recon1 -> h1_r
I0705 11:39:12.338017 14303 net.cpp:141] Setting up recon1
I0705 11:39:12.338024 14303 net.cpp:148] Top shape: 16 1 192 256 (786432)
I0705 11:39:12.338027 14303 net.cpp:156] Memory required for data: 3540524992
I0705 11:39:12.338032 14303 net.cpp:484] Sharing parameters 'conv1_w' owned by layer 'conv1', param index 0
I0705 11:39:12.338034 14303 layer_factory.hpp:77] Creating layer bn1_r
I0705 11:39:12.338040 14303 net.cpp:91] Creating Layer bn1_r
I0705 11:39:12.338043 14303 net.cpp:425] bn1_r <- h1_r
I0705 11:39:12.338047 14303 net.cpp:386] bn1_r -> h1_r (in-place)
I0705 11:39:12.338266 14303 net.cpp:141] Setting up bn1_r
I0705 11:39:12.338274 14303 net.cpp:148] Top shape: 16 1 192 256 (786432)
I0705 11:39:12.338275 14303 net.cpp:156] Memory required for data: 3543670720
I0705 11:39:12.338284 14303 layer_factory.hpp:77] Creating layer comb0
I0705 11:39:12.338290 14303 net.cpp:91] Creating Layer comb0
I0705 11:39:12.338294 14303 net.cpp:425] comb0 <- noisy_data_noisy_data_0_split_1
I0705 11:39:12.338299 14303 net.cpp:425] comb0 <- h1_r
I0705 11:39:12.338302 14303 net.cpp:399] comb0 -> z0_r
I0705 11:39:12.340016 14303 net.cpp:141] Setting up comb0
I0705 11:39:12.340029 14303 net.cpp:148] Top shape: 16 1 192 256 (786432)
I0705 11:39:12.340031 14303 net.cpp:156] Memory required for data: 3546816448
I0705 11:39:12.340040 14303 layer_factory.hpp:77] Creating layer loss_ladder_6
I0705 11:39:12.340049 14303 net.cpp:91] Creating Layer loss_ladder_6
I0705 11:39:12.340051 14303 net.cpp:425] loss_ladder_6 <- z6_bn6_0_split_1
I0705 11:39:12.340056 14303 net.cpp:425] loss_ladder_6 <- z6_r_comb6_0_split_1
I0705 11:39:12.340059 14303 net.cpp:425] loss_ladder_6 <- bn6_param
I0705 11:39:12.340078 14303 net.cpp:399] loss_ladder_6 -> loss_ladder_6
I0705 11:39:12.340203 14303 net.cpp:141] Setting up loss_ladder_6
I0705 11:39:12.340209 14303 net.cpp:148] Top shape: (1)
I0705 11:39:12.340212 14303 net.cpp:151]     with loss weight 0.1
I0705 11:39:12.340229 14303 net.cpp:156] Memory required for data: 3546816452
I0705 11:39:12.340231 14303 layer_factory.hpp:77] Creating layer loss_ladder_5
I0705 11:39:12.340236 14303 net.cpp:91] Creating Layer loss_ladder_5
I0705 11:39:12.340240 14303 net.cpp:425] loss_ladder_5 <- z5_bn5_0_split_1
I0705 11:39:12.340243 14303 net.cpp:425] loss_ladder_5 <- z5_r_comb5_0_split_1
I0705 11:39:12.340246 14303 net.cpp:425] loss_ladder_5 <- bn5_param
I0705 11:39:12.340252 14303 net.cpp:399] loss_ladder_5 -> loss_ladder_5
I0705 11:39:12.340360 14303 net.cpp:141] Setting up loss_ladder_5
I0705 11:39:12.340366 14303 net.cpp:148] Top shape: (1)
I0705 11:39:12.340369 14303 net.cpp:151]     with loss weight 0.1
I0705 11:39:12.340373 14303 net.cpp:156] Memory required for data: 3546816456
I0705 11:39:12.340376 14303 layer_factory.hpp:77] Creating layer loss_ladder_4
I0705 11:39:12.340380 14303 net.cpp:91] Creating Layer loss_ladder_4
I0705 11:39:12.340384 14303 net.cpp:425] loss_ladder_4 <- z4_bn4_0_split_1
I0705 11:39:12.340387 14303 net.cpp:425] loss_ladder_4 <- z4_r_comb4_0_split_1
I0705 11:39:12.340391 14303 net.cpp:425] loss_ladder_4 <- bn4_param
I0705 11:39:12.340395 14303 net.cpp:399] loss_ladder_4 -> loss_ladder_4
I0705 11:39:12.340503 14303 net.cpp:141] Setting up loss_ladder_4
I0705 11:39:12.340508 14303 net.cpp:148] Top shape: (1)
I0705 11:39:12.340512 14303 net.cpp:151]     with loss weight 0.1
I0705 11:39:12.340514 14303 net.cpp:156] Memory required for data: 3546816460
I0705 11:39:12.340517 14303 layer_factory.hpp:77] Creating layer loss_ladder_3
I0705 11:39:12.340522 14303 net.cpp:91] Creating Layer loss_ladder_3
I0705 11:39:12.340524 14303 net.cpp:425] loss_ladder_3 <- z3_bn3_0_split_1
I0705 11:39:12.340528 14303 net.cpp:425] loss_ladder_3 <- z3_r_comb3_0_split_1
I0705 11:39:12.340530 14303 net.cpp:425] loss_ladder_3 <- bn3_param
I0705 11:39:12.340538 14303 net.cpp:399] loss_ladder_3 -> loss_ladder_3
I0705 11:39:12.340641 14303 net.cpp:141] Setting up loss_ladder_3
I0705 11:39:12.340646 14303 net.cpp:148] Top shape: (1)
I0705 11:39:12.340648 14303 net.cpp:151]     with loss weight 0.1
I0705 11:39:12.340652 14303 net.cpp:156] Memory required for data: 3546816464
I0705 11:39:12.340654 14303 layer_factory.hpp:77] Creating layer loss_ladder_2
I0705 11:39:12.340658 14303 net.cpp:91] Creating Layer loss_ladder_2
I0705 11:39:12.340662 14303 net.cpp:425] loss_ladder_2 <- z2_bn2_0_split_1
I0705 11:39:12.340664 14303 net.cpp:425] loss_ladder_2 <- z2_r_comb2_0_split_1
I0705 11:39:12.340667 14303 net.cpp:425] loss_ladder_2 <- bn2_param
I0705 11:39:12.340670 14303 net.cpp:399] loss_ladder_2 -> loss_ladder_2
I0705 11:39:12.340782 14303 net.cpp:141] Setting up loss_ladder_2
I0705 11:39:12.340790 14303 net.cpp:148] Top shape: (1)
I0705 11:39:12.340791 14303 net.cpp:151]     with loss weight 0.1
I0705 11:39:12.340795 14303 net.cpp:156] Memory required for data: 3546816468
I0705 11:39:12.340797 14303 layer_factory.hpp:77] Creating layer loss_ladder_1
I0705 11:39:12.340803 14303 net.cpp:91] Creating Layer loss_ladder_1
I0705 11:39:12.340806 14303 net.cpp:425] loss_ladder_1 <- z1_bn1_0_split_1
I0705 11:39:12.340809 14303 net.cpp:425] loss_ladder_1 <- z1_r_comb1_0_split_1
I0705 11:39:12.340812 14303 net.cpp:425] loss_ladder_1 <- bn1_param
I0705 11:39:12.340816 14303 net.cpp:399] loss_ladder_1 -> loss_ladder_1
I0705 11:39:12.340944 14303 net.cpp:141] Setting up loss_ladder_1
I0705 11:39:12.340950 14303 net.cpp:148] Top shape: (1)
I0705 11:39:12.340951 14303 net.cpp:151]     with loss weight 0.1
I0705 11:39:12.340955 14303 net.cpp:156] Memory required for data: 3546816472
I0705 11:39:12.340957 14303 layer_factory.hpp:77] Creating layer loss_ladder_0
I0705 11:39:12.340962 14303 net.cpp:91] Creating Layer loss_ladder_0
I0705 11:39:12.340965 14303 net.cpp:425] loss_ladder_0 <- noisy_data_noisy_data_0_split_2
I0705 11:39:12.340976 14303 net.cpp:425] loss_ladder_0 <- z0_r
I0705 11:39:12.340981 14303 net.cpp:399] loss_ladder_0 -> loss_ladder_0
I0705 11:39:12.341030 14303 net.cpp:141] Setting up loss_ladder_0
I0705 11:39:12.341035 14303 net.cpp:148] Top shape: (1)
I0705 11:39:12.341038 14303 net.cpp:151]     with loss weight 0.1
I0705 11:39:12.341042 14303 net.cpp:156] Memory required for data: 3546816476
I0705 11:39:12.341044 14303 layer_factory.hpp:77] Creating layer pool_final
I0705 11:39:12.341050 14303 net.cpp:91] Creating Layer pool_final
I0705 11:39:12.341053 14303 net.cpp:425] pool_final <- h6
I0705 11:39:12.341058 14303 net.cpp:399] pool_final -> pool_final
I0705 11:39:12.341295 14303 net.cpp:141] Setting up pool_final
I0705 11:39:12.341305 14303 net.cpp:148] Top shape: 16 256 1 1 (4096)
I0705 11:39:12.341307 14303 net.cpp:156] Memory required for data: 3546832860
I0705 11:39:12.341310 14303 layer_factory.hpp:77] Creating layer score
I0705 11:39:12.341317 14303 net.cpp:91] Creating Layer score
I0705 11:39:12.341320 14303 net.cpp:425] score <- pool_final
I0705 11:39:12.341325 14303 net.cpp:399] score -> score
I0705 11:39:12.341434 14303 net.cpp:141] Setting up score
I0705 11:39:12.341440 14303 net.cpp:148] Top shape: 16 2 (32)
I0705 11:39:12.341444 14303 net.cpp:156] Memory required for data: 3546832988
I0705 11:39:12.341447 14303 layer_factory.hpp:77] Creating layer score_score_0_split
I0705 11:39:12.341452 14303 net.cpp:91] Creating Layer score_score_0_split
I0705 11:39:12.341454 14303 net.cpp:425] score_score_0_split <- score
I0705 11:39:12.341459 14303 net.cpp:399] score_score_0_split -> score_score_0_split_0
I0705 11:39:12.341464 14303 net.cpp:399] score_score_0_split -> score_score_0_split_1
I0705 11:39:12.341498 14303 net.cpp:141] Setting up score_score_0_split
I0705 11:39:12.341503 14303 net.cpp:148] Top shape: 16 2 (32)
I0705 11:39:12.341506 14303 net.cpp:148] Top shape: 16 2 (32)
I0705 11:39:12.341507 14303 net.cpp:156] Memory required for data: 3546833244
I0705 11:39:12.341511 14303 layer_factory.hpp:77] Creating layer loss_supervised
I0705 11:39:12.341514 14303 net.cpp:91] Creating Layer loss_supervised
I0705 11:39:12.341516 14303 net.cpp:425] loss_supervised <- score_score_0_split_0
I0705 11:39:12.341521 14303 net.cpp:425] loss_supervised <- label_data_1_split_0
I0705 11:39:12.341524 14303 net.cpp:399] loss_supervised -> loss_supervised
I0705 11:39:12.341531 14303 layer_factory.hpp:77] Creating layer loss_supervised
I0705 11:39:12.341938 14303 net.cpp:141] Setting up loss_supervised
I0705 11:39:12.341948 14303 net.cpp:148] Top shape: (1)
I0705 11:39:12.341951 14303 net.cpp:151]     with loss weight 1
I0705 11:39:12.341956 14303 net.cpp:156] Memory required for data: 3546833248
I0705 11:39:12.341958 14303 layer_factory.hpp:77] Creating layer accuracy
I0705 11:39:12.341964 14303 net.cpp:91] Creating Layer accuracy
I0705 11:39:12.341966 14303 net.cpp:425] accuracy <- score_score_0_split_1
I0705 11:39:12.341970 14303 net.cpp:425] accuracy <- label_data_1_split_1
I0705 11:39:12.341975 14303 net.cpp:399] accuracy -> accuracy
I0705 11:39:12.341991 14303 net.cpp:141] Setting up accuracy
I0705 11:39:12.341996 14303 net.cpp:148] Top shape: (1)
I0705 11:39:12.341998 14303 net.cpp:156] Memory required for data: 3546833252
I0705 11:39:12.342000 14303 net.cpp:219] accuracy does not need backward computation.
I0705 11:39:12.342003 14303 net.cpp:217] loss_supervised needs backward computation.
I0705 11:39:12.342005 14303 net.cpp:217] score_score_0_split needs backward computation.
I0705 11:39:12.342008 14303 net.cpp:217] score needs backward computation.
I0705 11:39:12.342010 14303 net.cpp:217] pool_final needs backward computation.
I0705 11:39:12.342012 14303 net.cpp:217] loss_ladder_0 needs backward computation.
I0705 11:39:12.342015 14303 net.cpp:217] loss_ladder_1 needs backward computation.
I0705 11:39:12.342017 14303 net.cpp:217] loss_ladder_2 needs backward computation.
I0705 11:39:12.342020 14303 net.cpp:217] loss_ladder_3 needs backward computation.
I0705 11:39:12.342023 14303 net.cpp:217] loss_ladder_4 needs backward computation.
I0705 11:39:12.342034 14303 net.cpp:217] loss_ladder_5 needs backward computation.
I0705 11:39:12.342037 14303 net.cpp:217] loss_ladder_6 needs backward computation.
I0705 11:39:12.342039 14303 net.cpp:217] comb0 needs backward computation.
I0705 11:39:12.342042 14303 net.cpp:217] bn1_r needs backward computation.
I0705 11:39:12.342046 14303 net.cpp:217] recon1 needs backward computation.
I0705 11:39:12.342047 14303 net.cpp:217] z1_r_comb1_0_split needs backward computation.
I0705 11:39:12.342051 14303 net.cpp:217] comb1 needs backward computation.
I0705 11:39:12.342053 14303 net.cpp:217] upsample1 needs backward computation.
I0705 11:39:12.342056 14303 net.cpp:217] bn2_r needs backward computation.
I0705 11:39:12.342059 14303 net.cpp:217] recon2 needs backward computation.
I0705 11:39:12.342061 14303 net.cpp:217] z2_r_comb2_0_split needs backward computation.
I0705 11:39:12.342064 14303 net.cpp:217] comb2 needs backward computation.
I0705 11:39:12.342067 14303 net.cpp:217] upsample2 needs backward computation.
I0705 11:39:12.342070 14303 net.cpp:217] bn3_r needs backward computation.
I0705 11:39:12.342072 14303 net.cpp:217] recon3 needs backward computation.
I0705 11:39:12.342074 14303 net.cpp:217] z3_r_comb3_0_split needs backward computation.
I0705 11:39:12.342077 14303 net.cpp:217] comb3 needs backward computation.
I0705 11:39:12.342082 14303 net.cpp:217] upsample3 needs backward computation.
I0705 11:39:12.342084 14303 net.cpp:217] bn4_r needs backward computation.
I0705 11:39:12.342087 14303 net.cpp:217] recon4 needs backward computation.
I0705 11:39:12.342089 14303 net.cpp:217] z4_r_comb4_0_split needs backward computation.
I0705 11:39:12.342092 14303 net.cpp:217] comb4 needs backward computation.
I0705 11:39:12.342094 14303 net.cpp:217] upsample4 needs backward computation.
I0705 11:39:12.342097 14303 net.cpp:217] bn5_r needs backward computation.
I0705 11:39:12.342099 14303 net.cpp:217] recon5 needs backward computation.
I0705 11:39:12.342102 14303 net.cpp:217] z5_r_comb5_0_split needs backward computation.
I0705 11:39:12.342103 14303 net.cpp:217] comb5 needs backward computation.
I0705 11:39:12.342106 14303 net.cpp:217] upsample5 needs backward computation.
I0705 11:39:12.342109 14303 net.cpp:217] bn6_r needs backward computation.
I0705 11:39:12.342111 14303 net.cpp:217] recon6 needs backward computation.
I0705 11:39:12.342114 14303 net.cpp:217] z6_r_comb6_0_split needs backward computation.
I0705 11:39:12.342116 14303 net.cpp:217] comb6 needs backward computation.
I0705 11:39:12.342119 14303 net.cpp:217] u6 needs backward computation.
I0705 11:39:12.342121 14303 net.cpp:217] relu6_n needs backward computation.
I0705 11:39:12.342123 14303 net.cpp:217] scale6_n needs backward computation.
I0705 11:39:12.342126 14303 net.cpp:217] z6_n_noisy_z6_n_0_split needs backward computation.
I0705 11:39:12.342129 14303 net.cpp:217] noisy_z6_n needs backward computation.
I0705 11:39:12.342131 14303 net.cpp:217] bn6_n needs backward computation.
I0705 11:39:12.342134 14303 net.cpp:217] relu6 needs backward computation.
I0705 11:39:12.342136 14303 net.cpp:217] scale6 needs backward computation.
I0705 11:39:12.342139 14303 net.cpp:217] z6_bn6_0_split needs backward computation.
I0705 11:39:12.342142 14303 net.cpp:217] bn6 needs backward computation.
I0705 11:39:12.342144 14303 net.cpp:217] conv6 needs backward computation.
I0705 11:39:12.342147 14303 net.cpp:217] pool5_n needs backward computation.
I0705 11:39:12.342150 14303 net.cpp:217] pool5 needs backward computation.
I0705 11:39:12.342152 14303 net.cpp:217] relu5_n needs backward computation.
I0705 11:39:12.342155 14303 net.cpp:217] scale5_n needs backward computation.
I0705 11:39:12.342157 14303 net.cpp:217] z5_n_noisy_z5_n_0_split needs backward computation.
I0705 11:39:12.342160 14303 net.cpp:217] noisy_z5_n needs backward computation.
I0705 11:39:12.342162 14303 net.cpp:217] bn5_n needs backward computation.
I0705 11:39:12.342165 14303 net.cpp:217] relu5 needs backward computation.
I0705 11:39:12.342167 14303 net.cpp:217] scale5 needs backward computation.
I0705 11:39:12.342175 14303 net.cpp:217] z5_bn5_0_split needs backward computation.
I0705 11:39:12.342176 14303 net.cpp:217] bn5 needs backward computation.
I0705 11:39:12.342180 14303 net.cpp:217] conv5 needs backward computation.
I0705 11:39:12.342182 14303 net.cpp:217] pool4_n needs backward computation.
I0705 11:39:12.342185 14303 net.cpp:217] pool4 needs backward computation.
I0705 11:39:12.342187 14303 net.cpp:217] relu4_n needs backward computation.
I0705 11:39:12.342190 14303 net.cpp:217] scale4_n needs backward computation.
I0705 11:39:12.342192 14303 net.cpp:217] z4_n_noisy_z4_n_0_split needs backward computation.
I0705 11:39:12.342195 14303 net.cpp:217] noisy_z4_n needs backward computation.
I0705 11:39:12.342197 14303 net.cpp:217] bn4_n needs backward computation.
I0705 11:39:12.342200 14303 net.cpp:217] relu4 needs backward computation.
I0705 11:39:12.342201 14303 net.cpp:217] scale4 needs backward computation.
I0705 11:39:12.342205 14303 net.cpp:217] z4_bn4_0_split needs backward computation.
I0705 11:39:12.342206 14303 net.cpp:217] bn4 needs backward computation.
I0705 11:39:12.342209 14303 net.cpp:217] conv4 needs backward computation.
I0705 11:39:12.342212 14303 net.cpp:217] pool3_n needs backward computation.
I0705 11:39:12.342214 14303 net.cpp:217] pool3 needs backward computation.
I0705 11:39:12.342217 14303 net.cpp:217] relu3_n needs backward computation.
I0705 11:39:12.342219 14303 net.cpp:217] scale3_n needs backward computation.
I0705 11:39:12.342222 14303 net.cpp:217] z3_n_noisy_z3_n_0_split needs backward computation.
I0705 11:39:12.342224 14303 net.cpp:217] noisy_z3_n needs backward computation.
I0705 11:39:12.342227 14303 net.cpp:217] bn3_n needs backward computation.
I0705 11:39:12.342229 14303 net.cpp:217] relu3 needs backward computation.
I0705 11:39:12.342231 14303 net.cpp:217] scale3 needs backward computation.
I0705 11:39:12.342234 14303 net.cpp:217] z3_bn3_0_split needs backward computation.
I0705 11:39:12.342237 14303 net.cpp:217] bn3 needs backward computation.
I0705 11:39:12.342239 14303 net.cpp:217] conv3 needs backward computation.
I0705 11:39:12.342242 14303 net.cpp:217] pool2_n needs backward computation.
I0705 11:39:12.342245 14303 net.cpp:217] pool2 needs backward computation.
I0705 11:39:12.342247 14303 net.cpp:217] relu2_n needs backward computation.
I0705 11:39:12.342250 14303 net.cpp:217] scale2_n needs backward computation.
I0705 11:39:12.342252 14303 net.cpp:217] z2_n_noisy_z2_n_0_split needs backward computation.
I0705 11:39:12.342255 14303 net.cpp:217] noisy_z2_n needs backward computation.
I0705 11:39:12.342257 14303 net.cpp:217] bn2_n needs backward computation.
I0705 11:39:12.342259 14303 net.cpp:217] relu2 needs backward computation.
I0705 11:39:12.342262 14303 net.cpp:217] scale2 needs backward computation.
I0705 11:39:12.342264 14303 net.cpp:217] z2_bn2_0_split needs backward computation.
I0705 11:39:12.342267 14303 net.cpp:217] bn2 needs backward computation.
I0705 11:39:12.342269 14303 net.cpp:217] conv2 needs backward computation.
I0705 11:39:12.342272 14303 net.cpp:217] pool1_n needs backward computation.
I0705 11:39:12.342275 14303 net.cpp:217] pool1 needs backward computation.
I0705 11:39:12.342278 14303 net.cpp:217] relu1_n needs backward computation.
I0705 11:39:12.342280 14303 net.cpp:217] scale1_n needs backward computation.
I0705 11:39:12.342283 14303 net.cpp:217] z1_n_noisy_z1_n_0_split needs backward computation.
I0705 11:39:12.342285 14303 net.cpp:217] noisy_z1_n needs backward computation.
I0705 11:39:12.342288 14303 net.cpp:217] bn1_n needs backward computation.
I0705 11:39:12.342290 14303 net.cpp:217] relu1 needs backward computation.
I0705 11:39:12.342293 14303 net.cpp:217] scale1 needs backward computation.
I0705 11:39:12.342295 14303 net.cpp:217] z1_bn1_0_split needs backward computation.
I0705 11:39:12.342298 14303 net.cpp:217] bn1 needs backward computation.
I0705 11:39:12.342300 14303 net.cpp:217] conv1 needs backward computation.
I0705 11:39:12.342304 14303 net.cpp:219] noisy_data_noisy_data_0_split does not need backward computation.
I0705 11:39:12.342311 14303 net.cpp:219] noisy_data does not need backward computation.
I0705 11:39:12.342315 14303 net.cpp:219] label_data_1_split does not need backward computation.
I0705 11:39:12.342319 14303 net.cpp:219] data_data_0_split does not need backward computation.
I0705 11:39:12.342321 14303 net.cpp:219] data does not need backward computation.
I0705 11:39:12.342324 14303 net.cpp:261] This network produces output accuracy
I0705 11:39:12.342325 14303 net.cpp:261] This network produces output loss_ladder_0
I0705 11:39:12.342329 14303 net.cpp:261] This network produces output loss_ladder_1
I0705 11:39:12.342331 14303 net.cpp:261] This network produces output loss_ladder_2
I0705 11:39:12.342334 14303 net.cpp:261] This network produces output loss_ladder_3
I0705 11:39:12.342335 14303 net.cpp:261] This network produces output loss_ladder_4
I0705 11:39:12.342339 14303 net.cpp:261] This network produces output loss_ladder_5
I0705 11:39:12.342340 14303 net.cpp:261] This network produces output loss_ladder_6
I0705 11:39:12.342342 14303 net.cpp:261] This network produces output loss_supervised
I0705 11:39:12.343463 14303 net.cpp:274] Network initialization done.
I0705 11:39:12.344220 14303 solver.cpp:181] Creating test net (#0) specified by test_net file: models/laddernet/val.prototxt
I0705 11:39:12.344419 14303 net.cpp:49] Initializing net from parameters: 
name: "LadderNet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    scale: 0.0039215
    mirror: false
    mean_value: 100
    crop_h: 192
    crop_w: 256
  }
  data_param {
    source: "data/val_lmdb"
    batch_size: 8
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "z1_pre"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "z1_pre"
  top: "z1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "z1"
  top: "z1"
  param {
    name: "scale1_w"
  }
  param {
    name: "scale1_b"
  }
  scale_param {
    filler {
      type: "xavier"
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "z1"
  top: "z1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "z1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "z2_pre"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "z2_pre"
  top: "z2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "z2"
  top: "z2"
  param {
    name: "scale2_w"
  }
  param {
    name: "scale2_b"
  }
  scale_param {
    filler {
      type: "xavier"
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "z2"
  top: "z2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "z2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "pool2"
  top: "z3_pre"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "z3_pre"
  top: "z3"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "z3"
  top: "z3"
  param {
    name: "scale3_w"
  }
  param {
    name: "scale3_b"
  }
  scale_param {
    filler {
      type: "xavier"
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "z3"
  top: "z3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "z3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "pool3"
  top: "z4_pre"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "z4_pre"
  top: "z4"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "z4"
  top: "z4"
  param {
    name: "scale4_w"
  }
  param {
    name: "scale4_b"
  }
  scale_param {
    filler {
      type: "xavier"
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "z4"
  top: "z4"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "z4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5"
  type: "Convolution"
  bottom: "pool4"
  top: "z5_pre"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5"
  type: "BatchNorm"
  bottom: "z5_pre"
  top: "z5"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "scale5"
  type: "Scale"
  bottom: "z5"
  top: "z5"
  param {
    name: "scale5_w"
  }
  param {
    name: "scale5_b"
  }
  scale_param {
    filler {
      type: "xavier"
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5"
  type: "ReLU"
  bottom: "z5"
  top: "z5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "z5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv6"
  type: "Convolution"
  bottom: "pool5"
  top: "z6_pre"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn6"
  type: "BatchNorm"
  bottom: "z6_pre"
  top: "z6"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: true
    eps: 0.001
  }
}
layer {
  name: "scale6"
  type: "Scale"
  bottom: "z6"
  top: "z6"
  param {
    name: "scale6_w"
  }
  param {
    name: "scale6_b"
  }
  scale_param {
    filler {
      type: "xavier"
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu6"
  type: "ReLU"
  bottom: "z6"
  top: "z6"
}
layer {
  name: "pool_final"
  type: "Pooling"
  bottom: "z6"
  top: "pool_final"
  pooling_param {
    pool: AVE
    stride: 1
    kernel_h: 6
    kernel_w: 8
  }
}
layer {
  name: "score"
  type: "InnerProduct"
  bottom: "pool_final"
  top: "score"
  inner_product_param {
    num_output: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "prob"
  type: "SoftmaxWithLoss"
  bottom: "score"
  bottom: "label"
  top: "prob"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "score"
  bottom: "label"
  top: "accuracy"
}
I0705 11:39:12.344537 14303 layer_factory.hpp:77] Creating layer data
I0705 11:39:12.344589 14303 net.cpp:91] Creating Layer data
I0705 11:39:12.344595 14303 net.cpp:399] data -> data
I0705 11:39:12.344602 14303 net.cpp:399] data -> label
I0705 11:39:12.345903 14317 db_lmdb.cpp:35] Opened lmdb data/val_lmdb
I0705 11:39:12.346173 14303 data_layer.cpp:42] output data size: 8,1,192,256
I0705 11:39:12.350070 14303 net.cpp:141] Setting up data
I0705 11:39:12.350085 14303 net.cpp:148] Top shape: 8 1 192 256 (393216)
I0705 11:39:12.350090 14303 net.cpp:148] Top shape: 8 (8)
I0705 11:39:12.350092 14303 net.cpp:156] Memory required for data: 1572896
I0705 11:39:12.350095 14303 layer_factory.hpp:77] Creating layer label_data_1_split
I0705 11:39:12.350103 14303 net.cpp:91] Creating Layer label_data_1_split
I0705 11:39:12.350106 14303 net.cpp:425] label_data_1_split <- label
I0705 11:39:12.350111 14303 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0705 11:39:12.350117 14303 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0705 11:39:12.350175 14303 net.cpp:141] Setting up label_data_1_split
I0705 11:39:12.350181 14303 net.cpp:148] Top shape: 8 (8)
I0705 11:39:12.350184 14303 net.cpp:148] Top shape: 8 (8)
I0705 11:39:12.350186 14303 net.cpp:156] Memory required for data: 1572960
I0705 11:39:12.350189 14303 layer_factory.hpp:77] Creating layer conv1
I0705 11:39:12.350198 14303 net.cpp:91] Creating Layer conv1
I0705 11:39:12.350201 14303 net.cpp:425] conv1 <- data
I0705 11:39:12.350205 14303 net.cpp:399] conv1 -> z1_pre
I0705 11:39:12.351678 14303 net.cpp:141] Setting up conv1
I0705 11:39:12.351691 14303 net.cpp:148] Top shape: 8 32 192 256 (12582912)
I0705 11:39:12.351693 14303 net.cpp:156] Memory required for data: 51904608
I0705 11:39:12.351701 14303 layer_factory.hpp:77] Creating layer bn1
I0705 11:39:12.351706 14303 net.cpp:91] Creating Layer bn1
I0705 11:39:12.351709 14303 net.cpp:425] bn1 <- z1_pre
I0705 11:39:12.351713 14303 net.cpp:399] bn1 -> z1
I0705 11:39:12.351946 14303 net.cpp:141] Setting up bn1
I0705 11:39:12.351953 14303 net.cpp:148] Top shape: 8 32 192 256 (12582912)
I0705 11:39:12.351956 14303 net.cpp:156] Memory required for data: 102236256
I0705 11:39:12.351964 14303 layer_factory.hpp:77] Creating layer scale1
I0705 11:39:12.351972 14303 net.cpp:91] Creating Layer scale1
I0705 11:39:12.351975 14303 net.cpp:425] scale1 <- z1
I0705 11:39:12.351979 14303 net.cpp:386] scale1 -> z1 (in-place)
I0705 11:39:12.352020 14303 layer_factory.hpp:77] Creating layer scale1
I0705 11:39:12.352768 14303 net.cpp:141] Setting up scale1
I0705 11:39:12.352780 14303 net.cpp:148] Top shape: 8 32 192 256 (12582912)
I0705 11:39:12.352782 14303 net.cpp:156] Memory required for data: 152567904
I0705 11:39:12.352789 14303 layer_factory.hpp:77] Creating layer relu1
I0705 11:39:12.352795 14303 net.cpp:91] Creating Layer relu1
I0705 11:39:12.352797 14303 net.cpp:425] relu1 <- z1
I0705 11:39:12.352802 14303 net.cpp:386] relu1 -> z1 (in-place)
I0705 11:39:12.352962 14303 net.cpp:141] Setting up relu1
I0705 11:39:12.352969 14303 net.cpp:148] Top shape: 8 32 192 256 (12582912)
I0705 11:39:12.352972 14303 net.cpp:156] Memory required for data: 202899552
I0705 11:39:12.352974 14303 layer_factory.hpp:77] Creating layer pool1
I0705 11:39:12.352982 14303 net.cpp:91] Creating Layer pool1
I0705 11:39:12.352983 14303 net.cpp:425] pool1 <- z1
I0705 11:39:12.352988 14303 net.cpp:399] pool1 -> pool1
I0705 11:39:12.353045 14303 net.cpp:141] Setting up pool1
I0705 11:39:12.353052 14303 net.cpp:148] Top shape: 8 32 96 128 (3145728)
I0705 11:39:12.353055 14303 net.cpp:156] Memory required for data: 215482464
I0705 11:39:12.353056 14303 layer_factory.hpp:77] Creating layer conv2
I0705 11:39:12.353065 14303 net.cpp:91] Creating Layer conv2
I0705 11:39:12.353067 14303 net.cpp:425] conv2 <- pool1
I0705 11:39:12.353071 14303 net.cpp:399] conv2 -> z2_pre
I0705 11:39:12.354128 14303 net.cpp:141] Setting up conv2
I0705 11:39:12.354140 14303 net.cpp:148] Top shape: 8 64 96 128 (6291456)
I0705 11:39:12.354143 14303 net.cpp:156] Memory required for data: 240648288
I0705 11:39:12.354147 14303 layer_factory.hpp:77] Creating layer bn2
I0705 11:39:12.354156 14303 net.cpp:91] Creating Layer bn2
I0705 11:39:12.354157 14303 net.cpp:425] bn2 <- z2_pre
I0705 11:39:12.354162 14303 net.cpp:399] bn2 -> z2
I0705 11:39:12.354389 14303 net.cpp:141] Setting up bn2
I0705 11:39:12.354398 14303 net.cpp:148] Top shape: 8 64 96 128 (6291456)
I0705 11:39:12.354400 14303 net.cpp:156] Memory required for data: 265814112
I0705 11:39:12.354408 14303 layer_factory.hpp:77] Creating layer scale2
I0705 11:39:12.354414 14303 net.cpp:91] Creating Layer scale2
I0705 11:39:12.354418 14303 net.cpp:425] scale2 <- z2
I0705 11:39:12.354424 14303 net.cpp:386] scale2 -> z2 (in-place)
I0705 11:39:12.354470 14303 layer_factory.hpp:77] Creating layer scale2
I0705 11:39:12.354598 14303 net.cpp:141] Setting up scale2
I0705 11:39:12.354604 14303 net.cpp:148] Top shape: 8 64 96 128 (6291456)
I0705 11:39:12.354606 14303 net.cpp:156] Memory required for data: 290979936
I0705 11:39:12.354611 14303 layer_factory.hpp:77] Creating layer relu2
I0705 11:39:12.354615 14303 net.cpp:91] Creating Layer relu2
I0705 11:39:12.354617 14303 net.cpp:425] relu2 <- z2
I0705 11:39:12.354621 14303 net.cpp:386] relu2 -> z2 (in-place)
I0705 11:39:12.354921 14303 net.cpp:141] Setting up relu2
I0705 11:39:12.354933 14303 net.cpp:148] Top shape: 8 64 96 128 (6291456)
I0705 11:39:12.354934 14303 net.cpp:156] Memory required for data: 316145760
I0705 11:39:12.354938 14303 layer_factory.hpp:77] Creating layer pool2
I0705 11:39:12.354943 14303 net.cpp:91] Creating Layer pool2
I0705 11:39:12.354945 14303 net.cpp:425] pool2 <- z2
I0705 11:39:12.354950 14303 net.cpp:399] pool2 -> pool2
I0705 11:39:12.355000 14303 net.cpp:141] Setting up pool2
I0705 11:39:12.355005 14303 net.cpp:148] Top shape: 8 64 48 64 (1572864)
I0705 11:39:12.355007 14303 net.cpp:156] Memory required for data: 322437216
I0705 11:39:12.355010 14303 layer_factory.hpp:77] Creating layer conv3
I0705 11:39:12.355020 14303 net.cpp:91] Creating Layer conv3
I0705 11:39:12.355022 14303 net.cpp:425] conv3 <- pool2
I0705 11:39:12.355026 14303 net.cpp:399] conv3 -> z3_pre
I0705 11:39:12.356456 14303 net.cpp:141] Setting up conv3
I0705 11:39:12.356469 14303 net.cpp:148] Top shape: 8 128 48 64 (3145728)
I0705 11:39:12.356472 14303 net.cpp:156] Memory required for data: 335020128
I0705 11:39:12.356477 14303 layer_factory.hpp:77] Creating layer bn3
I0705 11:39:12.356483 14303 net.cpp:91] Creating Layer bn3
I0705 11:39:12.356487 14303 net.cpp:425] bn3 <- z3_pre
I0705 11:39:12.356490 14303 net.cpp:399] bn3 -> z3
I0705 11:39:12.356688 14303 net.cpp:141] Setting up bn3
I0705 11:39:12.356694 14303 net.cpp:148] Top shape: 8 128 48 64 (3145728)
I0705 11:39:12.356696 14303 net.cpp:156] Memory required for data: 347603040
I0705 11:39:12.356703 14303 layer_factory.hpp:77] Creating layer scale3
I0705 11:39:12.356709 14303 net.cpp:91] Creating Layer scale3
I0705 11:39:12.356711 14303 net.cpp:425] scale3 <- z3
I0705 11:39:12.356716 14303 net.cpp:386] scale3 -> z3 (in-place)
I0705 11:39:12.356758 14303 layer_factory.hpp:77] Creating layer scale3
I0705 11:39:12.356864 14303 net.cpp:141] Setting up scale3
I0705 11:39:12.356870 14303 net.cpp:148] Top shape: 8 128 48 64 (3145728)
I0705 11:39:12.356873 14303 net.cpp:156] Memory required for data: 360185952
I0705 11:39:12.356880 14303 layer_factory.hpp:77] Creating layer relu3
I0705 11:39:12.356885 14303 net.cpp:91] Creating Layer relu3
I0705 11:39:12.356887 14303 net.cpp:425] relu3 <- z3
I0705 11:39:12.356891 14303 net.cpp:386] relu3 -> z3 (in-place)
I0705 11:39:12.357215 14303 net.cpp:141] Setting up relu3
I0705 11:39:12.357226 14303 net.cpp:148] Top shape: 8 128 48 64 (3145728)
I0705 11:39:12.357229 14303 net.cpp:156] Memory required for data: 372768864
I0705 11:39:12.357233 14303 layer_factory.hpp:77] Creating layer pool3
I0705 11:39:12.357240 14303 net.cpp:91] Creating Layer pool3
I0705 11:39:12.357244 14303 net.cpp:425] pool3 <- z3
I0705 11:39:12.357247 14303 net.cpp:399] pool3 -> pool3
I0705 11:39:12.357295 14303 net.cpp:141] Setting up pool3
I0705 11:39:12.357302 14303 net.cpp:148] Top shape: 8 128 24 32 (786432)
I0705 11:39:12.357305 14303 net.cpp:156] Memory required for data: 375914592
I0705 11:39:12.357306 14303 layer_factory.hpp:77] Creating layer conv4
I0705 11:39:12.357314 14303 net.cpp:91] Creating Layer conv4
I0705 11:39:12.357326 14303 net.cpp:425] conv4 <- pool3
I0705 11:39:12.357332 14303 net.cpp:399] conv4 -> z4_pre
I0705 11:39:12.360615 14303 net.cpp:141] Setting up conv4
I0705 11:39:12.360627 14303 net.cpp:148] Top shape: 8 256 24 32 (1572864)
I0705 11:39:12.360630 14303 net.cpp:156] Memory required for data: 382206048
I0705 11:39:12.360635 14303 layer_factory.hpp:77] Creating layer bn4
I0705 11:39:12.360641 14303 net.cpp:91] Creating Layer bn4
I0705 11:39:12.360644 14303 net.cpp:425] bn4 <- z4_pre
I0705 11:39:12.360649 14303 net.cpp:399] bn4 -> z4
I0705 11:39:12.360852 14303 net.cpp:141] Setting up bn4
I0705 11:39:12.360858 14303 net.cpp:148] Top shape: 8 256 24 32 (1572864)
I0705 11:39:12.360860 14303 net.cpp:156] Memory required for data: 388497504
I0705 11:39:12.360867 14303 layer_factory.hpp:77] Creating layer scale4
I0705 11:39:12.360873 14303 net.cpp:91] Creating Layer scale4
I0705 11:39:12.360877 14303 net.cpp:425] scale4 <- z4
I0705 11:39:12.360879 14303 net.cpp:386] scale4 -> z4 (in-place)
I0705 11:39:12.360924 14303 layer_factory.hpp:77] Creating layer scale4
I0705 11:39:12.361027 14303 net.cpp:141] Setting up scale4
I0705 11:39:12.361033 14303 net.cpp:148] Top shape: 8 256 24 32 (1572864)
I0705 11:39:12.361035 14303 net.cpp:156] Memory required for data: 394788960
I0705 11:39:12.361039 14303 layer_factory.hpp:77] Creating layer relu4
I0705 11:39:12.361044 14303 net.cpp:91] Creating Layer relu4
I0705 11:39:12.361047 14303 net.cpp:425] relu4 <- z4
I0705 11:39:12.361050 14303 net.cpp:386] relu4 -> z4 (in-place)
I0705 11:39:12.361208 14303 net.cpp:141] Setting up relu4
I0705 11:39:12.361217 14303 net.cpp:148] Top shape: 8 256 24 32 (1572864)
I0705 11:39:12.361219 14303 net.cpp:156] Memory required for data: 401080416
I0705 11:39:12.361222 14303 layer_factory.hpp:77] Creating layer pool4
I0705 11:39:12.361227 14303 net.cpp:91] Creating Layer pool4
I0705 11:39:12.361228 14303 net.cpp:425] pool4 <- z4
I0705 11:39:12.361234 14303 net.cpp:399] pool4 -> pool4
I0705 11:39:12.361277 14303 net.cpp:141] Setting up pool4
I0705 11:39:12.361284 14303 net.cpp:148] Top shape: 8 256 12 16 (393216)
I0705 11:39:12.361285 14303 net.cpp:156] Memory required for data: 402653280
I0705 11:39:12.361289 14303 layer_factory.hpp:77] Creating layer conv5
I0705 11:39:12.361296 14303 net.cpp:91] Creating Layer conv5
I0705 11:39:12.361299 14303 net.cpp:425] conv5 <- pool4
I0705 11:39:12.361302 14303 net.cpp:399] conv5 -> z5_pre
I0705 11:39:12.366737 14303 net.cpp:141] Setting up conv5
I0705 11:39:12.366750 14303 net.cpp:148] Top shape: 8 256 12 16 (393216)
I0705 11:39:12.366752 14303 net.cpp:156] Memory required for data: 404226144
I0705 11:39:12.366757 14303 layer_factory.hpp:77] Creating layer bn5
I0705 11:39:12.366763 14303 net.cpp:91] Creating Layer bn5
I0705 11:39:12.366766 14303 net.cpp:425] bn5 <- z5_pre
I0705 11:39:12.366771 14303 net.cpp:399] bn5 -> z5
I0705 11:39:12.366979 14303 net.cpp:141] Setting up bn5
I0705 11:39:12.366986 14303 net.cpp:148] Top shape: 8 256 12 16 (393216)
I0705 11:39:12.366988 14303 net.cpp:156] Memory required for data: 405799008
I0705 11:39:12.366993 14303 layer_factory.hpp:77] Creating layer scale5
I0705 11:39:12.367000 14303 net.cpp:91] Creating Layer scale5
I0705 11:39:12.367002 14303 net.cpp:425] scale5 <- z5
I0705 11:39:12.367007 14303 net.cpp:386] scale5 -> z5 (in-place)
I0705 11:39:12.367051 14303 layer_factory.hpp:77] Creating layer scale5
I0705 11:39:12.367159 14303 net.cpp:141] Setting up scale5
I0705 11:39:12.367166 14303 net.cpp:148] Top shape: 8 256 12 16 (393216)
I0705 11:39:12.367167 14303 net.cpp:156] Memory required for data: 407371872
I0705 11:39:12.367172 14303 layer_factory.hpp:77] Creating layer relu5
I0705 11:39:12.367177 14303 net.cpp:91] Creating Layer relu5
I0705 11:39:12.367179 14303 net.cpp:425] relu5 <- z5
I0705 11:39:12.367183 14303 net.cpp:386] relu5 -> z5 (in-place)
I0705 11:39:12.367471 14303 net.cpp:141] Setting up relu5
I0705 11:39:12.367482 14303 net.cpp:148] Top shape: 8 256 12 16 (393216)
I0705 11:39:12.367486 14303 net.cpp:156] Memory required for data: 408944736
I0705 11:39:12.367497 14303 layer_factory.hpp:77] Creating layer pool5
I0705 11:39:12.367504 14303 net.cpp:91] Creating Layer pool5
I0705 11:39:12.367507 14303 net.cpp:425] pool5 <- z5
I0705 11:39:12.367511 14303 net.cpp:399] pool5 -> pool5
I0705 11:39:12.367563 14303 net.cpp:141] Setting up pool5
I0705 11:39:12.367569 14303 net.cpp:148] Top shape: 8 256 6 8 (98304)
I0705 11:39:12.367571 14303 net.cpp:156] Memory required for data: 409337952
I0705 11:39:12.367573 14303 layer_factory.hpp:77] Creating layer conv6
I0705 11:39:12.367581 14303 net.cpp:91] Creating Layer conv6
I0705 11:39:12.367584 14303 net.cpp:425] conv6 <- pool5
I0705 11:39:12.367588 14303 net.cpp:399] conv6 -> z6_pre
I0705 11:39:12.372927 14303 net.cpp:141] Setting up conv6
I0705 11:39:12.372939 14303 net.cpp:148] Top shape: 8 256 6 8 (98304)
I0705 11:39:12.372942 14303 net.cpp:156] Memory required for data: 409731168
I0705 11:39:12.372947 14303 layer_factory.hpp:77] Creating layer bn6
I0705 11:39:12.372954 14303 net.cpp:91] Creating Layer bn6
I0705 11:39:12.372956 14303 net.cpp:425] bn6 <- z6_pre
I0705 11:39:12.372961 14303 net.cpp:399] bn6 -> z6
I0705 11:39:12.373180 14303 net.cpp:141] Setting up bn6
I0705 11:39:12.373188 14303 net.cpp:148] Top shape: 8 256 6 8 (98304)
I0705 11:39:12.373189 14303 net.cpp:156] Memory required for data: 410124384
I0705 11:39:12.373200 14303 layer_factory.hpp:77] Creating layer scale6
I0705 11:39:12.373208 14303 net.cpp:91] Creating Layer scale6
I0705 11:39:12.373209 14303 net.cpp:425] scale6 <- z6
I0705 11:39:12.373214 14303 net.cpp:386] scale6 -> z6 (in-place)
I0705 11:39:12.373261 14303 layer_factory.hpp:77] Creating layer scale6
I0705 11:39:12.373381 14303 net.cpp:141] Setting up scale6
I0705 11:39:12.373389 14303 net.cpp:148] Top shape: 8 256 6 8 (98304)
I0705 11:39:12.373390 14303 net.cpp:156] Memory required for data: 410517600
I0705 11:39:12.373395 14303 layer_factory.hpp:77] Creating layer relu6
I0705 11:39:12.373400 14303 net.cpp:91] Creating Layer relu6
I0705 11:39:12.373402 14303 net.cpp:425] relu6 <- z6
I0705 11:39:12.373406 14303 net.cpp:386] relu6 -> z6 (in-place)
I0705 11:39:12.373697 14303 net.cpp:141] Setting up relu6
I0705 11:39:12.373708 14303 net.cpp:148] Top shape: 8 256 6 8 (98304)
I0705 11:39:12.373710 14303 net.cpp:156] Memory required for data: 410910816
I0705 11:39:12.373713 14303 layer_factory.hpp:77] Creating layer pool_final
I0705 11:39:12.373718 14303 net.cpp:91] Creating Layer pool_final
I0705 11:39:12.373723 14303 net.cpp:425] pool_final <- z6
I0705 11:39:12.373726 14303 net.cpp:399] pool_final -> pool_final
I0705 11:39:12.373895 14303 net.cpp:141] Setting up pool_final
I0705 11:39:12.373905 14303 net.cpp:148] Top shape: 8 256 1 1 (2048)
I0705 11:39:12.373908 14303 net.cpp:156] Memory required for data: 410919008
I0705 11:39:12.373910 14303 layer_factory.hpp:77] Creating layer score
I0705 11:39:12.373919 14303 net.cpp:91] Creating Layer score
I0705 11:39:12.373922 14303 net.cpp:425] score <- pool_final
I0705 11:39:12.373926 14303 net.cpp:399] score -> score
I0705 11:39:12.374045 14303 net.cpp:141] Setting up score
I0705 11:39:12.374053 14303 net.cpp:148] Top shape: 8 2 (16)
I0705 11:39:12.374054 14303 net.cpp:156] Memory required for data: 410919072
I0705 11:39:12.374059 14303 layer_factory.hpp:77] Creating layer score_score_0_split
I0705 11:39:12.374065 14303 net.cpp:91] Creating Layer score_score_0_split
I0705 11:39:12.374068 14303 net.cpp:425] score_score_0_split <- score
I0705 11:39:12.374070 14303 net.cpp:399] score_score_0_split -> score_score_0_split_0
I0705 11:39:12.374075 14303 net.cpp:399] score_score_0_split -> score_score_0_split_1
I0705 11:39:12.374114 14303 net.cpp:141] Setting up score_score_0_split
I0705 11:39:12.374120 14303 net.cpp:148] Top shape: 8 2 (16)
I0705 11:39:12.374124 14303 net.cpp:148] Top shape: 8 2 (16)
I0705 11:39:12.374125 14303 net.cpp:156] Memory required for data: 410919200
I0705 11:39:12.374127 14303 layer_factory.hpp:77] Creating layer prob
I0705 11:39:12.374132 14303 net.cpp:91] Creating Layer prob
I0705 11:39:12.374135 14303 net.cpp:425] prob <- score_score_0_split_0
I0705 11:39:12.374148 14303 net.cpp:425] prob <- label_data_1_split_0
I0705 11:39:12.374152 14303 net.cpp:399] prob -> prob
I0705 11:39:12.374160 14303 layer_factory.hpp:77] Creating layer prob
I0705 11:39:12.374542 14303 net.cpp:141] Setting up prob
I0705 11:39:12.374553 14303 net.cpp:148] Top shape: (1)
I0705 11:39:12.374557 14303 net.cpp:151]     with loss weight 1
I0705 11:39:12.374563 14303 net.cpp:156] Memory required for data: 410919204
I0705 11:39:12.374567 14303 layer_factory.hpp:77] Creating layer accuracy
I0705 11:39:12.374572 14303 net.cpp:91] Creating Layer accuracy
I0705 11:39:12.374575 14303 net.cpp:425] accuracy <- score_score_0_split_1
I0705 11:39:12.374578 14303 net.cpp:425] accuracy <- label_data_1_split_1
I0705 11:39:12.374583 14303 net.cpp:399] accuracy -> accuracy
I0705 11:39:12.374588 14303 net.cpp:141] Setting up accuracy
I0705 11:39:12.374593 14303 net.cpp:148] Top shape: (1)
I0705 11:39:12.374595 14303 net.cpp:156] Memory required for data: 410919208
I0705 11:39:12.374598 14303 net.cpp:219] accuracy does not need backward computation.
I0705 11:39:12.374600 14303 net.cpp:217] prob needs backward computation.
I0705 11:39:12.374603 14303 net.cpp:217] score_score_0_split needs backward computation.
I0705 11:39:12.374606 14303 net.cpp:217] score needs backward computation.
I0705 11:39:12.374608 14303 net.cpp:217] pool_final needs backward computation.
I0705 11:39:12.374610 14303 net.cpp:217] relu6 needs backward computation.
I0705 11:39:12.374613 14303 net.cpp:217] scale6 needs backward computation.
I0705 11:39:12.374614 14303 net.cpp:217] bn6 needs backward computation.
I0705 11:39:12.374616 14303 net.cpp:217] conv6 needs backward computation.
I0705 11:39:12.374619 14303 net.cpp:217] pool5 needs backward computation.
I0705 11:39:12.374621 14303 net.cpp:217] relu5 needs backward computation.
I0705 11:39:12.374624 14303 net.cpp:217] scale5 needs backward computation.
I0705 11:39:12.374625 14303 net.cpp:217] bn5 needs backward computation.
I0705 11:39:12.374627 14303 net.cpp:217] conv5 needs backward computation.
I0705 11:39:12.374630 14303 net.cpp:217] pool4 needs backward computation.
I0705 11:39:12.374632 14303 net.cpp:217] relu4 needs backward computation.
I0705 11:39:12.374634 14303 net.cpp:217] scale4 needs backward computation.
I0705 11:39:12.374636 14303 net.cpp:217] bn4 needs backward computation.
I0705 11:39:12.374639 14303 net.cpp:217] conv4 needs backward computation.
I0705 11:39:12.374640 14303 net.cpp:217] pool3 needs backward computation.
I0705 11:39:12.374642 14303 net.cpp:217] relu3 needs backward computation.
I0705 11:39:12.374645 14303 net.cpp:217] scale3 needs backward computation.
I0705 11:39:12.374647 14303 net.cpp:217] bn3 needs backward computation.
I0705 11:39:12.374650 14303 net.cpp:217] conv3 needs backward computation.
I0705 11:39:12.374651 14303 net.cpp:217] pool2 needs backward computation.
I0705 11:39:12.374653 14303 net.cpp:217] relu2 needs backward computation.
I0705 11:39:12.374655 14303 net.cpp:217] scale2 needs backward computation.
I0705 11:39:12.374657 14303 net.cpp:217] bn2 needs backward computation.
I0705 11:39:12.374660 14303 net.cpp:217] conv2 needs backward computation.
I0705 11:39:12.374662 14303 net.cpp:217] pool1 needs backward computation.
I0705 11:39:12.374665 14303 net.cpp:217] relu1 needs backward computation.
I0705 11:39:12.374666 14303 net.cpp:217] scale1 needs backward computation.
I0705 11:39:12.374668 14303 net.cpp:217] bn1 needs backward computation.
I0705 11:39:12.374671 14303 net.cpp:217] conv1 needs backward computation.
I0705 11:39:12.374675 14303 net.cpp:219] label_data_1_split does not need backward computation.
I0705 11:39:12.374677 14303 net.cpp:219] data does not need backward computation.
I0705 11:39:12.374680 14303 net.cpp:261] This network produces output accuracy
I0705 11:39:12.374682 14303 net.cpp:261] This network produces output prob
I0705 11:39:12.374701 14303 net.cpp:274] Network initialization done.
I0705 11:39:12.374842 14303 solver.cpp:60] Solver scaffolding done.
I0705 11:39:12.379823 14303 caffe.cpp:219] Starting Optimization
I0705 11:39:12.379839 14303 solver.cpp:279] Solving LadderNet
I0705 11:39:12.379842 14303 solver.cpp:280] Learning Rate Policy: step
I0705 11:39:12.387977 14303 solver.cpp:337] Iteration 0, Testing net (#0)
I0705 11:39:12.387989 14303 net.cpp:684] Ignoring source layer data_data_0_split
I0705 11:39:12.387992 14303 net.cpp:684] Ignoring source layer noisy_data
I0705 11:39:12.387995 14303 net.cpp:684] Ignoring source layer noisy_data_noisy_data_0_split
I0705 11:39:12.388051 14303 net.cpp:684] Ignoring source layer z1_bn1_0_split
I0705 11:39:12.388075 14303 net.cpp:684] Ignoring source layer bn1_n
I0705 11:39:12.388077 14303 net.cpp:684] Ignoring source layer noisy_z1_n
I0705 11:39:12.388079 14303 net.cpp:684] Ignoring source layer z1_n_noisy_z1_n_0_split
I0705 11:39:12.388082 14303 net.cpp:684] Ignoring source layer scale1_n
I0705 11:39:12.388083 14303 net.cpp:684] Ignoring source layer relu1_n
I0705 11:39:12.388085 14303 net.cpp:684] Ignoring source layer pool1_n
I0705 11:39:12.388130 14303 net.cpp:684] Ignoring source layer z2_bn2_0_split
I0705 11:39:12.388164 14303 net.cpp:684] Ignoring source layer bn2_n
I0705 11:39:12.388172 14303 net.cpp:684] Ignoring source layer noisy_z2_n
I0705 11:39:12.388175 14303 net.cpp:684] Ignoring source layer z2_n_noisy_z2_n_0_split
I0705 11:39:12.388176 14303 net.cpp:684] Ignoring source layer scale2_n
I0705 11:39:12.388178 14303 net.cpp:684] Ignoring source layer relu2_n
I0705 11:39:12.388180 14303 net.cpp:684] Ignoring source layer pool2_n
I0705 11:39:12.388219 14303 net.cpp:684] Ignoring source layer z3_bn3_0_split
I0705 11:39:12.388239 14303 net.cpp:684] Ignoring source layer bn3_n
I0705 11:39:12.388243 14303 net.cpp:684] Ignoring source layer noisy_z3_n
I0705 11:39:12.388245 14303 net.cpp:684] Ignoring source layer z3_n_noisy_z3_n_0_split
I0705 11:39:12.388247 14303 net.cpp:684] Ignoring source layer scale3_n
I0705 11:39:12.388249 14303 net.cpp:684] Ignoring source layer relu3_n
I0705 11:39:12.388252 14303 net.cpp:684] Ignoring source layer pool3_n
I0705 11:39:12.388520 14303 net.cpp:684] Ignoring source layer z4_bn4_0_split
I0705 11:39:12.388545 14303 net.cpp:684] Ignoring source layer bn4_n
I0705 11:39:12.388548 14303 net.cpp:684] Ignoring source layer noisy_z4_n
I0705 11:39:12.388550 14303 net.cpp:684] Ignoring source layer z4_n_noisy_z4_n_0_split
I0705 11:39:12.388552 14303 net.cpp:684] Ignoring source layer scale4_n
I0705 11:39:12.388553 14303 net.cpp:684] Ignoring source layer relu4_n
I0705 11:39:12.388556 14303 net.cpp:684] Ignoring source layer pool4_n
I0705 11:39:12.388907 14303 net.cpp:684] Ignoring source layer z5_bn5_0_split
I0705 11:39:12.388932 14303 net.cpp:684] Ignoring source layer bn5_n
I0705 11:39:12.388936 14303 net.cpp:684] Ignoring source layer noisy_z5_n
I0705 11:39:12.388937 14303 net.cpp:684] Ignoring source layer z5_n_noisy_z5_n_0_split
I0705 11:39:12.388939 14303 net.cpp:684] Ignoring source layer scale5_n
I0705 11:39:12.388942 14303 net.cpp:684] Ignoring source layer relu5_n
I0705 11:39:12.388943 14303 net.cpp:684] Ignoring source layer pool5_n
I0705 11:39:12.389292 14303 net.cpp:684] Ignoring source layer z6_bn6_0_split
I0705 11:39:12.389314 14303 net.cpp:684] Ignoring source layer bn6_n
I0705 11:39:12.389317 14303 net.cpp:684] Ignoring source layer noisy_z6_n
I0705 11:39:12.389320 14303 net.cpp:684] Ignoring source layer z6_n_noisy_z6_n_0_split
I0705 11:39:12.389322 14303 net.cpp:684] Ignoring source layer scale6_n
I0705 11:39:12.389323 14303 net.cpp:684] Ignoring source layer relu6_n
I0705 11:39:12.389325 14303 net.cpp:684] Ignoring source layer u6
I0705 11:39:12.389328 14303 net.cpp:684] Ignoring source layer comb6
I0705 11:39:12.389330 14303 net.cpp:684] Ignoring source layer z6_r_comb6_0_split
I0705 11:39:12.389333 14303 net.cpp:684] Ignoring source layer recon6
I0705 11:39:12.389334 14303 net.cpp:684] Ignoring source layer bn6_r
I0705 11:39:12.389336 14303 net.cpp:684] Ignoring source layer upsample5
I0705 11:39:12.389338 14303 net.cpp:684] Ignoring source layer comb5
I0705 11:39:12.389340 14303 net.cpp:684] Ignoring source layer z5_r_comb5_0_split
I0705 11:39:12.389351 14303 net.cpp:684] Ignoring source layer recon5
I0705 11:39:12.389353 14303 net.cpp:684] Ignoring source layer bn5_r
I0705 11:39:12.389355 14303 net.cpp:684] Ignoring source layer upsample4
I0705 11:39:12.389358 14303 net.cpp:684] Ignoring source layer comb4
I0705 11:39:12.389359 14303 net.cpp:684] Ignoring source layer z4_r_comb4_0_split
I0705 11:39:12.389361 14303 net.cpp:684] Ignoring source layer recon4
I0705 11:39:12.389364 14303 net.cpp:684] Ignoring source layer bn4_r
I0705 11:39:12.389365 14303 net.cpp:684] Ignoring source layer upsample3
I0705 11:39:12.389366 14303 net.cpp:684] Ignoring source layer comb3
I0705 11:39:12.389369 14303 net.cpp:684] Ignoring source layer z3_r_comb3_0_split
I0705 11:39:12.389370 14303 net.cpp:684] Ignoring source layer recon3
I0705 11:39:12.389372 14303 net.cpp:684] Ignoring source layer bn3_r
I0705 11:39:12.389374 14303 net.cpp:684] Ignoring source layer upsample2
I0705 11:39:12.389376 14303 net.cpp:684] Ignoring source layer comb2
I0705 11:39:12.389379 14303 net.cpp:684] Ignoring source layer z2_r_comb2_0_split
I0705 11:39:12.389379 14303 net.cpp:684] Ignoring source layer recon2
I0705 11:39:12.389381 14303 net.cpp:684] Ignoring source layer bn2_r
I0705 11:39:12.389384 14303 net.cpp:684] Ignoring source layer upsample1
I0705 11:39:12.389385 14303 net.cpp:684] Ignoring source layer comb1
I0705 11:39:12.389387 14303 net.cpp:684] Ignoring source layer z1_r_comb1_0_split
I0705 11:39:12.389389 14303 net.cpp:684] Ignoring source layer recon1
I0705 11:39:12.389390 14303 net.cpp:684] Ignoring source layer bn1_r
I0705 11:39:12.389392 14303 net.cpp:684] Ignoring source layer comb0
I0705 11:39:12.389395 14303 net.cpp:684] Ignoring source layer loss_ladder_6
I0705 11:39:12.389396 14303 net.cpp:684] Ignoring source layer loss_ladder_5
I0705 11:39:12.389399 14303 net.cpp:684] Ignoring source layer loss_ladder_4
I0705 11:39:12.389400 14303 net.cpp:684] Ignoring source layer loss_ladder_3
I0705 11:39:12.389402 14303 net.cpp:684] Ignoring source layer loss_ladder_2
I0705 11:39:12.389405 14303 net.cpp:684] Ignoring source layer loss_ladder_1
I0705 11:39:12.389406 14303 net.cpp:684] Ignoring source layer loss_ladder_0
I0705 11:39:12.389431 14303 net.cpp:684] Ignoring source layer loss_supervised
I0705 11:39:12.560803 14303 solver.cpp:404]     Test net output #0: accuracy = 0.507812
I0705 11:39:12.560833 14303 solver.cpp:404]     Test net output #1: prob = 42.986 (* 1 = 42.986 loss)
I0705 11:39:12.879643 14303 solver.cpp:228] Iteration 0, loss = 6.19535
I0705 11:39:12.879667 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0705 11:39:12.879673 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.0968918 (* 0.1 = 0.00968918 loss)
I0705 11:39:12.879678 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 47.5761 (* 0.1 = 4.75761 loss)
I0705 11:39:12.879683 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.91442 (* 0.1 = 0.291442 loss)
I0705 11:39:12.879686 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.05658 (* 0.1 = 0.105658 loss)
I0705 11:39:12.879689 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.96221 (* 0.1 = 0.096221 loss)
I0705 11:39:12.879693 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 1.07954 (* 0.1 = 0.107954 loss)
I0705 11:39:12.879698 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 1.03132 (* 0.1 = 0.103132 loss)
I0705 11:39:12.879701 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.723648 (* 1 = 0.723648 loss)
I0705 11:39:12.879714 14303 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0705 11:39:18.118006 14303 solver.cpp:228] Iteration 20, loss = 5.86486
I0705 11:39:18.118028 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0705 11:39:18.118036 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.0979806 (* 0.1 = 0.00979806 loss)
I0705 11:39:18.118041 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 44.3372 (* 0.1 = 4.43372 loss)
I0705 11:39:18.118046 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 3.09828 (* 0.1 = 0.309828 loss)
I0705 11:39:18.118067 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.0661 (* 0.1 = 0.10661 loss)
I0705 11:39:18.118070 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.955423 (* 0.1 = 0.0955423 loss)
I0705 11:39:18.118073 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 1.08931 (* 0.1 = 0.108931 loss)
I0705 11:39:18.118077 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 1.02791 (* 0.1 = 0.102791 loss)
I0705 11:39:18.118080 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.697637 (* 1 = 0.697637 loss)
I0705 11:39:18.118084 14303 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0705 11:39:23.502480 14303 solver.cpp:228] Iteration 40, loss = 6.08724
I0705 11:39:23.502502 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:39:23.502509 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.109005 (* 0.1 = 0.0109005 loss)
I0705 11:39:23.502513 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 47.0276 (* 0.1 = 4.70276 loss)
I0705 11:39:23.502517 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 3.33035 (* 0.1 = 0.333035 loss)
I0705 11:39:23.502521 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.07488 (* 0.1 = 0.107488 loss)
I0705 11:39:23.502526 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.933474 (* 0.1 = 0.0933474 loss)
I0705 11:39:23.502529 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 1.09455 (* 0.1 = 0.109455 loss)
I0705 11:39:23.502532 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 1.03215 (* 0.1 = 0.103215 loss)
I0705 11:39:23.502537 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.627043 (* 1 = 0.627043 loss)
I0705 11:39:23.502540 14303 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0705 11:39:28.888766 14303 solver.cpp:228] Iteration 60, loss = 6.28619
I0705 11:39:28.888788 14303 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0705 11:39:28.888795 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.111856 (* 0.1 = 0.0111856 loss)
I0705 11:39:28.888799 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 49.6821 (* 0.1 = 4.96821 loss)
I0705 11:39:28.888804 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 3.21442 (* 0.1 = 0.321442 loss)
I0705 11:39:28.888808 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.10684 (* 0.1 = 0.110684 loss)
I0705 11:39:28.888811 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.935722 (* 0.1 = 0.0935722 loss)
I0705 11:39:28.888815 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 1.10259 (* 0.1 = 0.110259 loss)
I0705 11:39:28.888819 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 1.05103 (* 0.1 = 0.105103 loss)
I0705 11:39:28.888823 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.56573 (* 1 = 0.56573 loss)
I0705 11:39:28.888826 14303 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0705 11:39:34.303447 14303 solver.cpp:228] Iteration 80, loss = 6.02089
I0705 11:39:34.303489 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:39:34.303498 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.113776 (* 0.1 = 0.0113776 loss)
I0705 11:39:34.303503 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 46.6875 (* 0.1 = 4.66875 loss)
I0705 11:39:34.303509 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.90502 (* 0.1 = 0.290502 loss)
I0705 11:39:34.303514 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.12374 (* 0.1 = 0.112374 loss)
I0705 11:39:34.303517 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.915986 (* 0.1 = 0.0915986 loss)
I0705 11:39:34.303522 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 1.09057 (* 0.1 = 0.109057 loss)
I0705 11:39:34.303526 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 1.0463 (* 0.1 = 0.10463 loss)
I0705 11:39:34.303529 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.632604 (* 1 = 0.632604 loss)
I0705 11:39:34.303552 14303 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0705 11:39:39.615802 14303 solver.cpp:337] Iteration 100, Testing net (#0)
I0705 11:39:39.615828 14303 net.cpp:684] Ignoring source layer data_data_0_split
I0705 11:39:39.615831 14303 net.cpp:684] Ignoring source layer noisy_data
I0705 11:39:39.615833 14303 net.cpp:684] Ignoring source layer noisy_data_noisy_data_0_split
I0705 11:39:39.615838 14303 net.cpp:684] Ignoring source layer z1_bn1_0_split
I0705 11:39:39.615840 14303 net.cpp:684] Ignoring source layer bn1_n
I0705 11:39:39.615842 14303 net.cpp:684] Ignoring source layer noisy_z1_n
I0705 11:39:39.615844 14303 net.cpp:684] Ignoring source layer z1_n_noisy_z1_n_0_split
I0705 11:39:39.615845 14303 net.cpp:684] Ignoring source layer scale1_n
I0705 11:39:39.615847 14303 net.cpp:684] Ignoring source layer relu1_n
I0705 11:39:39.615849 14303 net.cpp:684] Ignoring source layer pool1_n
I0705 11:39:39.615852 14303 net.cpp:684] Ignoring source layer z2_bn2_0_split
I0705 11:39:39.615855 14303 net.cpp:684] Ignoring source layer bn2_n
I0705 11:39:39.615856 14303 net.cpp:684] Ignoring source layer noisy_z2_n
I0705 11:39:39.615859 14303 net.cpp:684] Ignoring source layer z2_n_noisy_z2_n_0_split
I0705 11:39:39.615860 14303 net.cpp:684] Ignoring source layer scale2_n
I0705 11:39:39.615862 14303 net.cpp:684] Ignoring source layer relu2_n
I0705 11:39:39.615864 14303 net.cpp:684] Ignoring source layer pool2_n
I0705 11:39:39.615866 14303 net.cpp:684] Ignoring source layer z3_bn3_0_split
I0705 11:39:39.615869 14303 net.cpp:684] Ignoring source layer bn3_n
I0705 11:39:39.615871 14303 net.cpp:684] Ignoring source layer noisy_z3_n
I0705 11:39:39.615872 14303 net.cpp:684] Ignoring source layer z3_n_noisy_z3_n_0_split
I0705 11:39:39.615875 14303 net.cpp:684] Ignoring source layer scale3_n
I0705 11:39:39.615876 14303 net.cpp:684] Ignoring source layer relu3_n
I0705 11:39:39.615878 14303 net.cpp:684] Ignoring source layer pool3_n
I0705 11:39:39.615881 14303 net.cpp:684] Ignoring source layer z4_bn4_0_split
I0705 11:39:39.615885 14303 net.cpp:684] Ignoring source layer bn4_n
I0705 11:39:39.615885 14303 net.cpp:684] Ignoring source layer noisy_z4_n
I0705 11:39:39.615887 14303 net.cpp:684] Ignoring source layer z4_n_noisy_z4_n_0_split
I0705 11:39:39.615890 14303 net.cpp:684] Ignoring source layer scale4_n
I0705 11:39:39.615891 14303 net.cpp:684] Ignoring source layer relu4_n
I0705 11:39:39.615893 14303 net.cpp:684] Ignoring source layer pool4_n
I0705 11:39:39.615896 14303 net.cpp:684] Ignoring source layer z5_bn5_0_split
I0705 11:39:39.615898 14303 net.cpp:684] Ignoring source layer bn5_n
I0705 11:39:39.615900 14303 net.cpp:684] Ignoring source layer noisy_z5_n
I0705 11:39:39.615901 14303 net.cpp:684] Ignoring source layer z5_n_noisy_z5_n_0_split
I0705 11:39:39.615903 14303 net.cpp:684] Ignoring source layer scale5_n
I0705 11:39:39.615906 14303 net.cpp:684] Ignoring source layer relu5_n
I0705 11:39:39.615907 14303 net.cpp:684] Ignoring source layer pool5_n
I0705 11:39:39.615909 14303 net.cpp:684] Ignoring source layer z6_bn6_0_split
I0705 11:39:39.615913 14303 net.cpp:684] Ignoring source layer bn6_n
I0705 11:39:39.615916 14303 net.cpp:684] Ignoring source layer noisy_z6_n
I0705 11:39:39.615917 14303 net.cpp:684] Ignoring source layer z6_n_noisy_z6_n_0_split
I0705 11:39:39.615919 14303 net.cpp:684] Ignoring source layer scale6_n
I0705 11:39:39.615921 14303 net.cpp:684] Ignoring source layer relu6_n
I0705 11:39:39.615922 14303 net.cpp:684] Ignoring source layer u6
I0705 11:39:39.615924 14303 net.cpp:684] Ignoring source layer comb6
I0705 11:39:39.615926 14303 net.cpp:684] Ignoring source layer z6_r_comb6_0_split
I0705 11:39:39.615928 14303 net.cpp:684] Ignoring source layer recon6
I0705 11:39:39.615929 14303 net.cpp:684] Ignoring source layer bn6_r
I0705 11:39:39.615931 14303 net.cpp:684] Ignoring source layer upsample5
I0705 11:39:39.615933 14303 net.cpp:684] Ignoring source layer comb5
I0705 11:39:39.615936 14303 net.cpp:684] Ignoring source layer z5_r_comb5_0_split
I0705 11:39:39.615952 14303 net.cpp:684] Ignoring source layer recon5
I0705 11:39:39.615953 14303 net.cpp:684] Ignoring source layer bn5_r
I0705 11:39:39.615955 14303 net.cpp:684] Ignoring source layer upsample4
I0705 11:39:39.615957 14303 net.cpp:684] Ignoring source layer comb4
I0705 11:39:39.615958 14303 net.cpp:684] Ignoring source layer z4_r_comb4_0_split
I0705 11:39:39.615960 14303 net.cpp:684] Ignoring source layer recon4
I0705 11:39:39.615962 14303 net.cpp:684] Ignoring source layer bn4_r
I0705 11:39:39.615964 14303 net.cpp:684] Ignoring source layer upsample3
I0705 11:39:39.615967 14303 net.cpp:684] Ignoring source layer comb3
I0705 11:39:39.615967 14303 net.cpp:684] Ignoring source layer z3_r_comb3_0_split
I0705 11:39:39.615969 14303 net.cpp:684] Ignoring source layer recon3
I0705 11:39:39.615972 14303 net.cpp:684] Ignoring source layer bn3_r
I0705 11:39:39.615973 14303 net.cpp:684] Ignoring source layer upsample2
I0705 11:39:39.615975 14303 net.cpp:684] Ignoring source layer comb2
I0705 11:39:39.615977 14303 net.cpp:684] Ignoring source layer z2_r_comb2_0_split
I0705 11:39:39.615978 14303 net.cpp:684] Ignoring source layer recon2
I0705 11:39:39.615980 14303 net.cpp:684] Ignoring source layer bn2_r
I0705 11:39:39.615983 14303 net.cpp:684] Ignoring source layer upsample1
I0705 11:39:39.615983 14303 net.cpp:684] Ignoring source layer comb1
I0705 11:39:39.615985 14303 net.cpp:684] Ignoring source layer z1_r_comb1_0_split
I0705 11:39:39.615988 14303 net.cpp:684] Ignoring source layer recon1
I0705 11:39:39.615989 14303 net.cpp:684] Ignoring source layer bn1_r
I0705 11:39:39.615991 14303 net.cpp:684] Ignoring source layer comb0
I0705 11:39:39.615993 14303 net.cpp:684] Ignoring source layer loss_ladder_6
I0705 11:39:39.615994 14303 net.cpp:684] Ignoring source layer loss_ladder_5
I0705 11:39:39.615996 14303 net.cpp:684] Ignoring source layer loss_ladder_4
I0705 11:39:39.615998 14303 net.cpp:684] Ignoring source layer loss_ladder_3
I0705 11:39:39.615999 14303 net.cpp:684] Ignoring source layer loss_ladder_2
I0705 11:39:39.616001 14303 net.cpp:684] Ignoring source layer loss_ladder_1
I0705 11:39:39.616003 14303 net.cpp:684] Ignoring source layer loss_ladder_0
I0705 11:39:39.616006 14303 net.cpp:684] Ignoring source layer loss_supervised
I0705 11:39:39.774837 14303 solver.cpp:404]     Test net output #0: accuracy = 0.53125
I0705 11:39:39.774862 14303 solver.cpp:404]     Test net output #1: prob = 0.69938 (* 1 = 0.69938 loss)
I0705 11:39:39.868104 14303 solver.cpp:228] Iteration 100, loss = 6.04436
I0705 11:39:39.868126 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:39:39.868144 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.107266 (* 0.1 = 0.0107266 loss)
I0705 11:39:39.868149 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 46.0438 (* 0.1 = 4.60438 loss)
I0705 11:39:39.868152 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 3.19104 (* 0.1 = 0.319104 loss)
I0705 11:39:39.868156 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.06332 (* 0.1 = 0.106332 loss)
I0705 11:39:39.868160 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.910045 (* 0.1 = 0.0910045 loss)
I0705 11:39:39.868163 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 1.0776 (* 0.1 = 0.10776 loss)
I0705 11:39:39.868167 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 1.00992 (* 0.1 = 0.100992 loss)
I0705 11:39:39.868171 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.704055 (* 1 = 0.704055 loss)
I0705 11:39:39.868175 14303 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0705 11:39:45.278317 14303 solver.cpp:228] Iteration 120, loss = 7.96752
I0705 11:39:45.278439 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:39:45.278448 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.122132 (* 0.1 = 0.0122132 loss)
I0705 11:39:45.278453 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 66.839 (* 0.1 = 6.6839 loss)
I0705 11:39:45.278457 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.77705 (* 0.1 = 0.177705 loss)
I0705 11:39:45.278461 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.985865 (* 0.1 = 0.0985865 loss)
I0705 11:39:45.278465 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.849601 (* 0.1 = 0.0849601 loss)
I0705 11:39:45.278468 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 1.03383 (* 0.1 = 0.103383 loss)
I0705 11:39:45.278472 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.976969 (* 0.1 = 0.0976969 loss)
I0705 11:39:45.278476 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.709069 (* 1 = 0.709069 loss)
I0705 11:39:45.278481 14303 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0705 11:39:50.689682 14303 solver.cpp:228] Iteration 140, loss = 5.86699
I0705 11:39:50.689704 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:39:50.689712 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.110959 (* 0.1 = 0.0110959 loss)
I0705 11:39:50.689715 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 45.5944 (* 0.1 = 4.55944 loss)
I0705 11:39:50.689720 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.62755 (* 0.1 = 0.262755 loss)
I0705 11:39:50.689735 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.08216 (* 0.1 = 0.108216 loss)
I0705 11:39:50.689738 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.913869 (* 0.1 = 0.0913869 loss)
I0705 11:39:50.689743 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 1.07701 (* 0.1 = 0.107701 loss)
I0705 11:39:50.689746 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.998695 (* 0.1 = 0.0998695 loss)
I0705 11:39:50.689750 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.626523 (* 1 = 0.626523 loss)
I0705 11:39:50.689754 14303 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0705 11:39:56.101222 14303 solver.cpp:228] Iteration 160, loss = 7.38138
I0705 11:39:56.101244 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:39:56.101251 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.12034 (* 0.1 = 0.012034 loss)
I0705 11:39:56.101255 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 61.0578 (* 0.1 = 6.10578 loss)
I0705 11:39:56.101260 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.16702 (* 0.1 = 0.216702 loss)
I0705 11:39:56.101263 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.12781 (* 0.1 = 0.112781 loss)
I0705 11:39:56.101267 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.892018 (* 0.1 = 0.0892018 loss)
I0705 11:39:56.101272 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 1.05656 (* 0.1 = 0.105656 loss)
I0705 11:39:56.101276 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 1.01991 (* 0.1 = 0.101991 loss)
I0705 11:39:56.101280 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.637231 (* 1 = 0.637231 loss)
I0705 11:39:56.101295 14303 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0705 11:40:01.512642 14303 solver.cpp:228] Iteration 180, loss = 5.64513
I0705 11:40:01.512663 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:40:01.512670 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.105631 (* 0.1 = 0.0105631 loss)
I0705 11:40:01.512676 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 42.7527 (* 0.1 = 4.27527 loss)
I0705 11:40:01.512679 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 3.26172 (* 0.1 = 0.326172 loss)
I0705 11:40:01.512682 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.08603 (* 0.1 = 0.108603 loss)
I0705 11:40:01.512686 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.90958 (* 0.1 = 0.090958 loss)
I0705 11:40:01.512709 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 1.04761 (* 0.1 = 0.104761 loss)
I0705 11:40:01.512713 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.997405 (* 0.1 = 0.0997405 loss)
I0705 11:40:01.512717 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.62906 (* 1 = 0.62906 loss)
I0705 11:40:01.512720 14303 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0705 11:40:06.846267 14303 solver.cpp:337] Iteration 200, Testing net (#0)
I0705 11:40:06.846285 14303 net.cpp:684] Ignoring source layer data_data_0_split
I0705 11:40:06.846287 14303 net.cpp:684] Ignoring source layer noisy_data
I0705 11:40:06.846290 14303 net.cpp:684] Ignoring source layer noisy_data_noisy_data_0_split
I0705 11:40:06.846293 14303 net.cpp:684] Ignoring source layer z1_bn1_0_split
I0705 11:40:06.846297 14303 net.cpp:684] Ignoring source layer bn1_n
I0705 11:40:06.846298 14303 net.cpp:684] Ignoring source layer noisy_z1_n
I0705 11:40:06.846300 14303 net.cpp:684] Ignoring source layer z1_n_noisy_z1_n_0_split
I0705 11:40:06.846302 14303 net.cpp:684] Ignoring source layer scale1_n
I0705 11:40:06.846303 14303 net.cpp:684] Ignoring source layer relu1_n
I0705 11:40:06.846307 14303 net.cpp:684] Ignoring source layer pool1_n
I0705 11:40:06.846308 14303 net.cpp:684] Ignoring source layer z2_bn2_0_split
I0705 11:40:06.846312 14303 net.cpp:684] Ignoring source layer bn2_n
I0705 11:40:06.846313 14303 net.cpp:684] Ignoring source layer noisy_z2_n
I0705 11:40:06.846314 14303 net.cpp:684] Ignoring source layer z2_n_noisy_z2_n_0_split
I0705 11:40:06.846316 14303 net.cpp:684] Ignoring source layer scale2_n
I0705 11:40:06.846318 14303 net.cpp:684] Ignoring source layer relu2_n
I0705 11:40:06.846320 14303 net.cpp:684] Ignoring source layer pool2_n
I0705 11:40:06.846323 14303 net.cpp:684] Ignoring source layer z3_bn3_0_split
I0705 11:40:06.846325 14303 net.cpp:684] Ignoring source layer bn3_n
I0705 11:40:06.846328 14303 net.cpp:684] Ignoring source layer noisy_z3_n
I0705 11:40:06.846329 14303 net.cpp:684] Ignoring source layer z3_n_noisy_z3_n_0_split
I0705 11:40:06.846330 14303 net.cpp:684] Ignoring source layer scale3_n
I0705 11:40:06.846333 14303 net.cpp:684] Ignoring source layer relu3_n
I0705 11:40:06.846335 14303 net.cpp:684] Ignoring source layer pool3_n
I0705 11:40:06.846338 14303 net.cpp:684] Ignoring source layer z4_bn4_0_split
I0705 11:40:06.846340 14303 net.cpp:684] Ignoring source layer bn4_n
I0705 11:40:06.846343 14303 net.cpp:684] Ignoring source layer noisy_z4_n
I0705 11:40:06.846344 14303 net.cpp:684] Ignoring source layer z4_n_noisy_z4_n_0_split
I0705 11:40:06.846346 14303 net.cpp:684] Ignoring source layer scale4_n
I0705 11:40:06.846349 14303 net.cpp:684] Ignoring source layer relu4_n
I0705 11:40:06.846350 14303 net.cpp:684] Ignoring source layer pool4_n
I0705 11:40:06.846354 14303 net.cpp:684] Ignoring source layer z5_bn5_0_split
I0705 11:40:06.846356 14303 net.cpp:684] Ignoring source layer bn5_n
I0705 11:40:06.846357 14303 net.cpp:684] Ignoring source layer noisy_z5_n
I0705 11:40:06.846360 14303 net.cpp:684] Ignoring source layer z5_n_noisy_z5_n_0_split
I0705 11:40:06.846361 14303 net.cpp:684] Ignoring source layer scale5_n
I0705 11:40:06.846364 14303 net.cpp:684] Ignoring source layer relu5_n
I0705 11:40:06.846365 14303 net.cpp:684] Ignoring source layer pool5_n
I0705 11:40:06.846369 14303 net.cpp:684] Ignoring source layer z6_bn6_0_split
I0705 11:40:06.846371 14303 net.cpp:684] Ignoring source layer bn6_n
I0705 11:40:06.846374 14303 net.cpp:684] Ignoring source layer noisy_z6_n
I0705 11:40:06.846375 14303 net.cpp:684] Ignoring source layer z6_n_noisy_z6_n_0_split
I0705 11:40:06.846377 14303 net.cpp:684] Ignoring source layer scale6_n
I0705 11:40:06.846379 14303 net.cpp:684] Ignoring source layer relu6_n
I0705 11:40:06.846380 14303 net.cpp:684] Ignoring source layer u6
I0705 11:40:06.846384 14303 net.cpp:684] Ignoring source layer comb6
I0705 11:40:06.846385 14303 net.cpp:684] Ignoring source layer z6_r_comb6_0_split
I0705 11:40:06.846405 14303 net.cpp:684] Ignoring source layer recon6
I0705 11:40:06.846407 14303 net.cpp:684] Ignoring source layer bn6_r
I0705 11:40:06.846410 14303 net.cpp:684] Ignoring source layer upsample5
I0705 11:40:06.846412 14303 net.cpp:684] Ignoring source layer comb5
I0705 11:40:06.846413 14303 net.cpp:684] Ignoring source layer z5_r_comb5_0_split
I0705 11:40:06.846415 14303 net.cpp:684] Ignoring source layer recon5
I0705 11:40:06.846417 14303 net.cpp:684] Ignoring source layer bn5_r
I0705 11:40:06.846420 14303 net.cpp:684] Ignoring source layer upsample4
I0705 11:40:06.846421 14303 net.cpp:684] Ignoring source layer comb4
I0705 11:40:06.846423 14303 net.cpp:684] Ignoring source layer z4_r_comb4_0_split
I0705 11:40:06.846424 14303 net.cpp:684] Ignoring source layer recon4
I0705 11:40:06.846426 14303 net.cpp:684] Ignoring source layer bn4_r
I0705 11:40:06.846428 14303 net.cpp:684] Ignoring source layer upsample3
I0705 11:40:06.846431 14303 net.cpp:684] Ignoring source layer comb3
I0705 11:40:06.846431 14303 net.cpp:684] Ignoring source layer z3_r_comb3_0_split
I0705 11:40:06.846433 14303 net.cpp:684] Ignoring source layer recon3
I0705 11:40:06.846436 14303 net.cpp:684] Ignoring source layer bn3_r
I0705 11:40:06.846437 14303 net.cpp:684] Ignoring source layer upsample2
I0705 11:40:06.846439 14303 net.cpp:684] Ignoring source layer comb2
I0705 11:40:06.846441 14303 net.cpp:684] Ignoring source layer z2_r_comb2_0_split
I0705 11:40:06.846442 14303 net.cpp:684] Ignoring source layer recon2
I0705 11:40:06.846444 14303 net.cpp:684] Ignoring source layer bn2_r
I0705 11:40:06.846446 14303 net.cpp:684] Ignoring source layer upsample1
I0705 11:40:06.846448 14303 net.cpp:684] Ignoring source layer comb1
I0705 11:40:06.846451 14303 net.cpp:684] Ignoring source layer z1_r_comb1_0_split
I0705 11:40:06.846451 14303 net.cpp:684] Ignoring source layer recon1
I0705 11:40:06.846454 14303 net.cpp:684] Ignoring source layer bn1_r
I0705 11:40:06.846456 14303 net.cpp:684] Ignoring source layer comb0
I0705 11:40:06.846457 14303 net.cpp:684] Ignoring source layer loss_ladder_6
I0705 11:40:06.846459 14303 net.cpp:684] Ignoring source layer loss_ladder_5
I0705 11:40:06.846460 14303 net.cpp:684] Ignoring source layer loss_ladder_4
I0705 11:40:06.846462 14303 net.cpp:684] Ignoring source layer loss_ladder_3
I0705 11:40:06.846464 14303 net.cpp:684] Ignoring source layer loss_ladder_2
I0705 11:40:06.846465 14303 net.cpp:684] Ignoring source layer loss_ladder_1
I0705 11:40:06.846467 14303 net.cpp:684] Ignoring source layer loss_ladder_0
I0705 11:40:06.846470 14303 net.cpp:684] Ignoring source layer loss_supervised
I0705 11:40:07.005688 14303 solver.cpp:404]     Test net output #0: accuracy = 0.640625
I0705 11:40:07.005712 14303 solver.cpp:404]     Test net output #1: prob = 0.672326 (* 1 = 0.672326 loss)
I0705 11:40:07.099210 14303 solver.cpp:228] Iteration 200, loss = 5.98111
I0705 11:40:07.099228 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:40:07.099246 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.108886 (* 0.1 = 0.0108886 loss)
I0705 11:40:07.099251 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 45.9289 (* 0.1 = 4.59289 loss)
I0705 11:40:07.099254 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.97758 (* 0.1 = 0.297758 loss)
I0705 11:40:07.099258 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.09328 (* 0.1 = 0.109328 loss)
I0705 11:40:07.099262 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.870994 (* 0.1 = 0.0870994 loss)
I0705 11:40:07.099266 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 1.02216 (* 0.1 = 0.102216 loss)
I0705 11:40:07.099269 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.962972 (* 0.1 = 0.0962972 loss)
I0705 11:40:07.099273 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.684641 (* 1 = 0.684641 loss)
I0705 11:40:07.099277 14303 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0705 11:40:12.530802 14303 solver.cpp:228] Iteration 220, loss = 6.37284
I0705 11:40:12.530835 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:40:12.530843 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.119042 (* 0.1 = 0.0119042 loss)
I0705 11:40:12.530848 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 51.1901 (* 0.1 = 5.11901 loss)
I0705 11:40:12.530853 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.02702 (* 0.1 = 0.202702 loss)
I0705 11:40:12.530856 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.08059 (* 0.1 = 0.108059 loss)
I0705 11:40:12.530860 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.876343 (* 0.1 = 0.0876343 loss)
I0705 11:40:12.530874 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 1.0461 (* 0.1 = 0.10461 loss)
I0705 11:40:12.530879 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.970776 (* 0.1 = 0.0970776 loss)
I0705 11:40:12.530882 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.641846 (* 1 = 0.641846 loss)
I0705 11:40:12.530886 14303 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0705 11:40:17.963522 14303 solver.cpp:228] Iteration 240, loss = 6.54532
I0705 11:40:17.963660 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0705 11:40:17.963670 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.118585 (* 0.1 = 0.0118585 loss)
I0705 11:40:17.963673 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 52.0689 (* 0.1 = 5.20689 loss)
I0705 11:40:17.963678 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.16083 (* 0.1 = 0.216083 loss)
I0705 11:40:17.963682 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.10034 (* 0.1 = 0.110034 loss)
I0705 11:40:17.963686 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.872864 (* 0.1 = 0.0872864 loss)
I0705 11:40:17.963690 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 1.03645 (* 0.1 = 0.103645 loss)
I0705 11:40:17.963693 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.974838 (* 0.1 = 0.0974838 loss)
I0705 11:40:17.963697 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.712038 (* 1 = 0.712038 loss)
I0705 11:40:17.963701 14303 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0705 11:40:23.395922 14303 solver.cpp:228] Iteration 260, loss = 5.99406
I0705 11:40:23.395943 14303 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0705 11:40:23.395951 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.113246 (* 0.1 = 0.0113246 loss)
I0705 11:40:23.395956 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 47.0975 (* 0.1 = 4.70975 loss)
I0705 11:40:23.395959 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.64542 (* 0.1 = 0.264542 loss)
I0705 11:40:23.395963 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.12854 (* 0.1 = 0.112854 loss)
I0705 11:40:23.395967 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.898549 (* 0.1 = 0.0898549 loss)
I0705 11:40:23.395970 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 1.03498 (* 0.1 = 0.103498 loss)
I0705 11:40:23.395974 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.96685 (* 0.1 = 0.096685 loss)
I0705 11:40:23.395978 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.605551 (* 1 = 0.605551 loss)
I0705 11:40:23.395982 14303 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0705 11:40:28.830008 14303 solver.cpp:228] Iteration 280, loss = 8.8111
I0705 11:40:28.830041 14303 solver.cpp:244]     Train net output #0: accuracy = 0.375
I0705 11:40:28.830049 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.121413 (* 0.1 = 0.0121413 loss)
I0705 11:40:28.830054 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 75.4726 (* 0.1 = 7.54726 loss)
I0705 11:40:28.830057 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.31081 (* 0.1 = 0.131081 loss)
I0705 11:40:28.830062 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.91096 (* 0.1 = 0.091096 loss)
I0705 11:40:28.830066 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.807663 (* 0.1 = 0.0807663 loss)
I0705 11:40:28.830070 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.966362 (* 0.1 = 0.0966362 loss)
I0705 11:40:28.830073 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.918708 (* 0.1 = 0.0918708 loss)
I0705 11:40:28.830077 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.76025 (* 1 = 0.76025 loss)
I0705 11:40:28.830081 14303 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0705 11:40:34.166970 14303 solver.cpp:337] Iteration 300, Testing net (#0)
I0705 11:40:34.166987 14303 net.cpp:684] Ignoring source layer data_data_0_split
I0705 11:40:34.166990 14303 net.cpp:684] Ignoring source layer noisy_data
I0705 11:40:34.166992 14303 net.cpp:684] Ignoring source layer noisy_data_noisy_data_0_split
I0705 11:40:34.166995 14303 net.cpp:684] Ignoring source layer z1_bn1_0_split
I0705 11:40:34.166997 14303 net.cpp:684] Ignoring source layer bn1_n
I0705 11:40:34.166999 14303 net.cpp:684] Ignoring source layer noisy_z1_n
I0705 11:40:34.167001 14303 net.cpp:684] Ignoring source layer z1_n_noisy_z1_n_0_split
I0705 11:40:34.167003 14303 net.cpp:684] Ignoring source layer scale1_n
I0705 11:40:34.167021 14303 net.cpp:684] Ignoring source layer relu1_n
I0705 11:40:34.167023 14303 net.cpp:684] Ignoring source layer pool1_n
I0705 11:40:34.167026 14303 net.cpp:684] Ignoring source layer z2_bn2_0_split
I0705 11:40:34.167028 14303 net.cpp:684] Ignoring source layer bn2_n
I0705 11:40:34.167031 14303 net.cpp:684] Ignoring source layer noisy_z2_n
I0705 11:40:34.167032 14303 net.cpp:684] Ignoring source layer z2_n_noisy_z2_n_0_split
I0705 11:40:34.167033 14303 net.cpp:684] Ignoring source layer scale2_n
I0705 11:40:34.167035 14303 net.cpp:684] Ignoring source layer relu2_n
I0705 11:40:34.167037 14303 net.cpp:684] Ignoring source layer pool2_n
I0705 11:40:34.167040 14303 net.cpp:684] Ignoring source layer z3_bn3_0_split
I0705 11:40:34.167043 14303 net.cpp:684] Ignoring source layer bn3_n
I0705 11:40:34.167045 14303 net.cpp:684] Ignoring source layer noisy_z3_n
I0705 11:40:34.167047 14303 net.cpp:684] Ignoring source layer z3_n_noisy_z3_n_0_split
I0705 11:40:34.167048 14303 net.cpp:684] Ignoring source layer scale3_n
I0705 11:40:34.167050 14303 net.cpp:684] Ignoring source layer relu3_n
I0705 11:40:34.167052 14303 net.cpp:684] Ignoring source layer pool3_n
I0705 11:40:34.167054 14303 net.cpp:684] Ignoring source layer z4_bn4_0_split
I0705 11:40:34.167068 14303 net.cpp:684] Ignoring source layer bn4_n
I0705 11:40:34.167070 14303 net.cpp:684] Ignoring source layer noisy_z4_n
I0705 11:40:34.167073 14303 net.cpp:684] Ignoring source layer z4_n_noisy_z4_n_0_split
I0705 11:40:34.167074 14303 net.cpp:684] Ignoring source layer scale4_n
I0705 11:40:34.167075 14303 net.cpp:684] Ignoring source layer relu4_n
I0705 11:40:34.167078 14303 net.cpp:684] Ignoring source layer pool4_n
I0705 11:40:34.167080 14303 net.cpp:684] Ignoring source layer z5_bn5_0_split
I0705 11:40:34.167083 14303 net.cpp:684] Ignoring source layer bn5_n
I0705 11:40:34.167085 14303 net.cpp:684] Ignoring source layer noisy_z5_n
I0705 11:40:34.167086 14303 net.cpp:684] Ignoring source layer z5_n_noisy_z5_n_0_split
I0705 11:40:34.167088 14303 net.cpp:684] Ignoring source layer scale5_n
I0705 11:40:34.167090 14303 net.cpp:684] Ignoring source layer relu5_n
I0705 11:40:34.167093 14303 net.cpp:684] Ignoring source layer pool5_n
I0705 11:40:34.167095 14303 net.cpp:684] Ignoring source layer z6_bn6_0_split
I0705 11:40:34.167098 14303 net.cpp:684] Ignoring source layer bn6_n
I0705 11:40:34.167099 14303 net.cpp:684] Ignoring source layer noisy_z6_n
I0705 11:40:34.167101 14303 net.cpp:684] Ignoring source layer z6_n_noisy_z6_n_0_split
I0705 11:40:34.167104 14303 net.cpp:684] Ignoring source layer scale6_n
I0705 11:40:34.167105 14303 net.cpp:684] Ignoring source layer relu6_n
I0705 11:40:34.167107 14303 net.cpp:684] Ignoring source layer u6
I0705 11:40:34.167109 14303 net.cpp:684] Ignoring source layer comb6
I0705 11:40:34.167111 14303 net.cpp:684] Ignoring source layer z6_r_comb6_0_split
I0705 11:40:34.167114 14303 net.cpp:684] Ignoring source layer recon6
I0705 11:40:34.167115 14303 net.cpp:684] Ignoring source layer bn6_r
I0705 11:40:34.167117 14303 net.cpp:684] Ignoring source layer upsample5
I0705 11:40:34.167119 14303 net.cpp:684] Ignoring source layer comb5
I0705 11:40:34.167121 14303 net.cpp:684] Ignoring source layer z5_r_comb5_0_split
I0705 11:40:34.167124 14303 net.cpp:684] Ignoring source layer recon5
I0705 11:40:34.167124 14303 net.cpp:684] Ignoring source layer bn5_r
I0705 11:40:34.167126 14303 net.cpp:684] Ignoring source layer upsample4
I0705 11:40:34.167129 14303 net.cpp:684] Ignoring source layer comb4
I0705 11:40:34.167130 14303 net.cpp:684] Ignoring source layer z4_r_comb4_0_split
I0705 11:40:34.167132 14303 net.cpp:684] Ignoring source layer recon4
I0705 11:40:34.167135 14303 net.cpp:684] Ignoring source layer bn4_r
I0705 11:40:34.167135 14303 net.cpp:684] Ignoring source layer upsample3
I0705 11:40:34.167137 14303 net.cpp:684] Ignoring source layer comb3
I0705 11:40:34.167140 14303 net.cpp:684] Ignoring source layer z3_r_comb3_0_split
I0705 11:40:34.167141 14303 net.cpp:684] Ignoring source layer recon3
I0705 11:40:34.167147 14303 net.cpp:684] Ignoring source layer bn3_r
I0705 11:40:34.167148 14303 net.cpp:684] Ignoring source layer upsample2
I0705 11:40:34.167150 14303 net.cpp:684] Ignoring source layer comb2
I0705 11:40:34.167152 14303 net.cpp:684] Ignoring source layer z2_r_comb2_0_split
I0705 11:40:34.167155 14303 net.cpp:684] Ignoring source layer recon2
I0705 11:40:34.167156 14303 net.cpp:684] Ignoring source layer bn2_r
I0705 11:40:34.167158 14303 net.cpp:684] Ignoring source layer upsample1
I0705 11:40:34.167160 14303 net.cpp:684] Ignoring source layer comb1
I0705 11:40:34.167161 14303 net.cpp:684] Ignoring source layer z1_r_comb1_0_split
I0705 11:40:34.167163 14303 net.cpp:684] Ignoring source layer recon1
I0705 11:40:34.167165 14303 net.cpp:684] Ignoring source layer bn1_r
I0705 11:40:34.167167 14303 net.cpp:684] Ignoring source layer comb0
I0705 11:40:34.167168 14303 net.cpp:684] Ignoring source layer loss_ladder_6
I0705 11:40:34.167171 14303 net.cpp:684] Ignoring source layer loss_ladder_5
I0705 11:40:34.167172 14303 net.cpp:684] Ignoring source layer loss_ladder_4
I0705 11:40:34.167174 14303 net.cpp:684] Ignoring source layer loss_ladder_3
I0705 11:40:34.167176 14303 net.cpp:684] Ignoring source layer loss_ladder_2
I0705 11:40:34.167177 14303 net.cpp:684] Ignoring source layer loss_ladder_1
I0705 11:40:34.167179 14303 net.cpp:684] Ignoring source layer loss_ladder_0
I0705 11:40:34.167182 14303 net.cpp:684] Ignoring source layer loss_supervised
I0705 11:40:34.326467 14303 solver.cpp:404]     Test net output #0: accuracy = 0.539062
I0705 11:40:34.326503 14303 solver.cpp:404]     Test net output #1: prob = 0.952511 (* 1 = 0.952511 loss)
I0705 11:40:34.420099 14303 solver.cpp:228] Iteration 300, loss = 5.49063
I0705 11:40:34.420117 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:40:34.420125 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.112304 (* 0.1 = 0.0112304 loss)
I0705 11:40:34.420128 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 42.4435 (* 0.1 = 4.24435 loss)
I0705 11:40:34.420132 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.65489 (* 0.1 = 0.265489 loss)
I0705 11:40:34.420136 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.10608 (* 0.1 = 0.110608 loss)
I0705 11:40:34.420140 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.8904 (* 0.1 = 0.08904 loss)
I0705 11:40:34.420143 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 1.02703 (* 0.1 = 0.102703 loss)
I0705 11:40:34.420147 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.95195 (* 0.1 = 0.095195 loss)
I0705 11:40:34.420151 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.572011 (* 1 = 0.572011 loss)
I0705 11:40:34.420156 14303 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0705 11:40:39.861528 14303 solver.cpp:228] Iteration 320, loss = 5.91079
I0705 11:40:39.861552 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:40:39.861557 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.104351 (* 0.1 = 0.0104351 loss)
I0705 11:40:39.861562 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 45.4804 (* 0.1 = 4.54804 loss)
I0705 11:40:39.861567 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 3.1002 (* 0.1 = 0.31002 loss)
I0705 11:40:39.861570 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.10142 (* 0.1 = 0.110142 loss)
I0705 11:40:39.861573 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.893104 (* 0.1 = 0.0893104 loss)
I0705 11:40:39.861577 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 1.00911 (* 0.1 = 0.100911 loss)
I0705 11:40:39.861582 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.937922 (* 0.1 = 0.0937922 loss)
I0705 11:40:39.861584 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.648146 (* 1 = 0.648146 loss)
I0705 11:40:39.861588 14303 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0705 11:40:45.406338 14303 solver.cpp:228] Iteration 340, loss = 8.44987
I0705 11:40:45.406379 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0705 11:40:45.406388 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.120499 (* 0.1 = 0.0120499 loss)
I0705 11:40:45.406391 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 72.0624 (* 0.1 = 7.20624 loss)
I0705 11:40:45.406407 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.59592 (* 0.1 = 0.159592 loss)
I0705 11:40:45.406411 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.954817 (* 0.1 = 0.0954817 loss)
I0705 11:40:45.406415 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.813675 (* 0.1 = 0.0813675 loss)
I0705 11:40:45.406419 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.987488 (* 0.1 = 0.0987488 loss)
I0705 11:40:45.406422 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.924987 (* 0.1 = 0.0924987 loss)
I0705 11:40:45.406426 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.703887 (* 1 = 0.703887 loss)
I0705 11:40:45.406430 14303 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0705 11:40:50.948307 14303 solver.cpp:228] Iteration 360, loss = 5.6273
I0705 11:40:50.948437 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:40:50.948448 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.110806 (* 0.1 = 0.0110806 loss)
I0705 11:40:50.948452 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 43.8165 (* 0.1 = 4.38165 loss)
I0705 11:40:50.948457 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.36483 (* 0.1 = 0.236483 loss)
I0705 11:40:50.948460 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.06794 (* 0.1 = 0.106794 loss)
I0705 11:40:50.948464 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.874942 (* 0.1 = 0.0874942 loss)
I0705 11:40:50.948468 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 1.01149 (* 0.1 = 0.101149 loss)
I0705 11:40:50.948472 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.940345 (* 0.1 = 0.0940345 loss)
I0705 11:40:50.948477 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.608618 (* 1 = 0.608618 loss)
I0705 11:40:50.948480 14303 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0705 11:40:56.438778 14303 solver.cpp:228] Iteration 380, loss = 8.23969
I0705 11:40:56.438802 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:40:56.438808 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.119074 (* 0.1 = 0.0119074 loss)
I0705 11:40:56.438812 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 70.9334 (* 0.1 = 7.09334 loss)
I0705 11:40:56.438817 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.52847 (* 0.1 = 0.152847 loss)
I0705 11:40:56.438820 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.96854 (* 0.1 = 0.096854 loss)
I0705 11:40:56.438824 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.825419 (* 0.1 = 0.0825419 loss)
I0705 11:40:56.438827 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.972577 (* 0.1 = 0.0972577 loss)
I0705 11:40:56.438832 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.951953 (* 0.1 = 0.0951953 loss)
I0705 11:40:56.438835 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.609741 (* 1 = 0.609741 loss)
I0705 11:40:56.438839 14303 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0705 11:41:01.822777 14303 solver.cpp:337] Iteration 400, Testing net (#0)
I0705 11:41:01.822795 14303 net.cpp:684] Ignoring source layer data_data_0_split
I0705 11:41:01.822809 14303 net.cpp:684] Ignoring source layer noisy_data
I0705 11:41:01.822810 14303 net.cpp:684] Ignoring source layer noisy_data_noisy_data_0_split
I0705 11:41:01.822813 14303 net.cpp:684] Ignoring source layer z1_bn1_0_split
I0705 11:41:01.822816 14303 net.cpp:684] Ignoring source layer bn1_n
I0705 11:41:01.822818 14303 net.cpp:684] Ignoring source layer noisy_z1_n
I0705 11:41:01.822820 14303 net.cpp:684] Ignoring source layer z1_n_noisy_z1_n_0_split
I0705 11:41:01.822823 14303 net.cpp:684] Ignoring source layer scale1_n
I0705 11:41:01.822825 14303 net.cpp:684] Ignoring source layer relu1_n
I0705 11:41:01.822827 14303 net.cpp:684] Ignoring source layer pool1_n
I0705 11:41:01.822831 14303 net.cpp:684] Ignoring source layer z2_bn2_0_split
I0705 11:41:01.822834 14303 net.cpp:684] Ignoring source layer bn2_n
I0705 11:41:01.822835 14303 net.cpp:684] Ignoring source layer noisy_z2_n
I0705 11:41:01.822837 14303 net.cpp:684] Ignoring source layer z2_n_noisy_z2_n_0_split
I0705 11:41:01.822839 14303 net.cpp:684] Ignoring source layer scale2_n
I0705 11:41:01.822840 14303 net.cpp:684] Ignoring source layer relu2_n
I0705 11:41:01.822842 14303 net.cpp:684] Ignoring source layer pool2_n
I0705 11:41:01.822845 14303 net.cpp:684] Ignoring source layer z3_bn3_0_split
I0705 11:41:01.822849 14303 net.cpp:684] Ignoring source layer bn3_n
I0705 11:41:01.822849 14303 net.cpp:684] Ignoring source layer noisy_z3_n
I0705 11:41:01.822851 14303 net.cpp:684] Ignoring source layer z3_n_noisy_z3_n_0_split
I0705 11:41:01.822854 14303 net.cpp:684] Ignoring source layer scale3_n
I0705 11:41:01.822855 14303 net.cpp:684] Ignoring source layer relu3_n
I0705 11:41:01.822871 14303 net.cpp:684] Ignoring source layer pool3_n
I0705 11:41:01.822875 14303 net.cpp:684] Ignoring source layer z4_bn4_0_split
I0705 11:41:01.822877 14303 net.cpp:684] Ignoring source layer bn4_n
I0705 11:41:01.822880 14303 net.cpp:684] Ignoring source layer noisy_z4_n
I0705 11:41:01.822880 14303 net.cpp:684] Ignoring source layer z4_n_noisy_z4_n_0_split
I0705 11:41:01.822882 14303 net.cpp:684] Ignoring source layer scale4_n
I0705 11:41:01.822885 14303 net.cpp:684] Ignoring source layer relu4_n
I0705 11:41:01.822886 14303 net.cpp:684] Ignoring source layer pool4_n
I0705 11:41:01.822890 14303 net.cpp:684] Ignoring source layer z5_bn5_0_split
I0705 11:41:01.822891 14303 net.cpp:684] Ignoring source layer bn5_n
I0705 11:41:01.822893 14303 net.cpp:684] Ignoring source layer noisy_z5_n
I0705 11:41:01.822896 14303 net.cpp:684] Ignoring source layer z5_n_noisy_z5_n_0_split
I0705 11:41:01.822897 14303 net.cpp:684] Ignoring source layer scale5_n
I0705 11:41:01.822899 14303 net.cpp:684] Ignoring source layer relu5_n
I0705 11:41:01.822901 14303 net.cpp:684] Ignoring source layer pool5_n
I0705 11:41:01.822904 14303 net.cpp:684] Ignoring source layer z6_bn6_0_split
I0705 11:41:01.822906 14303 net.cpp:684] Ignoring source layer bn6_n
I0705 11:41:01.822909 14303 net.cpp:684] Ignoring source layer noisy_z6_n
I0705 11:41:01.822911 14303 net.cpp:684] Ignoring source layer z6_n_noisy_z6_n_0_split
I0705 11:41:01.822912 14303 net.cpp:684] Ignoring source layer scale6_n
I0705 11:41:01.822914 14303 net.cpp:684] Ignoring source layer relu6_n
I0705 11:41:01.822916 14303 net.cpp:684] Ignoring source layer u6
I0705 11:41:01.822918 14303 net.cpp:684] Ignoring source layer comb6
I0705 11:41:01.822921 14303 net.cpp:684] Ignoring source layer z6_r_comb6_0_split
I0705 11:41:01.822922 14303 net.cpp:684] Ignoring source layer recon6
I0705 11:41:01.822924 14303 net.cpp:684] Ignoring source layer bn6_r
I0705 11:41:01.822926 14303 net.cpp:684] Ignoring source layer upsample5
I0705 11:41:01.822927 14303 net.cpp:684] Ignoring source layer comb5
I0705 11:41:01.822929 14303 net.cpp:684] Ignoring source layer z5_r_comb5_0_split
I0705 11:41:01.822932 14303 net.cpp:684] Ignoring source layer recon5
I0705 11:41:01.822933 14303 net.cpp:684] Ignoring source layer bn5_r
I0705 11:41:01.822935 14303 net.cpp:684] Ignoring source layer upsample4
I0705 11:41:01.822937 14303 net.cpp:684] Ignoring source layer comb4
I0705 11:41:01.822939 14303 net.cpp:684] Ignoring source layer z4_r_comb4_0_split
I0705 11:41:01.822940 14303 net.cpp:684] Ignoring source layer recon4
I0705 11:41:01.822942 14303 net.cpp:684] Ignoring source layer bn4_r
I0705 11:41:01.822944 14303 net.cpp:684] Ignoring source layer upsample3
I0705 11:41:01.822947 14303 net.cpp:684] Ignoring source layer comb3
I0705 11:41:01.822948 14303 net.cpp:684] Ignoring source layer z3_r_comb3_0_split
I0705 11:41:01.822949 14303 net.cpp:684] Ignoring source layer recon3
I0705 11:41:01.822952 14303 net.cpp:684] Ignoring source layer bn3_r
I0705 11:41:01.822953 14303 net.cpp:684] Ignoring source layer upsample2
I0705 11:41:01.822955 14303 net.cpp:684] Ignoring source layer comb2
I0705 11:41:01.822957 14303 net.cpp:684] Ignoring source layer z2_r_comb2_0_split
I0705 11:41:01.822959 14303 net.cpp:684] Ignoring source layer recon2
I0705 11:41:01.822960 14303 net.cpp:684] Ignoring source layer bn2_r
I0705 11:41:01.822962 14303 net.cpp:684] Ignoring source layer upsample1
I0705 11:41:01.822964 14303 net.cpp:684] Ignoring source layer comb1
I0705 11:41:01.822967 14303 net.cpp:684] Ignoring source layer z1_r_comb1_0_split
I0705 11:41:01.822968 14303 net.cpp:684] Ignoring source layer recon1
I0705 11:41:01.822970 14303 net.cpp:684] Ignoring source layer bn1_r
I0705 11:41:01.822973 14303 net.cpp:684] Ignoring source layer comb0
I0705 11:41:01.822973 14303 net.cpp:684] Ignoring source layer loss_ladder_6
I0705 11:41:01.822975 14303 net.cpp:684] Ignoring source layer loss_ladder_5
I0705 11:41:01.822978 14303 net.cpp:684] Ignoring source layer loss_ladder_4
I0705 11:41:01.822979 14303 net.cpp:684] Ignoring source layer loss_ladder_3
I0705 11:41:01.822984 14303 net.cpp:684] Ignoring source layer loss_ladder_2
I0705 11:41:01.822988 14303 net.cpp:684] Ignoring source layer loss_ladder_1
I0705 11:41:01.822988 14303 net.cpp:684] Ignoring source layer loss_ladder_0
I0705 11:41:01.822991 14303 net.cpp:684] Ignoring source layer loss_supervised
I0705 11:41:01.983506 14303 solver.cpp:404]     Test net output #0: accuracy = 0.554688
I0705 11:41:01.983541 14303 solver.cpp:404]     Test net output #1: prob = 0.752059 (* 1 = 0.752059 loss)
I0705 11:41:02.077920 14303 solver.cpp:228] Iteration 400, loss = 6.42819
I0705 11:41:02.077941 14303 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0705 11:41:02.077947 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.106306 (* 0.1 = 0.0106306 loss)
I0705 11:41:02.077952 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 51.0418 (* 0.1 = 5.10418 loss)
I0705 11:41:02.077956 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 3.14124 (* 0.1 = 0.314124 loss)
I0705 11:41:02.077960 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.10061 (* 0.1 = 0.110061 loss)
I0705 11:41:02.077963 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.87816 (* 0.1 = 0.087816 loss)
I0705 11:41:02.077967 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.985605 (* 0.1 = 0.0985605 loss)
I0705 11:41:02.077971 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.928753 (* 0.1 = 0.0928753 loss)
I0705 11:41:02.077975 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.609947 (* 1 = 0.609947 loss)
I0705 11:41:02.077980 14303 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0705 11:41:07.566102 14303 solver.cpp:228] Iteration 420, loss = 7.62487
I0705 11:41:07.566125 14303 solver.cpp:244]     Train net output #0: accuracy = 0.4375
I0705 11:41:07.566131 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.121773 (* 0.1 = 0.0121773 loss)
I0705 11:41:07.566136 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 63.2329 (* 0.1 = 6.32329 loss)
I0705 11:41:07.566140 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.70222 (* 0.1 = 0.170222 loss)
I0705 11:41:07.566144 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.01743 (* 0.1 = 0.101743 loss)
I0705 11:41:07.566148 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.822577 (* 0.1 = 0.0822577 loss)
I0705 11:41:07.566154 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.981555 (* 0.1 = 0.0981555 loss)
I0705 11:41:07.566156 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.924456 (* 0.1 = 0.0924456 loss)
I0705 11:41:07.566160 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.744575 (* 1 = 0.744575 loss)
I0705 11:41:07.566164 14303 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0705 11:41:13.046362 14303 solver.cpp:228] Iteration 440, loss = 6.60184
I0705 11:41:13.046386 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0705 11:41:13.046393 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.115316 (* 0.1 = 0.0115316 loss)
I0705 11:41:13.046397 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 53.0678 (* 0.1 = 5.30678 loss)
I0705 11:41:13.046401 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.02967 (* 0.1 = 0.202967 loss)
I0705 11:41:13.046406 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.05617 (* 0.1 = 0.105617 loss)
I0705 11:41:13.046409 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.827131 (* 0.1 = 0.0827131 loss)
I0705 11:41:13.046414 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.956455 (* 0.1 = 0.0956455 loss)
I0705 11:41:13.046418 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.88046 (* 0.1 = 0.088046 loss)
I0705 11:41:13.046422 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.708539 (* 1 = 0.708539 loss)
I0705 11:41:13.046425 14303 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0705 11:41:18.527050 14303 solver.cpp:228] Iteration 460, loss = 8.25569
I0705 11:41:18.527093 14303 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0705 11:41:18.527101 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.118768 (* 0.1 = 0.0118768 loss)
I0705 11:41:18.527106 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 70.8646 (* 0.1 = 7.08646 loss)
I0705 11:41:18.527109 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.67141 (* 0.1 = 0.167141 loss)
I0705 11:41:18.527113 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.03085 (* 0.1 = 0.103085 loss)
I0705 11:41:18.527117 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.835382 (* 0.1 = 0.0835382 loss)
I0705 11:41:18.527120 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.966044 (* 0.1 = 0.0966044 loss)
I0705 11:41:18.527124 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.923037 (* 0.1 = 0.0923037 loss)
I0705 11:41:18.527127 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.614683 (* 1 = 0.614683 loss)
I0705 11:41:18.527132 14303 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0705 11:41:23.992842 14303 solver.cpp:228] Iteration 480, loss = 6.45528
I0705 11:41:23.992959 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:41:23.992969 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.113039 (* 0.1 = 0.0113039 loss)
I0705 11:41:23.992974 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 52.2202 (* 0.1 = 5.22202 loss)
I0705 11:41:23.992979 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.23362 (* 0.1 = 0.223362 loss)
I0705 11:41:23.992981 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.08327 (* 0.1 = 0.108327 loss)
I0705 11:41:23.992985 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.8771 (* 0.1 = 0.08771 loss)
I0705 11:41:23.992990 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 1.00663 (* 0.1 = 0.100663 loss)
I0705 11:41:23.992993 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.933184 (* 0.1 = 0.0933184 loss)
I0705 11:41:23.992996 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.608573 (* 1 = 0.608573 loss)
I0705 11:41:23.993000 14303 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0705 11:41:29.371704 14303 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_500.caffemodel
I0705 11:41:29.926117 14303 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_500.solverstate
I0705 11:41:30.073803 14303 solver.cpp:337] Iteration 500, Testing net (#0)
I0705 11:41:30.073827 14303 net.cpp:684] Ignoring source layer data_data_0_split
I0705 11:41:30.073832 14303 net.cpp:684] Ignoring source layer noisy_data
I0705 11:41:30.073833 14303 net.cpp:684] Ignoring source layer noisy_data_noisy_data_0_split
I0705 11:41:30.073837 14303 net.cpp:684] Ignoring source layer z1_bn1_0_split
I0705 11:41:30.073839 14303 net.cpp:684] Ignoring source layer bn1_n
I0705 11:41:30.073842 14303 net.cpp:684] Ignoring source layer noisy_z1_n
I0705 11:41:30.073843 14303 net.cpp:684] Ignoring source layer z1_n_noisy_z1_n_0_split
I0705 11:41:30.073845 14303 net.cpp:684] Ignoring source layer scale1_n
I0705 11:41:30.073846 14303 net.cpp:684] Ignoring source layer relu1_n
I0705 11:41:30.073849 14303 net.cpp:684] Ignoring source layer pool1_n
I0705 11:41:30.073853 14303 net.cpp:684] Ignoring source layer z2_bn2_0_split
I0705 11:41:30.073855 14303 net.cpp:684] Ignoring source layer bn2_n
I0705 11:41:30.073858 14303 net.cpp:684] Ignoring source layer noisy_z2_n
I0705 11:41:30.073859 14303 net.cpp:684] Ignoring source layer z2_n_noisy_z2_n_0_split
I0705 11:41:30.073861 14303 net.cpp:684] Ignoring source layer scale2_n
I0705 11:41:30.073863 14303 net.cpp:684] Ignoring source layer relu2_n
I0705 11:41:30.073865 14303 net.cpp:684] Ignoring source layer pool2_n
I0705 11:41:30.073868 14303 net.cpp:684] Ignoring source layer z3_bn3_0_split
I0705 11:41:30.073871 14303 net.cpp:684] Ignoring source layer bn3_n
I0705 11:41:30.073873 14303 net.cpp:684] Ignoring source layer noisy_z3_n
I0705 11:41:30.073875 14303 net.cpp:684] Ignoring source layer z3_n_noisy_z3_n_0_split
I0705 11:41:30.073878 14303 net.cpp:684] Ignoring source layer scale3_n
I0705 11:41:30.073879 14303 net.cpp:684] Ignoring source layer relu3_n
I0705 11:41:30.073881 14303 net.cpp:684] Ignoring source layer pool3_n
I0705 11:41:30.073884 14303 net.cpp:684] Ignoring source layer z4_bn4_0_split
I0705 11:41:30.073889 14303 net.cpp:684] Ignoring source layer bn4_n
I0705 11:41:30.073890 14303 net.cpp:684] Ignoring source layer noisy_z4_n
I0705 11:41:30.073892 14303 net.cpp:684] Ignoring source layer z4_n_noisy_z4_n_0_split
I0705 11:41:30.073894 14303 net.cpp:684] Ignoring source layer scale4_n
I0705 11:41:30.073896 14303 net.cpp:684] Ignoring source layer relu4_n
I0705 11:41:30.073899 14303 net.cpp:684] Ignoring source layer pool4_n
I0705 11:41:30.073901 14303 net.cpp:684] Ignoring source layer z5_bn5_0_split
I0705 11:41:30.073904 14303 net.cpp:684] Ignoring source layer bn5_n
I0705 11:41:30.073906 14303 net.cpp:684] Ignoring source layer noisy_z5_n
I0705 11:41:30.073909 14303 net.cpp:684] Ignoring source layer z5_n_noisy_z5_n_0_split
I0705 11:41:30.073910 14303 net.cpp:684] Ignoring source layer scale5_n
I0705 11:41:30.073925 14303 net.cpp:684] Ignoring source layer relu5_n
I0705 11:41:30.073927 14303 net.cpp:684] Ignoring source layer pool5_n
I0705 11:41:30.073930 14303 net.cpp:684] Ignoring source layer z6_bn6_0_split
I0705 11:41:30.073933 14303 net.cpp:684] Ignoring source layer bn6_n
I0705 11:41:30.073935 14303 net.cpp:684] Ignoring source layer noisy_z6_n
I0705 11:41:30.073937 14303 net.cpp:684] Ignoring source layer z6_n_noisy_z6_n_0_split
I0705 11:41:30.073940 14303 net.cpp:684] Ignoring source layer scale6_n
I0705 11:41:30.073940 14303 net.cpp:684] Ignoring source layer relu6_n
I0705 11:41:30.073942 14303 net.cpp:684] Ignoring source layer u6
I0705 11:41:30.073945 14303 net.cpp:684] Ignoring source layer comb6
I0705 11:41:30.073946 14303 net.cpp:684] Ignoring source layer z6_r_comb6_0_split
I0705 11:41:30.073950 14303 net.cpp:684] Ignoring source layer recon6
I0705 11:41:30.073951 14303 net.cpp:684] Ignoring source layer bn6_r
I0705 11:41:30.073952 14303 net.cpp:684] Ignoring source layer upsample5
I0705 11:41:30.073954 14303 net.cpp:684] Ignoring source layer comb5
I0705 11:41:30.073957 14303 net.cpp:684] Ignoring source layer z5_r_comb5_0_split
I0705 11:41:30.073958 14303 net.cpp:684] Ignoring source layer recon5
I0705 11:41:30.073961 14303 net.cpp:684] Ignoring source layer bn5_r
I0705 11:41:30.073962 14303 net.cpp:684] Ignoring source layer upsample4
I0705 11:41:30.073964 14303 net.cpp:684] Ignoring source layer comb4
I0705 11:41:30.073966 14303 net.cpp:684] Ignoring source layer z4_r_comb4_0_split
I0705 11:41:30.073968 14303 net.cpp:684] Ignoring source layer recon4
I0705 11:41:30.073971 14303 net.cpp:684] Ignoring source layer bn4_r
I0705 11:41:30.073972 14303 net.cpp:684] Ignoring source layer upsample3
I0705 11:41:30.073974 14303 net.cpp:684] Ignoring source layer comb3
I0705 11:41:30.073976 14303 net.cpp:684] Ignoring source layer z3_r_comb3_0_split
I0705 11:41:30.073978 14303 net.cpp:684] Ignoring source layer recon3
I0705 11:41:30.073981 14303 net.cpp:684] Ignoring source layer bn3_r
I0705 11:41:30.073982 14303 net.cpp:684] Ignoring source layer upsample2
I0705 11:41:30.073984 14303 net.cpp:684] Ignoring source layer comb2
I0705 11:41:30.073985 14303 net.cpp:684] Ignoring source layer z2_r_comb2_0_split
I0705 11:41:30.073987 14303 net.cpp:684] Ignoring source layer recon2
I0705 11:41:30.073989 14303 net.cpp:684] Ignoring source layer bn2_r
I0705 11:41:30.073992 14303 net.cpp:684] Ignoring source layer upsample1
I0705 11:41:30.073993 14303 net.cpp:684] Ignoring source layer comb1
I0705 11:41:30.073995 14303 net.cpp:684] Ignoring source layer z1_r_comb1_0_split
I0705 11:41:30.073997 14303 net.cpp:684] Ignoring source layer recon1
I0705 11:41:30.073999 14303 net.cpp:684] Ignoring source layer bn1_r
I0705 11:41:30.074002 14303 net.cpp:684] Ignoring source layer comb0
I0705 11:41:30.074003 14303 net.cpp:684] Ignoring source layer loss_ladder_6
I0705 11:41:30.074004 14303 net.cpp:684] Ignoring source layer loss_ladder_5
I0705 11:41:30.074007 14303 net.cpp:684] Ignoring source layer loss_ladder_4
I0705 11:41:30.074008 14303 net.cpp:684] Ignoring source layer loss_ladder_3
I0705 11:41:30.074010 14303 net.cpp:684] Ignoring source layer loss_ladder_2
I0705 11:41:30.074012 14303 net.cpp:684] Ignoring source layer loss_ladder_1
I0705 11:41:30.074014 14303 net.cpp:684] Ignoring source layer loss_ladder_0
I0705 11:41:30.074018 14303 net.cpp:684] Ignoring source layer loss_supervised
I0705 11:41:30.233597 14303 solver.cpp:404]     Test net output #0: accuracy = 0.578125
I0705 11:41:30.233626 14303 solver.cpp:404]     Test net output #1: prob = 0.735029 (* 1 = 0.735029 loss)
I0705 11:41:30.328965 14303 solver.cpp:228] Iteration 500, loss = 5.85072
I0705 11:41:30.329005 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:41:30.329017 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.103409 (* 0.1 = 0.0103409 loss)
I0705 11:41:30.329026 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 44.7004 (* 0.1 = 4.47004 loss)
I0705 11:41:30.329035 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 3.08133 (* 0.1 = 0.308133 loss)
I0705 11:41:30.329072 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.10397 (* 0.1 = 0.110397 loss)
I0705 11:41:30.329080 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.862914 (* 0.1 = 0.0862914 loss)
I0705 11:41:30.329088 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.963039 (* 0.1 = 0.0963039 loss)
I0705 11:41:30.329095 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.899915 (* 0.1 = 0.0899915 loss)
I0705 11:41:30.329102 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.679227 (* 1 = 0.679227 loss)
I0705 11:41:30.329109 14303 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0705 11:41:35.782032 14303 solver.cpp:228] Iteration 520, loss = 8.24323
I0705 11:41:35.782055 14303 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0705 11:41:35.782063 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.119641 (* 0.1 = 0.0119641 loss)
I0705 11:41:35.782068 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 71.6873 (* 0.1 = 7.16873 loss)
I0705 11:41:35.782073 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.40191 (* 0.1 = 0.140191 loss)
I0705 11:41:35.782076 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.923519 (* 0.1 = 0.0923519 loss)
I0705 11:41:35.782080 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.76847 (* 0.1 = 0.0768469 loss)
I0705 11:41:35.782083 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.912739 (* 0.1 = 0.0912739 loss)
I0705 11:41:35.782088 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.880838 (* 0.1 = 0.0880838 loss)
I0705 11:41:35.782091 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.573788 (* 1 = 0.573788 loss)
I0705 11:41:35.782094 14303 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0705 11:41:41.222932 14303 solver.cpp:228] Iteration 540, loss = 5.53688
I0705 11:41:41.222957 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0705 11:41:41.222965 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.103378 (* 0.1 = 0.0103379 loss)
I0705 11:41:41.222968 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 41.8272 (* 0.1 = 4.18272 loss)
I0705 11:41:41.222973 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 3.02974 (* 0.1 = 0.302974 loss)
I0705 11:41:41.222977 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.07365 (* 0.1 = 0.107365 loss)
I0705 11:41:41.222980 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.862076 (* 0.1 = 0.0862076 loss)
I0705 11:41:41.222985 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.967741 (* 0.1 = 0.0967741 loss)
I0705 11:41:41.222988 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.908136 (* 0.1 = 0.0908136 loss)
I0705 11:41:41.222992 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.659692 (* 1 = 0.659692 loss)
I0705 11:41:41.222995 14303 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0705 11:41:46.692174 14303 solver.cpp:228] Iteration 560, loss = 6.04894
I0705 11:41:46.692198 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:41:46.692205 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.107041 (* 0.1 = 0.0107041 loss)
I0705 11:41:46.692210 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 47.3637 (* 0.1 = 4.73637 loss)
I0705 11:41:46.692214 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.83217 (* 0.1 = 0.283217 loss)
I0705 11:41:46.692219 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.06801 (* 0.1 = 0.106801 loss)
I0705 11:41:46.692222 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.862622 (* 0.1 = 0.0862622 loss)
I0705 11:41:46.692225 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.984855 (* 0.1 = 0.0984855 loss)
I0705 11:41:46.692229 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.918723 (* 0.1 = 0.0918723 loss)
I0705 11:41:46.692251 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.635227 (* 1 = 0.635227 loss)
I0705 11:41:46.692255 14303 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0705 11:41:52.179841 14303 solver.cpp:228] Iteration 580, loss = 5.52363
I0705 11:41:52.179864 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0705 11:41:52.179872 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.105142 (* 0.1 = 0.0105142 loss)
I0705 11:41:52.179875 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 41.4979 (* 0.1 = 4.14979 loss)
I0705 11:41:52.179880 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.58249 (* 0.1 = 0.258249 loss)
I0705 11:41:52.179883 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.02982 (* 0.1 = 0.102982 loss)
I0705 11:41:52.179888 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.842866 (* 0.1 = 0.0842866 loss)
I0705 11:41:52.179891 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.965725 (* 0.1 = 0.0965725 loss)
I0705 11:41:52.179894 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.896519 (* 0.1 = 0.0896519 loss)
I0705 11:41:52.179898 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.73159 (* 1 = 0.73159 loss)
I0705 11:41:52.179903 14303 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0705 11:41:57.538883 14303 solver.cpp:337] Iteration 600, Testing net (#0)
I0705 11:41:57.539006 14303 net.cpp:684] Ignoring source layer data_data_0_split
I0705 11:41:57.539011 14303 net.cpp:684] Ignoring source layer noisy_data
I0705 11:41:57.539013 14303 net.cpp:684] Ignoring source layer noisy_data_noisy_data_0_split
I0705 11:41:57.539016 14303 net.cpp:684] Ignoring source layer z1_bn1_0_split
I0705 11:41:57.539019 14303 net.cpp:684] Ignoring source layer bn1_n
I0705 11:41:57.539021 14303 net.cpp:684] Ignoring source layer noisy_z1_n
I0705 11:41:57.539022 14303 net.cpp:684] Ignoring source layer z1_n_noisy_z1_n_0_split
I0705 11:41:57.539024 14303 net.cpp:684] Ignoring source layer scale1_n
I0705 11:41:57.539026 14303 net.cpp:684] Ignoring source layer relu1_n
I0705 11:41:57.539028 14303 net.cpp:684] Ignoring source layer pool1_n
I0705 11:41:57.539031 14303 net.cpp:684] Ignoring source layer z2_bn2_0_split
I0705 11:41:57.539033 14303 net.cpp:684] Ignoring source layer bn2_n
I0705 11:41:57.539036 14303 net.cpp:684] Ignoring source layer noisy_z2_n
I0705 11:41:57.539037 14303 net.cpp:684] Ignoring source layer z2_n_noisy_z2_n_0_split
I0705 11:41:57.539039 14303 net.cpp:684] Ignoring source layer scale2_n
I0705 11:41:57.539041 14303 net.cpp:684] Ignoring source layer relu2_n
I0705 11:41:57.539043 14303 net.cpp:684] Ignoring source layer pool2_n
I0705 11:41:57.539046 14303 net.cpp:684] Ignoring source layer z3_bn3_0_split
I0705 11:41:57.539048 14303 net.cpp:684] Ignoring source layer bn3_n
I0705 11:41:57.539050 14303 net.cpp:684] Ignoring source layer noisy_z3_n
I0705 11:41:57.539052 14303 net.cpp:684] Ignoring source layer z3_n_noisy_z3_n_0_split
I0705 11:41:57.539053 14303 net.cpp:684] Ignoring source layer scale3_n
I0705 11:41:57.539055 14303 net.cpp:684] Ignoring source layer relu3_n
I0705 11:41:57.539057 14303 net.cpp:684] Ignoring source layer pool3_n
I0705 11:41:57.539060 14303 net.cpp:684] Ignoring source layer z4_bn4_0_split
I0705 11:41:57.539064 14303 net.cpp:684] Ignoring source layer bn4_n
I0705 11:41:57.539067 14303 net.cpp:684] Ignoring source layer noisy_z4_n
I0705 11:41:57.539068 14303 net.cpp:684] Ignoring source layer z4_n_noisy_z4_n_0_split
I0705 11:41:57.539070 14303 net.cpp:684] Ignoring source layer scale4_n
I0705 11:41:57.539072 14303 net.cpp:684] Ignoring source layer relu4_n
I0705 11:41:57.539073 14303 net.cpp:684] Ignoring source layer pool4_n
I0705 11:41:57.539077 14303 net.cpp:684] Ignoring source layer z5_bn5_0_split
I0705 11:41:57.539079 14303 net.cpp:684] Ignoring source layer bn5_n
I0705 11:41:57.539082 14303 net.cpp:684] Ignoring source layer noisy_z5_n
I0705 11:41:57.539083 14303 net.cpp:684] Ignoring source layer z5_n_noisy_z5_n_0_split
I0705 11:41:57.539085 14303 net.cpp:684] Ignoring source layer scale5_n
I0705 11:41:57.539086 14303 net.cpp:684] Ignoring source layer relu5_n
I0705 11:41:57.539088 14303 net.cpp:684] Ignoring source layer pool5_n
I0705 11:41:57.539091 14303 net.cpp:684] Ignoring source layer z6_bn6_0_split
I0705 11:41:57.539094 14303 net.cpp:684] Ignoring source layer bn6_n
I0705 11:41:57.539096 14303 net.cpp:684] Ignoring source layer noisy_z6_n
I0705 11:41:57.539098 14303 net.cpp:684] Ignoring source layer z6_n_noisy_z6_n_0_split
I0705 11:41:57.539099 14303 net.cpp:684] Ignoring source layer scale6_n
I0705 11:41:57.539101 14303 net.cpp:684] Ignoring source layer relu6_n
I0705 11:41:57.539103 14303 net.cpp:684] Ignoring source layer u6
I0705 11:41:57.539105 14303 net.cpp:684] Ignoring source layer comb6
I0705 11:41:57.539108 14303 net.cpp:684] Ignoring source layer z6_r_comb6_0_split
I0705 11:41:57.539109 14303 net.cpp:684] Ignoring source layer recon6
I0705 11:41:57.539111 14303 net.cpp:684] Ignoring source layer bn6_r
I0705 11:41:57.539113 14303 net.cpp:684] Ignoring source layer upsample5
I0705 11:41:57.539115 14303 net.cpp:684] Ignoring source layer comb5
I0705 11:41:57.539118 14303 net.cpp:684] Ignoring source layer z5_r_comb5_0_split
I0705 11:41:57.539119 14303 net.cpp:684] Ignoring source layer recon5
I0705 11:41:57.539120 14303 net.cpp:684] Ignoring source layer bn5_r
I0705 11:41:57.539122 14303 net.cpp:684] Ignoring source layer upsample4
I0705 11:41:57.539130 14303 net.cpp:684] Ignoring source layer comb4
I0705 11:41:57.539132 14303 net.cpp:684] Ignoring source layer z4_r_comb4_0_split
I0705 11:41:57.539134 14303 net.cpp:684] Ignoring source layer recon4
I0705 11:41:57.539135 14303 net.cpp:684] Ignoring source layer bn4_r
I0705 11:41:57.539137 14303 net.cpp:684] Ignoring source layer upsample3
I0705 11:41:57.539139 14303 net.cpp:684] Ignoring source layer comb3
I0705 11:41:57.539141 14303 net.cpp:684] Ignoring source layer z3_r_comb3_0_split
I0705 11:41:57.539144 14303 net.cpp:684] Ignoring source layer recon3
I0705 11:41:57.539144 14303 net.cpp:684] Ignoring source layer bn3_r
I0705 11:41:57.539146 14303 net.cpp:684] Ignoring source layer upsample2
I0705 11:41:57.539149 14303 net.cpp:684] Ignoring source layer comb2
I0705 11:41:57.539150 14303 net.cpp:684] Ignoring source layer z2_r_comb2_0_split
I0705 11:41:57.539152 14303 net.cpp:684] Ignoring source layer recon2
I0705 11:41:57.539154 14303 net.cpp:684] Ignoring source layer bn2_r
I0705 11:41:57.539155 14303 net.cpp:684] Ignoring source layer upsample1
I0705 11:41:57.539157 14303 net.cpp:684] Ignoring source layer comb1
I0705 11:41:57.539160 14303 net.cpp:684] Ignoring source layer z1_r_comb1_0_split
I0705 11:41:57.539161 14303 net.cpp:684] Ignoring source layer recon1
I0705 11:41:57.539162 14303 net.cpp:684] Ignoring source layer bn1_r
I0705 11:41:57.539165 14303 net.cpp:684] Ignoring source layer comb0
I0705 11:41:57.539166 14303 net.cpp:684] Ignoring source layer loss_ladder_6
I0705 11:41:57.539168 14303 net.cpp:684] Ignoring source layer loss_ladder_5
I0705 11:41:57.539170 14303 net.cpp:684] Ignoring source layer loss_ladder_4
I0705 11:41:57.539171 14303 net.cpp:684] Ignoring source layer loss_ladder_3
I0705 11:41:57.539173 14303 net.cpp:684] Ignoring source layer loss_ladder_2
I0705 11:41:57.539175 14303 net.cpp:684] Ignoring source layer loss_ladder_1
I0705 11:41:57.539177 14303 net.cpp:684] Ignoring source layer loss_ladder_0
I0705 11:41:57.539180 14303 net.cpp:684] Ignoring source layer loss_supervised
I0705 11:41:57.698935 14303 solver.cpp:404]     Test net output #0: accuracy = 0.46875
I0705 11:41:57.698971 14303 solver.cpp:404]     Test net output #1: prob = 1.48705 (* 1 = 1.48705 loss)
I0705 11:41:57.792933 14303 solver.cpp:228] Iteration 600, loss = 5.28514
I0705 11:41:57.792954 14303 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0705 11:41:57.792973 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.102619 (* 0.1 = 0.0102619 loss)
I0705 11:41:57.792976 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 40.8411 (* 0.1 = 4.08411 loss)
I0705 11:41:57.792981 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.98086 (* 0.1 = 0.298086 loss)
I0705 11:41:57.792984 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.07848 (* 0.1 = 0.107848 loss)
I0705 11:41:57.792989 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.868208 (* 0.1 = 0.0868208 loss)
I0705 11:41:57.792992 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.957663 (* 0.1 = 0.0957663 loss)
I0705 11:41:57.792996 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.901502 (* 0.1 = 0.0901502 loss)
I0705 11:41:57.793000 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.512093 (* 1 = 0.512093 loss)
I0705 11:41:57.793004 14303 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0705 11:42:03.247809 14303 solver.cpp:228] Iteration 620, loss = 5.63153
I0705 11:42:03.247833 14303 solver.cpp:244]     Train net output #0: accuracy = 0.4375
I0705 11:42:03.247839 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.106076 (* 0.1 = 0.0106076 loss)
I0705 11:42:03.247844 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 42.7814 (* 0.1 = 4.27814 loss)
I0705 11:42:03.247849 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.78344 (* 0.1 = 0.278344 loss)
I0705 11:42:03.247853 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.06768 (* 0.1 = 0.106768 loss)
I0705 11:42:03.247856 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.844212 (* 0.1 = 0.0844212 loss)
I0705 11:42:03.247879 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.947021 (* 0.1 = 0.0947021 loss)
I0705 11:42:03.247882 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.880094 (* 0.1 = 0.0880094 loss)
I0705 11:42:03.247886 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.690536 (* 1 = 0.690536 loss)
I0705 11:42:03.247890 14303 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0705 11:42:08.702934 14303 solver.cpp:228] Iteration 640, loss = 5.21954
I0705 11:42:08.702956 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:42:08.702963 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.10395 (* 0.1 = 0.010395 loss)
I0705 11:42:08.702967 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 39.4714 (* 0.1 = 3.94714 loss)
I0705 11:42:08.702972 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.98161 (* 0.1 = 0.298161 loss)
I0705 11:42:08.702976 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.07199 (* 0.1 = 0.107199 loss)
I0705 11:42:08.702980 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.852679 (* 0.1 = 0.0852679 loss)
I0705 11:42:08.702983 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.941959 (* 0.1 = 0.0941959 loss)
I0705 11:42:08.702987 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.894762 (* 0.1 = 0.0894762 loss)
I0705 11:42:08.702991 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.587702 (* 1 = 0.587702 loss)
I0705 11:42:08.702994 14303 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0705 11:42:14.157335 14303 solver.cpp:228] Iteration 660, loss = 6.1499
I0705 11:42:14.157371 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:42:14.157377 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.109347 (* 0.1 = 0.0109347 loss)
I0705 11:42:14.157382 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 49.2075 (* 0.1 = 4.92075 loss)
I0705 11:42:14.157387 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.40049 (* 0.1 = 0.240049 loss)
I0705 11:42:14.157390 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.04493 (* 0.1 = 0.104493 loss)
I0705 11:42:14.157394 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.824471 (* 0.1 = 0.0824471 loss)
I0705 11:42:14.157398 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.952729 (* 0.1 = 0.0952729 loss)
I0705 11:42:14.157402 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.892773 (* 0.1 = 0.0892773 loss)
I0705 11:42:14.157405 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.60667 (* 1 = 0.60667 loss)
I0705 11:42:14.157409 14303 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0705 11:42:19.630760 14303 solver.cpp:228] Iteration 680, loss = 5.5215
I0705 11:42:19.630784 14303 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0705 11:42:19.630791 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.106886 (* 0.1 = 0.0106886 loss)
I0705 11:42:19.630795 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 43.6952 (* 0.1 = 4.36952 loss)
I0705 11:42:19.630800 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.58659 (* 0.1 = 0.258659 loss)
I0705 11:42:19.630805 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.04749 (* 0.1 = 0.104749 loss)
I0705 11:42:19.630808 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.81891 (* 0.1 = 0.081891 loss)
I0705 11:42:19.630812 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.922 (* 0.1 = 0.0922 loss)
I0705 11:42:19.630816 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.861049 (* 0.1 = 0.0861049 loss)
I0705 11:42:19.630820 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.517685 (* 1 = 0.517685 loss)
I0705 11:42:19.630823 14303 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0705 11:42:25.012545 14303 solver.cpp:337] Iteration 700, Testing net (#0)
I0705 11:42:25.012591 14303 net.cpp:684] Ignoring source layer data_data_0_split
I0705 11:42:25.012595 14303 net.cpp:684] Ignoring source layer noisy_data
I0705 11:42:25.012598 14303 net.cpp:684] Ignoring source layer noisy_data_noisy_data_0_split
I0705 11:42:25.012600 14303 net.cpp:684] Ignoring source layer z1_bn1_0_split
I0705 11:42:25.012603 14303 net.cpp:684] Ignoring source layer bn1_n
I0705 11:42:25.012605 14303 net.cpp:684] Ignoring source layer noisy_z1_n
I0705 11:42:25.012606 14303 net.cpp:684] Ignoring source layer z1_n_noisy_z1_n_0_split
I0705 11:42:25.012610 14303 net.cpp:684] Ignoring source layer scale1_n
I0705 11:42:25.012612 14303 net.cpp:684] Ignoring source layer relu1_n
I0705 11:42:25.012614 14303 net.cpp:684] Ignoring source layer pool1_n
I0705 11:42:25.012617 14303 net.cpp:684] Ignoring source layer z2_bn2_0_split
I0705 11:42:25.012619 14303 net.cpp:684] Ignoring source layer bn2_n
I0705 11:42:25.012621 14303 net.cpp:684] Ignoring source layer noisy_z2_n
I0705 11:42:25.012624 14303 net.cpp:684] Ignoring source layer z2_n_noisy_z2_n_0_split
I0705 11:42:25.012624 14303 net.cpp:684] Ignoring source layer scale2_n
I0705 11:42:25.012626 14303 net.cpp:684] Ignoring source layer relu2_n
I0705 11:42:25.012629 14303 net.cpp:684] Ignoring source layer pool2_n
I0705 11:42:25.012631 14303 net.cpp:684] Ignoring source layer z3_bn3_0_split
I0705 11:42:25.012634 14303 net.cpp:684] Ignoring source layer bn3_n
I0705 11:42:25.012635 14303 net.cpp:684] Ignoring source layer noisy_z3_n
I0705 11:42:25.012637 14303 net.cpp:684] Ignoring source layer z3_n_noisy_z3_n_0_split
I0705 11:42:25.012639 14303 net.cpp:684] Ignoring source layer scale3_n
I0705 11:42:25.012641 14303 net.cpp:684] Ignoring source layer relu3_n
I0705 11:42:25.012644 14303 net.cpp:684] Ignoring source layer pool3_n
I0705 11:42:25.012646 14303 net.cpp:684] Ignoring source layer z4_bn4_0_split
I0705 11:42:25.012650 14303 net.cpp:684] Ignoring source layer bn4_n
I0705 11:42:25.012651 14303 net.cpp:684] Ignoring source layer noisy_z4_n
I0705 11:42:25.012653 14303 net.cpp:684] Ignoring source layer z4_n_noisy_z4_n_0_split
I0705 11:42:25.012655 14303 net.cpp:684] Ignoring source layer scale4_n
I0705 11:42:25.012657 14303 net.cpp:684] Ignoring source layer relu4_n
I0705 11:42:25.012660 14303 net.cpp:684] Ignoring source layer pool4_n
I0705 11:42:25.012662 14303 net.cpp:684] Ignoring source layer z5_bn5_0_split
I0705 11:42:25.012665 14303 net.cpp:684] Ignoring source layer bn5_n
I0705 11:42:25.012667 14303 net.cpp:684] Ignoring source layer noisy_z5_n
I0705 11:42:25.012670 14303 net.cpp:684] Ignoring source layer z5_n_noisy_z5_n_0_split
I0705 11:42:25.012671 14303 net.cpp:684] Ignoring source layer scale5_n
I0705 11:42:25.012672 14303 net.cpp:684] Ignoring source layer relu5_n
I0705 11:42:25.012675 14303 net.cpp:684] Ignoring source layer pool5_n
I0705 11:42:25.012677 14303 net.cpp:684] Ignoring source layer z6_bn6_0_split
I0705 11:42:25.012681 14303 net.cpp:684] Ignoring source layer bn6_n
I0705 11:42:25.012682 14303 net.cpp:684] Ignoring source layer noisy_z6_n
I0705 11:42:25.012684 14303 net.cpp:684] Ignoring source layer z6_n_noisy_z6_n_0_split
I0705 11:42:25.012686 14303 net.cpp:684] Ignoring source layer scale6_n
I0705 11:42:25.012687 14303 net.cpp:684] Ignoring source layer relu6_n
I0705 11:42:25.012689 14303 net.cpp:684] Ignoring source layer u6
I0705 11:42:25.012691 14303 net.cpp:684] Ignoring source layer comb6
I0705 11:42:25.012693 14303 net.cpp:684] Ignoring source layer z6_r_comb6_0_split
I0705 11:42:25.012696 14303 net.cpp:684] Ignoring source layer recon6
I0705 11:42:25.012697 14303 net.cpp:684] Ignoring source layer bn6_r
I0705 11:42:25.012699 14303 net.cpp:684] Ignoring source layer upsample5
I0705 11:42:25.012701 14303 net.cpp:684] Ignoring source layer comb5
I0705 11:42:25.012703 14303 net.cpp:684] Ignoring source layer z5_r_comb5_0_split
I0705 11:42:25.012706 14303 net.cpp:684] Ignoring source layer recon5
I0705 11:42:25.012706 14303 net.cpp:684] Ignoring source layer bn5_r
I0705 11:42:25.012708 14303 net.cpp:684] Ignoring source layer upsample4
I0705 11:42:25.012714 14303 net.cpp:684] Ignoring source layer comb4
I0705 11:42:25.012717 14303 net.cpp:684] Ignoring source layer z4_r_comb4_0_split
I0705 11:42:25.012718 14303 net.cpp:684] Ignoring source layer recon4
I0705 11:42:25.012720 14303 net.cpp:684] Ignoring source layer bn4_r
I0705 11:42:25.012722 14303 net.cpp:684] Ignoring source layer upsample3
I0705 11:42:25.012724 14303 net.cpp:684] Ignoring source layer comb3
I0705 11:42:25.012727 14303 net.cpp:684] Ignoring source layer z3_r_comb3_0_split
I0705 11:42:25.012728 14303 net.cpp:684] Ignoring source layer recon3
I0705 11:42:25.012729 14303 net.cpp:684] Ignoring source layer bn3_r
I0705 11:42:25.012732 14303 net.cpp:684] Ignoring source layer upsample2
I0705 11:42:25.012733 14303 net.cpp:684] Ignoring source layer comb2
I0705 11:42:25.012735 14303 net.cpp:684] Ignoring source layer z2_r_comb2_0_split
I0705 11:42:25.012737 14303 net.cpp:684] Ignoring source layer recon2
I0705 11:42:25.012739 14303 net.cpp:684] Ignoring source layer bn2_r
I0705 11:42:25.012740 14303 net.cpp:684] Ignoring source layer upsample1
I0705 11:42:25.012742 14303 net.cpp:684] Ignoring source layer comb1
I0705 11:42:25.012744 14303 net.cpp:684] Ignoring source layer z1_r_comb1_0_split
I0705 11:42:25.012747 14303 net.cpp:684] Ignoring source layer recon1
I0705 11:42:25.012748 14303 net.cpp:684] Ignoring source layer bn1_r
I0705 11:42:25.012750 14303 net.cpp:684] Ignoring source layer comb0
I0705 11:42:25.012751 14303 net.cpp:684] Ignoring source layer loss_ladder_6
I0705 11:42:25.012753 14303 net.cpp:684] Ignoring source layer loss_ladder_5
I0705 11:42:25.012755 14303 net.cpp:684] Ignoring source layer loss_ladder_4
I0705 11:42:25.012758 14303 net.cpp:684] Ignoring source layer loss_ladder_3
I0705 11:42:25.012759 14303 net.cpp:684] Ignoring source layer loss_ladder_2
I0705 11:42:25.012761 14303 net.cpp:684] Ignoring source layer loss_ladder_1
I0705 11:42:25.012763 14303 net.cpp:684] Ignoring source layer loss_ladder_0
I0705 11:42:25.012765 14303 net.cpp:684] Ignoring source layer loss_supervised
I0705 11:42:25.173202 14303 solver.cpp:404]     Test net output #0: accuracy = 0.523438
I0705 11:42:25.173226 14303 solver.cpp:404]     Test net output #1: prob = 0.953122 (* 1 = 0.953122 loss)
I0705 11:42:25.267515 14303 solver.cpp:228] Iteration 700, loss = 5.02846
I0705 11:42:25.267547 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:42:25.267554 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.104367 (* 0.1 = 0.0104367 loss)
I0705 11:42:25.267560 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 36.517 (* 0.1 = 3.6517 loss)
I0705 11:42:25.267563 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.98529 (* 0.1 = 0.298529 loss)
I0705 11:42:25.267568 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.04836 (* 0.1 = 0.104836 loss)
I0705 11:42:25.267571 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.841604 (* 0.1 = 0.0841604 loss)
I0705 11:42:25.267575 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.945358 (* 0.1 = 0.0945358 loss)
I0705 11:42:25.267580 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.891974 (* 0.1 = 0.0891974 loss)
I0705 11:42:25.267583 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.695068 (* 1 = 0.695068 loss)
I0705 11:42:25.267587 14303 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0705 11:42:30.730106 14303 solver.cpp:228] Iteration 720, loss = 5.68219
I0705 11:42:30.730235 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0705 11:42:30.730245 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.104875 (* 0.1 = 0.0104875 loss)
I0705 11:42:30.730250 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 43.3478 (* 0.1 = 4.33478 loss)
I0705 11:42:30.730255 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.74446 (* 0.1 = 0.274446 loss)
I0705 11:42:30.730259 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.0324 (* 0.1 = 0.10324 loss)
I0705 11:42:30.730263 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.809596 (* 0.1 = 0.0809596 loss)
I0705 11:42:30.730268 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.90426 (* 0.1 = 0.090426 loss)
I0705 11:42:30.730273 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.855 (* 0.1 = 0.0855 loss)
I0705 11:42:30.730276 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.702353 (* 1 = 0.702353 loss)
I0705 11:42:30.730284 14303 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0705 11:42:36.184634 14303 solver.cpp:228] Iteration 740, loss = 5.8401
I0705 11:42:36.184669 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0705 11:42:36.184676 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.107613 (* 0.1 = 0.0107613 loss)
I0705 11:42:36.184680 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 44.4651 (* 0.1 = 4.44651 loss)
I0705 11:42:36.184685 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.66676 (* 0.1 = 0.266676 loss)
I0705 11:42:36.184689 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.04297 (* 0.1 = 0.104297 loss)
I0705 11:42:36.184694 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.820882 (* 0.1 = 0.0820882 loss)
I0705 11:42:36.184697 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.930924 (* 0.1 = 0.0930924 loss)
I0705 11:42:36.184700 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.867529 (* 0.1 = 0.0867529 loss)
I0705 11:42:36.184705 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.749919 (* 1 = 0.749919 loss)
I0705 11:42:36.184708 14303 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0705 11:42:41.638934 14303 solver.cpp:228] Iteration 760, loss = 5.73902
I0705 11:42:41.638969 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:42:41.638978 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.102577 (* 0.1 = 0.0102577 loss)
I0705 11:42:41.638981 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 44.3136 (* 0.1 = 4.43136 loss)
I0705 11:42:41.638986 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.98048 (* 0.1 = 0.298048 loss)
I0705 11:42:41.638990 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.06415 (* 0.1 = 0.106415 loss)
I0705 11:42:41.638994 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.829252 (* 0.1 = 0.0829252 loss)
I0705 11:42:41.638998 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.913999 (* 0.1 = 0.0913999 loss)
I0705 11:42:41.639001 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.855603 (* 0.1 = 0.0855603 loss)
I0705 11:42:41.639005 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.633063 (* 1 = 0.633063 loss)
I0705 11:42:41.639009 14303 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0705 11:42:47.094794 14303 solver.cpp:228] Iteration 780, loss = 5.80757
I0705 11:42:47.094817 14303 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0705 11:42:47.094825 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.104887 (* 0.1 = 0.0104887 loss)
I0705 11:42:47.094830 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 45.5463 (* 0.1 = 4.55463 loss)
I0705 11:42:47.094833 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.80441 (* 0.1 = 0.280441 loss)
I0705 11:42:47.094837 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.05899 (* 0.1 = 0.105899 loss)
I0705 11:42:47.094841 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.82203 (* 0.1 = 0.082203 loss)
I0705 11:42:47.094863 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.924545 (* 0.1 = 0.0924545 loss)
I0705 11:42:47.094867 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.843025 (* 0.1 = 0.0843025 loss)
I0705 11:42:47.094882 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.597145 (* 1 = 0.597145 loss)
I0705 11:42:47.094887 14303 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0705 11:42:52.453336 14303 solver.cpp:337] Iteration 800, Testing net (#0)
I0705 11:42:52.453364 14303 net.cpp:684] Ignoring source layer data_data_0_split
I0705 11:42:52.453368 14303 net.cpp:684] Ignoring source layer noisy_data
I0705 11:42:52.453371 14303 net.cpp:684] Ignoring source layer noisy_data_noisy_data_0_split
I0705 11:42:52.453372 14303 net.cpp:684] Ignoring source layer z1_bn1_0_split
I0705 11:42:52.453377 14303 net.cpp:684] Ignoring source layer bn1_n
I0705 11:42:52.453377 14303 net.cpp:684] Ignoring source layer noisy_z1_n
I0705 11:42:52.453379 14303 net.cpp:684] Ignoring source layer z1_n_noisy_z1_n_0_split
I0705 11:42:52.453383 14303 net.cpp:684] Ignoring source layer scale1_n
I0705 11:42:52.453385 14303 net.cpp:684] Ignoring source layer relu1_n
I0705 11:42:52.453387 14303 net.cpp:684] Ignoring source layer pool1_n
I0705 11:42:52.453389 14303 net.cpp:684] Ignoring source layer z2_bn2_0_split
I0705 11:42:52.453392 14303 net.cpp:684] Ignoring source layer bn2_n
I0705 11:42:52.453394 14303 net.cpp:684] Ignoring source layer noisy_z2_n
I0705 11:42:52.453397 14303 net.cpp:684] Ignoring source layer z2_n_noisy_z2_n_0_split
I0705 11:42:52.453397 14303 net.cpp:684] Ignoring source layer scale2_n
I0705 11:42:52.453399 14303 net.cpp:684] Ignoring source layer relu2_n
I0705 11:42:52.453402 14303 net.cpp:684] Ignoring source layer pool2_n
I0705 11:42:52.453404 14303 net.cpp:684] Ignoring source layer z3_bn3_0_split
I0705 11:42:52.453408 14303 net.cpp:684] Ignoring source layer bn3_n
I0705 11:42:52.453409 14303 net.cpp:684] Ignoring source layer noisy_z3_n
I0705 11:42:52.453410 14303 net.cpp:684] Ignoring source layer z3_n_noisy_z3_n_0_split
I0705 11:42:52.453413 14303 net.cpp:684] Ignoring source layer scale3_n
I0705 11:42:52.453414 14303 net.cpp:684] Ignoring source layer relu3_n
I0705 11:42:52.453416 14303 net.cpp:684] Ignoring source layer pool3_n
I0705 11:42:52.453419 14303 net.cpp:684] Ignoring source layer z4_bn4_0_split
I0705 11:42:52.453421 14303 net.cpp:684] Ignoring source layer bn4_n
I0705 11:42:52.453423 14303 net.cpp:684] Ignoring source layer noisy_z4_n
I0705 11:42:52.453425 14303 net.cpp:684] Ignoring source layer z4_n_noisy_z4_n_0_split
I0705 11:42:52.453428 14303 net.cpp:684] Ignoring source layer scale4_n
I0705 11:42:52.453429 14303 net.cpp:684] Ignoring source layer relu4_n
I0705 11:42:52.453431 14303 net.cpp:684] Ignoring source layer pool4_n
I0705 11:42:52.453434 14303 net.cpp:684] Ignoring source layer z5_bn5_0_split
I0705 11:42:52.453436 14303 net.cpp:684] Ignoring source layer bn5_n
I0705 11:42:52.453438 14303 net.cpp:684] Ignoring source layer noisy_z5_n
I0705 11:42:52.453440 14303 net.cpp:684] Ignoring source layer z5_n_noisy_z5_n_0_split
I0705 11:42:52.453443 14303 net.cpp:684] Ignoring source layer scale5_n
I0705 11:42:52.453444 14303 net.cpp:684] Ignoring source layer relu5_n
I0705 11:42:52.453445 14303 net.cpp:684] Ignoring source layer pool5_n
I0705 11:42:52.453449 14303 net.cpp:684] Ignoring source layer z6_bn6_0_split
I0705 11:42:52.453450 14303 net.cpp:684] Ignoring source layer bn6_n
I0705 11:42:52.453452 14303 net.cpp:684] Ignoring source layer noisy_z6_n
I0705 11:42:52.453454 14303 net.cpp:684] Ignoring source layer z6_n_noisy_z6_n_0_split
I0705 11:42:52.453456 14303 net.cpp:684] Ignoring source layer scale6_n
I0705 11:42:52.453459 14303 net.cpp:684] Ignoring source layer relu6_n
I0705 11:42:52.453460 14303 net.cpp:684] Ignoring source layer u6
I0705 11:42:52.453462 14303 net.cpp:684] Ignoring source layer comb6
I0705 11:42:52.453464 14303 net.cpp:684] Ignoring source layer z6_r_comb6_0_split
I0705 11:42:52.453480 14303 net.cpp:684] Ignoring source layer recon6
I0705 11:42:52.453482 14303 net.cpp:684] Ignoring source layer bn6_r
I0705 11:42:52.453485 14303 net.cpp:684] Ignoring source layer upsample5
I0705 11:42:52.453486 14303 net.cpp:684] Ignoring source layer comb5
I0705 11:42:52.453488 14303 net.cpp:684] Ignoring source layer z5_r_comb5_0_split
I0705 11:42:52.453490 14303 net.cpp:684] Ignoring source layer recon5
I0705 11:42:52.453492 14303 net.cpp:684] Ignoring source layer bn5_r
I0705 11:42:52.453493 14303 net.cpp:684] Ignoring source layer upsample4
I0705 11:42:52.453495 14303 net.cpp:684] Ignoring source layer comb4
I0705 11:42:52.453497 14303 net.cpp:684] Ignoring source layer z4_r_comb4_0_split
I0705 11:42:52.453500 14303 net.cpp:684] Ignoring source layer recon4
I0705 11:42:52.453501 14303 net.cpp:684] Ignoring source layer bn4_r
I0705 11:42:52.453502 14303 net.cpp:684] Ignoring source layer upsample3
I0705 11:42:52.453505 14303 net.cpp:684] Ignoring source layer comb3
I0705 11:42:52.453506 14303 net.cpp:684] Ignoring source layer z3_r_comb3_0_split
I0705 11:42:52.453508 14303 net.cpp:684] Ignoring source layer recon3
I0705 11:42:52.453510 14303 net.cpp:684] Ignoring source layer bn3_r
I0705 11:42:52.453511 14303 net.cpp:684] Ignoring source layer upsample2
I0705 11:42:52.453513 14303 net.cpp:684] Ignoring source layer comb2
I0705 11:42:52.453516 14303 net.cpp:684] Ignoring source layer z2_r_comb2_0_split
I0705 11:42:52.453517 14303 net.cpp:684] Ignoring source layer recon2
I0705 11:42:52.453519 14303 net.cpp:684] Ignoring source layer bn2_r
I0705 11:42:52.453521 14303 net.cpp:684] Ignoring source layer upsample1
I0705 11:42:52.453522 14303 net.cpp:684] Ignoring source layer comb1
I0705 11:42:52.453524 14303 net.cpp:684] Ignoring source layer z1_r_comb1_0_split
I0705 11:42:52.453526 14303 net.cpp:684] Ignoring source layer recon1
I0705 11:42:52.453528 14303 net.cpp:684] Ignoring source layer bn1_r
I0705 11:42:52.453531 14303 net.cpp:684] Ignoring source layer comb0
I0705 11:42:52.453531 14303 net.cpp:684] Ignoring source layer loss_ladder_6
I0705 11:42:52.453533 14303 net.cpp:684] Ignoring source layer loss_ladder_5
I0705 11:42:52.453536 14303 net.cpp:684] Ignoring source layer loss_ladder_4
I0705 11:42:52.453536 14303 net.cpp:684] Ignoring source layer loss_ladder_3
I0705 11:42:52.453538 14303 net.cpp:684] Ignoring source layer loss_ladder_2
I0705 11:42:52.453541 14303 net.cpp:684] Ignoring source layer loss_ladder_1
I0705 11:42:52.453542 14303 net.cpp:684] Ignoring source layer loss_ladder_0
I0705 11:42:52.453546 14303 net.cpp:684] Ignoring source layer loss_supervised
I0705 11:42:52.613358 14303 solver.cpp:404]     Test net output #0: accuracy = 0.453125
I0705 11:42:52.613384 14303 solver.cpp:404]     Test net output #1: prob = 0.934398 (* 1 = 0.934398 loss)
I0705 11:42:52.707315 14303 solver.cpp:228] Iteration 800, loss = 6.30434
I0705 11:42:52.707336 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0705 11:42:52.707343 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.110376 (* 0.1 = 0.0110376 loss)
I0705 11:42:52.707347 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 50.8128 (* 0.1 = 5.08128 loss)
I0705 11:42:52.707352 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.17756 (* 0.1 = 0.217756 loss)
I0705 11:42:52.707356 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.01994 (* 0.1 = 0.101994 loss)
I0705 11:42:52.707360 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.815329 (* 0.1 = 0.0815329 loss)
I0705 11:42:52.707365 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.930818 (* 0.1 = 0.0930818 loss)
I0705 11:42:52.707368 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.871882 (* 0.1 = 0.0871883 loss)
I0705 11:42:52.707372 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.630469 (* 1 = 0.630469 loss)
I0705 11:42:52.707376 14303 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0705 11:42:58.162421 14303 solver.cpp:228] Iteration 820, loss = 5.15512
I0705 11:42:58.162466 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:42:58.162474 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.103461 (* 0.1 = 0.0103461 loss)
I0705 11:42:58.162478 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 38.96 (* 0.1 = 3.896 loss)
I0705 11:42:58.162483 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.80593 (* 0.1 = 0.280593 loss)
I0705 11:42:58.162498 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.02232 (* 0.1 = 0.102232 loss)
I0705 11:42:58.162502 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.823476 (* 0.1 = 0.0823476 loss)
I0705 11:42:58.162505 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.928879 (* 0.1 = 0.0928879 loss)
I0705 11:42:58.162509 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.883058 (* 0.1 = 0.0883058 loss)
I0705 11:42:58.162513 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.602403 (* 1 = 0.602403 loss)
I0705 11:42:58.162518 14303 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0705 11:43:03.615684 14303 solver.cpp:228] Iteration 840, loss = 5.56628
I0705 11:43:03.615810 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0705 11:43:03.615820 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.10872 (* 0.1 = 0.010872 loss)
I0705 11:43:03.615825 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 43.3995 (* 0.1 = 4.33995 loss)
I0705 11:43:03.615830 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.54194 (* 0.1 = 0.254194 loss)
I0705 11:43:03.615834 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.03184 (* 0.1 = 0.103184 loss)
I0705 11:43:03.615838 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.811228 (* 0.1 = 0.0811228 loss)
I0705 11:43:03.615841 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.926008 (* 0.1 = 0.0926008 loss)
I0705 11:43:03.615845 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.852304 (* 0.1 = 0.0852304 loss)
I0705 11:43:03.615849 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.599127 (* 1 = 0.599127 loss)
I0705 11:43:03.615852 14303 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0705 11:43:09.071162 14303 solver.cpp:228] Iteration 860, loss = 6.43213
I0705 11:43:09.071187 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:43:09.071194 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.109563 (* 0.1 = 0.0109563 loss)
I0705 11:43:09.071199 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 52.6847 (* 0.1 = 5.26847 loss)
I0705 11:43:09.071204 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.98131 (* 0.1 = 0.198131 loss)
I0705 11:43:09.071208 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.00953 (* 0.1 = 0.100953 loss)
I0705 11:43:09.071211 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.812931 (* 0.1 = 0.0812931 loss)
I0705 11:43:09.071215 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.916343 (* 0.1 = 0.0916343 loss)
I0705 11:43:09.071219 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.846447 (* 0.1 = 0.0846447 loss)
I0705 11:43:09.071223 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.596044 (* 1 = 0.596044 loss)
I0705 11:43:09.071226 14303 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0705 11:43:14.514065 14303 solver.cpp:228] Iteration 880, loss = 5.81341
I0705 11:43:14.514088 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0705 11:43:14.514096 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.110887 (* 0.1 = 0.0110887 loss)
I0705 11:43:14.514101 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 45.0736 (* 0.1 = 4.50736 loss)
I0705 11:43:14.514104 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.09925 (* 0.1 = 0.209925 loss)
I0705 11:43:14.514108 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.999543 (* 0.1 = 0.0999543 loss)
I0705 11:43:14.514111 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.798839 (* 0.1 = 0.0798839 loss)
I0705 11:43:14.514116 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.924605 (* 0.1 = 0.0924605 loss)
I0705 11:43:14.514119 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.863719 (* 0.1 = 0.0863719 loss)
I0705 11:43:14.514123 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.726359 (* 1 = 0.726359 loss)
I0705 11:43:14.514127 14303 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0705 11:43:19.867216 14303 solver.cpp:337] Iteration 900, Testing net (#0)
I0705 11:43:19.867234 14303 net.cpp:684] Ignoring source layer data_data_0_split
I0705 11:43:19.867238 14303 net.cpp:684] Ignoring source layer noisy_data
I0705 11:43:19.867239 14303 net.cpp:684] Ignoring source layer noisy_data_noisy_data_0_split
I0705 11:43:19.867243 14303 net.cpp:684] Ignoring source layer z1_bn1_0_split
I0705 11:43:19.867244 14303 net.cpp:684] Ignoring source layer bn1_n
I0705 11:43:19.867246 14303 net.cpp:684] Ignoring source layer noisy_z1_n
I0705 11:43:19.867249 14303 net.cpp:684] Ignoring source layer z1_n_noisy_z1_n_0_split
I0705 11:43:19.867250 14303 net.cpp:684] Ignoring source layer scale1_n
I0705 11:43:19.867271 14303 net.cpp:684] Ignoring source layer relu1_n
I0705 11:43:19.867274 14303 net.cpp:684] Ignoring source layer pool1_n
I0705 11:43:19.867276 14303 net.cpp:684] Ignoring source layer z2_bn2_0_split
I0705 11:43:19.867280 14303 net.cpp:684] Ignoring source layer bn2_n
I0705 11:43:19.867281 14303 net.cpp:684] Ignoring source layer noisy_z2_n
I0705 11:43:19.867283 14303 net.cpp:684] Ignoring source layer z2_n_noisy_z2_n_0_split
I0705 11:43:19.867285 14303 net.cpp:684] Ignoring source layer scale2_n
I0705 11:43:19.867286 14303 net.cpp:684] Ignoring source layer relu2_n
I0705 11:43:19.867288 14303 net.cpp:684] Ignoring source layer pool2_n
I0705 11:43:19.867291 14303 net.cpp:684] Ignoring source layer z3_bn3_0_split
I0705 11:43:19.867295 14303 net.cpp:684] Ignoring source layer bn3_n
I0705 11:43:19.867295 14303 net.cpp:684] Ignoring source layer noisy_z3_n
I0705 11:43:19.867297 14303 net.cpp:684] Ignoring source layer z3_n_noisy_z3_n_0_split
I0705 11:43:19.867300 14303 net.cpp:684] Ignoring source layer scale3_n
I0705 11:43:19.867301 14303 net.cpp:684] Ignoring source layer relu3_n
I0705 11:43:19.867303 14303 net.cpp:684] Ignoring source layer pool3_n
I0705 11:43:19.867317 14303 net.cpp:684] Ignoring source layer z4_bn4_0_split
I0705 11:43:19.867321 14303 net.cpp:684] Ignoring source layer bn4_n
I0705 11:43:19.867322 14303 net.cpp:684] Ignoring source layer noisy_z4_n
I0705 11:43:19.867323 14303 net.cpp:684] Ignoring source layer z4_n_noisy_z4_n_0_split
I0705 11:43:19.867326 14303 net.cpp:684] Ignoring source layer scale4_n
I0705 11:43:19.867327 14303 net.cpp:684] Ignoring source layer relu4_n
I0705 11:43:19.867329 14303 net.cpp:684] Ignoring source layer pool4_n
I0705 11:43:19.867332 14303 net.cpp:684] Ignoring source layer z5_bn5_0_split
I0705 11:43:19.867336 14303 net.cpp:684] Ignoring source layer bn5_n
I0705 11:43:19.867337 14303 net.cpp:684] Ignoring source layer noisy_z5_n
I0705 11:43:19.867338 14303 net.cpp:684] Ignoring source layer z5_n_noisy_z5_n_0_split
I0705 11:43:19.867341 14303 net.cpp:684] Ignoring source layer scale5_n
I0705 11:43:19.867342 14303 net.cpp:684] Ignoring source layer relu5_n
I0705 11:43:19.867344 14303 net.cpp:684] Ignoring source layer pool5_n
I0705 11:43:19.867347 14303 net.cpp:684] Ignoring source layer z6_bn6_0_split
I0705 11:43:19.867350 14303 net.cpp:684] Ignoring source layer bn6_n
I0705 11:43:19.867352 14303 net.cpp:684] Ignoring source layer noisy_z6_n
I0705 11:43:19.867354 14303 net.cpp:684] Ignoring source layer z6_n_noisy_z6_n_0_split
I0705 11:43:19.867357 14303 net.cpp:684] Ignoring source layer scale6_n
I0705 11:43:19.867357 14303 net.cpp:684] Ignoring source layer relu6_n
I0705 11:43:19.867359 14303 net.cpp:684] Ignoring source layer u6
I0705 11:43:19.867362 14303 net.cpp:684] Ignoring source layer comb6
I0705 11:43:19.867363 14303 net.cpp:684] Ignoring source layer z6_r_comb6_0_split
I0705 11:43:19.867365 14303 net.cpp:684] Ignoring source layer recon6
I0705 11:43:19.867368 14303 net.cpp:684] Ignoring source layer bn6_r
I0705 11:43:19.867370 14303 net.cpp:684] Ignoring source layer upsample5
I0705 11:43:19.867372 14303 net.cpp:684] Ignoring source layer comb5
I0705 11:43:19.867373 14303 net.cpp:684] Ignoring source layer z5_r_comb5_0_split
I0705 11:43:19.867375 14303 net.cpp:684] Ignoring source layer recon5
I0705 11:43:19.867377 14303 net.cpp:684] Ignoring source layer bn5_r
I0705 11:43:19.867379 14303 net.cpp:684] Ignoring source layer upsample4
I0705 11:43:19.867382 14303 net.cpp:684] Ignoring source layer comb4
I0705 11:43:19.867383 14303 net.cpp:684] Ignoring source layer z4_r_comb4_0_split
I0705 11:43:19.867384 14303 net.cpp:684] Ignoring source layer recon4
I0705 11:43:19.867390 14303 net.cpp:684] Ignoring source layer bn4_r
I0705 11:43:19.867393 14303 net.cpp:684] Ignoring source layer upsample3
I0705 11:43:19.867394 14303 net.cpp:684] Ignoring source layer comb3
I0705 11:43:19.867395 14303 net.cpp:684] Ignoring source layer z3_r_comb3_0_split
I0705 11:43:19.867398 14303 net.cpp:684] Ignoring source layer recon3
I0705 11:43:19.867404 14303 net.cpp:684] Ignoring source layer bn3_r
I0705 11:43:19.867406 14303 net.cpp:684] Ignoring source layer upsample2
I0705 11:43:19.867408 14303 net.cpp:684] Ignoring source layer comb2
I0705 11:43:19.867410 14303 net.cpp:684] Ignoring source layer z2_r_comb2_0_split
I0705 11:43:19.867411 14303 net.cpp:684] Ignoring source layer recon2
I0705 11:43:19.867414 14303 net.cpp:684] Ignoring source layer bn2_r
I0705 11:43:19.867415 14303 net.cpp:684] Ignoring source layer upsample1
I0705 11:43:19.867418 14303 net.cpp:684] Ignoring source layer comb1
I0705 11:43:19.867419 14303 net.cpp:684] Ignoring source layer z1_r_comb1_0_split
I0705 11:43:19.867421 14303 net.cpp:684] Ignoring source layer recon1
I0705 11:43:19.867424 14303 net.cpp:684] Ignoring source layer bn1_r
I0705 11:43:19.867424 14303 net.cpp:684] Ignoring source layer comb0
I0705 11:43:19.867426 14303 net.cpp:684] Ignoring source layer loss_ladder_6
I0705 11:43:19.867429 14303 net.cpp:684] Ignoring source layer loss_ladder_5
I0705 11:43:19.867430 14303 net.cpp:684] Ignoring source layer loss_ladder_4
I0705 11:43:19.867432 14303 net.cpp:684] Ignoring source layer loss_ladder_3
I0705 11:43:19.867434 14303 net.cpp:684] Ignoring source layer loss_ladder_2
I0705 11:43:19.867435 14303 net.cpp:684] Ignoring source layer loss_ladder_1
I0705 11:43:19.867437 14303 net.cpp:684] Ignoring source layer loss_ladder_0
I0705 11:43:19.867440 14303 net.cpp:684] Ignoring source layer loss_supervised
I0705 11:43:20.026701 14303 solver.cpp:404]     Test net output #0: accuracy = 0.632812
I0705 11:43:20.026727 14303 solver.cpp:404]     Test net output #1: prob = 1.08493 (* 1 = 1.08493 loss)
I0705 11:43:20.120370 14303 solver.cpp:228] Iteration 900, loss = 5.40418
I0705 11:43:20.120391 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:43:20.120398 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.100454 (* 0.1 = 0.0100454 loss)
I0705 11:43:20.120403 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 41.4157 (* 0.1 = 4.14157 loss)
I0705 11:43:20.120407 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.87792 (* 0.1 = 0.287792 loss)
I0705 11:43:20.120410 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.05782 (* 0.1 = 0.105782 loss)
I0705 11:43:20.120414 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.809056 (* 0.1 = 0.0809056 loss)
I0705 11:43:20.120419 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.886482 (* 0.1 = 0.0886482 loss)
I0705 11:43:20.120422 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.851794 (* 0.1 = 0.0851794 loss)
I0705 11:43:20.120426 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.604262 (* 1 = 0.604262 loss)
I0705 11:43:20.120430 14303 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0705 11:43:25.564684 14303 solver.cpp:228] Iteration 920, loss = 5.30563
I0705 11:43:25.564707 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0705 11:43:25.564714 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.0993854 (* 0.1 = 0.00993854 loss)
I0705 11:43:25.564718 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 39.7332 (* 0.1 = 3.97332 loss)
I0705 11:43:25.564723 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.83082 (* 0.1 = 0.283082 loss)
I0705 11:43:25.564728 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.07567 (* 0.1 = 0.107567 loss)
I0705 11:43:25.564730 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.819175 (* 0.1 = 0.0819175 loss)
I0705 11:43:25.564734 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.887103 (* 0.1 = 0.0887103 loss)
I0705 11:43:25.564738 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.846325 (* 0.1 = 0.0846325 loss)
I0705 11:43:25.564743 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.676465 (* 1 = 0.676465 loss)
I0705 11:43:25.564746 14303 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0705 11:43:31.015638 14303 solver.cpp:228] Iteration 940, loss = 5.64124
I0705 11:43:31.015684 14303 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0705 11:43:31.015692 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.100974 (* 0.1 = 0.0100974 loss)
I0705 11:43:31.015697 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 44.5743 (* 0.1 = 4.45743 loss)
I0705 11:43:31.015702 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.82042 (* 0.1 = 0.282042 loss)
I0705 11:43:31.015705 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.07463 (* 0.1 = 0.107463 loss)
I0705 11:43:31.015708 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.839982 (* 0.1 = 0.0839982 loss)
I0705 11:43:31.015712 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.914922 (* 0.1 = 0.0914922 loss)
I0705 11:43:31.015717 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.875276 (* 0.1 = 0.0875276 loss)
I0705 11:43:31.015719 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.521195 (* 1 = 0.521195 loss)
I0705 11:43:31.015723 14303 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0705 11:43:36.496979 14303 solver.cpp:228] Iteration 960, loss = 5.58595
I0705 11:43:36.497113 14303 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0705 11:43:36.497124 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.106467 (* 0.1 = 0.0106467 loss)
I0705 11:43:36.497129 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 43.7098 (* 0.1 = 4.37098 loss)
I0705 11:43:36.497134 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.57621 (* 0.1 = 0.257621 loss)
I0705 11:43:36.497138 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.04053 (* 0.1 = 0.104053 loss)
I0705 11:43:36.497143 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.817061 (* 0.1 = 0.0817061 loss)
I0705 11:43:36.497146 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.918808 (* 0.1 = 0.0918809 loss)
I0705 11:43:36.497150 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.864946 (* 0.1 = 0.0864946 loss)
I0705 11:43:36.497155 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.582561 (* 1 = 0.582561 loss)
I0705 11:43:36.497159 14303 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0705 11:43:41.941396 14303 solver.cpp:228] Iteration 980, loss = 5.0517
I0705 11:43:41.941421 14303 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0705 11:43:41.941428 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.100053 (* 0.1 = 0.0100053 loss)
I0705 11:43:41.941432 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 38.635 (* 0.1 = 3.8635 loss)
I0705 11:43:41.941437 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.85207 (* 0.1 = 0.285207 loss)
I0705 11:43:41.941440 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.04651 (* 0.1 = 0.104651 loss)
I0705 11:43:41.941444 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.821167 (* 0.1 = 0.0821167 loss)
I0705 11:43:41.941449 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.912201 (* 0.1 = 0.0912201 loss)
I0705 11:43:41.941453 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.864534 (* 0.1 = 0.0864534 loss)
I0705 11:43:41.941457 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.528544 (* 1 = 0.528544 loss)
I0705 11:43:41.941460 14303 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0705 11:43:47.281849 14303 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_1000.caffemodel
I0705 11:43:47.558691 14303 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_1000.solverstate
I0705 11:43:47.688033 14303 solver.cpp:337] Iteration 1000, Testing net (#0)
I0705 11:43:47.688065 14303 net.cpp:684] Ignoring source layer data_data_0_split
I0705 11:43:47.688068 14303 net.cpp:684] Ignoring source layer noisy_data
I0705 11:43:47.688071 14303 net.cpp:684] Ignoring source layer noisy_data_noisy_data_0_split
I0705 11:43:47.688073 14303 net.cpp:684] Ignoring source layer z1_bn1_0_split
I0705 11:43:47.688076 14303 net.cpp:684] Ignoring source layer bn1_n
I0705 11:43:47.688078 14303 net.cpp:684] Ignoring source layer noisy_z1_n
I0705 11:43:47.688081 14303 net.cpp:684] Ignoring source layer z1_n_noisy_z1_n_0_split
I0705 11:43:47.688083 14303 net.cpp:684] Ignoring source layer scale1_n
I0705 11:43:47.688086 14303 net.cpp:684] Ignoring source layer relu1_n
I0705 11:43:47.688087 14303 net.cpp:684] Ignoring source layer pool1_n
I0705 11:43:47.688091 14303 net.cpp:684] Ignoring source layer z2_bn2_0_split
I0705 11:43:47.688093 14303 net.cpp:684] Ignoring source layer bn2_n
I0705 11:43:47.688096 14303 net.cpp:684] Ignoring source layer noisy_z2_n
I0705 11:43:47.688097 14303 net.cpp:684] Ignoring source layer z2_n_noisy_z2_n_0_split
I0705 11:43:47.688098 14303 net.cpp:684] Ignoring source layer scale2_n
I0705 11:43:47.688100 14303 net.cpp:684] Ignoring source layer relu2_n
I0705 11:43:47.688102 14303 net.cpp:684] Ignoring source layer pool2_n
I0705 11:43:47.688105 14303 net.cpp:684] Ignoring source layer z3_bn3_0_split
I0705 11:43:47.688108 14303 net.cpp:684] Ignoring source layer bn3_n
I0705 11:43:47.688110 14303 net.cpp:684] Ignoring source layer noisy_z3_n
I0705 11:43:47.688122 14303 net.cpp:684] Ignoring source layer z3_n_noisy_z3_n_0_split
I0705 11:43:47.688125 14303 net.cpp:684] Ignoring source layer scale3_n
I0705 11:43:47.688127 14303 net.cpp:684] Ignoring source layer relu3_n
I0705 11:43:47.688128 14303 net.cpp:684] Ignoring source layer pool3_n
I0705 11:43:47.688132 14303 net.cpp:684] Ignoring source layer z4_bn4_0_split
I0705 11:43:47.688134 14303 net.cpp:684] Ignoring source layer bn4_n
I0705 11:43:47.688136 14303 net.cpp:684] Ignoring source layer noisy_z4_n
I0705 11:43:47.688138 14303 net.cpp:684] Ignoring source layer z4_n_noisy_z4_n_0_split
I0705 11:43:47.688140 14303 net.cpp:684] Ignoring source layer scale4_n
I0705 11:43:47.688143 14303 net.cpp:684] Ignoring source layer relu4_n
I0705 11:43:47.688144 14303 net.cpp:684] Ignoring source layer pool4_n
I0705 11:43:47.688146 14303 net.cpp:684] Ignoring source layer z5_bn5_0_split
I0705 11:43:47.688149 14303 net.cpp:684] Ignoring source layer bn5_n
I0705 11:43:47.688151 14303 net.cpp:684] Ignoring source layer noisy_z5_n
I0705 11:43:47.688153 14303 net.cpp:684] Ignoring source layer z5_n_noisy_z5_n_0_split
I0705 11:43:47.688155 14303 net.cpp:684] Ignoring source layer scale5_n
I0705 11:43:47.688158 14303 net.cpp:684] Ignoring source layer relu5_n
I0705 11:43:47.688159 14303 net.cpp:684] Ignoring source layer pool5_n
I0705 11:43:47.688163 14303 net.cpp:684] Ignoring source layer z6_bn6_0_split
I0705 11:43:47.688165 14303 net.cpp:684] Ignoring source layer bn6_n
I0705 11:43:47.688168 14303 net.cpp:684] Ignoring source layer noisy_z6_n
I0705 11:43:47.688169 14303 net.cpp:684] Ignoring source layer z6_n_noisy_z6_n_0_split
I0705 11:43:47.688171 14303 net.cpp:684] Ignoring source layer scale6_n
I0705 11:43:47.688174 14303 net.cpp:684] Ignoring source layer relu6_n
I0705 11:43:47.688175 14303 net.cpp:684] Ignoring source layer u6
I0705 11:43:47.688177 14303 net.cpp:684] Ignoring source layer comb6
I0705 11:43:47.688179 14303 net.cpp:684] Ignoring source layer z6_r_comb6_0_split
I0705 11:43:47.688181 14303 net.cpp:684] Ignoring source layer recon6
I0705 11:43:47.688184 14303 net.cpp:684] Ignoring source layer bn6_r
I0705 11:43:47.688184 14303 net.cpp:684] Ignoring source layer upsample5
I0705 11:43:47.688186 14303 net.cpp:684] Ignoring source layer comb5
I0705 11:43:47.688189 14303 net.cpp:684] Ignoring source layer z5_r_comb5_0_split
I0705 11:43:47.688190 14303 net.cpp:684] Ignoring source layer recon5
I0705 11:43:47.688192 14303 net.cpp:684] Ignoring source layer bn5_r
I0705 11:43:47.688194 14303 net.cpp:684] Ignoring source layer upsample4
I0705 11:43:47.688196 14303 net.cpp:684] Ignoring source layer comb4
I0705 11:43:47.688199 14303 net.cpp:684] Ignoring source layer z4_r_comb4_0_split
I0705 11:43:47.688199 14303 net.cpp:684] Ignoring source layer recon4
I0705 11:43:47.688201 14303 net.cpp:684] Ignoring source layer bn4_r
I0705 11:43:47.688204 14303 net.cpp:684] Ignoring source layer upsample3
I0705 11:43:47.688205 14303 net.cpp:684] Ignoring source layer comb3
I0705 11:43:47.688207 14303 net.cpp:684] Ignoring source layer z3_r_comb3_0_split
I0705 11:43:47.688210 14303 net.cpp:684] Ignoring source layer recon3
I0705 11:43:47.688211 14303 net.cpp:684] Ignoring source layer bn3_r
I0705 11:43:47.688212 14303 net.cpp:684] Ignoring source layer upsample2
I0705 11:43:47.688215 14303 net.cpp:684] Ignoring source layer comb2
I0705 11:43:47.688216 14303 net.cpp:684] Ignoring source layer z2_r_comb2_0_split
I0705 11:43:47.688220 14303 net.cpp:684] Ignoring source layer recon2
I0705 11:43:47.688221 14303 net.cpp:684] Ignoring source layer bn2_r
I0705 11:43:47.688223 14303 net.cpp:684] Ignoring source layer upsample1
I0705 11:43:47.688225 14303 net.cpp:684] Ignoring source layer comb1
I0705 11:43:47.688226 14303 net.cpp:684] Ignoring source layer z1_r_comb1_0_split
I0705 11:43:47.688228 14303 net.cpp:684] Ignoring source layer recon1
I0705 11:43:47.688230 14303 net.cpp:684] Ignoring source layer bn1_r
I0705 11:43:47.688232 14303 net.cpp:684] Ignoring source layer comb0
I0705 11:43:47.688235 14303 net.cpp:684] Ignoring source layer loss_ladder_6
I0705 11:43:47.688240 14303 net.cpp:684] Ignoring source layer loss_ladder_5
I0705 11:43:47.688241 14303 net.cpp:684] Ignoring source layer loss_ladder_4
I0705 11:43:47.688243 14303 net.cpp:684] Ignoring source layer loss_ladder_3
I0705 11:43:47.688249 14303 net.cpp:684] Ignoring source layer loss_ladder_2
I0705 11:43:47.688251 14303 net.cpp:684] Ignoring source layer loss_ladder_1
I0705 11:43:47.688253 14303 net.cpp:684] Ignoring source layer loss_ladder_0
I0705 11:43:47.688256 14303 net.cpp:684] Ignoring source layer loss_supervised
I0705 11:43:47.846906 14303 solver.cpp:404]     Test net output #0: accuracy = 0.546875
I0705 11:43:47.846932 14303 solver.cpp:404]     Test net output #1: prob = 0.920538 (* 1 = 0.920538 loss)
I0705 11:43:47.941377 14303 solver.cpp:228] Iteration 1000, loss = 6.30546
I0705 11:43:47.941400 14303 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0705 11:43:47.941418 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.109394 (* 0.1 = 0.0109394 loss)
I0705 11:43:47.941423 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 51.5227 (* 0.1 = 5.15227 loss)
I0705 11:43:47.941428 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.92204 (* 0.1 = 0.192204 loss)
I0705 11:43:47.941432 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.9278 (* 0.1 = 0.09278 loss)
I0705 11:43:47.941437 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.736378 (* 0.1 = 0.0736378 loss)
I0705 11:43:47.941439 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.870446 (* 0.1 = 0.0870446 loss)
I0705 11:43:47.941443 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.817526 (* 0.1 = 0.0817526 loss)
I0705 11:43:47.941447 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.614833 (* 1 = 0.614833 loss)
I0705 11:43:47.941452 14303 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0705 11:43:53.375454 14303 solver.cpp:228] Iteration 1020, loss = 6.04467
I0705 11:43:53.375478 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0705 11:43:53.375486 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.106029 (* 0.1 = 0.0106029 loss)
I0705 11:43:53.375490 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 47.191 (* 0.1 = 4.7191 loss)
I0705 11:43:53.375495 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.42795 (* 0.1 = 0.242795 loss)
I0705 11:43:53.375499 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.01019 (* 0.1 = 0.101019 loss)
I0705 11:43:53.375504 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.792208 (* 0.1 = 0.0792208 loss)
I0705 11:43:53.375507 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.898767 (* 0.1 = 0.0898767 loss)
I0705 11:43:53.375511 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.841779 (* 0.1 = 0.0841779 loss)
I0705 11:43:53.375514 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.717872 (* 1 = 0.717872 loss)
I0705 11:43:53.375519 14303 sgd_solver.cpp:106] Iteration 1020, lr = 0.01
I0705 11:43:58.810462 14303 solver.cpp:228] Iteration 1040, loss = 6.85403
I0705 11:43:58.810487 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:43:58.810493 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.110765 (* 0.1 = 0.0110765 loss)
I0705 11:43:58.810498 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 57.4277 (* 0.1 = 5.74277 loss)
I0705 11:43:58.810503 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.53671 (* 0.1 = 0.153671 loss)
I0705 11:43:58.810506 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.868727 (* 0.1 = 0.0868727 loss)
I0705 11:43:58.810509 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.755627 (* 0.1 = 0.0755627 loss)
I0705 11:43:58.810513 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.894576 (* 0.1 = 0.0894576 loss)
I0705 11:43:58.810518 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.837752 (* 0.1 = 0.0837752 loss)
I0705 11:43:58.810541 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.610845 (* 1 = 0.610845 loss)
I0705 11:43:58.810546 14303 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I0705 11:44:04.244926 14303 solver.cpp:228] Iteration 1060, loss = 7.3955
I0705 11:44:04.244951 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0705 11:44:04.244958 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.111605 (* 0.1 = 0.0111605 loss)
I0705 11:44:04.244962 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 61.681 (* 0.1 = 6.1681 loss)
I0705 11:44:04.244967 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.666 (* 0.1 = 0.1666 loss)
I0705 11:44:04.244971 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.908731 (* 0.1 = 0.0908731 loss)
I0705 11:44:04.244976 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.745499 (* 0.1 = 0.0745499 loss)
I0705 11:44:04.244978 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.887733 (* 0.1 = 0.0887733 loss)
I0705 11:44:04.244982 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.84584 (* 0.1 = 0.084584 loss)
I0705 11:44:04.244987 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.710863 (* 1 = 0.710863 loss)
I0705 11:44:04.244990 14303 sgd_solver.cpp:106] Iteration 1060, lr = 0.01
I0705 11:44:09.679684 14303 solver.cpp:228] Iteration 1080, loss = 6.41351
I0705 11:44:09.679812 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:44:09.679822 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.109548 (* 0.1 = 0.0109548 loss)
I0705 11:44:09.679827 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 52.3329 (* 0.1 = 5.23329 loss)
I0705 11:44:09.679832 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.89836 (* 0.1 = 0.189836 loss)
I0705 11:44:09.679836 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.954417 (* 0.1 = 0.0954417 loss)
I0705 11:44:09.679841 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.773974 (* 0.1 = 0.0773975 loss)
I0705 11:44:09.679844 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.895112 (* 0.1 = 0.0895112 loss)
I0705 11:44:09.679848 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.832159 (* 0.1 = 0.0832159 loss)
I0705 11:44:09.679852 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.633864 (* 1 = 0.633864 loss)
I0705 11:44:09.679855 14303 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I0705 11:44:15.018745 14303 solver.cpp:337] Iteration 1100, Testing net (#0)
I0705 11:44:15.018770 14303 net.cpp:684] Ignoring source layer data_data_0_split
I0705 11:44:15.018774 14303 net.cpp:684] Ignoring source layer noisy_data
I0705 11:44:15.018775 14303 net.cpp:684] Ignoring source layer noisy_data_noisy_data_0_split
I0705 11:44:15.018779 14303 net.cpp:684] Ignoring source layer z1_bn1_0_split
I0705 11:44:15.018781 14303 net.cpp:684] Ignoring source layer bn1_n
I0705 11:44:15.018784 14303 net.cpp:684] Ignoring source layer noisy_z1_n
I0705 11:44:15.018785 14303 net.cpp:684] Ignoring source layer z1_n_noisy_z1_n_0_split
I0705 11:44:15.018787 14303 net.cpp:684] Ignoring source layer scale1_n
I0705 11:44:15.018790 14303 net.cpp:684] Ignoring source layer relu1_n
I0705 11:44:15.018791 14303 net.cpp:684] Ignoring source layer pool1_n
I0705 11:44:15.018793 14303 net.cpp:684] Ignoring source layer z2_bn2_0_split
I0705 11:44:15.018796 14303 net.cpp:684] Ignoring source layer bn2_n
I0705 11:44:15.018798 14303 net.cpp:684] Ignoring source layer noisy_z2_n
I0705 11:44:15.018800 14303 net.cpp:684] Ignoring source layer z2_n_noisy_z2_n_0_split
I0705 11:44:15.018801 14303 net.cpp:684] Ignoring source layer scale2_n
I0705 11:44:15.018803 14303 net.cpp:684] Ignoring source layer relu2_n
I0705 11:44:15.018806 14303 net.cpp:684] Ignoring source layer pool2_n
I0705 11:44:15.018808 14303 net.cpp:684] Ignoring source layer z3_bn3_0_split
I0705 11:44:15.018811 14303 net.cpp:684] Ignoring source layer bn3_n
I0705 11:44:15.018813 14303 net.cpp:684] Ignoring source layer noisy_z3_n
I0705 11:44:15.018826 14303 net.cpp:684] Ignoring source layer z3_n_noisy_z3_n_0_split
I0705 11:44:15.018827 14303 net.cpp:684] Ignoring source layer scale3_n
I0705 11:44:15.018829 14303 net.cpp:684] Ignoring source layer relu3_n
I0705 11:44:15.018831 14303 net.cpp:684] Ignoring source layer pool3_n
I0705 11:44:15.018834 14303 net.cpp:684] Ignoring source layer z4_bn4_0_split
I0705 11:44:15.018837 14303 net.cpp:684] Ignoring source layer bn4_n
I0705 11:44:15.018839 14303 net.cpp:684] Ignoring source layer noisy_z4_n
I0705 11:44:15.018841 14303 net.cpp:684] Ignoring source layer z4_n_noisy_z4_n_0_split
I0705 11:44:15.018843 14303 net.cpp:684] Ignoring source layer scale4_n
I0705 11:44:15.018846 14303 net.cpp:684] Ignoring source layer relu4_n
I0705 11:44:15.018847 14303 net.cpp:684] Ignoring source layer pool4_n
I0705 11:44:15.018851 14303 net.cpp:684] Ignoring source layer z5_bn5_0_split
I0705 11:44:15.018853 14303 net.cpp:684] Ignoring source layer bn5_n
I0705 11:44:15.018856 14303 net.cpp:684] Ignoring source layer noisy_z5_n
I0705 11:44:15.018857 14303 net.cpp:684] Ignoring source layer z5_n_noisy_z5_n_0_split
I0705 11:44:15.018859 14303 net.cpp:684] Ignoring source layer scale5_n
I0705 11:44:15.018862 14303 net.cpp:684] Ignoring source layer relu5_n
I0705 11:44:15.018863 14303 net.cpp:684] Ignoring source layer pool5_n
I0705 11:44:15.018865 14303 net.cpp:684] Ignoring source layer z6_bn6_0_split
I0705 11:44:15.018888 14303 net.cpp:684] Ignoring source layer bn6_n
I0705 11:44:15.018892 14303 net.cpp:684] Ignoring source layer noisy_z6_n
I0705 11:44:15.018893 14303 net.cpp:684] Ignoring source layer z6_n_noisy_z6_n_0_split
I0705 11:44:15.018895 14303 net.cpp:684] Ignoring source layer scale6_n
I0705 11:44:15.018898 14303 net.cpp:684] Ignoring source layer relu6_n
I0705 11:44:15.018898 14303 net.cpp:684] Ignoring source layer u6
I0705 11:44:15.018900 14303 net.cpp:684] Ignoring source layer comb6
I0705 11:44:15.018903 14303 net.cpp:684] Ignoring source layer z6_r_comb6_0_split
I0705 11:44:15.018904 14303 net.cpp:684] Ignoring source layer recon6
I0705 11:44:15.018906 14303 net.cpp:684] Ignoring source layer bn6_r
I0705 11:44:15.018908 14303 net.cpp:684] Ignoring source layer upsample5
I0705 11:44:15.018910 14303 net.cpp:684] Ignoring source layer comb5
I0705 11:44:15.018913 14303 net.cpp:684] Ignoring source layer z5_r_comb5_0_split
I0705 11:44:15.018913 14303 net.cpp:684] Ignoring source layer recon5
I0705 11:44:15.018915 14303 net.cpp:684] Ignoring source layer bn5_r
I0705 11:44:15.018918 14303 net.cpp:684] Ignoring source layer upsample4
I0705 11:44:15.018919 14303 net.cpp:684] Ignoring source layer comb4
I0705 11:44:15.018921 14303 net.cpp:684] Ignoring source layer z4_r_comb4_0_split
I0705 11:44:15.018923 14303 net.cpp:684] Ignoring source layer recon4
I0705 11:44:15.018926 14303 net.cpp:684] Ignoring source layer bn4_r
I0705 11:44:15.018929 14303 net.cpp:684] Ignoring source layer upsample3
I0705 11:44:15.018930 14303 net.cpp:684] Ignoring source layer comb3
I0705 11:44:15.018931 14303 net.cpp:684] Ignoring source layer z3_r_comb3_0_split
I0705 11:44:15.018934 14303 net.cpp:684] Ignoring source layer recon3
I0705 11:44:15.018935 14303 net.cpp:684] Ignoring source layer bn3_r
I0705 11:44:15.018937 14303 net.cpp:684] Ignoring source layer upsample2
I0705 11:44:15.018939 14303 net.cpp:684] Ignoring source layer comb2
I0705 11:44:15.018941 14303 net.cpp:684] Ignoring source layer z2_r_comb2_0_split
I0705 11:44:15.018944 14303 net.cpp:684] Ignoring source layer recon2
I0705 11:44:15.018944 14303 net.cpp:684] Ignoring source layer bn2_r
I0705 11:44:15.018946 14303 net.cpp:684] Ignoring source layer upsample1
I0705 11:44:15.018949 14303 net.cpp:684] Ignoring source layer comb1
I0705 11:44:15.018950 14303 net.cpp:684] Ignoring source layer z1_r_comb1_0_split
I0705 11:44:15.018952 14303 net.cpp:684] Ignoring source layer recon1
I0705 11:44:15.018954 14303 net.cpp:684] Ignoring source layer bn1_r
I0705 11:44:15.018956 14303 net.cpp:684] Ignoring source layer comb0
I0705 11:44:15.018957 14303 net.cpp:684] Ignoring source layer loss_ladder_6
I0705 11:44:15.018959 14303 net.cpp:684] Ignoring source layer loss_ladder_5
I0705 11:44:15.018961 14303 net.cpp:684] Ignoring source layer loss_ladder_4
I0705 11:44:15.018964 14303 net.cpp:684] Ignoring source layer loss_ladder_3
I0705 11:44:15.018965 14303 net.cpp:684] Ignoring source layer loss_ladder_2
I0705 11:44:15.018966 14303 net.cpp:684] Ignoring source layer loss_ladder_1
I0705 11:44:15.018968 14303 net.cpp:684] Ignoring source layer loss_ladder_0
I0705 11:44:15.018971 14303 net.cpp:684] Ignoring source layer loss_supervised
I0705 11:44:15.178390 14303 solver.cpp:404]     Test net output #0: accuracy = 0.5
I0705 11:44:15.178426 14303 solver.cpp:404]     Test net output #1: prob = 1.13444 (* 1 = 1.13444 loss)
I0705 11:44:15.272018 14303 solver.cpp:228] Iteration 1100, loss = 5.76909
I0705 11:44:15.272037 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:44:15.272043 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.106806 (* 0.1 = 0.0106806 loss)
I0705 11:44:15.272048 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 46.5941 (* 0.1 = 4.65941 loss)
I0705 11:44:15.272053 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.20323 (* 0.1 = 0.220323 loss)
I0705 11:44:15.272056 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.977561 (* 0.1 = 0.0977561 loss)
I0705 11:44:15.272060 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.759017 (* 0.1 = 0.0759017 loss)
I0705 11:44:15.272079 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.863478 (* 0.1 = 0.0863478 loss)
I0705 11:44:15.272083 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.799916 (* 0.1 = 0.0799916 loss)
I0705 11:44:15.272088 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.53867 (* 1 = 0.53867 loss)
I0705 11:44:15.272091 14303 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0705 11:44:20.708025 14303 solver.cpp:228] Iteration 1120, loss = 6.0401
I0705 11:44:20.708050 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:44:20.708056 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.100135 (* 0.1 = 0.0100135 loss)
I0705 11:44:20.708060 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 47.5986 (* 0.1 = 4.75986 loss)
I0705 11:44:20.708065 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.45783 (* 0.1 = 0.245783 loss)
I0705 11:44:20.708068 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.981587 (* 0.1 = 0.0981587 loss)
I0705 11:44:20.708072 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.794832 (* 0.1 = 0.0794832 loss)
I0705 11:44:20.708076 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.88699 (* 0.1 = 0.088699 loss)
I0705 11:44:20.708081 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.832031 (* 0.1 = 0.0832031 loss)
I0705 11:44:20.708084 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.674899 (* 1 = 0.674899 loss)
I0705 11:44:20.708087 14303 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I0705 11:44:26.145215 14303 solver.cpp:228] Iteration 1140, loss = 4.63012
I0705 11:44:26.145238 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0705 11:44:26.145246 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.0996631 (* 0.1 = 0.00996631 loss)
I0705 11:44:26.145251 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 32.8962 (* 0.1 = 3.28962 loss)
I0705 11:44:26.145254 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.66527 (* 0.1 = 0.266527 loss)
I0705 11:44:26.145258 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.00068 (* 0.1 = 0.100068 loss)
I0705 11:44:26.145262 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.809014 (* 0.1 = 0.0809014 loss)
I0705 11:44:26.145267 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.890783 (* 0.1 = 0.0890783 loss)
I0705 11:44:26.145270 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.838117 (* 0.1 = 0.0838117 loss)
I0705 11:44:26.145274 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.710142 (* 1 = 0.710142 loss)
I0705 11:44:26.145278 14303 sgd_solver.cpp:106] Iteration 1140, lr = 0.01
I0705 11:44:31.586247 14303 solver.cpp:228] Iteration 1160, loss = 5.75555
I0705 11:44:31.586272 14303 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0705 11:44:31.586279 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.101458 (* 0.1 = 0.0101458 loss)
I0705 11:44:31.586283 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 45.4878 (* 0.1 = 4.54878 loss)
I0705 11:44:31.586288 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.69681 (* 0.1 = 0.269681 loss)
I0705 11:44:31.586292 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 1.0234 (* 0.1 = 0.10234 loss)
I0705 11:44:31.586307 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.809257 (* 0.1 = 0.0809257 loss)
I0705 11:44:31.586310 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.896137 (* 0.1 = 0.0896137 loss)
I0705 11:44:31.586314 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.831918 (* 0.1 = 0.0831918 loss)
I0705 11:44:31.586318 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.570869 (* 1 = 0.570869 loss)
I0705 11:44:31.586321 14303 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I0705 11:44:37.027415 14303 solver.cpp:228] Iteration 1180, loss = 6.58186
I0705 11:44:37.027459 14303 solver.cpp:244]     Train net output #0: accuracy = 0.375
I0705 11:44:37.027468 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.108455 (* 0.1 = 0.0108455 loss)
I0705 11:44:37.027472 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 52.8327 (* 0.1 = 5.28327 loss)
I0705 11:44:37.027477 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.55559 (* 0.1 = 0.155559 loss)
I0705 11:44:37.027482 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.869502 (* 0.1 = 0.0869502 loss)
I0705 11:44:37.027495 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.768885 (* 0.1 = 0.0768885 loss)
I0705 11:44:37.027499 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.919911 (* 0.1 = 0.0919911 loss)
I0705 11:44:37.027503 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.86353 (* 0.1 = 0.086353 loss)
I0705 11:44:37.027508 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.789996 (* 1 = 0.789996 loss)
I0705 11:44:37.027511 14303 sgd_solver.cpp:106] Iteration 1180, lr = 0.01
I0705 11:44:42.384193 14303 solver.cpp:337] Iteration 1200, Testing net (#0)
I0705 11:44:42.384299 14303 net.cpp:684] Ignoring source layer data_data_0_split
I0705 11:44:42.384302 14303 net.cpp:684] Ignoring source layer noisy_data
I0705 11:44:42.384305 14303 net.cpp:684] Ignoring source layer noisy_data_noisy_data_0_split
I0705 11:44:42.384307 14303 net.cpp:684] Ignoring source layer z1_bn1_0_split
I0705 11:44:42.384310 14303 net.cpp:684] Ignoring source layer bn1_n
I0705 11:44:42.384312 14303 net.cpp:684] Ignoring source layer noisy_z1_n
I0705 11:44:42.384315 14303 net.cpp:684] Ignoring source layer z1_n_noisy_z1_n_0_split
I0705 11:44:42.384315 14303 net.cpp:684] Ignoring source layer scale1_n
I0705 11:44:42.384317 14303 net.cpp:684] Ignoring source layer relu1_n
I0705 11:44:42.384320 14303 net.cpp:684] Ignoring source layer pool1_n
I0705 11:44:42.384322 14303 net.cpp:684] Ignoring source layer z2_bn2_0_split
I0705 11:44:42.384325 14303 net.cpp:684] Ignoring source layer bn2_n
I0705 11:44:42.384327 14303 net.cpp:684] Ignoring source layer noisy_z2_n
I0705 11:44:42.384328 14303 net.cpp:684] Ignoring source layer z2_n_noisy_z2_n_0_split
I0705 11:44:42.384330 14303 net.cpp:684] Ignoring source layer scale2_n
I0705 11:44:42.384332 14303 net.cpp:684] Ignoring source layer relu2_n
I0705 11:44:42.384335 14303 net.cpp:684] Ignoring source layer pool2_n
I0705 11:44:42.384337 14303 net.cpp:684] Ignoring source layer z3_bn3_0_split
I0705 11:44:42.384340 14303 net.cpp:684] Ignoring source layer bn3_n
I0705 11:44:42.384341 14303 net.cpp:684] Ignoring source layer noisy_z3_n
I0705 11:44:42.384343 14303 net.cpp:684] Ignoring source layer z3_n_noisy_z3_n_0_split
I0705 11:44:42.384346 14303 net.cpp:684] Ignoring source layer scale3_n
I0705 11:44:42.384346 14303 net.cpp:684] Ignoring source layer relu3_n
I0705 11:44:42.384349 14303 net.cpp:684] Ignoring source layer pool3_n
I0705 11:44:42.384352 14303 net.cpp:684] Ignoring source layer z4_bn4_0_split
I0705 11:44:42.384354 14303 net.cpp:684] Ignoring source layer bn4_n
I0705 11:44:42.384356 14303 net.cpp:684] Ignoring source layer noisy_z4_n
I0705 11:44:42.384358 14303 net.cpp:684] Ignoring source layer z4_n_noisy_z4_n_0_split
I0705 11:44:42.384361 14303 net.cpp:684] Ignoring source layer scale4_n
I0705 11:44:42.384362 14303 net.cpp:684] Ignoring source layer relu4_n
I0705 11:44:42.384364 14303 net.cpp:684] Ignoring source layer pool4_n
I0705 11:44:42.384367 14303 net.cpp:684] Ignoring source layer z5_bn5_0_split
I0705 11:44:42.384371 14303 net.cpp:684] Ignoring source layer bn5_n
I0705 11:44:42.384371 14303 net.cpp:684] Ignoring source layer noisy_z5_n
I0705 11:44:42.384373 14303 net.cpp:684] Ignoring source layer z5_n_noisy_z5_n_0_split
I0705 11:44:42.384376 14303 net.cpp:684] Ignoring source layer scale5_n
I0705 11:44:42.384377 14303 net.cpp:684] Ignoring source layer relu5_n
I0705 11:44:42.384379 14303 net.cpp:684] Ignoring source layer pool5_n
I0705 11:44:42.384382 14303 net.cpp:684] Ignoring source layer z6_bn6_0_split
I0705 11:44:42.384384 14303 net.cpp:684] Ignoring source layer bn6_n
I0705 11:44:42.384387 14303 net.cpp:684] Ignoring source layer noisy_z6_n
I0705 11:44:42.384388 14303 net.cpp:684] Ignoring source layer z6_n_noisy_z6_n_0_split
I0705 11:44:42.384390 14303 net.cpp:684] Ignoring source layer scale6_n
I0705 11:44:42.384392 14303 net.cpp:684] Ignoring source layer relu6_n
I0705 11:44:42.384393 14303 net.cpp:684] Ignoring source layer u6
I0705 11:44:42.384395 14303 net.cpp:684] Ignoring source layer comb6
I0705 11:44:42.384397 14303 net.cpp:684] Ignoring source layer z6_r_comb6_0_split
I0705 11:44:42.384399 14303 net.cpp:684] Ignoring source layer recon6
I0705 11:44:42.384402 14303 net.cpp:684] Ignoring source layer bn6_r
I0705 11:44:42.384402 14303 net.cpp:684] Ignoring source layer upsample5
I0705 11:44:42.384404 14303 net.cpp:684] Ignoring source layer comb5
I0705 11:44:42.384407 14303 net.cpp:684] Ignoring source layer z5_r_comb5_0_split
I0705 11:44:42.384408 14303 net.cpp:684] Ignoring source layer recon5
I0705 11:44:42.384410 14303 net.cpp:684] Ignoring source layer bn5_r
I0705 11:44:42.384413 14303 net.cpp:684] Ignoring source layer upsample4
I0705 11:44:42.384423 14303 net.cpp:684] Ignoring source layer comb4
I0705 11:44:42.384425 14303 net.cpp:684] Ignoring source layer z4_r_comb4_0_split
I0705 11:44:42.384426 14303 net.cpp:684] Ignoring source layer recon4
I0705 11:44:42.384428 14303 net.cpp:684] Ignoring source layer bn4_r
I0705 11:44:42.384430 14303 net.cpp:684] Ignoring source layer upsample3
I0705 11:44:42.384433 14303 net.cpp:684] Ignoring source layer comb3
I0705 11:44:42.384434 14303 net.cpp:684] Ignoring source layer z3_r_comb3_0_split
I0705 11:44:42.384436 14303 net.cpp:684] Ignoring source layer recon3
I0705 11:44:42.384438 14303 net.cpp:684] Ignoring source layer bn3_r
I0705 11:44:42.384439 14303 net.cpp:684] Ignoring source layer upsample2
I0705 11:44:42.384441 14303 net.cpp:684] Ignoring source layer comb2
I0705 11:44:42.384443 14303 net.cpp:684] Ignoring source layer z2_r_comb2_0_split
I0705 11:44:42.384445 14303 net.cpp:684] Ignoring source layer recon2
I0705 11:44:42.384448 14303 net.cpp:684] Ignoring source layer bn2_r
I0705 11:44:42.384449 14303 net.cpp:684] Ignoring source layer upsample1
I0705 11:44:42.384450 14303 net.cpp:684] Ignoring source layer comb1
I0705 11:44:42.384452 14303 net.cpp:684] Ignoring source layer z1_r_comb1_0_split
I0705 11:44:42.384454 14303 net.cpp:684] Ignoring source layer recon1
I0705 11:44:42.384456 14303 net.cpp:684] Ignoring source layer bn1_r
I0705 11:44:42.384457 14303 net.cpp:684] Ignoring source layer comb0
I0705 11:44:42.384459 14303 net.cpp:684] Ignoring source layer loss_ladder_6
I0705 11:44:42.384461 14303 net.cpp:684] Ignoring source layer loss_ladder_5
I0705 11:44:42.384464 14303 net.cpp:684] Ignoring source layer loss_ladder_4
I0705 11:44:42.384469 14303 net.cpp:684] Ignoring source layer loss_ladder_3
I0705 11:44:42.384469 14303 net.cpp:684] Ignoring source layer loss_ladder_2
I0705 11:44:42.384471 14303 net.cpp:684] Ignoring source layer loss_ladder_1
I0705 11:44:42.384474 14303 net.cpp:684] Ignoring source layer loss_ladder_0
I0705 11:44:42.384476 14303 net.cpp:684] Ignoring source layer loss_supervised
I0705 11:44:42.544128 14303 solver.cpp:404]     Test net output #0: accuracy = 0.507812
I0705 11:44:42.544164 14303 solver.cpp:404]     Test net output #1: prob = 1.72272 (* 1 = 1.72272 loss)
I0705 11:44:42.638175 14303 solver.cpp:228] Iteration 1200, loss = 6.45407
I0705 11:44:42.638193 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:44:42.638200 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.107322 (* 0.1 = 0.0107322 loss)
I0705 11:44:42.638205 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 53.4771 (* 0.1 = 5.34771 loss)
I0705 11:44:42.638209 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.43475 (* 0.1 = 0.143475 loss)
I0705 11:44:42.638213 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.833443 (* 0.1 = 0.0833443 loss)
I0705 11:44:42.638216 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.750386 (* 0.1 = 0.0750386 loss)
I0705 11:44:42.638221 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.879034 (* 0.1 = 0.0879034 loss)
I0705 11:44:42.638224 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.844878 (* 0.1 = 0.0844878 loss)
I0705 11:44:42.638228 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.62138 (* 1 = 0.62138 loss)
I0705 11:44:42.638232 14303 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0705 11:44:48.090049 14303 solver.cpp:228] Iteration 1220, loss = 6.91518
I0705 11:44:48.090072 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:44:48.090080 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.107786 (* 0.1 = 0.0107786 loss)
I0705 11:44:48.090085 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 58.0268 (* 0.1 = 5.80268 loss)
I0705 11:44:48.090088 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.38331 (* 0.1 = 0.138331 loss)
I0705 11:44:48.090092 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.858231 (* 0.1 = 0.0858231 loss)
I0705 11:44:48.090095 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.745161 (* 0.1 = 0.0745161 loss)
I0705 11:44:48.090121 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.867418 (* 0.1 = 0.0867418 loss)
I0705 11:44:48.090126 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.824226 (* 0.1 = 0.0824226 loss)
I0705 11:44:48.090129 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.633888 (* 1 = 0.633888 loss)
I0705 11:44:48.090132 14303 sgd_solver.cpp:106] Iteration 1220, lr = 0.01
I0705 11:44:53.525621 14303 solver.cpp:228] Iteration 1240, loss = 5.24939
I0705 11:44:53.525645 14303 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0705 11:44:53.525652 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.101511 (* 0.1 = 0.0101511 loss)
I0705 11:44:53.525656 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 40.3967 (* 0.1 = 4.03967 loss)
I0705 11:44:53.525661 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.62427 (* 0.1 = 0.262427 loss)
I0705 11:44:53.525665 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.986347 (* 0.1 = 0.0986347 loss)
I0705 11:44:53.525670 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.783328 (* 0.1 = 0.0783328 loss)
I0705 11:44:53.525672 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.87034 (* 0.1 = 0.087034 loss)
I0705 11:44:53.525676 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.819637 (* 0.1 = 0.0819637 loss)
I0705 11:44:53.525681 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.591172 (* 1 = 0.591172 loss)
I0705 11:44:53.525683 14303 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I0705 11:44:58.962312 14303 solver.cpp:228] Iteration 1260, loss = 5.98186
I0705 11:44:58.962335 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:44:58.962343 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.104257 (* 0.1 = 0.0104257 loss)
I0705 11:44:58.962347 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 48.2327 (* 0.1 = 4.82327 loss)
I0705 11:44:58.962352 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.21562 (* 0.1 = 0.221562 loss)
I0705 11:44:58.962357 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.984708 (* 0.1 = 0.0984708 loss)
I0705 11:44:58.962360 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.784304 (* 0.1 = 0.0784304 loss)
I0705 11:44:58.962363 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.871598 (* 0.1 = 0.0871598 loss)
I0705 11:44:58.962368 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.810348 (* 0.1 = 0.0810348 loss)
I0705 11:44:58.962371 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.581506 (* 1 = 0.581506 loss)
I0705 11:44:58.962375 14303 sgd_solver.cpp:106] Iteration 1260, lr = 0.01
I0705 11:45:04.397449 14303 solver.cpp:228] Iteration 1280, loss = 4.96726
I0705 11:45:04.397474 14303 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0705 11:45:04.397480 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.105624 (* 0.1 = 0.0105624 loss)
I0705 11:45:04.397485 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 38.5149 (* 0.1 = 3.8515 loss)
I0705 11:45:04.397490 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.07431 (* 0.1 = 0.207431 loss)
I0705 11:45:04.397493 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.943528 (* 0.1 = 0.0943528 loss)
I0705 11:45:04.397497 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.782707 (* 0.1 = 0.0782707 loss)
I0705 11:45:04.397500 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.891883 (* 0.1 = 0.0891883 loss)
I0705 11:45:04.397505 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.840247 (* 0.1 = 0.0840247 loss)
I0705 11:45:04.397508 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.551939 (* 1 = 0.551939 loss)
I0705 11:45:04.397512 14303 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I0705 11:45:09.737500 14303 solver.cpp:337] Iteration 1300, Testing net (#0)
I0705 11:45:09.737534 14303 net.cpp:684] Ignoring source layer data_data_0_split
I0705 11:45:09.737536 14303 net.cpp:684] Ignoring source layer noisy_data
I0705 11:45:09.737538 14303 net.cpp:684] Ignoring source layer noisy_data_noisy_data_0_split
I0705 11:45:09.737541 14303 net.cpp:684] Ignoring source layer z1_bn1_0_split
I0705 11:45:09.737545 14303 net.cpp:684] Ignoring source layer bn1_n
I0705 11:45:09.737546 14303 net.cpp:684] Ignoring source layer noisy_z1_n
I0705 11:45:09.737547 14303 net.cpp:684] Ignoring source layer z1_n_noisy_z1_n_0_split
I0705 11:45:09.737550 14303 net.cpp:684] Ignoring source layer scale1_n
I0705 11:45:09.737551 14303 net.cpp:684] Ignoring source layer relu1_n
I0705 11:45:09.737553 14303 net.cpp:684] Ignoring source layer pool1_n
I0705 11:45:09.737556 14303 net.cpp:684] Ignoring source layer z2_bn2_0_split
I0705 11:45:09.737558 14303 net.cpp:684] Ignoring source layer bn2_n
I0705 11:45:09.737560 14303 net.cpp:684] Ignoring source layer noisy_z2_n
I0705 11:45:09.737562 14303 net.cpp:684] Ignoring source layer z2_n_noisy_z2_n_0_split
I0705 11:45:09.737565 14303 net.cpp:684] Ignoring source layer scale2_n
I0705 11:45:09.737566 14303 net.cpp:684] Ignoring source layer relu2_n
I0705 11:45:09.737568 14303 net.cpp:684] Ignoring source layer pool2_n
I0705 11:45:09.737571 14303 net.cpp:684] Ignoring source layer z3_bn3_0_split
I0705 11:45:09.737573 14303 net.cpp:684] Ignoring source layer bn3_n
I0705 11:45:09.737576 14303 net.cpp:684] Ignoring source layer noisy_z3_n
I0705 11:45:09.737577 14303 net.cpp:684] Ignoring source layer z3_n_noisy_z3_n_0_split
I0705 11:45:09.737579 14303 net.cpp:684] Ignoring source layer scale3_n
I0705 11:45:09.737581 14303 net.cpp:684] Ignoring source layer relu3_n
I0705 11:45:09.737582 14303 net.cpp:684] Ignoring source layer pool3_n
I0705 11:45:09.737597 14303 net.cpp:684] Ignoring source layer z4_bn4_0_split
I0705 11:45:09.737599 14303 net.cpp:684] Ignoring source layer bn4_n
I0705 11:45:09.737601 14303 net.cpp:684] Ignoring source layer noisy_z4_n
I0705 11:45:09.737603 14303 net.cpp:684] Ignoring source layer z4_n_noisy_z4_n_0_split
I0705 11:45:09.737606 14303 net.cpp:684] Ignoring source layer scale4_n
I0705 11:45:09.737607 14303 net.cpp:684] Ignoring source layer relu4_n
I0705 11:45:09.737609 14303 net.cpp:684] Ignoring source layer pool4_n
I0705 11:45:09.737612 14303 net.cpp:684] Ignoring source layer z5_bn5_0_split
I0705 11:45:09.737615 14303 net.cpp:684] Ignoring source layer bn5_n
I0705 11:45:09.737617 14303 net.cpp:684] Ignoring source layer noisy_z5_n
I0705 11:45:09.737618 14303 net.cpp:684] Ignoring source layer z5_n_noisy_z5_n_0_split
I0705 11:45:09.737620 14303 net.cpp:684] Ignoring source layer scale5_n
I0705 11:45:09.737622 14303 net.cpp:684] Ignoring source layer relu5_n
I0705 11:45:09.737624 14303 net.cpp:684] Ignoring source layer pool5_n
I0705 11:45:09.737627 14303 net.cpp:684] Ignoring source layer z6_bn6_0_split
I0705 11:45:09.737629 14303 net.cpp:684] Ignoring source layer bn6_n
I0705 11:45:09.737632 14303 net.cpp:684] Ignoring source layer noisy_z6_n
I0705 11:45:09.737633 14303 net.cpp:684] Ignoring source layer z6_n_noisy_z6_n_0_split
I0705 11:45:09.737634 14303 net.cpp:684] Ignoring source layer scale6_n
I0705 11:45:09.737637 14303 net.cpp:684] Ignoring source layer relu6_n
I0705 11:45:09.737638 14303 net.cpp:684] Ignoring source layer u6
I0705 11:45:09.737640 14303 net.cpp:684] Ignoring source layer comb6
I0705 11:45:09.737643 14303 net.cpp:684] Ignoring source layer z6_r_comb6_0_split
I0705 11:45:09.737644 14303 net.cpp:684] Ignoring source layer recon6
I0705 11:45:09.737646 14303 net.cpp:684] Ignoring source layer bn6_r
I0705 11:45:09.737648 14303 net.cpp:684] Ignoring source layer upsample5
I0705 11:45:09.737650 14303 net.cpp:684] Ignoring source layer comb5
I0705 11:45:09.737651 14303 net.cpp:684] Ignoring source layer z5_r_comb5_0_split
I0705 11:45:09.737653 14303 net.cpp:684] Ignoring source layer recon5
I0705 11:45:09.737655 14303 net.cpp:684] Ignoring source layer bn5_r
I0705 11:45:09.737658 14303 net.cpp:684] Ignoring source layer upsample4
I0705 11:45:09.737663 14303 net.cpp:684] Ignoring source layer comb4
I0705 11:45:09.737665 14303 net.cpp:684] Ignoring source layer z4_r_comb4_0_split
I0705 11:45:09.737666 14303 net.cpp:684] Ignoring source layer recon4
I0705 11:45:09.737668 14303 net.cpp:684] Ignoring source layer bn4_r
I0705 11:45:09.737670 14303 net.cpp:684] Ignoring source layer upsample3
I0705 11:45:09.737673 14303 net.cpp:684] Ignoring source layer comb3
I0705 11:45:09.737674 14303 net.cpp:684] Ignoring source layer z3_r_comb3_0_split
I0705 11:45:09.737676 14303 net.cpp:684] Ignoring source layer recon3
I0705 11:45:09.737678 14303 net.cpp:684] Ignoring source layer bn3_r
I0705 11:45:09.737679 14303 net.cpp:684] Ignoring source layer upsample2
I0705 11:45:09.737681 14303 net.cpp:684] Ignoring source layer comb2
I0705 11:45:09.737684 14303 net.cpp:684] Ignoring source layer z2_r_comb2_0_split
I0705 11:45:09.737685 14303 net.cpp:684] Ignoring source layer recon2
I0705 11:45:09.737687 14303 net.cpp:684] Ignoring source layer bn2_r
I0705 11:45:09.737689 14303 net.cpp:684] Ignoring source layer upsample1
I0705 11:45:09.737691 14303 net.cpp:684] Ignoring source layer comb1
I0705 11:45:09.737694 14303 net.cpp:684] Ignoring source layer z1_r_comb1_0_split
I0705 11:45:09.737694 14303 net.cpp:684] Ignoring source layer recon1
I0705 11:45:09.737699 14303 net.cpp:684] Ignoring source layer bn1_r
I0705 11:45:09.737699 14303 net.cpp:684] Ignoring source layer comb0
I0705 11:45:09.737701 14303 net.cpp:684] Ignoring source layer loss_ladder_6
I0705 11:45:09.737704 14303 net.cpp:684] Ignoring source layer loss_ladder_5
I0705 11:45:09.737705 14303 net.cpp:684] Ignoring source layer loss_ladder_4
I0705 11:45:09.737706 14303 net.cpp:684] Ignoring source layer loss_ladder_3
I0705 11:45:09.737709 14303 net.cpp:684] Ignoring source layer loss_ladder_2
I0705 11:45:09.737710 14303 net.cpp:684] Ignoring source layer loss_ladder_1
I0705 11:45:09.737712 14303 net.cpp:684] Ignoring source layer loss_ladder_0
I0705 11:45:09.737715 14303 net.cpp:684] Ignoring source layer loss_supervised
I0705 11:45:09.897042 14303 solver.cpp:404]     Test net output #0: accuracy = 0.5
I0705 11:45:09.897078 14303 solver.cpp:404]     Test net output #1: prob = 1.3059 (* 1 = 1.3059 loss)
I0705 11:45:09.990686 14303 solver.cpp:228] Iteration 1300, loss = 5.74567
I0705 11:45:09.990705 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:45:09.990712 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.103921 (* 0.1 = 0.0103921 loss)
I0705 11:45:09.990716 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 46.3591 (* 0.1 = 4.63591 loss)
I0705 11:45:09.990721 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.89586 (* 0.1 = 0.189586 loss)
I0705 11:45:09.990725 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.914755 (* 0.1 = 0.0914755 loss)
I0705 11:45:09.990728 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.775617 (* 0.1 = 0.0775617 loss)
I0705 11:45:09.990732 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.883367 (* 0.1 = 0.0883367 loss)
I0705 11:45:09.990736 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.813548 (* 0.1 = 0.0813548 loss)
I0705 11:45:09.990741 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.571055 (* 1 = 0.571055 loss)
I0705 11:45:09.990744 14303 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0705 11:45:15.426672 14303 solver.cpp:228] Iteration 1320, loss = 5.49093
I0705 11:45:15.426812 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:45:15.426822 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.101976 (* 0.1 = 0.0101976 loss)
I0705 11:45:15.426827 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 43.2406 (* 0.1 = 4.32406 loss)
I0705 11:45:15.426832 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.25758 (* 0.1 = 0.225758 loss)
I0705 11:45:15.426836 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.951805 (* 0.1 = 0.0951805 loss)
I0705 11:45:15.426839 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.766177 (* 0.1 = 0.0766177 loss)
I0705 11:45:15.426843 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.861574 (* 0.1 = 0.0861574 loss)
I0705 11:45:15.426847 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.805597 (* 0.1 = 0.0805597 loss)
I0705 11:45:15.426851 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.592399 (* 1 = 0.592399 loss)
I0705 11:45:15.426854 14303 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I0705 11:45:20.865325 14303 solver.cpp:228] Iteration 1340, loss = 5.10743
I0705 11:45:20.865350 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:45:20.865356 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.101839 (* 0.1 = 0.0101839 loss)
I0705 11:45:20.865361 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 38.3865 (* 0.1 = 3.83865 loss)
I0705 11:45:20.865365 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.27626 (* 0.1 = 0.227626 loss)
I0705 11:45:20.865370 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.933956 (* 0.1 = 0.0933956 loss)
I0705 11:45:20.865372 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.78741 (* 0.1 = 0.078741 loss)
I0705 11:45:20.865376 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.892017 (* 0.1 = 0.0892017 loss)
I0705 11:45:20.865381 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.849252 (* 0.1 = 0.0849252 loss)
I0705 11:45:20.865384 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.684703 (* 1 = 0.684703 loss)
I0705 11:45:20.865387 14303 sgd_solver.cpp:106] Iteration 1340, lr = 0.01
I0705 11:45:26.299796 14303 solver.cpp:228] Iteration 1360, loss = 4.79128
I0705 11:45:26.299820 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0705 11:45:26.299828 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.0993505 (* 0.1 = 0.00993505 loss)
I0705 11:45:26.299832 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 35.0239 (* 0.1 = 3.50239 loss)
I0705 11:45:26.299836 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.70279 (* 0.1 = 0.270279 loss)
I0705 11:45:26.299840 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.981733 (* 0.1 = 0.0981733 loss)
I0705 11:45:26.299844 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.76908 (* 0.1 = 0.076908 loss)
I0705 11:45:26.299849 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.864655 (* 0.1 = 0.0864656 loss)
I0705 11:45:26.299852 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.814314 (* 0.1 = 0.0814314 loss)
I0705 11:45:26.299856 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.665698 (* 1 = 0.665698 loss)
I0705 11:45:26.299860 14303 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I0705 11:45:31.746825 14303 solver.cpp:228] Iteration 1380, loss = 8.31441
I0705 11:45:31.746850 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:45:31.746868 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.109461 (* 0.1 = 0.0109461 loss)
I0705 11:45:31.746872 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 71.5555 (* 0.1 = 7.15555 loss)
I0705 11:45:31.746877 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.52093 (* 0.1 = 0.152093 loss)
I0705 11:45:31.746882 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.797166 (* 0.1 = 0.0797166 loss)
I0705 11:45:31.746906 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.689229 (* 0.1 = 0.068923 loss)
I0705 11:45:31.746911 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.859428 (* 0.1 = 0.0859428 loss)
I0705 11:45:31.746914 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.804871 (* 0.1 = 0.0804871 loss)
I0705 11:45:31.746917 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.68075 (* 1 = 0.68075 loss)
I0705 11:45:31.746922 14303 sgd_solver.cpp:106] Iteration 1380, lr = 0.01
I0705 11:45:37.112285 14303 solver.cpp:337] Iteration 1400, Testing net (#0)
I0705 11:45:37.112303 14303 net.cpp:684] Ignoring source layer data_data_0_split
I0705 11:45:37.112305 14303 net.cpp:684] Ignoring source layer noisy_data
I0705 11:45:37.112308 14303 net.cpp:684] Ignoring source layer noisy_data_noisy_data_0_split
I0705 11:45:37.112310 14303 net.cpp:684] Ignoring source layer z1_bn1_0_split
I0705 11:45:37.112313 14303 net.cpp:684] Ignoring source layer bn1_n
I0705 11:45:37.112315 14303 net.cpp:684] Ignoring source layer noisy_z1_n
I0705 11:45:37.112316 14303 net.cpp:684] Ignoring source layer z1_n_noisy_z1_n_0_split
I0705 11:45:37.112318 14303 net.cpp:684] Ignoring source layer scale1_n
I0705 11:45:37.112320 14303 net.cpp:684] Ignoring source layer relu1_n
I0705 11:45:37.112323 14303 net.cpp:684] Ignoring source layer pool1_n
I0705 11:45:37.112324 14303 net.cpp:684] Ignoring source layer z2_bn2_0_split
I0705 11:45:37.112328 14303 net.cpp:684] Ignoring source layer bn2_n
I0705 11:45:37.112329 14303 net.cpp:684] Ignoring source layer noisy_z2_n
I0705 11:45:37.112331 14303 net.cpp:684] Ignoring source layer z2_n_noisy_z2_n_0_split
I0705 11:45:37.112334 14303 net.cpp:684] Ignoring source layer scale2_n
I0705 11:45:37.112335 14303 net.cpp:684] Ignoring source layer relu2_n
I0705 11:45:37.112337 14303 net.cpp:684] Ignoring source layer pool2_n
I0705 11:45:37.112339 14303 net.cpp:684] Ignoring source layer z3_bn3_0_split
I0705 11:45:37.112342 14303 net.cpp:684] Ignoring source layer bn3_n
I0705 11:45:37.112344 14303 net.cpp:684] Ignoring source layer noisy_z3_n
I0705 11:45:37.112345 14303 net.cpp:684] Ignoring source layer z3_n_noisy_z3_n_0_split
I0705 11:45:37.112347 14303 net.cpp:684] Ignoring source layer scale3_n
I0705 11:45:37.112349 14303 net.cpp:684] Ignoring source layer relu3_n
I0705 11:45:37.112351 14303 net.cpp:684] Ignoring source layer pool3_n
I0705 11:45:37.112354 14303 net.cpp:684] Ignoring source layer z4_bn4_0_split
I0705 11:45:37.112356 14303 net.cpp:684] Ignoring source layer bn4_n
I0705 11:45:37.112359 14303 net.cpp:684] Ignoring source layer noisy_z4_n
I0705 11:45:37.112360 14303 net.cpp:684] Ignoring source layer z4_n_noisy_z4_n_0_split
I0705 11:45:37.112362 14303 net.cpp:684] Ignoring source layer scale4_n
I0705 11:45:37.112365 14303 net.cpp:684] Ignoring source layer relu4_n
I0705 11:45:37.112366 14303 net.cpp:684] Ignoring source layer pool4_n
I0705 11:45:37.112368 14303 net.cpp:684] Ignoring source layer z5_bn5_0_split
I0705 11:45:37.112371 14303 net.cpp:684] Ignoring source layer bn5_n
I0705 11:45:37.112373 14303 net.cpp:684] Ignoring source layer noisy_z5_n
I0705 11:45:37.112375 14303 net.cpp:684] Ignoring source layer z5_n_noisy_z5_n_0_split
I0705 11:45:37.112376 14303 net.cpp:684] Ignoring source layer scale5_n
I0705 11:45:37.112378 14303 net.cpp:684] Ignoring source layer relu5_n
I0705 11:45:37.112380 14303 net.cpp:684] Ignoring source layer pool5_n
I0705 11:45:37.112393 14303 net.cpp:684] Ignoring source layer z6_bn6_0_split
I0705 11:45:37.112396 14303 net.cpp:684] Ignoring source layer bn6_n
I0705 11:45:37.112398 14303 net.cpp:684] Ignoring source layer noisy_z6_n
I0705 11:45:37.112401 14303 net.cpp:684] Ignoring source layer z6_n_noisy_z6_n_0_split
I0705 11:45:37.112401 14303 net.cpp:684] Ignoring source layer scale6_n
I0705 11:45:37.112403 14303 net.cpp:684] Ignoring source layer relu6_n
I0705 11:45:37.112406 14303 net.cpp:684] Ignoring source layer u6
I0705 11:45:37.112407 14303 net.cpp:684] Ignoring source layer comb6
I0705 11:45:37.112409 14303 net.cpp:684] Ignoring source layer z6_r_comb6_0_split
I0705 11:45:37.112426 14303 net.cpp:684] Ignoring source layer recon6
I0705 11:45:37.112429 14303 net.cpp:684] Ignoring source layer bn6_r
I0705 11:45:37.112431 14303 net.cpp:684] Ignoring source layer upsample5
I0705 11:45:37.112432 14303 net.cpp:684] Ignoring source layer comb5
I0705 11:45:37.112434 14303 net.cpp:684] Ignoring source layer z5_r_comb5_0_split
I0705 11:45:37.112437 14303 net.cpp:684] Ignoring source layer recon5
I0705 11:45:37.112438 14303 net.cpp:684] Ignoring source layer bn5_r
I0705 11:45:37.112440 14303 net.cpp:684] Ignoring source layer upsample4
I0705 11:45:37.112442 14303 net.cpp:684] Ignoring source layer comb4
I0705 11:45:37.112443 14303 net.cpp:684] Ignoring source layer z4_r_comb4_0_split
I0705 11:45:37.112445 14303 net.cpp:684] Ignoring source layer recon4
I0705 11:45:37.112447 14303 net.cpp:684] Ignoring source layer bn4_r
I0705 11:45:37.112449 14303 net.cpp:684] Ignoring source layer upsample3
I0705 11:45:37.112452 14303 net.cpp:684] Ignoring source layer comb3
I0705 11:45:37.112453 14303 net.cpp:684] Ignoring source layer z3_r_comb3_0_split
I0705 11:45:37.112455 14303 net.cpp:684] Ignoring source layer recon3
I0705 11:45:37.112457 14303 net.cpp:684] Ignoring source layer bn3_r
I0705 11:45:37.112458 14303 net.cpp:684] Ignoring source layer upsample2
I0705 11:45:37.112460 14303 net.cpp:684] Ignoring source layer comb2
I0705 11:45:37.112462 14303 net.cpp:684] Ignoring source layer z2_r_comb2_0_split
I0705 11:45:37.112464 14303 net.cpp:684] Ignoring source layer recon2
I0705 11:45:37.112467 14303 net.cpp:684] Ignoring source layer bn2_r
I0705 11:45:37.112468 14303 net.cpp:684] Ignoring source layer upsample1
I0705 11:45:37.112469 14303 net.cpp:684] Ignoring source layer comb1
I0705 11:45:37.112471 14303 net.cpp:684] Ignoring source layer z1_r_comb1_0_split
I0705 11:45:37.112473 14303 net.cpp:684] Ignoring source layer recon1
I0705 11:45:37.112475 14303 net.cpp:684] Ignoring source layer bn1_r
I0705 11:45:37.112478 14303 net.cpp:684] Ignoring source layer comb0
I0705 11:45:37.112479 14303 net.cpp:684] Ignoring source layer loss_ladder_6
I0705 11:45:37.112481 14303 net.cpp:684] Ignoring source layer loss_ladder_5
I0705 11:45:37.112483 14303 net.cpp:684] Ignoring source layer loss_ladder_4
I0705 11:45:37.112484 14303 net.cpp:684] Ignoring source layer loss_ladder_3
I0705 11:45:37.112486 14303 net.cpp:684] Ignoring source layer loss_ladder_2
I0705 11:45:37.112488 14303 net.cpp:684] Ignoring source layer loss_ladder_1
I0705 11:45:37.112490 14303 net.cpp:684] Ignoring source layer loss_ladder_0
I0705 11:45:37.112493 14303 net.cpp:684] Ignoring source layer loss_supervised
I0705 11:45:37.272181 14303 solver.cpp:404]     Test net output #0: accuracy = 0.53125
I0705 11:45:37.272205 14303 solver.cpp:404]     Test net output #1: prob = 0.977068 (* 1 = 0.977068 loss)
I0705 11:45:37.365809 14303 solver.cpp:228] Iteration 1400, loss = 5.26566
I0705 11:45:37.365830 14303 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0705 11:45:37.365838 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.104733 (* 0.1 = 0.0104733 loss)
I0705 11:45:37.365841 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 41.6661 (* 0.1 = 4.16661 loss)
I0705 11:45:37.365846 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.28353 (* 0.1 = 0.228353 loss)
I0705 11:45:37.365849 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.949368 (* 0.1 = 0.0949368 loss)
I0705 11:45:37.365854 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.77372 (* 0.1 = 0.077372 loss)
I0705 11:45:37.365859 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.894162 (* 0.1 = 0.0894162 loss)
I0705 11:45:37.365862 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.805561 (* 0.1 = 0.0805561 loss)
I0705 11:45:37.365866 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.51794 (* 1 = 0.51794 loss)
I0705 11:45:37.365870 14303 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0705 11:45:42.799971 14303 solver.cpp:228] Iteration 1420, loss = 5.21472
I0705 11:45:42.800012 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0705 11:45:42.800021 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.101832 (* 0.1 = 0.0101832 loss)
I0705 11:45:42.800025 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 38.7082 (* 0.1 = 3.87082 loss)
I0705 11:45:42.800030 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.35803 (* 0.1 = 0.235803 loss)
I0705 11:45:42.800034 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.922856 (* 0.1 = 0.0922856 loss)
I0705 11:45:42.800037 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.762565 (* 0.1 = 0.0762565 loss)
I0705 11:45:42.800042 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.877377 (* 0.1 = 0.0877377 loss)
I0705 11:45:42.800045 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.807932 (* 0.1 = 0.0807932 loss)
I0705 11:45:42.800050 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.760841 (* 1 = 0.760841 loss)
I0705 11:45:42.800053 14303 sgd_solver.cpp:106] Iteration 1420, lr = 0.01
I0705 11:45:48.235554 14303 solver.cpp:228] Iteration 1440, loss = 6.36213
I0705 11:45:48.235659 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:45:48.235669 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.107327 (* 0.1 = 0.0107327 loss)
I0705 11:45:48.235673 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 52.6599 (* 0.1 = 5.26599 loss)
I0705 11:45:48.235678 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.59497 (* 0.1 = 0.159497 loss)
I0705 11:45:48.235682 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.826894 (* 0.1 = 0.0826894 loss)
I0705 11:45:48.235687 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.719536 (* 0.1 = 0.0719536 loss)
I0705 11:45:48.235690 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.876632 (* 0.1 = 0.0876632 loss)
I0705 11:45:48.235693 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.827234 (* 0.1 = 0.0827234 loss)
I0705 11:45:48.235697 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.600885 (* 1 = 0.600885 loss)
I0705 11:45:48.235702 14303 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I0705 11:45:53.672199 14303 solver.cpp:228] Iteration 1460, loss = 8.3345
I0705 11:45:53.672233 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:45:53.672241 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.108496 (* 0.1 = 0.0108496 loss)
I0705 11:45:53.672245 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 72.9537 (* 0.1 = 7.29537 loss)
I0705 11:45:53.672250 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.13863 (* 0.1 = 0.113863 loss)
I0705 11:45:53.672255 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.729011 (* 0.1 = 0.0729011 loss)
I0705 11:45:53.672258 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.685276 (* 0.1 = 0.0685276 loss)
I0705 11:45:53.672262 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.845487 (* 0.1 = 0.0845487 loss)
I0705 11:45:53.672266 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.800972 (* 0.1 = 0.0800972 loss)
I0705 11:45:53.672269 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.608343 (* 1 = 0.608343 loss)
I0705 11:45:53.672273 14303 sgd_solver.cpp:106] Iteration 1460, lr = 0.01
I0705 11:45:59.108170 14303 solver.cpp:228] Iteration 1480, loss = 7.7133
I0705 11:45:59.108193 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0705 11:45:59.108201 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.106488 (* 0.1 = 0.0106488 loss)
I0705 11:45:59.108204 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 65.3152 (* 0.1 = 6.53152 loss)
I0705 11:45:59.108209 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.14005 (* 0.1 = 0.114005 loss)
I0705 11:45:59.108212 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.762747 (* 0.1 = 0.0762747 loss)
I0705 11:45:59.108217 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.69754 (* 0.1 = 0.069754 loss)
I0705 11:45:59.108220 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.836195 (* 0.1 = 0.0836195 loss)
I0705 11:45:59.108224 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.797701 (* 0.1 = 0.0797701 loss)
I0705 11:45:59.108228 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.7477 (* 1 = 0.7477 loss)
I0705 11:45:59.108232 14303 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I0705 11:46:04.448272 14303 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_1500.caffemodel
I0705 11:46:04.895313 14303 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_1500.solverstate
I0705 11:46:05.183887 14303 solver.cpp:337] Iteration 1500, Testing net (#0)
I0705 11:46:05.183926 14303 net.cpp:684] Ignoring source layer data_data_0_split
I0705 11:46:05.183935 14303 net.cpp:684] Ignoring source layer noisy_data
I0705 11:46:05.183941 14303 net.cpp:684] Ignoring source layer noisy_data_noisy_data_0_split
I0705 11:46:05.183948 14303 net.cpp:684] Ignoring source layer z1_bn1_0_split
I0705 11:46:05.183986 14303 net.cpp:684] Ignoring source layer bn1_n
I0705 11:46:05.183992 14303 net.cpp:684] Ignoring source layer noisy_z1_n
I0705 11:46:05.183998 14303 net.cpp:684] Ignoring source layer z1_n_noisy_z1_n_0_split
I0705 11:46:05.184005 14303 net.cpp:684] Ignoring source layer scale1_n
I0705 11:46:05.184010 14303 net.cpp:684] Ignoring source layer relu1_n
I0705 11:46:05.184015 14303 net.cpp:684] Ignoring source layer pool1_n
I0705 11:46:05.184023 14303 net.cpp:684] Ignoring source layer z2_bn2_0_split
I0705 11:46:05.184031 14303 net.cpp:684] Ignoring source layer bn2_n
I0705 11:46:05.184037 14303 net.cpp:684] Ignoring source layer noisy_z2_n
I0705 11:46:05.184043 14303 net.cpp:684] Ignoring source layer z2_n_noisy_z2_n_0_split
I0705 11:46:05.184048 14303 net.cpp:684] Ignoring source layer scale2_n
I0705 11:46:05.184054 14303 net.cpp:684] Ignoring source layer relu2_n
I0705 11:46:05.184061 14303 net.cpp:684] Ignoring source layer pool2_n
I0705 11:46:05.184068 14303 net.cpp:684] Ignoring source layer z3_bn3_0_split
I0705 11:46:05.184085 14303 net.cpp:684] Ignoring source layer bn3_n
I0705 11:46:05.184090 14303 net.cpp:684] Ignoring source layer noisy_z3_n
I0705 11:46:05.184095 14303 net.cpp:684] Ignoring source layer z3_n_noisy_z3_n_0_split
I0705 11:46:05.184101 14303 net.cpp:684] Ignoring source layer scale3_n
I0705 11:46:05.184106 14303 net.cpp:684] Ignoring source layer relu3_n
I0705 11:46:05.184113 14303 net.cpp:684] Ignoring source layer pool3_n
I0705 11:46:05.184119 14303 net.cpp:684] Ignoring source layer z4_bn4_0_split
I0705 11:46:05.184126 14303 net.cpp:684] Ignoring source layer bn4_n
I0705 11:46:05.184131 14303 net.cpp:684] Ignoring source layer noisy_z4_n
I0705 11:46:05.184137 14303 net.cpp:684] Ignoring source layer z4_n_noisy_z4_n_0_split
I0705 11:46:05.184142 14303 net.cpp:684] Ignoring source layer scale4_n
I0705 11:46:05.184147 14303 net.cpp:684] Ignoring source layer relu4_n
I0705 11:46:05.184154 14303 net.cpp:684] Ignoring source layer pool4_n
I0705 11:46:05.184160 14303 net.cpp:684] Ignoring source layer z5_bn5_0_split
I0705 11:46:05.184168 14303 net.cpp:684] Ignoring source layer bn5_n
I0705 11:46:05.184173 14303 net.cpp:684] Ignoring source layer noisy_z5_n
I0705 11:46:05.184180 14303 net.cpp:684] Ignoring source layer z5_n_noisy_z5_n_0_split
I0705 11:46:05.184185 14303 net.cpp:684] Ignoring source layer scale5_n
I0705 11:46:05.184190 14303 net.cpp:684] Ignoring source layer relu5_n
I0705 11:46:05.184195 14303 net.cpp:684] Ignoring source layer pool5_n
I0705 11:46:05.184203 14303 net.cpp:684] Ignoring source layer z6_bn6_0_split
I0705 11:46:05.184211 14303 net.cpp:684] Ignoring source layer bn6_n
I0705 11:46:05.184216 14303 net.cpp:684] Ignoring source layer noisy_z6_n
I0705 11:46:05.184222 14303 net.cpp:684] Ignoring source layer z6_n_noisy_z6_n_0_split
I0705 11:46:05.184227 14303 net.cpp:684] Ignoring source layer scale6_n
I0705 11:46:05.184233 14303 net.cpp:684] Ignoring source layer relu6_n
I0705 11:46:05.184238 14303 net.cpp:684] Ignoring source layer u6
I0705 11:46:05.184245 14303 net.cpp:684] Ignoring source layer comb6
I0705 11:46:05.184250 14303 net.cpp:684] Ignoring source layer z6_r_comb6_0_split
I0705 11:46:05.184257 14303 net.cpp:684] Ignoring source layer recon6
I0705 11:46:05.184262 14303 net.cpp:684] Ignoring source layer bn6_r
I0705 11:46:05.184267 14303 net.cpp:684] Ignoring source layer upsample5
I0705 11:46:05.184273 14303 net.cpp:684] Ignoring source layer comb5
I0705 11:46:05.184278 14303 net.cpp:684] Ignoring source layer z5_r_comb5_0_split
I0705 11:46:05.184284 14303 net.cpp:684] Ignoring source layer recon5
I0705 11:46:05.184290 14303 net.cpp:684] Ignoring source layer bn5_r
I0705 11:46:05.184296 14303 net.cpp:684] Ignoring source layer upsample4
I0705 11:46:05.184303 14303 net.cpp:684] Ignoring source layer comb4
I0705 11:46:05.184309 14303 net.cpp:684] Ignoring source layer z4_r_comb4_0_split
I0705 11:46:05.184314 14303 net.cpp:684] Ignoring source layer recon4
I0705 11:46:05.184319 14303 net.cpp:684] Ignoring source layer bn4_r
I0705 11:46:05.184325 14303 net.cpp:684] Ignoring source layer upsample3
I0705 11:46:05.184346 14303 net.cpp:684] Ignoring source layer comb3
I0705 11:46:05.184352 14303 net.cpp:684] Ignoring source layer z3_r_comb3_0_split
I0705 11:46:05.184357 14303 net.cpp:684] Ignoring source layer recon3
I0705 11:46:05.184363 14303 net.cpp:684] Ignoring source layer bn3_r
I0705 11:46:05.184368 14303 net.cpp:684] Ignoring source layer upsample2
I0705 11:46:05.184375 14303 net.cpp:684] Ignoring source layer comb2
I0705 11:46:05.184379 14303 net.cpp:684] Ignoring source layer z2_r_comb2_0_split
I0705 11:46:05.184384 14303 net.cpp:684] Ignoring source layer recon2
I0705 11:46:05.184389 14303 net.cpp:684] Ignoring source layer bn2_r
I0705 11:46:05.184396 14303 net.cpp:684] Ignoring source layer upsample1
I0705 11:46:05.184401 14303 net.cpp:684] Ignoring source layer comb1
I0705 11:46:05.184406 14303 net.cpp:684] Ignoring source layer z1_r_comb1_0_split
I0705 11:46:05.184412 14303 net.cpp:684] Ignoring source layer recon1
I0705 11:46:05.184417 14303 net.cpp:684] Ignoring source layer bn1_r
I0705 11:46:05.184423 14303 net.cpp:684] Ignoring source layer comb0
I0705 11:46:05.184429 14303 net.cpp:684] Ignoring source layer loss_ladder_6
I0705 11:46:05.184434 14303 net.cpp:684] Ignoring source layer loss_ladder_5
I0705 11:46:05.184439 14303 net.cpp:684] Ignoring source layer loss_ladder_4
I0705 11:46:05.184445 14303 net.cpp:684] Ignoring source layer loss_ladder_3
I0705 11:46:05.184450 14303 net.cpp:684] Ignoring source layer loss_ladder_2
I0705 11:46:05.184455 14303 net.cpp:684] Ignoring source layer loss_ladder_1
I0705 11:46:05.184461 14303 net.cpp:684] Ignoring source layer loss_ladder_0
I0705 11:46:05.184468 14303 net.cpp:684] Ignoring source layer loss_supervised
I0705 11:46:05.344724 14303 solver.cpp:404]     Test net output #0: accuracy = 0.53125
I0705 11:46:05.344761 14303 solver.cpp:404]     Test net output #1: prob = 1.39266 (* 1 = 1.39266 loss)
I0705 11:46:05.439293 14303 solver.cpp:228] Iteration 1500, loss = 5.3594
I0705 11:46:05.439316 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0705 11:46:05.439323 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.103739 (* 0.1 = 0.0103739 loss)
I0705 11:46:05.439329 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 41.3767 (* 0.1 = 4.13767 loss)
I0705 11:46:05.439334 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.88416 (* 0.1 = 0.188416 loss)
I0705 11:46:05.439338 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.908421 (* 0.1 = 0.0908421 loss)
I0705 11:46:05.439342 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.774898 (* 0.1 = 0.0774898 loss)
I0705 11:46:05.439347 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.895368 (* 0.1 = 0.0895368 loss)
I0705 11:46:05.439352 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.834289 (* 0.1 = 0.0834289 loss)
I0705 11:46:05.439355 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.681646 (* 1 = 0.681646 loss)
I0705 11:46:05.439360 14303 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0705 11:46:10.875757 14303 solver.cpp:228] Iteration 1520, loss = 4.94628
I0705 11:46:10.875780 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0705 11:46:10.875788 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.101356 (* 0.1 = 0.0101356 loss)
I0705 11:46:10.875793 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 37.267 (* 0.1 = 3.7267 loss)
I0705 11:46:10.875797 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.2839 (* 0.1 = 0.22839 loss)
I0705 11:46:10.875802 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.910269 (* 0.1 = 0.0910269 loss)
I0705 11:46:10.875805 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.749841 (* 0.1 = 0.0749841 loss)
I0705 11:46:10.875810 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.868 (* 0.1 = 0.0868 loss)
I0705 11:46:10.875814 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.796209 (* 0.1 = 0.0796209 loss)
I0705 11:46:10.875836 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.648618 (* 1 = 0.648618 loss)
I0705 11:46:10.875840 14303 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I0705 11:46:16.311089 14303 solver.cpp:228] Iteration 1540, loss = 4.92448
I0705 11:46:16.311112 14303 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0705 11:46:16.311120 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.0975296 (* 0.1 = 0.00975296 loss)
I0705 11:46:16.311125 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 37.6811 (* 0.1 = 3.76811 loss)
I0705 11:46:16.311128 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.53261 (* 0.1 = 0.253261 loss)
I0705 11:46:16.311132 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.975239 (* 0.1 = 0.097524 loss)
I0705 11:46:16.311136 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.787522 (* 0.1 = 0.0787522 loss)
I0705 11:46:16.311141 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.872202 (* 0.1 = 0.0872202 loss)
I0705 11:46:16.311144 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.822505 (* 0.1 = 0.0822505 loss)
I0705 11:46:16.311148 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.547614 (* 1 = 0.547614 loss)
I0705 11:46:16.311151 14303 sgd_solver.cpp:106] Iteration 1540, lr = 0.01
I0705 11:46:21.745884 14303 solver.cpp:228] Iteration 1560, loss = 6.0706
I0705 11:46:21.745987 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:46:21.745997 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.1051 (* 0.1 = 0.01051 loss)
I0705 11:46:21.746002 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 49.0259 (* 0.1 = 4.90259 loss)
I0705 11:46:21.746006 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.79018 (* 0.1 = 0.179018 loss)
I0705 11:46:21.746011 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.878156 (* 0.1 = 0.0878156 loss)
I0705 11:46:21.746014 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.710153 (* 0.1 = 0.0710153 loss)
I0705 11:46:21.746018 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.838496 (* 0.1 = 0.0838496 loss)
I0705 11:46:21.746022 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.775136 (* 0.1 = 0.0775136 loss)
I0705 11:46:21.746026 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.658291 (* 1 = 0.658291 loss)
I0705 11:46:21.746029 14303 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I0705 11:46:27.183135 14303 solver.cpp:228] Iteration 1580, loss = 4.81102
I0705 11:46:27.183168 14303 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0705 11:46:27.183176 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.0994628 (* 0.1 = 0.00994628 loss)
I0705 11:46:27.183181 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 36.7814 (* 0.1 = 3.67814 loss)
I0705 11:46:27.183184 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.29685 (* 0.1 = 0.229685 loss)
I0705 11:46:27.183188 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.918018 (* 0.1 = 0.0918018 loss)
I0705 11:46:27.183192 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.765866 (* 0.1 = 0.0765866 loss)
I0705 11:46:27.183197 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.877617 (* 0.1 = 0.0877617 loss)
I0705 11:46:27.183199 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.817178 (* 0.1 = 0.0817178 loss)
I0705 11:46:27.183203 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.555375 (* 1 = 0.555375 loss)
I0705 11:46:27.183207 14303 sgd_solver.cpp:106] Iteration 1580, lr = 0.01
I0705 11:46:32.524371 14303 solver.cpp:337] Iteration 1600, Testing net (#0)
I0705 11:46:32.524389 14303 net.cpp:684] Ignoring source layer data_data_0_split
I0705 11:46:32.524392 14303 net.cpp:684] Ignoring source layer noisy_data
I0705 11:46:32.524394 14303 net.cpp:684] Ignoring source layer noisy_data_noisy_data_0_split
I0705 11:46:32.524396 14303 net.cpp:684] Ignoring source layer z1_bn1_0_split
I0705 11:46:32.524400 14303 net.cpp:684] Ignoring source layer bn1_n
I0705 11:46:32.524401 14303 net.cpp:684] Ignoring source layer noisy_z1_n
I0705 11:46:32.524404 14303 net.cpp:684] Ignoring source layer z1_n_noisy_z1_n_0_split
I0705 11:46:32.524405 14303 net.cpp:684] Ignoring source layer scale1_n
I0705 11:46:32.524407 14303 net.cpp:684] Ignoring source layer relu1_n
I0705 11:46:32.524410 14303 net.cpp:684] Ignoring source layer pool1_n
I0705 11:46:32.524411 14303 net.cpp:684] Ignoring source layer z2_bn2_0_split
I0705 11:46:32.524415 14303 net.cpp:684] Ignoring source layer bn2_n
I0705 11:46:32.524416 14303 net.cpp:684] Ignoring source layer noisy_z2_n
I0705 11:46:32.524418 14303 net.cpp:684] Ignoring source layer z2_n_noisy_z2_n_0_split
I0705 11:46:32.524420 14303 net.cpp:684] Ignoring source layer scale2_n
I0705 11:46:32.524421 14303 net.cpp:684] Ignoring source layer relu2_n
I0705 11:46:32.524423 14303 net.cpp:684] Ignoring source layer pool2_n
I0705 11:46:32.524426 14303 net.cpp:684] Ignoring source layer z3_bn3_0_split
I0705 11:46:32.524430 14303 net.cpp:684] Ignoring source layer bn3_n
I0705 11:46:32.524430 14303 net.cpp:684] Ignoring source layer noisy_z3_n
I0705 11:46:32.524432 14303 net.cpp:684] Ignoring source layer z3_n_noisy_z3_n_0_split
I0705 11:46:32.524435 14303 net.cpp:684] Ignoring source layer scale3_n
I0705 11:46:32.524436 14303 net.cpp:684] Ignoring source layer relu3_n
I0705 11:46:32.524466 14303 net.cpp:684] Ignoring source layer pool3_n
I0705 11:46:32.524469 14303 net.cpp:684] Ignoring source layer z4_bn4_0_split
I0705 11:46:32.524471 14303 net.cpp:684] Ignoring source layer bn4_n
I0705 11:46:32.524473 14303 net.cpp:684] Ignoring source layer noisy_z4_n
I0705 11:46:32.524476 14303 net.cpp:684] Ignoring source layer z4_n_noisy_z4_n_0_split
I0705 11:46:32.524477 14303 net.cpp:684] Ignoring source layer scale4_n
I0705 11:46:32.524479 14303 net.cpp:684] Ignoring source layer relu4_n
I0705 11:46:32.524482 14303 net.cpp:684] Ignoring source layer pool4_n
I0705 11:46:32.524483 14303 net.cpp:684] Ignoring source layer z5_bn5_0_split
I0705 11:46:32.524487 14303 net.cpp:684] Ignoring source layer bn5_n
I0705 11:46:32.524488 14303 net.cpp:684] Ignoring source layer noisy_z5_n
I0705 11:46:32.524490 14303 net.cpp:684] Ignoring source layer z5_n_noisy_z5_n_0_split
I0705 11:46:32.524492 14303 net.cpp:684] Ignoring source layer scale5_n
I0705 11:46:32.524493 14303 net.cpp:684] Ignoring source layer relu5_n
I0705 11:46:32.524495 14303 net.cpp:684] Ignoring source layer pool5_n
I0705 11:46:32.524498 14303 net.cpp:684] Ignoring source layer z6_bn6_0_split
I0705 11:46:32.524502 14303 net.cpp:684] Ignoring source layer bn6_n
I0705 11:46:32.524502 14303 net.cpp:684] Ignoring source layer noisy_z6_n
I0705 11:46:32.524504 14303 net.cpp:684] Ignoring source layer z6_n_noisy_z6_n_0_split
I0705 11:46:32.524507 14303 net.cpp:684] Ignoring source layer scale6_n
I0705 11:46:32.524508 14303 net.cpp:684] Ignoring source layer relu6_n
I0705 11:46:32.524510 14303 net.cpp:684] Ignoring source layer u6
I0705 11:46:32.524513 14303 net.cpp:684] Ignoring source layer comb6
I0705 11:46:32.524514 14303 net.cpp:684] Ignoring source layer z6_r_comb6_0_split
I0705 11:46:32.524515 14303 net.cpp:684] Ignoring source layer recon6
I0705 11:46:32.524518 14303 net.cpp:684] Ignoring source layer bn6_r
I0705 11:46:32.524519 14303 net.cpp:684] Ignoring source layer upsample5
I0705 11:46:32.524521 14303 net.cpp:684] Ignoring source layer comb5
I0705 11:46:32.524523 14303 net.cpp:684] Ignoring source layer z5_r_comb5_0_split
I0705 11:46:32.524524 14303 net.cpp:684] Ignoring source layer recon5
I0705 11:46:32.524526 14303 net.cpp:684] Ignoring source layer bn5_r
I0705 11:46:32.524528 14303 net.cpp:684] Ignoring source layer upsample4
I0705 11:46:32.524530 14303 net.cpp:684] Ignoring source layer comb4
I0705 11:46:32.524533 14303 net.cpp:684] Ignoring source layer z4_r_comb4_0_split
I0705 11:46:32.524533 14303 net.cpp:684] Ignoring source layer recon4
I0705 11:46:32.524535 14303 net.cpp:684] Ignoring source layer bn4_r
I0705 11:46:32.524538 14303 net.cpp:684] Ignoring source layer upsample3
I0705 11:46:32.524539 14303 net.cpp:684] Ignoring source layer comb3
I0705 11:46:32.524541 14303 net.cpp:684] Ignoring source layer z3_r_comb3_0_split
I0705 11:46:32.524543 14303 net.cpp:684] Ignoring source layer recon3
I0705 11:46:32.524544 14303 net.cpp:684] Ignoring source layer bn3_r
I0705 11:46:32.524547 14303 net.cpp:684] Ignoring source layer upsample2
I0705 11:46:32.524549 14303 net.cpp:684] Ignoring source layer comb2
I0705 11:46:32.524551 14303 net.cpp:684] Ignoring source layer z2_r_comb2_0_split
I0705 11:46:32.524554 14303 net.cpp:684] Ignoring source layer recon2
I0705 11:46:32.524555 14303 net.cpp:684] Ignoring source layer bn2_r
I0705 11:46:32.524557 14303 net.cpp:684] Ignoring source layer upsample1
I0705 11:46:32.524559 14303 net.cpp:684] Ignoring source layer comb1
I0705 11:46:32.524560 14303 net.cpp:684] Ignoring source layer z1_r_comb1_0_split
I0705 11:46:32.524562 14303 net.cpp:684] Ignoring source layer recon1
I0705 11:46:32.524564 14303 net.cpp:684] Ignoring source layer bn1_r
I0705 11:46:32.524566 14303 net.cpp:684] Ignoring source layer comb0
I0705 11:46:32.524567 14303 net.cpp:684] Ignoring source layer loss_ladder_6
I0705 11:46:32.524569 14303 net.cpp:684] Ignoring source layer loss_ladder_5
I0705 11:46:32.524571 14303 net.cpp:684] Ignoring source layer loss_ladder_4
I0705 11:46:32.524574 14303 net.cpp:684] Ignoring source layer loss_ladder_3
I0705 11:46:32.524580 14303 net.cpp:684] Ignoring source layer loss_ladder_2
I0705 11:46:32.524581 14303 net.cpp:684] Ignoring source layer loss_ladder_1
I0705 11:46:32.524582 14303 net.cpp:684] Ignoring source layer loss_ladder_0
I0705 11:46:32.524585 14303 net.cpp:684] Ignoring source layer loss_supervised
I0705 11:46:32.684069 14303 solver.cpp:404]     Test net output #0: accuracy = 0.5
I0705 11:46:32.684094 14303 solver.cpp:404]     Test net output #1: prob = 1.06078 (* 1 = 1.06078 loss)
I0705 11:46:32.777711 14303 solver.cpp:228] Iteration 1600, loss = 5.61286
I0705 11:46:32.777729 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:46:32.777736 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.100124 (* 0.1 = 0.0100124 loss)
I0705 11:46:32.777741 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 44.5995 (* 0.1 = 4.45995 loss)
I0705 11:46:32.777745 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.15254 (* 0.1 = 0.215254 loss)
I0705 11:46:32.777750 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.924879 (* 0.1 = 0.0924879 loss)
I0705 11:46:32.777752 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.781333 (* 0.1 = 0.0781333 loss)
I0705 11:46:32.777757 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.881339 (* 0.1 = 0.0881339 loss)
I0705 11:46:32.777761 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.817671 (* 0.1 = 0.0817671 loss)
I0705 11:46:32.777765 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.587115 (* 1 = 0.587115 loss)
I0705 11:46:32.777770 14303 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0705 11:46:38.213143 14303 solver.cpp:228] Iteration 1620, loss = 5.3385
I0705 11:46:38.213166 14303 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0705 11:46:38.213173 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.10013 (* 0.1 = 0.010013 loss)
I0705 11:46:38.213177 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 42.0082 (* 0.1 = 4.20082 loss)
I0705 11:46:38.213182 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.54288 (* 0.1 = 0.254288 loss)
I0705 11:46:38.213186 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.978861 (* 0.1 = 0.0978861 loss)
I0705 11:46:38.213191 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.768213 (* 0.1 = 0.0768213 loss)
I0705 11:46:38.213196 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.870211 (* 0.1 = 0.0870211 loss)
I0705 11:46:38.213199 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.813821 (* 0.1 = 0.0813821 loss)
I0705 11:46:38.213203 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.530268 (* 1 = 0.530268 loss)
I0705 11:46:38.213207 14303 sgd_solver.cpp:106] Iteration 1620, lr = 0.01
I0705 11:46:43.650056 14303 solver.cpp:228] Iteration 1640, loss = 4.93543
I0705 11:46:43.650080 14303 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0705 11:46:43.650089 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.103372 (* 0.1 = 0.0103372 loss)
I0705 11:46:43.650092 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 38.0371 (* 0.1 = 3.80371 loss)
I0705 11:46:43.650096 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.81485 (* 0.1 = 0.181485 loss)
I0705 11:46:43.650100 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.877101 (* 0.1 = 0.0877101 loss)
I0705 11:46:43.650104 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.73776 (* 0.1 = 0.073776 loss)
I0705 11:46:43.650110 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.869414 (* 0.1 = 0.0869414 loss)
I0705 11:46:43.650112 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.799099 (* 0.1 = 0.0799099 loss)
I0705 11:46:43.650116 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.611562 (* 1 = 0.611562 loss)
I0705 11:46:43.650120 14303 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I0705 11:46:49.086360 14303 solver.cpp:228] Iteration 1660, loss = 4.80169
I0705 11:46:49.086403 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0705 11:46:49.086412 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.102179 (* 0.1 = 0.0102179 loss)
I0705 11:46:49.086417 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 35.0004 (* 0.1 = 3.50004 loss)
I0705 11:46:49.086421 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.22332 (* 0.1 = 0.222332 loss)
I0705 11:46:49.086426 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.897152 (* 0.1 = 0.0897152 loss)
I0705 11:46:49.086428 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.731064 (* 0.1 = 0.0731064 loss)
I0705 11:46:49.086432 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.855798 (* 0.1 = 0.0855798 loss)
I0705 11:46:49.086436 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.786527 (* 0.1 = 0.0786527 loss)
I0705 11:46:49.086441 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.742046 (* 1 = 0.742046 loss)
I0705 11:46:49.086443 14303 sgd_solver.cpp:106] Iteration 1660, lr = 0.01
I0705 11:46:54.521612 14303 solver.cpp:228] Iteration 1680, loss = 4.95041
I0705 11:46:54.521745 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0705 11:46:54.521756 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.0978675 (* 0.1 = 0.00978675 loss)
I0705 11:46:54.521761 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 36.085 (* 0.1 = 3.6085 loss)
I0705 11:46:54.521765 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.71445 (* 0.1 = 0.271445 loss)
I0705 11:46:54.521770 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.976403 (* 0.1 = 0.0976403 loss)
I0705 11:46:54.521773 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.749043 (* 0.1 = 0.0749043 loss)
I0705 11:46:54.521777 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.850021 (* 0.1 = 0.0850021 loss)
I0705 11:46:54.521781 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.797461 (* 0.1 = 0.0797461 loss)
I0705 11:46:54.521785 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.723382 (* 1 = 0.723382 loss)
I0705 11:46:54.521790 14303 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I0705 11:46:59.860994 14303 solver.cpp:337] Iteration 1700, Testing net (#0)
I0705 11:46:59.861012 14303 net.cpp:684] Ignoring source layer data_data_0_split
I0705 11:46:59.861016 14303 net.cpp:684] Ignoring source layer noisy_data
I0705 11:46:59.861017 14303 net.cpp:684] Ignoring source layer noisy_data_noisy_data_0_split
I0705 11:46:59.861019 14303 net.cpp:684] Ignoring source layer z1_bn1_0_split
I0705 11:46:59.861022 14303 net.cpp:684] Ignoring source layer bn1_n
I0705 11:46:59.861024 14303 net.cpp:684] Ignoring source layer noisy_z1_n
I0705 11:46:59.861027 14303 net.cpp:684] Ignoring source layer z1_n_noisy_z1_n_0_split
I0705 11:46:59.861027 14303 net.cpp:684] Ignoring source layer scale1_n
I0705 11:46:59.861029 14303 net.cpp:684] Ignoring source layer relu1_n
I0705 11:46:59.861032 14303 net.cpp:684] Ignoring source layer pool1_n
I0705 11:46:59.861034 14303 net.cpp:684] Ignoring source layer z2_bn2_0_split
I0705 11:46:59.861037 14303 net.cpp:684] Ignoring source layer bn2_n
I0705 11:46:59.861040 14303 net.cpp:684] Ignoring source layer noisy_z2_n
I0705 11:46:59.861042 14303 net.cpp:684] Ignoring source layer z2_n_noisy_z2_n_0_split
I0705 11:46:59.861043 14303 net.cpp:684] Ignoring source layer scale2_n
I0705 11:46:59.861045 14303 net.cpp:684] Ignoring source layer relu2_n
I0705 11:46:59.861047 14303 net.cpp:684] Ignoring source layer pool2_n
I0705 11:46:59.861050 14303 net.cpp:684] Ignoring source layer z3_bn3_0_split
I0705 11:46:59.861053 14303 net.cpp:684] Ignoring source layer bn3_n
I0705 11:46:59.861054 14303 net.cpp:684] Ignoring source layer noisy_z3_n
I0705 11:46:59.861057 14303 net.cpp:684] Ignoring source layer z3_n_noisy_z3_n_0_split
I0705 11:46:59.861058 14303 net.cpp:684] Ignoring source layer scale3_n
I0705 11:46:59.861060 14303 net.cpp:684] Ignoring source layer relu3_n
I0705 11:46:59.861063 14303 net.cpp:684] Ignoring source layer pool3_n
I0705 11:46:59.861064 14303 net.cpp:684] Ignoring source layer z4_bn4_0_split
I0705 11:46:59.861068 14303 net.cpp:684] Ignoring source layer bn4_n
I0705 11:46:59.861069 14303 net.cpp:684] Ignoring source layer noisy_z4_n
I0705 11:46:59.861071 14303 net.cpp:684] Ignoring source layer z4_n_noisy_z4_n_0_split
I0705 11:46:59.861073 14303 net.cpp:684] Ignoring source layer scale4_n
I0705 11:46:59.861074 14303 net.cpp:684] Ignoring source layer relu4_n
I0705 11:46:59.861076 14303 net.cpp:684] Ignoring source layer pool4_n
I0705 11:46:59.861079 14303 net.cpp:684] Ignoring source layer z5_bn5_0_split
I0705 11:46:59.861083 14303 net.cpp:684] Ignoring source layer bn5_n
I0705 11:46:59.861083 14303 net.cpp:684] Ignoring source layer noisy_z5_n
I0705 11:46:59.861085 14303 net.cpp:684] Ignoring source layer z5_n_noisy_z5_n_0_split
I0705 11:46:59.861088 14303 net.cpp:684] Ignoring source layer scale5_n
I0705 11:46:59.861088 14303 net.cpp:684] Ignoring source layer relu5_n
I0705 11:46:59.861101 14303 net.cpp:684] Ignoring source layer pool5_n
I0705 11:46:59.861104 14303 net.cpp:684] Ignoring source layer z6_bn6_0_split
I0705 11:46:59.861124 14303 net.cpp:684] Ignoring source layer bn6_n
I0705 11:46:59.861125 14303 net.cpp:684] Ignoring source layer noisy_z6_n
I0705 11:46:59.861127 14303 net.cpp:684] Ignoring source layer z6_n_noisy_z6_n_0_split
I0705 11:46:59.861129 14303 net.cpp:684] Ignoring source layer scale6_n
I0705 11:46:59.861131 14303 net.cpp:684] Ignoring source layer relu6_n
I0705 11:46:59.861134 14303 net.cpp:684] Ignoring source layer u6
I0705 11:46:59.861135 14303 net.cpp:684] Ignoring source layer comb6
I0705 11:46:59.861137 14303 net.cpp:684] Ignoring source layer z6_r_comb6_0_split
I0705 11:46:59.861140 14303 net.cpp:684] Ignoring source layer recon6
I0705 11:46:59.861141 14303 net.cpp:684] Ignoring source layer bn6_r
I0705 11:46:59.861142 14303 net.cpp:684] Ignoring source layer upsample5
I0705 11:46:59.861145 14303 net.cpp:684] Ignoring source layer comb5
I0705 11:46:59.861146 14303 net.cpp:684] Ignoring source layer z5_r_comb5_0_split
I0705 11:46:59.861148 14303 net.cpp:684] Ignoring source layer recon5
I0705 11:46:59.861150 14303 net.cpp:684] Ignoring source layer bn5_r
I0705 11:46:59.861152 14303 net.cpp:684] Ignoring source layer upsample4
I0705 11:46:59.861155 14303 net.cpp:684] Ignoring source layer comb4
I0705 11:46:59.861156 14303 net.cpp:684] Ignoring source layer z4_r_comb4_0_split
I0705 11:46:59.861158 14303 net.cpp:684] Ignoring source layer recon4
I0705 11:46:59.861160 14303 net.cpp:684] Ignoring source layer bn4_r
I0705 11:46:59.861161 14303 net.cpp:684] Ignoring source layer upsample3
I0705 11:46:59.861163 14303 net.cpp:684] Ignoring source layer comb3
I0705 11:46:59.861166 14303 net.cpp:684] Ignoring source layer z3_r_comb3_0_split
I0705 11:46:59.861167 14303 net.cpp:684] Ignoring source layer recon3
I0705 11:46:59.861169 14303 net.cpp:684] Ignoring source layer bn3_r
I0705 11:46:59.861171 14303 net.cpp:684] Ignoring source layer upsample2
I0705 11:46:59.861173 14303 net.cpp:684] Ignoring source layer comb2
I0705 11:46:59.861174 14303 net.cpp:684] Ignoring source layer z2_r_comb2_0_split
I0705 11:46:59.861176 14303 net.cpp:684] Ignoring source layer recon2
I0705 11:46:59.861178 14303 net.cpp:684] Ignoring source layer bn2_r
I0705 11:46:59.861181 14303 net.cpp:684] Ignoring source layer upsample1
I0705 11:46:59.861182 14303 net.cpp:684] Ignoring source layer comb1
I0705 11:46:59.861184 14303 net.cpp:684] Ignoring source layer z1_r_comb1_0_split
I0705 11:46:59.861186 14303 net.cpp:684] Ignoring source layer recon1
I0705 11:46:59.861187 14303 net.cpp:684] Ignoring source layer bn1_r
I0705 11:46:59.861189 14303 net.cpp:684] Ignoring source layer comb0
I0705 11:46:59.861191 14303 net.cpp:684] Ignoring source layer loss_ladder_6
I0705 11:46:59.861193 14303 net.cpp:684] Ignoring source layer loss_ladder_5
I0705 11:46:59.861196 14303 net.cpp:684] Ignoring source layer loss_ladder_4
I0705 11:46:59.861196 14303 net.cpp:684] Ignoring source layer loss_ladder_3
I0705 11:46:59.861198 14303 net.cpp:684] Ignoring source layer loss_ladder_2
I0705 11:46:59.861201 14303 net.cpp:684] Ignoring source layer loss_ladder_1
I0705 11:46:59.861202 14303 net.cpp:684] Ignoring source layer loss_ladder_0
I0705 11:46:59.861204 14303 net.cpp:684] Ignoring source layer loss_supervised
I0705 11:47:00.020910 14303 solver.cpp:404]     Test net output #0: accuracy = 0.578125
I0705 11:47:00.020946 14303 solver.cpp:404]     Test net output #1: prob = 1.02941 (* 1 = 1.02941 loss)
I0705 11:47:00.114596 14303 solver.cpp:228] Iteration 1700, loss = 5.05003
I0705 11:47:00.114616 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:47:00.114624 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.100727 (* 0.1 = 0.0100727 loss)
I0705 11:47:00.114627 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 38.9493 (* 0.1 = 3.89493 loss)
I0705 11:47:00.114632 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.27406 (* 0.1 = 0.227406 loss)
I0705 11:47:00.114635 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.885643 (* 0.1 = 0.0885644 loss)
I0705 11:47:00.114639 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.72723 (* 0.1 = 0.072723 loss)
I0705 11:47:00.114660 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.854483 (* 0.1 = 0.0854483 loss)
I0705 11:47:00.114665 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.780051 (* 0.1 = 0.0780051 loss)
I0705 11:47:00.114668 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.592881 (* 1 = 0.592881 loss)
I0705 11:47:00.114672 14303 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0705 11:47:05.549275 14303 solver.cpp:228] Iteration 1720, loss = 5.39993
I0705 11:47:05.549299 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0705 11:47:05.549306 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.101002 (* 0.1 = 0.0101002 loss)
I0705 11:47:05.549310 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 41.499 (* 0.1 = 4.1499 loss)
I0705 11:47:05.549315 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.42882 (* 0.1 = 0.242882 loss)
I0705 11:47:05.549319 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.905793 (* 0.1 = 0.0905793 loss)
I0705 11:47:05.549322 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.724151 (* 0.1 = 0.0724151 loss)
I0705 11:47:05.549326 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.849742 (* 0.1 = 0.0849742 loss)
I0705 11:47:05.549330 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.793353 (* 0.1 = 0.0793353 loss)
I0705 11:47:05.549334 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.66974 (* 1 = 0.66974 loss)
I0705 11:47:05.549337 14303 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I0705 11:47:10.984113 14303 solver.cpp:228] Iteration 1740, loss = 4.99837
I0705 11:47:10.984136 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:47:10.984143 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.101694 (* 0.1 = 0.0101694 loss)
I0705 11:47:10.984148 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 38.295 (* 0.1 = 3.8295 loss)
I0705 11:47:10.984153 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.40826 (* 0.1 = 0.240826 loss)
I0705 11:47:10.984156 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.896378 (* 0.1 = 0.0896378 loss)
I0705 11:47:10.984159 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.756482 (* 0.1 = 0.0756482 loss)
I0705 11:47:10.984165 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.891348 (* 0.1 = 0.0891348 loss)
I0705 11:47:10.984169 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.805524 (* 0.1 = 0.0805524 loss)
I0705 11:47:10.984172 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.582907 (* 1 = 0.582907 loss)
I0705 11:47:10.984176 14303 sgd_solver.cpp:106] Iteration 1740, lr = 0.01
I0705 11:47:16.418465 14303 solver.cpp:228] Iteration 1760, loss = 5.83194
I0705 11:47:16.418488 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:47:16.418496 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.102549 (* 0.1 = 0.0102549 loss)
I0705 11:47:16.418500 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 46.6607 (* 0.1 = 4.66607 loss)
I0705 11:47:16.418505 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.79168 (* 0.1 = 0.179168 loss)
I0705 11:47:16.418509 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.807355 (* 0.1 = 0.0807355 loss)
I0705 11:47:16.418512 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.729709 (* 0.1 = 0.0729709 loss)
I0705 11:47:16.418517 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.876814 (* 0.1 = 0.0876814 loss)
I0705 11:47:16.418520 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.806668 (* 0.1 = 0.0806668 loss)
I0705 11:47:16.418524 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.654393 (* 1 = 0.654393 loss)
I0705 11:47:16.418529 14303 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I0705 11:47:21.853323 14303 solver.cpp:228] Iteration 1780, loss = 5.13517
I0705 11:47:21.853366 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:47:21.853374 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.0982396 (* 0.1 = 0.00982396 loss)
I0705 11:47:21.853379 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 39.1327 (* 0.1 = 3.91327 loss)
I0705 11:47:21.853384 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.54661 (* 0.1 = 0.254661 loss)
I0705 11:47:21.853387 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.897727 (* 0.1 = 0.0897728 loss)
I0705 11:47:21.853391 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.717828 (* 0.1 = 0.0717828 loss)
I0705 11:47:21.853395 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.83539 (* 0.1 = 0.083539 loss)
I0705 11:47:21.853399 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.78291 (* 0.1 = 0.078291 loss)
I0705 11:47:21.853404 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.63403 (* 1 = 0.63403 loss)
I0705 11:47:21.853406 14303 sgd_solver.cpp:106] Iteration 1780, lr = 0.01
I0705 11:47:27.192090 14303 solver.cpp:337] Iteration 1800, Testing net (#0)
I0705 11:47:27.192219 14303 net.cpp:684] Ignoring source layer data_data_0_split
I0705 11:47:27.192224 14303 net.cpp:684] Ignoring source layer noisy_data
I0705 11:47:27.192227 14303 net.cpp:684] Ignoring source layer noisy_data_noisy_data_0_split
I0705 11:47:27.192229 14303 net.cpp:684] Ignoring source layer z1_bn1_0_split
I0705 11:47:27.192234 14303 net.cpp:684] Ignoring source layer bn1_n
I0705 11:47:27.192234 14303 net.cpp:684] Ignoring source layer noisy_z1_n
I0705 11:47:27.192236 14303 net.cpp:684] Ignoring source layer z1_n_noisy_z1_n_0_split
I0705 11:47:27.192239 14303 net.cpp:684] Ignoring source layer scale1_n
I0705 11:47:27.192240 14303 net.cpp:684] Ignoring source layer relu1_n
I0705 11:47:27.192242 14303 net.cpp:684] Ignoring source layer pool1_n
I0705 11:47:27.192245 14303 net.cpp:684] Ignoring source layer z2_bn2_0_split
I0705 11:47:27.192248 14303 net.cpp:684] Ignoring source layer bn2_n
I0705 11:47:27.192250 14303 net.cpp:684] Ignoring source layer noisy_z2_n
I0705 11:47:27.192252 14303 net.cpp:684] Ignoring source layer z2_n_noisy_z2_n_0_split
I0705 11:47:27.192253 14303 net.cpp:684] Ignoring source layer scale2_n
I0705 11:47:27.192255 14303 net.cpp:684] Ignoring source layer relu2_n
I0705 11:47:27.192257 14303 net.cpp:684] Ignoring source layer pool2_n
I0705 11:47:27.192260 14303 net.cpp:684] Ignoring source layer z3_bn3_0_split
I0705 11:47:27.192263 14303 net.cpp:684] Ignoring source layer bn3_n
I0705 11:47:27.192265 14303 net.cpp:684] Ignoring source layer noisy_z3_n
I0705 11:47:27.192266 14303 net.cpp:684] Ignoring source layer z3_n_noisy_z3_n_0_split
I0705 11:47:27.192268 14303 net.cpp:684] Ignoring source layer scale3_n
I0705 11:47:27.192270 14303 net.cpp:684] Ignoring source layer relu3_n
I0705 11:47:27.192272 14303 net.cpp:684] Ignoring source layer pool3_n
I0705 11:47:27.192276 14303 net.cpp:684] Ignoring source layer z4_bn4_0_split
I0705 11:47:27.192277 14303 net.cpp:684] Ignoring source layer bn4_n
I0705 11:47:27.192279 14303 net.cpp:684] Ignoring source layer noisy_z4_n
I0705 11:47:27.192281 14303 net.cpp:684] Ignoring source layer z4_n_noisy_z4_n_0_split
I0705 11:47:27.192283 14303 net.cpp:684] Ignoring source layer scale4_n
I0705 11:47:27.192286 14303 net.cpp:684] Ignoring source layer relu4_n
I0705 11:47:27.192287 14303 net.cpp:684] Ignoring source layer pool4_n
I0705 11:47:27.192291 14303 net.cpp:684] Ignoring source layer z5_bn5_0_split
I0705 11:47:27.192292 14303 net.cpp:684] Ignoring source layer bn5_n
I0705 11:47:27.192294 14303 net.cpp:684] Ignoring source layer noisy_z5_n
I0705 11:47:27.192296 14303 net.cpp:684] Ignoring source layer z5_n_noisy_z5_n_0_split
I0705 11:47:27.192297 14303 net.cpp:684] Ignoring source layer scale5_n
I0705 11:47:27.192299 14303 net.cpp:684] Ignoring source layer relu5_n
I0705 11:47:27.192301 14303 net.cpp:684] Ignoring source layer pool5_n
I0705 11:47:27.192304 14303 net.cpp:684] Ignoring source layer z6_bn6_0_split
I0705 11:47:27.192306 14303 net.cpp:684] Ignoring source layer bn6_n
I0705 11:47:27.192308 14303 net.cpp:684] Ignoring source layer noisy_z6_n
I0705 11:47:27.192311 14303 net.cpp:684] Ignoring source layer z6_n_noisy_z6_n_0_split
I0705 11:47:27.192312 14303 net.cpp:684] Ignoring source layer scale6_n
I0705 11:47:27.192314 14303 net.cpp:684] Ignoring source layer relu6_n
I0705 11:47:27.192317 14303 net.cpp:684] Ignoring source layer u6
I0705 11:47:27.192318 14303 net.cpp:684] Ignoring source layer comb6
I0705 11:47:27.192319 14303 net.cpp:684] Ignoring source layer z6_r_comb6_0_split
I0705 11:47:27.192322 14303 net.cpp:684] Ignoring source layer recon6
I0705 11:47:27.192323 14303 net.cpp:684] Ignoring source layer bn6_r
I0705 11:47:27.192325 14303 net.cpp:684] Ignoring source layer upsample5
I0705 11:47:27.192327 14303 net.cpp:684] Ignoring source layer comb5
I0705 11:47:27.192329 14303 net.cpp:684] Ignoring source layer z5_r_comb5_0_split
I0705 11:47:27.192330 14303 net.cpp:684] Ignoring source layer recon5
I0705 11:47:27.192332 14303 net.cpp:684] Ignoring source layer bn5_r
I0705 11:47:27.192334 14303 net.cpp:684] Ignoring source layer upsample4
I0705 11:47:27.192343 14303 net.cpp:684] Ignoring source layer comb4
I0705 11:47:27.192345 14303 net.cpp:684] Ignoring source layer z4_r_comb4_0_split
I0705 11:47:27.192348 14303 net.cpp:684] Ignoring source layer recon4
I0705 11:47:27.192349 14303 net.cpp:684] Ignoring source layer bn4_r
I0705 11:47:27.192351 14303 net.cpp:684] Ignoring source layer upsample3
I0705 11:47:27.192353 14303 net.cpp:684] Ignoring source layer comb3
I0705 11:47:27.192354 14303 net.cpp:684] Ignoring source layer z3_r_comb3_0_split
I0705 11:47:27.192356 14303 net.cpp:684] Ignoring source layer recon3
I0705 11:47:27.192358 14303 net.cpp:684] Ignoring source layer bn3_r
I0705 11:47:27.192360 14303 net.cpp:684] Ignoring source layer upsample2
I0705 11:47:27.192363 14303 net.cpp:684] Ignoring source layer comb2
I0705 11:47:27.192363 14303 net.cpp:684] Ignoring source layer z2_r_comb2_0_split
I0705 11:47:27.192365 14303 net.cpp:684] Ignoring source layer recon2
I0705 11:47:27.192368 14303 net.cpp:684] Ignoring source layer bn2_r
I0705 11:47:27.192369 14303 net.cpp:684] Ignoring source layer upsample1
I0705 11:47:27.192371 14303 net.cpp:684] Ignoring source layer comb1
I0705 11:47:27.192373 14303 net.cpp:684] Ignoring source layer z1_r_comb1_0_split
I0705 11:47:27.192374 14303 net.cpp:684] Ignoring source layer recon1
I0705 11:47:27.192376 14303 net.cpp:684] Ignoring source layer bn1_r
I0705 11:47:27.192378 14303 net.cpp:684] Ignoring source layer comb0
I0705 11:47:27.192380 14303 net.cpp:684] Ignoring source layer loss_ladder_6
I0705 11:47:27.192381 14303 net.cpp:684] Ignoring source layer loss_ladder_5
I0705 11:47:27.192384 14303 net.cpp:684] Ignoring source layer loss_ladder_4
I0705 11:47:27.192385 14303 net.cpp:684] Ignoring source layer loss_ladder_3
I0705 11:47:27.192387 14303 net.cpp:684] Ignoring source layer loss_ladder_2
I0705 11:47:27.192389 14303 net.cpp:684] Ignoring source layer loss_ladder_1
I0705 11:47:27.192390 14303 net.cpp:684] Ignoring source layer loss_ladder_0
I0705 11:47:27.192394 14303 net.cpp:684] Ignoring source layer loss_supervised
I0705 11:47:27.351984 14303 solver.cpp:404]     Test net output #0: accuracy = 0.523438
I0705 11:47:27.352020 14303 solver.cpp:404]     Test net output #1: prob = 1.66415 (* 1 = 1.66415 loss)
I0705 11:47:27.445605 14303 solver.cpp:228] Iteration 1800, loss = 5.22513
I0705 11:47:27.445622 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0705 11:47:27.445629 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.102475 (* 0.1 = 0.0102475 loss)
I0705 11:47:27.445633 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 40.3559 (* 0.1 = 4.03559 loss)
I0705 11:47:27.445638 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.97492 (* 0.1 = 0.197492 loss)
I0705 11:47:27.445641 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.824341 (* 0.1 = 0.0824341 loss)
I0705 11:47:27.445646 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.718566 (* 0.1 = 0.0718566 loss)
I0705 11:47:27.445650 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.865893 (* 0.1 = 0.0865893 loss)
I0705 11:47:27.445654 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.791845 (* 0.1 = 0.0791845 loss)
I0705 11:47:27.445657 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.66174 (* 1 = 0.66174 loss)
I0705 11:47:27.445662 14303 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0705 11:47:32.887953 14303 solver.cpp:228] Iteration 1820, loss = 4.96491
I0705 11:47:32.887976 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0705 11:47:32.887984 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.0959112 (* 0.1 = 0.00959112 loss)
I0705 11:47:32.887987 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 36.4805 (* 0.1 = 3.64805 loss)
I0705 11:47:32.887992 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.66863 (* 0.1 = 0.266863 loss)
I0705 11:47:32.887996 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.960943 (* 0.1 = 0.0960943 loss)
I0705 11:47:32.888000 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.717643 (* 0.1 = 0.0717643 loss)
I0705 11:47:32.888020 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.820369 (* 0.1 = 0.0820369 loss)
I0705 11:47:32.888025 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.775124 (* 0.1 = 0.0775124 loss)
I0705 11:47:32.888028 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.712995 (* 1 = 0.712995 loss)
I0705 11:47:32.888031 14303 sgd_solver.cpp:106] Iteration 1820, lr = 0.01
I0705 11:47:38.343884 14303 solver.cpp:228] Iteration 1840, loss = 5.72816
I0705 11:47:38.343909 14303 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0705 11:47:38.343915 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.103011 (* 0.1 = 0.0103011 loss)
I0705 11:47:38.343920 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 45.8661 (* 0.1 = 4.58661 loss)
I0705 11:47:38.343924 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.93639 (* 0.1 = 0.193639 loss)
I0705 11:47:38.343929 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.838005 (* 0.1 = 0.0838005 loss)
I0705 11:47:38.343931 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.713287 (* 0.1 = 0.0713287 loss)
I0705 11:47:38.343936 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.850322 (* 0.1 = 0.0850322 loss)
I0705 11:47:38.343940 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.795665 (* 0.1 = 0.0795665 loss)
I0705 11:47:38.343943 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.617875 (* 1 = 0.617875 loss)
I0705 11:47:38.343947 14303 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I0705 11:47:43.779994 14303 solver.cpp:228] Iteration 1860, loss = 8.02131
I0705 11:47:43.780016 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0705 11:47:43.780024 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.10371 (* 0.1 = 0.010371 loss)
I0705 11:47:43.780027 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 69.4584 (* 0.1 = 6.94584 loss)
I0705 11:47:43.780032 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.21858 (* 0.1 = 0.121858 loss)
I0705 11:47:43.780036 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.696257 (* 0.1 = 0.0696257 loss)
I0705 11:47:43.780040 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.641335 (* 0.1 = 0.0641335 loss)
I0705 11:47:43.780043 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.799774 (* 0.1 = 0.0799774 loss)
I0705 11:47:43.780047 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.761342 (* 0.1 = 0.0761342 loss)
I0705 11:47:43.780050 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.653373 (* 1 = 0.653373 loss)
I0705 11:47:43.780055 14303 sgd_solver.cpp:106] Iteration 1860, lr = 0.01
I0705 11:47:49.214387 14303 solver.cpp:228] Iteration 1880, loss = 4.46966
I0705 11:47:49.214411 14303 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0705 11:47:49.214417 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.0992025 (* 0.1 = 0.00992025 loss)
I0705 11:47:49.214422 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 34.3733 (* 0.1 = 3.43733 loss)
I0705 11:47:49.214426 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.34557 (* 0.1 = 0.234557 loss)
I0705 11:47:49.214431 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.870759 (* 0.1 = 0.0870759 loss)
I0705 11:47:49.214434 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.73536 (* 0.1 = 0.073536 loss)
I0705 11:47:49.214437 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.854949 (* 0.1 = 0.0854949 loss)
I0705 11:47:49.214442 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.786743 (* 0.1 = 0.0786742 loss)
I0705 11:47:49.214445 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.463079 (* 1 = 0.463079 loss)
I0705 11:47:49.214459 14303 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I0705 11:47:54.553485 14303 solver.cpp:337] Iteration 1900, Testing net (#0)
I0705 11:47:54.553519 14303 net.cpp:684] Ignoring source layer data_data_0_split
I0705 11:47:54.553522 14303 net.cpp:684] Ignoring source layer noisy_data
I0705 11:47:54.553524 14303 net.cpp:684] Ignoring source layer noisy_data_noisy_data_0_split
I0705 11:47:54.553527 14303 net.cpp:684] Ignoring source layer z1_bn1_0_split
I0705 11:47:54.553530 14303 net.cpp:684] Ignoring source layer bn1_n
I0705 11:47:54.553532 14303 net.cpp:684] Ignoring source layer noisy_z1_n
I0705 11:47:54.553534 14303 net.cpp:684] Ignoring source layer z1_n_noisy_z1_n_0_split
I0705 11:47:54.553535 14303 net.cpp:684] Ignoring source layer scale1_n
I0705 11:47:54.553537 14303 net.cpp:684] Ignoring source layer relu1_n
I0705 11:47:54.553539 14303 net.cpp:684] Ignoring source layer pool1_n
I0705 11:47:54.553542 14303 net.cpp:684] Ignoring source layer z2_bn2_0_split
I0705 11:47:54.553545 14303 net.cpp:684] Ignoring source layer bn2_n
I0705 11:47:54.553547 14303 net.cpp:684] Ignoring source layer noisy_z2_n
I0705 11:47:54.553550 14303 net.cpp:684] Ignoring source layer z2_n_noisy_z2_n_0_split
I0705 11:47:54.553551 14303 net.cpp:684] Ignoring source layer scale2_n
I0705 11:47:54.553552 14303 net.cpp:684] Ignoring source layer relu2_n
I0705 11:47:54.553555 14303 net.cpp:684] Ignoring source layer pool2_n
I0705 11:47:54.553558 14303 net.cpp:684] Ignoring source layer z3_bn3_0_split
I0705 11:47:54.553560 14303 net.cpp:684] Ignoring source layer bn3_n
I0705 11:47:54.553562 14303 net.cpp:684] Ignoring source layer noisy_z3_n
I0705 11:47:54.553563 14303 net.cpp:684] Ignoring source layer z3_n_noisy_z3_n_0_split
I0705 11:47:54.553565 14303 net.cpp:684] Ignoring source layer scale3_n
I0705 11:47:54.553567 14303 net.cpp:684] Ignoring source layer relu3_n
I0705 11:47:54.553570 14303 net.cpp:684] Ignoring source layer pool3_n
I0705 11:47:54.553572 14303 net.cpp:684] Ignoring source layer z4_bn4_0_split
I0705 11:47:54.553575 14303 net.cpp:684] Ignoring source layer bn4_n
I0705 11:47:54.553576 14303 net.cpp:684] Ignoring source layer noisy_z4_n
I0705 11:47:54.553578 14303 net.cpp:684] Ignoring source layer z4_n_noisy_z4_n_0_split
I0705 11:47:54.553580 14303 net.cpp:684] Ignoring source layer scale4_n
I0705 11:47:54.553581 14303 net.cpp:684] Ignoring source layer relu4_n
I0705 11:47:54.553583 14303 net.cpp:684] Ignoring source layer pool4_n
I0705 11:47:54.553586 14303 net.cpp:684] Ignoring source layer z5_bn5_0_split
I0705 11:47:54.553588 14303 net.cpp:684] Ignoring source layer bn5_n
I0705 11:47:54.553591 14303 net.cpp:684] Ignoring source layer noisy_z5_n
I0705 11:47:54.553592 14303 net.cpp:684] Ignoring source layer z5_n_noisy_z5_n_0_split
I0705 11:47:54.553593 14303 net.cpp:684] Ignoring source layer scale5_n
I0705 11:47:54.553596 14303 net.cpp:684] Ignoring source layer relu5_n
I0705 11:47:54.553597 14303 net.cpp:684] Ignoring source layer pool5_n
I0705 11:47:54.553611 14303 net.cpp:684] Ignoring source layer z6_bn6_0_split
I0705 11:47:54.553614 14303 net.cpp:684] Ignoring source layer bn6_n
I0705 11:47:54.553616 14303 net.cpp:684] Ignoring source layer noisy_z6_n
I0705 11:47:54.553617 14303 net.cpp:684] Ignoring source layer z6_n_noisy_z6_n_0_split
I0705 11:47:54.553619 14303 net.cpp:684] Ignoring source layer scale6_n
I0705 11:47:54.553622 14303 net.cpp:684] Ignoring source layer relu6_n
I0705 11:47:54.553623 14303 net.cpp:684] Ignoring source layer u6
I0705 11:47:54.553625 14303 net.cpp:684] Ignoring source layer comb6
I0705 11:47:54.553627 14303 net.cpp:684] Ignoring source layer z6_r_comb6_0_split
I0705 11:47:54.553628 14303 net.cpp:684] Ignoring source layer recon6
I0705 11:47:54.553630 14303 net.cpp:684] Ignoring source layer bn6_r
I0705 11:47:54.553632 14303 net.cpp:684] Ignoring source layer upsample5
I0705 11:47:54.553634 14303 net.cpp:684] Ignoring source layer comb5
I0705 11:47:54.553637 14303 net.cpp:684] Ignoring source layer z5_r_comb5_0_split
I0705 11:47:54.553638 14303 net.cpp:684] Ignoring source layer recon5
I0705 11:47:54.553639 14303 net.cpp:684] Ignoring source layer bn5_r
I0705 11:47:54.553642 14303 net.cpp:684] Ignoring source layer upsample4
I0705 11:47:54.553647 14303 net.cpp:684] Ignoring source layer comb4
I0705 11:47:54.553649 14303 net.cpp:684] Ignoring source layer z4_r_comb4_0_split
I0705 11:47:54.553653 14303 net.cpp:684] Ignoring source layer recon4
I0705 11:47:54.553654 14303 net.cpp:684] Ignoring source layer bn4_r
I0705 11:47:54.553656 14303 net.cpp:684] Ignoring source layer upsample3
I0705 11:47:54.553658 14303 net.cpp:684] Ignoring source layer comb3
I0705 11:47:54.553659 14303 net.cpp:684] Ignoring source layer z3_r_comb3_0_split
I0705 11:47:54.553661 14303 net.cpp:684] Ignoring source layer recon3
I0705 11:47:54.553663 14303 net.cpp:684] Ignoring source layer bn3_r
I0705 11:47:54.553665 14303 net.cpp:684] Ignoring source layer upsample2
I0705 11:47:54.553668 14303 net.cpp:684] Ignoring source layer comb2
I0705 11:47:54.553669 14303 net.cpp:684] Ignoring source layer z2_r_comb2_0_split
I0705 11:47:54.553671 14303 net.cpp:684] Ignoring source layer recon2
I0705 11:47:54.553673 14303 net.cpp:684] Ignoring source layer bn2_r
I0705 11:47:54.553674 14303 net.cpp:684] Ignoring source layer upsample1
I0705 11:47:54.553676 14303 net.cpp:684] Ignoring source layer comb1
I0705 11:47:54.553678 14303 net.cpp:684] Ignoring source layer z1_r_comb1_0_split
I0705 11:47:54.553680 14303 net.cpp:684] Ignoring source layer recon1
I0705 11:47:54.553683 14303 net.cpp:684] Ignoring source layer bn1_r
I0705 11:47:54.553684 14303 net.cpp:684] Ignoring source layer comb0
I0705 11:47:54.553685 14303 net.cpp:684] Ignoring source layer loss_ladder_6
I0705 11:47:54.553688 14303 net.cpp:684] Ignoring source layer loss_ladder_5
I0705 11:47:54.553689 14303 net.cpp:684] Ignoring source layer loss_ladder_4
I0705 11:47:54.553691 14303 net.cpp:684] Ignoring source layer loss_ladder_3
I0705 11:47:54.553694 14303 net.cpp:684] Ignoring source layer loss_ladder_2
I0705 11:47:54.553694 14303 net.cpp:684] Ignoring source layer loss_ladder_1
I0705 11:47:54.553696 14303 net.cpp:684] Ignoring source layer loss_ladder_0
I0705 11:47:54.553699 14303 net.cpp:684] Ignoring source layer loss_supervised
I0705 11:47:54.713234 14303 solver.cpp:404]     Test net output #0: accuracy = 0.46875
I0705 11:47:54.713270 14303 solver.cpp:404]     Test net output #1: prob = 1.47235 (* 1 = 1.47235 loss)
I0705 11:47:54.806884 14303 solver.cpp:228] Iteration 1900, loss = 5.78095
I0705 11:47:54.806900 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0705 11:47:54.806920 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.100214 (* 0.1 = 0.0100214 loss)
I0705 11:47:54.806923 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 46.1736 (* 0.1 = 4.61736 loss)
I0705 11:47:54.806928 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.75906 (* 0.1 = 0.175906 loss)
I0705 11:47:54.806932 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.77017 (* 0.1 = 0.077017 loss)
I0705 11:47:54.806936 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.697801 (* 0.1 = 0.0697801 loss)
I0705 11:47:54.806941 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.831393 (* 0.1 = 0.0831393 loss)
I0705 11:47:54.806943 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.790796 (* 0.1 = 0.0790797 loss)
I0705 11:47:54.806947 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.668645 (* 1 = 0.668645 loss)
I0705 11:47:54.806951 14303 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0705 11:48:00.241668 14303 solver.cpp:228] Iteration 1920, loss = 5.35342
I0705 11:48:00.241806 14303 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0705 11:48:00.241817 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.0995803 (* 0.1 = 0.00995804 loss)
I0705 11:48:00.241822 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 43.5336 (* 0.1 = 4.35336 loss)
I0705 11:48:00.241827 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.95134 (* 0.1 = 0.195134 loss)
I0705 11:48:00.241830 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.823215 (* 0.1 = 0.0823215 loss)
I0705 11:48:00.241833 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.717399 (* 0.1 = 0.0717399 loss)
I0705 11:48:00.241837 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.833842 (* 0.1 = 0.0833842 loss)
I0705 11:48:00.241842 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.79226 (* 0.1 = 0.079226 loss)
I0705 11:48:00.241845 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.478293 (* 1 = 0.478293 loss)
I0705 11:48:00.241849 14303 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I0705 11:48:05.676079 14303 solver.cpp:228] Iteration 1940, loss = 5.80189
I0705 11:48:05.676101 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:48:05.676108 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.101539 (* 0.1 = 0.0101539 loss)
I0705 11:48:05.676112 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 46.4614 (* 0.1 = 4.64614 loss)
I0705 11:48:05.676117 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.5773 (* 0.1 = 0.15773 loss)
I0705 11:48:05.676120 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.792507 (* 0.1 = 0.0792507 loss)
I0705 11:48:05.676125 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.692033 (* 0.1 = 0.0692033 loss)
I0705 11:48:05.676128 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.837165 (* 0.1 = 0.0837165 loss)
I0705 11:48:05.676132 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.773244 (* 0.1 = 0.0773244 loss)
I0705 11:48:05.676136 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.678365 (* 1 = 0.678365 loss)
I0705 11:48:05.676139 14303 sgd_solver.cpp:106] Iteration 1940, lr = 0.01
I0705 11:48:11.111805 14303 solver.cpp:228] Iteration 1960, loss = 5.06735
I0705 11:48:11.111832 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0705 11:48:11.111840 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.0979847 (* 0.1 = 0.00979847 loss)
I0705 11:48:11.111845 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 38.8068 (* 0.1 = 3.88068 loss)
I0705 11:48:11.111850 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.25128 (* 0.1 = 0.225128 loss)
I0705 11:48:11.111855 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.859644 (* 0.1 = 0.0859644 loss)
I0705 11:48:11.111858 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.717255 (* 0.1 = 0.0717255 loss)
I0705 11:48:11.111862 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.837988 (* 0.1 = 0.0837988 loss)
I0705 11:48:11.111866 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.781805 (* 0.1 = 0.0781805 loss)
I0705 11:48:11.111871 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.632075 (* 1 = 0.632075 loss)
I0705 11:48:11.111876 14303 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I0705 11:48:16.546478 14303 solver.cpp:228] Iteration 1980, loss = 5.03485
I0705 11:48:16.546500 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:48:16.546507 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.0958405 (* 0.1 = 0.00958405 loss)
I0705 11:48:16.546512 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 38.2065 (* 0.1 = 3.82065 loss)
I0705 11:48:16.546516 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.54292 (* 0.1 = 0.254292 loss)
I0705 11:48:16.546520 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.922289 (* 0.1 = 0.0922289 loss)
I0705 11:48:16.546541 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.706073 (* 0.1 = 0.0706073 loss)
I0705 11:48:16.546545 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.816201 (* 0.1 = 0.0816201 loss)
I0705 11:48:16.546550 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.753757 (* 0.1 = 0.0753757 loss)
I0705 11:48:16.546564 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.63049 (* 1 = 0.63049 loss)
I0705 11:48:16.546568 14303 sgd_solver.cpp:106] Iteration 1980, lr = 0.01
I0705 11:48:21.884409 14303 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_2000.caffemodel
I0705 11:48:22.521463 14303 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_2000.solverstate
I0705 11:48:22.869956 14303 solver.cpp:337] Iteration 2000, Testing net (#0)
I0705 11:48:22.869997 14303 net.cpp:684] Ignoring source layer data_data_0_split
I0705 11:48:22.870005 14303 net.cpp:684] Ignoring source layer noisy_data
I0705 11:48:22.870012 14303 net.cpp:684] Ignoring source layer noisy_data_noisy_data_0_split
I0705 11:48:22.870018 14303 net.cpp:684] Ignoring source layer z1_bn1_0_split
I0705 11:48:22.870026 14303 net.cpp:684] Ignoring source layer bn1_n
I0705 11:48:22.870031 14303 net.cpp:684] Ignoring source layer noisy_z1_n
I0705 11:48:22.870036 14303 net.cpp:684] Ignoring source layer z1_n_noisy_z1_n_0_split
I0705 11:48:22.870041 14303 net.cpp:684] Ignoring source layer scale1_n
I0705 11:48:22.870046 14303 net.cpp:684] Ignoring source layer relu1_n
I0705 11:48:22.870052 14303 net.cpp:684] Ignoring source layer pool1_n
I0705 11:48:22.870059 14303 net.cpp:684] Ignoring source layer z2_bn2_0_split
I0705 11:48:22.870066 14303 net.cpp:684] Ignoring source layer bn2_n
I0705 11:48:22.870071 14303 net.cpp:684] Ignoring source layer noisy_z2_n
I0705 11:48:22.870075 14303 net.cpp:684] Ignoring source layer z2_n_noisy_z2_n_0_split
I0705 11:48:22.870080 14303 net.cpp:684] Ignoring source layer scale2_n
I0705 11:48:22.870085 14303 net.cpp:684] Ignoring source layer relu2_n
I0705 11:48:22.870090 14303 net.cpp:684] Ignoring source layer pool2_n
I0705 11:48:22.870097 14303 net.cpp:684] Ignoring source layer z3_bn3_0_split
I0705 11:48:22.870105 14303 net.cpp:684] Ignoring source layer bn3_n
I0705 11:48:22.870110 14303 net.cpp:684] Ignoring source layer noisy_z3_n
I0705 11:48:22.870115 14303 net.cpp:684] Ignoring source layer z3_n_noisy_z3_n_0_split
I0705 11:48:22.870120 14303 net.cpp:684] Ignoring source layer scale3_n
I0705 11:48:22.870124 14303 net.cpp:684] Ignoring source layer relu3_n
I0705 11:48:22.870129 14303 net.cpp:684] Ignoring source layer pool3_n
I0705 11:48:22.870141 14303 net.cpp:684] Ignoring source layer z4_bn4_0_split
I0705 11:48:22.870147 14303 net.cpp:684] Ignoring source layer bn4_n
I0705 11:48:22.870151 14303 net.cpp:684] Ignoring source layer noisy_z4_n
I0705 11:48:22.870157 14303 net.cpp:684] Ignoring source layer z4_n_noisy_z4_n_0_split
I0705 11:48:22.870162 14303 net.cpp:684] Ignoring source layer scale4_n
I0705 11:48:22.870167 14303 net.cpp:684] Ignoring source layer relu4_n
I0705 11:48:22.870172 14303 net.cpp:684] Ignoring source layer pool4_n
I0705 11:48:22.870178 14303 net.cpp:684] Ignoring source layer z5_bn5_0_split
I0705 11:48:22.870185 14303 net.cpp:684] Ignoring source layer bn5_n
I0705 11:48:22.870190 14303 net.cpp:684] Ignoring source layer noisy_z5_n
I0705 11:48:22.870195 14303 net.cpp:684] Ignoring source layer z5_n_noisy_z5_n_0_split
I0705 11:48:22.870200 14303 net.cpp:684] Ignoring source layer scale5_n
I0705 11:48:22.870204 14303 net.cpp:684] Ignoring source layer relu5_n
I0705 11:48:22.870210 14303 net.cpp:684] Ignoring source layer pool5_n
I0705 11:48:22.870216 14303 net.cpp:684] Ignoring source layer z6_bn6_0_split
I0705 11:48:22.870223 14303 net.cpp:684] Ignoring source layer bn6_n
I0705 11:48:22.870229 14303 net.cpp:684] Ignoring source layer noisy_z6_n
I0705 11:48:22.870234 14303 net.cpp:684] Ignoring source layer z6_n_noisy_z6_n_0_split
I0705 11:48:22.870239 14303 net.cpp:684] Ignoring source layer scale6_n
I0705 11:48:22.870268 14303 net.cpp:684] Ignoring source layer relu6_n
I0705 11:48:22.870275 14303 net.cpp:684] Ignoring source layer u6
I0705 11:48:22.870280 14303 net.cpp:684] Ignoring source layer comb6
I0705 11:48:22.870285 14303 net.cpp:684] Ignoring source layer z6_r_comb6_0_split
I0705 11:48:22.870290 14303 net.cpp:684] Ignoring source layer recon6
I0705 11:48:22.870296 14303 net.cpp:684] Ignoring source layer bn6_r
I0705 11:48:22.870301 14303 net.cpp:684] Ignoring source layer upsample5
I0705 11:48:22.870306 14303 net.cpp:684] Ignoring source layer comb5
I0705 11:48:22.870311 14303 net.cpp:684] Ignoring source layer z5_r_comb5_0_split
I0705 11:48:22.870316 14303 net.cpp:684] Ignoring source layer recon5
I0705 11:48:22.870321 14303 net.cpp:684] Ignoring source layer bn5_r
I0705 11:48:22.870326 14303 net.cpp:684] Ignoring source layer upsample4
I0705 11:48:22.870331 14303 net.cpp:684] Ignoring source layer comb4
I0705 11:48:22.870335 14303 net.cpp:684] Ignoring source layer z4_r_comb4_0_split
I0705 11:48:22.870339 14303 net.cpp:684] Ignoring source layer recon4
I0705 11:48:22.870344 14303 net.cpp:684] Ignoring source layer bn4_r
I0705 11:48:22.870349 14303 net.cpp:684] Ignoring source layer upsample3
I0705 11:48:22.870354 14303 net.cpp:684] Ignoring source layer comb3
I0705 11:48:22.870359 14303 net.cpp:684] Ignoring source layer z3_r_comb3_0_split
I0705 11:48:22.870364 14303 net.cpp:684] Ignoring source layer recon3
I0705 11:48:22.870369 14303 net.cpp:684] Ignoring source layer bn3_r
I0705 11:48:22.870373 14303 net.cpp:684] Ignoring source layer upsample2
I0705 11:48:22.870379 14303 net.cpp:684] Ignoring source layer comb2
I0705 11:48:22.870384 14303 net.cpp:684] Ignoring source layer z2_r_comb2_0_split
I0705 11:48:22.870389 14303 net.cpp:684] Ignoring source layer recon2
I0705 11:48:22.870394 14303 net.cpp:684] Ignoring source layer bn2_r
I0705 11:48:22.870399 14303 net.cpp:684] Ignoring source layer upsample1
I0705 11:48:22.870404 14303 net.cpp:684] Ignoring source layer comb1
I0705 11:48:22.870409 14303 net.cpp:684] Ignoring source layer z1_r_comb1_0_split
I0705 11:48:22.870414 14303 net.cpp:684] Ignoring source layer recon1
I0705 11:48:22.870419 14303 net.cpp:684] Ignoring source layer bn1_r
I0705 11:48:22.870424 14303 net.cpp:684] Ignoring source layer comb0
I0705 11:48:22.870429 14303 net.cpp:684] Ignoring source layer loss_ladder_6
I0705 11:48:22.870434 14303 net.cpp:684] Ignoring source layer loss_ladder_5
I0705 11:48:22.870437 14303 net.cpp:684] Ignoring source layer loss_ladder_4
I0705 11:48:22.870442 14303 net.cpp:684] Ignoring source layer loss_ladder_3
I0705 11:48:22.870447 14303 net.cpp:684] Ignoring source layer loss_ladder_2
I0705 11:48:22.870451 14303 net.cpp:684] Ignoring source layer loss_ladder_1
I0705 11:48:22.870456 14303 net.cpp:684] Ignoring source layer loss_ladder_0
I0705 11:48:22.870463 14303 net.cpp:684] Ignoring source layer loss_supervised
I0705 11:48:23.030274 14303 solver.cpp:404]     Test net output #0: accuracy = 0.507812
I0705 11:48:23.030309 14303 solver.cpp:404]     Test net output #1: prob = 1.37586 (* 1 = 1.37586 loss)
I0705 11:48:23.124730 14303 solver.cpp:228] Iteration 2000, loss = 4.64925
I0705 11:48:23.124752 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:48:23.124759 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.0955542 (* 0.1 = 0.00955542 loss)
I0705 11:48:23.124764 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 34.9298 (* 0.1 = 3.49298 loss)
I0705 11:48:23.124768 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 2.56896 (* 0.1 = 0.256896 loss)
I0705 11:48:23.124773 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.935587 (* 0.1 = 0.0935587 loss)
I0705 11:48:23.124776 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.723398 (* 0.1 = 0.0723398 loss)
I0705 11:48:23.124780 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.822974 (* 0.1 = 0.0822974 loss)
I0705 11:48:23.124785 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.766238 (* 0.1 = 0.0766238 loss)
I0705 11:48:23.124809 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.564992 (* 1 = 0.564992 loss)
I0705 11:48:23.124815 14303 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I0705 11:48:28.559646 14303 solver.cpp:228] Iteration 2020, loss = 5.86403
I0705 11:48:28.559669 14303 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0705 11:48:28.559677 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.100959 (* 0.1 = 0.0100959 loss)
I0705 11:48:28.559681 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 46.7477 (* 0.1 = 4.67477 loss)
I0705 11:48:28.559685 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.95323 (* 0.1 = 0.195323 loss)
I0705 11:48:28.559689 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.835371 (* 0.1 = 0.0835371 loss)
I0705 11:48:28.559694 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.70611 (* 0.1 = 0.070611 loss)
I0705 11:48:28.559698 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.841338 (* 0.1 = 0.0841338 loss)
I0705 11:48:28.559702 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.792508 (* 0.1 = 0.0792508 loss)
I0705 11:48:28.559706 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.666307 (* 1 = 0.666307 loss)
I0705 11:48:28.559710 14303 sgd_solver.cpp:106] Iteration 2020, lr = 0.01
I0705 11:48:33.993305 14303 solver.cpp:228] Iteration 2040, loss = 6.0588
I0705 11:48:33.993573 14303 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0705 11:48:33.993585 14303 solver.cpp:244]     Train net output #1: loss_ladder_0 = 0.100027 (* 0.1 = 0.0100027 loss)
I0705 11:48:33.993590 14303 solver.cpp:244]     Train net output #2: loss_ladder_1 = 49.0332 (* 0.1 = 4.90332 loss)
I0705 11:48:33.993595 14303 solver.cpp:244]     Train net output #3: loss_ladder_2 = 1.86428 (* 0.1 = 0.186428 loss)
I0705 11:48:33.993599 14303 solver.cpp:244]     Train net output #4: loss_ladder_3 = 0.803776 (* 0.1 = 0.0803776 loss)
I0705 11:48:33.993603 14303 solver.cpp:244]     Train net output #5: loss_ladder_4 = 0.695575 (* 0.1 = 0.0695575 loss)
I0705 11:48:33.993607 14303 solver.cpp:244]     Train net output #6: loss_ladder_5 = 0.826039 (* 0.1 = 0.0826039 loss)
I0705 11:48:33.993610 14303 solver.cpp:244]     Train net output #7: loss_ladder_6 = 0.762709 (* 0.1 = 0.0762709 loss)
I0705 11:48:33.993614 14303 solver.cpp:244]     Train net output #8: loss_supervised = 0.65024 (* 1 = 0.65024 loss)
I0705 11:48:33.993618 14303 sgd_solver.cpp:106] Iteration 2040, lr = 0.01
