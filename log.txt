I0624 13:54:12.918395 18353 caffe.cpp:185] Using GPUs 1
I0624 13:54:12.931835 18353 caffe.cpp:190] GPU 1: GeForce GTX TITAN X
I0624 13:54:13.263394 18353 solver.cpp:48] Initializing solver from parameters: 
test_iter: 16
test_interval: 100
base_lr: 0.01
display: 20
max_iter: 2000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 500
snapshot_prefix: "data/models/segnet"
solver_mode: GPU
device_id: 1
net: "models/segnet/train_val.prototxt"
test_initialization: true
iter_size: 1
I0624 13:54:13.263509 18353 solver.cpp:91] Creating training net from net file: models/segnet/train_val.prototxt
I0624 13:54:13.264941 18353 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0624 13:54:13.265372 18353 net.cpp:49] Initializing net from parameters: 
name: "segnet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "DenseImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 224
    mean_value: 100
  }
  dense_image_data_param {
    source: "data/train_seg.txt"
    batch_size: 32
    shuffle: true
    new_height: 224
    new_width: 310
    is_color: false
    root_folder: "data/raw/train/"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 14
    upsample_w: 14
  }
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2_D"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2_D"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1_D"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1_D"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 28
    upsample_w: 28
  }
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2_D"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2_D"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1_D"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1_D"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
    upsample_h: 56
    upsample_w: 56
  }
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn3_2_D"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2_D"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1_D"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1_D"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
    upsample_h: 112
    upsample_w: 112
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2_D"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2_D"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1_D"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1_D"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
    upsample_h: 224
    upsample_w: 224
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2_D"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2_D"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2
    bias_term: true
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "accuracy"
}
I0624 13:54:13.265650 18353 layer_factory.hpp:77] Creating layer data
I0624 13:54:13.265681 18353 net.cpp:91] Creating Layer data
I0624 13:54:13.265686 18353 net.cpp:399] data -> data
I0624 13:54:13.265707 18353 net.cpp:399] data -> label
I0624 13:54:13.266022 18353 dense_image_data_layer.cpp:38] Opening file data/train_seg.txt
I0624 13:54:13.266911 18353 dense_image_data_layer.cpp:48] Shuffling data
I0624 13:54:13.267125 18353 dense_image_data_layer.cpp:53] A total of 2024 examples.
I0624 13:54:13.513574 18353 dense_image_data_layer.cpp:92] output data size: 1,1,224,224
I0624 13:54:13.515386 18353 net.cpp:141] Setting up data
I0624 13:54:13.515404 18353 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 13:54:13.515409 18353 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 13:54:13.515413 18353 net.cpp:156] Memory required for data: 401408
I0624 13:54:13.515419 18353 layer_factory.hpp:77] Creating layer label_data_1_split
I0624 13:54:13.515434 18353 net.cpp:91] Creating Layer label_data_1_split
I0624 13:54:13.515437 18353 net.cpp:425] label_data_1_split <- label
I0624 13:54:13.515446 18353 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0624 13:54:13.515460 18353 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0624 13:54:13.515521 18353 net.cpp:141] Setting up label_data_1_split
I0624 13:54:13.515528 18353 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 13:54:13.515532 18353 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 13:54:13.515533 18353 net.cpp:156] Memory required for data: 802816
I0624 13:54:13.515537 18353 layer_factory.hpp:77] Creating layer conv1_1
I0624 13:54:13.515549 18353 net.cpp:91] Creating Layer conv1_1
I0624 13:54:13.515552 18353 net.cpp:425] conv1_1 <- data
I0624 13:54:13.515558 18353 net.cpp:399] conv1_1 -> conv1_1
I0624 13:54:13.701439 18353 net.cpp:141] Setting up conv1_1
I0624 13:54:13.701464 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.701467 18353 net.cpp:156] Memory required for data: 7225344
I0624 13:54:13.701480 18353 layer_factory.hpp:77] Creating layer bn1_1
I0624 13:54:13.701490 18353 net.cpp:91] Creating Layer bn1_1
I0624 13:54:13.701495 18353 net.cpp:425] bn1_1 <- conv1_1
I0624 13:54:13.701499 18353 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0624 13:54:13.701684 18353 net.cpp:141] Setting up bn1_1
I0624 13:54:13.701692 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.701694 18353 net.cpp:156] Memory required for data: 13647872
I0624 13:54:13.701704 18353 layer_factory.hpp:77] Creating layer scale1_1
I0624 13:54:13.701714 18353 net.cpp:91] Creating Layer scale1_1
I0624 13:54:13.701716 18353 net.cpp:425] scale1_1 <- conv1_1
I0624 13:54:13.701720 18353 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0624 13:54:13.701756 18353 layer_factory.hpp:77] Creating layer scale1_1
I0624 13:54:13.701912 18353 net.cpp:141] Setting up scale1_1
I0624 13:54:13.701920 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.701922 18353 net.cpp:156] Memory required for data: 20070400
I0624 13:54:13.701928 18353 layer_factory.hpp:77] Creating layer relu1_1
I0624 13:54:13.701933 18353 net.cpp:91] Creating Layer relu1_1
I0624 13:54:13.701936 18353 net.cpp:425] relu1_1 <- conv1_1
I0624 13:54:13.701939 18353 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0624 13:54:13.702198 18353 net.cpp:141] Setting up relu1_1
I0624 13:54:13.702209 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.702213 18353 net.cpp:156] Memory required for data: 26492928
I0624 13:54:13.702214 18353 layer_factory.hpp:77] Creating layer conv1_2
I0624 13:54:13.702224 18353 net.cpp:91] Creating Layer conv1_2
I0624 13:54:13.702226 18353 net.cpp:425] conv1_2 <- conv1_1
I0624 13:54:13.702230 18353 net.cpp:399] conv1_2 -> conv1_2
I0624 13:54:13.703775 18353 net.cpp:141] Setting up conv1_2
I0624 13:54:13.703788 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.703790 18353 net.cpp:156] Memory required for data: 32915456
I0624 13:54:13.703795 18353 layer_factory.hpp:77] Creating layer bn1_2
I0624 13:54:13.703801 18353 net.cpp:91] Creating Layer bn1_2
I0624 13:54:13.703804 18353 net.cpp:425] bn1_2 <- conv1_2
I0624 13:54:13.703809 18353 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0624 13:54:13.703979 18353 net.cpp:141] Setting up bn1_2
I0624 13:54:13.703986 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.703989 18353 net.cpp:156] Memory required for data: 39337984
I0624 13:54:13.703996 18353 layer_factory.hpp:77] Creating layer scale1_2
I0624 13:54:13.704020 18353 net.cpp:91] Creating Layer scale1_2
I0624 13:54:13.704022 18353 net.cpp:425] scale1_2 <- conv1_2
I0624 13:54:13.704027 18353 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0624 13:54:13.704058 18353 layer_factory.hpp:77] Creating layer scale1_2
I0624 13:54:13.704216 18353 net.cpp:141] Setting up scale1_2
I0624 13:54:13.704223 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.704226 18353 net.cpp:156] Memory required for data: 45760512
I0624 13:54:13.704231 18353 layer_factory.hpp:77] Creating layer relu1_2
I0624 13:54:13.704234 18353 net.cpp:91] Creating Layer relu1_2
I0624 13:54:13.704237 18353 net.cpp:425] relu1_2 <- conv1_2
I0624 13:54:13.704241 18353 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0624 13:54:13.704375 18353 net.cpp:141] Setting up relu1_2
I0624 13:54:13.704383 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.704385 18353 net.cpp:156] Memory required for data: 52183040
I0624 13:54:13.704388 18353 layer_factory.hpp:77] Creating layer pool1
I0624 13:54:13.704391 18353 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 13:54:13.704396 18353 net.cpp:91] Creating Layer pool1
I0624 13:54:13.704398 18353 net.cpp:425] pool1 <- conv1_2
I0624 13:54:13.704402 18353 net.cpp:399] pool1 -> pool1
I0624 13:54:13.704409 18353 net.cpp:399] pool1 -> pool1_mask
I0624 13:54:13.704450 18353 net.cpp:141] Setting up pool1
I0624 13:54:13.704457 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.704460 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.704463 18353 net.cpp:156] Memory required for data: 55394304
I0624 13:54:13.704464 18353 layer_factory.hpp:77] Creating layer conv2_1
I0624 13:54:13.704471 18353 net.cpp:91] Creating Layer conv2_1
I0624 13:54:13.704474 18353 net.cpp:425] conv2_1 <- pool1
I0624 13:54:13.704478 18353 net.cpp:399] conv2_1 -> conv2_1
I0624 13:54:13.706091 18353 net.cpp:141] Setting up conv2_1
I0624 13:54:13.706105 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.706109 18353 net.cpp:156] Memory required for data: 58605568
I0624 13:54:13.706112 18353 layer_factory.hpp:77] Creating layer bn2_1
I0624 13:54:13.706120 18353 net.cpp:91] Creating Layer bn2_1
I0624 13:54:13.706121 18353 net.cpp:425] bn2_1 <- conv2_1
I0624 13:54:13.706126 18353 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0624 13:54:13.706280 18353 net.cpp:141] Setting up bn2_1
I0624 13:54:13.706288 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.706290 18353 net.cpp:156] Memory required for data: 61816832
I0624 13:54:13.706295 18353 layer_factory.hpp:77] Creating layer scale2_1
I0624 13:54:13.706303 18353 net.cpp:91] Creating Layer scale2_1
I0624 13:54:13.706305 18353 net.cpp:425] scale2_1 <- conv2_1
I0624 13:54:13.706310 18353 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0624 13:54:13.706341 18353 layer_factory.hpp:77] Creating layer scale2_1
I0624 13:54:13.706439 18353 net.cpp:141] Setting up scale2_1
I0624 13:54:13.706445 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.706447 18353 net.cpp:156] Memory required for data: 65028096
I0624 13:54:13.706455 18353 layer_factory.hpp:77] Creating layer relu2_1
I0624 13:54:13.706460 18353 net.cpp:91] Creating Layer relu2_1
I0624 13:54:13.706462 18353 net.cpp:425] relu2_1 <- conv2_1
I0624 13:54:13.706467 18353 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0624 13:54:13.706728 18353 net.cpp:141] Setting up relu2_1
I0624 13:54:13.706740 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.706743 18353 net.cpp:156] Memory required for data: 68239360
I0624 13:54:13.706745 18353 layer_factory.hpp:77] Creating layer conv2_2
I0624 13:54:13.706754 18353 net.cpp:91] Creating Layer conv2_2
I0624 13:54:13.706758 18353 net.cpp:425] conv2_2 <- conv2_1
I0624 13:54:13.706763 18353 net.cpp:399] conv2_2 -> conv2_2
I0624 13:54:13.707770 18353 net.cpp:141] Setting up conv2_2
I0624 13:54:13.707783 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.707795 18353 net.cpp:156] Memory required for data: 71450624
I0624 13:54:13.707801 18353 layer_factory.hpp:77] Creating layer bn2_2
I0624 13:54:13.707809 18353 net.cpp:91] Creating Layer bn2_2
I0624 13:54:13.707813 18353 net.cpp:425] bn2_2 <- conv2_2
I0624 13:54:13.707818 18353 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0624 13:54:13.707973 18353 net.cpp:141] Setting up bn2_2
I0624 13:54:13.707980 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.707983 18353 net.cpp:156] Memory required for data: 74661888
I0624 13:54:13.707988 18353 layer_factory.hpp:77] Creating layer scale2_2
I0624 13:54:13.707994 18353 net.cpp:91] Creating Layer scale2_2
I0624 13:54:13.707998 18353 net.cpp:425] scale2_2 <- conv2_2
I0624 13:54:13.708001 18353 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0624 13:54:13.708031 18353 layer_factory.hpp:77] Creating layer scale2_2
I0624 13:54:13.708133 18353 net.cpp:141] Setting up scale2_2
I0624 13:54:13.708140 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.708142 18353 net.cpp:156] Memory required for data: 77873152
I0624 13:54:13.708148 18353 layer_factory.hpp:77] Creating layer relu2_2
I0624 13:54:13.708151 18353 net.cpp:91] Creating Layer relu2_2
I0624 13:54:13.708153 18353 net.cpp:425] relu2_2 <- conv2_2
I0624 13:54:13.708158 18353 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0624 13:54:13.708425 18353 net.cpp:141] Setting up relu2_2
I0624 13:54:13.708437 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.708441 18353 net.cpp:156] Memory required for data: 81084416
I0624 13:54:13.708443 18353 layer_factory.hpp:77] Creating layer pool2
I0624 13:54:13.708446 18353 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 13:54:13.708451 18353 net.cpp:91] Creating Layer pool2
I0624 13:54:13.708453 18353 net.cpp:425] pool2 <- conv2_2
I0624 13:54:13.708457 18353 net.cpp:399] pool2 -> pool2
I0624 13:54:13.708463 18353 net.cpp:399] pool2 -> pool2_mask
I0624 13:54:13.708498 18353 net.cpp:141] Setting up pool2
I0624 13:54:13.708505 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.708508 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.708510 18353 net.cpp:156] Memory required for data: 82690048
I0624 13:54:13.708513 18353 layer_factory.hpp:77] Creating layer conv3_1
I0624 13:54:13.708520 18353 net.cpp:91] Creating Layer conv3_1
I0624 13:54:13.708523 18353 net.cpp:425] conv3_1 <- pool2
I0624 13:54:13.708528 18353 net.cpp:399] conv3_1 -> conv3_1
I0624 13:54:13.710465 18353 net.cpp:141] Setting up conv3_1
I0624 13:54:13.710477 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.710480 18353 net.cpp:156] Memory required for data: 84295680
I0624 13:54:13.710485 18353 layer_factory.hpp:77] Creating layer bn3_1
I0624 13:54:13.710491 18353 net.cpp:91] Creating Layer bn3_1
I0624 13:54:13.710494 18353 net.cpp:425] bn3_1 <- conv3_1
I0624 13:54:13.710499 18353 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0624 13:54:13.711262 18353 net.cpp:141] Setting up bn3_1
I0624 13:54:13.711273 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.711277 18353 net.cpp:156] Memory required for data: 85901312
I0624 13:54:13.711282 18353 layer_factory.hpp:77] Creating layer scale3_1
I0624 13:54:13.711289 18353 net.cpp:91] Creating Layer scale3_1
I0624 13:54:13.711292 18353 net.cpp:425] scale3_1 <- conv3_1
I0624 13:54:13.711297 18353 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0624 13:54:13.711331 18353 layer_factory.hpp:77] Creating layer scale3_1
I0624 13:54:13.711422 18353 net.cpp:141] Setting up scale3_1
I0624 13:54:13.711428 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.711431 18353 net.cpp:156] Memory required for data: 87506944
I0624 13:54:13.711436 18353 layer_factory.hpp:77] Creating layer relu3_1
I0624 13:54:13.711441 18353 net.cpp:91] Creating Layer relu3_1
I0624 13:54:13.711443 18353 net.cpp:425] relu3_1 <- conv3_1
I0624 13:54:13.711447 18353 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0624 13:54:13.711591 18353 net.cpp:141] Setting up relu3_1
I0624 13:54:13.711601 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.711614 18353 net.cpp:156] Memory required for data: 89112576
I0624 13:54:13.711617 18353 layer_factory.hpp:77] Creating layer conv3_2
I0624 13:54:13.711627 18353 net.cpp:91] Creating Layer conv3_2
I0624 13:54:13.711633 18353 net.cpp:425] conv3_2 <- conv3_1
I0624 13:54:13.711638 18353 net.cpp:399] conv3_2 -> conv3_2
I0624 13:54:13.713397 18353 net.cpp:141] Setting up conv3_2
I0624 13:54:13.713412 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.713414 18353 net.cpp:156] Memory required for data: 90718208
I0624 13:54:13.713418 18353 layer_factory.hpp:77] Creating layer bn3_2
I0624 13:54:13.713424 18353 net.cpp:91] Creating Layer bn3_2
I0624 13:54:13.713428 18353 net.cpp:425] bn3_2 <- conv3_2
I0624 13:54:13.713431 18353 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0624 13:54:13.713583 18353 net.cpp:141] Setting up bn3_2
I0624 13:54:13.713590 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.713593 18353 net.cpp:156] Memory required for data: 92323840
I0624 13:54:13.713601 18353 layer_factory.hpp:77] Creating layer scale3_2
I0624 13:54:13.713608 18353 net.cpp:91] Creating Layer scale3_2
I0624 13:54:13.713611 18353 net.cpp:425] scale3_2 <- conv3_2
I0624 13:54:13.713614 18353 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0624 13:54:13.713649 18353 layer_factory.hpp:77] Creating layer scale3_2
I0624 13:54:13.713738 18353 net.cpp:141] Setting up scale3_2
I0624 13:54:13.713744 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.713747 18353 net.cpp:156] Memory required for data: 93929472
I0624 13:54:13.713752 18353 layer_factory.hpp:77] Creating layer relu3_2
I0624 13:54:13.713755 18353 net.cpp:91] Creating Layer relu3_2
I0624 13:54:13.713758 18353 net.cpp:425] relu3_2 <- conv3_2
I0624 13:54:13.713763 18353 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0624 13:54:13.714032 18353 net.cpp:141] Setting up relu3_2
I0624 13:54:13.714042 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.714046 18353 net.cpp:156] Memory required for data: 95535104
I0624 13:54:13.714047 18353 layer_factory.hpp:77] Creating layer pool3
I0624 13:54:13.714051 18353 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 13:54:13.714056 18353 net.cpp:91] Creating Layer pool3
I0624 13:54:13.714058 18353 net.cpp:425] pool3 <- conv3_2
I0624 13:54:13.714062 18353 net.cpp:399] pool3 -> pool3
I0624 13:54:13.714068 18353 net.cpp:399] pool3 -> pool3_mask
I0624 13:54:13.714105 18353 net.cpp:141] Setting up pool3
I0624 13:54:13.714114 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.714118 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.714119 18353 net.cpp:156] Memory required for data: 96337920
I0624 13:54:13.714121 18353 layer_factory.hpp:77] Creating layer conv4_1
I0624 13:54:13.714129 18353 net.cpp:91] Creating Layer conv4_1
I0624 13:54:13.714131 18353 net.cpp:425] conv4_1 <- pool3
I0624 13:54:13.714138 18353 net.cpp:399] conv4_1 -> conv4_1
I0624 13:54:13.717360 18353 net.cpp:141] Setting up conv4_1
I0624 13:54:13.717372 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.717375 18353 net.cpp:156] Memory required for data: 97140736
I0624 13:54:13.717381 18353 layer_factory.hpp:77] Creating layer bn4_1
I0624 13:54:13.717387 18353 net.cpp:91] Creating Layer bn4_1
I0624 13:54:13.717391 18353 net.cpp:425] bn4_1 <- conv4_1
I0624 13:54:13.717394 18353 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0624 13:54:13.717552 18353 net.cpp:141] Setting up bn4_1
I0624 13:54:13.717559 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.717562 18353 net.cpp:156] Memory required for data: 97943552
I0624 13:54:13.717567 18353 layer_factory.hpp:77] Creating layer scale4_1
I0624 13:54:13.717574 18353 net.cpp:91] Creating Layer scale4_1
I0624 13:54:13.717577 18353 net.cpp:425] scale4_1 <- conv4_1
I0624 13:54:13.717581 18353 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0624 13:54:13.717615 18353 layer_factory.hpp:77] Creating layer scale4_1
I0624 13:54:13.717716 18353 net.cpp:141] Setting up scale4_1
I0624 13:54:13.717732 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.717736 18353 net.cpp:156] Memory required for data: 98746368
I0624 13:54:13.717741 18353 layer_factory.hpp:77] Creating layer relu4_1
I0624 13:54:13.717748 18353 net.cpp:91] Creating Layer relu4_1
I0624 13:54:13.717751 18353 net.cpp:425] relu4_1 <- conv4_1
I0624 13:54:13.717756 18353 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0624 13:54:13.718031 18353 net.cpp:141] Setting up relu4_1
I0624 13:54:13.718044 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.718046 18353 net.cpp:156] Memory required for data: 99549184
I0624 13:54:13.718049 18353 layer_factory.hpp:77] Creating layer conv4_2
I0624 13:54:13.718057 18353 net.cpp:91] Creating Layer conv4_2
I0624 13:54:13.718060 18353 net.cpp:425] conv4_2 <- conv4_1
I0624 13:54:13.718065 18353 net.cpp:399] conv4_2 -> conv4_2
I0624 13:54:13.723716 18353 net.cpp:141] Setting up conv4_2
I0624 13:54:13.723728 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.723731 18353 net.cpp:156] Memory required for data: 100352000
I0624 13:54:13.723736 18353 layer_factory.hpp:77] Creating layer bn4_2
I0624 13:54:13.723743 18353 net.cpp:91] Creating Layer bn4_2
I0624 13:54:13.723747 18353 net.cpp:425] bn4_2 <- conv4_2
I0624 13:54:13.723750 18353 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0624 13:54:13.723914 18353 net.cpp:141] Setting up bn4_2
I0624 13:54:13.723922 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.723925 18353 net.cpp:156] Memory required for data: 101154816
I0624 13:54:13.723930 18353 layer_factory.hpp:77] Creating layer scale4_2
I0624 13:54:13.723937 18353 net.cpp:91] Creating Layer scale4_2
I0624 13:54:13.723939 18353 net.cpp:425] scale4_2 <- conv4_2
I0624 13:54:13.723944 18353 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0624 13:54:13.723978 18353 layer_factory.hpp:77] Creating layer scale4_2
I0624 13:54:13.724071 18353 net.cpp:141] Setting up scale4_2
I0624 13:54:13.724077 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.724081 18353 net.cpp:156] Memory required for data: 101957632
I0624 13:54:13.724084 18353 layer_factory.hpp:77] Creating layer relu4_2
I0624 13:54:13.724088 18353 net.cpp:91] Creating Layer relu4_2
I0624 13:54:13.724092 18353 net.cpp:425] relu4_2 <- conv4_2
I0624 13:54:13.724094 18353 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0624 13:54:13.724243 18353 net.cpp:141] Setting up relu4_2
I0624 13:54:13.724252 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.724254 18353 net.cpp:156] Memory required for data: 102760448
I0624 13:54:13.724257 18353 layer_factory.hpp:77] Creating layer pool4
I0624 13:54:13.724259 18353 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 13:54:13.724266 18353 net.cpp:91] Creating Layer pool4
I0624 13:54:13.724267 18353 net.cpp:425] pool4 <- conv4_2
I0624 13:54:13.724272 18353 net.cpp:399] pool4 -> pool4
I0624 13:54:13.724277 18353 net.cpp:399] pool4 -> pool4_mask
I0624 13:54:13.724315 18353 net.cpp:141] Setting up pool4
I0624 13:54:13.724321 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.724324 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.724326 18353 net.cpp:156] Memory required for data: 103161856
I0624 13:54:13.724328 18353 layer_factory.hpp:77] Creating layer conv5_1
I0624 13:54:13.724336 18353 net.cpp:91] Creating Layer conv5_1
I0624 13:54:13.724339 18353 net.cpp:425] conv5_1 <- pool4
I0624 13:54:13.724350 18353 net.cpp:399] conv5_1 -> conv5_1
I0624 13:54:13.729848 18353 net.cpp:141] Setting up conv5_1
I0624 13:54:13.729862 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.729866 18353 net.cpp:156] Memory required for data: 103362560
I0624 13:54:13.729869 18353 layer_factory.hpp:77] Creating layer bn5_1
I0624 13:54:13.729876 18353 net.cpp:91] Creating Layer bn5_1
I0624 13:54:13.729878 18353 net.cpp:425] bn5_1 <- conv5_1
I0624 13:54:13.729883 18353 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0624 13:54:13.730049 18353 net.cpp:141] Setting up bn5_1
I0624 13:54:13.730067 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.730069 18353 net.cpp:156] Memory required for data: 103563264
I0624 13:54:13.730075 18353 layer_factory.hpp:77] Creating layer scale5_1
I0624 13:54:13.730082 18353 net.cpp:91] Creating Layer scale5_1
I0624 13:54:13.730083 18353 net.cpp:425] scale5_1 <- conv5_1
I0624 13:54:13.730087 18353 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0624 13:54:13.730124 18353 layer_factory.hpp:77] Creating layer scale5_1
I0624 13:54:13.730216 18353 net.cpp:141] Setting up scale5_1
I0624 13:54:13.730222 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.730224 18353 net.cpp:156] Memory required for data: 103763968
I0624 13:54:13.730228 18353 layer_factory.hpp:77] Creating layer relu5_1
I0624 13:54:13.730233 18353 net.cpp:91] Creating Layer relu5_1
I0624 13:54:13.730237 18353 net.cpp:425] relu5_1 <- conv5_1
I0624 13:54:13.730239 18353 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0624 13:54:13.730514 18353 net.cpp:141] Setting up relu5_1
I0624 13:54:13.730525 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.730526 18353 net.cpp:156] Memory required for data: 103964672
I0624 13:54:13.730530 18353 layer_factory.hpp:77] Creating layer conv5_2
I0624 13:54:13.730537 18353 net.cpp:91] Creating Layer conv5_2
I0624 13:54:13.730540 18353 net.cpp:425] conv5_2 <- conv5_1
I0624 13:54:13.730545 18353 net.cpp:399] conv5_2 -> conv5_2
I0624 13:54:13.735982 18353 net.cpp:141] Setting up conv5_2
I0624 13:54:13.735998 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.736001 18353 net.cpp:156] Memory required for data: 104165376
I0624 13:54:13.736006 18353 layer_factory.hpp:77] Creating layer bn5_2
I0624 13:54:13.736012 18353 net.cpp:91] Creating Layer bn5_2
I0624 13:54:13.736016 18353 net.cpp:425] bn5_2 <- conv5_2
I0624 13:54:13.736021 18353 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0624 13:54:13.736181 18353 net.cpp:141] Setting up bn5_2
I0624 13:54:13.736188 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.736191 18353 net.cpp:156] Memory required for data: 104366080
I0624 13:54:13.736197 18353 layer_factory.hpp:77] Creating layer scale5_2
I0624 13:54:13.736204 18353 net.cpp:91] Creating Layer scale5_2
I0624 13:54:13.736207 18353 net.cpp:425] scale5_2 <- conv5_2
I0624 13:54:13.736210 18353 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0624 13:54:13.736249 18353 layer_factory.hpp:77] Creating layer scale5_2
I0624 13:54:13.736343 18353 net.cpp:141] Setting up scale5_2
I0624 13:54:13.736351 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.736352 18353 net.cpp:156] Memory required for data: 104566784
I0624 13:54:13.736356 18353 layer_factory.hpp:77] Creating layer relu5_2
I0624 13:54:13.736362 18353 net.cpp:91] Creating Layer relu5_2
I0624 13:54:13.736366 18353 net.cpp:425] relu5_2 <- conv5_2
I0624 13:54:13.736368 18353 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0624 13:54:13.736780 18353 net.cpp:141] Setting up relu5_2
I0624 13:54:13.736790 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.736793 18353 net.cpp:156] Memory required for data: 104767488
I0624 13:54:13.736795 18353 layer_factory.hpp:77] Creating layer pool5
I0624 13:54:13.736799 18353 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 13:54:13.736804 18353 net.cpp:91] Creating Layer pool5
I0624 13:54:13.736807 18353 net.cpp:425] pool5 <- conv5_2
I0624 13:54:13.736811 18353 net.cpp:399] pool5 -> pool5
I0624 13:54:13.736816 18353 net.cpp:399] pool5 -> pool5_mask
I0624 13:54:13.736857 18353 net.cpp:141] Setting up pool5
I0624 13:54:13.736865 18353 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 13:54:13.736868 18353 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 13:54:13.736871 18353 net.cpp:156] Memory required for data: 104867840
I0624 13:54:13.736873 18353 layer_factory.hpp:77] Creating layer upsample5
I0624 13:54:13.736881 18353 net.cpp:91] Creating Layer upsample5
I0624 13:54:13.736882 18353 net.cpp:425] upsample5 <- pool5
I0624 13:54:13.736886 18353 net.cpp:425] upsample5 <- pool5_mask
I0624 13:54:13.736901 18353 net.cpp:399] upsample5 -> pool5_D
I0624 13:54:13.736927 18353 net.cpp:141] Setting up upsample5
I0624 13:54:13.736934 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.736937 18353 net.cpp:156] Memory required for data: 105068544
I0624 13:54:13.736938 18353 layer_factory.hpp:77] Creating layer conv5_2_D
I0624 13:54:13.736948 18353 net.cpp:91] Creating Layer conv5_2_D
I0624 13:54:13.736951 18353 net.cpp:425] conv5_2_D <- pool5_D
I0624 13:54:13.736955 18353 net.cpp:399] conv5_2_D -> conv5_2_D
I0624 13:54:13.742444 18353 net.cpp:141] Setting up conv5_2_D
I0624 13:54:13.742456 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.742458 18353 net.cpp:156] Memory required for data: 105269248
I0624 13:54:13.742463 18353 layer_factory.hpp:77] Creating layer bn5_2_D
I0624 13:54:13.742470 18353 net.cpp:91] Creating Layer bn5_2_D
I0624 13:54:13.742473 18353 net.cpp:425] bn5_2_D <- conv5_2_D
I0624 13:54:13.742477 18353 net.cpp:386] bn5_2_D -> conv5_2_D (in-place)
I0624 13:54:13.742645 18353 net.cpp:141] Setting up bn5_2_D
I0624 13:54:13.742651 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.742655 18353 net.cpp:156] Memory required for data: 105469952
I0624 13:54:13.742660 18353 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 13:54:13.742666 18353 net.cpp:91] Creating Layer scale5_2_D
I0624 13:54:13.742669 18353 net.cpp:425] scale5_2_D <- conv5_2_D
I0624 13:54:13.742672 18353 net.cpp:386] scale5_2_D -> conv5_2_D (in-place)
I0624 13:54:13.742709 18353 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 13:54:13.742810 18353 net.cpp:141] Setting up scale5_2_D
I0624 13:54:13.742816 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.742820 18353 net.cpp:156] Memory required for data: 105670656
I0624 13:54:13.742832 18353 layer_factory.hpp:77] Creating layer relu5_2_D
I0624 13:54:13.742837 18353 net.cpp:91] Creating Layer relu5_2_D
I0624 13:54:13.742841 18353 net.cpp:425] relu5_2_D <- conv5_2_D
I0624 13:54:13.742844 18353 net.cpp:386] relu5_2_D -> conv5_2_D (in-place)
I0624 13:54:13.742990 18353 net.cpp:141] Setting up relu5_2_D
I0624 13:54:13.742998 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.743001 18353 net.cpp:156] Memory required for data: 105871360
I0624 13:54:13.743003 18353 layer_factory.hpp:77] Creating layer conv5_1_D
I0624 13:54:13.743011 18353 net.cpp:91] Creating Layer conv5_1_D
I0624 13:54:13.743015 18353 net.cpp:425] conv5_1_D <- conv5_2_D
I0624 13:54:13.743019 18353 net.cpp:399] conv5_1_D -> conv5_1_D
I0624 13:54:13.748525 18353 net.cpp:141] Setting up conv5_1_D
I0624 13:54:13.748538 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.748540 18353 net.cpp:156] Memory required for data: 106072064
I0624 13:54:13.748545 18353 layer_factory.hpp:77] Creating layer bn5_1_D
I0624 13:54:13.748551 18353 net.cpp:91] Creating Layer bn5_1_D
I0624 13:54:13.748553 18353 net.cpp:425] bn5_1_D <- conv5_1_D
I0624 13:54:13.748559 18353 net.cpp:386] bn5_1_D -> conv5_1_D (in-place)
I0624 13:54:13.748738 18353 net.cpp:141] Setting up bn5_1_D
I0624 13:54:13.748745 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.748747 18353 net.cpp:156] Memory required for data: 106272768
I0624 13:54:13.748754 18353 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 13:54:13.748759 18353 net.cpp:91] Creating Layer scale5_1_D
I0624 13:54:13.748761 18353 net.cpp:425] scale5_1_D <- conv5_1_D
I0624 13:54:13.748764 18353 net.cpp:386] scale5_1_D -> conv5_1_D (in-place)
I0624 13:54:13.748798 18353 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 13:54:13.748896 18353 net.cpp:141] Setting up scale5_1_D
I0624 13:54:13.748903 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.748905 18353 net.cpp:156] Memory required for data: 106473472
I0624 13:54:13.748909 18353 layer_factory.hpp:77] Creating layer relu5_1_D
I0624 13:54:13.748914 18353 net.cpp:91] Creating Layer relu5_1_D
I0624 13:54:13.748917 18353 net.cpp:425] relu5_1_D <- conv5_1_D
I0624 13:54:13.748920 18353 net.cpp:386] relu5_1_D -> conv5_1_D (in-place)
I0624 13:54:13.749228 18353 net.cpp:141] Setting up relu5_1_D
I0624 13:54:13.749240 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.749243 18353 net.cpp:156] Memory required for data: 106674176
I0624 13:54:13.749246 18353 layer_factory.hpp:77] Creating layer upsample4
I0624 13:54:13.749253 18353 net.cpp:91] Creating Layer upsample4
I0624 13:54:13.749258 18353 net.cpp:425] upsample4 <- conv5_1_D
I0624 13:54:13.749261 18353 net.cpp:425] upsample4 <- pool4_mask
I0624 13:54:13.749264 18353 net.cpp:399] upsample4 -> pool4_D
I0624 13:54:13.749297 18353 net.cpp:141] Setting up upsample4
I0624 13:54:13.749303 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.749305 18353 net.cpp:156] Memory required for data: 107476992
I0624 13:54:13.749308 18353 layer_factory.hpp:77] Creating layer conv4_2_D
I0624 13:54:13.749316 18353 net.cpp:91] Creating Layer conv4_2_D
I0624 13:54:13.749320 18353 net.cpp:425] conv4_2_D <- pool4_D
I0624 13:54:13.749325 18353 net.cpp:399] conv4_2_D -> conv4_2_D
I0624 13:54:13.754690 18353 net.cpp:141] Setting up conv4_2_D
I0624 13:54:13.754703 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.754705 18353 net.cpp:156] Memory required for data: 108279808
I0624 13:54:13.754710 18353 layer_factory.hpp:77] Creating layer bn4_2_D
I0624 13:54:13.754717 18353 net.cpp:91] Creating Layer bn4_2_D
I0624 13:54:13.754720 18353 net.cpp:425] bn4_2_D <- conv4_2_D
I0624 13:54:13.754725 18353 net.cpp:386] bn4_2_D -> conv4_2_D (in-place)
I0624 13:54:13.754904 18353 net.cpp:141] Setting up bn4_2_D
I0624 13:54:13.754912 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.754914 18353 net.cpp:156] Memory required for data: 109082624
I0624 13:54:13.754920 18353 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 13:54:13.754926 18353 net.cpp:91] Creating Layer scale4_2_D
I0624 13:54:13.754930 18353 net.cpp:425] scale4_2_D <- conv4_2_D
I0624 13:54:13.754932 18353 net.cpp:386] scale4_2_D -> conv4_2_D (in-place)
I0624 13:54:13.754966 18353 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 13:54:13.755067 18353 net.cpp:141] Setting up scale4_2_D
I0624 13:54:13.755074 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.755076 18353 net.cpp:156] Memory required for data: 109885440
I0624 13:54:13.755081 18353 layer_factory.hpp:77] Creating layer relu4_2_D
I0624 13:54:13.755085 18353 net.cpp:91] Creating Layer relu4_2_D
I0624 13:54:13.755087 18353 net.cpp:425] relu4_2_D <- conv4_2_D
I0624 13:54:13.755092 18353 net.cpp:386] relu4_2_D -> conv4_2_D (in-place)
I0624 13:54:13.755380 18353 net.cpp:141] Setting up relu4_2_D
I0624 13:54:13.755391 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.755394 18353 net.cpp:156] Memory required for data: 110688256
I0624 13:54:13.755396 18353 layer_factory.hpp:77] Creating layer conv4_1_D
I0624 13:54:13.755408 18353 net.cpp:91] Creating Layer conv4_1_D
I0624 13:54:13.755410 18353 net.cpp:425] conv4_1_D <- conv4_2_D
I0624 13:54:13.755416 18353 net.cpp:399] conv4_1_D -> conv4_1_D
I0624 13:54:13.758676 18353 net.cpp:141] Setting up conv4_1_D
I0624 13:54:13.758687 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.758688 18353 net.cpp:156] Memory required for data: 111089664
I0624 13:54:13.758693 18353 layer_factory.hpp:77] Creating layer bn4_1_D
I0624 13:54:13.758700 18353 net.cpp:91] Creating Layer bn4_1_D
I0624 13:54:13.758703 18353 net.cpp:425] bn4_1_D <- conv4_1_D
I0624 13:54:13.758708 18353 net.cpp:386] bn4_1_D -> conv4_1_D (in-place)
I0624 13:54:13.758882 18353 net.cpp:141] Setting up bn4_1_D
I0624 13:54:13.758889 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.758893 18353 net.cpp:156] Memory required for data: 111491072
I0624 13:54:13.758898 18353 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 13:54:13.758903 18353 net.cpp:91] Creating Layer scale4_1_D
I0624 13:54:13.758905 18353 net.cpp:425] scale4_1_D <- conv4_1_D
I0624 13:54:13.758913 18353 net.cpp:386] scale4_1_D -> conv4_1_D (in-place)
I0624 13:54:13.758949 18353 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 13:54:13.759066 18353 net.cpp:141] Setting up scale4_1_D
I0624 13:54:13.759073 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.759076 18353 net.cpp:156] Memory required for data: 111892480
I0624 13:54:13.759080 18353 layer_factory.hpp:77] Creating layer relu4_1_D
I0624 13:54:13.759090 18353 net.cpp:91] Creating Layer relu4_1_D
I0624 13:54:13.759095 18353 net.cpp:425] relu4_1_D <- conv4_1_D
I0624 13:54:13.759099 18353 net.cpp:386] relu4_1_D -> conv4_1_D (in-place)
I0624 13:54:13.759265 18353 net.cpp:141] Setting up relu4_1_D
I0624 13:54:13.759274 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.759277 18353 net.cpp:156] Memory required for data: 112293888
I0624 13:54:13.759280 18353 layer_factory.hpp:77] Creating layer upsample3
I0624 13:54:13.759285 18353 net.cpp:91] Creating Layer upsample3
I0624 13:54:13.759289 18353 net.cpp:425] upsample3 <- conv4_1_D
I0624 13:54:13.759292 18353 net.cpp:425] upsample3 <- pool3_mask
I0624 13:54:13.759296 18353 net.cpp:399] upsample3 -> pool3_D
I0624 13:54:13.759325 18353 net.cpp:141] Setting up upsample3
I0624 13:54:13.759331 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.759333 18353 net.cpp:156] Memory required for data: 113899520
I0624 13:54:13.759335 18353 layer_factory.hpp:77] Creating layer conv3_2_D
I0624 13:54:13.759343 18353 net.cpp:91] Creating Layer conv3_2_D
I0624 13:54:13.759346 18353 net.cpp:425] conv3_2_D <- pool3_D
I0624 13:54:13.759351 18353 net.cpp:399] conv3_2_D -> conv3_2_D
I0624 13:54:13.761837 18353 net.cpp:141] Setting up conv3_2_D
I0624 13:54:13.761850 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.761853 18353 net.cpp:156] Memory required for data: 115505152
I0624 13:54:13.761858 18353 layer_factory.hpp:77] Creating layer bn3_2_D
I0624 13:54:13.761868 18353 net.cpp:91] Creating Layer bn3_2_D
I0624 13:54:13.761871 18353 net.cpp:425] bn3_2_D <- conv3_2_D
I0624 13:54:13.761875 18353 net.cpp:386] bn3_2_D -> conv3_2_D (in-place)
I0624 13:54:13.762058 18353 net.cpp:141] Setting up bn3_2_D
I0624 13:54:13.762066 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.762069 18353 net.cpp:156] Memory required for data: 117110784
I0624 13:54:13.762075 18353 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 13:54:13.762082 18353 net.cpp:91] Creating Layer scale3_2_D
I0624 13:54:13.762084 18353 net.cpp:425] scale3_2_D <- conv3_2_D
I0624 13:54:13.762089 18353 net.cpp:386] scale3_2_D -> conv3_2_D (in-place)
I0624 13:54:13.762125 18353 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 13:54:13.762230 18353 net.cpp:141] Setting up scale3_2_D
I0624 13:54:13.762238 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.762240 18353 net.cpp:156] Memory required for data: 118716416
I0624 13:54:13.762244 18353 layer_factory.hpp:77] Creating layer relu3_2_D
I0624 13:54:13.762249 18353 net.cpp:91] Creating Layer relu3_2_D
I0624 13:54:13.762253 18353 net.cpp:425] relu3_2_D <- conv3_2_D
I0624 13:54:13.762255 18353 net.cpp:386] relu3_2_D -> conv3_2_D (in-place)
I0624 13:54:13.762543 18353 net.cpp:141] Setting up relu3_2_D
I0624 13:54:13.762554 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.762557 18353 net.cpp:156] Memory required for data: 120322048
I0624 13:54:13.762559 18353 layer_factory.hpp:77] Creating layer conv3_1_D
I0624 13:54:13.762568 18353 net.cpp:91] Creating Layer conv3_1_D
I0624 13:54:13.762572 18353 net.cpp:425] conv3_1_D <- conv3_2_D
I0624 13:54:13.762575 18353 net.cpp:399] conv3_1_D -> conv3_1_D
I0624 13:54:13.763978 18353 net.cpp:141] Setting up conv3_1_D
I0624 13:54:13.763990 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.763993 18353 net.cpp:156] Memory required for data: 121124864
I0624 13:54:13.763998 18353 layer_factory.hpp:77] Creating layer bn3_1_D
I0624 13:54:13.764004 18353 net.cpp:91] Creating Layer bn3_1_D
I0624 13:54:13.764008 18353 net.cpp:425] bn3_1_D <- conv3_1_D
I0624 13:54:13.764011 18353 net.cpp:386] bn3_1_D -> conv3_1_D (in-place)
I0624 13:54:13.764202 18353 net.cpp:141] Setting up bn3_1_D
I0624 13:54:13.764219 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.764221 18353 net.cpp:156] Memory required for data: 121927680
I0624 13:54:13.764226 18353 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 13:54:13.764232 18353 net.cpp:91] Creating Layer scale3_1_D
I0624 13:54:13.764235 18353 net.cpp:425] scale3_1_D <- conv3_1_D
I0624 13:54:13.764240 18353 net.cpp:386] scale3_1_D -> conv3_1_D (in-place)
I0624 13:54:13.764282 18353 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 13:54:13.764396 18353 net.cpp:141] Setting up scale3_1_D
I0624 13:54:13.764403 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.764406 18353 net.cpp:156] Memory required for data: 122730496
I0624 13:54:13.764410 18353 layer_factory.hpp:77] Creating layer relu3_1_D
I0624 13:54:13.764415 18353 net.cpp:91] Creating Layer relu3_1_D
I0624 13:54:13.764417 18353 net.cpp:425] relu3_1_D <- conv3_1_D
I0624 13:54:13.764421 18353 net.cpp:386] relu3_1_D -> conv3_1_D (in-place)
I0624 13:54:13.764737 18353 net.cpp:141] Setting up relu3_1_D
I0624 13:54:13.764750 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.764752 18353 net.cpp:156] Memory required for data: 123533312
I0624 13:54:13.764755 18353 layer_factory.hpp:77] Creating layer upsample2
I0624 13:54:13.764760 18353 net.cpp:91] Creating Layer upsample2
I0624 13:54:13.764763 18353 net.cpp:425] upsample2 <- conv3_1_D
I0624 13:54:13.764766 18353 net.cpp:425] upsample2 <- pool2_mask
I0624 13:54:13.764770 18353 net.cpp:399] upsample2 -> pool2_D
I0624 13:54:13.764803 18353 net.cpp:141] Setting up upsample2
I0624 13:54:13.764809 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.764811 18353 net.cpp:156] Memory required for data: 126744576
I0624 13:54:13.764814 18353 layer_factory.hpp:77] Creating layer conv2_2_D
I0624 13:54:13.764822 18353 net.cpp:91] Creating Layer conv2_2_D
I0624 13:54:13.764824 18353 net.cpp:425] conv2_2_D <- pool2_D
I0624 13:54:13.764828 18353 net.cpp:399] conv2_2_D -> conv2_2_D
I0624 13:54:13.766047 18353 net.cpp:141] Setting up conv2_2_D
I0624 13:54:13.766062 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.766065 18353 net.cpp:156] Memory required for data: 129955840
I0624 13:54:13.766072 18353 layer_factory.hpp:77] Creating layer bn2_2_D
I0624 13:54:13.766083 18353 net.cpp:91] Creating Layer bn2_2_D
I0624 13:54:13.766088 18353 net.cpp:425] bn2_2_D <- conv2_2_D
I0624 13:54:13.766098 18353 net.cpp:386] bn2_2_D -> conv2_2_D (in-place)
I0624 13:54:13.766311 18353 net.cpp:141] Setting up bn2_2_D
I0624 13:54:13.766321 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.766326 18353 net.cpp:156] Memory required for data: 133167104
I0624 13:54:13.766335 18353 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 13:54:13.766347 18353 net.cpp:91] Creating Layer scale2_2_D
I0624 13:54:13.766353 18353 net.cpp:425] scale2_2_D <- conv2_2_D
I0624 13:54:13.766360 18353 net.cpp:386] scale2_2_D -> conv2_2_D (in-place)
I0624 13:54:13.766410 18353 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 13:54:13.766551 18353 net.cpp:141] Setting up scale2_2_D
I0624 13:54:13.766561 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.766566 18353 net.cpp:156] Memory required for data: 136378368
I0624 13:54:13.766572 18353 layer_factory.hpp:77] Creating layer relu2_2_D
I0624 13:54:13.766580 18353 net.cpp:91] Creating Layer relu2_2_D
I0624 13:54:13.766584 18353 net.cpp:425] relu2_2_D <- conv2_2_D
I0624 13:54:13.766593 18353 net.cpp:386] relu2_2_D -> conv2_2_D (in-place)
I0624 13:54:13.766755 18353 net.cpp:141] Setting up relu2_2_D
I0624 13:54:13.766768 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.766773 18353 net.cpp:156] Memory required for data: 139589632
I0624 13:54:13.766777 18353 layer_factory.hpp:77] Creating layer conv2_1_D
I0624 13:54:13.766788 18353 net.cpp:91] Creating Layer conv2_1_D
I0624 13:54:13.766793 18353 net.cpp:425] conv2_1_D <- conv2_2_D
I0624 13:54:13.766801 18353 net.cpp:399] conv2_1_D -> conv2_1_D
I0624 13:54:13.768007 18353 net.cpp:141] Setting up conv2_1_D
I0624 13:54:13.768029 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.768034 18353 net.cpp:156] Memory required for data: 141195264
I0624 13:54:13.768041 18353 layer_factory.hpp:77] Creating layer bn2_1_D
I0624 13:54:13.768052 18353 net.cpp:91] Creating Layer bn2_1_D
I0624 13:54:13.768059 18353 net.cpp:425] bn2_1_D <- conv2_1_D
I0624 13:54:13.768069 18353 net.cpp:386] bn2_1_D -> conv2_1_D (in-place)
I0624 13:54:13.768271 18353 net.cpp:141] Setting up bn2_1_D
I0624 13:54:13.768282 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.768286 18353 net.cpp:156] Memory required for data: 142800896
I0624 13:54:13.768296 18353 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 13:54:13.768307 18353 net.cpp:91] Creating Layer scale2_1_D
I0624 13:54:13.768312 18353 net.cpp:425] scale2_1_D <- conv2_1_D
I0624 13:54:13.768319 18353 net.cpp:386] scale2_1_D -> conv2_1_D (in-place)
I0624 13:54:13.768369 18353 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 13:54:13.768512 18353 net.cpp:141] Setting up scale2_1_D
I0624 13:54:13.768522 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.768527 18353 net.cpp:156] Memory required for data: 144406528
I0624 13:54:13.768534 18353 layer_factory.hpp:77] Creating layer relu2_1_D
I0624 13:54:13.768542 18353 net.cpp:91] Creating Layer relu2_1_D
I0624 13:54:13.768546 18353 net.cpp:425] relu2_1_D <- conv2_1_D
I0624 13:54:13.768555 18353 net.cpp:386] relu2_1_D -> conv2_1_D (in-place)
I0624 13:54:13.768847 18353 net.cpp:141] Setting up relu2_1_D
I0624 13:54:13.768860 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.768864 18353 net.cpp:156] Memory required for data: 146012160
I0624 13:54:13.768936 18353 layer_factory.hpp:77] Creating layer upsample1
I0624 13:54:13.768947 18353 net.cpp:91] Creating Layer upsample1
I0624 13:54:13.768954 18353 net.cpp:425] upsample1 <- conv2_1_D
I0624 13:54:13.768959 18353 net.cpp:425] upsample1 <- pool1_mask
I0624 13:54:13.768966 18353 net.cpp:399] upsample1 -> pool1_D
I0624 13:54:13.769006 18353 net.cpp:141] Setting up upsample1
I0624 13:54:13.769016 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.769019 18353 net.cpp:156] Memory required for data: 152434688
I0624 13:54:13.769023 18353 layer_factory.hpp:77] Creating layer conv1_2_D
I0624 13:54:13.769035 18353 net.cpp:91] Creating Layer conv1_2_D
I0624 13:54:13.769042 18353 net.cpp:425] conv1_2_D <- pool1_D
I0624 13:54:13.769050 18353 net.cpp:399] conv1_2_D -> conv1_2_D
I0624 13:54:13.770006 18353 net.cpp:141] Setting up conv1_2_D
I0624 13:54:13.770020 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.770025 18353 net.cpp:156] Memory required for data: 158857216
I0624 13:54:13.770033 18353 layer_factory.hpp:77] Creating layer bn1_2_D
I0624 13:54:13.770045 18353 net.cpp:91] Creating Layer bn1_2_D
I0624 13:54:13.770051 18353 net.cpp:425] bn1_2_D <- conv1_2_D
I0624 13:54:13.770057 18353 net.cpp:386] bn1_2_D -> conv1_2_D (in-place)
I0624 13:54:13.770301 18353 net.cpp:141] Setting up bn1_2_D
I0624 13:54:13.770313 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.770316 18353 net.cpp:156] Memory required for data: 165279744
I0624 13:54:13.770326 18353 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 13:54:13.770337 18353 net.cpp:91] Creating Layer scale1_2_D
I0624 13:54:13.770344 18353 net.cpp:425] scale1_2_D <- conv1_2_D
I0624 13:54:13.770350 18353 net.cpp:386] scale1_2_D -> conv1_2_D (in-place)
I0624 13:54:13.770401 18353 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 13:54:13.770606 18353 net.cpp:141] Setting up scale1_2_D
I0624 13:54:13.770615 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.770619 18353 net.cpp:156] Memory required for data: 171702272
I0624 13:54:13.770627 18353 layer_factory.hpp:77] Creating layer relu1_2_D
I0624 13:54:13.770634 18353 net.cpp:91] Creating Layer relu1_2_D
I0624 13:54:13.770638 18353 net.cpp:425] relu1_2_D <- conv1_2_D
I0624 13:54:13.770647 18353 net.cpp:386] relu1_2_D -> conv1_2_D (in-place)
I0624 13:54:13.770954 18353 net.cpp:141] Setting up relu1_2_D
I0624 13:54:13.770967 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.770972 18353 net.cpp:156] Memory required for data: 178124800
I0624 13:54:13.770975 18353 layer_factory.hpp:77] Creating layer conv1_1_D
I0624 13:54:13.770993 18353 net.cpp:91] Creating Layer conv1_1_D
I0624 13:54:13.771000 18353 net.cpp:425] conv1_1_D <- conv1_2_D
I0624 13:54:13.771009 18353 net.cpp:399] conv1_1_D -> conv1_1_D
I0624 13:54:13.773851 18353 net.cpp:141] Setting up conv1_1_D
I0624 13:54:13.773866 18353 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 13:54:13.773870 18353 net.cpp:156] Memory required for data: 178526208
I0624 13:54:13.773880 18353 layer_factory.hpp:77] Creating layer conv1_1_D_conv1_1_D_0_split
I0624 13:54:13.773890 18353 net.cpp:91] Creating Layer conv1_1_D_conv1_1_D_0_split
I0624 13:54:13.773895 18353 net.cpp:425] conv1_1_D_conv1_1_D_0_split <- conv1_1_D
I0624 13:54:13.773902 18353 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_0
I0624 13:54:13.773911 18353 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_1
I0624 13:54:13.773965 18353 net.cpp:141] Setting up conv1_1_D_conv1_1_D_0_split
I0624 13:54:13.773975 18353 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 13:54:13.773980 18353 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 13:54:13.773984 18353 net.cpp:156] Memory required for data: 179329024
I0624 13:54:13.773988 18353 layer_factory.hpp:77] Creating layer loss
I0624 13:54:13.773998 18353 net.cpp:91] Creating Layer loss
I0624 13:54:13.774003 18353 net.cpp:425] loss <- conv1_1_D_conv1_1_D_0_split_0
I0624 13:54:13.774008 18353 net.cpp:425] loss <- label_data_1_split_0
I0624 13:54:13.774014 18353 net.cpp:399] loss -> loss
I0624 13:54:13.774026 18353 layer_factory.hpp:77] Creating layer loss
I0624 13:54:13.774971 18353 net.cpp:141] Setting up loss
I0624 13:54:13.774983 18353 net.cpp:148] Top shape: (1)
I0624 13:54:13.774987 18353 net.cpp:151]     with loss weight 1
I0624 13:54:13.775012 18353 net.cpp:156] Memory required for data: 179329028
I0624 13:54:13.775017 18353 layer_factory.hpp:77] Creating layer accuracy
I0624 13:54:13.775027 18353 net.cpp:91] Creating Layer accuracy
I0624 13:54:13.775032 18353 net.cpp:425] accuracy <- conv1_1_D_conv1_1_D_0_split_1
I0624 13:54:13.775038 18353 net.cpp:425] accuracy <- label_data_1_split_1
I0624 13:54:13.775045 18353 net.cpp:399] accuracy -> accuracy
I0624 13:54:13.775056 18353 net.cpp:141] Setting up accuracy
I0624 13:54:13.775064 18353 net.cpp:148] Top shape: (1)
I0624 13:54:13.775068 18353 net.cpp:156] Memory required for data: 179329032
I0624 13:54:13.775073 18353 net.cpp:219] accuracy does not need backward computation.
I0624 13:54:13.775077 18353 net.cpp:217] loss needs backward computation.
I0624 13:54:13.775082 18353 net.cpp:217] conv1_1_D_conv1_1_D_0_split needs backward computation.
I0624 13:54:13.775086 18353 net.cpp:217] conv1_1_D needs backward computation.
I0624 13:54:13.775091 18353 net.cpp:217] relu1_2_D needs backward computation.
I0624 13:54:13.775094 18353 net.cpp:217] scale1_2_D needs backward computation.
I0624 13:54:13.775099 18353 net.cpp:217] bn1_2_D needs backward computation.
I0624 13:54:13.775102 18353 net.cpp:217] conv1_2_D needs backward computation.
I0624 13:54:13.775106 18353 net.cpp:217] upsample1 needs backward computation.
I0624 13:54:13.775110 18353 net.cpp:217] relu2_1_D needs backward computation.
I0624 13:54:13.775115 18353 net.cpp:217] scale2_1_D needs backward computation.
I0624 13:54:13.775118 18353 net.cpp:217] bn2_1_D needs backward computation.
I0624 13:54:13.775121 18353 net.cpp:217] conv2_1_D needs backward computation.
I0624 13:54:13.775125 18353 net.cpp:217] relu2_2_D needs backward computation.
I0624 13:54:13.775130 18353 net.cpp:217] scale2_2_D needs backward computation.
I0624 13:54:13.775133 18353 net.cpp:217] bn2_2_D needs backward computation.
I0624 13:54:13.775137 18353 net.cpp:217] conv2_2_D needs backward computation.
I0624 13:54:13.775141 18353 net.cpp:217] upsample2 needs backward computation.
I0624 13:54:13.775166 18353 net.cpp:217] relu3_1_D needs backward computation.
I0624 13:54:13.775171 18353 net.cpp:217] scale3_1_D needs backward computation.
I0624 13:54:13.775174 18353 net.cpp:217] bn3_1_D needs backward computation.
I0624 13:54:13.775178 18353 net.cpp:217] conv3_1_D needs backward computation.
I0624 13:54:13.775182 18353 net.cpp:217] relu3_2_D needs backward computation.
I0624 13:54:13.775188 18353 net.cpp:217] scale3_2_D needs backward computation.
I0624 13:54:13.775192 18353 net.cpp:217] bn3_2_D needs backward computation.
I0624 13:54:13.775197 18353 net.cpp:217] conv3_2_D needs backward computation.
I0624 13:54:13.775202 18353 net.cpp:217] upsample3 needs backward computation.
I0624 13:54:13.775207 18353 net.cpp:217] relu4_1_D needs backward computation.
I0624 13:54:13.775210 18353 net.cpp:217] scale4_1_D needs backward computation.
I0624 13:54:13.775214 18353 net.cpp:217] bn4_1_D needs backward computation.
I0624 13:54:13.775218 18353 net.cpp:217] conv4_1_D needs backward computation.
I0624 13:54:13.775223 18353 net.cpp:217] relu4_2_D needs backward computation.
I0624 13:54:13.775226 18353 net.cpp:217] scale4_2_D needs backward computation.
I0624 13:54:13.775230 18353 net.cpp:217] bn4_2_D needs backward computation.
I0624 13:54:13.775234 18353 net.cpp:217] conv4_2_D needs backward computation.
I0624 13:54:13.775238 18353 net.cpp:217] upsample4 needs backward computation.
I0624 13:54:13.775243 18353 net.cpp:217] relu5_1_D needs backward computation.
I0624 13:54:13.775248 18353 net.cpp:217] scale5_1_D needs backward computation.
I0624 13:54:13.775251 18353 net.cpp:217] bn5_1_D needs backward computation.
I0624 13:54:13.775255 18353 net.cpp:217] conv5_1_D needs backward computation.
I0624 13:54:13.775259 18353 net.cpp:217] relu5_2_D needs backward computation.
I0624 13:54:13.775264 18353 net.cpp:217] scale5_2_D needs backward computation.
I0624 13:54:13.775267 18353 net.cpp:217] bn5_2_D needs backward computation.
I0624 13:54:13.775271 18353 net.cpp:217] conv5_2_D needs backward computation.
I0624 13:54:13.775275 18353 net.cpp:217] upsample5 needs backward computation.
I0624 13:54:13.775280 18353 net.cpp:217] pool5 needs backward computation.
I0624 13:54:13.775285 18353 net.cpp:217] relu5_2 needs backward computation.
I0624 13:54:13.775290 18353 net.cpp:217] scale5_2 needs backward computation.
I0624 13:54:13.775293 18353 net.cpp:217] bn5_2 needs backward computation.
I0624 13:54:13.775296 18353 net.cpp:217] conv5_2 needs backward computation.
I0624 13:54:13.775300 18353 net.cpp:217] relu5_1 needs backward computation.
I0624 13:54:13.775305 18353 net.cpp:217] scale5_1 needs backward computation.
I0624 13:54:13.775308 18353 net.cpp:217] bn5_1 needs backward computation.
I0624 13:54:13.775312 18353 net.cpp:217] conv5_1 needs backward computation.
I0624 13:54:13.775316 18353 net.cpp:217] pool4 needs backward computation.
I0624 13:54:13.775323 18353 net.cpp:217] relu4_2 needs backward computation.
I0624 13:54:13.775327 18353 net.cpp:217] scale4_2 needs backward computation.
I0624 13:54:13.775331 18353 net.cpp:217] bn4_2 needs backward computation.
I0624 13:54:13.775336 18353 net.cpp:217] conv4_2 needs backward computation.
I0624 13:54:13.775339 18353 net.cpp:217] relu4_1 needs backward computation.
I0624 13:54:13.775343 18353 net.cpp:217] scale4_1 needs backward computation.
I0624 13:54:13.775347 18353 net.cpp:217] bn4_1 needs backward computation.
I0624 13:54:13.775352 18353 net.cpp:217] conv4_1 needs backward computation.
I0624 13:54:13.775355 18353 net.cpp:217] pool3 needs backward computation.
I0624 13:54:13.775359 18353 net.cpp:217] relu3_2 needs backward computation.
I0624 13:54:13.775363 18353 net.cpp:217] scale3_2 needs backward computation.
I0624 13:54:13.775367 18353 net.cpp:217] bn3_2 needs backward computation.
I0624 13:54:13.775372 18353 net.cpp:217] conv3_2 needs backward computation.
I0624 13:54:13.775375 18353 net.cpp:217] relu3_1 needs backward computation.
I0624 13:54:13.775379 18353 net.cpp:217] scale3_1 needs backward computation.
I0624 13:54:13.775383 18353 net.cpp:217] bn3_1 needs backward computation.
I0624 13:54:13.776978 18353 net.cpp:217] conv3_1 needs backward computation.
I0624 13:54:13.776996 18353 net.cpp:217] pool2 needs backward computation.
I0624 13:54:13.777005 18353 net.cpp:217] relu2_2 needs backward computation.
I0624 13:54:13.777015 18353 net.cpp:217] scale2_2 needs backward computation.
I0624 13:54:13.777024 18353 net.cpp:217] bn2_2 needs backward computation.
I0624 13:54:13.777029 18353 net.cpp:217] conv2_2 needs backward computation.
I0624 13:54:13.777036 18353 net.cpp:217] relu2_1 needs backward computation.
I0624 13:54:13.777042 18353 net.cpp:217] scale2_1 needs backward computation.
I0624 13:54:13.777050 18353 net.cpp:217] bn2_1 needs backward computation.
I0624 13:54:13.777055 18353 net.cpp:217] conv2_1 needs backward computation.
I0624 13:54:13.777060 18353 net.cpp:217] pool1 needs backward computation.
I0624 13:54:13.777068 18353 net.cpp:217] relu1_2 needs backward computation.
I0624 13:54:13.777076 18353 net.cpp:217] scale1_2 needs backward computation.
I0624 13:54:13.777082 18353 net.cpp:217] bn1_2 needs backward computation.
I0624 13:54:13.777087 18353 net.cpp:217] conv1_2 needs backward computation.
I0624 13:54:13.777096 18353 net.cpp:217] relu1_1 needs backward computation.
I0624 13:54:13.777101 18353 net.cpp:217] scale1_1 needs backward computation.
I0624 13:54:13.777107 18353 net.cpp:217] bn1_1 needs backward computation.
I0624 13:54:13.777113 18353 net.cpp:217] conv1_1 needs backward computation.
I0624 13:54:13.777122 18353 net.cpp:219] label_data_1_split does not need backward computation.
I0624 13:54:13.777132 18353 net.cpp:219] data does not need backward computation.
I0624 13:54:13.777138 18353 net.cpp:261] This network produces output accuracy
I0624 13:54:13.777146 18353 net.cpp:261] This network produces output loss
I0624 13:54:13.777241 18353 net.cpp:274] Network initialization done.
I0624 13:54:13.781112 18353 solver.cpp:181] Creating test net (#0) specified by net file: models/segnet/train_val.prototxt
I0624 13:54:13.781314 18353 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0624 13:54:13.782488 18353 net.cpp:49] Initializing net from parameters: 
name: "segnet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "DenseImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 224
    mean_value: 100
  }
  dense_image_data_param {
    source: "data/val_seg.txt"
    batch_size: 1
    shuffle: true
    new_height: 224
    new_width: 310
    is_color: false
    root_folder: "data/raw/train/"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 14
    upsample_w: 14
  }
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2_D"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2_D"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1_D"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1_D"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 28
    upsample_w: 28
  }
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2_D"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2_D"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1_D"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1_D"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
    upsample_h: 56
    upsample_w: 56
  }
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn3_2_D"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2_D"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1_D"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1_D"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
    upsample_h: 112
    upsample_w: 112
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2_D"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2_D"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1_D"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1_D"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
    upsample_h: 224
    upsample_w: 224
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2_D"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2_D"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2
    bias_term: true
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "accuracy"
}
I0624 13:54:13.783102 18353 layer_factory.hpp:77] Creating layer data
I0624 13:54:13.783130 18353 net.cpp:91] Creating Layer data
I0624 13:54:13.783139 18353 net.cpp:399] data -> data
I0624 13:54:13.783165 18353 net.cpp:399] data -> label
I0624 13:54:13.783186 18353 dense_image_data_layer.cpp:38] Opening file data/val_seg.txt
I0624 13:54:13.784307 18353 dense_image_data_layer.cpp:48] Shuffling data
I0624 13:54:13.784400 18353 dense_image_data_layer.cpp:53] A total of 299 examples.
I0624 13:54:13.795824 18353 dense_image_data_layer.cpp:92] output data size: 1,1,224,224
I0624 13:54:13.796893 18353 net.cpp:141] Setting up data
I0624 13:54:13.796916 18353 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 13:54:13.796929 18353 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 13:54:13.796936 18353 net.cpp:156] Memory required for data: 401408
I0624 13:54:13.796946 18353 layer_factory.hpp:77] Creating layer label_data_1_split
I0624 13:54:13.796963 18353 net.cpp:91] Creating Layer label_data_1_split
I0624 13:54:13.796975 18353 net.cpp:425] label_data_1_split <- label
I0624 13:54:13.796986 18353 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0624 13:54:13.797003 18353 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0624 13:54:13.797103 18353 net.cpp:141] Setting up label_data_1_split
I0624 13:54:13.797116 18353 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 13:54:13.797130 18353 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 13:54:13.797137 18353 net.cpp:156] Memory required for data: 802816
I0624 13:54:13.797143 18353 layer_factory.hpp:77] Creating layer conv1_1
I0624 13:54:13.797163 18353 net.cpp:91] Creating Layer conv1_1
I0624 13:54:13.797171 18353 net.cpp:425] conv1_1 <- data
I0624 13:54:13.797180 18353 net.cpp:399] conv1_1 -> conv1_1
I0624 13:54:13.799989 18353 net.cpp:141] Setting up conv1_1
I0624 13:54:13.800020 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.800034 18353 net.cpp:156] Memory required for data: 7225344
I0624 13:54:13.800057 18353 layer_factory.hpp:77] Creating layer bn1_1
I0624 13:54:13.800073 18353 net.cpp:91] Creating Layer bn1_1
I0624 13:54:13.800086 18353 net.cpp:425] bn1_1 <- conv1_1
I0624 13:54:13.800098 18353 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0624 13:54:13.802209 18353 net.cpp:141] Setting up bn1_1
I0624 13:54:13.802243 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.802259 18353 net.cpp:156] Memory required for data: 13647872
I0624 13:54:13.802294 18353 layer_factory.hpp:77] Creating layer scale1_1
I0624 13:54:13.802322 18353 net.cpp:91] Creating Layer scale1_1
I0624 13:54:13.802337 18353 net.cpp:425] scale1_1 <- conv1_1
I0624 13:54:13.802356 18353 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0624 13:54:13.802507 18353 layer_factory.hpp:77] Creating layer scale1_1
I0624 13:54:13.803035 18353 net.cpp:141] Setting up scale1_1
I0624 13:54:13.803059 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.803066 18353 net.cpp:156] Memory required for data: 20070400
I0624 13:54:13.803105 18353 layer_factory.hpp:77] Creating layer relu1_1
I0624 13:54:13.803119 18353 net.cpp:91] Creating Layer relu1_1
I0624 13:54:13.803127 18353 net.cpp:425] relu1_1 <- conv1_1
I0624 13:54:13.803135 18353 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0624 13:54:13.803726 18353 net.cpp:141] Setting up relu1_1
I0624 13:54:13.803747 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.803755 18353 net.cpp:156] Memory required for data: 26492928
I0624 13:54:13.803761 18353 layer_factory.hpp:77] Creating layer conv1_2
I0624 13:54:13.803778 18353 net.cpp:91] Creating Layer conv1_2
I0624 13:54:13.803786 18353 net.cpp:425] conv1_2 <- conv1_1
I0624 13:54:13.803795 18353 net.cpp:399] conv1_2 -> conv1_2
I0624 13:54:13.805663 18353 net.cpp:141] Setting up conv1_2
I0624 13:54:13.805686 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.805693 18353 net.cpp:156] Memory required for data: 32915456
I0624 13:54:13.805703 18353 layer_factory.hpp:77] Creating layer bn1_2
I0624 13:54:13.805716 18353 net.cpp:91] Creating Layer bn1_2
I0624 13:54:13.805723 18353 net.cpp:425] bn1_2 <- conv1_2
I0624 13:54:13.805732 18353 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0624 13:54:13.806192 18353 net.cpp:141] Setting up bn1_2
I0624 13:54:13.806205 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.806210 18353 net.cpp:156] Memory required for data: 39337984
I0624 13:54:13.806227 18353 layer_factory.hpp:77] Creating layer scale1_2
I0624 13:54:13.806241 18353 net.cpp:91] Creating Layer scale1_2
I0624 13:54:13.806247 18353 net.cpp:425] scale1_2 <- conv1_2
I0624 13:54:13.806255 18353 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0624 13:54:13.806336 18353 layer_factory.hpp:77] Creating layer scale1_2
I0624 13:54:13.807588 18353 net.cpp:141] Setting up scale1_2
I0624 13:54:13.807610 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.807615 18353 net.cpp:156] Memory required for data: 45760512
I0624 13:54:13.807626 18353 layer_factory.hpp:77] Creating layer relu1_2
I0624 13:54:13.807638 18353 net.cpp:91] Creating Layer relu1_2
I0624 13:54:13.807646 18353 net.cpp:425] relu1_2 <- conv1_2
I0624 13:54:13.807653 18353 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0624 13:54:13.808190 18353 net.cpp:141] Setting up relu1_2
I0624 13:54:13.808210 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.808215 18353 net.cpp:156] Memory required for data: 52183040
I0624 13:54:13.808221 18353 layer_factory.hpp:77] Creating layer pool1
I0624 13:54:13.808228 18353 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 13:54:13.808236 18353 net.cpp:91] Creating Layer pool1
I0624 13:54:13.808243 18353 net.cpp:425] pool1 <- conv1_2
I0624 13:54:13.808254 18353 net.cpp:399] pool1 -> pool1
I0624 13:54:13.808264 18353 net.cpp:399] pool1 -> pool1_mask
I0624 13:54:13.808352 18353 net.cpp:141] Setting up pool1
I0624 13:54:13.808363 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.808369 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.808374 18353 net.cpp:156] Memory required for data: 55394304
I0624 13:54:13.808379 18353 layer_factory.hpp:77] Creating layer conv2_1
I0624 13:54:13.808393 18353 net.cpp:91] Creating Layer conv2_1
I0624 13:54:13.808398 18353 net.cpp:425] conv2_1 <- pool1
I0624 13:54:13.808408 18353 net.cpp:399] conv2_1 -> conv2_1
I0624 13:54:13.810555 18353 net.cpp:141] Setting up conv2_1
I0624 13:54:13.810577 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.810583 18353 net.cpp:156] Memory required for data: 58605568
I0624 13:54:13.810592 18353 layer_factory.hpp:77] Creating layer bn2_1
I0624 13:54:13.810602 18353 net.cpp:91] Creating Layer bn2_1
I0624 13:54:13.810608 18353 net.cpp:425] bn2_1 <- conv2_1
I0624 13:54:13.810617 18353 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0624 13:54:13.811063 18353 net.cpp:141] Setting up bn2_1
I0624 13:54:13.811075 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.811080 18353 net.cpp:156] Memory required for data: 61816832
I0624 13:54:13.811112 18353 layer_factory.hpp:77] Creating layer scale2_1
I0624 13:54:13.811125 18353 net.cpp:91] Creating Layer scale2_1
I0624 13:54:13.811131 18353 net.cpp:425] scale2_1 <- conv2_1
I0624 13:54:13.811138 18353 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0624 13:54:13.811235 18353 layer_factory.hpp:77] Creating layer scale2_1
I0624 13:54:13.811573 18353 net.cpp:141] Setting up scale2_1
I0624 13:54:13.811589 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.811594 18353 net.cpp:156] Memory required for data: 65028096
I0624 13:54:13.811610 18353 layer_factory.hpp:77] Creating layer relu2_1
I0624 13:54:13.811619 18353 net.cpp:91] Creating Layer relu2_1
I0624 13:54:13.811625 18353 net.cpp:425] relu2_1 <- conv2_1
I0624 13:54:13.811633 18353 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0624 13:54:13.811961 18353 net.cpp:141] Setting up relu2_1
I0624 13:54:13.811976 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.811981 18353 net.cpp:156] Memory required for data: 68239360
I0624 13:54:13.811986 18353 layer_factory.hpp:77] Creating layer conv2_2
I0624 13:54:13.812000 18353 net.cpp:91] Creating Layer conv2_2
I0624 13:54:13.812005 18353 net.cpp:425] conv2_2 <- conv2_1
I0624 13:54:13.812013 18353 net.cpp:399] conv2_2 -> conv2_2
I0624 13:54:13.814687 18353 net.cpp:141] Setting up conv2_2
I0624 13:54:13.814709 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.814715 18353 net.cpp:156] Memory required for data: 71450624
I0624 13:54:13.814724 18353 layer_factory.hpp:77] Creating layer bn2_2
I0624 13:54:13.814738 18353 net.cpp:91] Creating Layer bn2_2
I0624 13:54:13.814743 18353 net.cpp:425] bn2_2 <- conv2_2
I0624 13:54:13.814751 18353 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0624 13:54:13.815163 18353 net.cpp:141] Setting up bn2_2
I0624 13:54:13.815176 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.815181 18353 net.cpp:156] Memory required for data: 74661888
I0624 13:54:13.815192 18353 layer_factory.hpp:77] Creating layer scale2_2
I0624 13:54:13.815203 18353 net.cpp:91] Creating Layer scale2_2
I0624 13:54:13.815207 18353 net.cpp:425] scale2_2 <- conv2_2
I0624 13:54:13.815215 18353 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0624 13:54:13.815290 18353 layer_factory.hpp:77] Creating layer scale2_2
I0624 13:54:13.815554 18353 net.cpp:141] Setting up scale2_2
I0624 13:54:13.815567 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.815572 18353 net.cpp:156] Memory required for data: 77873152
I0624 13:54:13.815579 18353 layer_factory.hpp:77] Creating layer relu2_2
I0624 13:54:13.815587 18353 net.cpp:91] Creating Layer relu2_2
I0624 13:54:13.815593 18353 net.cpp:425] relu2_2 <- conv2_2
I0624 13:54:13.815599 18353 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0624 13:54:13.816112 18353 net.cpp:141] Setting up relu2_2
I0624 13:54:13.816131 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.816136 18353 net.cpp:156] Memory required for data: 81084416
I0624 13:54:13.816141 18353 layer_factory.hpp:77] Creating layer pool2
I0624 13:54:13.816148 18353 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 13:54:13.816155 18353 net.cpp:91] Creating Layer pool2
I0624 13:54:13.816160 18353 net.cpp:425] pool2 <- conv2_2
I0624 13:54:13.816169 18353 net.cpp:399] pool2 -> pool2
I0624 13:54:13.816179 18353 net.cpp:399] pool2 -> pool2_mask
I0624 13:54:13.816258 18353 net.cpp:141] Setting up pool2
I0624 13:54:13.816269 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.816277 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.816280 18353 net.cpp:156] Memory required for data: 82690048
I0624 13:54:13.816285 18353 layer_factory.hpp:77] Creating layer conv3_1
I0624 13:54:13.816298 18353 net.cpp:91] Creating Layer conv3_1
I0624 13:54:13.816303 18353 net.cpp:425] conv3_1 <- pool2
I0624 13:54:13.816310 18353 net.cpp:399] conv3_1 -> conv3_1
I0624 13:54:13.818828 18353 net.cpp:141] Setting up conv3_1
I0624 13:54:13.818848 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.818871 18353 net.cpp:156] Memory required for data: 84295680
I0624 13:54:13.818881 18353 layer_factory.hpp:77] Creating layer bn3_1
I0624 13:54:13.818892 18353 net.cpp:91] Creating Layer bn3_1
I0624 13:54:13.818897 18353 net.cpp:425] bn3_1 <- conv3_1
I0624 13:54:13.818904 18353 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0624 13:54:13.819308 18353 net.cpp:141] Setting up bn3_1
I0624 13:54:13.819320 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.819325 18353 net.cpp:156] Memory required for data: 85901312
I0624 13:54:13.819336 18353 layer_factory.hpp:77] Creating layer scale3_1
I0624 13:54:13.819347 18353 net.cpp:91] Creating Layer scale3_1
I0624 13:54:13.819352 18353 net.cpp:425] scale3_1 <- conv3_1
I0624 13:54:13.819360 18353 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0624 13:54:13.819443 18353 layer_factory.hpp:77] Creating layer scale3_1
I0624 13:54:13.819669 18353 net.cpp:141] Setting up scale3_1
I0624 13:54:13.819681 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.819685 18353 net.cpp:156] Memory required for data: 87506944
I0624 13:54:13.819694 18353 layer_factory.hpp:77] Creating layer relu3_1
I0624 13:54:13.819702 18353 net.cpp:91] Creating Layer relu3_1
I0624 13:54:13.819707 18353 net.cpp:425] relu3_1 <- conv3_1
I0624 13:54:13.819715 18353 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0624 13:54:13.820235 18353 net.cpp:141] Setting up relu3_1
I0624 13:54:13.820255 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.820261 18353 net.cpp:156] Memory required for data: 89112576
I0624 13:54:13.820266 18353 layer_factory.hpp:77] Creating layer conv3_2
I0624 13:54:13.820278 18353 net.cpp:91] Creating Layer conv3_2
I0624 13:54:13.820284 18353 net.cpp:425] conv3_2 <- conv3_1
I0624 13:54:13.820293 18353 net.cpp:399] conv3_2 -> conv3_2
I0624 13:54:13.824807 18353 net.cpp:141] Setting up conv3_2
I0624 13:54:13.824829 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.824834 18353 net.cpp:156] Memory required for data: 90718208
I0624 13:54:13.824843 18353 layer_factory.hpp:77] Creating layer bn3_2
I0624 13:54:13.824853 18353 net.cpp:91] Creating Layer bn3_2
I0624 13:54:13.824858 18353 net.cpp:425] bn3_2 <- conv3_2
I0624 13:54:13.824867 18353 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0624 13:54:13.825243 18353 net.cpp:141] Setting up bn3_2
I0624 13:54:13.825254 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.825259 18353 net.cpp:156] Memory required for data: 92323840
I0624 13:54:13.825278 18353 layer_factory.hpp:77] Creating layer scale3_2
I0624 13:54:13.825287 18353 net.cpp:91] Creating Layer scale3_2
I0624 13:54:13.825292 18353 net.cpp:425] scale3_2 <- conv3_2
I0624 13:54:13.825299 18353 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0624 13:54:13.825390 18353 layer_factory.hpp:77] Creating layer scale3_2
I0624 13:54:13.825623 18353 net.cpp:141] Setting up scale3_2
I0624 13:54:13.825634 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.825639 18353 net.cpp:156] Memory required for data: 93929472
I0624 13:54:13.825647 18353 layer_factory.hpp:77] Creating layer relu3_2
I0624 13:54:13.825655 18353 net.cpp:91] Creating Layer relu3_2
I0624 13:54:13.825660 18353 net.cpp:425] relu3_2 <- conv3_2
I0624 13:54:13.825667 18353 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0624 13:54:13.825971 18353 net.cpp:141] Setting up relu3_2
I0624 13:54:13.825986 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.825990 18353 net.cpp:156] Memory required for data: 95535104
I0624 13:54:13.825995 18353 layer_factory.hpp:77] Creating layer pool3
I0624 13:54:13.826000 18353 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 13:54:13.826009 18353 net.cpp:91] Creating Layer pool3
I0624 13:54:13.826014 18353 net.cpp:425] pool3 <- conv3_2
I0624 13:54:13.826020 18353 net.cpp:399] pool3 -> pool3
I0624 13:54:13.826030 18353 net.cpp:399] pool3 -> pool3_mask
I0624 13:54:13.826105 18353 net.cpp:141] Setting up pool3
I0624 13:54:13.826115 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.826139 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.826144 18353 net.cpp:156] Memory required for data: 96337920
I0624 13:54:13.826148 18353 layer_factory.hpp:77] Creating layer conv4_1
I0624 13:54:13.826160 18353 net.cpp:91] Creating Layer conv4_1
I0624 13:54:13.826165 18353 net.cpp:425] conv4_1 <- pool3
I0624 13:54:13.826174 18353 net.cpp:399] conv4_1 -> conv4_1
I0624 13:54:13.833130 18353 net.cpp:141] Setting up conv4_1
I0624 13:54:13.833155 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.833160 18353 net.cpp:156] Memory required for data: 97140736
I0624 13:54:13.833170 18353 layer_factory.hpp:77] Creating layer bn4_1
I0624 13:54:13.833184 18353 net.cpp:91] Creating Layer bn4_1
I0624 13:54:13.833189 18353 net.cpp:425] bn4_1 <- conv4_1
I0624 13:54:13.833197 18353 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0624 13:54:13.833585 18353 net.cpp:141] Setting up bn4_1
I0624 13:54:13.833596 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.833600 18353 net.cpp:156] Memory required for data: 97943552
I0624 13:54:13.833611 18353 layer_factory.hpp:77] Creating layer scale4_1
I0624 13:54:13.833622 18353 net.cpp:91] Creating Layer scale4_1
I0624 13:54:13.833627 18353 net.cpp:425] scale4_1 <- conv4_1
I0624 13:54:13.833634 18353 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0624 13:54:13.833717 18353 layer_factory.hpp:77] Creating layer scale4_1
I0624 13:54:13.833947 18353 net.cpp:141] Setting up scale4_1
I0624 13:54:13.833961 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.833964 18353 net.cpp:156] Memory required for data: 98746368
I0624 13:54:13.833972 18353 layer_factory.hpp:77] Creating layer relu4_1
I0624 13:54:13.833986 18353 net.cpp:91] Creating Layer relu4_1
I0624 13:54:13.833992 18353 net.cpp:425] relu4_1 <- conv4_1
I0624 13:54:13.833998 18353 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0624 13:54:13.834502 18353 net.cpp:141] Setting up relu4_1
I0624 13:54:13.834522 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.834527 18353 net.cpp:156] Memory required for data: 99549184
I0624 13:54:13.834532 18353 layer_factory.hpp:77] Creating layer conv4_2
I0624 13:54:13.834547 18353 net.cpp:91] Creating Layer conv4_2
I0624 13:54:13.834553 18353 net.cpp:425] conv4_2 <- conv4_1
I0624 13:54:13.834563 18353 net.cpp:399] conv4_2 -> conv4_2
I0624 13:54:13.844169 18353 net.cpp:141] Setting up conv4_2
I0624 13:54:13.844193 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.844198 18353 net.cpp:156] Memory required for data: 100352000
I0624 13:54:13.844207 18353 layer_factory.hpp:77] Creating layer bn4_2
I0624 13:54:13.844219 18353 net.cpp:91] Creating Layer bn4_2
I0624 13:54:13.844225 18353 net.cpp:425] bn4_2 <- conv4_2
I0624 13:54:13.844233 18353 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0624 13:54:13.844595 18353 net.cpp:141] Setting up bn4_2
I0624 13:54:13.844606 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.844610 18353 net.cpp:156] Memory required for data: 101154816
I0624 13:54:13.844620 18353 layer_factory.hpp:77] Creating layer scale4_2
I0624 13:54:13.844630 18353 net.cpp:91] Creating Layer scale4_2
I0624 13:54:13.844635 18353 net.cpp:425] scale4_2 <- conv4_2
I0624 13:54:13.844642 18353 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0624 13:54:13.844708 18353 layer_factory.hpp:77] Creating layer scale4_2
I0624 13:54:13.844924 18353 net.cpp:141] Setting up scale4_2
I0624 13:54:13.844935 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.844939 18353 net.cpp:156] Memory required for data: 101957632
I0624 13:54:13.844947 18353 layer_factory.hpp:77] Creating layer relu4_2
I0624 13:54:13.844955 18353 net.cpp:91] Creating Layer relu4_2
I0624 13:54:13.844959 18353 net.cpp:425] relu4_2 <- conv4_2
I0624 13:54:13.844966 18353 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0624 13:54:13.845439 18353 net.cpp:141] Setting up relu4_2
I0624 13:54:13.845459 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.845464 18353 net.cpp:156] Memory required for data: 102760448
I0624 13:54:13.845468 18353 layer_factory.hpp:77] Creating layer pool4
I0624 13:54:13.845492 18353 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 13:54:13.845500 18353 net.cpp:91] Creating Layer pool4
I0624 13:54:13.845506 18353 net.cpp:425] pool4 <- conv4_2
I0624 13:54:13.845513 18353 net.cpp:399] pool4 -> pool4
I0624 13:54:13.845526 18353 net.cpp:399] pool4 -> pool4_mask
I0624 13:54:13.845610 18353 net.cpp:141] Setting up pool4
I0624 13:54:13.845621 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.845626 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.845630 18353 net.cpp:156] Memory required for data: 103161856
I0624 13:54:13.845634 18353 layer_factory.hpp:77] Creating layer conv5_1
I0624 13:54:13.845652 18353 net.cpp:91] Creating Layer conv5_1
I0624 13:54:13.845657 18353 net.cpp:425] conv5_1 <- pool4
I0624 13:54:13.845669 18353 net.cpp:399] conv5_1 -> conv5_1
I0624 13:54:13.854955 18353 net.cpp:141] Setting up conv5_1
I0624 13:54:13.854975 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.854981 18353 net.cpp:156] Memory required for data: 103362560
I0624 13:54:13.854990 18353 layer_factory.hpp:77] Creating layer bn5_1
I0624 13:54:13.855002 18353 net.cpp:91] Creating Layer bn5_1
I0624 13:54:13.855008 18353 net.cpp:425] bn5_1 <- conv5_1
I0624 13:54:13.855015 18353 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0624 13:54:13.855370 18353 net.cpp:141] Setting up bn5_1
I0624 13:54:13.855381 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.855384 18353 net.cpp:156] Memory required for data: 103563264
I0624 13:54:13.855394 18353 layer_factory.hpp:77] Creating layer scale5_1
I0624 13:54:13.855406 18353 net.cpp:91] Creating Layer scale5_1
I0624 13:54:13.855412 18353 net.cpp:425] scale5_1 <- conv5_1
I0624 13:54:13.855417 18353 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0624 13:54:13.855484 18353 layer_factory.hpp:77] Creating layer scale5_1
I0624 13:54:13.855679 18353 net.cpp:141] Setting up scale5_1
I0624 13:54:13.855689 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.855692 18353 net.cpp:156] Memory required for data: 103763968
I0624 13:54:13.855700 18353 layer_factory.hpp:77] Creating layer relu5_1
I0624 13:54:13.855708 18353 net.cpp:91] Creating Layer relu5_1
I0624 13:54:13.855712 18353 net.cpp:425] relu5_1 <- conv5_1
I0624 13:54:13.855718 18353 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0624 13:54:13.856005 18353 net.cpp:141] Setting up relu5_1
I0624 13:54:13.856019 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.856022 18353 net.cpp:156] Memory required for data: 103964672
I0624 13:54:13.856026 18353 layer_factory.hpp:77] Creating layer conv5_2
I0624 13:54:13.856040 18353 net.cpp:91] Creating Layer conv5_2
I0624 13:54:13.856043 18353 net.cpp:425] conv5_2 <- conv5_1
I0624 13:54:13.856052 18353 net.cpp:399] conv5_2 -> conv5_2
I0624 13:54:13.865741 18353 net.cpp:141] Setting up conv5_2
I0624 13:54:13.865767 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.865773 18353 net.cpp:156] Memory required for data: 104165376
I0624 13:54:13.865782 18353 layer_factory.hpp:77] Creating layer bn5_2
I0624 13:54:13.865792 18353 net.cpp:91] Creating Layer bn5_2
I0624 13:54:13.865798 18353 net.cpp:425] bn5_2 <- conv5_2
I0624 13:54:13.865808 18353 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0624 13:54:13.866147 18353 net.cpp:141] Setting up bn5_2
I0624 13:54:13.866158 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.866161 18353 net.cpp:156] Memory required for data: 104366080
I0624 13:54:13.866170 18353 layer_factory.hpp:77] Creating layer scale5_2
I0624 13:54:13.866179 18353 net.cpp:91] Creating Layer scale5_2
I0624 13:54:13.866184 18353 net.cpp:425] scale5_2 <- conv5_2
I0624 13:54:13.866190 18353 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0624 13:54:13.866255 18353 layer_factory.hpp:77] Creating layer scale5_2
I0624 13:54:13.866466 18353 net.cpp:141] Setting up scale5_2
I0624 13:54:13.866475 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.866479 18353 net.cpp:156] Memory required for data: 104566784
I0624 13:54:13.866504 18353 layer_factory.hpp:77] Creating layer relu5_2
I0624 13:54:13.866514 18353 net.cpp:91] Creating Layer relu5_2
I0624 13:54:13.866519 18353 net.cpp:425] relu5_2 <- conv5_2
I0624 13:54:13.866524 18353 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0624 13:54:13.866982 18353 net.cpp:141] Setting up relu5_2
I0624 13:54:13.866998 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.867002 18353 net.cpp:156] Memory required for data: 104767488
I0624 13:54:13.867007 18353 layer_factory.hpp:77] Creating layer pool5
I0624 13:54:13.867012 18353 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 13:54:13.867018 18353 net.cpp:91] Creating Layer pool5
I0624 13:54:13.867025 18353 net.cpp:425] pool5 <- conv5_2
I0624 13:54:13.867033 18353 net.cpp:399] pool5 -> pool5
I0624 13:54:13.867040 18353 net.cpp:399] pool5 -> pool5_mask
I0624 13:54:13.867125 18353 net.cpp:141] Setting up pool5
I0624 13:54:13.867135 18353 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 13:54:13.867139 18353 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 13:54:13.867143 18353 net.cpp:156] Memory required for data: 104867840
I0624 13:54:13.867147 18353 layer_factory.hpp:77] Creating layer upsample5
I0624 13:54:13.867163 18353 net.cpp:91] Creating Layer upsample5
I0624 13:54:13.867167 18353 net.cpp:425] upsample5 <- pool5
I0624 13:54:13.867173 18353 net.cpp:425] upsample5 <- pool5_mask
I0624 13:54:13.867179 18353 net.cpp:399] upsample5 -> pool5_D
I0624 13:54:13.867223 18353 net.cpp:141] Setting up upsample5
I0624 13:54:13.867233 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.867235 18353 net.cpp:156] Memory required for data: 105068544
I0624 13:54:13.867239 18353 layer_factory.hpp:77] Creating layer conv5_2_D
I0624 13:54:13.867252 18353 net.cpp:91] Creating Layer conv5_2_D
I0624 13:54:13.867256 18353 net.cpp:425] conv5_2_D <- pool5_D
I0624 13:54:13.867264 18353 net.cpp:399] conv5_2_D -> conv5_2_D
I0624 13:54:13.875785 18353 net.cpp:141] Setting up conv5_2_D
I0624 13:54:13.875803 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.875808 18353 net.cpp:156] Memory required for data: 105269248
I0624 13:54:13.875815 18353 layer_factory.hpp:77] Creating layer bn5_2_D
I0624 13:54:13.875825 18353 net.cpp:91] Creating Layer bn5_2_D
I0624 13:54:13.875830 18353 net.cpp:425] bn5_2_D <- conv5_2_D
I0624 13:54:13.875836 18353 net.cpp:386] bn5_2_D -> conv5_2_D (in-place)
I0624 13:54:13.876157 18353 net.cpp:141] Setting up bn5_2_D
I0624 13:54:13.876168 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.876170 18353 net.cpp:156] Memory required for data: 105469952
I0624 13:54:13.876179 18353 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 13:54:13.876189 18353 net.cpp:91] Creating Layer scale5_2_D
I0624 13:54:13.876194 18353 net.cpp:425] scale5_2_D <- conv5_2_D
I0624 13:54:13.876199 18353 net.cpp:386] scale5_2_D -> conv5_2_D (in-place)
I0624 13:54:13.876261 18353 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 13:54:13.876440 18353 net.cpp:141] Setting up scale5_2_D
I0624 13:54:13.876448 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.876452 18353 net.cpp:156] Memory required for data: 105670656
I0624 13:54:13.876471 18353 layer_factory.hpp:77] Creating layer relu5_2_D
I0624 13:54:13.876479 18353 net.cpp:91] Creating Layer relu5_2_D
I0624 13:54:13.876484 18353 net.cpp:425] relu5_2_D <- conv5_2_D
I0624 13:54:13.876489 18353 net.cpp:386] relu5_2_D -> conv5_2_D (in-place)
I0624 13:54:13.876909 18353 net.cpp:141] Setting up relu5_2_D
I0624 13:54:13.876924 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.876929 18353 net.cpp:156] Memory required for data: 105871360
I0624 13:54:13.876932 18353 layer_factory.hpp:77] Creating layer conv5_1_D
I0624 13:54:13.876945 18353 net.cpp:91] Creating Layer conv5_1_D
I0624 13:54:13.876955 18353 net.cpp:425] conv5_1_D <- conv5_2_D
I0624 13:54:13.876961 18353 net.cpp:399] conv5_1_D -> conv5_1_D
I0624 13:54:13.885561 18353 net.cpp:141] Setting up conv5_1_D
I0624 13:54:13.885596 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.885599 18353 net.cpp:156] Memory required for data: 106072064
I0624 13:54:13.885607 18353 layer_factory.hpp:77] Creating layer bn5_1_D
I0624 13:54:13.885615 18353 net.cpp:91] Creating Layer bn5_1_D
I0624 13:54:13.885619 18353 net.cpp:425] bn5_1_D <- conv5_1_D
I0624 13:54:13.885627 18353 net.cpp:386] bn5_1_D -> conv5_1_D (in-place)
I0624 13:54:13.885937 18353 net.cpp:141] Setting up bn5_1_D
I0624 13:54:13.885947 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.885951 18353 net.cpp:156] Memory required for data: 106272768
I0624 13:54:13.885959 18353 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 13:54:13.885967 18353 net.cpp:91] Creating Layer scale5_1_D
I0624 13:54:13.885970 18353 net.cpp:425] scale5_1_D <- conv5_1_D
I0624 13:54:13.885977 18353 net.cpp:386] scale5_1_D -> conv5_1_D (in-place)
I0624 13:54:13.886036 18353 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 13:54:13.886211 18353 net.cpp:141] Setting up scale5_1_D
I0624 13:54:13.886221 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.886224 18353 net.cpp:156] Memory required for data: 106473472
I0624 13:54:13.886231 18353 layer_factory.hpp:77] Creating layer relu5_1_D
I0624 13:54:13.886240 18353 net.cpp:91] Creating Layer relu5_1_D
I0624 13:54:13.886242 18353 net.cpp:425] relu5_1_D <- conv5_1_D
I0624 13:54:13.886248 18353 net.cpp:386] relu5_1_D -> conv5_1_D (in-place)
I0624 13:54:13.886488 18353 net.cpp:141] Setting up relu5_1_D
I0624 13:54:13.886500 18353 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 13:54:13.886503 18353 net.cpp:156] Memory required for data: 106674176
I0624 13:54:13.886507 18353 layer_factory.hpp:77] Creating layer upsample4
I0624 13:54:13.886517 18353 net.cpp:91] Creating Layer upsample4
I0624 13:54:13.886520 18353 net.cpp:425] upsample4 <- conv5_1_D
I0624 13:54:13.886525 18353 net.cpp:425] upsample4 <- pool4_mask
I0624 13:54:13.886533 18353 net.cpp:399] upsample4 -> pool4_D
I0624 13:54:13.886574 18353 net.cpp:141] Setting up upsample4
I0624 13:54:13.886581 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.886584 18353 net.cpp:156] Memory required for data: 107476992
I0624 13:54:13.886587 18353 layer_factory.hpp:77] Creating layer conv4_2_D
I0624 13:54:13.886600 18353 net.cpp:91] Creating Layer conv4_2_D
I0624 13:54:13.886602 18353 net.cpp:425] conv4_2_D <- pool4_D
I0624 13:54:13.886612 18353 net.cpp:399] conv4_2_D -> conv4_2_D
I0624 13:54:13.895184 18353 net.cpp:141] Setting up conv4_2_D
I0624 13:54:13.895205 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.895208 18353 net.cpp:156] Memory required for data: 108279808
I0624 13:54:13.895215 18353 layer_factory.hpp:77] Creating layer bn4_2_D
I0624 13:54:13.895226 18353 net.cpp:91] Creating Layer bn4_2_D
I0624 13:54:13.895231 18353 net.cpp:425] bn4_2_D <- conv4_2_D
I0624 13:54:13.895236 18353 net.cpp:386] bn4_2_D -> conv4_2_D (in-place)
I0624 13:54:13.895558 18353 net.cpp:141] Setting up bn4_2_D
I0624 13:54:13.895567 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.895571 18353 net.cpp:156] Memory required for data: 109082624
I0624 13:54:13.895579 18353 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 13:54:13.895587 18353 net.cpp:91] Creating Layer scale4_2_D
I0624 13:54:13.895591 18353 net.cpp:425] scale4_2_D <- conv4_2_D
I0624 13:54:13.895598 18353 net.cpp:386] scale4_2_D -> conv4_2_D (in-place)
I0624 13:54:13.895655 18353 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 13:54:13.895838 18353 net.cpp:141] Setting up scale4_2_D
I0624 13:54:13.895846 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.895849 18353 net.cpp:156] Memory required for data: 109885440
I0624 13:54:13.895855 18353 layer_factory.hpp:77] Creating layer relu4_2_D
I0624 13:54:13.895862 18353 net.cpp:91] Creating Layer relu4_2_D
I0624 13:54:13.895865 18353 net.cpp:425] relu4_2_D <- conv4_2_D
I0624 13:54:13.895870 18353 net.cpp:386] relu4_2_D -> conv4_2_D (in-place)
I0624 13:54:13.896275 18353 net.cpp:141] Setting up relu4_2_D
I0624 13:54:13.896306 18353 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 13:54:13.896311 18353 net.cpp:156] Memory required for data: 110688256
I0624 13:54:13.896316 18353 layer_factory.hpp:77] Creating layer conv4_1_D
I0624 13:54:13.896325 18353 net.cpp:91] Creating Layer conv4_1_D
I0624 13:54:13.896329 18353 net.cpp:425] conv4_1_D <- conv4_2_D
I0624 13:54:13.896337 18353 net.cpp:399] conv4_1_D -> conv4_1_D
I0624 13:54:13.900950 18353 net.cpp:141] Setting up conv4_1_D
I0624 13:54:13.900966 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.900970 18353 net.cpp:156] Memory required for data: 111089664
I0624 13:54:13.900977 18353 layer_factory.hpp:77] Creating layer bn4_1_D
I0624 13:54:13.900986 18353 net.cpp:91] Creating Layer bn4_1_D
I0624 13:54:13.900991 18353 net.cpp:425] bn4_1_D <- conv4_1_D
I0624 13:54:13.900998 18353 net.cpp:386] bn4_1_D -> conv4_1_D (in-place)
I0624 13:54:13.901309 18353 net.cpp:141] Setting up bn4_1_D
I0624 13:54:13.901317 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.901320 18353 net.cpp:156] Memory required for data: 111491072
I0624 13:54:13.901329 18353 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 13:54:13.901336 18353 net.cpp:91] Creating Layer scale4_1_D
I0624 13:54:13.901340 18353 net.cpp:425] scale4_1_D <- conv4_1_D
I0624 13:54:13.901346 18353 net.cpp:386] scale4_1_D -> conv4_1_D (in-place)
I0624 13:54:13.901404 18353 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 13:54:13.901582 18353 net.cpp:141] Setting up scale4_1_D
I0624 13:54:13.901590 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.901593 18353 net.cpp:156] Memory required for data: 111892480
I0624 13:54:13.901599 18353 layer_factory.hpp:77] Creating layer relu4_1_D
I0624 13:54:13.901614 18353 net.cpp:91] Creating Layer relu4_1_D
I0624 13:54:13.901618 18353 net.cpp:425] relu4_1_D <- conv4_1_D
I0624 13:54:13.901623 18353 net.cpp:386] relu4_1_D -> conv4_1_D (in-place)
I0624 13:54:13.902020 18353 net.cpp:141] Setting up relu4_1_D
I0624 13:54:13.902035 18353 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 13:54:13.902040 18353 net.cpp:156] Memory required for data: 112293888
I0624 13:54:13.902045 18353 layer_factory.hpp:77] Creating layer upsample3
I0624 13:54:13.902051 18353 net.cpp:91] Creating Layer upsample3
I0624 13:54:13.902055 18353 net.cpp:425] upsample3 <- conv4_1_D
I0624 13:54:13.902061 18353 net.cpp:425] upsample3 <- pool3_mask
I0624 13:54:13.902066 18353 net.cpp:399] upsample3 -> pool3_D
I0624 13:54:13.902112 18353 net.cpp:141] Setting up upsample3
I0624 13:54:13.902118 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.902122 18353 net.cpp:156] Memory required for data: 113899520
I0624 13:54:13.902125 18353 layer_factory.hpp:77] Creating layer conv3_2_D
I0624 13:54:13.902137 18353 net.cpp:91] Creating Layer conv3_2_D
I0624 13:54:13.902142 18353 net.cpp:425] conv3_2_D <- pool3_D
I0624 13:54:13.902148 18353 net.cpp:399] conv3_2_D -> conv3_2_D
I0624 13:54:13.905632 18353 net.cpp:141] Setting up conv3_2_D
I0624 13:54:13.905649 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.905653 18353 net.cpp:156] Memory required for data: 115505152
I0624 13:54:13.905661 18353 layer_factory.hpp:77] Creating layer bn3_2_D
I0624 13:54:13.905670 18353 net.cpp:91] Creating Layer bn3_2_D
I0624 13:54:13.905675 18353 net.cpp:425] bn3_2_D <- conv3_2_D
I0624 13:54:13.905683 18353 net.cpp:386] bn3_2_D -> conv3_2_D (in-place)
I0624 13:54:13.905995 18353 net.cpp:141] Setting up bn3_2_D
I0624 13:54:13.906007 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.906009 18353 net.cpp:156] Memory required for data: 117110784
I0624 13:54:13.906018 18353 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 13:54:13.906026 18353 net.cpp:91] Creating Layer scale3_2_D
I0624 13:54:13.906030 18353 net.cpp:425] scale3_2_D <- conv3_2_D
I0624 13:54:13.906036 18353 net.cpp:386] scale3_2_D -> conv3_2_D (in-place)
I0624 13:54:13.906096 18353 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 13:54:13.906270 18353 net.cpp:141] Setting up scale3_2_D
I0624 13:54:13.906291 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.906296 18353 net.cpp:156] Memory required for data: 118716416
I0624 13:54:13.906301 18353 layer_factory.hpp:77] Creating layer relu3_2_D
I0624 13:54:13.906308 18353 net.cpp:91] Creating Layer relu3_2_D
I0624 13:54:13.906311 18353 net.cpp:425] relu3_2_D <- conv3_2_D
I0624 13:54:13.906318 18353 net.cpp:386] relu3_2_D -> conv3_2_D (in-place)
I0624 13:54:13.906553 18353 net.cpp:141] Setting up relu3_2_D
I0624 13:54:13.906566 18353 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 13:54:13.906569 18353 net.cpp:156] Memory required for data: 120322048
I0624 13:54:13.906574 18353 layer_factory.hpp:77] Creating layer conv3_1_D
I0624 13:54:13.906584 18353 net.cpp:91] Creating Layer conv3_1_D
I0624 13:54:13.906586 18353 net.cpp:425] conv3_1_D <- conv3_2_D
I0624 13:54:13.906594 18353 net.cpp:399] conv3_1_D -> conv3_1_D
I0624 13:54:13.908701 18353 net.cpp:141] Setting up conv3_1_D
I0624 13:54:13.908718 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.908722 18353 net.cpp:156] Memory required for data: 121124864
I0624 13:54:13.908728 18353 layer_factory.hpp:77] Creating layer bn3_1_D
I0624 13:54:13.908735 18353 net.cpp:91] Creating Layer bn3_1_D
I0624 13:54:13.908740 18353 net.cpp:425] bn3_1_D <- conv3_1_D
I0624 13:54:13.908746 18353 net.cpp:386] bn3_1_D -> conv3_1_D (in-place)
I0624 13:54:13.909061 18353 net.cpp:141] Setting up bn3_1_D
I0624 13:54:13.909070 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.909073 18353 net.cpp:156] Memory required for data: 121927680
I0624 13:54:13.909081 18353 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 13:54:13.909088 18353 net.cpp:91] Creating Layer scale3_1_D
I0624 13:54:13.909091 18353 net.cpp:425] scale3_1_D <- conv3_1_D
I0624 13:54:13.909098 18353 net.cpp:386] scale3_1_D -> conv3_1_D (in-place)
I0624 13:54:13.909157 18353 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 13:54:13.909399 18353 net.cpp:141] Setting up scale3_1_D
I0624 13:54:13.909409 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.909412 18353 net.cpp:156] Memory required for data: 122730496
I0624 13:54:13.909420 18353 layer_factory.hpp:77] Creating layer relu3_1_D
I0624 13:54:13.909425 18353 net.cpp:91] Creating Layer relu3_1_D
I0624 13:54:13.909430 18353 net.cpp:425] relu3_1_D <- conv3_1_D
I0624 13:54:13.909435 18353 net.cpp:386] relu3_1_D -> conv3_1_D (in-place)
I0624 13:54:13.909842 18353 net.cpp:141] Setting up relu3_1_D
I0624 13:54:13.909855 18353 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 13:54:13.909858 18353 net.cpp:156] Memory required for data: 123533312
I0624 13:54:13.909862 18353 layer_factory.hpp:77] Creating layer upsample2
I0624 13:54:13.909871 18353 net.cpp:91] Creating Layer upsample2
I0624 13:54:13.909875 18353 net.cpp:425] upsample2 <- conv3_1_D
I0624 13:54:13.909880 18353 net.cpp:425] upsample2 <- pool2_mask
I0624 13:54:13.909885 18353 net.cpp:399] upsample2 -> pool2_D
I0624 13:54:13.909931 18353 net.cpp:141] Setting up upsample2
I0624 13:54:13.909937 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.909940 18353 net.cpp:156] Memory required for data: 126744576
I0624 13:54:13.909943 18353 layer_factory.hpp:77] Creating layer conv2_2_D
I0624 13:54:13.909953 18353 net.cpp:91] Creating Layer conv2_2_D
I0624 13:54:13.909957 18353 net.cpp:425] conv2_2_D <- pool2_D
I0624 13:54:13.909965 18353 net.cpp:399] conv2_2_D -> conv2_2_D
I0624 13:54:13.911561 18353 net.cpp:141] Setting up conv2_2_D
I0624 13:54:13.911577 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.911581 18353 net.cpp:156] Memory required for data: 129955840
I0624 13:54:13.911588 18353 layer_factory.hpp:77] Creating layer bn2_2_D
I0624 13:54:13.911597 18353 net.cpp:91] Creating Layer bn2_2_D
I0624 13:54:13.911602 18353 net.cpp:425] bn2_2_D <- conv2_2_D
I0624 13:54:13.911607 18353 net.cpp:386] bn2_2_D -> conv2_2_D (in-place)
I0624 13:54:13.912679 18353 net.cpp:141] Setting up bn2_2_D
I0624 13:54:13.912696 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.912713 18353 net.cpp:156] Memory required for data: 133167104
I0624 13:54:13.912721 18353 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 13:54:13.912730 18353 net.cpp:91] Creating Layer scale2_2_D
I0624 13:54:13.912734 18353 net.cpp:425] scale2_2_D <- conv2_2_D
I0624 13:54:13.912740 18353 net.cpp:386] scale2_2_D -> conv2_2_D (in-place)
I0624 13:54:13.912834 18353 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 13:54:13.913141 18353 net.cpp:141] Setting up scale2_2_D
I0624 13:54:13.913158 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.913164 18353 net.cpp:156] Memory required for data: 136378368
I0624 13:54:13.913174 18353 layer_factory.hpp:77] Creating layer relu2_2_D
I0624 13:54:13.913183 18353 net.cpp:91] Creating Layer relu2_2_D
I0624 13:54:13.913189 18353 net.cpp:425] relu2_2_D <- conv2_2_D
I0624 13:54:13.913197 18353 net.cpp:386] relu2_2_D -> conv2_2_D (in-place)
I0624 13:54:13.913735 18353 net.cpp:141] Setting up relu2_2_D
I0624 13:54:13.913755 18353 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 13:54:13.913761 18353 net.cpp:156] Memory required for data: 139589632
I0624 13:54:13.913767 18353 layer_factory.hpp:77] Creating layer conv2_1_D
I0624 13:54:13.913784 18353 net.cpp:91] Creating Layer conv2_1_D
I0624 13:54:13.913792 18353 net.cpp:425] conv2_1_D <- conv2_2_D
I0624 13:54:13.913803 18353 net.cpp:399] conv2_1_D -> conv2_1_D
I0624 13:54:13.915731 18353 net.cpp:141] Setting up conv2_1_D
I0624 13:54:13.915745 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.915748 18353 net.cpp:156] Memory required for data: 141195264
I0624 13:54:13.915753 18353 layer_factory.hpp:77] Creating layer bn2_1_D
I0624 13:54:13.915761 18353 net.cpp:91] Creating Layer bn2_1_D
I0624 13:54:13.915765 18353 net.cpp:425] bn2_1_D <- conv2_1_D
I0624 13:54:13.915769 18353 net.cpp:386] bn2_1_D -> conv2_1_D (in-place)
I0624 13:54:13.916023 18353 net.cpp:141] Setting up bn2_1_D
I0624 13:54:13.916031 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.916034 18353 net.cpp:156] Memory required for data: 142800896
I0624 13:54:13.916040 18353 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 13:54:13.916046 18353 net.cpp:91] Creating Layer scale2_1_D
I0624 13:54:13.916049 18353 net.cpp:425] scale2_1_D <- conv2_1_D
I0624 13:54:13.916055 18353 net.cpp:386] scale2_1_D -> conv2_1_D (in-place)
I0624 13:54:13.916106 18353 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 13:54:13.916259 18353 net.cpp:141] Setting up scale2_1_D
I0624 13:54:13.916266 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.916268 18353 net.cpp:156] Memory required for data: 144406528
I0624 13:54:13.916273 18353 layer_factory.hpp:77] Creating layer relu2_1_D
I0624 13:54:13.916278 18353 net.cpp:91] Creating Layer relu2_1_D
I0624 13:54:13.916281 18353 net.cpp:425] relu2_1_D <- conv2_1_D
I0624 13:54:13.916286 18353 net.cpp:386] relu2_1_D -> conv2_1_D (in-place)
I0624 13:54:13.916463 18353 net.cpp:141] Setting up relu2_1_D
I0624 13:54:13.916472 18353 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 13:54:13.916474 18353 net.cpp:156] Memory required for data: 146012160
I0624 13:54:13.916478 18353 layer_factory.hpp:77] Creating layer upsample1
I0624 13:54:13.916484 18353 net.cpp:91] Creating Layer upsample1
I0624 13:54:13.916487 18353 net.cpp:425] upsample1 <- conv2_1_D
I0624 13:54:13.916491 18353 net.cpp:425] upsample1 <- pool1_mask
I0624 13:54:13.916496 18353 net.cpp:399] upsample1 -> pool1_D
I0624 13:54:13.916532 18353 net.cpp:141] Setting up upsample1
I0624 13:54:13.916538 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.916540 18353 net.cpp:156] Memory required for data: 152434688
I0624 13:54:13.916543 18353 layer_factory.hpp:77] Creating layer conv1_2_D
I0624 13:54:13.916551 18353 net.cpp:91] Creating Layer conv1_2_D
I0624 13:54:13.916554 18353 net.cpp:425] conv1_2_D <- pool1_D
I0624 13:54:13.916559 18353 net.cpp:399] conv1_2_D -> conv1_2_D
I0624 13:54:13.917834 18353 net.cpp:141] Setting up conv1_2_D
I0624 13:54:13.917847 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.917860 18353 net.cpp:156] Memory required for data: 158857216
I0624 13:54:13.917866 18353 layer_factory.hpp:77] Creating layer bn1_2_D
I0624 13:54:13.917875 18353 net.cpp:91] Creating Layer bn1_2_D
I0624 13:54:13.917878 18353 net.cpp:425] bn1_2_D <- conv1_2_D
I0624 13:54:13.917883 18353 net.cpp:386] bn1_2_D -> conv1_2_D (in-place)
I0624 13:54:13.918175 18353 net.cpp:141] Setting up bn1_2_D
I0624 13:54:13.918184 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.918186 18353 net.cpp:156] Memory required for data: 165279744
I0624 13:54:13.918192 18353 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 13:54:13.918198 18353 net.cpp:91] Creating Layer scale1_2_D
I0624 13:54:13.918201 18353 net.cpp:425] scale1_2_D <- conv1_2_D
I0624 13:54:13.918205 18353 net.cpp:386] scale1_2_D -> conv1_2_D (in-place)
I0624 13:54:13.918256 18353 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 13:54:13.919188 18353 net.cpp:141] Setting up scale1_2_D
I0624 13:54:13.919203 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.919205 18353 net.cpp:156] Memory required for data: 171702272
I0624 13:54:13.919211 18353 layer_factory.hpp:77] Creating layer relu1_2_D
I0624 13:54:13.919216 18353 net.cpp:91] Creating Layer relu1_2_D
I0624 13:54:13.919219 18353 net.cpp:425] relu1_2_D <- conv1_2_D
I0624 13:54:13.919224 18353 net.cpp:386] relu1_2_D -> conv1_2_D (in-place)
I0624 13:54:13.919584 18353 net.cpp:141] Setting up relu1_2_D
I0624 13:54:13.919596 18353 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 13:54:13.919600 18353 net.cpp:156] Memory required for data: 178124800
I0624 13:54:13.919603 18353 layer_factory.hpp:77] Creating layer conv1_1_D
I0624 13:54:13.919613 18353 net.cpp:91] Creating Layer conv1_1_D
I0624 13:54:13.919616 18353 net.cpp:425] conv1_1_D <- conv1_2_D
I0624 13:54:13.919621 18353 net.cpp:399] conv1_1_D -> conv1_1_D
I0624 13:54:13.920965 18353 net.cpp:141] Setting up conv1_1_D
I0624 13:54:13.920979 18353 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 13:54:13.920981 18353 net.cpp:156] Memory required for data: 178526208
I0624 13:54:13.920989 18353 layer_factory.hpp:77] Creating layer conv1_1_D_conv1_1_D_0_split
I0624 13:54:13.920994 18353 net.cpp:91] Creating Layer conv1_1_D_conv1_1_D_0_split
I0624 13:54:13.920997 18353 net.cpp:425] conv1_1_D_conv1_1_D_0_split <- conv1_1_D
I0624 13:54:13.921003 18353 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_0
I0624 13:54:13.921010 18353 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_1
I0624 13:54:13.921066 18353 net.cpp:141] Setting up conv1_1_D_conv1_1_D_0_split
I0624 13:54:13.921072 18353 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 13:54:13.921077 18353 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 13:54:13.921078 18353 net.cpp:156] Memory required for data: 179329024
I0624 13:54:13.921082 18353 layer_factory.hpp:77] Creating layer loss
I0624 13:54:13.921087 18353 net.cpp:91] Creating Layer loss
I0624 13:54:13.921090 18353 net.cpp:425] loss <- conv1_1_D_conv1_1_D_0_split_0
I0624 13:54:13.921094 18353 net.cpp:425] loss <- label_data_1_split_0
I0624 13:54:13.921098 18353 net.cpp:399] loss -> loss
I0624 13:54:13.921104 18353 layer_factory.hpp:77] Creating layer loss
I0624 13:54:13.921669 18353 net.cpp:141] Setting up loss
I0624 13:54:13.921681 18353 net.cpp:148] Top shape: (1)
I0624 13:54:13.921684 18353 net.cpp:151]     with loss weight 1
I0624 13:54:13.921694 18353 net.cpp:156] Memory required for data: 179329028
I0624 13:54:13.921696 18353 layer_factory.hpp:77] Creating layer accuracy
I0624 13:54:13.921703 18353 net.cpp:91] Creating Layer accuracy
I0624 13:54:13.921706 18353 net.cpp:425] accuracy <- conv1_1_D_conv1_1_D_0_split_1
I0624 13:54:13.921710 18353 net.cpp:425] accuracy <- label_data_1_split_1
I0624 13:54:13.921715 18353 net.cpp:399] accuracy -> accuracy
I0624 13:54:13.921721 18353 net.cpp:141] Setting up accuracy
I0624 13:54:13.921725 18353 net.cpp:148] Top shape: (1)
I0624 13:54:13.921727 18353 net.cpp:156] Memory required for data: 179329032
I0624 13:54:13.921742 18353 net.cpp:219] accuracy does not need backward computation.
I0624 13:54:13.921746 18353 net.cpp:217] loss needs backward computation.
I0624 13:54:13.921749 18353 net.cpp:217] conv1_1_D_conv1_1_D_0_split needs backward computation.
I0624 13:54:13.921752 18353 net.cpp:217] conv1_1_D needs backward computation.
I0624 13:54:13.921754 18353 net.cpp:217] relu1_2_D needs backward computation.
I0624 13:54:13.921757 18353 net.cpp:217] scale1_2_D needs backward computation.
I0624 13:54:13.921759 18353 net.cpp:217] bn1_2_D needs backward computation.
I0624 13:54:13.921761 18353 net.cpp:217] conv1_2_D needs backward computation.
I0624 13:54:13.921764 18353 net.cpp:217] upsample1 needs backward computation.
I0624 13:54:13.921769 18353 net.cpp:217] relu2_1_D needs backward computation.
I0624 13:54:13.921772 18353 net.cpp:217] scale2_1_D needs backward computation.
I0624 13:54:13.921774 18353 net.cpp:217] bn2_1_D needs backward computation.
I0624 13:54:13.921777 18353 net.cpp:217] conv2_1_D needs backward computation.
I0624 13:54:13.921779 18353 net.cpp:217] relu2_2_D needs backward computation.
I0624 13:54:13.921782 18353 net.cpp:217] scale2_2_D needs backward computation.
I0624 13:54:13.921783 18353 net.cpp:217] bn2_2_D needs backward computation.
I0624 13:54:13.921787 18353 net.cpp:217] conv2_2_D needs backward computation.
I0624 13:54:13.921789 18353 net.cpp:217] upsample2 needs backward computation.
I0624 13:54:13.921792 18353 net.cpp:217] relu3_1_D needs backward computation.
I0624 13:54:13.921794 18353 net.cpp:217] scale3_1_D needs backward computation.
I0624 13:54:13.921798 18353 net.cpp:217] bn3_1_D needs backward computation.
I0624 13:54:13.921802 18353 net.cpp:217] conv3_1_D needs backward computation.
I0624 13:54:13.921804 18353 net.cpp:217] relu3_2_D needs backward computation.
I0624 13:54:13.921807 18353 net.cpp:217] scale3_2_D needs backward computation.
I0624 13:54:13.921809 18353 net.cpp:217] bn3_2_D needs backward computation.
I0624 13:54:13.921811 18353 net.cpp:217] conv3_2_D needs backward computation.
I0624 13:54:13.921814 18353 net.cpp:217] upsample3 needs backward computation.
I0624 13:54:13.921818 18353 net.cpp:217] relu4_1_D needs backward computation.
I0624 13:54:13.921820 18353 net.cpp:217] scale4_1_D needs backward computation.
I0624 13:54:13.921823 18353 net.cpp:217] bn4_1_D needs backward computation.
I0624 13:54:13.921825 18353 net.cpp:217] conv4_1_D needs backward computation.
I0624 13:54:13.921828 18353 net.cpp:217] relu4_2_D needs backward computation.
I0624 13:54:13.921831 18353 net.cpp:217] scale4_2_D needs backward computation.
I0624 13:54:13.921833 18353 net.cpp:217] bn4_2_D needs backward computation.
I0624 13:54:13.921836 18353 net.cpp:217] conv4_2_D needs backward computation.
I0624 13:54:13.921839 18353 net.cpp:217] upsample4 needs backward computation.
I0624 13:54:13.921843 18353 net.cpp:217] relu5_1_D needs backward computation.
I0624 13:54:13.921844 18353 net.cpp:217] scale5_1_D needs backward computation.
I0624 13:54:13.921849 18353 net.cpp:217] bn5_1_D needs backward computation.
I0624 13:54:13.921850 18353 net.cpp:217] conv5_1_D needs backward computation.
I0624 13:54:13.921854 18353 net.cpp:217] relu5_2_D needs backward computation.
I0624 13:54:13.921856 18353 net.cpp:217] scale5_2_D needs backward computation.
I0624 13:54:13.921859 18353 net.cpp:217] bn5_2_D needs backward computation.
I0624 13:54:13.921860 18353 net.cpp:217] conv5_2_D needs backward computation.
I0624 13:54:13.921864 18353 net.cpp:217] upsample5 needs backward computation.
I0624 13:54:13.921867 18353 net.cpp:217] pool5 needs backward computation.
I0624 13:54:13.921870 18353 net.cpp:217] relu5_2 needs backward computation.
I0624 13:54:13.921874 18353 net.cpp:217] scale5_2 needs backward computation.
I0624 13:54:13.921875 18353 net.cpp:217] bn5_2 needs backward computation.
I0624 13:54:13.921877 18353 net.cpp:217] conv5_2 needs backward computation.
I0624 13:54:13.921880 18353 net.cpp:217] relu5_1 needs backward computation.
I0624 13:54:13.921883 18353 net.cpp:217] scale5_1 needs backward computation.
I0624 13:54:13.921890 18353 net.cpp:217] bn5_1 needs backward computation.
I0624 13:54:13.921893 18353 net.cpp:217] conv5_1 needs backward computation.
I0624 13:54:13.921896 18353 net.cpp:217] pool4 needs backward computation.
I0624 13:54:13.921900 18353 net.cpp:217] relu4_2 needs backward computation.
I0624 13:54:13.921901 18353 net.cpp:217] scale4_2 needs backward computation.
I0624 13:54:13.921905 18353 net.cpp:217] bn4_2 needs backward computation.
I0624 13:54:13.921906 18353 net.cpp:217] conv4_2 needs backward computation.
I0624 13:54:13.921911 18353 net.cpp:217] relu4_1 needs backward computation.
I0624 13:54:13.921914 18353 net.cpp:217] scale4_1 needs backward computation.
I0624 13:54:13.921917 18353 net.cpp:217] bn4_1 needs backward computation.
I0624 13:54:13.921919 18353 net.cpp:217] conv4_1 needs backward computation.
I0624 13:54:13.921922 18353 net.cpp:217] pool3 needs backward computation.
I0624 13:54:13.921924 18353 net.cpp:217] relu3_2 needs backward computation.
I0624 13:54:13.921927 18353 net.cpp:217] scale3_2 needs backward computation.
I0624 13:54:13.921929 18353 net.cpp:217] bn3_2 needs backward computation.
I0624 13:54:13.921932 18353 net.cpp:217] conv3_2 needs backward computation.
I0624 13:54:13.921934 18353 net.cpp:217] relu3_1 needs backward computation.
I0624 13:54:13.921937 18353 net.cpp:217] scale3_1 needs backward computation.
I0624 13:54:13.921939 18353 net.cpp:217] bn3_1 needs backward computation.
I0624 13:54:13.921942 18353 net.cpp:217] conv3_1 needs backward computation.
I0624 13:54:13.921946 18353 net.cpp:217] pool2 needs backward computation.
I0624 13:54:13.921947 18353 net.cpp:217] relu2_2 needs backward computation.
I0624 13:54:13.921950 18353 net.cpp:217] scale2_2 needs backward computation.
I0624 13:54:13.921952 18353 net.cpp:217] bn2_2 needs backward computation.
I0624 13:54:13.921955 18353 net.cpp:217] conv2_2 needs backward computation.
I0624 13:54:13.921957 18353 net.cpp:217] relu2_1 needs backward computation.
I0624 13:54:13.921960 18353 net.cpp:217] scale2_1 needs backward computation.
I0624 13:54:13.921963 18353 net.cpp:217] bn2_1 needs backward computation.
I0624 13:54:13.921965 18353 net.cpp:217] conv2_1 needs backward computation.
I0624 13:54:13.921968 18353 net.cpp:217] pool1 needs backward computation.
I0624 13:54:13.921972 18353 net.cpp:217] relu1_2 needs backward computation.
I0624 13:54:13.921973 18353 net.cpp:217] scale1_2 needs backward computation.
I0624 13:54:13.921977 18353 net.cpp:217] bn1_2 needs backward computation.
I0624 13:54:13.921978 18353 net.cpp:217] conv1_2 needs backward computation.
I0624 13:54:13.921982 18353 net.cpp:217] relu1_1 needs backward computation.
I0624 13:54:13.921983 18353 net.cpp:217] scale1_1 needs backward computation.
I0624 13:54:13.921986 18353 net.cpp:217] bn1_1 needs backward computation.
I0624 13:54:13.921989 18353 net.cpp:217] conv1_1 needs backward computation.
I0624 13:54:13.921993 18353 net.cpp:219] label_data_1_split does not need backward computation.
I0624 13:54:13.921995 18353 net.cpp:219] data does not need backward computation.
I0624 13:54:13.921998 18353 net.cpp:261] This network produces output accuracy
I0624 13:54:13.922001 18353 net.cpp:261] This network produces output loss
I0624 13:54:13.922051 18353 net.cpp:274] Network initialization done.
I0624 13:54:13.922327 18353 solver.cpp:60] Solver scaffolding done.
I0624 13:54:13.927279 18353 caffe.cpp:219] Starting Optimization
I0624 13:54:13.927287 18353 solver.cpp:279] Solving segnet
I0624 13:54:13.927290 18353 solver.cpp:280] Learning Rate Policy: step
I0624 13:54:13.932564 18353 solver.cpp:337] Iteration 0, Testing net (#0)
I0624 13:54:14.301425 18353 solver.cpp:404]     Test net output #0: accuracy = 0.537452
I0624 13:54:14.301452 18353 solver.cpp:404]     Test net output #1: loss = 0.725279 (* 1 = 0.725279 loss)
I0624 13:54:15.058629 18353 solver.cpp:228] Iteration 0, loss = 0.724146
I0624 13:54:15.058655 18353 solver.cpp:244]     Train net output #0: accuracy = 0.536619
I0624 13:54:15.058663 18353 solver.cpp:244]     Train net output #1: loss = 0.724146 (* 1 = 0.724146 loss)
I0624 13:54:15.058693 18353 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0624 13:54:29.378131 18353 solver.cpp:228] Iteration 20, loss = 0.279161
I0624 13:54:29.378157 18353 solver.cpp:244]     Train net output #0: accuracy = 0.957215
I0624 13:54:29.378165 18353 solver.cpp:244]     Train net output #1: loss = 0.279161 (* 1 = 0.279161 loss)
I0624 13:54:29.378170 18353 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0624 13:54:44.031246 18353 solver.cpp:228] Iteration 40, loss = 0.184418
I0624 13:54:44.031307 18353 solver.cpp:244]     Train net output #0: accuracy = 0.959128
I0624 13:54:44.031316 18353 solver.cpp:244]     Train net output #1: loss = 0.184418 (* 1 = 0.184418 loss)
I0624 13:54:44.031322 18353 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0624 13:54:58.649756 18353 solver.cpp:228] Iteration 60, loss = 0.164278
I0624 13:54:58.649780 18353 solver.cpp:244]     Train net output #0: accuracy = 0.961961
I0624 13:54:58.649788 18353 solver.cpp:244]     Train net output #1: loss = 0.164278 (* 1 = 0.164278 loss)
I0624 13:54:58.649793 18353 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0624 13:55:13.267417 18353 solver.cpp:228] Iteration 80, loss = 0.170846
I0624 13:55:13.267444 18353 solver.cpp:244]     Train net output #0: accuracy = 0.9594
I0624 13:55:13.267452 18353 solver.cpp:244]     Train net output #1: loss = 0.170846 (* 1 = 0.170846 loss)
I0624 13:55:13.267457 18353 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0624 13:55:27.485368 18353 solver.cpp:337] Iteration 100, Testing net (#0)
I0624 13:55:27.821208 18353 solver.cpp:404]     Test net output #0: accuracy = 0.960021
I0624 13:55:27.821243 18353 solver.cpp:404]     Test net output #1: loss = 0.167101 (* 1 = 0.167101 loss)
I0624 13:55:28.230455 18353 solver.cpp:228] Iteration 100, loss = 0.159109
I0624 13:55:28.230479 18353 solver.cpp:244]     Train net output #0: accuracy = 0.962868
I0624 13:55:28.230485 18353 solver.cpp:244]     Train net output #1: loss = 0.159109 (* 1 = 0.159109 loss)
I0624 13:55:28.230490 18353 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0624 13:55:42.847285 18353 solver.cpp:228] Iteration 120, loss = 0.155371
I0624 13:55:42.847308 18353 solver.cpp:244]     Train net output #0: accuracy = 0.962933
I0624 13:55:42.847316 18353 solver.cpp:244]     Train net output #1: loss = 0.155371 (* 1 = 0.155371 loss)
I0624 13:55:42.847321 18353 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0624 13:55:57.479846 18353 solver.cpp:228] Iteration 140, loss = 0.17061
I0624 13:55:57.479881 18353 solver.cpp:244]     Train net output #0: accuracy = 0.957796
I0624 13:55:57.479887 18353 solver.cpp:244]     Train net output #1: loss = 0.17061 (* 1 = 0.17061 loss)
I0624 13:55:57.479892 18353 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0624 13:56:12.129005 18353 solver.cpp:228] Iteration 160, loss = 0.155859
I0624 13:56:12.129109 18353 solver.cpp:244]     Train net output #0: accuracy = 0.961909
I0624 13:56:12.129118 18353 solver.cpp:244]     Train net output #1: loss = 0.155859 (* 1 = 0.155859 loss)
I0624 13:56:12.129123 18353 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0624 13:56:26.818622 18353 solver.cpp:228] Iteration 180, loss = 0.155052
I0624 13:56:26.818648 18353 solver.cpp:244]     Train net output #0: accuracy = 0.960647
I0624 13:56:26.818666 18353 solver.cpp:244]     Train net output #1: loss = 0.155052 (* 1 = 0.155052 loss)
I0624 13:56:26.818671 18353 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0624 13:56:41.064301 18353 solver.cpp:337] Iteration 200, Testing net (#0)
I0624 13:56:41.400609 18353 solver.cpp:404]     Test net output #0: accuracy = 0.956742
I0624 13:56:41.400632 18353 solver.cpp:404]     Test net output #1: loss = 0.162979 (* 1 = 0.162979 loss)
I0624 13:56:41.810281 18353 solver.cpp:228] Iteration 200, loss = 0.145909
I0624 13:56:41.810305 18353 solver.cpp:244]     Train net output #0: accuracy = 0.961393
I0624 13:56:41.810312 18353 solver.cpp:244]     Train net output #1: loss = 0.145909 (* 1 = 0.145909 loss)
I0624 13:56:41.810317 18353 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0624 13:56:56.456368 18353 solver.cpp:228] Iteration 220, loss = 0.156049
I0624 13:56:56.456470 18353 solver.cpp:244]     Train net output #0: accuracy = 0.95873
I0624 13:56:56.456480 18353 solver.cpp:244]     Train net output #1: loss = 0.156049 (* 1 = 0.156049 loss)
I0624 13:56:56.456486 18353 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0624 13:57:11.101212 18353 solver.cpp:228] Iteration 240, loss = 0.145085
I0624 13:57:11.101234 18353 solver.cpp:244]     Train net output #0: accuracy = 0.959492
I0624 13:57:11.101241 18353 solver.cpp:244]     Train net output #1: loss = 0.145085 (* 1 = 0.145085 loss)
I0624 13:57:11.101246 18353 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0624 13:57:25.741889 18353 solver.cpp:228] Iteration 260, loss = 0.148975
I0624 13:57:25.741912 18353 solver.cpp:244]     Train net output #0: accuracy = 0.957047
I0624 13:57:25.741919 18353 solver.cpp:244]     Train net output #1: loss = 0.148975 (* 1 = 0.148975 loss)
I0624 13:57:25.741924 18353 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0624 13:57:40.381590 18353 solver.cpp:228] Iteration 280, loss = 0.133317
I0624 13:57:40.381692 18353 solver.cpp:244]     Train net output #0: accuracy = 0.960251
I0624 13:57:40.381702 18353 solver.cpp:244]     Train net output #1: loss = 0.133317 (* 1 = 0.133317 loss)
I0624 13:57:40.381706 18353 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0624 13:57:54.601105 18353 solver.cpp:337] Iteration 300, Testing net (#0)
I0624 13:57:54.937306 18353 solver.cpp:404]     Test net output #0: accuracy = 0.961045
I0624 13:57:54.937340 18353 solver.cpp:404]     Test net output #1: loss = 0.12165 (* 1 = 0.12165 loss)
I0624 13:57:55.345929 18353 solver.cpp:228] Iteration 300, loss = 0.128392
I0624 13:57:55.345954 18353 solver.cpp:244]     Train net output #0: accuracy = 0.962344
I0624 13:57:55.345963 18353 solver.cpp:244]     Train net output #1: loss = 0.128392 (* 1 = 0.128392 loss)
I0624 13:57:55.345966 18353 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0624 13:58:09.978418 18353 solver.cpp:228] Iteration 320, loss = 0.119978
I0624 13:58:09.978453 18353 solver.cpp:244]     Train net output #0: accuracy = 0.961506
I0624 13:58:09.978461 18353 solver.cpp:244]     Train net output #1: loss = 0.119978 (* 1 = 0.119978 loss)
I0624 13:58:09.978466 18353 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0624 13:58:24.607568 18353 solver.cpp:228] Iteration 340, loss = 0.121553
I0624 13:58:24.607673 18353 solver.cpp:244]     Train net output #0: accuracy = 0.960828
I0624 13:58:24.607682 18353 solver.cpp:244]     Train net output #1: loss = 0.121553 (* 1 = 0.121553 loss)
I0624 13:58:24.607687 18353 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0624 13:58:39.295615 18353 solver.cpp:228] Iteration 360, loss = 0.113908
I0624 13:58:39.295640 18353 solver.cpp:244]     Train net output #0: accuracy = 0.959678
I0624 13:58:39.295649 18353 solver.cpp:244]     Train net output #1: loss = 0.113908 (* 1 = 0.113908 loss)
I0624 13:58:39.295652 18353 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0624 13:58:53.936630 18353 solver.cpp:228] Iteration 380, loss = 0.105754
I0624 13:58:53.936655 18353 solver.cpp:244]     Train net output #0: accuracy = 0.962382
I0624 13:58:53.936661 18353 solver.cpp:244]     Train net output #1: loss = 0.105754 (* 1 = 0.105754 loss)
I0624 13:58:53.936666 18353 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0624 13:59:08.154316 18353 solver.cpp:337] Iteration 400, Testing net (#0)
I0624 13:59:08.490871 18353 solver.cpp:404]     Test net output #0: accuracy = 0.960308
I0624 13:59:08.490906 18353 solver.cpp:404]     Test net output #1: loss = 0.110345 (* 1 = 0.110345 loss)
I0624 13:59:08.901298 18353 solver.cpp:228] Iteration 400, loss = 0.100459
I0624 13:59:08.901322 18353 solver.cpp:244]     Train net output #0: accuracy = 0.960776
I0624 13:59:08.901329 18353 solver.cpp:244]     Train net output #1: loss = 0.100459 (* 1 = 0.100459 loss)
I0624 13:59:08.901335 18353 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0624 13:59:23.517493 18353 solver.cpp:228] Iteration 420, loss = 0.0900748
I0624 13:59:23.517518 18353 solver.cpp:244]     Train net output #0: accuracy = 0.960089
I0624 13:59:23.517524 18353 solver.cpp:244]     Train net output #1: loss = 0.0900748 (* 1 = 0.0900748 loss)
I0624 13:59:23.517529 18353 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0624 13:59:38.141052 18353 solver.cpp:228] Iteration 440, loss = 0.0900009
I0624 13:59:38.141077 18353 solver.cpp:244]     Train net output #0: accuracy = 0.961223
I0624 13:59:38.141083 18353 solver.cpp:244]     Train net output #1: loss = 0.0900009 (* 1 = 0.0900009 loss)
I0624 13:59:38.141088 18353 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0624 13:59:52.759651 18353 solver.cpp:228] Iteration 460, loss = 0.0928793
I0624 13:59:52.759785 18353 solver.cpp:244]     Train net output #0: accuracy = 0.957468
I0624 13:59:52.759796 18353 solver.cpp:244]     Train net output #1: loss = 0.0928793 (* 1 = 0.0928793 loss)
I0624 13:59:52.759801 18353 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0624 14:00:07.383680 18353 solver.cpp:228] Iteration 480, loss = 0.0791099
I0624 14:00:07.383704 18353 solver.cpp:244]     Train net output #0: accuracy = 0.958579
I0624 14:00:07.383711 18353 solver.cpp:244]     Train net output #1: loss = 0.0791099 (* 1 = 0.0791099 loss)
I0624 14:00:07.383728 18353 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0624 14:00:21.659811 18353 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_500.caffemodel
I0624 14:00:21.723325 18353 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_500.solverstate
I0624 14:00:21.746764 18353 solver.cpp:337] Iteration 500, Testing net (#0)
I0624 14:00:22.085218 18353 solver.cpp:404]     Test net output #0: accuracy = 0.962007
I0624 14:00:22.085243 18353 solver.cpp:404]     Test net output #1: loss = 0.0745117 (* 1 = 0.0745117 loss)
I0624 14:00:22.494601 18353 solver.cpp:228] Iteration 500, loss = 0.0748195
I0624 14:00:22.494638 18353 solver.cpp:244]     Train net output #0: accuracy = 0.957714
I0624 14:00:22.494647 18353 solver.cpp:244]     Train net output #1: loss = 0.0748195 (* 1 = 0.0748195 loss)
I0624 14:00:22.494652 18353 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0624 14:00:37.145248 18353 solver.cpp:228] Iteration 520, loss = 0.0715747
I0624 14:00:37.145351 18353 solver.cpp:244]     Train net output #0: accuracy = 0.957573
I0624 14:00:37.145361 18353 solver.cpp:244]     Train net output #1: loss = 0.0715747 (* 1 = 0.0715747 loss)
I0624 14:00:37.145366 18353 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0624 14:00:51.765321 18353 solver.cpp:228] Iteration 540, loss = 0.0927644
I0624 14:00:51.765347 18353 solver.cpp:244]     Train net output #0: accuracy = 0.954369
I0624 14:00:51.765354 18353 solver.cpp:244]     Train net output #1: loss = 0.0927644 (* 1 = 0.0927644 loss)
I0624 14:00:51.765358 18353 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0624 14:01:06.395365 18353 solver.cpp:228] Iteration 560, loss = 0.0703689
I0624 14:01:06.395401 18353 solver.cpp:244]     Train net output #0: accuracy = 0.960642
I0624 14:01:06.395408 18353 solver.cpp:244]     Train net output #1: loss = 0.0703689 (* 1 = 0.0703689 loss)
I0624 14:01:06.395413 18353 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0624 14:01:21.005295 18353 solver.cpp:228] Iteration 580, loss = 0.0766441
I0624 14:01:21.005408 18353 solver.cpp:244]     Train net output #0: accuracy = 0.97085
I0624 14:01:21.005417 18353 solver.cpp:244]     Train net output #1: loss = 0.0766441 (* 1 = 0.0766441 loss)
I0624 14:01:21.005422 18353 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0624 14:01:35.231122 18353 solver.cpp:337] Iteration 600, Testing net (#0)
I0624 14:01:35.566961 18353 solver.cpp:404]     Test net output #0: accuracy = 0.970754
I0624 14:01:35.566995 18353 solver.cpp:404]     Test net output #1: loss = 0.0682377 (* 1 = 0.0682377 loss)
I0624 14:01:35.976045 18353 solver.cpp:228] Iteration 600, loss = 0.0677918
I0624 14:01:35.976069 18353 solver.cpp:244]     Train net output #0: accuracy = 0.973175
I0624 14:01:35.976076 18353 solver.cpp:244]     Train net output #1: loss = 0.0677918 (* 1 = 0.0677918 loss)
I0624 14:01:35.976081 18353 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0624 14:01:50.593183 18353 solver.cpp:228] Iteration 620, loss = 0.0692086
I0624 14:01:50.593210 18353 solver.cpp:244]     Train net output #0: accuracy = 0.972835
I0624 14:01:50.593217 18353 solver.cpp:244]     Train net output #1: loss = 0.0692086 (* 1 = 0.0692086 loss)
I0624 14:01:50.593222 18353 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0624 14:02:05.216209 18353 solver.cpp:228] Iteration 640, loss = 0.0615178
I0624 14:02:05.216326 18353 solver.cpp:244]     Train net output #0: accuracy = 0.975331
I0624 14:02:05.216337 18353 solver.cpp:244]     Train net output #1: loss = 0.0615178 (* 1 = 0.0615178 loss)
I0624 14:02:05.216342 18353 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0624 14:02:19.827494 18353 solver.cpp:228] Iteration 660, loss = 0.0608139
I0624 14:02:19.827520 18353 solver.cpp:244]     Train net output #0: accuracy = 0.977397
I0624 14:02:19.827527 18353 solver.cpp:244]     Train net output #1: loss = 0.0608139 (* 1 = 0.0608139 loss)
I0624 14:02:19.827531 18353 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0624 14:02:34.498422 18353 solver.cpp:228] Iteration 680, loss = 0.0630502
I0624 14:02:34.498446 18353 solver.cpp:244]     Train net output #0: accuracy = 0.978152
I0624 14:02:34.498453 18353 solver.cpp:244]     Train net output #1: loss = 0.0630502 (* 1 = 0.0630502 loss)
I0624 14:02:34.498458 18353 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0624 14:02:48.710953 18353 solver.cpp:337] Iteration 700, Testing net (#0)
I0624 14:02:49.046722 18353 solver.cpp:404]     Test net output #0: accuracy = 0.979673
I0624 14:02:49.046756 18353 solver.cpp:404]     Test net output #1: loss = 0.0580773 (* 1 = 0.0580773 loss)
I0624 14:02:49.456470 18353 solver.cpp:228] Iteration 700, loss = 0.0669421
I0624 14:02:49.456495 18353 solver.cpp:244]     Train net output #0: accuracy = 0.975812
I0624 14:02:49.456501 18353 solver.cpp:244]     Train net output #1: loss = 0.0669421 (* 1 = 0.0669421 loss)
I0624 14:02:49.456506 18353 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0624 14:03:04.084933 18353 solver.cpp:228] Iteration 720, loss = 0.059609
I0624 14:03:04.084957 18353 solver.cpp:244]     Train net output #0: accuracy = 0.976417
I0624 14:03:04.084965 18353 solver.cpp:244]     Train net output #1: loss = 0.059609 (* 1 = 0.059609 loss)
I0624 14:03:04.084970 18353 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0624 14:03:18.701774 18353 solver.cpp:228] Iteration 740, loss = 0.0555766
I0624 14:03:18.701810 18353 solver.cpp:244]     Train net output #0: accuracy = 0.980132
I0624 14:03:18.701818 18353 solver.cpp:244]     Train net output #1: loss = 0.0555766 (* 1 = 0.0555766 loss)
I0624 14:03:18.701823 18353 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0624 14:03:33.318568 18353 solver.cpp:228] Iteration 760, loss = 0.0614597
I0624 14:03:33.318660 18353 solver.cpp:244]     Train net output #0: accuracy = 0.978646
I0624 14:03:33.318670 18353 solver.cpp:244]     Train net output #1: loss = 0.0614597 (* 1 = 0.0614597 loss)
I0624 14:03:33.318675 18353 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0624 14:03:47.938019 18353 solver.cpp:228] Iteration 780, loss = 0.0689755
I0624 14:03:47.938042 18353 solver.cpp:244]     Train net output #0: accuracy = 0.976782
I0624 14:03:47.938050 18353 solver.cpp:244]     Train net output #1: loss = 0.0689755 (* 1 = 0.0689755 loss)
I0624 14:03:47.938055 18353 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0624 14:04:02.152492 18353 solver.cpp:337] Iteration 800, Testing net (#0)
I0624 14:04:02.488809 18353 solver.cpp:404]     Test net output #0: accuracy = 0.974548
I0624 14:04:02.488844 18353 solver.cpp:404]     Test net output #1: loss = 0.0645146 (* 1 = 0.0645146 loss)
I0624 14:04:02.898685 18353 solver.cpp:228] Iteration 800, loss = 0.0618737
I0624 14:04:02.898710 18353 solver.cpp:244]     Train net output #0: accuracy = 0.977544
I0624 14:04:02.898716 18353 solver.cpp:244]     Train net output #1: loss = 0.0618737 (* 1 = 0.0618737 loss)
I0624 14:04:02.898720 18353 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0624 14:04:17.525995 18353 solver.cpp:228] Iteration 820, loss = 0.0513541
I0624 14:04:17.526115 18353 solver.cpp:244]     Train net output #0: accuracy = 0.980827
I0624 14:04:17.526126 18353 solver.cpp:244]     Train net output #1: loss = 0.0513541 (* 1 = 0.0513541 loss)
I0624 14:04:17.526131 18353 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0624 14:04:32.166388 18353 solver.cpp:228] Iteration 840, loss = 0.0534772
I0624 14:04:32.166425 18353 solver.cpp:244]     Train net output #0: accuracy = 0.983084
I0624 14:04:32.166434 18353 solver.cpp:244]     Train net output #1: loss = 0.0534772 (* 1 = 0.0534772 loss)
I0624 14:04:32.166440 18353 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0624 14:04:46.802911 18353 solver.cpp:228] Iteration 860, loss = 0.0491241
I0624 14:04:46.802937 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982268
I0624 14:04:46.802943 18353 solver.cpp:244]     Train net output #1: loss = 0.0491241 (* 1 = 0.0491241 loss)
I0624 14:04:46.802948 18353 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0624 14:05:01.427945 18353 solver.cpp:228] Iteration 880, loss = 0.0542038
I0624 14:05:01.428045 18353 solver.cpp:244]     Train net output #0: accuracy = 0.978663
I0624 14:05:01.428055 18353 solver.cpp:244]     Train net output #1: loss = 0.0542038 (* 1 = 0.0542038 loss)
I0624 14:05:01.428059 18353 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0624 14:05:15.646544 18353 solver.cpp:337] Iteration 900, Testing net (#0)
I0624 14:05:15.983731 18353 solver.cpp:404]     Test net output #0: accuracy = 0.978232
I0624 14:05:15.983757 18353 solver.cpp:404]     Test net output #1: loss = 0.0545115 (* 1 = 0.0545115 loss)
I0624 14:05:16.393128 18353 solver.cpp:228] Iteration 900, loss = 0.0582187
I0624 14:05:16.393152 18353 solver.cpp:244]     Train net output #0: accuracy = 0.978857
I0624 14:05:16.393159 18353 solver.cpp:244]     Train net output #1: loss = 0.0582187 (* 1 = 0.0582187 loss)
I0624 14:05:16.393164 18353 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0624 14:05:31.015259 18353 solver.cpp:228] Iteration 920, loss = 0.0482975
I0624 14:05:31.015283 18353 solver.cpp:244]     Train net output #0: accuracy = 0.981586
I0624 14:05:31.015291 18353 solver.cpp:244]     Train net output #1: loss = 0.0482975 (* 1 = 0.0482975 loss)
I0624 14:05:31.015295 18353 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0624 14:05:45.640573 18353 solver.cpp:228] Iteration 940, loss = 0.0511484
I0624 14:05:45.640669 18353 solver.cpp:244]     Train net output #0: accuracy = 0.981192
I0624 14:05:45.640678 18353 solver.cpp:244]     Train net output #1: loss = 0.0511484 (* 1 = 0.0511484 loss)
I0624 14:05:45.640683 18353 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0624 14:06:00.271034 18353 solver.cpp:228] Iteration 960, loss = 0.0463565
I0624 14:06:00.271059 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982266
I0624 14:06:00.271065 18353 solver.cpp:244]     Train net output #1: loss = 0.0463565 (* 1 = 0.0463565 loss)
I0624 14:06:00.271070 18353 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0624 14:06:14.901949 18353 solver.cpp:228] Iteration 980, loss = 0.0550168
I0624 14:06:14.901974 18353 solver.cpp:244]     Train net output #0: accuracy = 0.979388
I0624 14:06:14.901983 18353 solver.cpp:244]     Train net output #1: loss = 0.0550168 (* 1 = 0.0550168 loss)
I0624 14:06:14.901988 18353 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0624 14:06:29.097652 18353 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_1000.caffemodel
I0624 14:06:29.144742 18353 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_1000.solverstate
I0624 14:06:29.167605 18353 solver.cpp:337] Iteration 1000, Testing net (#0)
I0624 14:06:29.505873 18353 solver.cpp:404]     Test net output #0: accuracy = 0.979678
I0624 14:06:29.505908 18353 solver.cpp:404]     Test net output #1: loss = 0.053645 (* 1 = 0.053645 loss)
I0624 14:06:29.925745 18353 solver.cpp:228] Iteration 1000, loss = 0.0567826
I0624 14:06:29.925771 18353 solver.cpp:244]     Train net output #0: accuracy = 0.978521
I0624 14:06:29.925778 18353 solver.cpp:244]     Train net output #1: loss = 0.0567826 (* 1 = 0.0567826 loss)
I0624 14:06:29.925782 18353 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0624 14:06:44.579529 18353 solver.cpp:228] Iteration 1020, loss = 0.047306
I0624 14:06:44.579555 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982656
I0624 14:06:44.579562 18353 solver.cpp:244]     Train net output #1: loss = 0.047306 (* 1 = 0.047306 loss)
I0624 14:06:44.579567 18353 sgd_solver.cpp:106] Iteration 1020, lr = 0.01
I0624 14:06:59.203131 18353 solver.cpp:228] Iteration 1040, loss = 0.0472528
I0624 14:06:59.203245 18353 solver.cpp:244]     Train net output #0: accuracy = 0.981992
I0624 14:06:59.203256 18353 solver.cpp:244]     Train net output #1: loss = 0.0472528 (* 1 = 0.0472528 loss)
I0624 14:06:59.203261 18353 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I0624 14:07:13.823009 18353 solver.cpp:228] Iteration 1060, loss = 0.0463792
I0624 14:07:13.823035 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982299
I0624 14:07:13.823041 18353 solver.cpp:244]     Train net output #1: loss = 0.0463792 (* 1 = 0.0463792 loss)
I0624 14:07:13.823046 18353 sgd_solver.cpp:106] Iteration 1060, lr = 0.01
I0624 14:07:28.442375 18353 solver.cpp:228] Iteration 1080, loss = 0.0453115
I0624 14:07:28.442401 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982542
I0624 14:07:28.442409 18353 solver.cpp:244]     Train net output #1: loss = 0.0453115 (* 1 = 0.0453115 loss)
I0624 14:07:28.442412 18353 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I0624 14:07:42.650655 18353 solver.cpp:337] Iteration 1100, Testing net (#0)
I0624 14:07:42.987040 18353 solver.cpp:404]     Test net output #0: accuracy = 0.980983
I0624 14:07:42.987074 18353 solver.cpp:404]     Test net output #1: loss = 0.04705 (* 1 = 0.04705 loss)
I0624 14:07:43.395676 18353 solver.cpp:228] Iteration 1100, loss = 0.0443787
I0624 14:07:43.395704 18353 solver.cpp:244]     Train net output #0: accuracy = 0.98394
I0624 14:07:43.395711 18353 solver.cpp:244]     Train net output #1: loss = 0.0443787 (* 1 = 0.0443787 loss)
I0624 14:07:43.395715 18353 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0624 14:07:58.002928 18353 solver.cpp:228] Iteration 1120, loss = 0.0506252
I0624 14:07:58.002954 18353 solver.cpp:244]     Train net output #0: accuracy = 0.981632
I0624 14:07:58.002961 18353 solver.cpp:244]     Train net output #1: loss = 0.0506252 (* 1 = 0.0506252 loss)
I0624 14:07:58.002966 18353 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I0624 14:08:12.624084 18353 solver.cpp:228] Iteration 1140, loss = 0.0549
I0624 14:08:12.624109 18353 solver.cpp:244]     Train net output #0: accuracy = 0.98195
I0624 14:08:12.624115 18353 solver.cpp:244]     Train net output #1: loss = 0.0549 (* 1 = 0.0549 loss)
I0624 14:08:12.624119 18353 sgd_solver.cpp:106] Iteration 1140, lr = 0.01
I0624 14:08:27.242965 18353 solver.cpp:228] Iteration 1160, loss = 0.0477591
I0624 14:08:27.243062 18353 solver.cpp:244]     Train net output #0: accuracy = 0.981922
I0624 14:08:27.243072 18353 solver.cpp:244]     Train net output #1: loss = 0.0477591 (* 1 = 0.0477591 loss)
I0624 14:08:27.243077 18353 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I0624 14:08:41.926856 18353 solver.cpp:228] Iteration 1180, loss = 0.0486042
I0624 14:08:41.926882 18353 solver.cpp:244]     Train net output #0: accuracy = 0.980324
I0624 14:08:41.926889 18353 solver.cpp:244]     Train net output #1: loss = 0.0486042 (* 1 = 0.0486042 loss)
I0624 14:08:41.926894 18353 sgd_solver.cpp:106] Iteration 1180, lr = 0.01
I0624 14:08:56.136394 18353 solver.cpp:337] Iteration 1200, Testing net (#0)
I0624 14:08:56.473107 18353 solver.cpp:404]     Test net output #0: accuracy = 0.980338
I0624 14:08:56.473142 18353 solver.cpp:404]     Test net output #1: loss = 0.0515377 (* 1 = 0.0515377 loss)
I0624 14:08:56.883250 18353 solver.cpp:228] Iteration 1200, loss = 0.0528292
I0624 14:08:56.883275 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982535
I0624 14:08:56.883282 18353 solver.cpp:244]     Train net output #1: loss = 0.0528292 (* 1 = 0.0528292 loss)
I0624 14:08:56.883287 18353 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0624 14:09:11.504889 18353 solver.cpp:228] Iteration 1220, loss = 0.0447128
I0624 14:09:11.505008 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982673
I0624 14:09:11.505018 18353 solver.cpp:244]     Train net output #1: loss = 0.0447128 (* 1 = 0.0447128 loss)
I0624 14:09:11.505023 18353 sgd_solver.cpp:106] Iteration 1220, lr = 0.01
I0624 14:09:26.132289 18353 solver.cpp:228] Iteration 1240, loss = 0.0476316
I0624 14:09:26.132316 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982242
I0624 14:09:26.132334 18353 solver.cpp:244]     Train net output #1: loss = 0.0476316 (* 1 = 0.0476316 loss)
I0624 14:09:26.132339 18353 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I0624 14:09:40.755981 18353 solver.cpp:228] Iteration 1260, loss = 0.0463768
I0624 14:09:40.756005 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982215
I0624 14:09:40.756011 18353 solver.cpp:244]     Train net output #1: loss = 0.0463768 (* 1 = 0.0463768 loss)
I0624 14:09:40.756016 18353 sgd_solver.cpp:106] Iteration 1260, lr = 0.01
I0624 14:09:55.375607 18353 solver.cpp:228] Iteration 1280, loss = 0.0446028
I0624 14:09:55.375705 18353 solver.cpp:244]     Train net output #0: accuracy = 0.983164
I0624 14:09:55.375715 18353 solver.cpp:244]     Train net output #1: loss = 0.0446028 (* 1 = 0.0446028 loss)
I0624 14:09:55.375720 18353 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I0624 14:10:09.593077 18353 solver.cpp:337] Iteration 1300, Testing net (#0)
I0624 14:10:09.929332 18353 solver.cpp:404]     Test net output #0: accuracy = 0.982333
I0624 14:10:09.929357 18353 solver.cpp:404]     Test net output #1: loss = 0.0520042 (* 1 = 0.0520042 loss)
I0624 14:10:10.339445 18353 solver.cpp:228] Iteration 1300, loss = 0.0445654
I0624 14:10:10.339470 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982638
I0624 14:10:10.339478 18353 solver.cpp:244]     Train net output #1: loss = 0.0445654 (* 1 = 0.0445654 loss)
I0624 14:10:10.339483 18353 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0624 14:10:24.968092 18353 solver.cpp:228] Iteration 1320, loss = 0.04075
I0624 14:10:24.968128 18353 solver.cpp:244]     Train net output #0: accuracy = 0.98477
I0624 14:10:24.968137 18353 solver.cpp:244]     Train net output #1: loss = 0.04075 (* 1 = 0.04075 loss)
I0624 14:10:24.968142 18353 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I0624 14:10:39.625999 18353 solver.cpp:228] Iteration 1340, loss = 0.0494391
I0624 14:10:39.626102 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982535
I0624 14:10:39.626112 18353 solver.cpp:244]     Train net output #1: loss = 0.0494391 (* 1 = 0.0494391 loss)
I0624 14:10:39.626117 18353 sgd_solver.cpp:106] Iteration 1340, lr = 0.01
I0624 14:10:54.244520 18353 solver.cpp:228] Iteration 1360, loss = 0.0454086
I0624 14:10:54.244545 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982199
I0624 14:10:54.244552 18353 solver.cpp:244]     Train net output #1: loss = 0.0454086 (* 1 = 0.0454086 loss)
I0624 14:10:54.244556 18353 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I0624 14:11:08.872153 18353 solver.cpp:228] Iteration 1380, loss = 0.0379164
I0624 14:11:08.872179 18353 solver.cpp:244]     Train net output #0: accuracy = 0.985763
I0624 14:11:08.872185 18353 solver.cpp:244]     Train net output #1: loss = 0.0379164 (* 1 = 0.0379164 loss)
I0624 14:11:08.872190 18353 sgd_solver.cpp:106] Iteration 1380, lr = 0.01
I0624 14:11:23.094391 18353 solver.cpp:337] Iteration 1400, Testing net (#0)
I0624 14:11:23.430480 18353 solver.cpp:404]     Test net output #0: accuracy = 0.981691
I0624 14:11:23.430515 18353 solver.cpp:404]     Test net output #1: loss = 0.0530297 (* 1 = 0.0530297 loss)
I0624 14:11:23.839520 18353 solver.cpp:228] Iteration 1400, loss = 0.0418028
I0624 14:11:23.839545 18353 solver.cpp:244]     Train net output #0: accuracy = 0.984113
I0624 14:11:23.839553 18353 solver.cpp:244]     Train net output #1: loss = 0.0418028 (* 1 = 0.0418028 loss)
I0624 14:11:23.839558 18353 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0624 14:11:38.477931 18353 solver.cpp:228] Iteration 1420, loss = 0.0426751
I0624 14:11:38.477954 18353 solver.cpp:244]     Train net output #0: accuracy = 0.984827
I0624 14:11:38.477962 18353 solver.cpp:244]     Train net output #1: loss = 0.0426751 (* 1 = 0.0426751 loss)
I0624 14:11:38.477967 18353 sgd_solver.cpp:106] Iteration 1420, lr = 0.01
I0624 14:11:53.101079 18353 solver.cpp:228] Iteration 1440, loss = 0.0448359
I0624 14:11:53.101192 18353 solver.cpp:244]     Train net output #0: accuracy = 0.982584
I0624 14:11:53.101202 18353 solver.cpp:244]     Train net output #1: loss = 0.0448359 (* 1 = 0.0448359 loss)
I0624 14:11:53.101207 18353 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I0624 14:12:07.723986 18353 solver.cpp:228] Iteration 1460, loss = 0.0396116
I0624 14:12:07.724011 18353 solver.cpp:244]     Train net output #0: accuracy = 0.984612
I0624 14:12:07.724019 18353 solver.cpp:244]     Train net output #1: loss = 0.0396116 (* 1 = 0.0396116 loss)
I0624 14:12:07.724025 18353 sgd_solver.cpp:106] Iteration 1460, lr = 0.01
I0624 14:12:22.348093 18353 solver.cpp:228] Iteration 1480, loss = 0.0478724
I0624 14:12:22.348119 18353 solver.cpp:244]     Train net output #0: accuracy = 0.981321
I0624 14:12:22.348125 18353 solver.cpp:244]     Train net output #1: loss = 0.0478724 (* 1 = 0.0478724 loss)
I0624 14:12:22.348130 18353 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I0624 14:12:36.577867 18353 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_1500.caffemodel
I0624 14:12:36.642369 18353 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_1500.solverstate
I0624 14:12:36.689146 18353 solver.cpp:337] Iteration 1500, Testing net (#0)
I0624 14:12:37.044914 18353 solver.cpp:404]     Test net output #0: accuracy = 0.978975
I0624 14:12:37.044941 18353 solver.cpp:404]     Test net output #1: loss = 0.060757 (* 1 = 0.060757 loss)
I0624 14:12:37.466497 18353 solver.cpp:228] Iteration 1500, loss = 0.0379697
I0624 14:12:37.466526 18353 solver.cpp:244]     Train net output #0: accuracy = 0.985349
I0624 14:12:37.466534 18353 solver.cpp:244]     Train net output #1: loss = 0.0379697 (* 1 = 0.0379697 loss)
I0624 14:12:37.466539 18353 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0624 14:12:52.099280 18353 solver.cpp:228] Iteration 1520, loss = 0.0380289
I0624 14:12:52.099306 18353 solver.cpp:244]     Train net output #0: accuracy = 0.985502
I0624 14:12:52.099313 18353 solver.cpp:244]     Train net output #1: loss = 0.0380289 (* 1 = 0.0380289 loss)
I0624 14:12:52.099318 18353 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I0624 14:13:06.732216 18353 solver.cpp:228] Iteration 1540, loss = 0.0412049
I0624 14:13:06.732318 18353 solver.cpp:244]     Train net output #0: accuracy = 0.984427
I0624 14:13:06.732328 18353 solver.cpp:244]     Train net output #1: loss = 0.0412049 (* 1 = 0.0412049 loss)
I0624 14:13:06.732333 18353 sgd_solver.cpp:106] Iteration 1540, lr = 0.01
I0624 14:13:21.346871 18353 solver.cpp:228] Iteration 1560, loss = 0.0373822
I0624 14:13:21.346895 18353 solver.cpp:244]     Train net output #0: accuracy = 0.985454
I0624 14:13:21.346902 18353 solver.cpp:244]     Train net output #1: loss = 0.0373822 (* 1 = 0.0373822 loss)
I0624 14:13:21.346907 18353 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I0624 14:13:35.968839 18353 solver.cpp:228] Iteration 1580, loss = 0.039261
I0624 14:13:35.968863 18353 solver.cpp:244]     Train net output #0: accuracy = 0.984336
I0624 14:13:35.968871 18353 solver.cpp:244]     Train net output #1: loss = 0.039261 (* 1 = 0.039261 loss)
I0624 14:13:35.968876 18353 sgd_solver.cpp:106] Iteration 1580, lr = 0.01
I0624 14:13:50.175360 18353 solver.cpp:337] Iteration 1600, Testing net (#0)
I0624 14:13:50.511725 18353 solver.cpp:404]     Test net output #0: accuracy = 0.971328
I0624 14:13:50.511760 18353 solver.cpp:404]     Test net output #1: loss = 0.0877981 (* 1 = 0.0877981 loss)
I0624 14:13:50.921253 18353 solver.cpp:228] Iteration 1600, loss = 0.0380583
I0624 14:13:50.921278 18353 solver.cpp:244]     Train net output #0: accuracy = 0.984896
I0624 14:13:50.921285 18353 solver.cpp:244]     Train net output #1: loss = 0.0380583 (* 1 = 0.0380583 loss)
I0624 14:13:50.921290 18353 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0624 14:14:05.545501 18353 solver.cpp:228] Iteration 1620, loss = 0.0395639
I0624 14:14:05.545526 18353 solver.cpp:244]     Train net output #0: accuracy = 0.985533
I0624 14:14:05.545533 18353 solver.cpp:244]     Train net output #1: loss = 0.0395639 (* 1 = 0.0395639 loss)
I0624 14:14:05.545538 18353 sgd_solver.cpp:106] Iteration 1620, lr = 0.01
I0624 14:14:20.177366 18353 solver.cpp:228] Iteration 1640, loss = 0.0411933
I0624 14:14:20.177482 18353 solver.cpp:244]     Train net output #0: accuracy = 0.985011
I0624 14:14:20.177491 18353 solver.cpp:244]     Train net output #1: loss = 0.0411933 (* 1 = 0.0411933 loss)
I0624 14:14:20.177496 18353 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I0624 14:14:34.822425 18353 solver.cpp:228] Iteration 1660, loss = 0.0393753
I0624 14:14:34.822460 18353 solver.cpp:244]     Train net output #0: accuracy = 0.984305
I0624 14:14:34.822468 18353 solver.cpp:244]     Train net output #1: loss = 0.0393753 (* 1 = 0.0393753 loss)
I0624 14:14:34.822471 18353 sgd_solver.cpp:106] Iteration 1660, lr = 0.01
I0624 14:14:49.453811 18353 solver.cpp:228] Iteration 1680, loss = 0.0354045
I0624 14:14:49.453836 18353 solver.cpp:244]     Train net output #0: accuracy = 0.986833
I0624 14:14:49.453845 18353 solver.cpp:244]     Train net output #1: loss = 0.0354045 (* 1 = 0.0354045 loss)
I0624 14:14:49.453850 18353 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I0624 14:15:03.681876 18353 solver.cpp:337] Iteration 1700, Testing net (#0)
I0624 14:15:04.018290 18353 solver.cpp:404]     Test net output #0: accuracy = 0.979318
I0624 14:15:04.018323 18353 solver.cpp:404]     Test net output #1: loss = 0.0570952 (* 1 = 0.0570952 loss)
I0624 14:15:04.428544 18353 solver.cpp:228] Iteration 1700, loss = 0.0378261
I0624 14:15:04.428567 18353 solver.cpp:244]     Train net output #0: accuracy = 0.98534
I0624 14:15:04.428575 18353 solver.cpp:244]     Train net output #1: loss = 0.0378261 (* 1 = 0.0378261 loss)
I0624 14:15:04.428580 18353 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0624 14:15:19.067670 18353 solver.cpp:228] Iteration 1720, loss = 0.0363023
I0624 14:15:19.067706 18353 solver.cpp:244]     Train net output #0: accuracy = 0.986233
I0624 14:15:19.067714 18353 solver.cpp:244]     Train net output #1: loss = 0.0363023 (* 1 = 0.0363023 loss)
I0624 14:15:19.067719 18353 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I0624 14:15:33.707140 18353 solver.cpp:228] Iteration 1740, loss = 0.0383459
I0624 14:15:33.707247 18353 solver.cpp:244]     Train net output #0: accuracy = 0.985731
I0624 14:15:33.707255 18353 solver.cpp:244]     Train net output #1: loss = 0.0383459 (* 1 = 0.0383459 loss)
I0624 14:15:33.707260 18353 sgd_solver.cpp:106] Iteration 1740, lr = 0.01
I0624 14:15:48.350531 18353 solver.cpp:228] Iteration 1760, loss = 0.0368736
I0624 14:15:48.350567 18353 solver.cpp:244]     Train net output #0: accuracy = 0.985698
I0624 14:15:48.350574 18353 solver.cpp:244]     Train net output #1: loss = 0.0368736 (* 1 = 0.0368736 loss)
I0624 14:15:48.350579 18353 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I0624 14:16:02.997864 18353 solver.cpp:228] Iteration 1780, loss = 0.0323696
I0624 14:16:02.997896 18353 solver.cpp:244]     Train net output #0: accuracy = 0.988004
I0624 14:16:02.997905 18353 solver.cpp:244]     Train net output #1: loss = 0.0323696 (* 1 = 0.0323696 loss)
I0624 14:16:02.997908 18353 sgd_solver.cpp:106] Iteration 1780, lr = 0.01
I0624 14:16:17.227628 18353 solver.cpp:337] Iteration 1800, Testing net (#0)
I0624 14:16:17.564254 18353 solver.cpp:404]     Test net output #0: accuracy = 0.981612
I0624 14:16:17.564287 18353 solver.cpp:404]     Test net output #1: loss = 0.0441892 (* 1 = 0.0441892 loss)
I0624 14:16:17.973635 18353 solver.cpp:228] Iteration 1800, loss = 0.0353707
I0624 14:16:17.973670 18353 solver.cpp:244]     Train net output #0: accuracy = 0.986
I0624 14:16:17.973676 18353 solver.cpp:244]     Train net output #1: loss = 0.0353707 (* 1 = 0.0353707 loss)
I0624 14:16:17.973680 18353 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0624 14:16:32.612193 18353 solver.cpp:228] Iteration 1820, loss = 0.0354224
I0624 14:16:32.612229 18353 solver.cpp:244]     Train net output #0: accuracy = 0.986203
I0624 14:16:32.612236 18353 solver.cpp:244]     Train net output #1: loss = 0.0354224 (* 1 = 0.0354224 loss)
I0624 14:16:32.612241 18353 sgd_solver.cpp:106] Iteration 1820, lr = 0.01
I0624 14:16:47.246500 18353 solver.cpp:228] Iteration 1840, loss = 0.032245
I0624 14:16:47.246610 18353 solver.cpp:244]     Train net output #0: accuracy = 0.988051
I0624 14:16:47.246620 18353 solver.cpp:244]     Train net output #1: loss = 0.032245 (* 1 = 0.032245 loss)
I0624 14:16:47.246625 18353 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I0624 14:17:01.872440 18353 solver.cpp:228] Iteration 1860, loss = 0.0344382
I0624 14:17:01.872463 18353 solver.cpp:244]     Train net output #0: accuracy = 0.987042
I0624 14:17:01.872470 18353 solver.cpp:244]     Train net output #1: loss = 0.0344382 (* 1 = 0.0344382 loss)
I0624 14:17:01.872475 18353 sgd_solver.cpp:106] Iteration 1860, lr = 0.01
I0624 14:17:16.503384 18353 solver.cpp:228] Iteration 1880, loss = 0.0424625
I0624 14:17:16.503407 18353 solver.cpp:244]     Train net output #0: accuracy = 0.986786
I0624 14:17:16.503414 18353 solver.cpp:244]     Train net output #1: loss = 0.0424625 (* 1 = 0.0424625 loss)
I0624 14:17:16.503419 18353 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I0624 14:17:30.721786 18353 solver.cpp:337] Iteration 1900, Testing net (#0)
I0624 14:17:31.058409 18353 solver.cpp:404]     Test net output #0: accuracy = 0.9802
I0624 14:17:31.058434 18353 solver.cpp:404]     Test net output #1: loss = 0.0526123 (* 1 = 0.0526123 loss)
I0624 14:17:31.469099 18353 solver.cpp:228] Iteration 1900, loss = 0.0359345
I0624 14:17:31.469125 18353 solver.cpp:244]     Train net output #0: accuracy = 0.987274
I0624 14:17:31.469131 18353 solver.cpp:244]     Train net output #1: loss = 0.0359345 (* 1 = 0.0359345 loss)
I0624 14:17:31.469136 18353 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0624 14:17:46.100793 18353 solver.cpp:228] Iteration 1920, loss = 0.0330293
I0624 14:17:46.100816 18353 solver.cpp:244]     Train net output #0: accuracy = 0.987419
I0624 14:17:46.100823 18353 solver.cpp:244]     Train net output #1: loss = 0.0330293 (* 1 = 0.0330293 loss)
I0624 14:17:46.100828 18353 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I0624 14:18:00.743013 18353 solver.cpp:228] Iteration 1940, loss = 0.0329473
I0624 14:18:00.743127 18353 solver.cpp:244]     Train net output #0: accuracy = 0.986966
I0624 14:18:00.743139 18353 solver.cpp:244]     Train net output #1: loss = 0.0329473 (* 1 = 0.0329473 loss)
I0624 14:18:00.743144 18353 sgd_solver.cpp:106] Iteration 1940, lr = 0.01
I0624 14:18:15.376183 18353 solver.cpp:228] Iteration 1960, loss = 0.031651
I0624 14:18:15.376206 18353 solver.cpp:244]     Train net output #0: accuracy = 0.987665
I0624 14:18:15.376214 18353 solver.cpp:244]     Train net output #1: loss = 0.031651 (* 1 = 0.031651 loss)
I0624 14:18:15.376219 18353 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I0624 14:18:30.009703 18353 solver.cpp:228] Iteration 1980, loss = 0.0346759
I0624 14:18:30.009727 18353 solver.cpp:244]     Train net output #0: accuracy = 0.986469
I0624 14:18:30.009734 18353 solver.cpp:244]     Train net output #1: loss = 0.0346759 (* 1 = 0.0346759 loss)
I0624 14:18:30.009738 18353 sgd_solver.cpp:106] Iteration 1980, lr = 0.01
I0624 14:18:44.246991 18353 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_2000.caffemodel
I0624 14:18:44.293891 18353 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_2000.solverstate
I0624 14:18:44.653373 18353 solver.cpp:317] Iteration 2000, loss = 0.0353529
I0624 14:18:44.653396 18353 solver.cpp:337] Iteration 2000, Testing net (#0)
I0624 14:18:44.991438 18353 solver.cpp:404]     Test net output #0: accuracy = 0.977843
I0624 14:18:44.991461 18353 solver.cpp:404]     Test net output #1: loss = 0.0576193 (* 1 = 0.0576193 loss)
I0624 14:18:44.991466 18353 solver.cpp:322] Optimization Done.
I0624 14:18:44.991468 18353 caffe.cpp:222] Optimization Done.
I0624 14:20:05.943852 18728 caffe.cpp:185] Using GPUs 1
I0624 14:20:05.959584 18728 caffe.cpp:190] GPU 1: GeForce GTX TITAN X
I0624 14:20:06.313060 18728 solver.cpp:48] Initializing solver from parameters: 
test_iter: 16
test_interval: 100
base_lr: 0.01
display: 20
max_iter: 4000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 500
snapshot_prefix: "data/models/segnet"
solver_mode: GPU
device_id: 1
net: "models/segnet/train_val.prototxt"
test_initialization: true
iter_size: 1
I0624 14:20:06.313172 18728 solver.cpp:91] Creating training net from net file: models/segnet/train_val.prototxt
I0624 14:20:06.314604 18728 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0624 14:20:06.315026 18728 net.cpp:49] Initializing net from parameters: 
name: "segnet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "DenseImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 224
    mean_value: 100
  }
  dense_image_data_param {
    source: "data/train_seg.txt"
    batch_size: 32
    shuffle: true
    new_height: 224
    new_width: 310
    is_color: false
    root_folder: "data/raw/train/"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 14
    upsample_w: 14
  }
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2_D"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2_D"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1_D"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1_D"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 28
    upsample_w: 28
  }
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2_D"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2_D"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1_D"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1_D"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
    upsample_h: 56
    upsample_w: 56
  }
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn3_2_D"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2_D"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1_D"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1_D"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
    upsample_h: 112
    upsample_w: 112
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2_D"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2_D"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1_D"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1_D"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
    upsample_h: 224
    upsample_w: 224
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2_D"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2_D"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2
    bias_term: true
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "accuracy"
}
I0624 14:20:06.315304 18728 layer_factory.hpp:77] Creating layer data
I0624 14:20:06.315336 18728 net.cpp:91] Creating Layer data
I0624 14:20:06.315341 18728 net.cpp:399] data -> data
I0624 14:20:06.315361 18728 net.cpp:399] data -> label
I0624 14:20:06.315675 18728 dense_image_data_layer.cpp:38] Opening file data/train_seg.txt
I0624 14:20:06.316576 18728 dense_image_data_layer.cpp:48] Shuffling data
I0624 14:20:06.316787 18728 dense_image_data_layer.cpp:53] A total of 2024 examples.
I0624 14:20:06.566215 18728 dense_image_data_layer.cpp:92] output data size: 1,1,224,224
I0624 14:20:06.568034 18728 net.cpp:141] Setting up data
I0624 14:20:06.568053 18728 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 14:20:06.568058 18728 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 14:20:06.568059 18728 net.cpp:156] Memory required for data: 401408
I0624 14:20:06.568066 18728 layer_factory.hpp:77] Creating layer label_data_1_split
I0624 14:20:06.568080 18728 net.cpp:91] Creating Layer label_data_1_split
I0624 14:20:06.568084 18728 net.cpp:425] label_data_1_split <- label
I0624 14:20:06.568094 18728 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0624 14:20:06.568102 18728 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0624 14:20:06.568183 18728 net.cpp:141] Setting up label_data_1_split
I0624 14:20:06.568192 18728 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 14:20:06.568194 18728 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 14:20:06.568197 18728 net.cpp:156] Memory required for data: 802816
I0624 14:20:06.568198 18728 layer_factory.hpp:77] Creating layer conv1_1
I0624 14:20:06.568213 18728 net.cpp:91] Creating Layer conv1_1
I0624 14:20:06.568218 18728 net.cpp:425] conv1_1 <- data
I0624 14:20:06.568223 18728 net.cpp:399] conv1_1 -> conv1_1
I0624 14:20:06.755383 18728 net.cpp:141] Setting up conv1_1
I0624 14:20:06.755409 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.755411 18728 net.cpp:156] Memory required for data: 7225344
I0624 14:20:06.755424 18728 layer_factory.hpp:77] Creating layer bn1_1
I0624 14:20:06.755439 18728 net.cpp:91] Creating Layer bn1_1
I0624 14:20:06.755444 18728 net.cpp:425] bn1_1 <- conv1_1
I0624 14:20:06.755448 18728 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0624 14:20:06.755633 18728 net.cpp:141] Setting up bn1_1
I0624 14:20:06.755641 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.755645 18728 net.cpp:156] Memory required for data: 13647872
I0624 14:20:06.755652 18728 layer_factory.hpp:77] Creating layer scale1_1
I0624 14:20:06.755661 18728 net.cpp:91] Creating Layer scale1_1
I0624 14:20:06.755664 18728 net.cpp:425] scale1_1 <- conv1_1
I0624 14:20:06.755667 18728 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0624 14:20:06.755702 18728 layer_factory.hpp:77] Creating layer scale1_1
I0624 14:20:06.755859 18728 net.cpp:141] Setting up scale1_1
I0624 14:20:06.755867 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.755869 18728 net.cpp:156] Memory required for data: 20070400
I0624 14:20:06.755875 18728 layer_factory.hpp:77] Creating layer relu1_1
I0624 14:20:06.755880 18728 net.cpp:91] Creating Layer relu1_1
I0624 14:20:06.755883 18728 net.cpp:425] relu1_1 <- conv1_1
I0624 14:20:06.755887 18728 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0624 14:20:06.756150 18728 net.cpp:141] Setting up relu1_1
I0624 14:20:06.756161 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.756163 18728 net.cpp:156] Memory required for data: 26492928
I0624 14:20:06.756166 18728 layer_factory.hpp:77] Creating layer conv1_2
I0624 14:20:06.756175 18728 net.cpp:91] Creating Layer conv1_2
I0624 14:20:06.756177 18728 net.cpp:425] conv1_2 <- conv1_1
I0624 14:20:06.756182 18728 net.cpp:399] conv1_2 -> conv1_2
I0624 14:20:06.757727 18728 net.cpp:141] Setting up conv1_2
I0624 14:20:06.757740 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.757742 18728 net.cpp:156] Memory required for data: 32915456
I0624 14:20:06.757746 18728 layer_factory.hpp:77] Creating layer bn1_2
I0624 14:20:06.757752 18728 net.cpp:91] Creating Layer bn1_2
I0624 14:20:06.757755 18728 net.cpp:425] bn1_2 <- conv1_2
I0624 14:20:06.757760 18728 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0624 14:20:06.757932 18728 net.cpp:141] Setting up bn1_2
I0624 14:20:06.757941 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.757942 18728 net.cpp:156] Memory required for data: 39337984
I0624 14:20:06.757951 18728 layer_factory.hpp:77] Creating layer scale1_2
I0624 14:20:06.757972 18728 net.cpp:91] Creating Layer scale1_2
I0624 14:20:06.757974 18728 net.cpp:425] scale1_2 <- conv1_2
I0624 14:20:06.757978 18728 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0624 14:20:06.758010 18728 layer_factory.hpp:77] Creating layer scale1_2
I0624 14:20:06.758167 18728 net.cpp:141] Setting up scale1_2
I0624 14:20:06.758173 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.758175 18728 net.cpp:156] Memory required for data: 45760512
I0624 14:20:06.758180 18728 layer_factory.hpp:77] Creating layer relu1_2
I0624 14:20:06.758184 18728 net.cpp:91] Creating Layer relu1_2
I0624 14:20:06.758188 18728 net.cpp:425] relu1_2 <- conv1_2
I0624 14:20:06.758190 18728 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0624 14:20:06.758322 18728 net.cpp:141] Setting up relu1_2
I0624 14:20:06.758330 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.758333 18728 net.cpp:156] Memory required for data: 52183040
I0624 14:20:06.758335 18728 layer_factory.hpp:77] Creating layer pool1
I0624 14:20:06.758338 18728 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 14:20:06.758343 18728 net.cpp:91] Creating Layer pool1
I0624 14:20:06.758345 18728 net.cpp:425] pool1 <- conv1_2
I0624 14:20:06.758349 18728 net.cpp:399] pool1 -> pool1
I0624 14:20:06.758357 18728 net.cpp:399] pool1 -> pool1_mask
I0624 14:20:06.758399 18728 net.cpp:141] Setting up pool1
I0624 14:20:06.758404 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.758405 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.758407 18728 net.cpp:156] Memory required for data: 55394304
I0624 14:20:06.758410 18728 layer_factory.hpp:77] Creating layer conv2_1
I0624 14:20:06.758417 18728 net.cpp:91] Creating Layer conv2_1
I0624 14:20:06.758419 18728 net.cpp:425] conv2_1 <- pool1
I0624 14:20:06.758424 18728 net.cpp:399] conv2_1 -> conv2_1
I0624 14:20:06.760037 18728 net.cpp:141] Setting up conv2_1
I0624 14:20:06.760049 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.760052 18728 net.cpp:156] Memory required for data: 58605568
I0624 14:20:06.760057 18728 layer_factory.hpp:77] Creating layer bn2_1
I0624 14:20:06.760063 18728 net.cpp:91] Creating Layer bn2_1
I0624 14:20:06.760066 18728 net.cpp:425] bn2_1 <- conv2_1
I0624 14:20:06.760071 18728 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0624 14:20:06.760227 18728 net.cpp:141] Setting up bn2_1
I0624 14:20:06.760236 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.760238 18728 net.cpp:156] Memory required for data: 61816832
I0624 14:20:06.760243 18728 layer_factory.hpp:77] Creating layer scale2_1
I0624 14:20:06.760249 18728 net.cpp:91] Creating Layer scale2_1
I0624 14:20:06.760251 18728 net.cpp:425] scale2_1 <- conv2_1
I0624 14:20:06.760257 18728 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0624 14:20:06.760293 18728 layer_factory.hpp:77] Creating layer scale2_1
I0624 14:20:06.760392 18728 net.cpp:141] Setting up scale2_1
I0624 14:20:06.760401 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.760402 18728 net.cpp:156] Memory required for data: 65028096
I0624 14:20:06.760411 18728 layer_factory.hpp:77] Creating layer relu2_1
I0624 14:20:06.760416 18728 net.cpp:91] Creating Layer relu2_1
I0624 14:20:06.760417 18728 net.cpp:425] relu2_1 <- conv2_1
I0624 14:20:06.760421 18728 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0624 14:20:06.760691 18728 net.cpp:141] Setting up relu2_1
I0624 14:20:06.760702 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.760705 18728 net.cpp:156] Memory required for data: 68239360
I0624 14:20:06.760709 18728 layer_factory.hpp:77] Creating layer conv2_2
I0624 14:20:06.760716 18728 net.cpp:91] Creating Layer conv2_2
I0624 14:20:06.760720 18728 net.cpp:425] conv2_2 <- conv2_1
I0624 14:20:06.760723 18728 net.cpp:399] conv2_2 -> conv2_2
I0624 14:20:06.761735 18728 net.cpp:141] Setting up conv2_2
I0624 14:20:06.761746 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.761759 18728 net.cpp:156] Memory required for data: 71450624
I0624 14:20:06.761764 18728 layer_factory.hpp:77] Creating layer bn2_2
I0624 14:20:06.761771 18728 net.cpp:91] Creating Layer bn2_2
I0624 14:20:06.761775 18728 net.cpp:425] bn2_2 <- conv2_2
I0624 14:20:06.761780 18728 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0624 14:20:06.761934 18728 net.cpp:141] Setting up bn2_2
I0624 14:20:06.761940 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.761942 18728 net.cpp:156] Memory required for data: 74661888
I0624 14:20:06.761948 18728 layer_factory.hpp:77] Creating layer scale2_2
I0624 14:20:06.761955 18728 net.cpp:91] Creating Layer scale2_2
I0624 14:20:06.761958 18728 net.cpp:425] scale2_2 <- conv2_2
I0624 14:20:06.761961 18728 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0624 14:20:06.761993 18728 layer_factory.hpp:77] Creating layer scale2_2
I0624 14:20:06.762089 18728 net.cpp:141] Setting up scale2_2
I0624 14:20:06.762095 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.762097 18728 net.cpp:156] Memory required for data: 77873152
I0624 14:20:06.762101 18728 layer_factory.hpp:77] Creating layer relu2_2
I0624 14:20:06.762106 18728 net.cpp:91] Creating Layer relu2_2
I0624 14:20:06.762109 18728 net.cpp:425] relu2_2 <- conv2_2
I0624 14:20:06.762115 18728 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0624 14:20:06.762380 18728 net.cpp:141] Setting up relu2_2
I0624 14:20:06.762390 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.762393 18728 net.cpp:156] Memory required for data: 81084416
I0624 14:20:06.762397 18728 layer_factory.hpp:77] Creating layer pool2
I0624 14:20:06.762399 18728 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 14:20:06.762404 18728 net.cpp:91] Creating Layer pool2
I0624 14:20:06.762408 18728 net.cpp:425] pool2 <- conv2_2
I0624 14:20:06.762411 18728 net.cpp:399] pool2 -> pool2
I0624 14:20:06.762415 18728 net.cpp:399] pool2 -> pool2_mask
I0624 14:20:06.762452 18728 net.cpp:141] Setting up pool2
I0624 14:20:06.762457 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.762460 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.762462 18728 net.cpp:156] Memory required for data: 82690048
I0624 14:20:06.762465 18728 layer_factory.hpp:77] Creating layer conv3_1
I0624 14:20:06.762471 18728 net.cpp:91] Creating Layer conv3_1
I0624 14:20:06.762475 18728 net.cpp:425] conv3_1 <- pool2
I0624 14:20:06.762478 18728 net.cpp:399] conv3_1 -> conv3_1
I0624 14:20:06.764432 18728 net.cpp:141] Setting up conv3_1
I0624 14:20:06.764446 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.764448 18728 net.cpp:156] Memory required for data: 84295680
I0624 14:20:06.764452 18728 layer_factory.hpp:77] Creating layer bn3_1
I0624 14:20:06.764458 18728 net.cpp:91] Creating Layer bn3_1
I0624 14:20:06.764461 18728 net.cpp:425] bn3_1 <- conv3_1
I0624 14:20:06.764466 18728 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0624 14:20:06.765233 18728 net.cpp:141] Setting up bn3_1
I0624 14:20:06.765244 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.765245 18728 net.cpp:156] Memory required for data: 85901312
I0624 14:20:06.765251 18728 layer_factory.hpp:77] Creating layer scale3_1
I0624 14:20:06.765257 18728 net.cpp:91] Creating Layer scale3_1
I0624 14:20:06.765260 18728 net.cpp:425] scale3_1 <- conv3_1
I0624 14:20:06.765270 18728 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0624 14:20:06.765305 18728 layer_factory.hpp:77] Creating layer scale3_1
I0624 14:20:06.765393 18728 net.cpp:141] Setting up scale3_1
I0624 14:20:06.765400 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.765403 18728 net.cpp:156] Memory required for data: 87506944
I0624 14:20:06.765406 18728 layer_factory.hpp:77] Creating layer relu3_1
I0624 14:20:06.765411 18728 net.cpp:91] Creating Layer relu3_1
I0624 14:20:06.765413 18728 net.cpp:425] relu3_1 <- conv3_1
I0624 14:20:06.765418 18728 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0624 14:20:06.765561 18728 net.cpp:141] Setting up relu3_1
I0624 14:20:06.765570 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.765581 18728 net.cpp:156] Memory required for data: 89112576
I0624 14:20:06.765584 18728 layer_factory.hpp:77] Creating layer conv3_2
I0624 14:20:06.765594 18728 net.cpp:91] Creating Layer conv3_2
I0624 14:20:06.765595 18728 net.cpp:425] conv3_2 <- conv3_1
I0624 14:20:06.765600 18728 net.cpp:399] conv3_2 -> conv3_2
I0624 14:20:06.767554 18728 net.cpp:141] Setting up conv3_2
I0624 14:20:06.767566 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.767570 18728 net.cpp:156] Memory required for data: 90718208
I0624 14:20:06.767573 18728 layer_factory.hpp:77] Creating layer bn3_2
I0624 14:20:06.767581 18728 net.cpp:91] Creating Layer bn3_2
I0624 14:20:06.767583 18728 net.cpp:425] bn3_2 <- conv3_2
I0624 14:20:06.767590 18728 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0624 14:20:06.767782 18728 net.cpp:141] Setting up bn3_2
I0624 14:20:06.767796 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.767798 18728 net.cpp:156] Memory required for data: 92323840
I0624 14:20:06.767812 18728 layer_factory.hpp:77] Creating layer scale3_2
I0624 14:20:06.767817 18728 net.cpp:91] Creating Layer scale3_2
I0624 14:20:06.767820 18728 net.cpp:425] scale3_2 <- conv3_2
I0624 14:20:06.767824 18728 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0624 14:20:06.767860 18728 layer_factory.hpp:77] Creating layer scale3_2
I0624 14:20:06.767956 18728 net.cpp:141] Setting up scale3_2
I0624 14:20:06.767962 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.767964 18728 net.cpp:156] Memory required for data: 93929472
I0624 14:20:06.767969 18728 layer_factory.hpp:77] Creating layer relu3_2
I0624 14:20:06.767973 18728 net.cpp:91] Creating Layer relu3_2
I0624 14:20:06.767976 18728 net.cpp:425] relu3_2 <- conv3_2
I0624 14:20:06.767981 18728 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0624 14:20:06.768259 18728 net.cpp:141] Setting up relu3_2
I0624 14:20:06.768270 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.768272 18728 net.cpp:156] Memory required for data: 95535104
I0624 14:20:06.768275 18728 layer_factory.hpp:77] Creating layer pool3
I0624 14:20:06.768277 18728 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 14:20:06.768282 18728 net.cpp:91] Creating Layer pool3
I0624 14:20:06.768285 18728 net.cpp:425] pool3 <- conv3_2
I0624 14:20:06.768290 18728 net.cpp:399] pool3 -> pool3
I0624 14:20:06.768296 18728 net.cpp:399] pool3 -> pool3_mask
I0624 14:20:06.768332 18728 net.cpp:141] Setting up pool3
I0624 14:20:06.768338 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.768342 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.768343 18728 net.cpp:156] Memory required for data: 96337920
I0624 14:20:06.768345 18728 layer_factory.hpp:77] Creating layer conv4_1
I0624 14:20:06.768353 18728 net.cpp:91] Creating Layer conv4_1
I0624 14:20:06.768355 18728 net.cpp:425] conv4_1 <- pool3
I0624 14:20:06.768359 18728 net.cpp:399] conv4_1 -> conv4_1
I0624 14:20:06.772145 18728 net.cpp:141] Setting up conv4_1
I0624 14:20:06.772161 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.772163 18728 net.cpp:156] Memory required for data: 97140736
I0624 14:20:06.772168 18728 layer_factory.hpp:77] Creating layer bn4_1
I0624 14:20:06.772174 18728 net.cpp:91] Creating Layer bn4_1
I0624 14:20:06.772176 18728 net.cpp:425] bn4_1 <- conv4_1
I0624 14:20:06.772183 18728 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0624 14:20:06.772346 18728 net.cpp:141] Setting up bn4_1
I0624 14:20:06.772354 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.772357 18728 net.cpp:156] Memory required for data: 97943552
I0624 14:20:06.772363 18728 layer_factory.hpp:77] Creating layer scale4_1
I0624 14:20:06.772369 18728 net.cpp:91] Creating Layer scale4_1
I0624 14:20:06.772372 18728 net.cpp:425] scale4_1 <- conv4_1
I0624 14:20:06.772375 18728 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0624 14:20:06.772409 18728 layer_factory.hpp:77] Creating layer scale4_1
I0624 14:20:06.772501 18728 net.cpp:141] Setting up scale4_1
I0624 14:20:06.772518 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.772521 18728 net.cpp:156] Memory required for data: 98746368
I0624 14:20:06.772526 18728 layer_factory.hpp:77] Creating layer relu4_1
I0624 14:20:06.772533 18728 net.cpp:91] Creating Layer relu4_1
I0624 14:20:06.772536 18728 net.cpp:425] relu4_1 <- conv4_1
I0624 14:20:06.772541 18728 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0624 14:20:06.772822 18728 net.cpp:141] Setting up relu4_1
I0624 14:20:06.772835 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.772837 18728 net.cpp:156] Memory required for data: 99549184
I0624 14:20:06.772840 18728 layer_factory.hpp:77] Creating layer conv4_2
I0624 14:20:06.772848 18728 net.cpp:91] Creating Layer conv4_2
I0624 14:20:06.772851 18728 net.cpp:425] conv4_2 <- conv4_1
I0624 14:20:06.772856 18728 net.cpp:399] conv4_2 -> conv4_2
I0624 14:20:06.778498 18728 net.cpp:141] Setting up conv4_2
I0624 14:20:06.778511 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.778513 18728 net.cpp:156] Memory required for data: 100352000
I0624 14:20:06.778518 18728 layer_factory.hpp:77] Creating layer bn4_2
I0624 14:20:06.778527 18728 net.cpp:91] Creating Layer bn4_2
I0624 14:20:06.778528 18728 net.cpp:425] bn4_2 <- conv4_2
I0624 14:20:06.778532 18728 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0624 14:20:06.778694 18728 net.cpp:141] Setting up bn4_2
I0624 14:20:06.778702 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.778704 18728 net.cpp:156] Memory required for data: 101154816
I0624 14:20:06.778710 18728 layer_factory.hpp:77] Creating layer scale4_2
I0624 14:20:06.778717 18728 net.cpp:91] Creating Layer scale4_2
I0624 14:20:06.778720 18728 net.cpp:425] scale4_2 <- conv4_2
I0624 14:20:06.778724 18728 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0624 14:20:06.778758 18728 layer_factory.hpp:77] Creating layer scale4_2
I0624 14:20:06.778852 18728 net.cpp:141] Setting up scale4_2
I0624 14:20:06.778859 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.778861 18728 net.cpp:156] Memory required for data: 101957632
I0624 14:20:06.778866 18728 layer_factory.hpp:77] Creating layer relu4_2
I0624 14:20:06.778870 18728 net.cpp:91] Creating Layer relu4_2
I0624 14:20:06.778873 18728 net.cpp:425] relu4_2 <- conv4_2
I0624 14:20:06.778877 18728 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0624 14:20:06.779021 18728 net.cpp:141] Setting up relu4_2
I0624 14:20:06.779031 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.779032 18728 net.cpp:156] Memory required for data: 102760448
I0624 14:20:06.779036 18728 layer_factory.hpp:77] Creating layer pool4
I0624 14:20:06.779038 18728 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 14:20:06.779043 18728 net.cpp:91] Creating Layer pool4
I0624 14:20:06.779045 18728 net.cpp:425] pool4 <- conv4_2
I0624 14:20:06.779050 18728 net.cpp:399] pool4 -> pool4
I0624 14:20:06.779055 18728 net.cpp:399] pool4 -> pool4_mask
I0624 14:20:06.779094 18728 net.cpp:141] Setting up pool4
I0624 14:20:06.779099 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.779101 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.779103 18728 net.cpp:156] Memory required for data: 103161856
I0624 14:20:06.779106 18728 layer_factory.hpp:77] Creating layer conv5_1
I0624 14:20:06.779114 18728 net.cpp:91] Creating Layer conv5_1
I0624 14:20:06.779117 18728 net.cpp:425] conv5_1 <- pool4
I0624 14:20:06.779121 18728 net.cpp:399] conv5_1 -> conv5_1
I0624 14:20:06.784559 18728 net.cpp:141] Setting up conv5_1
I0624 14:20:06.784572 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.784574 18728 net.cpp:156] Memory required for data: 103362560
I0624 14:20:06.784579 18728 layer_factory.hpp:77] Creating layer bn5_1
I0624 14:20:06.784586 18728 net.cpp:91] Creating Layer bn5_1
I0624 14:20:06.784590 18728 net.cpp:425] bn5_1 <- conv5_1
I0624 14:20:06.784595 18728 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0624 14:20:06.784767 18728 net.cpp:141] Setting up bn5_1
I0624 14:20:06.784785 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.784787 18728 net.cpp:156] Memory required for data: 103563264
I0624 14:20:06.784793 18728 layer_factory.hpp:77] Creating layer scale5_1
I0624 14:20:06.784800 18728 net.cpp:91] Creating Layer scale5_1
I0624 14:20:06.784801 18728 net.cpp:425] scale5_1 <- conv5_1
I0624 14:20:06.784808 18728 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0624 14:20:06.784845 18728 layer_factory.hpp:77] Creating layer scale5_1
I0624 14:20:06.784939 18728 net.cpp:141] Setting up scale5_1
I0624 14:20:06.784946 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.784948 18728 net.cpp:156] Memory required for data: 103763968
I0624 14:20:06.784953 18728 layer_factory.hpp:77] Creating layer relu5_1
I0624 14:20:06.784957 18728 net.cpp:91] Creating Layer relu5_1
I0624 14:20:06.784960 18728 net.cpp:425] relu5_1 <- conv5_1
I0624 14:20:06.784965 18728 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0624 14:20:06.785238 18728 net.cpp:141] Setting up relu5_1
I0624 14:20:06.785250 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.785253 18728 net.cpp:156] Memory required for data: 103964672
I0624 14:20:06.785255 18728 layer_factory.hpp:77] Creating layer conv5_2
I0624 14:20:06.785264 18728 net.cpp:91] Creating Layer conv5_2
I0624 14:20:06.785267 18728 net.cpp:425] conv5_2 <- conv5_1
I0624 14:20:06.785271 18728 net.cpp:399] conv5_2 -> conv5_2
I0624 14:20:06.790653 18728 net.cpp:141] Setting up conv5_2
I0624 14:20:06.790669 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.790673 18728 net.cpp:156] Memory required for data: 104165376
I0624 14:20:06.790676 18728 layer_factory.hpp:77] Creating layer bn5_2
I0624 14:20:06.790683 18728 net.cpp:91] Creating Layer bn5_2
I0624 14:20:06.790686 18728 net.cpp:425] bn5_2 <- conv5_2
I0624 14:20:06.790691 18728 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0624 14:20:06.790856 18728 net.cpp:141] Setting up bn5_2
I0624 14:20:06.790863 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.790866 18728 net.cpp:156] Memory required for data: 104366080
I0624 14:20:06.790871 18728 layer_factory.hpp:77] Creating layer scale5_2
I0624 14:20:06.790877 18728 net.cpp:91] Creating Layer scale5_2
I0624 14:20:06.790880 18728 net.cpp:425] scale5_2 <- conv5_2
I0624 14:20:06.790884 18728 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0624 14:20:06.790920 18728 layer_factory.hpp:77] Creating layer scale5_2
I0624 14:20:06.791013 18728 net.cpp:141] Setting up scale5_2
I0624 14:20:06.791019 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.791021 18728 net.cpp:156] Memory required for data: 104566784
I0624 14:20:06.791025 18728 layer_factory.hpp:77] Creating layer relu5_2
I0624 14:20:06.791031 18728 net.cpp:91] Creating Layer relu5_2
I0624 14:20:06.791033 18728 net.cpp:425] relu5_2 <- conv5_2
I0624 14:20:06.791038 18728 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0624 14:20:06.791321 18728 net.cpp:141] Setting up relu5_2
I0624 14:20:06.791332 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.791333 18728 net.cpp:156] Memory required for data: 104767488
I0624 14:20:06.791337 18728 layer_factory.hpp:77] Creating layer pool5
I0624 14:20:06.791339 18728 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 14:20:06.791344 18728 net.cpp:91] Creating Layer pool5
I0624 14:20:06.791348 18728 net.cpp:425] pool5 <- conv5_2
I0624 14:20:06.791352 18728 net.cpp:399] pool5 -> pool5
I0624 14:20:06.791357 18728 net.cpp:399] pool5 -> pool5_mask
I0624 14:20:06.791399 18728 net.cpp:141] Setting up pool5
I0624 14:20:06.791409 18728 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 14:20:06.791412 18728 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 14:20:06.791414 18728 net.cpp:156] Memory required for data: 104867840
I0624 14:20:06.791416 18728 layer_factory.hpp:77] Creating layer upsample5
I0624 14:20:06.791422 18728 net.cpp:91] Creating Layer upsample5
I0624 14:20:06.791424 18728 net.cpp:425] upsample5 <- pool5
I0624 14:20:06.791427 18728 net.cpp:425] upsample5 <- pool5_mask
I0624 14:20:06.791443 18728 net.cpp:399] upsample5 -> pool5_D
I0624 14:20:06.791473 18728 net.cpp:141] Setting up upsample5
I0624 14:20:06.791477 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.791479 18728 net.cpp:156] Memory required for data: 105068544
I0624 14:20:06.791481 18728 layer_factory.hpp:77] Creating layer conv5_2_D
I0624 14:20:06.791489 18728 net.cpp:91] Creating Layer conv5_2_D
I0624 14:20:06.791492 18728 net.cpp:425] conv5_2_D <- pool5_D
I0624 14:20:06.791497 18728 net.cpp:399] conv5_2_D -> conv5_2_D
I0624 14:20:06.797046 18728 net.cpp:141] Setting up conv5_2_D
I0624 14:20:06.797058 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.797061 18728 net.cpp:156] Memory required for data: 105269248
I0624 14:20:06.797065 18728 layer_factory.hpp:77] Creating layer bn5_2_D
I0624 14:20:06.797072 18728 net.cpp:91] Creating Layer bn5_2_D
I0624 14:20:06.797075 18728 net.cpp:425] bn5_2_D <- conv5_2_D
I0624 14:20:06.797080 18728 net.cpp:386] bn5_2_D -> conv5_2_D (in-place)
I0624 14:20:06.797256 18728 net.cpp:141] Setting up bn5_2_D
I0624 14:20:06.797263 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.797266 18728 net.cpp:156] Memory required for data: 105469952
I0624 14:20:06.797271 18728 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 14:20:06.797277 18728 net.cpp:91] Creating Layer scale5_2_D
I0624 14:20:06.797281 18728 net.cpp:425] scale5_2_D <- conv5_2_D
I0624 14:20:06.797284 18728 net.cpp:386] scale5_2_D -> conv5_2_D (in-place)
I0624 14:20:06.797319 18728 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 14:20:06.797415 18728 net.cpp:141] Setting up scale5_2_D
I0624 14:20:06.797422 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.797425 18728 net.cpp:156] Memory required for data: 105670656
I0624 14:20:06.797437 18728 layer_factory.hpp:77] Creating layer relu5_2_D
I0624 14:20:06.797444 18728 net.cpp:91] Creating Layer relu5_2_D
I0624 14:20:06.797447 18728 net.cpp:425] relu5_2_D <- conv5_2_D
I0624 14:20:06.797451 18728 net.cpp:386] relu5_2_D -> conv5_2_D (in-place)
I0624 14:20:06.797601 18728 net.cpp:141] Setting up relu5_2_D
I0624 14:20:06.797610 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.797613 18728 net.cpp:156] Memory required for data: 105871360
I0624 14:20:06.797616 18728 layer_factory.hpp:77] Creating layer conv5_1_D
I0624 14:20:06.797626 18728 net.cpp:91] Creating Layer conv5_1_D
I0624 14:20:06.797629 18728 net.cpp:425] conv5_1_D <- conv5_2_D
I0624 14:20:06.797633 18728 net.cpp:399] conv5_1_D -> conv5_1_D
I0624 14:20:06.803158 18728 net.cpp:141] Setting up conv5_1_D
I0624 14:20:06.803171 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.803174 18728 net.cpp:156] Memory required for data: 106072064
I0624 14:20:06.803179 18728 layer_factory.hpp:77] Creating layer bn5_1_D
I0624 14:20:06.803185 18728 net.cpp:91] Creating Layer bn5_1_D
I0624 14:20:06.803189 18728 net.cpp:425] bn5_1_D <- conv5_1_D
I0624 14:20:06.803194 18728 net.cpp:386] bn5_1_D -> conv5_1_D (in-place)
I0624 14:20:06.803375 18728 net.cpp:141] Setting up bn5_1_D
I0624 14:20:06.803382 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.803385 18728 net.cpp:156] Memory required for data: 106272768
I0624 14:20:06.803390 18728 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 14:20:06.803396 18728 net.cpp:91] Creating Layer scale5_1_D
I0624 14:20:06.803398 18728 net.cpp:425] scale5_1_D <- conv5_1_D
I0624 14:20:06.803403 18728 net.cpp:386] scale5_1_D -> conv5_1_D (in-place)
I0624 14:20:06.803442 18728 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 14:20:06.803544 18728 net.cpp:141] Setting up scale5_1_D
I0624 14:20:06.803550 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.803552 18728 net.cpp:156] Memory required for data: 106473472
I0624 14:20:06.803557 18728 layer_factory.hpp:77] Creating layer relu5_1_D
I0624 14:20:06.803561 18728 net.cpp:91] Creating Layer relu5_1_D
I0624 14:20:06.803565 18728 net.cpp:425] relu5_1_D <- conv5_1_D
I0624 14:20:06.803568 18728 net.cpp:386] relu5_1_D -> conv5_1_D (in-place)
I0624 14:20:06.803861 18728 net.cpp:141] Setting up relu5_1_D
I0624 14:20:06.803872 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.803875 18728 net.cpp:156] Memory required for data: 106674176
I0624 14:20:06.803877 18728 layer_factory.hpp:77] Creating layer upsample4
I0624 14:20:06.803884 18728 net.cpp:91] Creating Layer upsample4
I0624 14:20:06.803886 18728 net.cpp:425] upsample4 <- conv5_1_D
I0624 14:20:06.803890 18728 net.cpp:425] upsample4 <- pool4_mask
I0624 14:20:06.803895 18728 net.cpp:399] upsample4 -> pool4_D
I0624 14:20:06.803925 18728 net.cpp:141] Setting up upsample4
I0624 14:20:06.803930 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.803932 18728 net.cpp:156] Memory required for data: 107476992
I0624 14:20:06.803935 18728 layer_factory.hpp:77] Creating layer conv4_2_D
I0624 14:20:06.803941 18728 net.cpp:91] Creating Layer conv4_2_D
I0624 14:20:06.803944 18728 net.cpp:425] conv4_2_D <- pool4_D
I0624 14:20:06.803949 18728 net.cpp:399] conv4_2_D -> conv4_2_D
I0624 14:20:06.809365 18728 net.cpp:141] Setting up conv4_2_D
I0624 14:20:06.809378 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.809381 18728 net.cpp:156] Memory required for data: 108279808
I0624 14:20:06.809386 18728 layer_factory.hpp:77] Creating layer bn4_2_D
I0624 14:20:06.809392 18728 net.cpp:91] Creating Layer bn4_2_D
I0624 14:20:06.809396 18728 net.cpp:425] bn4_2_D <- conv4_2_D
I0624 14:20:06.809401 18728 net.cpp:386] bn4_2_D -> conv4_2_D (in-place)
I0624 14:20:06.809581 18728 net.cpp:141] Setting up bn4_2_D
I0624 14:20:06.809587 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.809590 18728 net.cpp:156] Memory required for data: 109082624
I0624 14:20:06.809595 18728 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 14:20:06.809602 18728 net.cpp:91] Creating Layer scale4_2_D
I0624 14:20:06.809605 18728 net.cpp:425] scale4_2_D <- conv4_2_D
I0624 14:20:06.809608 18728 net.cpp:386] scale4_2_D -> conv4_2_D (in-place)
I0624 14:20:06.809644 18728 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 14:20:06.809743 18728 net.cpp:141] Setting up scale4_2_D
I0624 14:20:06.809751 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.809752 18728 net.cpp:156] Memory required for data: 109885440
I0624 14:20:06.809757 18728 layer_factory.hpp:77] Creating layer relu4_2_D
I0624 14:20:06.809762 18728 net.cpp:91] Creating Layer relu4_2_D
I0624 14:20:06.809763 18728 net.cpp:425] relu4_2_D <- conv4_2_D
I0624 14:20:06.809769 18728 net.cpp:386] relu4_2_D -> conv4_2_D (in-place)
I0624 14:20:06.810048 18728 net.cpp:141] Setting up relu4_2_D
I0624 14:20:06.810060 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.810062 18728 net.cpp:156] Memory required for data: 110688256
I0624 14:20:06.810065 18728 layer_factory.hpp:77] Creating layer conv4_1_D
I0624 14:20:06.810075 18728 net.cpp:91] Creating Layer conv4_1_D
I0624 14:20:06.810076 18728 net.cpp:425] conv4_1_D <- conv4_2_D
I0624 14:20:06.810082 18728 net.cpp:399] conv4_1_D -> conv4_1_D
I0624 14:20:06.813397 18728 net.cpp:141] Setting up conv4_1_D
I0624 14:20:06.813410 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.813411 18728 net.cpp:156] Memory required for data: 111089664
I0624 14:20:06.813417 18728 layer_factory.hpp:77] Creating layer bn4_1_D
I0624 14:20:06.813423 18728 net.cpp:91] Creating Layer bn4_1_D
I0624 14:20:06.813426 18728 net.cpp:425] bn4_1_D <- conv4_1_D
I0624 14:20:06.813431 18728 net.cpp:386] bn4_1_D -> conv4_1_D (in-place)
I0624 14:20:06.813607 18728 net.cpp:141] Setting up bn4_1_D
I0624 14:20:06.813614 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.813617 18728 net.cpp:156] Memory required for data: 111491072
I0624 14:20:06.813622 18728 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 14:20:06.813629 18728 net.cpp:91] Creating Layer scale4_1_D
I0624 14:20:06.813632 18728 net.cpp:425] scale4_1_D <- conv4_1_D
I0624 14:20:06.813635 18728 net.cpp:386] scale4_1_D -> conv4_1_D (in-place)
I0624 14:20:06.813671 18728 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 14:20:06.813784 18728 net.cpp:141] Setting up scale4_1_D
I0624 14:20:06.813792 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.813794 18728 net.cpp:156] Memory required for data: 111892480
I0624 14:20:06.813798 18728 layer_factory.hpp:77] Creating layer relu4_1_D
I0624 14:20:06.813812 18728 net.cpp:91] Creating Layer relu4_1_D
I0624 14:20:06.813815 18728 net.cpp:425] relu4_1_D <- conv4_1_D
I0624 14:20:06.813819 18728 net.cpp:386] relu4_1_D -> conv4_1_D (in-place)
I0624 14:20:06.813972 18728 net.cpp:141] Setting up relu4_1_D
I0624 14:20:06.813980 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.813983 18728 net.cpp:156] Memory required for data: 112293888
I0624 14:20:06.813987 18728 layer_factory.hpp:77] Creating layer upsample3
I0624 14:20:06.813992 18728 net.cpp:91] Creating Layer upsample3
I0624 14:20:06.813995 18728 net.cpp:425] upsample3 <- conv4_1_D
I0624 14:20:06.813998 18728 net.cpp:425] upsample3 <- pool3_mask
I0624 14:20:06.814002 18728 net.cpp:399] upsample3 -> pool3_D
I0624 14:20:06.814029 18728 net.cpp:141] Setting up upsample3
I0624 14:20:06.814034 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.814036 18728 net.cpp:156] Memory required for data: 113899520
I0624 14:20:06.814038 18728 layer_factory.hpp:77] Creating layer conv3_2_D
I0624 14:20:06.814045 18728 net.cpp:91] Creating Layer conv3_2_D
I0624 14:20:06.814049 18728 net.cpp:425] conv3_2_D <- pool3_D
I0624 14:20:06.814054 18728 net.cpp:399] conv3_2_D -> conv3_2_D
I0624 14:20:06.816643 18728 net.cpp:141] Setting up conv3_2_D
I0624 14:20:06.816656 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.816659 18728 net.cpp:156] Memory required for data: 115505152
I0624 14:20:06.816664 18728 layer_factory.hpp:77] Creating layer bn3_2_D
I0624 14:20:06.816679 18728 net.cpp:91] Creating Layer bn3_2_D
I0624 14:20:06.816682 18728 net.cpp:425] bn3_2_D <- conv3_2_D
I0624 14:20:06.816686 18728 net.cpp:386] bn3_2_D -> conv3_2_D (in-place)
I0624 14:20:06.820010 18728 net.cpp:141] Setting up bn3_2_D
I0624 14:20:06.820024 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.820027 18728 net.cpp:156] Memory required for data: 117110784
I0624 14:20:06.820035 18728 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 14:20:06.820044 18728 net.cpp:91] Creating Layer scale3_2_D
I0624 14:20:06.820046 18728 net.cpp:425] scale3_2_D <- conv3_2_D
I0624 14:20:06.820052 18728 net.cpp:386] scale3_2_D -> conv3_2_D (in-place)
I0624 14:20:06.820093 18728 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 14:20:06.820205 18728 net.cpp:141] Setting up scale3_2_D
I0624 14:20:06.820212 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.820214 18728 net.cpp:156] Memory required for data: 118716416
I0624 14:20:06.820219 18728 layer_factory.hpp:77] Creating layer relu3_2_D
I0624 14:20:06.820225 18728 net.cpp:91] Creating Layer relu3_2_D
I0624 14:20:06.820227 18728 net.cpp:425] relu3_2_D <- conv3_2_D
I0624 14:20:06.820230 18728 net.cpp:386] relu3_2_D -> conv3_2_D (in-place)
I0624 14:20:06.823710 18728 net.cpp:141] Setting up relu3_2_D
I0624 14:20:06.823726 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.823729 18728 net.cpp:156] Memory required for data: 120322048
I0624 14:20:06.823734 18728 layer_factory.hpp:77] Creating layer conv3_1_D
I0624 14:20:06.823745 18728 net.cpp:91] Creating Layer conv3_1_D
I0624 14:20:06.823748 18728 net.cpp:425] conv3_1_D <- conv3_2_D
I0624 14:20:06.823755 18728 net.cpp:399] conv3_1_D -> conv3_1_D
I0624 14:20:06.825373 18728 net.cpp:141] Setting up conv3_1_D
I0624 14:20:06.825387 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.825388 18728 net.cpp:156] Memory required for data: 121124864
I0624 14:20:06.825393 18728 layer_factory.hpp:77] Creating layer bn3_1_D
I0624 14:20:06.825399 18728 net.cpp:91] Creating Layer bn3_1_D
I0624 14:20:06.825402 18728 net.cpp:425] bn3_1_D <- conv3_1_D
I0624 14:20:06.825407 18728 net.cpp:386] bn3_1_D -> conv3_1_D (in-place)
I0624 14:20:06.825604 18728 net.cpp:141] Setting up bn3_1_D
I0624 14:20:06.825623 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.825625 18728 net.cpp:156] Memory required for data: 121927680
I0624 14:20:06.825631 18728 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 14:20:06.825639 18728 net.cpp:91] Creating Layer scale3_1_D
I0624 14:20:06.825640 18728 net.cpp:425] scale3_1_D <- conv3_1_D
I0624 14:20:06.825645 18728 net.cpp:386] scale3_1_D -> conv3_1_D (in-place)
I0624 14:20:06.825688 18728 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 14:20:06.825806 18728 net.cpp:141] Setting up scale3_1_D
I0624 14:20:06.825814 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.825816 18728 net.cpp:156] Memory required for data: 122730496
I0624 14:20:06.825820 18728 layer_factory.hpp:77] Creating layer relu3_1_D
I0624 14:20:06.825827 18728 net.cpp:91] Creating Layer relu3_1_D
I0624 14:20:06.825830 18728 net.cpp:425] relu3_1_D <- conv3_1_D
I0624 14:20:06.825834 18728 net.cpp:386] relu3_1_D -> conv3_1_D (in-place)
I0624 14:20:06.826127 18728 net.cpp:141] Setting up relu3_1_D
I0624 14:20:06.826138 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.826140 18728 net.cpp:156] Memory required for data: 123533312
I0624 14:20:06.826143 18728 layer_factory.hpp:77] Creating layer upsample2
I0624 14:20:06.826150 18728 net.cpp:91] Creating Layer upsample2
I0624 14:20:06.826153 18728 net.cpp:425] upsample2 <- conv3_1_D
I0624 14:20:06.826158 18728 net.cpp:425] upsample2 <- pool2_mask
I0624 14:20:06.826160 18728 net.cpp:399] upsample2 -> pool2_D
I0624 14:20:06.826191 18728 net.cpp:141] Setting up upsample2
I0624 14:20:06.826196 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.826198 18728 net.cpp:156] Memory required for data: 126744576
I0624 14:20:06.826200 18728 layer_factory.hpp:77] Creating layer conv2_2_D
I0624 14:20:06.826210 18728 net.cpp:91] Creating Layer conv2_2_D
I0624 14:20:06.826212 18728 net.cpp:425] conv2_2_D <- pool2_D
I0624 14:20:06.826217 18728 net.cpp:399] conv2_2_D -> conv2_2_D
I0624 14:20:06.827476 18728 net.cpp:141] Setting up conv2_2_D
I0624 14:20:06.827487 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.827491 18728 net.cpp:156] Memory required for data: 129955840
I0624 14:20:06.827494 18728 layer_factory.hpp:77] Creating layer bn2_2_D
I0624 14:20:06.827502 18728 net.cpp:91] Creating Layer bn2_2_D
I0624 14:20:06.827504 18728 net.cpp:425] bn2_2_D <- conv2_2_D
I0624 14:20:06.827509 18728 net.cpp:386] bn2_2_D -> conv2_2_D (in-place)
I0624 14:20:06.827709 18728 net.cpp:141] Setting up bn2_2_D
I0624 14:20:06.827718 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.827719 18728 net.cpp:156] Memory required for data: 133167104
I0624 14:20:06.827724 18728 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 14:20:06.827730 18728 net.cpp:91] Creating Layer scale2_2_D
I0624 14:20:06.827733 18728 net.cpp:425] scale2_2_D <- conv2_2_D
I0624 14:20:06.827738 18728 net.cpp:386] scale2_2_D -> conv2_2_D (in-place)
I0624 14:20:06.827775 18728 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 14:20:06.827898 18728 net.cpp:141] Setting up scale2_2_D
I0624 14:20:06.827904 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.827906 18728 net.cpp:156] Memory required for data: 136378368
I0624 14:20:06.827911 18728 layer_factory.hpp:77] Creating layer relu2_2_D
I0624 14:20:06.827916 18728 net.cpp:91] Creating Layer relu2_2_D
I0624 14:20:06.827919 18728 net.cpp:425] relu2_2_D <- conv2_2_D
I0624 14:20:06.827922 18728 net.cpp:386] relu2_2_D -> conv2_2_D (in-place)
I0624 14:20:06.828076 18728 net.cpp:141] Setting up relu2_2_D
I0624 14:20:06.828085 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.828088 18728 net.cpp:156] Memory required for data: 139589632
I0624 14:20:06.828090 18728 layer_factory.hpp:77] Creating layer conv2_1_D
I0624 14:20:06.828100 18728 net.cpp:91] Creating Layer conv2_1_D
I0624 14:20:06.828104 18728 net.cpp:425] conv2_1_D <- conv2_2_D
I0624 14:20:06.828109 18728 net.cpp:399] conv2_1_D -> conv2_1_D
I0624 14:20:06.829138 18728 net.cpp:141] Setting up conv2_1_D
I0624 14:20:06.829157 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.829160 18728 net.cpp:156] Memory required for data: 141195264
I0624 14:20:06.829164 18728 layer_factory.hpp:77] Creating layer bn2_1_D
I0624 14:20:06.829172 18728 net.cpp:91] Creating Layer bn2_1_D
I0624 14:20:06.829174 18728 net.cpp:425] bn2_1_D <- conv2_1_D
I0624 14:20:06.829180 18728 net.cpp:386] bn2_1_D -> conv2_1_D (in-place)
I0624 14:20:06.829376 18728 net.cpp:141] Setting up bn2_1_D
I0624 14:20:06.829383 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.829386 18728 net.cpp:156] Memory required for data: 142800896
I0624 14:20:06.829391 18728 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 14:20:06.829397 18728 net.cpp:91] Creating Layer scale2_1_D
I0624 14:20:06.829399 18728 net.cpp:425] scale2_1_D <- conv2_1_D
I0624 14:20:06.829403 18728 net.cpp:386] scale2_1_D -> conv2_1_D (in-place)
I0624 14:20:06.829442 18728 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 14:20:06.829568 18728 net.cpp:141] Setting up scale2_1_D
I0624 14:20:06.829576 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.829578 18728 net.cpp:156] Memory required for data: 144406528
I0624 14:20:06.829582 18728 layer_factory.hpp:77] Creating layer relu2_1_D
I0624 14:20:06.829588 18728 net.cpp:91] Creating Layer relu2_1_D
I0624 14:20:06.829591 18728 net.cpp:425] relu2_1_D <- conv2_1_D
I0624 14:20:06.829594 18728 net.cpp:386] relu2_1_D -> conv2_1_D (in-place)
I0624 14:20:06.829893 18728 net.cpp:141] Setting up relu2_1_D
I0624 14:20:06.829905 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.829906 18728 net.cpp:156] Memory required for data: 146012160
I0624 14:20:06.829910 18728 layer_factory.hpp:77] Creating layer upsample1
I0624 14:20:06.829916 18728 net.cpp:91] Creating Layer upsample1
I0624 14:20:06.829918 18728 net.cpp:425] upsample1 <- conv2_1_D
I0624 14:20:06.829921 18728 net.cpp:425] upsample1 <- pool1_mask
I0624 14:20:06.829926 18728 net.cpp:399] upsample1 -> pool1_D
I0624 14:20:06.829955 18728 net.cpp:141] Setting up upsample1
I0624 14:20:06.829960 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.829962 18728 net.cpp:156] Memory required for data: 152434688
I0624 14:20:06.829965 18728 layer_factory.hpp:77] Creating layer conv1_2_D
I0624 14:20:06.829973 18728 net.cpp:91] Creating Layer conv1_2_D
I0624 14:20:06.829975 18728 net.cpp:425] conv1_2_D <- pool1_D
I0624 14:20:06.829979 18728 net.cpp:399] conv1_2_D -> conv1_2_D
I0624 14:20:06.830921 18728 net.cpp:141] Setting up conv1_2_D
I0624 14:20:06.830934 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.830936 18728 net.cpp:156] Memory required for data: 158857216
I0624 14:20:06.830940 18728 layer_factory.hpp:77] Creating layer bn1_2_D
I0624 14:20:06.830946 18728 net.cpp:91] Creating Layer bn1_2_D
I0624 14:20:06.830950 18728 net.cpp:425] bn1_2_D <- conv1_2_D
I0624 14:20:06.830956 18728 net.cpp:386] bn1_2_D -> conv1_2_D (in-place)
I0624 14:20:06.831207 18728 net.cpp:141] Setting up bn1_2_D
I0624 14:20:06.831215 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.831218 18728 net.cpp:156] Memory required for data: 165279744
I0624 14:20:06.831224 18728 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 14:20:06.831229 18728 net.cpp:91] Creating Layer scale1_2_D
I0624 14:20:06.831233 18728 net.cpp:425] scale1_2_D <- conv1_2_D
I0624 14:20:06.831238 18728 net.cpp:386] scale1_2_D -> conv1_2_D (in-place)
I0624 14:20:06.831275 18728 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 14:20:06.831465 18728 net.cpp:141] Setting up scale1_2_D
I0624 14:20:06.831473 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.831475 18728 net.cpp:156] Memory required for data: 171702272
I0624 14:20:06.831480 18728 layer_factory.hpp:77] Creating layer relu1_2_D
I0624 14:20:06.831483 18728 net.cpp:91] Creating Layer relu1_2_D
I0624 14:20:06.831486 18728 net.cpp:425] relu1_2_D <- conv1_2_D
I0624 14:20:06.831490 18728 net.cpp:386] relu1_2_D -> conv1_2_D (in-place)
I0624 14:20:06.831840 18728 net.cpp:141] Setting up relu1_2_D
I0624 14:20:06.831852 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.831856 18728 net.cpp:156] Memory required for data: 178124800
I0624 14:20:06.831858 18728 layer_factory.hpp:77] Creating layer conv1_1_D
I0624 14:20:06.831869 18728 net.cpp:91] Creating Layer conv1_1_D
I0624 14:20:06.831873 18728 net.cpp:425] conv1_1_D <- conv1_2_D
I0624 14:20:06.831878 18728 net.cpp:399] conv1_1_D -> conv1_1_D
I0624 14:20:06.833044 18728 net.cpp:141] Setting up conv1_1_D
I0624 14:20:06.833055 18728 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 14:20:06.833058 18728 net.cpp:156] Memory required for data: 178526208
I0624 14:20:06.833063 18728 layer_factory.hpp:77] Creating layer conv1_1_D_conv1_1_D_0_split
I0624 14:20:06.833070 18728 net.cpp:91] Creating Layer conv1_1_D_conv1_1_D_0_split
I0624 14:20:06.833073 18728 net.cpp:425] conv1_1_D_conv1_1_D_0_split <- conv1_1_D
I0624 14:20:06.833077 18728 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_0
I0624 14:20:06.833083 18728 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_1
I0624 14:20:06.833127 18728 net.cpp:141] Setting up conv1_1_D_conv1_1_D_0_split
I0624 14:20:06.833134 18728 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 14:20:06.833137 18728 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 14:20:06.833139 18728 net.cpp:156] Memory required for data: 179329024
I0624 14:20:06.833142 18728 layer_factory.hpp:77] Creating layer loss
I0624 14:20:06.833148 18728 net.cpp:91] Creating Layer loss
I0624 14:20:06.833150 18728 net.cpp:425] loss <- conv1_1_D_conv1_1_D_0_split_0
I0624 14:20:06.833153 18728 net.cpp:425] loss <- label_data_1_split_0
I0624 14:20:06.833156 18728 net.cpp:399] loss -> loss
I0624 14:20:06.833164 18728 layer_factory.hpp:77] Creating layer loss
I0624 14:20:06.834095 18728 net.cpp:141] Setting up loss
I0624 14:20:06.834106 18728 net.cpp:148] Top shape: (1)
I0624 14:20:06.834108 18728 net.cpp:151]     with loss weight 1
I0624 14:20:06.834125 18728 net.cpp:156] Memory required for data: 179329028
I0624 14:20:06.834127 18728 layer_factory.hpp:77] Creating layer accuracy
I0624 14:20:06.834134 18728 net.cpp:91] Creating Layer accuracy
I0624 14:20:06.834136 18728 net.cpp:425] accuracy <- conv1_1_D_conv1_1_D_0_split_1
I0624 14:20:06.834141 18728 net.cpp:425] accuracy <- label_data_1_split_1
I0624 14:20:06.834144 18728 net.cpp:399] accuracy -> accuracy
I0624 14:20:06.834151 18728 net.cpp:141] Setting up accuracy
I0624 14:20:06.834154 18728 net.cpp:148] Top shape: (1)
I0624 14:20:06.834156 18728 net.cpp:156] Memory required for data: 179329032
I0624 14:20:06.834158 18728 net.cpp:219] accuracy does not need backward computation.
I0624 14:20:06.834161 18728 net.cpp:217] loss needs backward computation.
I0624 14:20:06.834164 18728 net.cpp:217] conv1_1_D_conv1_1_D_0_split needs backward computation.
I0624 14:20:06.834167 18728 net.cpp:217] conv1_1_D needs backward computation.
I0624 14:20:06.834169 18728 net.cpp:217] relu1_2_D needs backward computation.
I0624 14:20:06.834172 18728 net.cpp:217] scale1_2_D needs backward computation.
I0624 14:20:06.834173 18728 net.cpp:217] bn1_2_D needs backward computation.
I0624 14:20:06.834175 18728 net.cpp:217] conv1_2_D needs backward computation.
I0624 14:20:06.834177 18728 net.cpp:217] upsample1 needs backward computation.
I0624 14:20:06.834180 18728 net.cpp:217] relu2_1_D needs backward computation.
I0624 14:20:06.834182 18728 net.cpp:217] scale2_1_D needs backward computation.
I0624 14:20:06.834184 18728 net.cpp:217] bn2_1_D needs backward computation.
I0624 14:20:06.834187 18728 net.cpp:217] conv2_1_D needs backward computation.
I0624 14:20:06.834188 18728 net.cpp:217] relu2_2_D needs backward computation.
I0624 14:20:06.834190 18728 net.cpp:217] scale2_2_D needs backward computation.
I0624 14:20:06.834192 18728 net.cpp:217] bn2_2_D needs backward computation.
I0624 14:20:06.834194 18728 net.cpp:217] conv2_2_D needs backward computation.
I0624 14:20:06.834197 18728 net.cpp:217] upsample2 needs backward computation.
I0624 14:20:06.834208 18728 net.cpp:217] relu3_1_D needs backward computation.
I0624 14:20:06.834210 18728 net.cpp:217] scale3_1_D needs backward computation.
I0624 14:20:06.834213 18728 net.cpp:217] bn3_1_D needs backward computation.
I0624 14:20:06.834214 18728 net.cpp:217] conv3_1_D needs backward computation.
I0624 14:20:06.834216 18728 net.cpp:217] relu3_2_D needs backward computation.
I0624 14:20:06.834219 18728 net.cpp:217] scale3_2_D needs backward computation.
I0624 14:20:06.834221 18728 net.cpp:217] bn3_2_D needs backward computation.
I0624 14:20:06.834223 18728 net.cpp:217] conv3_2_D needs backward computation.
I0624 14:20:06.834226 18728 net.cpp:217] upsample3 needs backward computation.
I0624 14:20:06.834229 18728 net.cpp:217] relu4_1_D needs backward computation.
I0624 14:20:06.834231 18728 net.cpp:217] scale4_1_D needs backward computation.
I0624 14:20:06.834233 18728 net.cpp:217] bn4_1_D needs backward computation.
I0624 14:20:06.834236 18728 net.cpp:217] conv4_1_D needs backward computation.
I0624 14:20:06.834239 18728 net.cpp:217] relu4_2_D needs backward computation.
I0624 14:20:06.834241 18728 net.cpp:217] scale4_2_D needs backward computation.
I0624 14:20:06.834244 18728 net.cpp:217] bn4_2_D needs backward computation.
I0624 14:20:06.834245 18728 net.cpp:217] conv4_2_D needs backward computation.
I0624 14:20:06.834249 18728 net.cpp:217] upsample4 needs backward computation.
I0624 14:20:06.834250 18728 net.cpp:217] relu5_1_D needs backward computation.
I0624 14:20:06.834254 18728 net.cpp:217] scale5_1_D needs backward computation.
I0624 14:20:06.834255 18728 net.cpp:217] bn5_1_D needs backward computation.
I0624 14:20:06.834257 18728 net.cpp:217] conv5_1_D needs backward computation.
I0624 14:20:06.834260 18728 net.cpp:217] relu5_2_D needs backward computation.
I0624 14:20:06.834262 18728 net.cpp:217] scale5_2_D needs backward computation.
I0624 14:20:06.834265 18728 net.cpp:217] bn5_2_D needs backward computation.
I0624 14:20:06.834267 18728 net.cpp:217] conv5_2_D needs backward computation.
I0624 14:20:06.834270 18728 net.cpp:217] upsample5 needs backward computation.
I0624 14:20:06.834272 18728 net.cpp:217] pool5 needs backward computation.
I0624 14:20:06.834275 18728 net.cpp:217] relu5_2 needs backward computation.
I0624 14:20:06.834277 18728 net.cpp:217] scale5_2 needs backward computation.
I0624 14:20:06.834280 18728 net.cpp:217] bn5_2 needs backward computation.
I0624 14:20:06.834282 18728 net.cpp:217] conv5_2 needs backward computation.
I0624 14:20:06.834285 18728 net.cpp:217] relu5_1 needs backward computation.
I0624 14:20:06.834288 18728 net.cpp:217] scale5_1 needs backward computation.
I0624 14:20:06.834291 18728 net.cpp:217] bn5_1 needs backward computation.
I0624 14:20:06.834293 18728 net.cpp:217] conv5_1 needs backward computation.
I0624 14:20:06.834296 18728 net.cpp:217] pool4 needs backward computation.
I0624 14:20:06.834300 18728 net.cpp:217] relu4_2 needs backward computation.
I0624 14:20:06.834301 18728 net.cpp:217] scale4_2 needs backward computation.
I0624 14:20:06.834303 18728 net.cpp:217] bn4_2 needs backward computation.
I0624 14:20:06.834306 18728 net.cpp:217] conv4_2 needs backward computation.
I0624 14:20:06.834308 18728 net.cpp:217] relu4_1 needs backward computation.
I0624 14:20:06.834311 18728 net.cpp:217] scale4_1 needs backward computation.
I0624 14:20:06.834313 18728 net.cpp:217] bn4_1 needs backward computation.
I0624 14:20:06.834316 18728 net.cpp:217] conv4_1 needs backward computation.
I0624 14:20:06.834317 18728 net.cpp:217] pool3 needs backward computation.
I0624 14:20:06.834321 18728 net.cpp:217] relu3_2 needs backward computation.
I0624 14:20:06.834322 18728 net.cpp:217] scale3_2 needs backward computation.
I0624 14:20:06.834324 18728 net.cpp:217] bn3_2 needs backward computation.
I0624 14:20:06.834327 18728 net.cpp:217] conv3_2 needs backward computation.
I0624 14:20:06.834329 18728 net.cpp:217] relu3_1 needs backward computation.
I0624 14:20:06.834331 18728 net.cpp:217] scale3_1 needs backward computation.
I0624 14:20:06.834333 18728 net.cpp:217] bn3_1 needs backward computation.
I0624 14:20:06.834341 18728 net.cpp:217] conv3_1 needs backward computation.
I0624 14:20:06.834343 18728 net.cpp:217] pool2 needs backward computation.
I0624 14:20:06.834345 18728 net.cpp:217] relu2_2 needs backward computation.
I0624 14:20:06.834347 18728 net.cpp:217] scale2_2 needs backward computation.
I0624 14:20:06.834349 18728 net.cpp:217] bn2_2 needs backward computation.
I0624 14:20:06.834352 18728 net.cpp:217] conv2_2 needs backward computation.
I0624 14:20:06.834354 18728 net.cpp:217] relu2_1 needs backward computation.
I0624 14:20:06.834357 18728 net.cpp:217] scale2_1 needs backward computation.
I0624 14:20:06.834359 18728 net.cpp:217] bn2_1 needs backward computation.
I0624 14:20:06.834362 18728 net.cpp:217] conv2_1 needs backward computation.
I0624 14:20:06.834363 18728 net.cpp:217] pool1 needs backward computation.
I0624 14:20:06.834365 18728 net.cpp:217] relu1_2 needs backward computation.
I0624 14:20:06.834368 18728 net.cpp:217] scale1_2 needs backward computation.
I0624 14:20:06.834370 18728 net.cpp:217] bn1_2 needs backward computation.
I0624 14:20:06.834373 18728 net.cpp:217] conv1_2 needs backward computation.
I0624 14:20:06.834375 18728 net.cpp:217] relu1_1 needs backward computation.
I0624 14:20:06.834378 18728 net.cpp:217] scale1_1 needs backward computation.
I0624 14:20:06.834380 18728 net.cpp:217] bn1_1 needs backward computation.
I0624 14:20:06.834383 18728 net.cpp:217] conv1_1 needs backward computation.
I0624 14:20:06.834385 18728 net.cpp:219] label_data_1_split does not need backward computation.
I0624 14:20:06.834388 18728 net.cpp:219] data does not need backward computation.
I0624 14:20:06.834390 18728 net.cpp:261] This network produces output accuracy
I0624 14:20:06.834393 18728 net.cpp:261] This network produces output loss
I0624 14:20:06.834425 18728 net.cpp:274] Network initialization done.
I0624 14:20:06.835929 18728 solver.cpp:181] Creating test net (#0) specified by net file: models/segnet/train_val.prototxt
I0624 14:20:06.836017 18728 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0624 14:20:06.836416 18728 net.cpp:49] Initializing net from parameters: 
name: "segnet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "DenseImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 224
    mean_value: 100
  }
  dense_image_data_param {
    source: "data/val_seg.txt"
    batch_size: 1
    shuffle: true
    new_height: 224
    new_width: 310
    is_color: false
    root_folder: "data/raw/train/"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 14
    upsample_w: 14
  }
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2_D"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2_D"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1_D"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1_D"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 28
    upsample_w: 28
  }
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2_D"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2_D"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1_D"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1_D"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
    upsample_h: 56
    upsample_w: 56
  }
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn3_2_D"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2_D"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1_D"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1_D"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
    upsample_h: 112
    upsample_w: 112
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2_D"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2_D"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1_D"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1_D"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
    upsample_h: 224
    upsample_w: 224
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2_D"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2_D"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2
    bias_term: true
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "accuracy"
}
I0624 14:20:06.836655 18728 layer_factory.hpp:77] Creating layer data
I0624 14:20:06.836668 18728 net.cpp:91] Creating Layer data
I0624 14:20:06.836671 18728 net.cpp:399] data -> data
I0624 14:20:06.836678 18728 net.cpp:399] data -> label
I0624 14:20:06.836688 18728 dense_image_data_layer.cpp:38] Opening file data/val_seg.txt
I0624 14:20:06.836840 18728 dense_image_data_layer.cpp:48] Shuffling data
I0624 14:20:06.836875 18728 dense_image_data_layer.cpp:53] A total of 299 examples.
I0624 14:20:06.841410 18728 dense_image_data_layer.cpp:92] output data size: 1,1,224,224
I0624 14:20:06.842622 18728 net.cpp:141] Setting up data
I0624 14:20:06.842633 18728 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 14:20:06.842638 18728 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 14:20:06.842639 18728 net.cpp:156] Memory required for data: 401408
I0624 14:20:06.842643 18728 layer_factory.hpp:77] Creating layer label_data_1_split
I0624 14:20:06.842649 18728 net.cpp:91] Creating Layer label_data_1_split
I0624 14:20:06.842651 18728 net.cpp:425] label_data_1_split <- label
I0624 14:20:06.842655 18728 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0624 14:20:06.842661 18728 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0624 14:20:06.842710 18728 net.cpp:141] Setting up label_data_1_split
I0624 14:20:06.842720 18728 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 14:20:06.842722 18728 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0624 14:20:06.842725 18728 net.cpp:156] Memory required for data: 802816
I0624 14:20:06.842726 18728 layer_factory.hpp:77] Creating layer conv1_1
I0624 14:20:06.842735 18728 net.cpp:91] Creating Layer conv1_1
I0624 14:20:06.842736 18728 net.cpp:425] conv1_1 <- data
I0624 14:20:06.842741 18728 net.cpp:399] conv1_1 -> conv1_1
I0624 14:20:06.844161 18728 net.cpp:141] Setting up conv1_1
I0624 14:20:06.844174 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.844177 18728 net.cpp:156] Memory required for data: 7225344
I0624 14:20:06.844182 18728 layer_factory.hpp:77] Creating layer bn1_1
I0624 14:20:06.844188 18728 net.cpp:91] Creating Layer bn1_1
I0624 14:20:06.844190 18728 net.cpp:425] bn1_1 <- conv1_1
I0624 14:20:06.844194 18728 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0624 14:20:06.845082 18728 net.cpp:141] Setting up bn1_1
I0624 14:20:06.845093 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.845095 18728 net.cpp:156] Memory required for data: 13647872
I0624 14:20:06.845104 18728 layer_factory.hpp:77] Creating layer scale1_1
I0624 14:20:06.845111 18728 net.cpp:91] Creating Layer scale1_1
I0624 14:20:06.845114 18728 net.cpp:425] scale1_1 <- conv1_1
I0624 14:20:06.845118 18728 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0624 14:20:06.845161 18728 layer_factory.hpp:77] Creating layer scale1_1
I0624 14:20:06.845315 18728 net.cpp:141] Setting up scale1_1
I0624 14:20:06.845322 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.845324 18728 net.cpp:156] Memory required for data: 20070400
I0624 14:20:06.845341 18728 layer_factory.hpp:77] Creating layer relu1_1
I0624 14:20:06.845346 18728 net.cpp:91] Creating Layer relu1_1
I0624 14:20:06.845350 18728 net.cpp:425] relu1_1 <- conv1_1
I0624 14:20:06.845352 18728 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0624 14:20:06.845649 18728 net.cpp:141] Setting up relu1_1
I0624 14:20:06.845660 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.845664 18728 net.cpp:156] Memory required for data: 26492928
I0624 14:20:06.845666 18728 layer_factory.hpp:77] Creating layer conv1_2
I0624 14:20:06.845674 18728 net.cpp:91] Creating Layer conv1_2
I0624 14:20:06.845676 18728 net.cpp:425] conv1_2 <- conv1_1
I0624 14:20:06.845680 18728 net.cpp:399] conv1_2 -> conv1_2
I0624 14:20:06.846595 18728 net.cpp:141] Setting up conv1_2
I0624 14:20:06.846606 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.846608 18728 net.cpp:156] Memory required for data: 32915456
I0624 14:20:06.846612 18728 layer_factory.hpp:77] Creating layer bn1_2
I0624 14:20:06.846618 18728 net.cpp:91] Creating Layer bn1_2
I0624 14:20:06.846621 18728 net.cpp:425] bn1_2 <- conv1_2
I0624 14:20:06.846624 18728 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0624 14:20:06.846833 18728 net.cpp:141] Setting up bn1_2
I0624 14:20:06.846840 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.846843 18728 net.cpp:156] Memory required for data: 39337984
I0624 14:20:06.846851 18728 layer_factory.hpp:77] Creating layer scale1_2
I0624 14:20:06.846858 18728 net.cpp:91] Creating Layer scale1_2
I0624 14:20:06.846861 18728 net.cpp:425] scale1_2 <- conv1_2
I0624 14:20:06.846865 18728 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0624 14:20:06.846904 18728 layer_factory.hpp:77] Creating layer scale1_2
I0624 14:20:06.847654 18728 net.cpp:141] Setting up scale1_2
I0624 14:20:06.847666 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.847669 18728 net.cpp:156] Memory required for data: 45760512
I0624 14:20:06.847674 18728 layer_factory.hpp:77] Creating layer relu1_2
I0624 14:20:06.847679 18728 net.cpp:91] Creating Layer relu1_2
I0624 14:20:06.847681 18728 net.cpp:425] relu1_2 <- conv1_2
I0624 14:20:06.847686 18728 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0624 14:20:06.847968 18728 net.cpp:141] Setting up relu1_2
I0624 14:20:06.847980 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.847981 18728 net.cpp:156] Memory required for data: 52183040
I0624 14:20:06.847985 18728 layer_factory.hpp:77] Creating layer pool1
I0624 14:20:06.847987 18728 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 14:20:06.847991 18728 net.cpp:91] Creating Layer pool1
I0624 14:20:06.847995 18728 net.cpp:425] pool1 <- conv1_2
I0624 14:20:06.847998 18728 net.cpp:399] pool1 -> pool1
I0624 14:20:06.848003 18728 net.cpp:399] pool1 -> pool1_mask
I0624 14:20:06.848047 18728 net.cpp:141] Setting up pool1
I0624 14:20:06.848053 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.848057 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.848058 18728 net.cpp:156] Memory required for data: 55394304
I0624 14:20:06.848060 18728 layer_factory.hpp:77] Creating layer conv2_1
I0624 14:20:06.848067 18728 net.cpp:91] Creating Layer conv2_1
I0624 14:20:06.848069 18728 net.cpp:425] conv2_1 <- pool1
I0624 14:20:06.848073 18728 net.cpp:399] conv2_1 -> conv2_1
I0624 14:20:06.849161 18728 net.cpp:141] Setting up conv2_1
I0624 14:20:06.849174 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.849175 18728 net.cpp:156] Memory required for data: 58605568
I0624 14:20:06.849179 18728 layer_factory.hpp:77] Creating layer bn2_1
I0624 14:20:06.849185 18728 net.cpp:91] Creating Layer bn2_1
I0624 14:20:06.849187 18728 net.cpp:425] bn2_1 <- conv2_1
I0624 14:20:06.849191 18728 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0624 14:20:06.849385 18728 net.cpp:141] Setting up bn2_1
I0624 14:20:06.849391 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.849393 18728 net.cpp:156] Memory required for data: 61816832
I0624 14:20:06.849411 18728 layer_factory.hpp:77] Creating layer scale2_1
I0624 14:20:06.849417 18728 net.cpp:91] Creating Layer scale2_1
I0624 14:20:06.849421 18728 net.cpp:425] scale2_1 <- conv2_1
I0624 14:20:06.849423 18728 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0624 14:20:06.849465 18728 layer_factory.hpp:77] Creating layer scale2_1
I0624 14:20:06.849587 18728 net.cpp:141] Setting up scale2_1
I0624 14:20:06.849593 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.849596 18728 net.cpp:156] Memory required for data: 65028096
I0624 14:20:06.849602 18728 layer_factory.hpp:77] Creating layer relu2_1
I0624 14:20:06.849607 18728 net.cpp:91] Creating Layer relu2_1
I0624 14:20:06.849609 18728 net.cpp:425] relu2_1 <- conv2_1
I0624 14:20:06.849613 18728 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0624 14:20:06.849766 18728 net.cpp:141] Setting up relu2_1
I0624 14:20:06.849781 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.849783 18728 net.cpp:156] Memory required for data: 68239360
I0624 14:20:06.849786 18728 layer_factory.hpp:77] Creating layer conv2_2
I0624 14:20:06.849793 18728 net.cpp:91] Creating Layer conv2_2
I0624 14:20:06.849797 18728 net.cpp:425] conv2_2 <- conv2_1
I0624 14:20:06.849800 18728 net.cpp:399] conv2_2 -> conv2_2
I0624 14:20:06.851125 18728 net.cpp:141] Setting up conv2_2
I0624 14:20:06.851136 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.851138 18728 net.cpp:156] Memory required for data: 71450624
I0624 14:20:06.851143 18728 layer_factory.hpp:77] Creating layer bn2_2
I0624 14:20:06.851157 18728 net.cpp:91] Creating Layer bn2_2
I0624 14:20:06.851161 18728 net.cpp:425] bn2_2 <- conv2_2
I0624 14:20:06.851166 18728 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0624 14:20:06.851363 18728 net.cpp:141] Setting up bn2_2
I0624 14:20:06.851371 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.851372 18728 net.cpp:156] Memory required for data: 74661888
I0624 14:20:06.851378 18728 layer_factory.hpp:77] Creating layer scale2_2
I0624 14:20:06.851383 18728 net.cpp:91] Creating Layer scale2_2
I0624 14:20:06.851387 18728 net.cpp:425] scale2_2 <- conv2_2
I0624 14:20:06.851389 18728 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0624 14:20:06.851429 18728 layer_factory.hpp:77] Creating layer scale2_2
I0624 14:20:06.851567 18728 net.cpp:141] Setting up scale2_2
I0624 14:20:06.851574 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.851577 18728 net.cpp:156] Memory required for data: 77873152
I0624 14:20:06.851582 18728 layer_factory.hpp:77] Creating layer relu2_2
I0624 14:20:06.851588 18728 net.cpp:91] Creating Layer relu2_2
I0624 14:20:06.851589 18728 net.cpp:425] relu2_2 <- conv2_2
I0624 14:20:06.851593 18728 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0624 14:20:06.851884 18728 net.cpp:141] Setting up relu2_2
I0624 14:20:06.851896 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.851897 18728 net.cpp:156] Memory required for data: 81084416
I0624 14:20:06.851900 18728 layer_factory.hpp:77] Creating layer pool2
I0624 14:20:06.851902 18728 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 14:20:06.851907 18728 net.cpp:91] Creating Layer pool2
I0624 14:20:06.851910 18728 net.cpp:425] pool2 <- conv2_2
I0624 14:20:06.851914 18728 net.cpp:399] pool2 -> pool2
I0624 14:20:06.851919 18728 net.cpp:399] pool2 -> pool2_mask
I0624 14:20:06.851963 18728 net.cpp:141] Setting up pool2
I0624 14:20:06.851969 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.851974 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.851975 18728 net.cpp:156] Memory required for data: 82690048
I0624 14:20:06.851977 18728 layer_factory.hpp:77] Creating layer conv3_1
I0624 14:20:06.851984 18728 net.cpp:91] Creating Layer conv3_1
I0624 14:20:06.851986 18728 net.cpp:425] conv3_1 <- pool2
I0624 14:20:06.851990 18728 net.cpp:399] conv3_1 -> conv3_1
I0624 14:20:06.853356 18728 net.cpp:141] Setting up conv3_1
I0624 14:20:06.853368 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.853380 18728 net.cpp:156] Memory required for data: 84295680
I0624 14:20:06.853385 18728 layer_factory.hpp:77] Creating layer bn3_1
I0624 14:20:06.853391 18728 net.cpp:91] Creating Layer bn3_1
I0624 14:20:06.853394 18728 net.cpp:425] bn3_1 <- conv3_1
I0624 14:20:06.853399 18728 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0624 14:20:06.853592 18728 net.cpp:141] Setting up bn3_1
I0624 14:20:06.853600 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.853601 18728 net.cpp:156] Memory required for data: 85901312
I0624 14:20:06.853607 18728 layer_factory.hpp:77] Creating layer scale3_1
I0624 14:20:06.853612 18728 net.cpp:91] Creating Layer scale3_1
I0624 14:20:06.853615 18728 net.cpp:425] scale3_1 <- conv3_1
I0624 14:20:06.853618 18728 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0624 14:20:06.853657 18728 layer_factory.hpp:77] Creating layer scale3_1
I0624 14:20:06.853780 18728 net.cpp:141] Setting up scale3_1
I0624 14:20:06.853786 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.853788 18728 net.cpp:156] Memory required for data: 87506944
I0624 14:20:06.853793 18728 layer_factory.hpp:77] Creating layer relu3_1
I0624 14:20:06.853797 18728 net.cpp:91] Creating Layer relu3_1
I0624 14:20:06.853801 18728 net.cpp:425] relu3_1 <- conv3_1
I0624 14:20:06.853803 18728 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0624 14:20:06.854090 18728 net.cpp:141] Setting up relu3_1
I0624 14:20:06.854101 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.854105 18728 net.cpp:156] Memory required for data: 89112576
I0624 14:20:06.854107 18728 layer_factory.hpp:77] Creating layer conv3_2
I0624 14:20:06.854115 18728 net.cpp:91] Creating Layer conv3_2
I0624 14:20:06.854118 18728 net.cpp:425] conv3_2 <- conv3_1
I0624 14:20:06.854123 18728 net.cpp:399] conv3_2 -> conv3_2
I0624 14:20:06.856575 18728 net.cpp:141] Setting up conv3_2
I0624 14:20:06.856588 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.856590 18728 net.cpp:156] Memory required for data: 90718208
I0624 14:20:06.856595 18728 layer_factory.hpp:77] Creating layer bn3_2
I0624 14:20:06.856601 18728 net.cpp:91] Creating Layer bn3_2
I0624 14:20:06.856604 18728 net.cpp:425] bn3_2 <- conv3_2
I0624 14:20:06.856608 18728 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0624 14:20:06.856801 18728 net.cpp:141] Setting up bn3_2
I0624 14:20:06.856808 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.856812 18728 net.cpp:156] Memory required for data: 92323840
I0624 14:20:06.856820 18728 layer_factory.hpp:77] Creating layer scale3_2
I0624 14:20:06.856829 18728 net.cpp:91] Creating Layer scale3_2
I0624 14:20:06.856832 18728 net.cpp:425] scale3_2 <- conv3_2
I0624 14:20:06.856837 18728 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0624 14:20:06.856876 18728 layer_factory.hpp:77] Creating layer scale3_2
I0624 14:20:06.856984 18728 net.cpp:141] Setting up scale3_2
I0624 14:20:06.856992 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.856994 18728 net.cpp:156] Memory required for data: 93929472
I0624 14:20:06.856998 18728 layer_factory.hpp:77] Creating layer relu3_2
I0624 14:20:06.857003 18728 net.cpp:91] Creating Layer relu3_2
I0624 14:20:06.857005 18728 net.cpp:425] relu3_2 <- conv3_2
I0624 14:20:06.857009 18728 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0624 14:20:06.857166 18728 net.cpp:141] Setting up relu3_2
I0624 14:20:06.857174 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.857177 18728 net.cpp:156] Memory required for data: 95535104
I0624 14:20:06.857179 18728 layer_factory.hpp:77] Creating layer pool3
I0624 14:20:06.857182 18728 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 14:20:06.857187 18728 net.cpp:91] Creating Layer pool3
I0624 14:20:06.857188 18728 net.cpp:425] pool3 <- conv3_2
I0624 14:20:06.857192 18728 net.cpp:399] pool3 -> pool3
I0624 14:20:06.857197 18728 net.cpp:399] pool3 -> pool3_mask
I0624 14:20:06.857240 18728 net.cpp:141] Setting up pool3
I0624 14:20:06.857244 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.857257 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.857259 18728 net.cpp:156] Memory required for data: 96337920
I0624 14:20:06.857262 18728 layer_factory.hpp:77] Creating layer conv4_1
I0624 14:20:06.857269 18728 net.cpp:91] Creating Layer conv4_1
I0624 14:20:06.857271 18728 net.cpp:425] conv4_1 <- pool3
I0624 14:20:06.857275 18728 net.cpp:399] conv4_1 -> conv4_1
I0624 14:20:06.860647 18728 net.cpp:141] Setting up conv4_1
I0624 14:20:06.860659 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.860662 18728 net.cpp:156] Memory required for data: 97140736
I0624 14:20:06.860666 18728 layer_factory.hpp:77] Creating layer bn4_1
I0624 14:20:06.860673 18728 net.cpp:91] Creating Layer bn4_1
I0624 14:20:06.860677 18728 net.cpp:425] bn4_1 <- conv4_1
I0624 14:20:06.860680 18728 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0624 14:20:06.860885 18728 net.cpp:141] Setting up bn4_1
I0624 14:20:06.860893 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.860895 18728 net.cpp:156] Memory required for data: 97943552
I0624 14:20:06.860901 18728 layer_factory.hpp:77] Creating layer scale4_1
I0624 14:20:06.860908 18728 net.cpp:91] Creating Layer scale4_1
I0624 14:20:06.860910 18728 net.cpp:425] scale4_1 <- conv4_1
I0624 14:20:06.860914 18728 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0624 14:20:06.860955 18728 layer_factory.hpp:77] Creating layer scale4_1
I0624 14:20:06.861075 18728 net.cpp:141] Setting up scale4_1
I0624 14:20:06.861083 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.861084 18728 net.cpp:156] Memory required for data: 98746368
I0624 14:20:06.861088 18728 layer_factory.hpp:77] Creating layer relu4_1
I0624 14:20:06.861096 18728 net.cpp:91] Creating Layer relu4_1
I0624 14:20:06.861099 18728 net.cpp:425] relu4_1 <- conv4_1
I0624 14:20:06.861104 18728 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0624 14:20:06.861400 18728 net.cpp:141] Setting up relu4_1
I0624 14:20:06.861410 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.861413 18728 net.cpp:156] Memory required for data: 99549184
I0624 14:20:06.861416 18728 layer_factory.hpp:77] Creating layer conv4_2
I0624 14:20:06.861424 18728 net.cpp:91] Creating Layer conv4_2
I0624 14:20:06.861428 18728 net.cpp:425] conv4_2 <- conv4_1
I0624 14:20:06.861431 18728 net.cpp:399] conv4_2 -> conv4_2
I0624 14:20:06.866891 18728 net.cpp:141] Setting up conv4_2
I0624 14:20:06.866904 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.866907 18728 net.cpp:156] Memory required for data: 100352000
I0624 14:20:06.866912 18728 layer_factory.hpp:77] Creating layer bn4_2
I0624 14:20:06.866919 18728 net.cpp:91] Creating Layer bn4_2
I0624 14:20:06.866922 18728 net.cpp:425] bn4_2 <- conv4_2
I0624 14:20:06.866926 18728 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0624 14:20:06.867126 18728 net.cpp:141] Setting up bn4_2
I0624 14:20:06.867135 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.867136 18728 net.cpp:156] Memory required for data: 101154816
I0624 14:20:06.867142 18728 layer_factory.hpp:77] Creating layer scale4_2
I0624 14:20:06.867159 18728 net.cpp:91] Creating Layer scale4_2
I0624 14:20:06.867163 18728 net.cpp:425] scale4_2 <- conv4_2
I0624 14:20:06.867167 18728 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0624 14:20:06.867218 18728 layer_factory.hpp:77] Creating layer scale4_2
I0624 14:20:06.867336 18728 net.cpp:141] Setting up scale4_2
I0624 14:20:06.867344 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.867347 18728 net.cpp:156] Memory required for data: 101957632
I0624 14:20:06.867352 18728 layer_factory.hpp:77] Creating layer relu4_2
I0624 14:20:06.867357 18728 net.cpp:91] Creating Layer relu4_2
I0624 14:20:06.867359 18728 net.cpp:425] relu4_2 <- conv4_2
I0624 14:20:06.867363 18728 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0624 14:20:06.867669 18728 net.cpp:141] Setting up relu4_2
I0624 14:20:06.867681 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.867683 18728 net.cpp:156] Memory required for data: 102760448
I0624 14:20:06.867686 18728 layer_factory.hpp:77] Creating layer pool4
I0624 14:20:06.867697 18728 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 14:20:06.867703 18728 net.cpp:91] Creating Layer pool4
I0624 14:20:06.867707 18728 net.cpp:425] pool4 <- conv4_2
I0624 14:20:06.867712 18728 net.cpp:399] pool4 -> pool4
I0624 14:20:06.867717 18728 net.cpp:399] pool4 -> pool4_mask
I0624 14:20:06.867766 18728 net.cpp:141] Setting up pool4
I0624 14:20:06.867771 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.867774 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.867776 18728 net.cpp:156] Memory required for data: 103161856
I0624 14:20:06.867779 18728 layer_factory.hpp:77] Creating layer conv5_1
I0624 14:20:06.867787 18728 net.cpp:91] Creating Layer conv5_1
I0624 14:20:06.867790 18728 net.cpp:425] conv5_1 <- pool4
I0624 14:20:06.867794 18728 net.cpp:399] conv5_1 -> conv5_1
I0624 14:20:06.873347 18728 net.cpp:141] Setting up conv5_1
I0624 14:20:06.873359 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.873363 18728 net.cpp:156] Memory required for data: 103362560
I0624 14:20:06.873366 18728 layer_factory.hpp:77] Creating layer bn5_1
I0624 14:20:06.873373 18728 net.cpp:91] Creating Layer bn5_1
I0624 14:20:06.873376 18728 net.cpp:425] bn5_1 <- conv5_1
I0624 14:20:06.873381 18728 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0624 14:20:06.873589 18728 net.cpp:141] Setting up bn5_1
I0624 14:20:06.873597 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.873600 18728 net.cpp:156] Memory required for data: 103563264
I0624 14:20:06.873605 18728 layer_factory.hpp:77] Creating layer scale5_1
I0624 14:20:06.873611 18728 net.cpp:91] Creating Layer scale5_1
I0624 14:20:06.873613 18728 net.cpp:425] scale5_1 <- conv5_1
I0624 14:20:06.873618 18728 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0624 14:20:06.873661 18728 layer_factory.hpp:77] Creating layer scale5_1
I0624 14:20:06.873775 18728 net.cpp:141] Setting up scale5_1
I0624 14:20:06.873781 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.873785 18728 net.cpp:156] Memory required for data: 103763968
I0624 14:20:06.873788 18728 layer_factory.hpp:77] Creating layer relu5_1
I0624 14:20:06.873792 18728 net.cpp:91] Creating Layer relu5_1
I0624 14:20:06.873795 18728 net.cpp:425] relu5_1 <- conv5_1
I0624 14:20:06.873800 18728 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0624 14:20:06.873965 18728 net.cpp:141] Setting up relu5_1
I0624 14:20:06.873975 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.873976 18728 net.cpp:156] Memory required for data: 103964672
I0624 14:20:06.873980 18728 layer_factory.hpp:77] Creating layer conv5_2
I0624 14:20:06.873987 18728 net.cpp:91] Creating Layer conv5_2
I0624 14:20:06.873991 18728 net.cpp:425] conv5_2 <- conv5_1
I0624 14:20:06.873996 18728 net.cpp:399] conv5_2 -> conv5_2
I0624 14:20:06.879627 18728 net.cpp:141] Setting up conv5_2
I0624 14:20:06.879642 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.879644 18728 net.cpp:156] Memory required for data: 104165376
I0624 14:20:06.879649 18728 layer_factory.hpp:77] Creating layer bn5_2
I0624 14:20:06.879657 18728 net.cpp:91] Creating Layer bn5_2
I0624 14:20:06.879660 18728 net.cpp:425] bn5_2 <- conv5_2
I0624 14:20:06.879665 18728 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0624 14:20:06.879873 18728 net.cpp:141] Setting up bn5_2
I0624 14:20:06.879881 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.879884 18728 net.cpp:156] Memory required for data: 104366080
I0624 14:20:06.879890 18728 layer_factory.hpp:77] Creating layer scale5_2
I0624 14:20:06.879896 18728 net.cpp:91] Creating Layer scale5_2
I0624 14:20:06.879899 18728 net.cpp:425] scale5_2 <- conv5_2
I0624 14:20:06.879904 18728 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0624 14:20:06.879947 18728 layer_factory.hpp:77] Creating layer scale5_2
I0624 14:20:06.880066 18728 net.cpp:141] Setting up scale5_2
I0624 14:20:06.880072 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.880075 18728 net.cpp:156] Memory required for data: 104566784
I0624 14:20:06.880089 18728 layer_factory.hpp:77] Creating layer relu5_2
I0624 14:20:06.880095 18728 net.cpp:91] Creating Layer relu5_2
I0624 14:20:06.880096 18728 net.cpp:425] relu5_2 <- conv5_2
I0624 14:20:06.880100 18728 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0624 14:20:06.880419 18728 net.cpp:141] Setting up relu5_2
I0624 14:20:06.880429 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.880431 18728 net.cpp:156] Memory required for data: 104767488
I0624 14:20:06.880434 18728 layer_factory.hpp:77] Creating layer pool5
I0624 14:20:06.880437 18728 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0624 14:20:06.880442 18728 net.cpp:91] Creating Layer pool5
I0624 14:20:06.880445 18728 net.cpp:425] pool5 <- conv5_2
I0624 14:20:06.880452 18728 net.cpp:399] pool5 -> pool5
I0624 14:20:06.880458 18728 net.cpp:399] pool5 -> pool5_mask
I0624 14:20:06.880509 18728 net.cpp:141] Setting up pool5
I0624 14:20:06.880517 18728 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 14:20:06.880519 18728 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0624 14:20:06.880522 18728 net.cpp:156] Memory required for data: 104867840
I0624 14:20:06.880523 18728 layer_factory.hpp:77] Creating layer upsample5
I0624 14:20:06.880530 18728 net.cpp:91] Creating Layer upsample5
I0624 14:20:06.880533 18728 net.cpp:425] upsample5 <- pool5
I0624 14:20:06.880537 18728 net.cpp:425] upsample5 <- pool5_mask
I0624 14:20:06.880539 18728 net.cpp:399] upsample5 -> pool5_D
I0624 14:20:06.880568 18728 net.cpp:141] Setting up upsample5
I0624 14:20:06.880573 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.880575 18728 net.cpp:156] Memory required for data: 105068544
I0624 14:20:06.880578 18728 layer_factory.hpp:77] Creating layer conv5_2_D
I0624 14:20:06.880586 18728 net.cpp:91] Creating Layer conv5_2_D
I0624 14:20:06.880589 18728 net.cpp:425] conv5_2_D <- pool5_D
I0624 14:20:06.880594 18728 net.cpp:399] conv5_2_D -> conv5_2_D
I0624 14:20:06.886281 18728 net.cpp:141] Setting up conv5_2_D
I0624 14:20:06.886296 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.886299 18728 net.cpp:156] Memory required for data: 105269248
I0624 14:20:06.886306 18728 layer_factory.hpp:77] Creating layer bn5_2_D
I0624 14:20:06.886312 18728 net.cpp:91] Creating Layer bn5_2_D
I0624 14:20:06.886315 18728 net.cpp:425] bn5_2_D <- conv5_2_D
I0624 14:20:06.886322 18728 net.cpp:386] bn5_2_D -> conv5_2_D (in-place)
I0624 14:20:06.886533 18728 net.cpp:141] Setting up bn5_2_D
I0624 14:20:06.886539 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.886543 18728 net.cpp:156] Memory required for data: 105469952
I0624 14:20:06.886548 18728 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 14:20:06.886554 18728 net.cpp:91] Creating Layer scale5_2_D
I0624 14:20:06.886557 18728 net.cpp:425] scale5_2_D <- conv5_2_D
I0624 14:20:06.886561 18728 net.cpp:386] scale5_2_D -> conv5_2_D (in-place)
I0624 14:20:06.886605 18728 layer_factory.hpp:77] Creating layer scale5_2_D
I0624 14:20:06.886720 18728 net.cpp:141] Setting up scale5_2_D
I0624 14:20:06.886729 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.886730 18728 net.cpp:156] Memory required for data: 105670656
I0624 14:20:06.886744 18728 layer_factory.hpp:77] Creating layer relu5_2_D
I0624 14:20:06.886750 18728 net.cpp:91] Creating Layer relu5_2_D
I0624 14:20:06.886752 18728 net.cpp:425] relu5_2_D <- conv5_2_D
I0624 14:20:06.886756 18728 net.cpp:386] relu5_2_D -> conv5_2_D (in-place)
I0624 14:20:06.887053 18728 net.cpp:141] Setting up relu5_2_D
I0624 14:20:06.887064 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.887066 18728 net.cpp:156] Memory required for data: 105871360
I0624 14:20:06.887069 18728 layer_factory.hpp:77] Creating layer conv5_1_D
I0624 14:20:06.887079 18728 net.cpp:91] Creating Layer conv5_1_D
I0624 14:20:06.887081 18728 net.cpp:425] conv5_1_D <- conv5_2_D
I0624 14:20:06.887087 18728 net.cpp:399] conv5_1_D -> conv5_1_D
I0624 14:20:06.893002 18728 net.cpp:141] Setting up conv5_1_D
I0624 14:20:06.893026 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.893029 18728 net.cpp:156] Memory required for data: 106072064
I0624 14:20:06.893034 18728 layer_factory.hpp:77] Creating layer bn5_1_D
I0624 14:20:06.893043 18728 net.cpp:91] Creating Layer bn5_1_D
I0624 14:20:06.893045 18728 net.cpp:425] bn5_1_D <- conv5_1_D
I0624 14:20:06.893050 18728 net.cpp:386] bn5_1_D -> conv5_1_D (in-place)
I0624 14:20:06.893261 18728 net.cpp:141] Setting up bn5_1_D
I0624 14:20:06.893270 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.893272 18728 net.cpp:156] Memory required for data: 106272768
I0624 14:20:06.893277 18728 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 14:20:06.893283 18728 net.cpp:91] Creating Layer scale5_1_D
I0624 14:20:06.893286 18728 net.cpp:425] scale5_1_D <- conv5_1_D
I0624 14:20:06.893290 18728 net.cpp:386] scale5_1_D -> conv5_1_D (in-place)
I0624 14:20:06.893337 18728 layer_factory.hpp:77] Creating layer scale5_1_D
I0624 14:20:06.893461 18728 net.cpp:141] Setting up scale5_1_D
I0624 14:20:06.893468 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.893471 18728 net.cpp:156] Memory required for data: 106473472
I0624 14:20:06.893474 18728 layer_factory.hpp:77] Creating layer relu5_1_D
I0624 14:20:06.893479 18728 net.cpp:91] Creating Layer relu5_1_D
I0624 14:20:06.893482 18728 net.cpp:425] relu5_1_D <- conv5_1_D
I0624 14:20:06.893486 18728 net.cpp:386] relu5_1_D -> conv5_1_D (in-place)
I0624 14:20:06.893646 18728 net.cpp:141] Setting up relu5_1_D
I0624 14:20:06.893654 18728 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0624 14:20:06.893656 18728 net.cpp:156] Memory required for data: 106674176
I0624 14:20:06.893659 18728 layer_factory.hpp:77] Creating layer upsample4
I0624 14:20:06.893666 18728 net.cpp:91] Creating Layer upsample4
I0624 14:20:06.893668 18728 net.cpp:425] upsample4 <- conv5_1_D
I0624 14:20:06.893672 18728 net.cpp:425] upsample4 <- pool4_mask
I0624 14:20:06.893676 18728 net.cpp:399] upsample4 -> pool4_D
I0624 14:20:06.893713 18728 net.cpp:141] Setting up upsample4
I0624 14:20:06.893720 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.893723 18728 net.cpp:156] Memory required for data: 107476992
I0624 14:20:06.893724 18728 layer_factory.hpp:77] Creating layer conv4_2_D
I0624 14:20:06.893733 18728 net.cpp:91] Creating Layer conv4_2_D
I0624 14:20:06.893735 18728 net.cpp:425] conv4_2_D <- pool4_D
I0624 14:20:06.893739 18728 net.cpp:399] conv4_2_D -> conv4_2_D
I0624 14:20:06.899406 18728 net.cpp:141] Setting up conv4_2_D
I0624 14:20:06.899420 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.899422 18728 net.cpp:156] Memory required for data: 108279808
I0624 14:20:06.899428 18728 layer_factory.hpp:77] Creating layer bn4_2_D
I0624 14:20:06.899435 18728 net.cpp:91] Creating Layer bn4_2_D
I0624 14:20:06.899438 18728 net.cpp:425] bn4_2_D <- conv4_2_D
I0624 14:20:06.899442 18728 net.cpp:386] bn4_2_D -> conv4_2_D (in-place)
I0624 14:20:06.899677 18728 net.cpp:141] Setting up bn4_2_D
I0624 14:20:06.899685 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.899688 18728 net.cpp:156] Memory required for data: 109082624
I0624 14:20:06.899694 18728 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 14:20:06.899701 18728 net.cpp:91] Creating Layer scale4_2_D
I0624 14:20:06.899704 18728 net.cpp:425] scale4_2_D <- conv4_2_D
I0624 14:20:06.899708 18728 net.cpp:386] scale4_2_D -> conv4_2_D (in-place)
I0624 14:20:06.899752 18728 layer_factory.hpp:77] Creating layer scale4_2_D
I0624 14:20:06.899888 18728 net.cpp:141] Setting up scale4_2_D
I0624 14:20:06.899895 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.899899 18728 net.cpp:156] Memory required for data: 109885440
I0624 14:20:06.899902 18728 layer_factory.hpp:77] Creating layer relu4_2_D
I0624 14:20:06.899909 18728 net.cpp:91] Creating Layer relu4_2_D
I0624 14:20:06.899911 18728 net.cpp:425] relu4_2_D <- conv4_2_D
I0624 14:20:06.899915 18728 net.cpp:386] relu4_2_D -> conv4_2_D (in-place)
I0624 14:20:06.900233 18728 net.cpp:141] Setting up relu4_2_D
I0624 14:20:06.900251 18728 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0624 14:20:06.900254 18728 net.cpp:156] Memory required for data: 110688256
I0624 14:20:06.900256 18728 layer_factory.hpp:77] Creating layer conv4_1_D
I0624 14:20:06.900266 18728 net.cpp:91] Creating Layer conv4_1_D
I0624 14:20:06.900269 18728 net.cpp:425] conv4_1_D <- conv4_2_D
I0624 14:20:06.900274 18728 net.cpp:399] conv4_1_D -> conv4_1_D
I0624 14:20:06.903528 18728 net.cpp:141] Setting up conv4_1_D
I0624 14:20:06.903539 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.903542 18728 net.cpp:156] Memory required for data: 111089664
I0624 14:20:06.903548 18728 layer_factory.hpp:77] Creating layer bn4_1_D
I0624 14:20:06.903558 18728 net.cpp:91] Creating Layer bn4_1_D
I0624 14:20:06.903561 18728 net.cpp:425] bn4_1_D <- conv4_1_D
I0624 14:20:06.903565 18728 net.cpp:386] bn4_1_D -> conv4_1_D (in-place)
I0624 14:20:06.903784 18728 net.cpp:141] Setting up bn4_1_D
I0624 14:20:06.903791 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.903794 18728 net.cpp:156] Memory required for data: 111491072
I0624 14:20:06.903800 18728 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 14:20:06.903805 18728 net.cpp:91] Creating Layer scale4_1_D
I0624 14:20:06.903807 18728 net.cpp:425] scale4_1_D <- conv4_1_D
I0624 14:20:06.903812 18728 net.cpp:386] scale4_1_D -> conv4_1_D (in-place)
I0624 14:20:06.903856 18728 layer_factory.hpp:77] Creating layer scale4_1_D
I0624 14:20:06.903977 18728 net.cpp:141] Setting up scale4_1_D
I0624 14:20:06.903985 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.903986 18728 net.cpp:156] Memory required for data: 111892480
I0624 14:20:06.903990 18728 layer_factory.hpp:77] Creating layer relu4_1_D
I0624 14:20:06.904001 18728 net.cpp:91] Creating Layer relu4_1_D
I0624 14:20:06.904005 18728 net.cpp:425] relu4_1_D <- conv4_1_D
I0624 14:20:06.904008 18728 net.cpp:386] relu4_1_D -> conv4_1_D (in-place)
I0624 14:20:06.904314 18728 net.cpp:141] Setting up relu4_1_D
I0624 14:20:06.904325 18728 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0624 14:20:06.904328 18728 net.cpp:156] Memory required for data: 112293888
I0624 14:20:06.904331 18728 layer_factory.hpp:77] Creating layer upsample3
I0624 14:20:06.904336 18728 net.cpp:91] Creating Layer upsample3
I0624 14:20:06.904340 18728 net.cpp:425] upsample3 <- conv4_1_D
I0624 14:20:06.904343 18728 net.cpp:425] upsample3 <- pool3_mask
I0624 14:20:06.904348 18728 net.cpp:399] upsample3 -> pool3_D
I0624 14:20:06.904393 18728 net.cpp:141] Setting up upsample3
I0624 14:20:06.904398 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.904400 18728 net.cpp:156] Memory required for data: 113899520
I0624 14:20:06.904403 18728 layer_factory.hpp:77] Creating layer conv3_2_D
I0624 14:20:06.904412 18728 net.cpp:91] Creating Layer conv3_2_D
I0624 14:20:06.904414 18728 net.cpp:425] conv3_2_D <- pool3_D
I0624 14:20:06.904420 18728 net.cpp:399] conv3_2_D -> conv3_2_D
I0624 14:20:06.907090 18728 net.cpp:141] Setting up conv3_2_D
I0624 14:20:06.907104 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.907105 18728 net.cpp:156] Memory required for data: 115505152
I0624 14:20:06.907111 18728 layer_factory.hpp:77] Creating layer bn3_2_D
I0624 14:20:06.907119 18728 net.cpp:91] Creating Layer bn3_2_D
I0624 14:20:06.907121 18728 net.cpp:425] bn3_2_D <- conv3_2_D
I0624 14:20:06.907125 18728 net.cpp:386] bn3_2_D -> conv3_2_D (in-place)
I0624 14:20:06.907361 18728 net.cpp:141] Setting up bn3_2_D
I0624 14:20:06.907369 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.907372 18728 net.cpp:156] Memory required for data: 117110784
I0624 14:20:06.907377 18728 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 14:20:06.907384 18728 net.cpp:91] Creating Layer scale3_2_D
I0624 14:20:06.907387 18728 net.cpp:425] scale3_2_D <- conv3_2_D
I0624 14:20:06.907392 18728 net.cpp:386] scale3_2_D -> conv3_2_D (in-place)
I0624 14:20:06.907438 18728 layer_factory.hpp:77] Creating layer scale3_2_D
I0624 14:20:06.907562 18728 net.cpp:141] Setting up scale3_2_D
I0624 14:20:06.907578 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.907582 18728 net.cpp:156] Memory required for data: 118716416
I0624 14:20:06.907585 18728 layer_factory.hpp:77] Creating layer relu3_2_D
I0624 14:20:06.907590 18728 net.cpp:91] Creating Layer relu3_2_D
I0624 14:20:06.907593 18728 net.cpp:425] relu3_2_D <- conv3_2_D
I0624 14:20:06.907600 18728 net.cpp:386] relu3_2_D -> conv3_2_D (in-place)
I0624 14:20:06.907768 18728 net.cpp:141] Setting up relu3_2_D
I0624 14:20:06.907776 18728 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0624 14:20:06.907778 18728 net.cpp:156] Memory required for data: 120322048
I0624 14:20:06.907781 18728 layer_factory.hpp:77] Creating layer conv3_1_D
I0624 14:20:06.907789 18728 net.cpp:91] Creating Layer conv3_1_D
I0624 14:20:06.907793 18728 net.cpp:425] conv3_1_D <- conv3_2_D
I0624 14:20:06.907799 18728 net.cpp:399] conv3_1_D -> conv3_1_D
I0624 14:20:06.909358 18728 net.cpp:141] Setting up conv3_1_D
I0624 14:20:06.909370 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.909373 18728 net.cpp:156] Memory required for data: 121124864
I0624 14:20:06.909378 18728 layer_factory.hpp:77] Creating layer bn3_1_D
I0624 14:20:06.909384 18728 net.cpp:91] Creating Layer bn3_1_D
I0624 14:20:06.909386 18728 net.cpp:425] bn3_1_D <- conv3_1_D
I0624 14:20:06.909390 18728 net.cpp:386] bn3_1_D -> conv3_1_D (in-place)
I0624 14:20:06.909622 18728 net.cpp:141] Setting up bn3_1_D
I0624 14:20:06.909631 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.909632 18728 net.cpp:156] Memory required for data: 121927680
I0624 14:20:06.909638 18728 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 14:20:06.909644 18728 net.cpp:91] Creating Layer scale3_1_D
I0624 14:20:06.909647 18728 net.cpp:425] scale3_1_D <- conv3_1_D
I0624 14:20:06.909651 18728 net.cpp:386] scale3_1_D -> conv3_1_D (in-place)
I0624 14:20:06.909696 18728 layer_factory.hpp:77] Creating layer scale3_1_D
I0624 14:20:06.909832 18728 net.cpp:141] Setting up scale3_1_D
I0624 14:20:06.909838 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.909842 18728 net.cpp:156] Memory required for data: 122730496
I0624 14:20:06.909845 18728 layer_factory.hpp:77] Creating layer relu3_1_D
I0624 14:20:06.909850 18728 net.cpp:91] Creating Layer relu3_1_D
I0624 14:20:06.909852 18728 net.cpp:425] relu3_1_D <- conv3_1_D
I0624 14:20:06.909857 18728 net.cpp:386] relu3_1_D -> conv3_1_D (in-place)
I0624 14:20:06.910178 18728 net.cpp:141] Setting up relu3_1_D
I0624 14:20:06.910187 18728 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0624 14:20:06.910190 18728 net.cpp:156] Memory required for data: 123533312
I0624 14:20:06.910193 18728 layer_factory.hpp:77] Creating layer upsample2
I0624 14:20:06.910198 18728 net.cpp:91] Creating Layer upsample2
I0624 14:20:06.910202 18728 net.cpp:425] upsample2 <- conv3_1_D
I0624 14:20:06.910205 18728 net.cpp:425] upsample2 <- pool2_mask
I0624 14:20:06.910212 18728 net.cpp:399] upsample2 -> pool2_D
I0624 14:20:06.910248 18728 net.cpp:141] Setting up upsample2
I0624 14:20:06.910254 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.910255 18728 net.cpp:156] Memory required for data: 126744576
I0624 14:20:06.910257 18728 layer_factory.hpp:77] Creating layer conv2_2_D
I0624 14:20:06.910267 18728 net.cpp:91] Creating Layer conv2_2_D
I0624 14:20:06.910269 18728 net.cpp:425] conv2_2_D <- pool2_D
I0624 14:20:06.910274 18728 net.cpp:399] conv2_2_D -> conv2_2_D
I0624 14:20:06.911478 18728 net.cpp:141] Setting up conv2_2_D
I0624 14:20:06.911492 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.911495 18728 net.cpp:156] Memory required for data: 129955840
I0624 14:20:06.911499 18728 layer_factory.hpp:77] Creating layer bn2_2_D
I0624 14:20:06.911506 18728 net.cpp:91] Creating Layer bn2_2_D
I0624 14:20:06.911509 18728 net.cpp:425] bn2_2_D <- conv2_2_D
I0624 14:20:06.911514 18728 net.cpp:386] bn2_2_D -> conv2_2_D (in-place)
I0624 14:20:06.912395 18728 net.cpp:141] Setting up bn2_2_D
I0624 14:20:06.912407 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.912418 18728 net.cpp:156] Memory required for data: 133167104
I0624 14:20:06.912425 18728 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 14:20:06.912433 18728 net.cpp:91] Creating Layer scale2_2_D
I0624 14:20:06.912436 18728 net.cpp:425] scale2_2_D <- conv2_2_D
I0624 14:20:06.912441 18728 net.cpp:386] scale2_2_D -> conv2_2_D (in-place)
I0624 14:20:06.912492 18728 layer_factory.hpp:77] Creating layer scale2_2_D
I0624 14:20:06.912628 18728 net.cpp:141] Setting up scale2_2_D
I0624 14:20:06.912636 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.912639 18728 net.cpp:156] Memory required for data: 136378368
I0624 14:20:06.912643 18728 layer_factory.hpp:77] Creating layer relu2_2_D
I0624 14:20:06.912649 18728 net.cpp:91] Creating Layer relu2_2_D
I0624 14:20:06.912652 18728 net.cpp:425] relu2_2_D <- conv2_2_D
I0624 14:20:06.912655 18728 net.cpp:386] relu2_2_D -> conv2_2_D (in-place)
I0624 14:20:06.912968 18728 net.cpp:141] Setting up relu2_2_D
I0624 14:20:06.912979 18728 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0624 14:20:06.912982 18728 net.cpp:156] Memory required for data: 139589632
I0624 14:20:06.912986 18728 layer_factory.hpp:77] Creating layer conv2_1_D
I0624 14:20:06.912993 18728 net.cpp:91] Creating Layer conv2_1_D
I0624 14:20:06.913002 18728 net.cpp:425] conv2_1_D <- conv2_2_D
I0624 14:20:06.913005 18728 net.cpp:399] conv2_1_D -> conv2_1_D
I0624 14:20:06.914232 18728 net.cpp:141] Setting up conv2_1_D
I0624 14:20:06.914243 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.914247 18728 net.cpp:156] Memory required for data: 141195264
I0624 14:20:06.914250 18728 layer_factory.hpp:77] Creating layer bn2_1_D
I0624 14:20:06.914258 18728 net.cpp:91] Creating Layer bn2_1_D
I0624 14:20:06.914260 18728 net.cpp:425] bn2_1_D <- conv2_1_D
I0624 14:20:06.914266 18728 net.cpp:386] bn2_1_D -> conv2_1_D (in-place)
I0624 14:20:06.914501 18728 net.cpp:141] Setting up bn2_1_D
I0624 14:20:06.914510 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.914511 18728 net.cpp:156] Memory required for data: 142800896
I0624 14:20:06.914517 18728 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 14:20:06.914525 18728 net.cpp:91] Creating Layer scale2_1_D
I0624 14:20:06.914527 18728 net.cpp:425] scale2_1_D <- conv2_1_D
I0624 14:20:06.914530 18728 net.cpp:386] scale2_1_D -> conv2_1_D (in-place)
I0624 14:20:06.914577 18728 layer_factory.hpp:77] Creating layer scale2_1_D
I0624 14:20:06.914716 18728 net.cpp:141] Setting up scale2_1_D
I0624 14:20:06.914723 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.914726 18728 net.cpp:156] Memory required for data: 144406528
I0624 14:20:06.914731 18728 layer_factory.hpp:77] Creating layer relu2_1_D
I0624 14:20:06.914736 18728 net.cpp:91] Creating Layer relu2_1_D
I0624 14:20:06.914739 18728 net.cpp:425] relu2_1_D <- conv2_1_D
I0624 14:20:06.914742 18728 net.cpp:386] relu2_1_D -> conv2_1_D (in-place)
I0624 14:20:06.914903 18728 net.cpp:141] Setting up relu2_1_D
I0624 14:20:06.914912 18728 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0624 14:20:06.914914 18728 net.cpp:156] Memory required for data: 146012160
I0624 14:20:06.914917 18728 layer_factory.hpp:77] Creating layer upsample1
I0624 14:20:06.914922 18728 net.cpp:91] Creating Layer upsample1
I0624 14:20:06.914924 18728 net.cpp:425] upsample1 <- conv2_1_D
I0624 14:20:06.914928 18728 net.cpp:425] upsample1 <- pool1_mask
I0624 14:20:06.914932 18728 net.cpp:399] upsample1 -> pool1_D
I0624 14:20:06.914965 18728 net.cpp:141] Setting up upsample1
I0624 14:20:06.914973 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.914975 18728 net.cpp:156] Memory required for data: 152434688
I0624 14:20:06.914978 18728 layer_factory.hpp:77] Creating layer conv1_2_D
I0624 14:20:06.914984 18728 net.cpp:91] Creating Layer conv1_2_D
I0624 14:20:06.914986 18728 net.cpp:425] conv1_2_D <- pool1_D
I0624 14:20:06.914991 18728 net.cpp:399] conv1_2_D -> conv1_2_D
I0624 14:20:06.916174 18728 net.cpp:141] Setting up conv1_2_D
I0624 14:20:06.916188 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.916198 18728 net.cpp:156] Memory required for data: 158857216
I0624 14:20:06.916203 18728 layer_factory.hpp:77] Creating layer bn1_2_D
I0624 14:20:06.916211 18728 net.cpp:91] Creating Layer bn1_2_D
I0624 14:20:06.916214 18728 net.cpp:425] bn1_2_D <- conv1_2_D
I0624 14:20:06.916218 18728 net.cpp:386] bn1_2_D -> conv1_2_D (in-place)
I0624 14:20:06.916493 18728 net.cpp:141] Setting up bn1_2_D
I0624 14:20:06.916501 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.916504 18728 net.cpp:156] Memory required for data: 165279744
I0624 14:20:06.916509 18728 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 14:20:06.916515 18728 net.cpp:91] Creating Layer scale1_2_D
I0624 14:20:06.916517 18728 net.cpp:425] scale1_2_D <- conv1_2_D
I0624 14:20:06.916522 18728 net.cpp:386] scale1_2_D -> conv1_2_D (in-place)
I0624 14:20:06.916574 18728 layer_factory.hpp:77] Creating layer scale1_2_D
I0624 14:20:06.917505 18728 net.cpp:141] Setting up scale1_2_D
I0624 14:20:06.917516 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.917520 18728 net.cpp:156] Memory required for data: 171702272
I0624 14:20:06.917524 18728 layer_factory.hpp:77] Creating layer relu1_2_D
I0624 14:20:06.917529 18728 net.cpp:91] Creating Layer relu1_2_D
I0624 14:20:06.917532 18728 net.cpp:425] relu1_2_D <- conv1_2_D
I0624 14:20:06.917537 18728 net.cpp:386] relu1_2_D -> conv1_2_D (in-place)
I0624 14:20:06.917871 18728 net.cpp:141] Setting up relu1_2_D
I0624 14:20:06.917882 18728 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0624 14:20:06.917886 18728 net.cpp:156] Memory required for data: 178124800
I0624 14:20:06.917887 18728 layer_factory.hpp:77] Creating layer conv1_1_D
I0624 14:20:06.917897 18728 net.cpp:91] Creating Layer conv1_1_D
I0624 14:20:06.917901 18728 net.cpp:425] conv1_1_D <- conv1_2_D
I0624 14:20:06.917906 18728 net.cpp:399] conv1_1_D -> conv1_1_D
I0624 14:20:06.919154 18728 net.cpp:141] Setting up conv1_1_D
I0624 14:20:06.919167 18728 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 14:20:06.919168 18728 net.cpp:156] Memory required for data: 178526208
I0624 14:20:06.919175 18728 layer_factory.hpp:77] Creating layer conv1_1_D_conv1_1_D_0_split
I0624 14:20:06.919181 18728 net.cpp:91] Creating Layer conv1_1_D_conv1_1_D_0_split
I0624 14:20:06.919184 18728 net.cpp:425] conv1_1_D_conv1_1_D_0_split <- conv1_1_D
I0624 14:20:06.919188 18728 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_0
I0624 14:20:06.919193 18728 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_1
I0624 14:20:06.919247 18728 net.cpp:141] Setting up conv1_1_D_conv1_1_D_0_split
I0624 14:20:06.919255 18728 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 14:20:06.919257 18728 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0624 14:20:06.919260 18728 net.cpp:156] Memory required for data: 179329024
I0624 14:20:06.919262 18728 layer_factory.hpp:77] Creating layer loss
I0624 14:20:06.919267 18728 net.cpp:91] Creating Layer loss
I0624 14:20:06.919270 18728 net.cpp:425] loss <- conv1_1_D_conv1_1_D_0_split_0
I0624 14:20:06.919272 18728 net.cpp:425] loss <- label_data_1_split_0
I0624 14:20:06.919277 18728 net.cpp:399] loss -> loss
I0624 14:20:06.919286 18728 layer_factory.hpp:77] Creating layer loss
I0624 14:20:06.919781 18728 net.cpp:141] Setting up loss
I0624 14:20:06.919792 18728 net.cpp:148] Top shape: (1)
I0624 14:20:06.919795 18728 net.cpp:151]     with loss weight 1
I0624 14:20:06.919802 18728 net.cpp:156] Memory required for data: 179329028
I0624 14:20:06.919805 18728 layer_factory.hpp:77] Creating layer accuracy
I0624 14:20:06.919809 18728 net.cpp:91] Creating Layer accuracy
I0624 14:20:06.919812 18728 net.cpp:425] accuracy <- conv1_1_D_conv1_1_D_0_split_1
I0624 14:20:06.919816 18728 net.cpp:425] accuracy <- label_data_1_split_1
I0624 14:20:06.919821 18728 net.cpp:399] accuracy -> accuracy
I0624 14:20:06.919827 18728 net.cpp:141] Setting up accuracy
I0624 14:20:06.919831 18728 net.cpp:148] Top shape: (1)
I0624 14:20:06.919832 18728 net.cpp:156] Memory required for data: 179329032
I0624 14:20:06.919843 18728 net.cpp:219] accuracy does not need backward computation.
I0624 14:20:06.919847 18728 net.cpp:217] loss needs backward computation.
I0624 14:20:06.919849 18728 net.cpp:217] conv1_1_D_conv1_1_D_0_split needs backward computation.
I0624 14:20:06.919852 18728 net.cpp:217] conv1_1_D needs backward computation.
I0624 14:20:06.919854 18728 net.cpp:217] relu1_2_D needs backward computation.
I0624 14:20:06.919857 18728 net.cpp:217] scale1_2_D needs backward computation.
I0624 14:20:06.919858 18728 net.cpp:217] bn1_2_D needs backward computation.
I0624 14:20:06.919860 18728 net.cpp:217] conv1_2_D needs backward computation.
I0624 14:20:06.919863 18728 net.cpp:217] upsample1 needs backward computation.
I0624 14:20:06.919865 18728 net.cpp:217] relu2_1_D needs backward computation.
I0624 14:20:06.919867 18728 net.cpp:217] scale2_1_D needs backward computation.
I0624 14:20:06.919869 18728 net.cpp:217] bn2_1_D needs backward computation.
I0624 14:20:06.919872 18728 net.cpp:217] conv2_1_D needs backward computation.
I0624 14:20:06.919874 18728 net.cpp:217] relu2_2_D needs backward computation.
I0624 14:20:06.919877 18728 net.cpp:217] scale2_2_D needs backward computation.
I0624 14:20:06.919878 18728 net.cpp:217] bn2_2_D needs backward computation.
I0624 14:20:06.919880 18728 net.cpp:217] conv2_2_D needs backward computation.
I0624 14:20:06.919883 18728 net.cpp:217] upsample2 needs backward computation.
I0624 14:20:06.919885 18728 net.cpp:217] relu3_1_D needs backward computation.
I0624 14:20:06.919888 18728 net.cpp:217] scale3_1_D needs backward computation.
I0624 14:20:06.919890 18728 net.cpp:217] bn3_1_D needs backward computation.
I0624 14:20:06.919893 18728 net.cpp:217] conv3_1_D needs backward computation.
I0624 14:20:06.919894 18728 net.cpp:217] relu3_2_D needs backward computation.
I0624 14:20:06.919898 18728 net.cpp:217] scale3_2_D needs backward computation.
I0624 14:20:06.919899 18728 net.cpp:217] bn3_2_D needs backward computation.
I0624 14:20:06.919901 18728 net.cpp:217] conv3_2_D needs backward computation.
I0624 14:20:06.919904 18728 net.cpp:217] upsample3 needs backward computation.
I0624 14:20:06.919908 18728 net.cpp:217] relu4_1_D needs backward computation.
I0624 14:20:06.919910 18728 net.cpp:217] scale4_1_D needs backward computation.
I0624 14:20:06.919912 18728 net.cpp:217] bn4_1_D needs backward computation.
I0624 14:20:06.919914 18728 net.cpp:217] conv4_1_D needs backward computation.
I0624 14:20:06.919917 18728 net.cpp:217] relu4_2_D needs backward computation.
I0624 14:20:06.919920 18728 net.cpp:217] scale4_2_D needs backward computation.
I0624 14:20:06.919922 18728 net.cpp:217] bn4_2_D needs backward computation.
I0624 14:20:06.919924 18728 net.cpp:217] conv4_2_D needs backward computation.
I0624 14:20:06.919927 18728 net.cpp:217] upsample4 needs backward computation.
I0624 14:20:06.919930 18728 net.cpp:217] relu5_1_D needs backward computation.
I0624 14:20:06.919934 18728 net.cpp:217] scale5_1_D needs backward computation.
I0624 14:20:06.919935 18728 net.cpp:217] bn5_1_D needs backward computation.
I0624 14:20:06.919937 18728 net.cpp:217] conv5_1_D needs backward computation.
I0624 14:20:06.919940 18728 net.cpp:217] relu5_2_D needs backward computation.
I0624 14:20:06.919942 18728 net.cpp:217] scale5_2_D needs backward computation.
I0624 14:20:06.919945 18728 net.cpp:217] bn5_2_D needs backward computation.
I0624 14:20:06.919946 18728 net.cpp:217] conv5_2_D needs backward computation.
I0624 14:20:06.919950 18728 net.cpp:217] upsample5 needs backward computation.
I0624 14:20:06.919952 18728 net.cpp:217] pool5 needs backward computation.
I0624 14:20:06.919955 18728 net.cpp:217] relu5_2 needs backward computation.
I0624 14:20:06.919957 18728 net.cpp:217] scale5_2 needs backward computation.
I0624 14:20:06.919960 18728 net.cpp:217] bn5_2 needs backward computation.
I0624 14:20:06.919961 18728 net.cpp:217] conv5_2 needs backward computation.
I0624 14:20:06.919965 18728 net.cpp:217] relu5_1 needs backward computation.
I0624 14:20:06.919967 18728 net.cpp:217] scale5_1 needs backward computation.
I0624 14:20:06.919975 18728 net.cpp:217] bn5_1 needs backward computation.
I0624 14:20:06.919978 18728 net.cpp:217] conv5_1 needs backward computation.
I0624 14:20:06.919981 18728 net.cpp:217] pool4 needs backward computation.
I0624 14:20:06.919983 18728 net.cpp:217] relu4_2 needs backward computation.
I0624 14:20:06.919986 18728 net.cpp:217] scale4_2 needs backward computation.
I0624 14:20:06.919988 18728 net.cpp:217] bn4_2 needs backward computation.
I0624 14:20:06.919991 18728 net.cpp:217] conv4_2 needs backward computation.
I0624 14:20:06.919994 18728 net.cpp:217] relu4_1 needs backward computation.
I0624 14:20:06.919996 18728 net.cpp:217] scale4_1 needs backward computation.
I0624 14:20:06.919998 18728 net.cpp:217] bn4_1 needs backward computation.
I0624 14:20:06.920001 18728 net.cpp:217] conv4_1 needs backward computation.
I0624 14:20:06.920003 18728 net.cpp:217] pool3 needs backward computation.
I0624 14:20:06.920006 18728 net.cpp:217] relu3_2 needs backward computation.
I0624 14:20:06.920008 18728 net.cpp:217] scale3_2 needs backward computation.
I0624 14:20:06.920011 18728 net.cpp:217] bn3_2 needs backward computation.
I0624 14:20:06.920013 18728 net.cpp:217] conv3_2 needs backward computation.
I0624 14:20:06.920016 18728 net.cpp:217] relu3_1 needs backward computation.
I0624 14:20:06.920018 18728 net.cpp:217] scale3_1 needs backward computation.
I0624 14:20:06.920020 18728 net.cpp:217] bn3_1 needs backward computation.
I0624 14:20:06.920022 18728 net.cpp:217] conv3_1 needs backward computation.
I0624 14:20:06.920024 18728 net.cpp:217] pool2 needs backward computation.
I0624 14:20:06.920027 18728 net.cpp:217] relu2_2 needs backward computation.
I0624 14:20:06.920029 18728 net.cpp:217] scale2_2 needs backward computation.
I0624 14:20:06.920032 18728 net.cpp:217] bn2_2 needs backward computation.
I0624 14:20:06.920034 18728 net.cpp:217] conv2_2 needs backward computation.
I0624 14:20:06.920037 18728 net.cpp:217] relu2_1 needs backward computation.
I0624 14:20:06.920039 18728 net.cpp:217] scale2_1 needs backward computation.
I0624 14:20:06.920042 18728 net.cpp:217] bn2_1 needs backward computation.
I0624 14:20:06.920043 18728 net.cpp:217] conv2_1 needs backward computation.
I0624 14:20:06.920047 18728 net.cpp:217] pool1 needs backward computation.
I0624 14:20:06.920048 18728 net.cpp:217] relu1_2 needs backward computation.
I0624 14:20:06.920053 18728 net.cpp:217] scale1_2 needs backward computation.
I0624 14:20:06.920054 18728 net.cpp:217] bn1_2 needs backward computation.
I0624 14:20:06.920056 18728 net.cpp:217] conv1_2 needs backward computation.
I0624 14:20:06.920059 18728 net.cpp:217] relu1_1 needs backward computation.
I0624 14:20:06.920061 18728 net.cpp:217] scale1_1 needs backward computation.
I0624 14:20:06.920063 18728 net.cpp:217] bn1_1 needs backward computation.
I0624 14:20:06.920066 18728 net.cpp:217] conv1_1 needs backward computation.
I0624 14:20:06.920069 18728 net.cpp:219] label_data_1_split does not need backward computation.
I0624 14:20:06.920073 18728 net.cpp:219] data does not need backward computation.
I0624 14:20:06.920074 18728 net.cpp:261] This network produces output accuracy
I0624 14:20:06.920076 18728 net.cpp:261] This network produces output loss
I0624 14:20:06.920109 18728 net.cpp:274] Network initialization done.
I0624 14:20:06.920368 18728 solver.cpp:60] Solver scaffolding done.
I0624 14:20:06.924808 18728 caffe.cpp:209] Resuming from data/models/segnet_iter_2000.solverstate
I0624 14:20:06.975622 18728 sgd_solver.cpp:318] SGDSolver: restoring history
I0624 14:20:06.997273 18728 caffe.cpp:219] Starting Optimization
I0624 14:20:06.997292 18728 solver.cpp:279] Solving segnet
I0624 14:20:06.997294 18728 solver.cpp:280] Learning Rate Policy: step
I0624 14:20:07.001029 18728 solver.cpp:337] Iteration 2000, Testing net (#0)
I0624 14:20:07.370817 18728 solver.cpp:404]     Test net output #0: accuracy = 0.983462
I0624 14:20:07.370842 18728 solver.cpp:404]     Test net output #1: loss = 0.0397269 (* 1 = 0.0397269 loss)
I0624 14:20:08.115504 18728 solver.cpp:228] Iteration 2000, loss = 0.0317226
I0624 14:20:08.115547 18728 solver.cpp:244]     Train net output #0: accuracy = 0.98713
I0624 14:20:08.115556 18728 solver.cpp:244]     Train net output #1: loss = 0.0317226 (* 1 = 0.0317226 loss)
I0624 14:20:08.115567 18728 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0624 14:20:22.424351 18728 solver.cpp:228] Iteration 2020, loss = 0.0298896
I0624 14:20:22.424388 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988878
I0624 14:20:22.424396 18728 solver.cpp:244]     Train net output #1: loss = 0.0298896 (* 1 = 0.0298896 loss)
I0624 14:20:22.424401 18728 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0624 14:20:37.055152 18728 solver.cpp:228] Iteration 2040, loss = 0.0333588
I0624 14:20:37.055220 18728 solver.cpp:244]     Train net output #0: accuracy = 0.986766
I0624 14:20:37.055230 18728 solver.cpp:244]     Train net output #1: loss = 0.0333588 (* 1 = 0.0333588 loss)
I0624 14:20:37.055234 18728 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0624 14:20:51.648465 18728 solver.cpp:228] Iteration 2060, loss = 0.0344136
I0624 14:20:51.648490 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987344
I0624 14:20:51.648499 18728 solver.cpp:244]     Train net output #1: loss = 0.0344136 (* 1 = 0.0344136 loss)
I0624 14:20:51.648504 18728 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0624 14:21:06.277082 18728 solver.cpp:228] Iteration 2080, loss = 0.0336114
I0624 14:21:06.277107 18728 solver.cpp:244]     Train net output #0: accuracy = 0.986308
I0624 14:21:06.277113 18728 solver.cpp:244]     Train net output #1: loss = 0.0336114 (* 1 = 0.0336114 loss)
I0624 14:21:06.277118 18728 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0624 14:21:20.513067 18728 solver.cpp:337] Iteration 2100, Testing net (#0)
I0624 14:21:20.848759 18728 solver.cpp:404]     Test net output #0: accuracy = 0.980658
I0624 14:21:20.848794 18728 solver.cpp:404]     Test net output #1: loss = 0.0627742 (* 1 = 0.0627742 loss)
I0624 14:21:21.258731 18728 solver.cpp:228] Iteration 2100, loss = 0.034273
I0624 14:21:21.258754 18728 solver.cpp:244]     Train net output #0: accuracy = 0.986999
I0624 14:21:21.258762 18728 solver.cpp:244]     Train net output #1: loss = 0.034273 (* 1 = 0.034273 loss)
I0624 14:21:21.258766 18728 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0624 14:21:35.901690 18728 solver.cpp:228] Iteration 2120, loss = 0.0307616
I0624 14:21:35.901713 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988964
I0624 14:21:35.901721 18728 solver.cpp:244]     Train net output #1: loss = 0.0307616 (* 1 = 0.0307616 loss)
I0624 14:21:35.901724 18728 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0624 14:21:50.720986 18728 solver.cpp:228] Iteration 2140, loss = 0.0426208
I0624 14:21:50.721084 18728 solver.cpp:244]     Train net output #0: accuracy = 0.986144
I0624 14:21:50.721094 18728 solver.cpp:244]     Train net output #1: loss = 0.0426208 (* 1 = 0.0426208 loss)
I0624 14:21:50.721099 18728 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0624 14:22:05.365671 18728 solver.cpp:228] Iteration 2160, loss = 0.0330436
I0624 14:22:05.365697 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987595
I0624 14:22:05.365705 18728 solver.cpp:244]     Train net output #1: loss = 0.0330436 (* 1 = 0.0330436 loss)
I0624 14:22:05.365710 18728 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0624 14:22:20.013093 18728 solver.cpp:228] Iteration 2180, loss = 0.0294458
I0624 14:22:20.013119 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989177
I0624 14:22:20.013126 18728 solver.cpp:244]     Train net output #1: loss = 0.0294458 (* 1 = 0.0294458 loss)
I0624 14:22:20.013131 18728 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0624 14:22:34.292227 18728 solver.cpp:337] Iteration 2200, Testing net (#0)
I0624 14:22:34.633185 18728 solver.cpp:404]     Test net output #0: accuracy = 0.982104
I0624 14:22:34.633220 18728 solver.cpp:404]     Test net output #1: loss = 0.0417979 (* 1 = 0.0417979 loss)
I0624 14:22:35.041831 18728 solver.cpp:228] Iteration 2200, loss = 0.0310358
I0624 14:22:35.041857 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988397
I0624 14:22:35.041863 18728 solver.cpp:244]     Train net output #1: loss = 0.0310358 (* 1 = 0.0310358 loss)
I0624 14:22:35.041868 18728 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0624 14:22:49.691501 18728 solver.cpp:228] Iteration 2220, loss = 0.0299741
I0624 14:22:49.691539 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988794
I0624 14:22:49.691546 18728 solver.cpp:244]     Train net output #1: loss = 0.0299741 (* 1 = 0.0299741 loss)
I0624 14:22:49.691551 18728 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0624 14:23:04.328893 18728 solver.cpp:228] Iteration 2240, loss = 0.0320167
I0624 14:23:04.329016 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988016
I0624 14:23:04.329027 18728 solver.cpp:244]     Train net output #1: loss = 0.0320167 (* 1 = 0.0320167 loss)
I0624 14:23:04.329032 18728 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0624 14:23:18.985420 18728 solver.cpp:228] Iteration 2260, loss = 0.0313044
I0624 14:23:18.985445 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988634
I0624 14:23:18.985452 18728 solver.cpp:244]     Train net output #1: loss = 0.0313044 (* 1 = 0.0313044 loss)
I0624 14:23:18.985457 18728 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0624 14:23:33.628046 18728 solver.cpp:228] Iteration 2280, loss = 0.0313787
I0624 14:23:33.628070 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989053
I0624 14:23:33.628077 18728 solver.cpp:244]     Train net output #1: loss = 0.0313787 (* 1 = 0.0313787 loss)
I0624 14:23:33.628082 18728 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0624 14:23:47.869063 18728 solver.cpp:337] Iteration 2300, Testing net (#0)
I0624 14:23:48.204766 18728 solver.cpp:404]     Test net output #0: accuracy = 0.977892
I0624 14:23:48.204790 18728 solver.cpp:404]     Test net output #1: loss = 0.0605657 (* 1 = 0.0605657 loss)
I0624 14:23:48.614558 18728 solver.cpp:228] Iteration 2300, loss = 0.0331856
I0624 14:23:48.614585 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987714
I0624 14:23:48.614593 18728 solver.cpp:244]     Train net output #1: loss = 0.0331856 (* 1 = 0.0331856 loss)
I0624 14:23:48.614598 18728 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0624 14:24:03.259907 18728 solver.cpp:228] Iteration 2320, loss = 0.0343364
I0624 14:24:03.259943 18728 solver.cpp:244]     Train net output #0: accuracy = 0.986205
I0624 14:24:03.259949 18728 solver.cpp:244]     Train net output #1: loss = 0.0343364 (* 1 = 0.0343364 loss)
I0624 14:24:03.259954 18728 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0624 14:24:17.897599 18728 solver.cpp:228] Iteration 2340, loss = 0.0304078
I0624 14:24:17.897693 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988684
I0624 14:24:17.897702 18728 solver.cpp:244]     Train net output #1: loss = 0.0304078 (* 1 = 0.0304078 loss)
I0624 14:24:17.897706 18728 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0624 14:24:32.552338 18728 solver.cpp:228] Iteration 2360, loss = 0.0286672
I0624 14:24:32.552372 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989297
I0624 14:24:32.552391 18728 solver.cpp:244]     Train net output #1: loss = 0.0286672 (* 1 = 0.0286672 loss)
I0624 14:24:32.552395 18728 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0624 14:24:47.209746 18728 solver.cpp:228] Iteration 2380, loss = 0.0308837
I0624 14:24:47.209774 18728 solver.cpp:244]     Train net output #0: accuracy = 0.98862
I0624 14:24:47.209780 18728 solver.cpp:244]     Train net output #1: loss = 0.0308837 (* 1 = 0.0308837 loss)
I0624 14:24:47.209785 18728 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0624 14:25:01.444952 18728 solver.cpp:337] Iteration 2400, Testing net (#0)
I0624 14:25:01.780772 18728 solver.cpp:404]     Test net output #0: accuracy = 0.979872
I0624 14:25:01.780797 18728 solver.cpp:404]     Test net output #1: loss = 0.0669868 (* 1 = 0.0669868 loss)
I0624 14:25:02.191479 18728 solver.cpp:228] Iteration 2400, loss = 0.0305465
I0624 14:25:02.191514 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988893
I0624 14:25:02.191522 18728 solver.cpp:244]     Train net output #1: loss = 0.0305465 (* 1 = 0.0305465 loss)
I0624 14:25:02.191526 18728 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0624 14:25:16.832619 18728 solver.cpp:228] Iteration 2420, loss = 0.0368938
I0624 14:25:16.832646 18728 solver.cpp:244]     Train net output #0: accuracy = 0.985576
I0624 14:25:16.832653 18728 solver.cpp:244]     Train net output #1: loss = 0.0368938 (* 1 = 0.0368938 loss)
I0624 14:25:16.832659 18728 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0624 14:25:31.479349 18728 solver.cpp:228] Iteration 2440, loss = 0.0330062
I0624 14:25:31.479465 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987242
I0624 14:25:31.479476 18728 solver.cpp:244]     Train net output #1: loss = 0.0330062 (* 1 = 0.0330062 loss)
I0624 14:25:31.479481 18728 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0624 14:25:46.127055 18728 solver.cpp:228] Iteration 2460, loss = 0.0321805
I0624 14:25:46.127081 18728 solver.cpp:244]     Train net output #0: accuracy = 0.98811
I0624 14:25:46.127089 18728 solver.cpp:244]     Train net output #1: loss = 0.0321805 (* 1 = 0.0321805 loss)
I0624 14:25:46.127092 18728 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0624 14:26:00.804774 18728 solver.cpp:228] Iteration 2480, loss = 0.0287155
I0624 14:26:00.804802 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989527
I0624 14:26:00.804811 18728 solver.cpp:244]     Train net output #1: loss = 0.0287155 (* 1 = 0.0287155 loss)
I0624 14:26:00.804816 18728 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0624 14:26:15.043617 18728 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_2500.caffemodel
I0624 14:26:15.085929 18728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_2500.solverstate
I0624 14:26:15.105268 18728 solver.cpp:337] Iteration 2500, Testing net (#0)
I0624 14:26:15.443189 18728 solver.cpp:404]     Test net output #0: accuracy = 0.979984
I0624 14:26:15.443213 18728 solver.cpp:404]     Test net output #1: loss = 0.0514456 (* 1 = 0.0514456 loss)
I0624 14:26:15.853430 18728 solver.cpp:228] Iteration 2500, loss = 0.0332934
I0624 14:26:15.853456 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987084
I0624 14:26:15.853462 18728 solver.cpp:244]     Train net output #1: loss = 0.0332934 (* 1 = 0.0332934 loss)
I0624 14:26:15.853466 18728 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0624 14:26:30.504237 18728 solver.cpp:228] Iteration 2520, loss = 0.0326524
I0624 14:26:30.504261 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987535
I0624 14:26:30.504279 18728 solver.cpp:244]     Train net output #1: loss = 0.0326524 (* 1 = 0.0326524 loss)
I0624 14:26:30.504284 18728 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0624 14:26:45.160706 18728 solver.cpp:228] Iteration 2540, loss = 0.0303533
I0624 14:26:45.160809 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988347
I0624 14:26:45.160820 18728 solver.cpp:244]     Train net output #1: loss = 0.0303533 (* 1 = 0.0303533 loss)
I0624 14:26:45.160825 18728 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0624 14:26:59.809756 18728 solver.cpp:228] Iteration 2560, loss = 0.030792
I0624 14:26:59.809780 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989018
I0624 14:26:59.809787 18728 solver.cpp:244]     Train net output #1: loss = 0.030792 (* 1 = 0.030792 loss)
I0624 14:26:59.809792 18728 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0624 14:27:14.478257 18728 solver.cpp:228] Iteration 2580, loss = 0.0322687
I0624 14:27:14.478282 18728 solver.cpp:244]     Train net output #0: accuracy = 0.98748
I0624 14:27:14.478291 18728 solver.cpp:244]     Train net output #1: loss = 0.0322687 (* 1 = 0.0322687 loss)
I0624 14:27:14.478296 18728 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0624 14:27:28.725553 18728 solver.cpp:337] Iteration 2600, Testing net (#0)
I0624 14:27:29.060778 18728 solver.cpp:404]     Test net output #0: accuracy = 0.980506
I0624 14:27:29.060813 18728 solver.cpp:404]     Test net output #1: loss = 0.0549367 (* 1 = 0.0549367 loss)
I0624 14:27:29.471688 18728 solver.cpp:228] Iteration 2600, loss = 0.0323618
I0624 14:27:29.471712 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987846
I0624 14:27:29.471720 18728 solver.cpp:244]     Train net output #1: loss = 0.0323618 (* 1 = 0.0323618 loss)
I0624 14:27:29.471725 18728 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0624 14:27:44.119618 18728 solver.cpp:228] Iteration 2620, loss = 0.0321162
I0624 14:27:44.119644 18728 solver.cpp:244]     Train net output #0: accuracy = 0.98763
I0624 14:27:44.119652 18728 solver.cpp:244]     Train net output #1: loss = 0.0321162 (* 1 = 0.0321162 loss)
I0624 14:27:44.119657 18728 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0624 14:27:58.786159 18728 solver.cpp:228] Iteration 2640, loss = 0.0320101
I0624 14:27:58.786247 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988434
I0624 14:27:58.786257 18728 solver.cpp:244]     Train net output #1: loss = 0.0320101 (* 1 = 0.0320101 loss)
I0624 14:27:58.786262 18728 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0624 14:28:13.439697 18728 solver.cpp:228] Iteration 2660, loss = 0.0293895
I0624 14:28:13.439723 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989667
I0624 14:28:13.439730 18728 solver.cpp:244]     Train net output #1: loss = 0.0293895 (* 1 = 0.0293895 loss)
I0624 14:28:13.439734 18728 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0624 14:28:28.075433 18728 solver.cpp:228] Iteration 2680, loss = 0.0297104
I0624 14:28:28.075458 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988534
I0624 14:28:28.075465 18728 solver.cpp:244]     Train net output #1: loss = 0.0297104 (* 1 = 0.0297104 loss)
I0624 14:28:28.075470 18728 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0624 14:28:42.344488 18728 solver.cpp:337] Iteration 2700, Testing net (#0)
I0624 14:28:42.679868 18728 solver.cpp:404]     Test net output #0: accuracy = 0.983454
I0624 14:28:42.679903 18728 solver.cpp:404]     Test net output #1: loss = 0.0447403 (* 1 = 0.0447403 loss)
I0624 14:28:43.090044 18728 solver.cpp:228] Iteration 2700, loss = 0.0320494
I0624 14:28:43.090077 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987382
I0624 14:28:43.090085 18728 solver.cpp:244]     Train net output #1: loss = 0.0320494 (* 1 = 0.0320494 loss)
I0624 14:28:43.090090 18728 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0624 14:28:57.725275 18728 solver.cpp:228] Iteration 2720, loss = 0.0294747
I0624 14:28:57.725299 18728 solver.cpp:244]     Train net output #0: accuracy = 0.98947
I0624 14:28:57.725307 18728 solver.cpp:244]     Train net output #1: loss = 0.0294747 (* 1 = 0.0294747 loss)
I0624 14:28:57.725312 18728 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0624 14:29:12.361052 18728 solver.cpp:228] Iteration 2740, loss = 0.0304899
I0624 14:29:12.361150 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988651
I0624 14:29:12.361160 18728 solver.cpp:244]     Train net output #1: loss = 0.0304899 (* 1 = 0.0304899 loss)
I0624 14:29:12.361165 18728 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0624 14:29:27.007299 18728 solver.cpp:228] Iteration 2760, loss = 0.0337582
I0624 14:29:27.007325 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987621
I0624 14:29:27.007333 18728 solver.cpp:244]     Train net output #1: loss = 0.0337582 (* 1 = 0.0337582 loss)
I0624 14:29:27.007339 18728 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0624 14:29:41.643795 18728 solver.cpp:228] Iteration 2780, loss = 0.0312958
I0624 14:29:41.643821 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988855
I0624 14:29:41.643827 18728 solver.cpp:244]     Train net output #1: loss = 0.0312958 (* 1 = 0.0312958 loss)
I0624 14:29:41.643832 18728 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0624 14:29:55.885380 18728 solver.cpp:337] Iteration 2800, Testing net (#0)
I0624 14:29:56.221424 18728 solver.cpp:404]     Test net output #0: accuracy = 0.977479
I0624 14:29:56.221449 18728 solver.cpp:404]     Test net output #1: loss = 0.0648069 (* 1 = 0.0648069 loss)
I0624 14:29:56.633036 18728 solver.cpp:228] Iteration 2800, loss = 0.0273738
I0624 14:29:56.633072 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989919
I0624 14:29:56.633080 18728 solver.cpp:244]     Train net output #1: loss = 0.0273738 (* 1 = 0.0273738 loss)
I0624 14:29:56.633086 18728 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0624 14:30:11.281976 18728 solver.cpp:228] Iteration 2820, loss = 0.0307217
I0624 14:30:11.282001 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987974
I0624 14:30:11.282011 18728 solver.cpp:244]     Train net output #1: loss = 0.0307217 (* 1 = 0.0307217 loss)
I0624 14:30:11.282014 18728 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0624 14:30:25.921934 18728 solver.cpp:228] Iteration 2840, loss = 0.0295506
I0624 14:30:25.922040 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989234
I0624 14:30:25.922050 18728 solver.cpp:244]     Train net output #1: loss = 0.0295506 (* 1 = 0.0295506 loss)
I0624 14:30:25.922055 18728 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0624 14:30:40.598812 18728 solver.cpp:228] Iteration 2860, loss = 0.0286551
I0624 14:30:40.598847 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989531
I0624 14:30:40.598855 18728 solver.cpp:244]     Train net output #1: loss = 0.0286551 (* 1 = 0.0286551 loss)
I0624 14:30:40.598860 18728 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0624 14:30:55.237862 18728 solver.cpp:228] Iteration 2880, loss = 0.0289909
I0624 14:30:55.237886 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989258
I0624 14:30:55.237893 18728 solver.cpp:244]     Train net output #1: loss = 0.0289909 (* 1 = 0.0289909 loss)
I0624 14:30:55.237898 18728 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0624 14:31:09.473880 18728 solver.cpp:337] Iteration 2900, Testing net (#0)
I0624 14:31:09.809751 18728 solver.cpp:404]     Test net output #0: accuracy = 0.979597
I0624 14:31:09.809787 18728 solver.cpp:404]     Test net output #1: loss = 0.0582538 (* 1 = 0.0582538 loss)
I0624 14:31:10.219909 18728 solver.cpp:228] Iteration 2900, loss = 0.0298889
I0624 14:31:10.219934 18728 solver.cpp:244]     Train net output #0: accuracy = 0.98925
I0624 14:31:10.219941 18728 solver.cpp:244]     Train net output #1: loss = 0.0298889 (* 1 = 0.0298889 loss)
I0624 14:31:10.219946 18728 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0624 14:31:24.868592 18728 solver.cpp:228] Iteration 2920, loss = 0.0337292
I0624 14:31:24.868616 18728 solver.cpp:244]     Train net output #0: accuracy = 0.986671
I0624 14:31:24.868624 18728 solver.cpp:244]     Train net output #1: loss = 0.0337292 (* 1 = 0.0337292 loss)
I0624 14:31:24.868629 18728 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0624 14:31:39.506940 18728 solver.cpp:228] Iteration 2940, loss = 0.0328489
I0624 14:31:39.507038 18728 solver.cpp:244]     Train net output #0: accuracy = 0.986701
I0624 14:31:39.507047 18728 solver.cpp:244]     Train net output #1: loss = 0.0328489 (* 1 = 0.0328489 loss)
I0624 14:31:39.507053 18728 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0624 14:31:54.149323 18728 solver.cpp:228] Iteration 2960, loss = 0.0283015
I0624 14:31:54.149348 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989597
I0624 14:31:54.149356 18728 solver.cpp:244]     Train net output #1: loss = 0.0283015 (* 1 = 0.0283015 loss)
I0624 14:31:54.149361 18728 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0624 14:32:08.805663 18728 solver.cpp:228] Iteration 2980, loss = 0.0315007
I0624 14:32:08.805701 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988378
I0624 14:32:08.805708 18728 solver.cpp:244]     Train net output #1: loss = 0.0315007 (* 1 = 0.0315007 loss)
I0624 14:32:08.805713 18728 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0624 14:32:23.058611 18728 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_3000.caffemodel
I0624 14:32:23.101297 18728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_3000.solverstate
I0624 14:32:23.120932 18728 solver.cpp:337] Iteration 3000, Testing net (#0)
I0624 14:32:23.459411 18728 solver.cpp:404]     Test net output #0: accuracy = 0.973141
I0624 14:32:23.459435 18728 solver.cpp:404]     Test net output #1: loss = 0.0841991 (* 1 = 0.0841991 loss)
I0624 14:32:23.869161 18728 solver.cpp:228] Iteration 3000, loss = 0.0315932
I0624 14:32:23.869187 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988852
I0624 14:32:23.869194 18728 solver.cpp:244]     Train net output #1: loss = 0.0315932 (* 1 = 0.0315932 loss)
I0624 14:32:23.869199 18728 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0624 14:32:38.564853 18728 solver.cpp:228] Iteration 3020, loss = 0.0274211
I0624 14:32:38.564890 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989916
I0624 14:32:38.564898 18728 solver.cpp:244]     Train net output #1: loss = 0.0274211 (* 1 = 0.0274211 loss)
I0624 14:32:38.564903 18728 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0624 14:32:53.222456 18728 solver.cpp:228] Iteration 3040, loss = 0.0294709
I0624 14:32:53.222579 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988824
I0624 14:32:53.222589 18728 solver.cpp:244]     Train net output #1: loss = 0.0294709 (* 1 = 0.0294709 loss)
I0624 14:32:53.222594 18728 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0624 14:33:07.884918 18728 solver.cpp:228] Iteration 3060, loss = 0.028989
I0624 14:33:07.884945 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989346
I0624 14:33:07.884953 18728 solver.cpp:244]     Train net output #1: loss = 0.028989 (* 1 = 0.028989 loss)
I0624 14:33:07.884958 18728 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0624 14:33:22.542104 18728 solver.cpp:228] Iteration 3080, loss = 0.0284576
I0624 14:33:22.542129 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988983
I0624 14:33:22.542135 18728 solver.cpp:244]     Train net output #1: loss = 0.0284576 (* 1 = 0.0284576 loss)
I0624 14:33:22.542140 18728 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0624 14:33:36.773969 18728 solver.cpp:337] Iteration 3100, Testing net (#0)
I0624 14:33:37.109563 18728 solver.cpp:404]     Test net output #0: accuracy = 0.983428
I0624 14:33:37.109597 18728 solver.cpp:404]     Test net output #1: loss = 0.0509554 (* 1 = 0.0509554 loss)
I0624 14:33:37.519773 18728 solver.cpp:228] Iteration 3100, loss = 0.0318339
I0624 14:33:37.519798 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988854
I0624 14:33:37.519805 18728 solver.cpp:244]     Train net output #1: loss = 0.0318339 (* 1 = 0.0318339 loss)
I0624 14:33:37.519810 18728 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0624 14:33:52.167330 18728 solver.cpp:228] Iteration 3120, loss = 0.0323391
I0624 14:33:52.167356 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987329
I0624 14:33:52.167363 18728 solver.cpp:244]     Train net output #1: loss = 0.0323391 (* 1 = 0.0323391 loss)
I0624 14:33:52.167369 18728 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0624 14:34:06.816234 18728 solver.cpp:228] Iteration 3140, loss = 0.0317778
I0624 14:34:06.816334 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988009
I0624 14:34:06.816342 18728 solver.cpp:244]     Train net output #1: loss = 0.0317778 (* 1 = 0.0317778 loss)
I0624 14:34:06.816346 18728 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0624 14:34:21.533946 18728 solver.cpp:228] Iteration 3160, loss = 0.0302634
I0624 14:34:21.533970 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988563
I0624 14:34:21.533978 18728 solver.cpp:244]     Train net output #1: loss = 0.0302634 (* 1 = 0.0302634 loss)
I0624 14:34:21.533983 18728 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0624 14:34:36.213848 18728 solver.cpp:228] Iteration 3180, loss = 0.0309452
I0624 14:34:36.213882 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988403
I0624 14:34:36.213891 18728 solver.cpp:244]     Train net output #1: loss = 0.0309452 (* 1 = 0.0309452 loss)
I0624 14:34:36.213896 18728 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0624 14:34:50.470705 18728 solver.cpp:337] Iteration 3200, Testing net (#0)
I0624 14:34:50.806445 18728 solver.cpp:404]     Test net output #0: accuracy = 0.980993
I0624 14:34:50.806470 18728 solver.cpp:404]     Test net output #1: loss = 0.0659193 (* 1 = 0.0659193 loss)
I0624 14:34:51.217998 18728 solver.cpp:228] Iteration 3200, loss = 0.0369511
I0624 14:34:51.218034 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987984
I0624 14:34:51.218042 18728 solver.cpp:244]     Train net output #1: loss = 0.0369511 (* 1 = 0.0369511 loss)
I0624 14:34:51.218047 18728 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0624 14:35:05.890123 18728 solver.cpp:228] Iteration 3220, loss = 0.0314893
I0624 14:35:05.890151 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988073
I0624 14:35:05.890169 18728 solver.cpp:244]     Train net output #1: loss = 0.0314893 (* 1 = 0.0314893 loss)
I0624 14:35:05.890175 18728 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0624 14:35:20.535902 18728 solver.cpp:228] Iteration 3240, loss = 0.0299134
I0624 14:35:20.536005 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988626
I0624 14:35:20.536015 18728 solver.cpp:244]     Train net output #1: loss = 0.0299134 (* 1 = 0.0299134 loss)
I0624 14:35:20.536020 18728 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0624 14:35:35.191922 18728 solver.cpp:228] Iteration 3260, loss = 0.0336353
I0624 14:35:35.191948 18728 solver.cpp:244]     Train net output #0: accuracy = 0.986309
I0624 14:35:35.191956 18728 solver.cpp:244]     Train net output #1: loss = 0.0336353 (* 1 = 0.0336353 loss)
I0624 14:35:35.191961 18728 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0624 14:35:49.825247 18728 solver.cpp:228] Iteration 3280, loss = 0.0288521
I0624 14:35:49.825270 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988816
I0624 14:35:49.825278 18728 solver.cpp:244]     Train net output #1: loss = 0.0288521 (* 1 = 0.0288521 loss)
I0624 14:35:49.825284 18728 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0624 14:36:04.053778 18728 solver.cpp:337] Iteration 3300, Testing net (#0)
I0624 14:36:04.389535 18728 solver.cpp:404]     Test net output #0: accuracy = 0.978965
I0624 14:36:04.389570 18728 solver.cpp:404]     Test net output #1: loss = 0.0644335 (* 1 = 0.0644335 loss)
I0624 14:36:04.798710 18728 solver.cpp:228] Iteration 3300, loss = 0.0299188
I0624 14:36:04.798734 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988323
I0624 14:36:04.798743 18728 solver.cpp:244]     Train net output #1: loss = 0.0299188 (* 1 = 0.0299188 loss)
I0624 14:36:04.798748 18728 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0624 14:36:19.436672 18728 solver.cpp:228] Iteration 3320, loss = 0.0292175
I0624 14:36:19.436697 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989072
I0624 14:36:19.436704 18728 solver.cpp:244]     Train net output #1: loss = 0.0292175 (* 1 = 0.0292175 loss)
I0624 14:36:19.436709 18728 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0624 14:36:34.132333 18728 solver.cpp:228] Iteration 3340, loss = 0.0253796
I0624 14:36:34.132433 18728 solver.cpp:244]     Train net output #0: accuracy = 0.990725
I0624 14:36:34.132442 18728 solver.cpp:244]     Train net output #1: loss = 0.0253796 (* 1 = 0.0253796 loss)
I0624 14:36:34.132447 18728 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0624 14:36:48.769639 18728 solver.cpp:228] Iteration 3360, loss = 0.0309913
I0624 14:36:48.769665 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988347
I0624 14:36:48.769671 18728 solver.cpp:244]     Train net output #1: loss = 0.0309913 (* 1 = 0.0309913 loss)
I0624 14:36:48.769676 18728 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0624 14:37:03.404404 18728 solver.cpp:228] Iteration 3380, loss = 0.0297397
I0624 14:37:03.404429 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988971
I0624 14:37:03.404436 18728 solver.cpp:244]     Train net output #1: loss = 0.0297397 (* 1 = 0.0297397 loss)
I0624 14:37:03.404440 18728 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0624 14:37:17.628885 18728 solver.cpp:337] Iteration 3400, Testing net (#0)
I0624 14:37:17.964864 18728 solver.cpp:404]     Test net output #0: accuracy = 0.983119
I0624 14:37:17.964887 18728 solver.cpp:404]     Test net output #1: loss = 0.05091 (* 1 = 0.05091 loss)
I0624 14:37:18.375226 18728 solver.cpp:228] Iteration 3400, loss = 0.0290371
I0624 14:37:18.375262 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989399
I0624 14:37:18.375269 18728 solver.cpp:244]     Train net output #1: loss = 0.0290371 (* 1 = 0.0290371 loss)
I0624 14:37:18.375274 18728 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0624 14:37:33.005058 18728 solver.cpp:228] Iteration 3420, loss = 0.0320369
I0624 14:37:33.005084 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987749
I0624 14:37:33.005090 18728 solver.cpp:244]     Train net output #1: loss = 0.0320369 (* 1 = 0.0320369 loss)
I0624 14:37:33.005095 18728 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0624 14:37:47.630008 18728 solver.cpp:228] Iteration 3440, loss = 0.0305586
I0624 14:37:47.630110 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988712
I0624 14:37:47.630118 18728 solver.cpp:244]     Train net output #1: loss = 0.0305586 (* 1 = 0.0305586 loss)
I0624 14:37:47.630123 18728 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0624 14:38:02.269814 18728 solver.cpp:228] Iteration 3460, loss = 0.0288126
I0624 14:38:02.269840 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989516
I0624 14:38:02.269846 18728 solver.cpp:244]     Train net output #1: loss = 0.0288126 (* 1 = 0.0288126 loss)
I0624 14:38:02.269852 18728 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0624 14:38:16.909931 18728 solver.cpp:228] Iteration 3480, loss = 0.0325279
I0624 14:38:16.909955 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987791
I0624 14:38:16.909963 18728 solver.cpp:244]     Train net output #1: loss = 0.0325279 (* 1 = 0.0325279 loss)
I0624 14:38:16.909968 18728 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0624 14:38:31.178711 18728 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_3500.caffemodel
I0624 14:38:31.225046 18728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_3500.solverstate
I0624 14:38:31.244412 18728 solver.cpp:337] Iteration 3500, Testing net (#0)
I0624 14:38:31.583062 18728 solver.cpp:404]     Test net output #0: accuracy = 0.978727
I0624 14:38:31.583098 18728 solver.cpp:404]     Test net output #1: loss = 0.0646643 (* 1 = 0.0646643 loss)
I0624 14:38:31.997580 18728 solver.cpp:228] Iteration 3500, loss = 0.0292591
I0624 14:38:31.997603 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989345
I0624 14:38:31.997611 18728 solver.cpp:244]     Train net output #1: loss = 0.0292591 (* 1 = 0.0292591 loss)
I0624 14:38:31.997617 18728 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0624 14:38:46.648941 18728 solver.cpp:228] Iteration 3520, loss = 0.0303442
I0624 14:38:46.648964 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988631
I0624 14:38:46.648983 18728 solver.cpp:244]     Train net output #1: loss = 0.0303442 (* 1 = 0.0303442 loss)
I0624 14:38:46.648988 18728 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0624 14:39:01.300587 18728 solver.cpp:228] Iteration 3540, loss = 0.0289428
I0624 14:39:01.300683 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989156
I0624 14:39:01.300691 18728 solver.cpp:244]     Train net output #1: loss = 0.0289428 (* 1 = 0.0289428 loss)
I0624 14:39:01.300696 18728 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0624 14:39:15.951899 18728 solver.cpp:228] Iteration 3560, loss = 0.0306273
I0624 14:39:15.951934 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988342
I0624 14:39:15.951941 18728 solver.cpp:244]     Train net output #1: loss = 0.0306273 (* 1 = 0.0306273 loss)
I0624 14:39:15.951946 18728 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0624 14:39:30.631451 18728 solver.cpp:228] Iteration 3580, loss = 0.0299322
I0624 14:39:30.631476 18728 solver.cpp:244]     Train net output #0: accuracy = 0.98869
I0624 14:39:30.631484 18728 solver.cpp:244]     Train net output #1: loss = 0.0299322 (* 1 = 0.0299322 loss)
I0624 14:39:30.631489 18728 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0624 14:39:44.871708 18728 solver.cpp:337] Iteration 3600, Testing net (#0)
I0624 14:39:45.207295 18728 solver.cpp:404]     Test net output #0: accuracy = 0.983765
I0624 14:39:45.207319 18728 solver.cpp:404]     Test net output #1: loss = 0.053445 (* 1 = 0.053445 loss)
I0624 14:39:45.616375 18728 solver.cpp:228] Iteration 3600, loss = 0.0302645
I0624 14:39:45.616401 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989032
I0624 14:39:45.616410 18728 solver.cpp:244]     Train net output #1: loss = 0.0302645 (* 1 = 0.0302645 loss)
I0624 14:39:45.616415 18728 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0624 14:40:00.266024 18728 solver.cpp:228] Iteration 3620, loss = 0.0306041
I0624 14:40:00.266049 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988506
I0624 14:40:00.266057 18728 solver.cpp:244]     Train net output #1: loss = 0.0306041 (* 1 = 0.0306041 loss)
I0624 14:40:00.266062 18728 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0624 14:40:14.915181 18728 solver.cpp:228] Iteration 3640, loss = 0.0309513
I0624 14:40:14.915285 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987666
I0624 14:40:14.915295 18728 solver.cpp:244]     Train net output #1: loss = 0.0309513 (* 1 = 0.0309513 loss)
I0624 14:40:14.915300 18728 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0624 14:40:29.562108 18728 solver.cpp:228] Iteration 3660, loss = 0.0305484
I0624 14:40:29.562131 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988634
I0624 14:40:29.562139 18728 solver.cpp:244]     Train net output #1: loss = 0.0305484 (* 1 = 0.0305484 loss)
I0624 14:40:29.562144 18728 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0624 14:40:44.263381 18728 solver.cpp:228] Iteration 3680, loss = 0.0298361
I0624 14:40:44.263404 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988422
I0624 14:40:44.263411 18728 solver.cpp:244]     Train net output #1: loss = 0.0298361 (* 1 = 0.0298361 loss)
I0624 14:40:44.263417 18728 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0624 14:40:58.498114 18728 solver.cpp:337] Iteration 3700, Testing net (#0)
I0624 14:40:58.834102 18728 solver.cpp:404]     Test net output #0: accuracy = 0.981582
I0624 14:40:58.834137 18728 solver.cpp:404]     Test net output #1: loss = 0.0468329 (* 1 = 0.0468329 loss)
I0624 14:40:59.243199 18728 solver.cpp:228] Iteration 3700, loss = 0.0309392
I0624 14:40:59.243224 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988101
I0624 14:40:59.243232 18728 solver.cpp:244]     Train net output #1: loss = 0.0309392 (* 1 = 0.0309392 loss)
I0624 14:40:59.243237 18728 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0624 14:41:13.875063 18728 solver.cpp:228] Iteration 3720, loss = 0.0303671
I0624 14:41:13.875088 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987521
I0624 14:41:13.875097 18728 solver.cpp:244]     Train net output #1: loss = 0.0303671 (* 1 = 0.0303671 loss)
I0624 14:41:13.875102 18728 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0624 14:41:28.506929 18728 solver.cpp:228] Iteration 3740, loss = 0.0311839
I0624 14:41:28.507030 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988753
I0624 14:41:28.507038 18728 solver.cpp:244]     Train net output #1: loss = 0.0311839 (* 1 = 0.0311839 loss)
I0624 14:41:28.507043 18728 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0624 14:41:43.140282 18728 solver.cpp:228] Iteration 3760, loss = 0.0295377
I0624 14:41:43.140305 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988982
I0624 14:41:43.140312 18728 solver.cpp:244]     Train net output #1: loss = 0.0295377 (* 1 = 0.0295377 loss)
I0624 14:41:43.140317 18728 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0624 14:41:57.796167 18728 solver.cpp:228] Iteration 3780, loss = 0.0307578
I0624 14:41:57.796192 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988339
I0624 14:41:57.796200 18728 solver.cpp:244]     Train net output #1: loss = 0.0307578 (* 1 = 0.0307578 loss)
I0624 14:41:57.796205 18728 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0624 14:42:12.039404 18728 solver.cpp:337] Iteration 3800, Testing net (#0)
I0624 14:42:12.375279 18728 solver.cpp:404]     Test net output #0: accuracy = 0.983232
I0624 14:42:12.375304 18728 solver.cpp:404]     Test net output #1: loss = 0.0498639 (* 1 = 0.0498639 loss)
I0624 14:42:12.785820 18728 solver.cpp:228] Iteration 3800, loss = 0.0262013
I0624 14:42:12.785848 18728 solver.cpp:244]     Train net output #0: accuracy = 0.990301
I0624 14:42:12.785856 18728 solver.cpp:244]     Train net output #1: loss = 0.0262013 (* 1 = 0.0262013 loss)
I0624 14:42:12.785861 18728 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0624 14:42:27.432337 18728 solver.cpp:228] Iteration 3820, loss = 0.0323588
I0624 14:42:27.432374 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987526
I0624 14:42:27.432381 18728 solver.cpp:244]     Train net output #1: loss = 0.0323588 (* 1 = 0.0323588 loss)
I0624 14:42:27.432385 18728 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0624 14:42:42.142011 18728 solver.cpp:228] Iteration 3840, loss = 0.0296228
I0624 14:42:42.142112 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988794
I0624 14:42:42.142122 18728 solver.cpp:244]     Train net output #1: loss = 0.0296228 (* 1 = 0.0296228 loss)
I0624 14:42:42.142127 18728 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0624 14:42:56.773892 18728 solver.cpp:228] Iteration 3860, loss = 0.0263012
I0624 14:42:56.773919 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989802
I0624 14:42:56.773927 18728 solver.cpp:244]     Train net output #1: loss = 0.0263012 (* 1 = 0.0263012 loss)
I0624 14:42:56.773931 18728 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0624 14:43:11.433778 18728 solver.cpp:228] Iteration 3880, loss = 0.0280846
I0624 14:43:11.433804 18728 solver.cpp:244]     Train net output #0: accuracy = 0.98983
I0624 14:43:11.433812 18728 solver.cpp:244]     Train net output #1: loss = 0.0280846 (* 1 = 0.0280846 loss)
I0624 14:43:11.433816 18728 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0624 14:43:25.693490 18728 solver.cpp:337] Iteration 3900, Testing net (#0)
I0624 14:43:26.030292 18728 solver.cpp:404]     Test net output #0: accuracy = 0.980901
I0624 14:43:26.030315 18728 solver.cpp:404]     Test net output #1: loss = 0.0501452 (* 1 = 0.0501452 loss)
I0624 14:43:26.440155 18728 solver.cpp:228] Iteration 3900, loss = 0.0247121
I0624 14:43:26.440178 18728 solver.cpp:244]     Train net output #0: accuracy = 0.991136
I0624 14:43:26.440186 18728 solver.cpp:244]     Train net output #1: loss = 0.0247121 (* 1 = 0.0247121 loss)
I0624 14:43:26.440191 18728 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0624 14:43:41.088313 18728 solver.cpp:228] Iteration 3920, loss = 0.0302876
I0624 14:43:41.088340 18728 solver.cpp:244]     Train net output #0: accuracy = 0.9892
I0624 14:43:41.088346 18728 solver.cpp:244]     Train net output #1: loss = 0.0302876 (* 1 = 0.0302876 loss)
I0624 14:43:41.088351 18728 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0624 14:43:55.743484 18728 solver.cpp:228] Iteration 3940, loss = 0.0283625
I0624 14:43:55.743587 18728 solver.cpp:244]     Train net output #0: accuracy = 0.989316
I0624 14:43:55.743597 18728 solver.cpp:244]     Train net output #1: loss = 0.0283625 (* 1 = 0.0283625 loss)
I0624 14:43:55.743602 18728 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0624 14:44:10.401749 18728 solver.cpp:228] Iteration 3960, loss = 0.0316653
I0624 14:44:10.401774 18728 solver.cpp:244]     Train net output #0: accuracy = 0.987885
I0624 14:44:10.401782 18728 solver.cpp:244]     Train net output #1: loss = 0.0316653 (* 1 = 0.0316653 loss)
I0624 14:44:10.401787 18728 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0624 14:44:25.055371 18728 solver.cpp:228] Iteration 3980, loss = 0.0318505
I0624 14:44:25.055394 18728 solver.cpp:244]     Train net output #0: accuracy = 0.988198
I0624 14:44:25.055402 18728 solver.cpp:244]     Train net output #1: loss = 0.0318505 (* 1 = 0.0318505 loss)
I0624 14:44:25.055407 18728 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0624 14:44:39.320749 18728 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_4000.caffemodel
I0624 14:44:39.363015 18728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_4000.solverstate
I0624 14:44:39.708937 18728 solver.cpp:317] Iteration 4000, loss = 0.0305756
I0624 14:44:39.708963 18728 solver.cpp:337] Iteration 4000, Testing net (#0)
I0624 14:44:40.047065 18728 solver.cpp:404]     Test net output #0: accuracy = 0.976249
I0624 14:44:40.047101 18728 solver.cpp:404]     Test net output #1: loss = 0.0839578 (* 1 = 0.0839578 loss)
I0624 14:44:40.047103 18728 solver.cpp:322] Optimization Done.
I0624 14:44:40.047106 18728 caffe.cpp:222] Optimization Done.
I0625 20:16:11.014530 18777 caffe.cpp:185] Using GPUs 0
I0625 20:16:11.030467 18777 caffe.cpp:190] GPU 0: Graphics Device
I0625 20:16:11.535266 18777 solver.cpp:48] Initializing solver from parameters: 
test_iter: 64
test_interval: 100
base_lr: 0.001
display: 20
max_iter: 6000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 500
snapshot_prefix: "data/models/bpnet"
solver_mode: GPU
device_id: 0
net: "models/bpnet/train_val.prototxt"
test_initialization: true
iter_size: 1
I0625 20:16:11.535387 18777 solver.cpp:91] Creating training net from net file: models/bpnet/train_val.prototxt
I0625 20:16:11.536218 18777 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0625 20:16:11.536450 18777 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 100
    crop_h: 196
    crop_w: 256
    rotation_range: 10
    scale_jitter_range: 0.1
    contrast_jitter_range: 0.3
  }
  data_param {
    source: "data/train_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  pooling_param {
    pool: AVE
    stride: 1
    kernel_h: 6
    kernel_w: 8
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0625 20:16:11.536618 18777 layer_factory.hpp:77] Creating layer data
I0625 20:16:11.537236 18777 net.cpp:91] Creating Layer data
I0625 20:16:11.537246 18777 net.cpp:399] data -> data
I0625 20:16:11.537267 18777 net.cpp:399] data -> label
I0625 20:16:11.538609 18781 db_lmdb.cpp:35] Opened lmdb data/train_lmdb
I0625 20:16:11.563078 18777 data_layer.cpp:42] output data size: 32,3,196,256
I0625 20:16:11.602191 18777 net.cpp:141] Setting up data
I0625 20:16:11.602219 18777 net.cpp:148] Top shape: 32 3 196 256 (4816896)
I0625 20:16:11.602224 18777 net.cpp:148] Top shape: 32 (32)
I0625 20:16:11.602226 18777 net.cpp:156] Memory required for data: 19267712
I0625 20:16:11.602234 18777 layer_factory.hpp:77] Creating layer label_data_1_split
I0625 20:16:11.602252 18777 net.cpp:91] Creating Layer label_data_1_split
I0625 20:16:11.602255 18777 net.cpp:425] label_data_1_split <- label
I0625 20:16:11.602265 18777 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0625 20:16:11.602272 18777 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0625 20:16:11.602318 18777 net.cpp:141] Setting up label_data_1_split
I0625 20:16:11.602322 18777 net.cpp:148] Top shape: 32 (32)
I0625 20:16:11.602325 18777 net.cpp:148] Top shape: 32 (32)
I0625 20:16:11.602327 18777 net.cpp:156] Memory required for data: 19267968
I0625 20:16:11.602330 18777 layer_factory.hpp:77] Creating layer conv1_1
I0625 20:16:11.602344 18777 net.cpp:91] Creating Layer conv1_1
I0625 20:16:11.602358 18777 net.cpp:425] conv1_1 <- data
I0625 20:16:11.602363 18777 net.cpp:399] conv1_1 -> conv1_1
I0625 20:16:11.885005 18777 net.cpp:141] Setting up conv1_1
I0625 20:16:11.885031 18777 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:11.885035 18777 net.cpp:156] Memory required for data: 70648192
I0625 20:16:11.885047 18777 layer_factory.hpp:77] Creating layer bn1_1
I0625 20:16:11.885063 18777 net.cpp:91] Creating Layer bn1_1
I0625 20:16:11.885067 18777 net.cpp:425] bn1_1 <- conv1_1
I0625 20:16:11.885071 18777 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0625 20:16:11.885222 18777 net.cpp:141] Setting up bn1_1
I0625 20:16:11.885231 18777 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:11.885232 18777 net.cpp:156] Memory required for data: 122028416
I0625 20:16:11.885241 18777 layer_factory.hpp:77] Creating layer scale1_1
I0625 20:16:11.885251 18777 net.cpp:91] Creating Layer scale1_1
I0625 20:16:11.885252 18777 net.cpp:425] scale1_1 <- conv1_1
I0625 20:16:11.885257 18777 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0625 20:16:11.885291 18777 layer_factory.hpp:77] Creating layer scale1_1
I0625 20:16:11.885391 18777 net.cpp:141] Setting up scale1_1
I0625 20:16:11.885399 18777 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:11.885401 18777 net.cpp:156] Memory required for data: 173408640
I0625 20:16:11.885407 18777 layer_factory.hpp:77] Creating layer relu1_1
I0625 20:16:11.885412 18777 net.cpp:91] Creating Layer relu1_1
I0625 20:16:11.885416 18777 net.cpp:425] relu1_1 <- conv1_1
I0625 20:16:11.885418 18777 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0625 20:16:11.885560 18777 net.cpp:141] Setting up relu1_1
I0625 20:16:11.885570 18777 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:11.885571 18777 net.cpp:156] Memory required for data: 224788864
I0625 20:16:11.885574 18777 layer_factory.hpp:77] Creating layer conv1_2
I0625 20:16:11.885582 18777 net.cpp:91] Creating Layer conv1_2
I0625 20:16:11.885586 18777 net.cpp:425] conv1_2 <- conv1_1
I0625 20:16:11.885589 18777 net.cpp:399] conv1_2 -> conv1_2
I0625 20:16:11.886401 18777 net.cpp:141] Setting up conv1_2
I0625 20:16:11.886414 18777 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:11.886416 18777 net.cpp:156] Memory required for data: 276169088
I0625 20:16:11.886420 18777 layer_factory.hpp:77] Creating layer bn1_2
I0625 20:16:11.886426 18777 net.cpp:91] Creating Layer bn1_2
I0625 20:16:11.886430 18777 net.cpp:425] bn1_2 <- conv1_2
I0625 20:16:11.886433 18777 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0625 20:16:11.886569 18777 net.cpp:141] Setting up bn1_2
I0625 20:16:11.886576 18777 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:11.886579 18777 net.cpp:156] Memory required for data: 327549312
I0625 20:16:11.886586 18777 layer_factory.hpp:77] Creating layer scale1_2
I0625 20:16:11.886593 18777 net.cpp:91] Creating Layer scale1_2
I0625 20:16:11.886596 18777 net.cpp:425] scale1_2 <- conv1_2
I0625 20:16:11.886600 18777 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0625 20:16:11.886628 18777 layer_factory.hpp:77] Creating layer scale1_2
I0625 20:16:11.886723 18777 net.cpp:141] Setting up scale1_2
I0625 20:16:11.886730 18777 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:11.886732 18777 net.cpp:156] Memory required for data: 378929536
I0625 20:16:11.886736 18777 layer_factory.hpp:77] Creating layer relu1_2
I0625 20:16:11.886740 18777 net.cpp:91] Creating Layer relu1_2
I0625 20:16:11.886744 18777 net.cpp:425] relu1_2 <- conv1_2
I0625 20:16:11.886746 18777 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0625 20:16:11.886870 18777 net.cpp:141] Setting up relu1_2
I0625 20:16:11.886883 18777 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:11.886885 18777 net.cpp:156] Memory required for data: 430309760
I0625 20:16:11.886888 18777 layer_factory.hpp:77] Creating layer pool1
I0625 20:16:11.886893 18777 net.cpp:91] Creating Layer pool1
I0625 20:16:11.886896 18777 net.cpp:425] pool1 <- conv1_2
I0625 20:16:11.886900 18777 net.cpp:399] pool1 -> pool1
I0625 20:16:11.886943 18777 net.cpp:141] Setting up pool1
I0625 20:16:11.886965 18777 net.cpp:148] Top shape: 32 32 49 64 (3211264)
I0625 20:16:11.886966 18777 net.cpp:156] Memory required for data: 443154816
I0625 20:16:11.886970 18777 layer_factory.hpp:77] Creating layer conv2_1
I0625 20:16:11.886976 18777 net.cpp:91] Creating Layer conv2_1
I0625 20:16:11.886979 18777 net.cpp:425] conv2_1 <- pool1
I0625 20:16:11.886983 18777 net.cpp:399] conv2_1 -> conv2_1
I0625 20:16:11.888959 18777 net.cpp:141] Setting up conv2_1
I0625 20:16:11.888973 18777 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:11.888977 18777 net.cpp:156] Memory required for data: 468844928
I0625 20:16:11.888980 18777 layer_factory.hpp:77] Creating layer bn2_1
I0625 20:16:11.888988 18777 net.cpp:91] Creating Layer bn2_1
I0625 20:16:11.888990 18777 net.cpp:425] bn2_1 <- conv2_1
I0625 20:16:11.888995 18777 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0625 20:16:11.890203 18777 net.cpp:141] Setting up bn2_1
I0625 20:16:11.890213 18777 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:11.890216 18777 net.cpp:156] Memory required for data: 494535040
I0625 20:16:11.890223 18777 layer_factory.hpp:77] Creating layer scale2_1
I0625 20:16:11.890229 18777 net.cpp:91] Creating Layer scale2_1
I0625 20:16:11.890231 18777 net.cpp:425] scale2_1 <- conv2_1
I0625 20:16:11.890239 18777 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0625 20:16:11.890275 18777 layer_factory.hpp:77] Creating layer scale2_1
I0625 20:16:11.890363 18777 net.cpp:141] Setting up scale2_1
I0625 20:16:11.890369 18777 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:11.890372 18777 net.cpp:156] Memory required for data: 520225152
I0625 20:16:11.890379 18777 layer_factory.hpp:77] Creating layer relu2_1
I0625 20:16:11.890388 18777 net.cpp:91] Creating Layer relu2_1
I0625 20:16:11.890389 18777 net.cpp:425] relu2_1 <- conv2_1
I0625 20:16:11.890393 18777 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0625 20:16:11.893370 18777 net.cpp:141] Setting up relu2_1
I0625 20:16:11.893383 18777 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:11.893386 18777 net.cpp:156] Memory required for data: 545915264
I0625 20:16:11.893388 18777 layer_factory.hpp:77] Creating layer conv2_2
I0625 20:16:11.893399 18777 net.cpp:91] Creating Layer conv2_2
I0625 20:16:11.893402 18777 net.cpp:425] conv2_2 <- conv2_1
I0625 20:16:11.893406 18777 net.cpp:399] conv2_2 -> conv2_2
I0625 20:16:11.894168 18777 net.cpp:141] Setting up conv2_2
I0625 20:16:11.894179 18777 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:11.894183 18777 net.cpp:156] Memory required for data: 571605376
I0625 20:16:11.894187 18777 layer_factory.hpp:77] Creating layer bn2_2
I0625 20:16:11.894196 18777 net.cpp:91] Creating Layer bn2_2
I0625 20:16:11.894199 18777 net.cpp:425] bn2_2 <- conv2_2
I0625 20:16:11.894203 18777 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0625 20:16:11.894343 18777 net.cpp:141] Setting up bn2_2
I0625 20:16:11.894351 18777 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:11.894353 18777 net.cpp:156] Memory required for data: 597295488
I0625 20:16:11.894359 18777 layer_factory.hpp:77] Creating layer scale2_2
I0625 20:16:11.894366 18777 net.cpp:91] Creating Layer scale2_2
I0625 20:16:11.894368 18777 net.cpp:425] scale2_2 <- conv2_2
I0625 20:16:11.894372 18777 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0625 20:16:11.894407 18777 layer_factory.hpp:77] Creating layer scale2_2
I0625 20:16:11.894493 18777 net.cpp:141] Setting up scale2_2
I0625 20:16:11.894500 18777 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:11.894502 18777 net.cpp:156] Memory required for data: 622985600
I0625 20:16:11.894506 18777 layer_factory.hpp:77] Creating layer relu2_2
I0625 20:16:11.894512 18777 net.cpp:91] Creating Layer relu2_2
I0625 20:16:11.894515 18777 net.cpp:425] relu2_2 <- conv2_2
I0625 20:16:11.894517 18777 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0625 20:16:11.894922 18777 net.cpp:141] Setting up relu2_2
I0625 20:16:11.894934 18777 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:11.894937 18777 net.cpp:156] Memory required for data: 648675712
I0625 20:16:11.894950 18777 layer_factory.hpp:77] Creating layer pool2
I0625 20:16:11.894958 18777 net.cpp:91] Creating Layer pool2
I0625 20:16:11.894960 18777 net.cpp:425] pool2 <- conv2_2
I0625 20:16:11.894964 18777 net.cpp:399] pool2 -> pool2
I0625 20:16:11.895001 18777 net.cpp:141] Setting up pool2
I0625 20:16:11.895009 18777 net.cpp:148] Top shape: 32 64 25 32 (1638400)
I0625 20:16:11.895010 18777 net.cpp:156] Memory required for data: 655229312
I0625 20:16:11.895012 18777 layer_factory.hpp:77] Creating layer conv3_1
I0625 20:16:11.895020 18777 net.cpp:91] Creating Layer conv3_1
I0625 20:16:11.895023 18777 net.cpp:425] conv3_1 <- pool2
I0625 20:16:11.895027 18777 net.cpp:399] conv3_1 -> conv3_1
I0625 20:16:11.897341 18777 net.cpp:141] Setting up conv3_1
I0625 20:16:11.897353 18777 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:11.897356 18777 net.cpp:156] Memory required for data: 668336512
I0625 20:16:11.897361 18777 layer_factory.hpp:77] Creating layer bn3_1
I0625 20:16:11.897368 18777 net.cpp:91] Creating Layer bn3_1
I0625 20:16:11.897372 18777 net.cpp:425] bn3_1 <- conv3_1
I0625 20:16:11.897375 18777 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0625 20:16:11.898613 18777 net.cpp:141] Setting up bn3_1
I0625 20:16:11.898625 18777 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:11.898627 18777 net.cpp:156] Memory required for data: 681443712
I0625 20:16:11.898633 18777 layer_factory.hpp:77] Creating layer scale3_1
I0625 20:16:11.898640 18777 net.cpp:91] Creating Layer scale3_1
I0625 20:16:11.898643 18777 net.cpp:425] scale3_1 <- conv3_1
I0625 20:16:11.898649 18777 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0625 20:16:11.898687 18777 layer_factory.hpp:77] Creating layer scale3_1
I0625 20:16:11.898769 18777 net.cpp:141] Setting up scale3_1
I0625 20:16:11.898777 18777 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:11.898779 18777 net.cpp:156] Memory required for data: 694550912
I0625 20:16:11.898783 18777 layer_factory.hpp:77] Creating layer relu3_1
I0625 20:16:11.898787 18777 net.cpp:91] Creating Layer relu3_1
I0625 20:16:11.898792 18777 net.cpp:425] relu3_1 <- conv3_1
I0625 20:16:11.898795 18777 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0625 20:16:11.898928 18777 net.cpp:141] Setting up relu3_1
I0625 20:16:11.898939 18777 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:11.898943 18777 net.cpp:156] Memory required for data: 707658112
I0625 20:16:11.898947 18777 layer_factory.hpp:77] Creating layer conv3_2
I0625 20:16:11.898960 18777 net.cpp:91] Creating Layer conv3_2
I0625 20:16:11.898965 18777 net.cpp:425] conv3_2 <- conv3_1
I0625 20:16:11.898974 18777 net.cpp:399] conv3_2 -> conv3_2
I0625 20:16:11.900918 18777 net.cpp:141] Setting up conv3_2
I0625 20:16:11.900933 18777 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:11.900936 18777 net.cpp:156] Memory required for data: 720765312
I0625 20:16:11.900943 18777 layer_factory.hpp:77] Creating layer bn3_2
I0625 20:16:11.900954 18777 net.cpp:91] Creating Layer bn3_2
I0625 20:16:11.900959 18777 net.cpp:425] bn3_2 <- conv3_2
I0625 20:16:11.900969 18777 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0625 20:16:11.901129 18777 net.cpp:141] Setting up bn3_2
I0625 20:16:11.901139 18777 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:11.901142 18777 net.cpp:156] Memory required for data: 733872512
I0625 20:16:11.901161 18777 layer_factory.hpp:77] Creating layer scale3_2
I0625 20:16:11.901171 18777 net.cpp:91] Creating Layer scale3_2
I0625 20:16:11.901180 18777 net.cpp:425] scale3_2 <- conv3_2
I0625 20:16:11.901187 18777 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0625 20:16:11.901235 18777 layer_factory.hpp:77] Creating layer scale3_2
I0625 20:16:11.901334 18777 net.cpp:141] Setting up scale3_2
I0625 20:16:11.901342 18777 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:11.901346 18777 net.cpp:156] Memory required for data: 746979712
I0625 20:16:11.901353 18777 layer_factory.hpp:77] Creating layer relu3_2
I0625 20:16:11.901361 18777 net.cpp:91] Creating Layer relu3_2
I0625 20:16:11.901365 18777 net.cpp:425] relu3_2 <- conv3_2
I0625 20:16:11.901386 18777 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0625 20:16:11.901540 18777 net.cpp:141] Setting up relu3_2
I0625 20:16:11.901551 18777 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:11.901556 18777 net.cpp:156] Memory required for data: 760086912
I0625 20:16:11.901561 18777 layer_factory.hpp:77] Creating layer pool3
I0625 20:16:11.901568 18777 net.cpp:91] Creating Layer pool3
I0625 20:16:11.901573 18777 net.cpp:425] pool3 <- conv3_2
I0625 20:16:11.901582 18777 net.cpp:399] pool3 -> pool3
I0625 20:16:11.901626 18777 net.cpp:141] Setting up pool3
I0625 20:16:11.901635 18777 net.cpp:148] Top shape: 32 128 13 16 (851968)
I0625 20:16:11.901638 18777 net.cpp:156] Memory required for data: 763494784
I0625 20:16:11.901643 18777 layer_factory.hpp:77] Creating layer conv4_1
I0625 20:16:11.901656 18777 net.cpp:91] Creating Layer conv4_1
I0625 20:16:11.901660 18777 net.cpp:425] conv4_1 <- pool3
I0625 20:16:11.901669 18777 net.cpp:399] conv4_1 -> conv4_1
I0625 20:16:11.904443 18777 net.cpp:141] Setting up conv4_1
I0625 20:16:11.904458 18777 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:11.904463 18777 net.cpp:156] Memory required for data: 770310528
I0625 20:16:11.904469 18777 layer_factory.hpp:77] Creating layer bn4_1
I0625 20:16:11.904479 18777 net.cpp:91] Creating Layer bn4_1
I0625 20:16:11.904485 18777 net.cpp:425] bn4_1 <- conv4_1
I0625 20:16:11.904494 18777 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0625 20:16:11.904650 18777 net.cpp:141] Setting up bn4_1
I0625 20:16:11.904660 18777 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:11.904664 18777 net.cpp:156] Memory required for data: 777126272
I0625 20:16:11.904673 18777 layer_factory.hpp:77] Creating layer scale4_1
I0625 20:16:11.904683 18777 net.cpp:91] Creating Layer scale4_1
I0625 20:16:11.904687 18777 net.cpp:425] scale4_1 <- conv4_1
I0625 20:16:11.904698 18777 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0625 20:16:11.904743 18777 layer_factory.hpp:77] Creating layer scale4_1
I0625 20:16:11.904840 18777 net.cpp:141] Setting up scale4_1
I0625 20:16:11.904850 18777 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:11.904853 18777 net.cpp:156] Memory required for data: 783942016
I0625 20:16:11.904860 18777 layer_factory.hpp:77] Creating layer relu4_1
I0625 20:16:11.904871 18777 net.cpp:91] Creating Layer relu4_1
I0625 20:16:11.904876 18777 net.cpp:425] relu4_1 <- conv4_1
I0625 20:16:11.904884 18777 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0625 20:16:11.905035 18777 net.cpp:141] Setting up relu4_1
I0625 20:16:11.905047 18777 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:11.905051 18777 net.cpp:156] Memory required for data: 790757760
I0625 20:16:11.905056 18777 layer_factory.hpp:77] Creating layer conv4_2
I0625 20:16:11.905066 18777 net.cpp:91] Creating Layer conv4_2
I0625 20:16:11.905071 18777 net.cpp:425] conv4_2 <- conv4_1
I0625 20:16:11.905079 18777 net.cpp:399] conv4_2 -> conv4_2
I0625 20:16:11.910622 18777 net.cpp:141] Setting up conv4_2
I0625 20:16:11.910640 18777 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:11.910645 18777 net.cpp:156] Memory required for data: 797573504
I0625 20:16:11.910652 18777 layer_factory.hpp:77] Creating layer bn4_2
I0625 20:16:11.910662 18777 net.cpp:91] Creating Layer bn4_2
I0625 20:16:11.910668 18777 net.cpp:425] bn4_2 <- conv4_2
I0625 20:16:11.910677 18777 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0625 20:16:11.910837 18777 net.cpp:141] Setting up bn4_2
I0625 20:16:11.910848 18777 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:11.910852 18777 net.cpp:156] Memory required for data: 804389248
I0625 20:16:11.910861 18777 layer_factory.hpp:77] Creating layer scale4_2
I0625 20:16:11.910871 18777 net.cpp:91] Creating Layer scale4_2
I0625 20:16:11.910876 18777 net.cpp:425] scale4_2 <- conv4_2
I0625 20:16:11.910887 18777 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0625 20:16:11.910931 18777 layer_factory.hpp:77] Creating layer scale4_2
I0625 20:16:11.911027 18777 net.cpp:141] Setting up scale4_2
I0625 20:16:11.911046 18777 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:11.911051 18777 net.cpp:156] Memory required for data: 811204992
I0625 20:16:11.911058 18777 layer_factory.hpp:77] Creating layer relu4_2
I0625 20:16:11.911067 18777 net.cpp:91] Creating Layer relu4_2
I0625 20:16:11.911070 18777 net.cpp:425] relu4_2 <- conv4_2
I0625 20:16:11.911077 18777 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0625 20:16:11.911234 18777 net.cpp:141] Setting up relu4_2
I0625 20:16:11.911247 18777 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:11.911250 18777 net.cpp:156] Memory required for data: 818020736
I0625 20:16:11.911254 18777 layer_factory.hpp:77] Creating layer pool4
I0625 20:16:11.911264 18777 net.cpp:91] Creating Layer pool4
I0625 20:16:11.911269 18777 net.cpp:425] pool4 <- conv4_2
I0625 20:16:11.911276 18777 net.cpp:399] pool4 -> pool4
I0625 20:16:11.911322 18777 net.cpp:141] Setting up pool4
I0625 20:16:11.911331 18777 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:11.911335 18777 net.cpp:156] Memory required for data: 819855744
I0625 20:16:11.911339 18777 layer_factory.hpp:77] Creating layer conv5_1
I0625 20:16:11.911351 18777 net.cpp:91] Creating Layer conv5_1
I0625 20:16:11.911355 18777 net.cpp:425] conv5_1 <- pool4
I0625 20:16:11.911363 18777 net.cpp:399] conv5_1 -> conv5_1
I0625 20:16:11.916949 18777 net.cpp:141] Setting up conv5_1
I0625 20:16:11.916966 18777 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:11.916970 18777 net.cpp:156] Memory required for data: 821690752
I0625 20:16:11.916977 18777 layer_factory.hpp:77] Creating layer bn5_1
I0625 20:16:11.916990 18777 net.cpp:91] Creating Layer bn5_1
I0625 20:16:11.916995 18777 net.cpp:425] bn5_1 <- conv5_1
I0625 20:16:11.917003 18777 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0625 20:16:11.917165 18777 net.cpp:141] Setting up bn5_1
I0625 20:16:11.917176 18777 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:11.917179 18777 net.cpp:156] Memory required for data: 823525760
I0625 20:16:11.917188 18777 layer_factory.hpp:77] Creating layer scale5_1
I0625 20:16:11.917198 18777 net.cpp:91] Creating Layer scale5_1
I0625 20:16:11.917203 18777 net.cpp:425] scale5_1 <- conv5_1
I0625 20:16:11.917212 18777 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0625 20:16:11.917258 18777 layer_factory.hpp:77] Creating layer scale5_1
I0625 20:16:11.917358 18777 net.cpp:141] Setting up scale5_1
I0625 20:16:11.917367 18777 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:11.917371 18777 net.cpp:156] Memory required for data: 825360768
I0625 20:16:11.917378 18777 layer_factory.hpp:77] Creating layer relu5_1
I0625 20:16:11.917387 18777 net.cpp:91] Creating Layer relu5_1
I0625 20:16:11.917390 18777 net.cpp:425] relu5_1 <- conv5_1
I0625 20:16:11.917397 18777 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0625 20:16:11.917870 18777 net.cpp:141] Setting up relu5_1
I0625 20:16:11.917882 18777 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:11.917887 18777 net.cpp:156] Memory required for data: 827195776
I0625 20:16:11.917891 18777 layer_factory.hpp:77] Creating layer conv5_2
I0625 20:16:11.917906 18777 net.cpp:91] Creating Layer conv5_2
I0625 20:16:11.917912 18777 net.cpp:425] conv5_2 <- conv5_1
I0625 20:16:11.917920 18777 net.cpp:399] conv5_2 -> conv5_2
I0625 20:16:11.923346 18777 net.cpp:141] Setting up conv5_2
I0625 20:16:11.923364 18777 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:11.923369 18777 net.cpp:156] Memory required for data: 829030784
I0625 20:16:11.923377 18777 layer_factory.hpp:77] Creating layer bn5_2
I0625 20:16:11.923388 18777 net.cpp:91] Creating Layer bn5_2
I0625 20:16:11.923394 18777 net.cpp:425] bn5_2 <- conv5_2
I0625 20:16:11.923403 18777 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0625 20:16:11.923575 18777 net.cpp:141] Setting up bn5_2
I0625 20:16:11.923586 18777 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:11.923590 18777 net.cpp:156] Memory required for data: 830865792
I0625 20:16:11.923599 18777 layer_factory.hpp:77] Creating layer scale5_2
I0625 20:16:11.923609 18777 net.cpp:91] Creating Layer scale5_2
I0625 20:16:11.923629 18777 net.cpp:425] scale5_2 <- conv5_2
I0625 20:16:11.923640 18777 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0625 20:16:11.923686 18777 layer_factory.hpp:77] Creating layer scale5_2
I0625 20:16:11.923787 18777 net.cpp:141] Setting up scale5_2
I0625 20:16:11.923799 18777 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:11.923802 18777 net.cpp:156] Memory required for data: 832700800
I0625 20:16:11.923810 18777 layer_factory.hpp:77] Creating layer relu5_2
I0625 20:16:11.923817 18777 net.cpp:91] Creating Layer relu5_2
I0625 20:16:11.923821 18777 net.cpp:425] relu5_2 <- conv5_2
I0625 20:16:11.923827 18777 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0625 20:16:11.924247 18777 net.cpp:141] Setting up relu5_2
I0625 20:16:11.924263 18777 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:11.924268 18777 net.cpp:156] Memory required for data: 834535808
I0625 20:16:11.924271 18777 layer_factory.hpp:77] Creating layer pool5
I0625 20:16:11.924280 18777 net.cpp:91] Creating Layer pool5
I0625 20:16:11.924285 18777 net.cpp:425] pool5 <- conv5_2
I0625 20:16:11.924293 18777 net.cpp:399] pool5 -> pool5
I0625 20:16:11.924466 18777 net.cpp:141] Setting up pool5
I0625 20:16:11.924479 18777 net.cpp:148] Top shape: 32 256 2 1 (16384)
I0625 20:16:11.924482 18777 net.cpp:156] Memory required for data: 834601344
I0625 20:16:11.924486 18777 layer_factory.hpp:77] Creating layer fc2
I0625 20:16:11.924494 18777 net.cpp:91] Creating Layer fc2
I0625 20:16:11.924499 18777 net.cpp:425] fc2 <- pool5
I0625 20:16:11.924510 18777 net.cpp:399] fc2 -> fc2
I0625 20:16:11.924623 18777 net.cpp:141] Setting up fc2
I0625 20:16:11.924633 18777 net.cpp:148] Top shape: 32 2 (64)
I0625 20:16:11.924636 18777 net.cpp:156] Memory required for data: 834601600
I0625 20:16:11.924644 18777 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0625 20:16:11.924652 18777 net.cpp:91] Creating Layer fc2_fc2_0_split
I0625 20:16:11.924656 18777 net.cpp:425] fc2_fc2_0_split <- fc2
I0625 20:16:11.924664 18777 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0625 20:16:11.924672 18777 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0625 20:16:11.924711 18777 net.cpp:141] Setting up fc2_fc2_0_split
I0625 20:16:11.924721 18777 net.cpp:148] Top shape: 32 2 (64)
I0625 20:16:11.924726 18777 net.cpp:148] Top shape: 32 2 (64)
I0625 20:16:11.924731 18777 net.cpp:156] Memory required for data: 834602112
I0625 20:16:11.924734 18777 layer_factory.hpp:77] Creating layer loss
I0625 20:16:11.924741 18777 net.cpp:91] Creating Layer loss
I0625 20:16:11.924746 18777 net.cpp:425] loss <- fc2_fc2_0_split_0
I0625 20:16:11.924751 18777 net.cpp:425] loss <- label_data_1_split_0
I0625 20:16:11.924757 18777 net.cpp:399] loss -> loss
I0625 20:16:11.924768 18777 layer_factory.hpp:77] Creating layer loss
I0625 20:16:11.924998 18777 net.cpp:141] Setting up loss
I0625 20:16:11.925007 18777 net.cpp:148] Top shape: (1)
I0625 20:16:11.925010 18777 net.cpp:151]     with loss weight 1
I0625 20:16:11.925034 18777 net.cpp:156] Memory required for data: 834602116
I0625 20:16:11.925040 18777 layer_factory.hpp:77] Creating layer accuracy
I0625 20:16:11.925048 18777 net.cpp:91] Creating Layer accuracy
I0625 20:16:11.925053 18777 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0625 20:16:11.925058 18777 net.cpp:425] accuracy <- label_data_1_split_1
I0625 20:16:11.925066 18777 net.cpp:399] accuracy -> accuracy
I0625 20:16:11.925077 18777 net.cpp:141] Setting up accuracy
I0625 20:16:11.925084 18777 net.cpp:148] Top shape: (1)
I0625 20:16:11.925087 18777 net.cpp:156] Memory required for data: 834602120
I0625 20:16:11.925092 18777 net.cpp:219] accuracy does not need backward computation.
I0625 20:16:11.925096 18777 net.cpp:217] loss needs backward computation.
I0625 20:16:11.925101 18777 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0625 20:16:11.925106 18777 net.cpp:217] fc2 needs backward computation.
I0625 20:16:11.925109 18777 net.cpp:217] pool5 needs backward computation.
I0625 20:16:11.925112 18777 net.cpp:217] relu5_2 needs backward computation.
I0625 20:16:11.925117 18777 net.cpp:217] scale5_2 needs backward computation.
I0625 20:16:11.925129 18777 net.cpp:217] bn5_2 needs backward computation.
I0625 20:16:11.925133 18777 net.cpp:217] conv5_2 needs backward computation.
I0625 20:16:11.925138 18777 net.cpp:217] relu5_1 needs backward computation.
I0625 20:16:11.925143 18777 net.cpp:217] scale5_1 needs backward computation.
I0625 20:16:11.925145 18777 net.cpp:217] bn5_1 needs backward computation.
I0625 20:16:11.925149 18777 net.cpp:217] conv5_1 needs backward computation.
I0625 20:16:11.925153 18777 net.cpp:217] pool4 needs backward computation.
I0625 20:16:11.925158 18777 net.cpp:217] relu4_2 needs backward computation.
I0625 20:16:11.925161 18777 net.cpp:217] scale4_2 needs backward computation.
I0625 20:16:11.925165 18777 net.cpp:217] bn4_2 needs backward computation.
I0625 20:16:11.925169 18777 net.cpp:217] conv4_2 needs backward computation.
I0625 20:16:11.925173 18777 net.cpp:217] relu4_1 needs backward computation.
I0625 20:16:11.925178 18777 net.cpp:217] scale4_1 needs backward computation.
I0625 20:16:11.925180 18777 net.cpp:217] bn4_1 needs backward computation.
I0625 20:16:11.925184 18777 net.cpp:217] conv4_1 needs backward computation.
I0625 20:16:11.925189 18777 net.cpp:217] pool3 needs backward computation.
I0625 20:16:11.925192 18777 net.cpp:217] relu3_2 needs backward computation.
I0625 20:16:11.925196 18777 net.cpp:217] scale3_2 needs backward computation.
I0625 20:16:11.925200 18777 net.cpp:217] bn3_2 needs backward computation.
I0625 20:16:11.925204 18777 net.cpp:217] conv3_2 needs backward computation.
I0625 20:16:11.925207 18777 net.cpp:217] relu3_1 needs backward computation.
I0625 20:16:11.925211 18777 net.cpp:217] scale3_1 needs backward computation.
I0625 20:16:11.925215 18777 net.cpp:217] bn3_1 needs backward computation.
I0625 20:16:11.925220 18777 net.cpp:217] conv3_1 needs backward computation.
I0625 20:16:11.925222 18777 net.cpp:217] pool2 needs backward computation.
I0625 20:16:11.925227 18777 net.cpp:217] relu2_2 needs backward computation.
I0625 20:16:11.925230 18777 net.cpp:217] scale2_2 needs backward computation.
I0625 20:16:11.925235 18777 net.cpp:217] bn2_2 needs backward computation.
I0625 20:16:11.925238 18777 net.cpp:217] conv2_2 needs backward computation.
I0625 20:16:11.925242 18777 net.cpp:217] relu2_1 needs backward computation.
I0625 20:16:11.925246 18777 net.cpp:217] scale2_1 needs backward computation.
I0625 20:16:11.925251 18777 net.cpp:217] bn2_1 needs backward computation.
I0625 20:16:11.925253 18777 net.cpp:217] conv2_1 needs backward computation.
I0625 20:16:11.925258 18777 net.cpp:217] pool1 needs backward computation.
I0625 20:16:11.925262 18777 net.cpp:217] relu1_2 needs backward computation.
I0625 20:16:11.925266 18777 net.cpp:217] scale1_2 needs backward computation.
I0625 20:16:11.925269 18777 net.cpp:217] bn1_2 needs backward computation.
I0625 20:16:11.925273 18777 net.cpp:217] conv1_2 needs backward computation.
I0625 20:16:11.925277 18777 net.cpp:217] relu1_1 needs backward computation.
I0625 20:16:11.925282 18777 net.cpp:217] scale1_1 needs backward computation.
I0625 20:16:11.925284 18777 net.cpp:217] bn1_1 needs backward computation.
I0625 20:16:11.925288 18777 net.cpp:217] conv1_1 needs backward computation.
I0625 20:16:11.925293 18777 net.cpp:219] label_data_1_split does not need backward computation.
I0625 20:16:11.925298 18777 net.cpp:219] data does not need backward computation.
I0625 20:16:11.925302 18777 net.cpp:261] This network produces output accuracy
I0625 20:16:11.925305 18777 net.cpp:261] This network produces output loss
I0625 20:16:11.925335 18777 net.cpp:274] Network initialization done.
I0625 20:16:11.926182 18777 solver.cpp:181] Creating test net (#0) specified by net file: models/bpnet/train_val.prototxt
I0625 20:16:11.926244 18777 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0625 20:16:11.926471 18777 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 100
    crop_h: 196
    crop_w: 256
  }
  data_param {
    source: "data/val_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  pooling_param {
    pool: AVE
    stride: 1
    kernel_h: 6
    kernel_w: 8
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0625 20:16:11.926697 18777 layer_factory.hpp:77] Creating layer data
I0625 20:16:11.926806 18777 net.cpp:91] Creating Layer data
I0625 20:16:11.926816 18777 net.cpp:399] data -> data
I0625 20:16:11.926827 18777 net.cpp:399] data -> label
I0625 20:16:11.929425 18790 db_lmdb.cpp:35] Opened lmdb data/val_lmdb
I0625 20:16:11.929807 18777 data_layer.cpp:42] output data size: 64,3,196,256
I0625 20:16:12.009420 18777 net.cpp:141] Setting up data
I0625 20:16:12.009446 18777 net.cpp:148] Top shape: 64 3 196 256 (9633792)
I0625 20:16:12.009476 18777 net.cpp:148] Top shape: 64 (64)
I0625 20:16:12.009481 18777 net.cpp:156] Memory required for data: 38535424
I0625 20:16:12.009490 18777 layer_factory.hpp:77] Creating layer label_data_1_split
I0625 20:16:12.009510 18777 net.cpp:91] Creating Layer label_data_1_split
I0625 20:16:12.009517 18777 net.cpp:425] label_data_1_split <- label
I0625 20:16:12.009526 18777 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0625 20:16:12.009539 18777 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0625 20:16:12.009603 18777 net.cpp:141] Setting up label_data_1_split
I0625 20:16:12.009613 18777 net.cpp:148] Top shape: 64 (64)
I0625 20:16:12.009618 18777 net.cpp:148] Top shape: 64 (64)
I0625 20:16:12.009621 18777 net.cpp:156] Memory required for data: 38535936
I0625 20:16:12.009625 18777 layer_factory.hpp:77] Creating layer conv1_1
I0625 20:16:12.009644 18777 net.cpp:91] Creating Layer conv1_1
I0625 20:16:12.009650 18777 net.cpp:425] conv1_1 <- data
I0625 20:16:12.009659 18777 net.cpp:399] conv1_1 -> conv1_1
I0625 20:16:12.010720 18777 net.cpp:141] Setting up conv1_1
I0625 20:16:12.010740 18777 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:12.010745 18777 net.cpp:156] Memory required for data: 141296384
I0625 20:16:12.010754 18777 layer_factory.hpp:77] Creating layer bn1_1
I0625 20:16:12.010768 18777 net.cpp:91] Creating Layer bn1_1
I0625 20:16:12.010773 18777 net.cpp:425] bn1_1 <- conv1_1
I0625 20:16:12.010783 18777 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0625 20:16:12.013909 18777 net.cpp:141] Setting up bn1_1
I0625 20:16:12.013926 18777 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:12.013929 18777 net.cpp:156] Memory required for data: 244056832
I0625 20:16:12.013945 18777 layer_factory.hpp:77] Creating layer scale1_1
I0625 20:16:12.013962 18777 net.cpp:91] Creating Layer scale1_1
I0625 20:16:12.013967 18777 net.cpp:425] scale1_1 <- conv1_1
I0625 20:16:12.013989 18777 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0625 20:16:12.014040 18777 layer_factory.hpp:77] Creating layer scale1_1
I0625 20:16:12.014166 18777 net.cpp:141] Setting up scale1_1
I0625 20:16:12.014175 18777 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:12.014179 18777 net.cpp:156] Memory required for data: 346817280
I0625 20:16:12.014189 18777 layer_factory.hpp:77] Creating layer relu1_1
I0625 20:16:12.014201 18777 net.cpp:91] Creating Layer relu1_1
I0625 20:16:12.014206 18777 net.cpp:425] relu1_1 <- conv1_1
I0625 20:16:12.014214 18777 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0625 20:16:12.014371 18777 net.cpp:141] Setting up relu1_1
I0625 20:16:12.014382 18777 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:12.014387 18777 net.cpp:156] Memory required for data: 449577728
I0625 20:16:12.014391 18777 layer_factory.hpp:77] Creating layer conv1_2
I0625 20:16:12.014403 18777 net.cpp:91] Creating Layer conv1_2
I0625 20:16:12.014408 18777 net.cpp:425] conv1_2 <- conv1_1
I0625 20:16:12.014416 18777 net.cpp:399] conv1_2 -> conv1_2
I0625 20:16:12.015359 18777 net.cpp:141] Setting up conv1_2
I0625 20:16:12.015373 18777 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:12.015378 18777 net.cpp:156] Memory required for data: 552338176
I0625 20:16:12.015385 18777 layer_factory.hpp:77] Creating layer bn1_2
I0625 20:16:12.015398 18777 net.cpp:91] Creating Layer bn1_2
I0625 20:16:12.015403 18777 net.cpp:425] bn1_2 <- conv1_2
I0625 20:16:12.015410 18777 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0625 20:16:12.015586 18777 net.cpp:141] Setting up bn1_2
I0625 20:16:12.015597 18777 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:12.015600 18777 net.cpp:156] Memory required for data: 655098624
I0625 20:16:12.015614 18777 layer_factory.hpp:77] Creating layer scale1_2
I0625 20:16:12.015625 18777 net.cpp:91] Creating Layer scale1_2
I0625 20:16:12.015630 18777 net.cpp:425] scale1_2 <- conv1_2
I0625 20:16:12.015637 18777 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0625 20:16:12.015684 18777 layer_factory.hpp:77] Creating layer scale1_2
I0625 20:16:12.015812 18777 net.cpp:141] Setting up scale1_2
I0625 20:16:12.015822 18777 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:12.015826 18777 net.cpp:156] Memory required for data: 757859072
I0625 20:16:12.015833 18777 layer_factory.hpp:77] Creating layer relu1_2
I0625 20:16:12.015841 18777 net.cpp:91] Creating Layer relu1_2
I0625 20:16:12.015846 18777 net.cpp:425] relu1_2 <- conv1_2
I0625 20:16:12.015851 18777 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0625 20:16:12.016273 18777 net.cpp:141] Setting up relu1_2
I0625 20:16:12.016285 18777 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:12.016289 18777 net.cpp:156] Memory required for data: 860619520
I0625 20:16:12.016294 18777 layer_factory.hpp:77] Creating layer pool1
I0625 20:16:12.016304 18777 net.cpp:91] Creating Layer pool1
I0625 20:16:12.016309 18777 net.cpp:425] pool1 <- conv1_2
I0625 20:16:12.016316 18777 net.cpp:399] pool1 -> pool1
I0625 20:16:12.016366 18777 net.cpp:141] Setting up pool1
I0625 20:16:12.016374 18777 net.cpp:148] Top shape: 64 32 49 64 (6422528)
I0625 20:16:12.016377 18777 net.cpp:156] Memory required for data: 886309632
I0625 20:16:12.016381 18777 layer_factory.hpp:77] Creating layer conv2_1
I0625 20:16:12.016393 18777 net.cpp:91] Creating Layer conv2_1
I0625 20:16:12.016398 18777 net.cpp:425] conv2_1 <- pool1
I0625 20:16:12.016405 18777 net.cpp:399] conv2_1 -> conv2_1
I0625 20:16:12.017374 18777 net.cpp:141] Setting up conv2_1
I0625 20:16:12.017387 18777 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:12.017391 18777 net.cpp:156] Memory required for data: 937689856
I0625 20:16:12.017398 18777 layer_factory.hpp:77] Creating layer bn2_1
I0625 20:16:12.017410 18777 net.cpp:91] Creating Layer bn2_1
I0625 20:16:12.017413 18777 net.cpp:425] bn2_1 <- conv2_1
I0625 20:16:12.017421 18777 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0625 20:16:12.017596 18777 net.cpp:141] Setting up bn2_1
I0625 20:16:12.017616 18777 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:12.017619 18777 net.cpp:156] Memory required for data: 989070080
I0625 20:16:12.017628 18777 layer_factory.hpp:77] Creating layer scale2_1
I0625 20:16:12.017639 18777 net.cpp:91] Creating Layer scale2_1
I0625 20:16:12.017644 18777 net.cpp:425] scale2_1 <- conv2_1
I0625 20:16:12.017650 18777 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0625 20:16:12.017694 18777 layer_factory.hpp:77] Creating layer scale2_1
I0625 20:16:12.017805 18777 net.cpp:141] Setting up scale2_1
I0625 20:16:12.017814 18777 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:12.017818 18777 net.cpp:156] Memory required for data: 1040450304
I0625 20:16:12.017829 18777 layer_factory.hpp:77] Creating layer relu2_1
I0625 20:16:12.017838 18777 net.cpp:91] Creating Layer relu2_1
I0625 20:16:12.017843 18777 net.cpp:425] relu2_1 <- conv2_1
I0625 20:16:12.017848 18777 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0625 20:16:12.017992 18777 net.cpp:141] Setting up relu2_1
I0625 20:16:12.018002 18777 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:12.018007 18777 net.cpp:156] Memory required for data: 1091830528
I0625 20:16:12.018010 18777 layer_factory.hpp:77] Creating layer conv2_2
I0625 20:16:12.018023 18777 net.cpp:91] Creating Layer conv2_2
I0625 20:16:12.018028 18777 net.cpp:425] conv2_2 <- conv2_1
I0625 20:16:12.018035 18777 net.cpp:399] conv2_2 -> conv2_2
I0625 20:16:12.019083 18777 net.cpp:141] Setting up conv2_2
I0625 20:16:12.019095 18777 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:12.019100 18777 net.cpp:156] Memory required for data: 1143210752
I0625 20:16:12.019107 18777 layer_factory.hpp:77] Creating layer bn2_2
I0625 20:16:12.019119 18777 net.cpp:91] Creating Layer bn2_2
I0625 20:16:12.019124 18777 net.cpp:425] bn2_2 <- conv2_2
I0625 20:16:12.019132 18777 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0625 20:16:12.019300 18777 net.cpp:141] Setting up bn2_2
I0625 20:16:12.019310 18777 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:12.019315 18777 net.cpp:156] Memory required for data: 1194590976
I0625 20:16:12.019323 18777 layer_factory.hpp:77] Creating layer scale2_2
I0625 20:16:12.019335 18777 net.cpp:91] Creating Layer scale2_2
I0625 20:16:12.019338 18777 net.cpp:425] scale2_2 <- conv2_2
I0625 20:16:12.019345 18777 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0625 20:16:12.019388 18777 layer_factory.hpp:77] Creating layer scale2_2
I0625 20:16:12.019496 18777 net.cpp:141] Setting up scale2_2
I0625 20:16:12.019507 18777 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:12.019511 18777 net.cpp:156] Memory required for data: 1245971200
I0625 20:16:12.019518 18777 layer_factory.hpp:77] Creating layer relu2_2
I0625 20:16:12.019526 18777 net.cpp:91] Creating Layer relu2_2
I0625 20:16:12.019529 18777 net.cpp:425] relu2_2 <- conv2_2
I0625 20:16:12.019536 18777 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0625 20:16:12.019695 18777 net.cpp:141] Setting up relu2_2
I0625 20:16:12.019706 18777 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:12.019709 18777 net.cpp:156] Memory required for data: 1297351424
I0625 20:16:12.019714 18777 layer_factory.hpp:77] Creating layer pool2
I0625 20:16:12.019721 18777 net.cpp:91] Creating Layer pool2
I0625 20:16:12.019726 18777 net.cpp:425] pool2 <- conv2_2
I0625 20:16:12.019731 18777 net.cpp:399] pool2 -> pool2
I0625 20:16:12.019778 18777 net.cpp:141] Setting up pool2
I0625 20:16:12.019786 18777 net.cpp:148] Top shape: 64 64 25 32 (3276800)
I0625 20:16:12.019790 18777 net.cpp:156] Memory required for data: 1310458624
I0625 20:16:12.019794 18777 layer_factory.hpp:77] Creating layer conv3_1
I0625 20:16:12.019805 18777 net.cpp:91] Creating Layer conv3_1
I0625 20:16:12.019809 18777 net.cpp:425] conv3_1 <- pool2
I0625 20:16:12.019819 18777 net.cpp:399] conv3_1 -> conv3_1
I0625 20:16:12.022322 18777 net.cpp:141] Setting up conv3_1
I0625 20:16:12.022336 18777 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:12.022341 18777 net.cpp:156] Memory required for data: 1336673024
I0625 20:16:12.022359 18777 layer_factory.hpp:77] Creating layer bn3_1
I0625 20:16:12.022372 18777 net.cpp:91] Creating Layer bn3_1
I0625 20:16:12.022379 18777 net.cpp:425] bn3_1 <- conv3_1
I0625 20:16:12.022387 18777 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0625 20:16:12.022545 18777 net.cpp:141] Setting up bn3_1
I0625 20:16:12.022554 18777 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:12.022558 18777 net.cpp:156] Memory required for data: 1362887424
I0625 20:16:12.022567 18777 layer_factory.hpp:77] Creating layer scale3_1
I0625 20:16:12.022577 18777 net.cpp:91] Creating Layer scale3_1
I0625 20:16:12.022581 18777 net.cpp:425] scale3_1 <- conv3_1
I0625 20:16:12.022589 18777 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0625 20:16:12.022629 18777 layer_factory.hpp:77] Creating layer scale3_1
I0625 20:16:12.022732 18777 net.cpp:141] Setting up scale3_1
I0625 20:16:12.022742 18777 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:12.022747 18777 net.cpp:156] Memory required for data: 1389101824
I0625 20:16:12.022753 18777 layer_factory.hpp:77] Creating layer relu3_1
I0625 20:16:12.022760 18777 net.cpp:91] Creating Layer relu3_1
I0625 20:16:12.022764 18777 net.cpp:425] relu3_1 <- conv3_1
I0625 20:16:12.022770 18777 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0625 20:16:12.022917 18777 net.cpp:141] Setting up relu3_1
I0625 20:16:12.022928 18777 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:12.022933 18777 net.cpp:156] Memory required for data: 1415316224
I0625 20:16:12.022936 18777 layer_factory.hpp:77] Creating layer conv3_2
I0625 20:16:12.022948 18777 net.cpp:91] Creating Layer conv3_2
I0625 20:16:12.022953 18777 net.cpp:425] conv3_2 <- conv3_1
I0625 20:16:12.022960 18777 net.cpp:399] conv3_2 -> conv3_2
I0625 20:16:12.024843 18777 net.cpp:141] Setting up conv3_2
I0625 20:16:12.024857 18777 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:12.024862 18777 net.cpp:156] Memory required for data: 1441530624
I0625 20:16:12.024868 18777 layer_factory.hpp:77] Creating layer bn3_2
I0625 20:16:12.024878 18777 net.cpp:91] Creating Layer bn3_2
I0625 20:16:12.024883 18777 net.cpp:425] bn3_2 <- conv3_2
I0625 20:16:12.024893 18777 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0625 20:16:12.025056 18777 net.cpp:141] Setting up bn3_2
I0625 20:16:12.025065 18777 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:12.025069 18777 net.cpp:156] Memory required for data: 1467745024
I0625 20:16:12.025087 18777 layer_factory.hpp:77] Creating layer scale3_2
I0625 20:16:12.025099 18777 net.cpp:91] Creating Layer scale3_2
I0625 20:16:12.025104 18777 net.cpp:425] scale3_2 <- conv3_2
I0625 20:16:12.025110 18777 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0625 20:16:12.025156 18777 layer_factory.hpp:77] Creating layer scale3_2
I0625 20:16:12.025255 18777 net.cpp:141] Setting up scale3_2
I0625 20:16:12.025264 18777 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:12.025269 18777 net.cpp:156] Memory required for data: 1493959424
I0625 20:16:12.025275 18777 layer_factory.hpp:77] Creating layer relu3_2
I0625 20:16:12.025282 18777 net.cpp:91] Creating Layer relu3_2
I0625 20:16:12.025286 18777 net.cpp:425] relu3_2 <- conv3_2
I0625 20:16:12.025295 18777 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0625 20:16:12.025439 18777 net.cpp:141] Setting up relu3_2
I0625 20:16:12.025450 18777 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:12.025454 18777 net.cpp:156] Memory required for data: 1520173824
I0625 20:16:12.025459 18777 layer_factory.hpp:77] Creating layer pool3
I0625 20:16:12.025465 18777 net.cpp:91] Creating Layer pool3
I0625 20:16:12.025470 18777 net.cpp:425] pool3 <- conv3_2
I0625 20:16:12.025478 18777 net.cpp:399] pool3 -> pool3
I0625 20:16:12.025524 18777 net.cpp:141] Setting up pool3
I0625 20:16:12.025533 18777 net.cpp:148] Top shape: 64 128 13 16 (1703936)
I0625 20:16:12.025537 18777 net.cpp:156] Memory required for data: 1526989568
I0625 20:16:12.025540 18777 layer_factory.hpp:77] Creating layer conv4_1
I0625 20:16:12.025552 18777 net.cpp:91] Creating Layer conv4_1
I0625 20:16:12.025568 18777 net.cpp:425] conv4_1 <- pool3
I0625 20:16:12.025576 18777 net.cpp:399] conv4_1 -> conv4_1
I0625 20:16:12.028240 18777 net.cpp:141] Setting up conv4_1
I0625 20:16:12.028254 18777 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:12.028259 18777 net.cpp:156] Memory required for data: 1540621056
I0625 20:16:12.028265 18777 layer_factory.hpp:77] Creating layer bn4_1
I0625 20:16:12.028275 18777 net.cpp:91] Creating Layer bn4_1
I0625 20:16:12.028280 18777 net.cpp:425] bn4_1 <- conv4_1
I0625 20:16:12.028288 18777 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0625 20:16:12.028456 18777 net.cpp:141] Setting up bn4_1
I0625 20:16:12.028466 18777 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:12.028470 18777 net.cpp:156] Memory required for data: 1554252544
I0625 20:16:12.028478 18777 layer_factory.hpp:77] Creating layer scale4_1
I0625 20:16:12.028487 18777 net.cpp:91] Creating Layer scale4_1
I0625 20:16:12.028492 18777 net.cpp:425] scale4_1 <- conv4_1
I0625 20:16:12.028501 18777 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0625 20:16:12.028542 18777 layer_factory.hpp:77] Creating layer scale4_1
I0625 20:16:12.028643 18777 net.cpp:141] Setting up scale4_1
I0625 20:16:12.028653 18777 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:12.028657 18777 net.cpp:156] Memory required for data: 1567884032
I0625 20:16:12.028666 18777 layer_factory.hpp:77] Creating layer relu4_1
I0625 20:16:12.028676 18777 net.cpp:91] Creating Layer relu4_1
I0625 20:16:12.028681 18777 net.cpp:425] relu4_1 <- conv4_1
I0625 20:16:12.028687 18777 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0625 20:16:12.028831 18777 net.cpp:141] Setting up relu4_1
I0625 20:16:12.028841 18777 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:12.028846 18777 net.cpp:156] Memory required for data: 1581515520
I0625 20:16:12.028849 18777 layer_factory.hpp:77] Creating layer conv4_2
I0625 20:16:12.028861 18777 net.cpp:91] Creating Layer conv4_2
I0625 20:16:12.028866 18777 net.cpp:425] conv4_2 <- conv4_1
I0625 20:16:12.028873 18777 net.cpp:399] conv4_2 -> conv4_2
I0625 20:16:12.034221 18777 net.cpp:141] Setting up conv4_2
I0625 20:16:12.034236 18777 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:12.034240 18777 net.cpp:156] Memory required for data: 1595147008
I0625 20:16:12.034247 18777 layer_factory.hpp:77] Creating layer bn4_2
I0625 20:16:12.034255 18777 net.cpp:91] Creating Layer bn4_2
I0625 20:16:12.034260 18777 net.cpp:425] bn4_2 <- conv4_2
I0625 20:16:12.034268 18777 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0625 20:16:12.034438 18777 net.cpp:141] Setting up bn4_2
I0625 20:16:12.034447 18777 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:12.034451 18777 net.cpp:156] Memory required for data: 1608778496
I0625 20:16:12.034461 18777 layer_factory.hpp:77] Creating layer scale4_2
I0625 20:16:12.034469 18777 net.cpp:91] Creating Layer scale4_2
I0625 20:16:12.034473 18777 net.cpp:425] scale4_2 <- conv4_2
I0625 20:16:12.034479 18777 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0625 20:16:12.034525 18777 layer_factory.hpp:77] Creating layer scale4_2
I0625 20:16:12.034627 18777 net.cpp:141] Setting up scale4_2
I0625 20:16:12.034638 18777 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:12.034642 18777 net.cpp:156] Memory required for data: 1622409984
I0625 20:16:12.034649 18777 layer_factory.hpp:77] Creating layer relu4_2
I0625 20:16:12.034657 18777 net.cpp:91] Creating Layer relu4_2
I0625 20:16:12.034660 18777 net.cpp:425] relu4_2 <- conv4_2
I0625 20:16:12.034667 18777 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0625 20:16:12.035086 18777 net.cpp:141] Setting up relu4_2
I0625 20:16:12.035099 18777 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:12.035104 18777 net.cpp:156] Memory required for data: 1636041472
I0625 20:16:12.035107 18777 layer_factory.hpp:77] Creating layer pool4
I0625 20:16:12.035115 18777 net.cpp:91] Creating Layer pool4
I0625 20:16:12.035120 18777 net.cpp:425] pool4 <- conv4_2
I0625 20:16:12.035127 18777 net.cpp:399] pool4 -> pool4
I0625 20:16:12.035182 18777 net.cpp:141] Setting up pool4
I0625 20:16:12.035202 18777 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:12.035205 18777 net.cpp:156] Memory required for data: 1639711488
I0625 20:16:12.035209 18777 layer_factory.hpp:77] Creating layer conv5_1
I0625 20:16:12.035221 18777 net.cpp:91] Creating Layer conv5_1
I0625 20:16:12.035226 18777 net.cpp:425] conv5_1 <- pool4
I0625 20:16:12.035235 18777 net.cpp:399] conv5_1 -> conv5_1
I0625 20:16:12.040622 18777 net.cpp:141] Setting up conv5_1
I0625 20:16:12.040638 18777 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:12.040642 18777 net.cpp:156] Memory required for data: 1643381504
I0625 20:16:12.040650 18777 layer_factory.hpp:77] Creating layer bn5_1
I0625 20:16:12.040663 18777 net.cpp:91] Creating Layer bn5_1
I0625 20:16:12.040668 18777 net.cpp:425] bn5_1 <- conv5_1
I0625 20:16:12.040674 18777 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0625 20:16:12.040849 18777 net.cpp:141] Setting up bn5_1
I0625 20:16:12.040859 18777 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:12.040863 18777 net.cpp:156] Memory required for data: 1647051520
I0625 20:16:12.040871 18777 layer_factory.hpp:77] Creating layer scale5_1
I0625 20:16:12.040882 18777 net.cpp:91] Creating Layer scale5_1
I0625 20:16:12.040886 18777 net.cpp:425] scale5_1 <- conv5_1
I0625 20:16:12.040894 18777 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0625 20:16:12.040940 18777 layer_factory.hpp:77] Creating layer scale5_1
I0625 20:16:12.041043 18777 net.cpp:141] Setting up scale5_1
I0625 20:16:12.041052 18777 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:12.041056 18777 net.cpp:156] Memory required for data: 1650721536
I0625 20:16:12.041064 18777 layer_factory.hpp:77] Creating layer relu5_1
I0625 20:16:12.041072 18777 net.cpp:91] Creating Layer relu5_1
I0625 20:16:12.041076 18777 net.cpp:425] relu5_1 <- conv5_1
I0625 20:16:12.041082 18777 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0625 20:16:12.041232 18777 net.cpp:141] Setting up relu5_1
I0625 20:16:12.041244 18777 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:12.041247 18777 net.cpp:156] Memory required for data: 1654391552
I0625 20:16:12.041251 18777 layer_factory.hpp:77] Creating layer conv5_2
I0625 20:16:12.041263 18777 net.cpp:91] Creating Layer conv5_2
I0625 20:16:12.041268 18777 net.cpp:425] conv5_2 <- conv5_1
I0625 20:16:12.041275 18777 net.cpp:399] conv5_2 -> conv5_2
I0625 20:16:12.046778 18777 net.cpp:141] Setting up conv5_2
I0625 20:16:12.046797 18777 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:12.046800 18777 net.cpp:156] Memory required for data: 1658061568
I0625 20:16:12.046808 18777 layer_factory.hpp:77] Creating layer bn5_2
I0625 20:16:12.046821 18777 net.cpp:91] Creating Layer bn5_2
I0625 20:16:12.046826 18777 net.cpp:425] bn5_2 <- conv5_2
I0625 20:16:12.046838 18777 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0625 20:16:12.047020 18777 net.cpp:141] Setting up bn5_2
I0625 20:16:12.047029 18777 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:12.047034 18777 net.cpp:156] Memory required for data: 1661731584
I0625 20:16:12.047042 18777 layer_factory.hpp:77] Creating layer scale5_2
I0625 20:16:12.047055 18777 net.cpp:91] Creating Layer scale5_2
I0625 20:16:12.047060 18777 net.cpp:425] scale5_2 <- conv5_2
I0625 20:16:12.047065 18777 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0625 20:16:12.047114 18777 layer_factory.hpp:77] Creating layer scale5_2
I0625 20:16:12.047224 18777 net.cpp:141] Setting up scale5_2
I0625 20:16:12.047235 18777 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:12.047237 18777 net.cpp:156] Memory required for data: 1665401600
I0625 20:16:12.047245 18777 layer_factory.hpp:77] Creating layer relu5_2
I0625 20:16:12.047252 18777 net.cpp:91] Creating Layer relu5_2
I0625 20:16:12.047257 18777 net.cpp:425] relu5_2 <- conv5_2
I0625 20:16:12.047265 18777 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0625 20:16:12.047415 18777 net.cpp:141] Setting up relu5_2
I0625 20:16:12.047425 18777 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:12.047428 18777 net.cpp:156] Memory required for data: 1669071616
I0625 20:16:12.047444 18777 layer_factory.hpp:77] Creating layer pool5
I0625 20:16:12.047456 18777 net.cpp:91] Creating Layer pool5
I0625 20:16:12.047462 18777 net.cpp:425] pool5 <- conv5_2
I0625 20:16:12.047469 18777 net.cpp:399] pool5 -> pool5
I0625 20:16:12.047636 18777 net.cpp:141] Setting up pool5
I0625 20:16:12.047646 18777 net.cpp:148] Top shape: 64 256 2 1 (32768)
I0625 20:16:12.047649 18777 net.cpp:156] Memory required for data: 1669202688
I0625 20:16:12.047653 18777 layer_factory.hpp:77] Creating layer fc2
I0625 20:16:12.047662 18777 net.cpp:91] Creating Layer fc2
I0625 20:16:12.047665 18777 net.cpp:425] fc2 <- pool5
I0625 20:16:12.047673 18777 net.cpp:399] fc2 -> fc2
I0625 20:16:12.047791 18777 net.cpp:141] Setting up fc2
I0625 20:16:12.047799 18777 net.cpp:148] Top shape: 64 2 (128)
I0625 20:16:12.047802 18777 net.cpp:156] Memory required for data: 1669203200
I0625 20:16:12.047811 18777 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0625 20:16:12.047817 18777 net.cpp:91] Creating Layer fc2_fc2_0_split
I0625 20:16:12.047822 18777 net.cpp:425] fc2_fc2_0_split <- fc2
I0625 20:16:12.047829 18777 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0625 20:16:12.047837 18777 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0625 20:16:12.047876 18777 net.cpp:141] Setting up fc2_fc2_0_split
I0625 20:16:12.047884 18777 net.cpp:148] Top shape: 64 2 (128)
I0625 20:16:12.047889 18777 net.cpp:148] Top shape: 64 2 (128)
I0625 20:16:12.047893 18777 net.cpp:156] Memory required for data: 1669204224
I0625 20:16:12.047896 18777 layer_factory.hpp:77] Creating layer loss
I0625 20:16:12.047904 18777 net.cpp:91] Creating Layer loss
I0625 20:16:12.047909 18777 net.cpp:425] loss <- fc2_fc2_0_split_0
I0625 20:16:12.047914 18777 net.cpp:425] loss <- label_data_1_split_0
I0625 20:16:12.047920 18777 net.cpp:399] loss -> loss
I0625 20:16:12.047930 18777 layer_factory.hpp:77] Creating layer loss
I0625 20:16:12.048418 18777 net.cpp:141] Setting up loss
I0625 20:16:12.048430 18777 net.cpp:148] Top shape: (1)
I0625 20:16:12.048435 18777 net.cpp:151]     with loss weight 1
I0625 20:16:12.048446 18777 net.cpp:156] Memory required for data: 1669204228
I0625 20:16:12.048451 18777 layer_factory.hpp:77] Creating layer accuracy
I0625 20:16:12.048458 18777 net.cpp:91] Creating Layer accuracy
I0625 20:16:12.048463 18777 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0625 20:16:12.048468 18777 net.cpp:425] accuracy <- label_data_1_split_1
I0625 20:16:12.048475 18777 net.cpp:399] accuracy -> accuracy
I0625 20:16:12.048485 18777 net.cpp:141] Setting up accuracy
I0625 20:16:12.048491 18777 net.cpp:148] Top shape: (1)
I0625 20:16:12.048494 18777 net.cpp:156] Memory required for data: 1669204232
I0625 20:16:12.048498 18777 net.cpp:219] accuracy does not need backward computation.
I0625 20:16:12.048503 18777 net.cpp:217] loss needs backward computation.
I0625 20:16:12.048507 18777 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0625 20:16:12.048511 18777 net.cpp:217] fc2 needs backward computation.
I0625 20:16:12.048516 18777 net.cpp:217] pool5 needs backward computation.
I0625 20:16:12.048518 18777 net.cpp:217] relu5_2 needs backward computation.
I0625 20:16:12.048528 18777 net.cpp:217] scale5_2 needs backward computation.
I0625 20:16:12.048532 18777 net.cpp:217] bn5_2 needs backward computation.
I0625 20:16:12.048534 18777 net.cpp:217] conv5_2 needs backward computation.
I0625 20:16:12.048538 18777 net.cpp:217] relu5_1 needs backward computation.
I0625 20:16:12.048542 18777 net.cpp:217] scale5_1 needs backward computation.
I0625 20:16:12.048545 18777 net.cpp:217] bn5_1 needs backward computation.
I0625 20:16:12.048549 18777 net.cpp:217] conv5_1 needs backward computation.
I0625 20:16:12.048553 18777 net.cpp:217] pool4 needs backward computation.
I0625 20:16:12.048557 18777 net.cpp:217] relu4_2 needs backward computation.
I0625 20:16:12.048562 18777 net.cpp:217] scale4_2 needs backward computation.
I0625 20:16:12.048565 18777 net.cpp:217] bn4_2 needs backward computation.
I0625 20:16:12.048568 18777 net.cpp:217] conv4_2 needs backward computation.
I0625 20:16:12.048581 18777 net.cpp:217] relu4_1 needs backward computation.
I0625 20:16:12.048585 18777 net.cpp:217] scale4_1 needs backward computation.
I0625 20:16:12.048588 18777 net.cpp:217] bn4_1 needs backward computation.
I0625 20:16:12.048593 18777 net.cpp:217] conv4_1 needs backward computation.
I0625 20:16:12.048596 18777 net.cpp:217] pool3 needs backward computation.
I0625 20:16:12.048600 18777 net.cpp:217] relu3_2 needs backward computation.
I0625 20:16:12.048604 18777 net.cpp:217] scale3_2 needs backward computation.
I0625 20:16:12.048607 18777 net.cpp:217] bn3_2 needs backward computation.
I0625 20:16:12.048611 18777 net.cpp:217] conv3_2 needs backward computation.
I0625 20:16:12.048617 18777 net.cpp:217] relu3_1 needs backward computation.
I0625 20:16:12.048621 18777 net.cpp:217] scale3_1 needs backward computation.
I0625 20:16:12.048624 18777 net.cpp:217] bn3_1 needs backward computation.
I0625 20:16:12.048629 18777 net.cpp:217] conv3_1 needs backward computation.
I0625 20:16:12.048632 18777 net.cpp:217] pool2 needs backward computation.
I0625 20:16:12.048636 18777 net.cpp:217] relu2_2 needs backward computation.
I0625 20:16:12.048640 18777 net.cpp:217] scale2_2 needs backward computation.
I0625 20:16:12.048643 18777 net.cpp:217] bn2_2 needs backward computation.
I0625 20:16:12.048647 18777 net.cpp:217] conv2_2 needs backward computation.
I0625 20:16:12.048650 18777 net.cpp:217] relu2_1 needs backward computation.
I0625 20:16:12.048655 18777 net.cpp:217] scale2_1 needs backward computation.
I0625 20:16:12.048658 18777 net.cpp:217] bn2_1 needs backward computation.
I0625 20:16:12.048662 18777 net.cpp:217] conv2_1 needs backward computation.
I0625 20:16:12.048666 18777 net.cpp:217] pool1 needs backward computation.
I0625 20:16:12.048669 18777 net.cpp:217] relu1_2 needs backward computation.
I0625 20:16:12.048673 18777 net.cpp:217] scale1_2 needs backward computation.
I0625 20:16:12.048677 18777 net.cpp:217] bn1_2 needs backward computation.
I0625 20:16:12.048681 18777 net.cpp:217] conv1_2 needs backward computation.
I0625 20:16:12.048684 18777 net.cpp:217] relu1_1 needs backward computation.
I0625 20:16:12.048688 18777 net.cpp:217] scale1_1 needs backward computation.
I0625 20:16:12.048691 18777 net.cpp:217] bn1_1 needs backward computation.
I0625 20:16:12.048696 18777 net.cpp:217] conv1_1 needs backward computation.
I0625 20:16:12.048699 18777 net.cpp:219] label_data_1_split does not need backward computation.
I0625 20:16:12.048704 18777 net.cpp:219] data does not need backward computation.
I0625 20:16:12.048707 18777 net.cpp:261] This network produces output accuracy
I0625 20:16:12.048712 18777 net.cpp:261] This network produces output loss
I0625 20:16:12.048739 18777 net.cpp:274] Network initialization done.
I0625 20:16:12.048874 18777 solver.cpp:60] Solver scaffolding done.
I0625 20:16:12.050561 18777 caffe.cpp:209] Resuming from data/models/segnet_iter_2000.solverstate
F0625 20:16:12.096027 18777 net.cpp:765] Cannot copy param 0 weights from layer 'conv1_1'; shape mismatch.  Source param shape is 32 1 3 3 (288); target param shape is 32 3 7 7 (4704). To learn this layer's parameters from scratch rather than copying from a saved net, rename the layer.
*** Check failure stack trace: ***
    @     0x7f598a71bdaa  (unknown)
    @     0x7f598a71bce4  (unknown)
    @     0x7f598a71b6e6  (unknown)
    @     0x7f598a71e687  (unknown)
    @     0x7f598ad604e7  caffe::Net<>::CopyTrainedLayersFrom()
    @     0x7f598ad54ace  caffe::SGDSolver<>::RestoreSolverStateFromBinaryProto()
    @     0x7f598ad9c2f3  caffe::Solver<>::Restore()
    @           0x407f88  train()
    @           0x4059bc  main
    @     0x7f5989a29f45  (unknown)
    @           0x4060f1  (unknown)
    @              (nil)  (unknown)
I0625 20:16:27.847614 18802 caffe.cpp:185] Using GPUs 0
I0625 20:16:27.864529 18802 caffe.cpp:190] GPU 0: Graphics Device
I0625 20:16:28.359876 18802 solver.cpp:48] Initializing solver from parameters: 
test_iter: 64
test_interval: 100
base_lr: 0.001
display: 20
max_iter: 6000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 500
snapshot_prefix: "data/models/bpnet"
solver_mode: GPU
device_id: 0
net: "models/bpnet/train_val.prototxt"
test_initialization: true
iter_size: 1
I0625 20:16:28.359997 18802 solver.cpp:91] Creating training net from net file: models/bpnet/train_val.prototxt
I0625 20:16:28.360836 18802 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0625 20:16:28.361068 18802 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 100
    crop_h: 196
    crop_w: 256
    rotation_range: 10
    scale_jitter_range: 0.1
    contrast_jitter_range: 0.3
  }
  data_param {
    source: "data/train_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  pooling_param {
    pool: AVE
    stride: 1
    kernel_h: 6
    kernel_w: 8
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0625 20:16:28.361238 18802 layer_factory.hpp:77] Creating layer data
I0625 20:16:28.361646 18802 net.cpp:91] Creating Layer data
I0625 20:16:28.361659 18802 net.cpp:399] data -> data
I0625 20:16:28.361681 18802 net.cpp:399] data -> label
I0625 20:16:28.362915 18806 db_lmdb.cpp:35] Opened lmdb data/train_lmdb
I0625 20:16:28.388108 18802 data_layer.cpp:42] output data size: 32,3,196,256
I0625 20:16:28.428061 18802 net.cpp:141] Setting up data
I0625 20:16:28.428091 18802 net.cpp:148] Top shape: 32 3 196 256 (4816896)
I0625 20:16:28.428094 18802 net.cpp:148] Top shape: 32 (32)
I0625 20:16:28.428097 18802 net.cpp:156] Memory required for data: 19267712
I0625 20:16:28.428105 18802 layer_factory.hpp:77] Creating layer label_data_1_split
I0625 20:16:28.428122 18802 net.cpp:91] Creating Layer label_data_1_split
I0625 20:16:28.428127 18802 net.cpp:425] label_data_1_split <- label
I0625 20:16:28.428136 18802 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0625 20:16:28.428145 18802 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0625 20:16:28.428189 18802 net.cpp:141] Setting up label_data_1_split
I0625 20:16:28.428195 18802 net.cpp:148] Top shape: 32 (32)
I0625 20:16:28.428199 18802 net.cpp:148] Top shape: 32 (32)
I0625 20:16:28.428200 18802 net.cpp:156] Memory required for data: 19267968
I0625 20:16:28.428203 18802 layer_factory.hpp:77] Creating layer conv1_1
I0625 20:16:28.428218 18802 net.cpp:91] Creating Layer conv1_1
I0625 20:16:28.428236 18802 net.cpp:425] conv1_1 <- data
I0625 20:16:28.428244 18802 net.cpp:399] conv1_1 -> conv1_1
I0625 20:16:28.819360 18802 net.cpp:141] Setting up conv1_1
I0625 20:16:28.819388 18802 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:28.819393 18802 net.cpp:156] Memory required for data: 70648192
I0625 20:16:28.819407 18802 layer_factory.hpp:77] Creating layer bn1_1
I0625 20:16:28.819425 18802 net.cpp:91] Creating Layer bn1_1
I0625 20:16:28.819433 18802 net.cpp:425] bn1_1 <- conv1_1
I0625 20:16:28.819439 18802 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0625 20:16:28.819636 18802 net.cpp:141] Setting up bn1_1
I0625 20:16:28.819659 18802 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:28.819663 18802 net.cpp:156] Memory required for data: 122028416
I0625 20:16:28.819674 18802 layer_factory.hpp:77] Creating layer scale1_1
I0625 20:16:28.819684 18802 net.cpp:91] Creating Layer scale1_1
I0625 20:16:28.819689 18802 net.cpp:425] scale1_1 <- conv1_1
I0625 20:16:28.819694 18802 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0625 20:16:28.819736 18802 layer_factory.hpp:77] Creating layer scale1_1
I0625 20:16:28.819860 18802 net.cpp:141] Setting up scale1_1
I0625 20:16:28.819869 18802 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:28.819872 18802 net.cpp:156] Memory required for data: 173408640
I0625 20:16:28.819880 18802 layer_factory.hpp:77] Creating layer relu1_1
I0625 20:16:28.819886 18802 net.cpp:91] Creating Layer relu1_1
I0625 20:16:28.819890 18802 net.cpp:425] relu1_1 <- conv1_1
I0625 20:16:28.819895 18802 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0625 20:16:28.820063 18802 net.cpp:141] Setting up relu1_1
I0625 20:16:28.820075 18802 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:28.820077 18802 net.cpp:156] Memory required for data: 224788864
I0625 20:16:28.820080 18802 layer_factory.hpp:77] Creating layer conv1_2
I0625 20:16:28.820091 18802 net.cpp:91] Creating Layer conv1_2
I0625 20:16:28.820096 18802 net.cpp:425] conv1_2 <- conv1_1
I0625 20:16:28.820102 18802 net.cpp:399] conv1_2 -> conv1_2
I0625 20:16:28.821120 18802 net.cpp:141] Setting up conv1_2
I0625 20:16:28.821135 18802 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:28.821140 18802 net.cpp:156] Memory required for data: 276169088
I0625 20:16:28.821144 18802 layer_factory.hpp:77] Creating layer bn1_2
I0625 20:16:28.821151 18802 net.cpp:91] Creating Layer bn1_2
I0625 20:16:28.821156 18802 net.cpp:425] bn1_2 <- conv1_2
I0625 20:16:28.821161 18802 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0625 20:16:28.821331 18802 net.cpp:141] Setting up bn1_2
I0625 20:16:28.821339 18802 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:28.821342 18802 net.cpp:156] Memory required for data: 327549312
I0625 20:16:28.821352 18802 layer_factory.hpp:77] Creating layer scale1_2
I0625 20:16:28.821360 18802 net.cpp:91] Creating Layer scale1_2
I0625 20:16:28.821363 18802 net.cpp:425] scale1_2 <- conv1_2
I0625 20:16:28.821367 18802 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0625 20:16:28.821403 18802 layer_factory.hpp:77] Creating layer scale1_2
I0625 20:16:28.821517 18802 net.cpp:141] Setting up scale1_2
I0625 20:16:28.821527 18802 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:28.821529 18802 net.cpp:156] Memory required for data: 378929536
I0625 20:16:28.821534 18802 layer_factory.hpp:77] Creating layer relu1_2
I0625 20:16:28.821539 18802 net.cpp:91] Creating Layer relu1_2
I0625 20:16:28.821542 18802 net.cpp:425] relu1_2 <- conv1_2
I0625 20:16:28.821547 18802 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0625 20:16:28.821702 18802 net.cpp:141] Setting up relu1_2
I0625 20:16:28.821712 18802 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:28.821715 18802 net.cpp:156] Memory required for data: 430309760
I0625 20:16:28.821718 18802 layer_factory.hpp:77] Creating layer pool1
I0625 20:16:28.821725 18802 net.cpp:91] Creating Layer pool1
I0625 20:16:28.821728 18802 net.cpp:425] pool1 <- conv1_2
I0625 20:16:28.821733 18802 net.cpp:399] pool1 -> pool1
I0625 20:16:28.821787 18802 net.cpp:141] Setting up pool1
I0625 20:16:28.821811 18802 net.cpp:148] Top shape: 32 32 49 64 (3211264)
I0625 20:16:28.821815 18802 net.cpp:156] Memory required for data: 443154816
I0625 20:16:28.821818 18802 layer_factory.hpp:77] Creating layer conv2_1
I0625 20:16:28.821827 18802 net.cpp:91] Creating Layer conv2_1
I0625 20:16:28.821833 18802 net.cpp:425] conv2_1 <- pool1
I0625 20:16:28.821838 18802 net.cpp:399] conv2_1 -> conv2_1
I0625 20:16:28.824261 18802 net.cpp:141] Setting up conv2_1
I0625 20:16:28.824277 18802 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:28.824280 18802 net.cpp:156] Memory required for data: 468844928
I0625 20:16:28.824286 18802 layer_factory.hpp:77] Creating layer bn2_1
I0625 20:16:28.824293 18802 net.cpp:91] Creating Layer bn2_1
I0625 20:16:28.824297 18802 net.cpp:425] bn2_1 <- conv2_1
I0625 20:16:28.824302 18802 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0625 20:16:28.825808 18802 net.cpp:141] Setting up bn2_1
I0625 20:16:28.825821 18802 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:28.825825 18802 net.cpp:156] Memory required for data: 494535040
I0625 20:16:28.825834 18802 layer_factory.hpp:77] Creating layer scale2_1
I0625 20:16:28.825841 18802 net.cpp:91] Creating Layer scale2_1
I0625 20:16:28.825845 18802 net.cpp:425] scale2_1 <- conv2_1
I0625 20:16:28.825851 18802 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0625 20:16:28.825892 18802 layer_factory.hpp:77] Creating layer scale2_1
I0625 20:16:28.825999 18802 net.cpp:141] Setting up scale2_1
I0625 20:16:28.826006 18802 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:28.826009 18802 net.cpp:156] Memory required for data: 520225152
I0625 20:16:28.826020 18802 layer_factory.hpp:77] Creating layer relu2_1
I0625 20:16:28.826025 18802 net.cpp:91] Creating Layer relu2_1
I0625 20:16:28.826030 18802 net.cpp:425] relu2_1 <- conv2_1
I0625 20:16:28.826033 18802 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0625 20:16:28.826521 18802 net.cpp:141] Setting up relu2_1
I0625 20:16:28.826536 18802 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:28.826539 18802 net.cpp:156] Memory required for data: 545915264
I0625 20:16:28.826544 18802 layer_factory.hpp:77] Creating layer conv2_2
I0625 20:16:28.826553 18802 net.cpp:91] Creating Layer conv2_2
I0625 20:16:28.826557 18802 net.cpp:425] conv2_2 <- conv2_1
I0625 20:16:28.826563 18802 net.cpp:399] conv2_2 -> conv2_2
I0625 20:16:28.827510 18802 net.cpp:141] Setting up conv2_2
I0625 20:16:28.827524 18802 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:28.827528 18802 net.cpp:156] Memory required for data: 571605376
I0625 20:16:28.827533 18802 layer_factory.hpp:77] Creating layer bn2_2
I0625 20:16:28.827543 18802 net.cpp:91] Creating Layer bn2_2
I0625 20:16:28.827546 18802 net.cpp:425] bn2_2 <- conv2_2
I0625 20:16:28.827553 18802 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0625 20:16:28.827736 18802 net.cpp:141] Setting up bn2_2
I0625 20:16:28.827745 18802 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:28.827749 18802 net.cpp:156] Memory required for data: 597295488
I0625 20:16:28.827755 18802 layer_factory.hpp:77] Creating layer scale2_2
I0625 20:16:28.827762 18802 net.cpp:91] Creating Layer scale2_2
I0625 20:16:28.827765 18802 net.cpp:425] scale2_2 <- conv2_2
I0625 20:16:28.827771 18802 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0625 20:16:28.827808 18802 layer_factory.hpp:77] Creating layer scale2_2
I0625 20:16:28.827929 18802 net.cpp:141] Setting up scale2_2
I0625 20:16:28.827937 18802 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:28.827940 18802 net.cpp:156] Memory required for data: 622985600
I0625 20:16:28.827945 18802 layer_factory.hpp:77] Creating layer relu2_2
I0625 20:16:28.827951 18802 net.cpp:91] Creating Layer relu2_2
I0625 20:16:28.827955 18802 net.cpp:425] relu2_2 <- conv2_2
I0625 20:16:28.827960 18802 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0625 20:16:28.828450 18802 net.cpp:141] Setting up relu2_2
I0625 20:16:28.828465 18802 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:28.828469 18802 net.cpp:156] Memory required for data: 648675712
I0625 20:16:28.828485 18802 layer_factory.hpp:77] Creating layer pool2
I0625 20:16:28.828493 18802 net.cpp:91] Creating Layer pool2
I0625 20:16:28.828497 18802 net.cpp:425] pool2 <- conv2_2
I0625 20:16:28.828502 18802 net.cpp:399] pool2 -> pool2
I0625 20:16:28.828549 18802 net.cpp:141] Setting up pool2
I0625 20:16:28.828558 18802 net.cpp:148] Top shape: 32 64 25 32 (1638400)
I0625 20:16:28.828560 18802 net.cpp:156] Memory required for data: 655229312
I0625 20:16:28.828563 18802 layer_factory.hpp:77] Creating layer conv3_1
I0625 20:16:28.828573 18802 net.cpp:91] Creating Layer conv3_1
I0625 20:16:28.828577 18802 net.cpp:425] conv3_1 <- pool2
I0625 20:16:28.828583 18802 net.cpp:399] conv3_1 -> conv3_1
I0625 20:16:28.831456 18802 net.cpp:141] Setting up conv3_1
I0625 20:16:28.831473 18802 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:28.831477 18802 net.cpp:156] Memory required for data: 668336512
I0625 20:16:28.831482 18802 layer_factory.hpp:77] Creating layer bn3_1
I0625 20:16:28.831491 18802 net.cpp:91] Creating Layer bn3_1
I0625 20:16:28.831495 18802 net.cpp:425] bn3_1 <- conv3_1
I0625 20:16:28.831501 18802 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0625 20:16:28.833075 18802 net.cpp:141] Setting up bn3_1
I0625 20:16:28.833089 18802 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:28.833092 18802 net.cpp:156] Memory required for data: 681443712
I0625 20:16:28.833101 18802 layer_factory.hpp:77] Creating layer scale3_1
I0625 20:16:28.833109 18802 net.cpp:91] Creating Layer scale3_1
I0625 20:16:28.833112 18802 net.cpp:425] scale3_1 <- conv3_1
I0625 20:16:28.833117 18802 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0625 20:16:28.833161 18802 layer_factory.hpp:77] Creating layer scale3_1
I0625 20:16:28.833264 18802 net.cpp:141] Setting up scale3_1
I0625 20:16:28.833273 18802 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:28.833276 18802 net.cpp:156] Memory required for data: 694550912
I0625 20:16:28.833281 18802 layer_factory.hpp:77] Creating layer relu3_1
I0625 20:16:28.833287 18802 net.cpp:91] Creating Layer relu3_1
I0625 20:16:28.833292 18802 net.cpp:425] relu3_1 <- conv3_1
I0625 20:16:28.833295 18802 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0625 20:16:28.833467 18802 net.cpp:141] Setting up relu3_1
I0625 20:16:28.833477 18802 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:28.833480 18802 net.cpp:156] Memory required for data: 707658112
I0625 20:16:28.833483 18802 layer_factory.hpp:77] Creating layer conv3_2
I0625 20:16:28.833494 18802 net.cpp:91] Creating Layer conv3_2
I0625 20:16:28.833499 18802 net.cpp:425] conv3_2 <- conv3_1
I0625 20:16:28.833505 18802 net.cpp:399] conv3_2 -> conv3_2
I0625 20:16:28.836458 18802 net.cpp:141] Setting up conv3_2
I0625 20:16:28.836498 18802 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:28.836503 18802 net.cpp:156] Memory required for data: 720765312
I0625 20:16:28.836511 18802 layer_factory.hpp:77] Creating layer bn3_2
I0625 20:16:28.836521 18802 net.cpp:91] Creating Layer bn3_2
I0625 20:16:28.836527 18802 net.cpp:425] bn3_2 <- conv3_2
I0625 20:16:28.836537 18802 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0625 20:16:28.836833 18802 net.cpp:141] Setting up bn3_2
I0625 20:16:28.836851 18802 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:28.836856 18802 net.cpp:156] Memory required for data: 733872512
I0625 20:16:28.836874 18802 layer_factory.hpp:77] Creating layer scale3_2
I0625 20:16:28.836887 18802 net.cpp:91] Creating Layer scale3_2
I0625 20:16:28.836894 18802 net.cpp:425] scale3_2 <- conv3_2
I0625 20:16:28.836901 18802 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0625 20:16:28.836978 18802 layer_factory.hpp:77] Creating layer scale3_2
I0625 20:16:28.837134 18802 net.cpp:141] Setting up scale3_2
I0625 20:16:28.837147 18802 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:28.837151 18802 net.cpp:156] Memory required for data: 746979712
I0625 20:16:28.837157 18802 layer_factory.hpp:77] Creating layer relu3_2
I0625 20:16:28.837162 18802 net.cpp:91] Creating Layer relu3_2
I0625 20:16:28.837165 18802 net.cpp:425] relu3_2 <- conv3_2
I0625 20:16:28.837188 18802 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0625 20:16:28.837366 18802 net.cpp:141] Setting up relu3_2
I0625 20:16:28.837378 18802 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:28.837381 18802 net.cpp:156] Memory required for data: 760086912
I0625 20:16:28.837385 18802 layer_factory.hpp:77] Creating layer pool3
I0625 20:16:28.837391 18802 net.cpp:91] Creating Layer pool3
I0625 20:16:28.837394 18802 net.cpp:425] pool3 <- conv3_2
I0625 20:16:28.837399 18802 net.cpp:399] pool3 -> pool3
I0625 20:16:28.837445 18802 net.cpp:141] Setting up pool3
I0625 20:16:28.837452 18802 net.cpp:148] Top shape: 32 128 13 16 (851968)
I0625 20:16:28.837455 18802 net.cpp:156] Memory required for data: 763494784
I0625 20:16:28.837457 18802 layer_factory.hpp:77] Creating layer conv4_1
I0625 20:16:28.837467 18802 net.cpp:91] Creating Layer conv4_1
I0625 20:16:28.837472 18802 net.cpp:425] conv4_1 <- pool3
I0625 20:16:28.837478 18802 net.cpp:399] conv4_1 -> conv4_1
I0625 20:16:28.840843 18802 net.cpp:141] Setting up conv4_1
I0625 20:16:28.840862 18802 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:28.840864 18802 net.cpp:156] Memory required for data: 770310528
I0625 20:16:28.840870 18802 layer_factory.hpp:77] Creating layer bn4_1
I0625 20:16:28.840878 18802 net.cpp:91] Creating Layer bn4_1
I0625 20:16:28.840880 18802 net.cpp:425] bn4_1 <- conv4_1
I0625 20:16:28.840888 18802 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0625 20:16:28.841073 18802 net.cpp:141] Setting up bn4_1
I0625 20:16:28.841081 18802 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:28.841084 18802 net.cpp:156] Memory required for data: 777126272
I0625 20:16:28.841091 18802 layer_factory.hpp:77] Creating layer scale4_1
I0625 20:16:28.841099 18802 net.cpp:91] Creating Layer scale4_1
I0625 20:16:28.841101 18802 net.cpp:425] scale4_1 <- conv4_1
I0625 20:16:28.841105 18802 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0625 20:16:28.841145 18802 layer_factory.hpp:77] Creating layer scale4_1
I0625 20:16:28.841248 18802 net.cpp:141] Setting up scale4_1
I0625 20:16:28.841255 18802 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:28.841258 18802 net.cpp:156] Memory required for data: 783942016
I0625 20:16:28.841264 18802 layer_factory.hpp:77] Creating layer relu4_1
I0625 20:16:28.841274 18802 net.cpp:91] Creating Layer relu4_1
I0625 20:16:28.841280 18802 net.cpp:425] relu4_1 <- conv4_1
I0625 20:16:28.841285 18802 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0625 20:16:28.841464 18802 net.cpp:141] Setting up relu4_1
I0625 20:16:28.841475 18802 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:28.841478 18802 net.cpp:156] Memory required for data: 790757760
I0625 20:16:28.841481 18802 layer_factory.hpp:77] Creating layer conv4_2
I0625 20:16:28.841491 18802 net.cpp:91] Creating Layer conv4_2
I0625 20:16:28.841495 18802 net.cpp:425] conv4_2 <- conv4_1
I0625 20:16:28.841500 18802 net.cpp:399] conv4_2 -> conv4_2
I0625 20:16:28.848204 18802 net.cpp:141] Setting up conv4_2
I0625 20:16:28.848222 18802 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:28.848225 18802 net.cpp:156] Memory required for data: 797573504
I0625 20:16:28.848230 18802 layer_factory.hpp:77] Creating layer bn4_2
I0625 20:16:28.848237 18802 net.cpp:91] Creating Layer bn4_2
I0625 20:16:28.848240 18802 net.cpp:425] bn4_2 <- conv4_2
I0625 20:16:28.848247 18802 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0625 20:16:28.848423 18802 net.cpp:141] Setting up bn4_2
I0625 20:16:28.848433 18802 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:28.848435 18802 net.cpp:156] Memory required for data: 804389248
I0625 20:16:28.848443 18802 layer_factory.hpp:77] Creating layer scale4_2
I0625 20:16:28.848449 18802 net.cpp:91] Creating Layer scale4_2
I0625 20:16:28.848453 18802 net.cpp:425] scale4_2 <- conv4_2
I0625 20:16:28.848456 18802 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0625 20:16:28.848496 18802 layer_factory.hpp:77] Creating layer scale4_2
I0625 20:16:28.848595 18802 net.cpp:141] Setting up scale4_2
I0625 20:16:28.848615 18802 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:28.848618 18802 net.cpp:156] Memory required for data: 811204992
I0625 20:16:28.848624 18802 layer_factory.hpp:77] Creating layer relu4_2
I0625 20:16:28.848630 18802 net.cpp:91] Creating Layer relu4_2
I0625 20:16:28.848634 18802 net.cpp:425] relu4_2 <- conv4_2
I0625 20:16:28.848639 18802 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0625 20:16:28.848806 18802 net.cpp:141] Setting up relu4_2
I0625 20:16:28.848816 18802 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:28.848819 18802 net.cpp:156] Memory required for data: 818020736
I0625 20:16:28.848822 18802 layer_factory.hpp:77] Creating layer pool4
I0625 20:16:28.848829 18802 net.cpp:91] Creating Layer pool4
I0625 20:16:28.848832 18802 net.cpp:425] pool4 <- conv4_2
I0625 20:16:28.848839 18802 net.cpp:399] pool4 -> pool4
I0625 20:16:28.848881 18802 net.cpp:141] Setting up pool4
I0625 20:16:28.848887 18802 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:28.848891 18802 net.cpp:156] Memory required for data: 819855744
I0625 20:16:28.848892 18802 layer_factory.hpp:77] Creating layer conv5_1
I0625 20:16:28.848901 18802 net.cpp:91] Creating Layer conv5_1
I0625 20:16:28.848904 18802 net.cpp:425] conv5_1 <- pool4
I0625 20:16:28.848911 18802 net.cpp:399] conv5_1 -> conv5_1
I0625 20:16:28.855219 18802 net.cpp:141] Setting up conv5_1
I0625 20:16:28.855237 18802 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:28.855239 18802 net.cpp:156] Memory required for data: 821690752
I0625 20:16:28.855244 18802 layer_factory.hpp:77] Creating layer bn5_1
I0625 20:16:28.855250 18802 net.cpp:91] Creating Layer bn5_1
I0625 20:16:28.855253 18802 net.cpp:425] bn5_1 <- conv5_1
I0625 20:16:28.855258 18802 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0625 20:16:28.855413 18802 net.cpp:141] Setting up bn5_1
I0625 20:16:28.855422 18802 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:28.855424 18802 net.cpp:156] Memory required for data: 823525760
I0625 20:16:28.855430 18802 layer_factory.hpp:77] Creating layer scale5_1
I0625 20:16:28.855435 18802 net.cpp:91] Creating Layer scale5_1
I0625 20:16:28.855438 18802 net.cpp:425] scale5_1 <- conv5_1
I0625 20:16:28.855442 18802 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0625 20:16:28.855479 18802 layer_factory.hpp:77] Creating layer scale5_1
I0625 20:16:28.855564 18802 net.cpp:141] Setting up scale5_1
I0625 20:16:28.855572 18802 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:28.855574 18802 net.cpp:156] Memory required for data: 825360768
I0625 20:16:28.855579 18802 layer_factory.hpp:77] Creating layer relu5_1
I0625 20:16:28.855584 18802 net.cpp:91] Creating Layer relu5_1
I0625 20:16:28.855587 18802 net.cpp:425] relu5_1 <- conv5_1
I0625 20:16:28.855590 18802 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0625 20:16:28.856025 18802 net.cpp:141] Setting up relu5_1
I0625 20:16:28.856039 18802 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:28.856041 18802 net.cpp:156] Memory required for data: 827195776
I0625 20:16:28.856045 18802 layer_factory.hpp:77] Creating layer conv5_2
I0625 20:16:28.856053 18802 net.cpp:91] Creating Layer conv5_2
I0625 20:16:28.856056 18802 net.cpp:425] conv5_2 <- conv5_1
I0625 20:16:28.856061 18802 net.cpp:399] conv5_2 -> conv5_2
I0625 20:16:28.861471 18802 net.cpp:141] Setting up conv5_2
I0625 20:16:28.861485 18802 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:28.861487 18802 net.cpp:156] Memory required for data: 829030784
I0625 20:16:28.861491 18802 layer_factory.hpp:77] Creating layer bn5_2
I0625 20:16:28.861498 18802 net.cpp:91] Creating Layer bn5_2
I0625 20:16:28.861501 18802 net.cpp:425] bn5_2 <- conv5_2
I0625 20:16:28.861505 18802 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0625 20:16:28.861662 18802 net.cpp:141] Setting up bn5_2
I0625 20:16:28.861670 18802 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:28.861672 18802 net.cpp:156] Memory required for data: 830865792
I0625 20:16:28.861678 18802 layer_factory.hpp:77] Creating layer scale5_2
I0625 20:16:28.861685 18802 net.cpp:91] Creating Layer scale5_2
I0625 20:16:28.861698 18802 net.cpp:425] scale5_2 <- conv5_2
I0625 20:16:28.861703 18802 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0625 20:16:28.861740 18802 layer_factory.hpp:77] Creating layer scale5_2
I0625 20:16:28.861831 18802 net.cpp:141] Setting up scale5_2
I0625 20:16:28.861840 18802 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:28.861841 18802 net.cpp:156] Memory required for data: 832700800
I0625 20:16:28.861845 18802 layer_factory.hpp:77] Creating layer relu5_2
I0625 20:16:28.861850 18802 net.cpp:91] Creating Layer relu5_2
I0625 20:16:28.861852 18802 net.cpp:425] relu5_2 <- conv5_2
I0625 20:16:28.861857 18802 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0625 20:16:28.862272 18802 net.cpp:141] Setting up relu5_2
I0625 20:16:28.862283 18802 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:28.862287 18802 net.cpp:156] Memory required for data: 834535808
I0625 20:16:28.862289 18802 layer_factory.hpp:77] Creating layer pool5
I0625 20:16:28.862296 18802 net.cpp:91] Creating Layer pool5
I0625 20:16:28.862299 18802 net.cpp:425] pool5 <- conv5_2
I0625 20:16:28.862303 18802 net.cpp:399] pool5 -> pool5
I0625 20:16:28.862470 18802 net.cpp:141] Setting up pool5
I0625 20:16:28.862480 18802 net.cpp:148] Top shape: 32 256 2 1 (16384)
I0625 20:16:28.862483 18802 net.cpp:156] Memory required for data: 834601344
I0625 20:16:28.862485 18802 layer_factory.hpp:77] Creating layer fc2
I0625 20:16:28.862491 18802 net.cpp:91] Creating Layer fc2
I0625 20:16:28.862493 18802 net.cpp:425] fc2 <- pool5
I0625 20:16:28.862498 18802 net.cpp:399] fc2 -> fc2
I0625 20:16:28.862596 18802 net.cpp:141] Setting up fc2
I0625 20:16:28.862602 18802 net.cpp:148] Top shape: 32 2 (64)
I0625 20:16:28.862604 18802 net.cpp:156] Memory required for data: 834601600
I0625 20:16:28.862609 18802 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0625 20:16:28.862615 18802 net.cpp:91] Creating Layer fc2_fc2_0_split
I0625 20:16:28.862617 18802 net.cpp:425] fc2_fc2_0_split <- fc2
I0625 20:16:28.862622 18802 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0625 20:16:28.862627 18802 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0625 20:16:28.862656 18802 net.cpp:141] Setting up fc2_fc2_0_split
I0625 20:16:28.862660 18802 net.cpp:148] Top shape: 32 2 (64)
I0625 20:16:28.862663 18802 net.cpp:148] Top shape: 32 2 (64)
I0625 20:16:28.862665 18802 net.cpp:156] Memory required for data: 834602112
I0625 20:16:28.862668 18802 layer_factory.hpp:77] Creating layer loss
I0625 20:16:28.862673 18802 net.cpp:91] Creating Layer loss
I0625 20:16:28.862675 18802 net.cpp:425] loss <- fc2_fc2_0_split_0
I0625 20:16:28.862679 18802 net.cpp:425] loss <- label_data_1_split_0
I0625 20:16:28.862682 18802 net.cpp:399] loss -> loss
I0625 20:16:28.862689 18802 layer_factory.hpp:77] Creating layer loss
I0625 20:16:28.862910 18802 net.cpp:141] Setting up loss
I0625 20:16:28.862920 18802 net.cpp:148] Top shape: (1)
I0625 20:16:28.862921 18802 net.cpp:151]     with loss weight 1
I0625 20:16:28.862936 18802 net.cpp:156] Memory required for data: 834602116
I0625 20:16:28.862938 18802 layer_factory.hpp:77] Creating layer accuracy
I0625 20:16:28.862946 18802 net.cpp:91] Creating Layer accuracy
I0625 20:16:28.862949 18802 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0625 20:16:28.862952 18802 net.cpp:425] accuracy <- label_data_1_split_1
I0625 20:16:28.862957 18802 net.cpp:399] accuracy -> accuracy
I0625 20:16:28.862963 18802 net.cpp:141] Setting up accuracy
I0625 20:16:28.862967 18802 net.cpp:148] Top shape: (1)
I0625 20:16:28.862969 18802 net.cpp:156] Memory required for data: 834602120
I0625 20:16:28.862972 18802 net.cpp:219] accuracy does not need backward computation.
I0625 20:16:28.862974 18802 net.cpp:217] loss needs backward computation.
I0625 20:16:28.862977 18802 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0625 20:16:28.862979 18802 net.cpp:217] fc2 needs backward computation.
I0625 20:16:28.862982 18802 net.cpp:217] pool5 needs backward computation.
I0625 20:16:28.862983 18802 net.cpp:217] relu5_2 needs backward computation.
I0625 20:16:28.862985 18802 net.cpp:217] scale5_2 needs backward computation.
I0625 20:16:28.862996 18802 net.cpp:217] bn5_2 needs backward computation.
I0625 20:16:28.862999 18802 net.cpp:217] conv5_2 needs backward computation.
I0625 20:16:28.863001 18802 net.cpp:217] relu5_1 needs backward computation.
I0625 20:16:28.863003 18802 net.cpp:217] scale5_1 needs backward computation.
I0625 20:16:28.863005 18802 net.cpp:217] bn5_1 needs backward computation.
I0625 20:16:28.863008 18802 net.cpp:217] conv5_1 needs backward computation.
I0625 20:16:28.863009 18802 net.cpp:217] pool4 needs backward computation.
I0625 20:16:28.863011 18802 net.cpp:217] relu4_2 needs backward computation.
I0625 20:16:28.863013 18802 net.cpp:217] scale4_2 needs backward computation.
I0625 20:16:28.863015 18802 net.cpp:217] bn4_2 needs backward computation.
I0625 20:16:28.863018 18802 net.cpp:217] conv4_2 needs backward computation.
I0625 20:16:28.863020 18802 net.cpp:217] relu4_1 needs backward computation.
I0625 20:16:28.863023 18802 net.cpp:217] scale4_1 needs backward computation.
I0625 20:16:28.863024 18802 net.cpp:217] bn4_1 needs backward computation.
I0625 20:16:28.863026 18802 net.cpp:217] conv4_1 needs backward computation.
I0625 20:16:28.863029 18802 net.cpp:217] pool3 needs backward computation.
I0625 20:16:28.863031 18802 net.cpp:217] relu3_2 needs backward computation.
I0625 20:16:28.863034 18802 net.cpp:217] scale3_2 needs backward computation.
I0625 20:16:28.863036 18802 net.cpp:217] bn3_2 needs backward computation.
I0625 20:16:28.863039 18802 net.cpp:217] conv3_2 needs backward computation.
I0625 20:16:28.863040 18802 net.cpp:217] relu3_1 needs backward computation.
I0625 20:16:28.863042 18802 net.cpp:217] scale3_1 needs backward computation.
I0625 20:16:28.863044 18802 net.cpp:217] bn3_1 needs backward computation.
I0625 20:16:28.863046 18802 net.cpp:217] conv3_1 needs backward computation.
I0625 20:16:28.863049 18802 net.cpp:217] pool2 needs backward computation.
I0625 20:16:28.863051 18802 net.cpp:217] relu2_2 needs backward computation.
I0625 20:16:28.863054 18802 net.cpp:217] scale2_2 needs backward computation.
I0625 20:16:28.863056 18802 net.cpp:217] bn2_2 needs backward computation.
I0625 20:16:28.863059 18802 net.cpp:217] conv2_2 needs backward computation.
I0625 20:16:28.863060 18802 net.cpp:217] relu2_1 needs backward computation.
I0625 20:16:28.863062 18802 net.cpp:217] scale2_1 needs backward computation.
I0625 20:16:28.863065 18802 net.cpp:217] bn2_1 needs backward computation.
I0625 20:16:28.863066 18802 net.cpp:217] conv2_1 needs backward computation.
I0625 20:16:28.863068 18802 net.cpp:217] pool1 needs backward computation.
I0625 20:16:28.863071 18802 net.cpp:217] relu1_2 needs backward computation.
I0625 20:16:28.863073 18802 net.cpp:217] scale1_2 needs backward computation.
I0625 20:16:28.863075 18802 net.cpp:217] bn1_2 needs backward computation.
I0625 20:16:28.863078 18802 net.cpp:217] conv1_2 needs backward computation.
I0625 20:16:28.863080 18802 net.cpp:217] relu1_1 needs backward computation.
I0625 20:16:28.863082 18802 net.cpp:217] scale1_1 needs backward computation.
I0625 20:16:28.863085 18802 net.cpp:217] bn1_1 needs backward computation.
I0625 20:16:28.863087 18802 net.cpp:217] conv1_1 needs backward computation.
I0625 20:16:28.863090 18802 net.cpp:219] label_data_1_split does not need backward computation.
I0625 20:16:28.863092 18802 net.cpp:219] data does not need backward computation.
I0625 20:16:28.863095 18802 net.cpp:261] This network produces output accuracy
I0625 20:16:28.863097 18802 net.cpp:261] This network produces output loss
I0625 20:16:28.863117 18802 net.cpp:274] Network initialization done.
I0625 20:16:28.863968 18802 solver.cpp:181] Creating test net (#0) specified by net file: models/bpnet/train_val.prototxt
I0625 20:16:28.864023 18802 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0625 20:16:28.864238 18802 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 100
    crop_h: 196
    crop_w: 256
  }
  data_param {
    source: "data/val_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  pooling_param {
    pool: AVE
    stride: 1
    kernel_h: 6
    kernel_w: 8
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0625 20:16:28.864387 18802 layer_factory.hpp:77] Creating layer data
I0625 20:16:28.864464 18802 net.cpp:91] Creating Layer data
I0625 20:16:28.864471 18802 net.cpp:399] data -> data
I0625 20:16:28.864478 18802 net.cpp:399] data -> label
I0625 20:16:28.865847 18815 db_lmdb.cpp:35] Opened lmdb data/val_lmdb
I0625 20:16:28.866233 18802 data_layer.cpp:42] output data size: 64,3,196,256
I0625 20:16:28.947494 18802 net.cpp:141] Setting up data
I0625 20:16:28.947523 18802 net.cpp:148] Top shape: 64 3 196 256 (9633792)
I0625 20:16:28.947530 18802 net.cpp:148] Top shape: 64 (64)
I0625 20:16:28.947533 18802 net.cpp:156] Memory required for data: 38535424
I0625 20:16:28.947540 18802 layer_factory.hpp:77] Creating layer label_data_1_split
I0625 20:16:28.947554 18802 net.cpp:91] Creating Layer label_data_1_split
I0625 20:16:28.947557 18802 net.cpp:425] label_data_1_split <- label
I0625 20:16:28.947566 18802 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0625 20:16:28.947573 18802 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0625 20:16:28.947702 18802 net.cpp:141] Setting up label_data_1_split
I0625 20:16:28.947721 18802 net.cpp:148] Top shape: 64 (64)
I0625 20:16:28.947727 18802 net.cpp:148] Top shape: 64 (64)
I0625 20:16:28.947731 18802 net.cpp:156] Memory required for data: 38535936
I0625 20:16:28.947736 18802 layer_factory.hpp:77] Creating layer conv1_1
I0625 20:16:28.947751 18802 net.cpp:91] Creating Layer conv1_1
I0625 20:16:28.947757 18802 net.cpp:425] conv1_1 <- data
I0625 20:16:28.947767 18802 net.cpp:399] conv1_1 -> conv1_1
I0625 20:16:28.951963 18802 net.cpp:141] Setting up conv1_1
I0625 20:16:28.951977 18802 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:28.951979 18802 net.cpp:156] Memory required for data: 141296384
I0625 20:16:28.951987 18802 layer_factory.hpp:77] Creating layer bn1_1
I0625 20:16:28.951995 18802 net.cpp:91] Creating Layer bn1_1
I0625 20:16:28.951997 18802 net.cpp:425] bn1_1 <- conv1_1
I0625 20:16:28.952003 18802 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0625 20:16:28.952184 18802 net.cpp:141] Setting up bn1_1
I0625 20:16:28.952193 18802 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:28.952194 18802 net.cpp:156] Memory required for data: 244056832
I0625 20:16:28.952203 18802 layer_factory.hpp:77] Creating layer scale1_1
I0625 20:16:28.952210 18802 net.cpp:91] Creating Layer scale1_1
I0625 20:16:28.952214 18802 net.cpp:425] scale1_1 <- conv1_1
I0625 20:16:28.952229 18802 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0625 20:16:28.952265 18802 layer_factory.hpp:77] Creating layer scale1_1
I0625 20:16:28.952373 18802 net.cpp:141] Setting up scale1_1
I0625 20:16:28.952380 18802 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:28.952383 18802 net.cpp:156] Memory required for data: 346817280
I0625 20:16:28.952389 18802 layer_factory.hpp:77] Creating layer relu1_1
I0625 20:16:28.952399 18802 net.cpp:91] Creating Layer relu1_1
I0625 20:16:28.952401 18802 net.cpp:425] relu1_1 <- conv1_1
I0625 20:16:28.952405 18802 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0625 20:16:28.952549 18802 net.cpp:141] Setting up relu1_1
I0625 20:16:28.952558 18802 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:28.952560 18802 net.cpp:156] Memory required for data: 449577728
I0625 20:16:28.952563 18802 layer_factory.hpp:77] Creating layer conv1_2
I0625 20:16:28.952570 18802 net.cpp:91] Creating Layer conv1_2
I0625 20:16:28.952574 18802 net.cpp:425] conv1_2 <- conv1_1
I0625 20:16:28.952579 18802 net.cpp:399] conv1_2 -> conv1_2
I0625 20:16:28.953491 18802 net.cpp:141] Setting up conv1_2
I0625 20:16:28.953503 18802 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:28.953506 18802 net.cpp:156] Memory required for data: 552338176
I0625 20:16:28.953510 18802 layer_factory.hpp:77] Creating layer bn1_2
I0625 20:16:28.953518 18802 net.cpp:91] Creating Layer bn1_2
I0625 20:16:28.953521 18802 net.cpp:425] bn1_2 <- conv1_2
I0625 20:16:28.953526 18802 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0625 20:16:28.953688 18802 net.cpp:141] Setting up bn1_2
I0625 20:16:28.953696 18802 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:28.953697 18802 net.cpp:156] Memory required for data: 655098624
I0625 20:16:28.953704 18802 layer_factory.hpp:77] Creating layer scale1_2
I0625 20:16:28.953712 18802 net.cpp:91] Creating Layer scale1_2
I0625 20:16:28.953714 18802 net.cpp:425] scale1_2 <- conv1_2
I0625 20:16:28.953718 18802 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0625 20:16:28.953752 18802 layer_factory.hpp:77] Creating layer scale1_2
I0625 20:16:28.953858 18802 net.cpp:141] Setting up scale1_2
I0625 20:16:28.953865 18802 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:28.953867 18802 net.cpp:156] Memory required for data: 757859072
I0625 20:16:28.953871 18802 layer_factory.hpp:77] Creating layer relu1_2
I0625 20:16:28.953876 18802 net.cpp:91] Creating Layer relu1_2
I0625 20:16:28.953878 18802 net.cpp:425] relu1_2 <- conv1_2
I0625 20:16:28.953881 18802 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0625 20:16:28.954295 18802 net.cpp:141] Setting up relu1_2
I0625 20:16:28.954306 18802 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:28.954308 18802 net.cpp:156] Memory required for data: 860619520
I0625 20:16:28.954311 18802 layer_factory.hpp:77] Creating layer pool1
I0625 20:16:28.954318 18802 net.cpp:91] Creating Layer pool1
I0625 20:16:28.954319 18802 net.cpp:425] pool1 <- conv1_2
I0625 20:16:28.954324 18802 net.cpp:399] pool1 -> pool1
I0625 20:16:28.954365 18802 net.cpp:141] Setting up pool1
I0625 20:16:28.954370 18802 net.cpp:148] Top shape: 64 32 49 64 (6422528)
I0625 20:16:28.954371 18802 net.cpp:156] Memory required for data: 886309632
I0625 20:16:28.954373 18802 layer_factory.hpp:77] Creating layer conv2_1
I0625 20:16:28.954383 18802 net.cpp:91] Creating Layer conv2_1
I0625 20:16:28.954385 18802 net.cpp:425] conv2_1 <- pool1
I0625 20:16:28.954390 18802 net.cpp:399] conv2_1 -> conv2_1
I0625 20:16:28.955359 18802 net.cpp:141] Setting up conv2_1
I0625 20:16:28.955371 18802 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:28.955374 18802 net.cpp:156] Memory required for data: 937689856
I0625 20:16:28.955379 18802 layer_factory.hpp:77] Creating layer bn2_1
I0625 20:16:28.955385 18802 net.cpp:91] Creating Layer bn2_1
I0625 20:16:28.955389 18802 net.cpp:425] bn2_1 <- conv2_1
I0625 20:16:28.955392 18802 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0625 20:16:28.955556 18802 net.cpp:141] Setting up bn2_1
I0625 20:16:28.955572 18802 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:28.955575 18802 net.cpp:156] Memory required for data: 989070080
I0625 20:16:28.955581 18802 layer_factory.hpp:77] Creating layer scale2_1
I0625 20:16:28.955587 18802 net.cpp:91] Creating Layer scale2_1
I0625 20:16:28.955590 18802 net.cpp:425] scale2_1 <- conv2_1
I0625 20:16:28.955593 18802 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0625 20:16:28.955627 18802 layer_factory.hpp:77] Creating layer scale2_1
I0625 20:16:28.955724 18802 net.cpp:141] Setting up scale2_1
I0625 20:16:28.955730 18802 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:28.955734 18802 net.cpp:156] Memory required for data: 1040450304
I0625 20:16:28.955740 18802 layer_factory.hpp:77] Creating layer relu2_1
I0625 20:16:28.955746 18802 net.cpp:91] Creating Layer relu2_1
I0625 20:16:28.955749 18802 net.cpp:425] relu2_1 <- conv2_1
I0625 20:16:28.955751 18802 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0625 20:16:28.955888 18802 net.cpp:141] Setting up relu2_1
I0625 20:16:28.955898 18802 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:28.955899 18802 net.cpp:156] Memory required for data: 1091830528
I0625 20:16:28.955901 18802 layer_factory.hpp:77] Creating layer conv2_2
I0625 20:16:28.955910 18802 net.cpp:91] Creating Layer conv2_2
I0625 20:16:28.955912 18802 net.cpp:425] conv2_2 <- conv2_1
I0625 20:16:28.955916 18802 net.cpp:399] conv2_2 -> conv2_2
I0625 20:16:28.956980 18802 net.cpp:141] Setting up conv2_2
I0625 20:16:28.956993 18802 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:28.956996 18802 net.cpp:156] Memory required for data: 1143210752
I0625 20:16:28.957000 18802 layer_factory.hpp:77] Creating layer bn2_2
I0625 20:16:28.957008 18802 net.cpp:91] Creating Layer bn2_2
I0625 20:16:28.957011 18802 net.cpp:425] bn2_2 <- conv2_2
I0625 20:16:28.957017 18802 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0625 20:16:28.957175 18802 net.cpp:141] Setting up bn2_2
I0625 20:16:28.957181 18802 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:28.957185 18802 net.cpp:156] Memory required for data: 1194590976
I0625 20:16:28.957190 18802 layer_factory.hpp:77] Creating layer scale2_2
I0625 20:16:28.957196 18802 net.cpp:91] Creating Layer scale2_2
I0625 20:16:28.957198 18802 net.cpp:425] scale2_2 <- conv2_2
I0625 20:16:28.957202 18802 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0625 20:16:28.957240 18802 layer_factory.hpp:77] Creating layer scale2_2
I0625 20:16:28.957340 18802 net.cpp:141] Setting up scale2_2
I0625 20:16:28.957346 18802 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:28.957348 18802 net.cpp:156] Memory required for data: 1245971200
I0625 20:16:28.957352 18802 layer_factory.hpp:77] Creating layer relu2_2
I0625 20:16:28.957358 18802 net.cpp:91] Creating Layer relu2_2
I0625 20:16:28.957360 18802 net.cpp:425] relu2_2 <- conv2_2
I0625 20:16:28.957363 18802 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0625 20:16:28.957515 18802 net.cpp:141] Setting up relu2_2
I0625 20:16:28.957522 18802 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:28.957525 18802 net.cpp:156] Memory required for data: 1297351424
I0625 20:16:28.957528 18802 layer_factory.hpp:77] Creating layer pool2
I0625 20:16:28.957532 18802 net.cpp:91] Creating Layer pool2
I0625 20:16:28.957535 18802 net.cpp:425] pool2 <- conv2_2
I0625 20:16:28.957540 18802 net.cpp:399] pool2 -> pool2
I0625 20:16:28.957576 18802 net.cpp:141] Setting up pool2
I0625 20:16:28.957581 18802 net.cpp:148] Top shape: 64 64 25 32 (3276800)
I0625 20:16:28.957583 18802 net.cpp:156] Memory required for data: 1310458624
I0625 20:16:28.957586 18802 layer_factory.hpp:77] Creating layer conv3_1
I0625 20:16:28.957593 18802 net.cpp:91] Creating Layer conv3_1
I0625 20:16:28.957597 18802 net.cpp:425] conv3_1 <- pool2
I0625 20:16:28.957600 18802 net.cpp:399] conv3_1 -> conv3_1
I0625 20:16:28.960185 18802 net.cpp:141] Setting up conv3_1
I0625 20:16:28.960197 18802 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:28.960199 18802 net.cpp:156] Memory required for data: 1336673024
I0625 20:16:28.960214 18802 layer_factory.hpp:77] Creating layer bn3_1
I0625 20:16:28.960222 18802 net.cpp:91] Creating Layer bn3_1
I0625 20:16:28.960224 18802 net.cpp:425] bn3_1 <- conv3_1
I0625 20:16:28.960228 18802 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0625 20:16:28.960379 18802 net.cpp:141] Setting up bn3_1
I0625 20:16:28.960386 18802 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:28.960389 18802 net.cpp:156] Memory required for data: 1362887424
I0625 20:16:28.960394 18802 layer_factory.hpp:77] Creating layer scale3_1
I0625 20:16:28.960400 18802 net.cpp:91] Creating Layer scale3_1
I0625 20:16:28.960402 18802 net.cpp:425] scale3_1 <- conv3_1
I0625 20:16:28.960407 18802 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0625 20:16:28.960438 18802 layer_factory.hpp:77] Creating layer scale3_1
I0625 20:16:28.960528 18802 net.cpp:141] Setting up scale3_1
I0625 20:16:28.960537 18802 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:28.960539 18802 net.cpp:156] Memory required for data: 1389101824
I0625 20:16:28.960543 18802 layer_factory.hpp:77] Creating layer relu3_1
I0625 20:16:28.960548 18802 net.cpp:91] Creating Layer relu3_1
I0625 20:16:28.960551 18802 net.cpp:425] relu3_1 <- conv3_1
I0625 20:16:28.960553 18802 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0625 20:16:28.960714 18802 net.cpp:141] Setting up relu3_1
I0625 20:16:28.960722 18802 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:28.960724 18802 net.cpp:156] Memory required for data: 1415316224
I0625 20:16:28.960727 18802 layer_factory.hpp:77] Creating layer conv3_2
I0625 20:16:28.960736 18802 net.cpp:91] Creating Layer conv3_2
I0625 20:16:28.960738 18802 net.cpp:425] conv3_2 <- conv3_1
I0625 20:16:28.960742 18802 net.cpp:399] conv3_2 -> conv3_2
I0625 20:16:28.962671 18802 net.cpp:141] Setting up conv3_2
I0625 20:16:28.962682 18802 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:28.962684 18802 net.cpp:156] Memory required for data: 1441530624
I0625 20:16:28.962689 18802 layer_factory.hpp:77] Creating layer bn3_2
I0625 20:16:28.962694 18802 net.cpp:91] Creating Layer bn3_2
I0625 20:16:28.962697 18802 net.cpp:425] bn3_2 <- conv3_2
I0625 20:16:28.962702 18802 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0625 20:16:28.962862 18802 net.cpp:141] Setting up bn3_2
I0625 20:16:28.962869 18802 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:28.962872 18802 net.cpp:156] Memory required for data: 1467745024
I0625 20:16:28.962882 18802 layer_factory.hpp:77] Creating layer scale3_2
I0625 20:16:28.962888 18802 net.cpp:91] Creating Layer scale3_2
I0625 20:16:28.962891 18802 net.cpp:425] scale3_2 <- conv3_2
I0625 20:16:28.962894 18802 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0625 20:16:28.962929 18802 layer_factory.hpp:77] Creating layer scale3_2
I0625 20:16:28.963018 18802 net.cpp:141] Setting up scale3_2
I0625 20:16:28.963024 18802 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:28.963027 18802 net.cpp:156] Memory required for data: 1493959424
I0625 20:16:28.963032 18802 layer_factory.hpp:77] Creating layer relu3_2
I0625 20:16:28.963035 18802 net.cpp:91] Creating Layer relu3_2
I0625 20:16:28.963037 18802 net.cpp:425] relu3_2 <- conv3_2
I0625 20:16:28.963042 18802 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0625 20:16:28.963189 18802 net.cpp:141] Setting up relu3_2
I0625 20:16:28.963198 18802 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:28.963201 18802 net.cpp:156] Memory required for data: 1520173824
I0625 20:16:28.963203 18802 layer_factory.hpp:77] Creating layer pool3
I0625 20:16:28.963215 18802 net.cpp:91] Creating Layer pool3
I0625 20:16:28.963217 18802 net.cpp:425] pool3 <- conv3_2
I0625 20:16:28.963222 18802 net.cpp:399] pool3 -> pool3
I0625 20:16:28.963258 18802 net.cpp:141] Setting up pool3
I0625 20:16:28.963265 18802 net.cpp:148] Top shape: 64 128 13 16 (1703936)
I0625 20:16:28.963268 18802 net.cpp:156] Memory required for data: 1526989568
I0625 20:16:28.963269 18802 layer_factory.hpp:77] Creating layer conv4_1
I0625 20:16:28.963277 18802 net.cpp:91] Creating Layer conv4_1
I0625 20:16:28.963290 18802 net.cpp:425] conv4_1 <- pool3
I0625 20:16:28.963294 18802 net.cpp:399] conv4_1 -> conv4_1
I0625 20:16:28.966027 18802 net.cpp:141] Setting up conv4_1
I0625 20:16:28.966040 18802 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:28.966042 18802 net.cpp:156] Memory required for data: 1540621056
I0625 20:16:28.966048 18802 layer_factory.hpp:77] Creating layer bn4_1
I0625 20:16:28.966053 18802 net.cpp:91] Creating Layer bn4_1
I0625 20:16:28.966056 18802 net.cpp:425] bn4_1 <- conv4_1
I0625 20:16:28.966061 18802 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0625 20:16:28.966225 18802 net.cpp:141] Setting up bn4_1
I0625 20:16:28.966233 18802 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:28.966235 18802 net.cpp:156] Memory required for data: 1554252544
I0625 20:16:28.966241 18802 layer_factory.hpp:77] Creating layer scale4_1
I0625 20:16:28.966246 18802 net.cpp:91] Creating Layer scale4_1
I0625 20:16:28.966248 18802 net.cpp:425] scale4_1 <- conv4_1
I0625 20:16:28.966253 18802 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0625 20:16:28.966285 18802 layer_factory.hpp:77] Creating layer scale4_1
I0625 20:16:28.966382 18802 net.cpp:141] Setting up scale4_1
I0625 20:16:28.966388 18802 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:28.966392 18802 net.cpp:156] Memory required for data: 1567884032
I0625 20:16:28.966395 18802 layer_factory.hpp:77] Creating layer relu4_1
I0625 20:16:28.966403 18802 net.cpp:91] Creating Layer relu4_1
I0625 20:16:28.966406 18802 net.cpp:425] relu4_1 <- conv4_1
I0625 20:16:28.966409 18802 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0625 20:16:28.966552 18802 net.cpp:141] Setting up relu4_1
I0625 20:16:28.966560 18802 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:28.966563 18802 net.cpp:156] Memory required for data: 1581515520
I0625 20:16:28.966565 18802 layer_factory.hpp:77] Creating layer conv4_2
I0625 20:16:28.966573 18802 net.cpp:91] Creating Layer conv4_2
I0625 20:16:28.966576 18802 net.cpp:425] conv4_2 <- conv4_1
I0625 20:16:28.966581 18802 net.cpp:399] conv4_2 -> conv4_2
I0625 20:16:28.972143 18802 net.cpp:141] Setting up conv4_2
I0625 20:16:28.972158 18802 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:28.972162 18802 net.cpp:156] Memory required for data: 1595147008
I0625 20:16:28.972167 18802 layer_factory.hpp:77] Creating layer bn4_2
I0625 20:16:28.972172 18802 net.cpp:91] Creating Layer bn4_2
I0625 20:16:28.972175 18802 net.cpp:425] bn4_2 <- conv4_2
I0625 20:16:28.972180 18802 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0625 20:16:28.972348 18802 net.cpp:141] Setting up bn4_2
I0625 20:16:28.972355 18802 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:28.972358 18802 net.cpp:156] Memory required for data: 1608778496
I0625 20:16:28.972363 18802 layer_factory.hpp:77] Creating layer scale4_2
I0625 20:16:28.972369 18802 net.cpp:91] Creating Layer scale4_2
I0625 20:16:28.972371 18802 net.cpp:425] scale4_2 <- conv4_2
I0625 20:16:28.972375 18802 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0625 20:16:28.972419 18802 layer_factory.hpp:77] Creating layer scale4_2
I0625 20:16:28.972510 18802 net.cpp:141] Setting up scale4_2
I0625 20:16:28.972517 18802 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:28.972519 18802 net.cpp:156] Memory required for data: 1622409984
I0625 20:16:28.972523 18802 layer_factory.hpp:77] Creating layer relu4_2
I0625 20:16:28.972528 18802 net.cpp:91] Creating Layer relu4_2
I0625 20:16:28.972532 18802 net.cpp:425] relu4_2 <- conv4_2
I0625 20:16:28.972534 18802 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0625 20:16:28.972955 18802 net.cpp:141] Setting up relu4_2
I0625 20:16:28.972968 18802 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:28.972971 18802 net.cpp:156] Memory required for data: 1636041472
I0625 20:16:28.972975 18802 layer_factory.hpp:77] Creating layer pool4
I0625 20:16:28.972981 18802 net.cpp:91] Creating Layer pool4
I0625 20:16:28.972985 18802 net.cpp:425] pool4 <- conv4_2
I0625 20:16:28.972987 18802 net.cpp:399] pool4 -> pool4
I0625 20:16:28.973032 18802 net.cpp:141] Setting up pool4
I0625 20:16:28.973049 18802 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:28.973052 18802 net.cpp:156] Memory required for data: 1639711488
I0625 20:16:28.973053 18802 layer_factory.hpp:77] Creating layer conv5_1
I0625 20:16:28.973062 18802 net.cpp:91] Creating Layer conv5_1
I0625 20:16:28.973064 18802 net.cpp:425] conv5_1 <- pool4
I0625 20:16:28.973069 18802 net.cpp:399] conv5_1 -> conv5_1
I0625 20:16:28.978778 18802 net.cpp:141] Setting up conv5_1
I0625 20:16:28.978801 18802 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:28.978804 18802 net.cpp:156] Memory required for data: 1643381504
I0625 20:16:28.978811 18802 layer_factory.hpp:77] Creating layer bn5_1
I0625 20:16:28.978821 18802 net.cpp:91] Creating Layer bn5_1
I0625 20:16:28.978826 18802 net.cpp:425] bn5_1 <- conv5_1
I0625 20:16:28.978833 18802 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0625 20:16:28.979084 18802 net.cpp:141] Setting up bn5_1
I0625 20:16:28.979096 18802 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:28.979100 18802 net.cpp:156] Memory required for data: 1647051520
I0625 20:16:28.979110 18802 layer_factory.hpp:77] Creating layer scale5_1
I0625 20:16:28.979118 18802 net.cpp:91] Creating Layer scale5_1
I0625 20:16:28.979122 18802 net.cpp:425] scale5_1 <- conv5_1
I0625 20:16:28.979128 18802 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0625 20:16:28.979189 18802 layer_factory.hpp:77] Creating layer scale5_1
I0625 20:16:28.979323 18802 net.cpp:141] Setting up scale5_1
I0625 20:16:28.979346 18802 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:28.979348 18802 net.cpp:156] Memory required for data: 1650721536
I0625 20:16:28.979356 18802 layer_factory.hpp:77] Creating layer relu5_1
I0625 20:16:28.979363 18802 net.cpp:91] Creating Layer relu5_1
I0625 20:16:28.979367 18802 net.cpp:425] relu5_1 <- conv5_1
I0625 20:16:28.979372 18802 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0625 20:16:28.979563 18802 net.cpp:141] Setting up relu5_1
I0625 20:16:28.979578 18802 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:28.979581 18802 net.cpp:156] Memory required for data: 1654391552
I0625 20:16:28.979585 18802 layer_factory.hpp:77] Creating layer conv5_2
I0625 20:16:28.979598 18802 net.cpp:91] Creating Layer conv5_2
I0625 20:16:28.979601 18802 net.cpp:425] conv5_2 <- conv5_1
I0625 20:16:28.979609 18802 net.cpp:399] conv5_2 -> conv5_2
I0625 20:16:28.985656 18802 net.cpp:141] Setting up conv5_2
I0625 20:16:28.985674 18802 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:28.985677 18802 net.cpp:156] Memory required for data: 1658061568
I0625 20:16:28.985683 18802 layer_factory.hpp:77] Creating layer bn5_2
I0625 20:16:28.985692 18802 net.cpp:91] Creating Layer bn5_2
I0625 20:16:28.985697 18802 net.cpp:425] bn5_2 <- conv5_2
I0625 20:16:28.985702 18802 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0625 20:16:28.985879 18802 net.cpp:141] Setting up bn5_2
I0625 20:16:28.985888 18802 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:28.985889 18802 net.cpp:156] Memory required for data: 1661731584
I0625 20:16:28.985895 18802 layer_factory.hpp:77] Creating layer scale5_2
I0625 20:16:28.985901 18802 net.cpp:91] Creating Layer scale5_2
I0625 20:16:28.985903 18802 net.cpp:425] scale5_2 <- conv5_2
I0625 20:16:28.985909 18802 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0625 20:16:28.985945 18802 layer_factory.hpp:77] Creating layer scale5_2
I0625 20:16:28.986040 18802 net.cpp:141] Setting up scale5_2
I0625 20:16:28.986047 18802 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:28.986050 18802 net.cpp:156] Memory required for data: 1665401600
I0625 20:16:28.986054 18802 layer_factory.hpp:77] Creating layer relu5_2
I0625 20:16:28.986059 18802 net.cpp:91] Creating Layer relu5_2
I0625 20:16:28.986062 18802 net.cpp:425] relu5_2 <- conv5_2
I0625 20:16:28.986068 18802 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0625 20:16:28.986215 18802 net.cpp:141] Setting up relu5_2
I0625 20:16:28.986224 18802 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:28.986227 18802 net.cpp:156] Memory required for data: 1669071616
I0625 20:16:28.986243 18802 layer_factory.hpp:77] Creating layer pool5
I0625 20:16:28.986249 18802 net.cpp:91] Creating Layer pool5
I0625 20:16:28.986251 18802 net.cpp:425] pool5 <- conv5_2
I0625 20:16:28.986256 18802 net.cpp:399] pool5 -> pool5
I0625 20:16:28.986418 18802 net.cpp:141] Setting up pool5
I0625 20:16:28.986426 18802 net.cpp:148] Top shape: 64 256 2 1 (32768)
I0625 20:16:28.986429 18802 net.cpp:156] Memory required for data: 1669202688
I0625 20:16:28.986431 18802 layer_factory.hpp:77] Creating layer fc2
I0625 20:16:28.986438 18802 net.cpp:91] Creating Layer fc2
I0625 20:16:28.986440 18802 net.cpp:425] fc2 <- pool5
I0625 20:16:28.986445 18802 net.cpp:399] fc2 -> fc2
I0625 20:16:28.986549 18802 net.cpp:141] Setting up fc2
I0625 20:16:28.986557 18802 net.cpp:148] Top shape: 64 2 (128)
I0625 20:16:28.986559 18802 net.cpp:156] Memory required for data: 1669203200
I0625 20:16:28.986563 18802 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0625 20:16:28.986569 18802 net.cpp:91] Creating Layer fc2_fc2_0_split
I0625 20:16:28.986572 18802 net.cpp:425] fc2_fc2_0_split <- fc2
I0625 20:16:28.986577 18802 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0625 20:16:28.986580 18802 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0625 20:16:28.986610 18802 net.cpp:141] Setting up fc2_fc2_0_split
I0625 20:16:28.986615 18802 net.cpp:148] Top shape: 64 2 (128)
I0625 20:16:28.986618 18802 net.cpp:148] Top shape: 64 2 (128)
I0625 20:16:28.986619 18802 net.cpp:156] Memory required for data: 1669204224
I0625 20:16:28.986621 18802 layer_factory.hpp:77] Creating layer loss
I0625 20:16:28.986627 18802 net.cpp:91] Creating Layer loss
I0625 20:16:28.986629 18802 net.cpp:425] loss <- fc2_fc2_0_split_0
I0625 20:16:28.986632 18802 net.cpp:425] loss <- label_data_1_split_0
I0625 20:16:28.986636 18802 net.cpp:399] loss -> loss
I0625 20:16:28.986642 18802 layer_factory.hpp:77] Creating layer loss
I0625 20:16:28.987166 18802 net.cpp:141] Setting up loss
I0625 20:16:28.987179 18802 net.cpp:148] Top shape: (1)
I0625 20:16:28.987181 18802 net.cpp:151]     with loss weight 1
I0625 20:16:28.987190 18802 net.cpp:156] Memory required for data: 1669204228
I0625 20:16:28.987192 18802 layer_factory.hpp:77] Creating layer accuracy
I0625 20:16:28.987197 18802 net.cpp:91] Creating Layer accuracy
I0625 20:16:28.987201 18802 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0625 20:16:28.987205 18802 net.cpp:425] accuracy <- label_data_1_split_1
I0625 20:16:28.987208 18802 net.cpp:399] accuracy -> accuracy
I0625 20:16:28.987215 18802 net.cpp:141] Setting up accuracy
I0625 20:16:28.987218 18802 net.cpp:148] Top shape: (1)
I0625 20:16:28.987221 18802 net.cpp:156] Memory required for data: 1669204232
I0625 20:16:28.987222 18802 net.cpp:219] accuracy does not need backward computation.
I0625 20:16:28.987226 18802 net.cpp:217] loss needs backward computation.
I0625 20:16:28.987228 18802 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0625 20:16:28.987231 18802 net.cpp:217] fc2 needs backward computation.
I0625 20:16:28.987232 18802 net.cpp:217] pool5 needs backward computation.
I0625 20:16:28.987236 18802 net.cpp:217] relu5_2 needs backward computation.
I0625 20:16:28.987237 18802 net.cpp:217] scale5_2 needs backward computation.
I0625 20:16:28.987239 18802 net.cpp:217] bn5_2 needs backward computation.
I0625 20:16:28.987241 18802 net.cpp:217] conv5_2 needs backward computation.
I0625 20:16:28.987243 18802 net.cpp:217] relu5_1 needs backward computation.
I0625 20:16:28.987246 18802 net.cpp:217] scale5_1 needs backward computation.
I0625 20:16:28.987247 18802 net.cpp:217] bn5_1 needs backward computation.
I0625 20:16:28.987249 18802 net.cpp:217] conv5_1 needs backward computation.
I0625 20:16:28.987252 18802 net.cpp:217] pool4 needs backward computation.
I0625 20:16:28.987254 18802 net.cpp:217] relu4_2 needs backward computation.
I0625 20:16:28.987257 18802 net.cpp:217] scale4_2 needs backward computation.
I0625 20:16:28.987259 18802 net.cpp:217] bn4_2 needs backward computation.
I0625 20:16:28.987262 18802 net.cpp:217] conv4_2 needs backward computation.
I0625 20:16:28.987273 18802 net.cpp:217] relu4_1 needs backward computation.
I0625 20:16:28.987275 18802 net.cpp:217] scale4_1 needs backward computation.
I0625 20:16:28.987277 18802 net.cpp:217] bn4_1 needs backward computation.
I0625 20:16:28.987280 18802 net.cpp:217] conv4_1 needs backward computation.
I0625 20:16:28.987282 18802 net.cpp:217] pool3 needs backward computation.
I0625 20:16:28.987285 18802 net.cpp:217] relu3_2 needs backward computation.
I0625 20:16:28.987287 18802 net.cpp:217] scale3_2 needs backward computation.
I0625 20:16:28.987289 18802 net.cpp:217] bn3_2 needs backward computation.
I0625 20:16:28.987293 18802 net.cpp:217] conv3_2 needs backward computation.
I0625 20:16:28.987294 18802 net.cpp:217] relu3_1 needs backward computation.
I0625 20:16:28.987296 18802 net.cpp:217] scale3_1 needs backward computation.
I0625 20:16:28.987298 18802 net.cpp:217] bn3_1 needs backward computation.
I0625 20:16:28.987300 18802 net.cpp:217] conv3_1 needs backward computation.
I0625 20:16:28.987303 18802 net.cpp:217] pool2 needs backward computation.
I0625 20:16:28.987305 18802 net.cpp:217] relu2_2 needs backward computation.
I0625 20:16:28.987308 18802 net.cpp:217] scale2_2 needs backward computation.
I0625 20:16:28.987310 18802 net.cpp:217] bn2_2 needs backward computation.
I0625 20:16:28.987313 18802 net.cpp:217] conv2_2 needs backward computation.
I0625 20:16:28.987314 18802 net.cpp:217] relu2_1 needs backward computation.
I0625 20:16:28.987316 18802 net.cpp:217] scale2_1 needs backward computation.
I0625 20:16:28.987318 18802 net.cpp:217] bn2_1 needs backward computation.
I0625 20:16:28.987320 18802 net.cpp:217] conv2_1 needs backward computation.
I0625 20:16:28.987324 18802 net.cpp:217] pool1 needs backward computation.
I0625 20:16:28.987328 18802 net.cpp:217] relu1_2 needs backward computation.
I0625 20:16:28.987329 18802 net.cpp:217] scale1_2 needs backward computation.
I0625 20:16:28.987331 18802 net.cpp:217] bn1_2 needs backward computation.
I0625 20:16:28.987334 18802 net.cpp:217] conv1_2 needs backward computation.
I0625 20:16:28.987336 18802 net.cpp:217] relu1_1 needs backward computation.
I0625 20:16:28.987339 18802 net.cpp:217] scale1_1 needs backward computation.
I0625 20:16:28.987340 18802 net.cpp:217] bn1_1 needs backward computation.
I0625 20:16:28.987342 18802 net.cpp:217] conv1_1 needs backward computation.
I0625 20:16:28.987345 18802 net.cpp:219] label_data_1_split does not need backward computation.
I0625 20:16:28.987349 18802 net.cpp:219] data does not need backward computation.
I0625 20:16:28.987350 18802 net.cpp:261] This network produces output accuracy
I0625 20:16:28.987354 18802 net.cpp:261] This network produces output loss
I0625 20:16:28.987372 18802 net.cpp:274] Network initialization done.
I0625 20:16:28.987504 18802 solver.cpp:60] Solver scaffolding done.
I0625 20:16:28.989274 18802 caffe.cpp:209] Resuming from data/models/segnet_iter_2000.solverstate
F0625 20:16:29.037294 18802 net.cpp:765] Cannot copy param 0 weights from layer 'conv1_1'; shape mismatch.  Source param shape is 32 1 3 3 (288); target param shape is 32 3 7 7 (4704). To learn this layer's parameters from scratch rather than copying from a saved net, rename the layer.
*** Check failure stack trace: ***
    @     0x7f21c3d98daa  (unknown)
    @     0x7f21c3d98ce4  (unknown)
    @     0x7f21c3d986e6  (unknown)
    @     0x7f21c3d9b687  (unknown)
    @     0x7f21c43dd4e7  caffe::Net<>::CopyTrainedLayersFrom()
    @     0x7f21c43d1ace  caffe::SGDSolver<>::RestoreSolverStateFromBinaryProto()
    @     0x7f21c44192f3  caffe::Solver<>::Restore()
    @           0x407f88  train()
    @           0x4059bc  main
    @     0x7f21c30a6f45  (unknown)
    @           0x4060f1  (unknown)
    @              (nil)  (unknown)
I0625 20:16:43.430938 18821 caffe.cpp:185] Using GPUs 0
I0625 20:16:43.446195 18821 caffe.cpp:190] GPU 0: Graphics Device
I0625 20:16:43.908095 18821 solver.cpp:48] Initializing solver from parameters: 
test_iter: 64
test_interval: 100
base_lr: 0.001
display: 20
max_iter: 6000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 500
snapshot_prefix: "data/models/bpnet"
solver_mode: GPU
device_id: 0
net: "models/bpnet/train_val.prototxt"
test_initialization: true
iter_size: 1
I0625 20:16:43.908210 18821 solver.cpp:91] Creating training net from net file: models/bpnet/train_val.prototxt
I0625 20:16:43.909004 18821 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0625 20:16:43.909234 18821 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 100
    crop_h: 196
    crop_w: 256
    rotation_range: 10
    scale_jitter_range: 0.1
    contrast_jitter_range: 0.3
  }
  data_param {
    source: "data/train_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  pooling_param {
    pool: AVE
    stride: 1
    kernel_h: 6
    kernel_w: 8
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0625 20:16:43.909392 18821 layer_factory.hpp:77] Creating layer data
I0625 20:16:43.909785 18821 net.cpp:91] Creating Layer data
I0625 20:16:43.909795 18821 net.cpp:399] data -> data
I0625 20:16:43.909816 18821 net.cpp:399] data -> label
I0625 20:16:43.911185 18825 db_lmdb.cpp:35] Opened lmdb data/train_lmdb
I0625 20:16:43.935374 18821 data_layer.cpp:42] output data size: 32,3,196,256
I0625 20:16:43.974674 18821 net.cpp:141] Setting up data
I0625 20:16:43.974701 18821 net.cpp:148] Top shape: 32 3 196 256 (4816896)
I0625 20:16:43.974707 18821 net.cpp:148] Top shape: 32 (32)
I0625 20:16:43.974710 18821 net.cpp:156] Memory required for data: 19267712
I0625 20:16:43.974719 18821 layer_factory.hpp:77] Creating layer label_data_1_split
I0625 20:16:43.974735 18821 net.cpp:91] Creating Layer label_data_1_split
I0625 20:16:43.974738 18821 net.cpp:425] label_data_1_split <- label
I0625 20:16:43.974748 18821 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0625 20:16:43.974756 18821 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0625 20:16:43.974895 18821 net.cpp:141] Setting up label_data_1_split
I0625 20:16:43.974903 18821 net.cpp:148] Top shape: 32 (32)
I0625 20:16:43.974906 18821 net.cpp:148] Top shape: 32 (32)
I0625 20:16:43.974910 18821 net.cpp:156] Memory required for data: 19267968
I0625 20:16:43.974911 18821 layer_factory.hpp:77] Creating layer conv1_1
I0625 20:16:43.974927 18821 net.cpp:91] Creating Layer conv1_1
I0625 20:16:43.974942 18821 net.cpp:425] conv1_1 <- data
I0625 20:16:43.974948 18821 net.cpp:399] conv1_1 -> conv1_1
I0625 20:16:44.321445 18821 net.cpp:141] Setting up conv1_1
I0625 20:16:44.321470 18821 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:44.321475 18821 net.cpp:156] Memory required for data: 70648192
I0625 20:16:44.321486 18821 layer_factory.hpp:77] Creating layer bn1_1
I0625 20:16:44.321497 18821 net.cpp:91] Creating Layer bn1_1
I0625 20:16:44.321501 18821 net.cpp:425] bn1_1 <- conv1_1
I0625 20:16:44.321506 18821 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0625 20:16:44.321682 18821 net.cpp:141] Setting up bn1_1
I0625 20:16:44.321691 18821 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:44.321693 18821 net.cpp:156] Memory required for data: 122028416
I0625 20:16:44.321703 18821 layer_factory.hpp:77] Creating layer scale1_1
I0625 20:16:44.321713 18821 net.cpp:91] Creating Layer scale1_1
I0625 20:16:44.321718 18821 net.cpp:425] scale1_1 <- conv1_1
I0625 20:16:44.321722 18821 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0625 20:16:44.321761 18821 layer_factory.hpp:77] Creating layer scale1_1
I0625 20:16:44.321869 18821 net.cpp:141] Setting up scale1_1
I0625 20:16:44.321877 18821 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:44.321880 18821 net.cpp:156] Memory required for data: 173408640
I0625 20:16:44.321887 18821 layer_factory.hpp:77] Creating layer relu1_1
I0625 20:16:44.321893 18821 net.cpp:91] Creating Layer relu1_1
I0625 20:16:44.321895 18821 net.cpp:425] relu1_1 <- conv1_1
I0625 20:16:44.321899 18821 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0625 20:16:44.322046 18821 net.cpp:141] Setting up relu1_1
I0625 20:16:44.322054 18821 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:44.322057 18821 net.cpp:156] Memory required for data: 224788864
I0625 20:16:44.322059 18821 layer_factory.hpp:77] Creating layer conv1_2
I0625 20:16:44.322069 18821 net.cpp:91] Creating Layer conv1_2
I0625 20:16:44.322072 18821 net.cpp:425] conv1_2 <- conv1_1
I0625 20:16:44.322077 18821 net.cpp:399] conv1_2 -> conv1_2
I0625 20:16:44.322973 18821 net.cpp:141] Setting up conv1_2
I0625 20:16:44.322988 18821 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:44.322991 18821 net.cpp:156] Memory required for data: 276169088
I0625 20:16:44.322996 18821 layer_factory.hpp:77] Creating layer bn1_2
I0625 20:16:44.323002 18821 net.cpp:91] Creating Layer bn1_2
I0625 20:16:44.323005 18821 net.cpp:425] bn1_2 <- conv1_2
I0625 20:16:44.323011 18821 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0625 20:16:44.323179 18821 net.cpp:141] Setting up bn1_2
I0625 20:16:44.323187 18821 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:44.323189 18821 net.cpp:156] Memory required for data: 327549312
I0625 20:16:44.323204 18821 layer_factory.hpp:77] Creating layer scale1_2
I0625 20:16:44.323210 18821 net.cpp:91] Creating Layer scale1_2
I0625 20:16:44.323213 18821 net.cpp:425] scale1_2 <- conv1_2
I0625 20:16:44.323218 18821 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0625 20:16:44.323249 18821 layer_factory.hpp:77] Creating layer scale1_2
I0625 20:16:44.323362 18821 net.cpp:141] Setting up scale1_2
I0625 20:16:44.323370 18821 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:44.323372 18821 net.cpp:156] Memory required for data: 378929536
I0625 20:16:44.323377 18821 layer_factory.hpp:77] Creating layer relu1_2
I0625 20:16:44.323382 18821 net.cpp:91] Creating Layer relu1_2
I0625 20:16:44.323385 18821 net.cpp:425] relu1_2 <- conv1_2
I0625 20:16:44.323388 18821 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0625 20:16:44.323534 18821 net.cpp:141] Setting up relu1_2
I0625 20:16:44.323544 18821 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:16:44.323546 18821 net.cpp:156] Memory required for data: 430309760
I0625 20:16:44.323549 18821 layer_factory.hpp:77] Creating layer pool1
I0625 20:16:44.323559 18821 net.cpp:91] Creating Layer pool1
I0625 20:16:44.323561 18821 net.cpp:425] pool1 <- conv1_2
I0625 20:16:44.323565 18821 net.cpp:399] pool1 -> pool1
I0625 20:16:44.323616 18821 net.cpp:141] Setting up pool1
I0625 20:16:44.323637 18821 net.cpp:148] Top shape: 32 32 49 64 (3211264)
I0625 20:16:44.323639 18821 net.cpp:156] Memory required for data: 443154816
I0625 20:16:44.323642 18821 layer_factory.hpp:77] Creating layer conv2_1
I0625 20:16:44.323650 18821 net.cpp:91] Creating Layer conv2_1
I0625 20:16:44.323653 18821 net.cpp:425] conv2_1 <- pool1
I0625 20:16:44.323658 18821 net.cpp:399] conv2_1 -> conv2_1
I0625 20:16:44.325755 18821 net.cpp:141] Setting up conv2_1
I0625 20:16:44.325769 18821 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:44.325773 18821 net.cpp:156] Memory required for data: 468844928
I0625 20:16:44.325778 18821 layer_factory.hpp:77] Creating layer bn2_1
I0625 20:16:44.325784 18821 net.cpp:91] Creating Layer bn2_1
I0625 20:16:44.325788 18821 net.cpp:425] bn2_1 <- conv2_1
I0625 20:16:44.325793 18821 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0625 20:16:44.327044 18821 net.cpp:141] Setting up bn2_1
I0625 20:16:44.327055 18821 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:44.327059 18821 net.cpp:156] Memory required for data: 494535040
I0625 20:16:44.327065 18821 layer_factory.hpp:77] Creating layer scale2_1
I0625 20:16:44.327075 18821 net.cpp:91] Creating Layer scale2_1
I0625 20:16:44.327077 18821 net.cpp:425] scale2_1 <- conv2_1
I0625 20:16:44.327082 18821 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0625 20:16:44.327121 18821 layer_factory.hpp:77] Creating layer scale2_1
I0625 20:16:44.327229 18821 net.cpp:141] Setting up scale2_1
I0625 20:16:44.327239 18821 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:44.327240 18821 net.cpp:156] Memory required for data: 520225152
I0625 20:16:44.327250 18821 layer_factory.hpp:77] Creating layer relu2_1
I0625 20:16:44.327255 18821 net.cpp:91] Creating Layer relu2_1
I0625 20:16:44.327258 18821 net.cpp:425] relu2_1 <- conv2_1
I0625 20:16:44.327262 18821 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0625 20:16:44.327708 18821 net.cpp:141] Setting up relu2_1
I0625 20:16:44.327720 18821 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:44.327723 18821 net.cpp:156] Memory required for data: 545915264
I0625 20:16:44.327726 18821 layer_factory.hpp:77] Creating layer conv2_2
I0625 20:16:44.327735 18821 net.cpp:91] Creating Layer conv2_2
I0625 20:16:44.327739 18821 net.cpp:425] conv2_2 <- conv2_1
I0625 20:16:44.327744 18821 net.cpp:399] conv2_2 -> conv2_2
I0625 20:16:44.328547 18821 net.cpp:141] Setting up conv2_2
I0625 20:16:44.328558 18821 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:44.328560 18821 net.cpp:156] Memory required for data: 571605376
I0625 20:16:44.328564 18821 layer_factory.hpp:77] Creating layer bn2_2
I0625 20:16:44.328574 18821 net.cpp:91] Creating Layer bn2_2
I0625 20:16:44.328577 18821 net.cpp:425] bn2_2 <- conv2_2
I0625 20:16:44.328582 18821 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0625 20:16:44.328735 18821 net.cpp:141] Setting up bn2_2
I0625 20:16:44.328743 18821 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:44.328745 18821 net.cpp:156] Memory required for data: 597295488
I0625 20:16:44.328752 18821 layer_factory.hpp:77] Creating layer scale2_2
I0625 20:16:44.328758 18821 net.cpp:91] Creating Layer scale2_2
I0625 20:16:44.328760 18821 net.cpp:425] scale2_2 <- conv2_2
I0625 20:16:44.328764 18821 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0625 20:16:44.328797 18821 layer_factory.hpp:77] Creating layer scale2_2
I0625 20:16:44.328892 18821 net.cpp:141] Setting up scale2_2
I0625 20:16:44.328899 18821 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:44.328902 18821 net.cpp:156] Memory required for data: 622985600
I0625 20:16:44.328907 18821 layer_factory.hpp:77] Creating layer relu2_2
I0625 20:16:44.328910 18821 net.cpp:91] Creating Layer relu2_2
I0625 20:16:44.328913 18821 net.cpp:425] relu2_2 <- conv2_2
I0625 20:16:44.328917 18821 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0625 20:16:44.329349 18821 net.cpp:141] Setting up relu2_2
I0625 20:16:44.329360 18821 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:16:44.329363 18821 net.cpp:156] Memory required for data: 648675712
I0625 20:16:44.329377 18821 layer_factory.hpp:77] Creating layer pool2
I0625 20:16:44.329385 18821 net.cpp:91] Creating Layer pool2
I0625 20:16:44.329388 18821 net.cpp:425] pool2 <- conv2_2
I0625 20:16:44.329393 18821 net.cpp:399] pool2 -> pool2
I0625 20:16:44.329432 18821 net.cpp:141] Setting up pool2
I0625 20:16:44.329440 18821 net.cpp:148] Top shape: 32 64 25 32 (1638400)
I0625 20:16:44.329444 18821 net.cpp:156] Memory required for data: 655229312
I0625 20:16:44.329447 18821 layer_factory.hpp:77] Creating layer conv3_1
I0625 20:16:44.329457 18821 net.cpp:91] Creating Layer conv3_1
I0625 20:16:44.329459 18821 net.cpp:425] conv3_1 <- pool2
I0625 20:16:44.329463 18821 net.cpp:399] conv3_1 -> conv3_1
I0625 20:16:44.331850 18821 net.cpp:141] Setting up conv3_1
I0625 20:16:44.331863 18821 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:44.331867 18821 net.cpp:156] Memory required for data: 668336512
I0625 20:16:44.331871 18821 layer_factory.hpp:77] Creating layer bn3_1
I0625 20:16:44.331879 18821 net.cpp:91] Creating Layer bn3_1
I0625 20:16:44.331882 18821 net.cpp:425] bn3_1 <- conv3_1
I0625 20:16:44.331887 18821 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0625 20:16:44.333135 18821 net.cpp:141] Setting up bn3_1
I0625 20:16:44.333148 18821 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:44.333150 18821 net.cpp:156] Memory required for data: 681443712
I0625 20:16:44.333158 18821 layer_factory.hpp:77] Creating layer scale3_1
I0625 20:16:44.333164 18821 net.cpp:91] Creating Layer scale3_1
I0625 20:16:44.333168 18821 net.cpp:425] scale3_1 <- conv3_1
I0625 20:16:44.333173 18821 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0625 20:16:44.333209 18821 layer_factory.hpp:77] Creating layer scale3_1
I0625 20:16:44.333302 18821 net.cpp:141] Setting up scale3_1
I0625 20:16:44.333310 18821 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:44.333312 18821 net.cpp:156] Memory required for data: 694550912
I0625 20:16:44.333317 18821 layer_factory.hpp:77] Creating layer relu3_1
I0625 20:16:44.333322 18821 net.cpp:91] Creating Layer relu3_1
I0625 20:16:44.333324 18821 net.cpp:425] relu3_1 <- conv3_1
I0625 20:16:44.333330 18821 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0625 20:16:44.333474 18821 net.cpp:141] Setting up relu3_1
I0625 20:16:44.333484 18821 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:44.333487 18821 net.cpp:156] Memory required for data: 707658112
I0625 20:16:44.333489 18821 layer_factory.hpp:77] Creating layer conv3_2
I0625 20:16:44.333498 18821 net.cpp:91] Creating Layer conv3_2
I0625 20:16:44.333501 18821 net.cpp:425] conv3_2 <- conv3_1
I0625 20:16:44.333506 18821 net.cpp:399] conv3_2 -> conv3_2
I0625 20:16:44.335546 18821 net.cpp:141] Setting up conv3_2
I0625 20:16:44.335561 18821 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:44.335564 18821 net.cpp:156] Memory required for data: 720765312
I0625 20:16:44.335568 18821 layer_factory.hpp:77] Creating layer bn3_2
I0625 20:16:44.335577 18821 net.cpp:91] Creating Layer bn3_2
I0625 20:16:44.335579 18821 net.cpp:425] bn3_2 <- conv3_2
I0625 20:16:44.335583 18821 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0625 20:16:44.335748 18821 net.cpp:141] Setting up bn3_2
I0625 20:16:44.335755 18821 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:44.335758 18821 net.cpp:156] Memory required for data: 733872512
I0625 20:16:44.335769 18821 layer_factory.hpp:77] Creating layer scale3_2
I0625 20:16:44.335777 18821 net.cpp:91] Creating Layer scale3_2
I0625 20:16:44.335778 18821 net.cpp:425] scale3_2 <- conv3_2
I0625 20:16:44.335783 18821 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0625 20:16:44.335818 18821 layer_factory.hpp:77] Creating layer scale3_2
I0625 20:16:44.335928 18821 net.cpp:141] Setting up scale3_2
I0625 20:16:44.335940 18821 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:44.335944 18821 net.cpp:156] Memory required for data: 746979712
I0625 20:16:44.335953 18821 layer_factory.hpp:77] Creating layer relu3_2
I0625 20:16:44.335960 18821 net.cpp:91] Creating Layer relu3_2
I0625 20:16:44.335965 18821 net.cpp:425] relu3_2 <- conv3_2
I0625 20:16:44.335986 18821 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0625 20:16:44.336149 18821 net.cpp:141] Setting up relu3_2
I0625 20:16:44.336163 18821 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:16:44.336166 18821 net.cpp:156] Memory required for data: 760086912
I0625 20:16:44.336171 18821 layer_factory.hpp:77] Creating layer pool3
I0625 20:16:44.336182 18821 net.cpp:91] Creating Layer pool3
I0625 20:16:44.336189 18821 net.cpp:425] pool3 <- conv3_2
I0625 20:16:44.336195 18821 net.cpp:399] pool3 -> pool3
I0625 20:16:44.336244 18821 net.cpp:141] Setting up pool3
I0625 20:16:44.336253 18821 net.cpp:148] Top shape: 32 128 13 16 (851968)
I0625 20:16:44.336258 18821 net.cpp:156] Memory required for data: 763494784
I0625 20:16:44.336262 18821 layer_factory.hpp:77] Creating layer conv4_1
I0625 20:16:44.336275 18821 net.cpp:91] Creating Layer conv4_1
I0625 20:16:44.336280 18821 net.cpp:425] conv4_1 <- pool3
I0625 20:16:44.336288 18821 net.cpp:399] conv4_1 -> conv4_1
I0625 20:16:44.339416 18821 net.cpp:141] Setting up conv4_1
I0625 20:16:44.339475 18821 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:44.339483 18821 net.cpp:156] Memory required for data: 770310528
I0625 20:16:44.339493 18821 layer_factory.hpp:77] Creating layer bn4_1
I0625 20:16:44.339505 18821 net.cpp:91] Creating Layer bn4_1
I0625 20:16:44.339531 18821 net.cpp:425] bn4_1 <- conv4_1
I0625 20:16:44.339540 18821 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0625 20:16:44.339707 18821 net.cpp:141] Setting up bn4_1
I0625 20:16:44.339717 18821 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:44.339721 18821 net.cpp:156] Memory required for data: 777126272
I0625 20:16:44.339731 18821 layer_factory.hpp:77] Creating layer scale4_1
I0625 20:16:44.339743 18821 net.cpp:91] Creating Layer scale4_1
I0625 20:16:44.339748 18821 net.cpp:425] scale4_1 <- conv4_1
I0625 20:16:44.339756 18821 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0625 20:16:44.339803 18821 layer_factory.hpp:77] Creating layer scale4_1
I0625 20:16:44.339905 18821 net.cpp:141] Setting up scale4_1
I0625 20:16:44.339915 18821 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:44.339918 18821 net.cpp:156] Memory required for data: 783942016
I0625 20:16:44.339926 18821 layer_factory.hpp:77] Creating layer relu4_1
I0625 20:16:44.339941 18821 net.cpp:91] Creating Layer relu4_1
I0625 20:16:44.339946 18821 net.cpp:425] relu4_1 <- conv4_1
I0625 20:16:44.339952 18821 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0625 20:16:44.340111 18821 net.cpp:141] Setting up relu4_1
I0625 20:16:44.340122 18821 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:44.340126 18821 net.cpp:156] Memory required for data: 790757760
I0625 20:16:44.340131 18821 layer_factory.hpp:77] Creating layer conv4_2
I0625 20:16:44.340145 18821 net.cpp:91] Creating Layer conv4_2
I0625 20:16:44.340150 18821 net.cpp:425] conv4_2 <- conv4_1
I0625 20:16:44.340158 18821 net.cpp:399] conv4_2 -> conv4_2
I0625 20:16:44.345958 18821 net.cpp:141] Setting up conv4_2
I0625 20:16:44.345974 18821 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:44.345979 18821 net.cpp:156] Memory required for data: 797573504
I0625 20:16:44.345986 18821 layer_factory.hpp:77] Creating layer bn4_2
I0625 20:16:44.345999 18821 net.cpp:91] Creating Layer bn4_2
I0625 20:16:44.346004 18821 net.cpp:425] bn4_2 <- conv4_2
I0625 20:16:44.346012 18821 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0625 20:16:44.346177 18821 net.cpp:141] Setting up bn4_2
I0625 20:16:44.346189 18821 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:44.346192 18821 net.cpp:156] Memory required for data: 804389248
I0625 20:16:44.346202 18821 layer_factory.hpp:77] Creating layer scale4_2
I0625 20:16:44.346213 18821 net.cpp:91] Creating Layer scale4_2
I0625 20:16:44.346218 18821 net.cpp:425] scale4_2 <- conv4_2
I0625 20:16:44.346225 18821 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0625 20:16:44.346279 18821 layer_factory.hpp:77] Creating layer scale4_2
I0625 20:16:44.346380 18821 net.cpp:141] Setting up scale4_2
I0625 20:16:44.346401 18821 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:44.346406 18821 net.cpp:156] Memory required for data: 811204992
I0625 20:16:44.346415 18821 layer_factory.hpp:77] Creating layer relu4_2
I0625 20:16:44.346422 18821 net.cpp:91] Creating Layer relu4_2
I0625 20:16:44.346427 18821 net.cpp:425] relu4_2 <- conv4_2
I0625 20:16:44.346436 18821 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0625 20:16:44.346590 18821 net.cpp:141] Setting up relu4_2
I0625 20:16:44.346601 18821 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:16:44.346606 18821 net.cpp:156] Memory required for data: 818020736
I0625 20:16:44.346611 18821 layer_factory.hpp:77] Creating layer pool4
I0625 20:16:44.346618 18821 net.cpp:91] Creating Layer pool4
I0625 20:16:44.346623 18821 net.cpp:425] pool4 <- conv4_2
I0625 20:16:44.346632 18821 net.cpp:399] pool4 -> pool4
I0625 20:16:44.346680 18821 net.cpp:141] Setting up pool4
I0625 20:16:44.346689 18821 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:44.346693 18821 net.cpp:156] Memory required for data: 819855744
I0625 20:16:44.346698 18821 layer_factory.hpp:77] Creating layer conv5_1
I0625 20:16:44.346712 18821 net.cpp:91] Creating Layer conv5_1
I0625 20:16:44.346717 18821 net.cpp:425] conv5_1 <- pool4
I0625 20:16:44.346725 18821 net.cpp:399] conv5_1 -> conv5_1
I0625 20:16:44.352787 18821 net.cpp:141] Setting up conv5_1
I0625 20:16:44.352802 18821 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:44.352807 18821 net.cpp:156] Memory required for data: 821690752
I0625 20:16:44.352815 18821 layer_factory.hpp:77] Creating layer bn5_1
I0625 20:16:44.352826 18821 net.cpp:91] Creating Layer bn5_1
I0625 20:16:44.352831 18821 net.cpp:425] bn5_1 <- conv5_1
I0625 20:16:44.352838 18821 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0625 20:16:44.353004 18821 net.cpp:141] Setting up bn5_1
I0625 20:16:44.353015 18821 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:44.353019 18821 net.cpp:156] Memory required for data: 823525760
I0625 20:16:44.353029 18821 layer_factory.hpp:77] Creating layer scale5_1
I0625 20:16:44.353039 18821 net.cpp:91] Creating Layer scale5_1
I0625 20:16:44.353044 18821 net.cpp:425] scale5_1 <- conv5_1
I0625 20:16:44.353051 18821 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0625 20:16:44.353098 18821 layer_factory.hpp:77] Creating layer scale5_1
I0625 20:16:44.353198 18821 net.cpp:141] Setting up scale5_1
I0625 20:16:44.353207 18821 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:44.353211 18821 net.cpp:156] Memory required for data: 825360768
I0625 20:16:44.353219 18821 layer_factory.hpp:77] Creating layer relu5_1
I0625 20:16:44.353227 18821 net.cpp:91] Creating Layer relu5_1
I0625 20:16:44.353231 18821 net.cpp:425] relu5_1 <- conv5_1
I0625 20:16:44.353240 18821 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0625 20:16:44.353674 18821 net.cpp:141] Setting up relu5_1
I0625 20:16:44.353688 18821 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:44.353693 18821 net.cpp:156] Memory required for data: 827195776
I0625 20:16:44.353698 18821 layer_factory.hpp:77] Creating layer conv5_2
I0625 20:16:44.353711 18821 net.cpp:91] Creating Layer conv5_2
I0625 20:16:44.353718 18821 net.cpp:425] conv5_2 <- conv5_1
I0625 20:16:44.353726 18821 net.cpp:399] conv5_2 -> conv5_2
I0625 20:16:44.359261 18821 net.cpp:141] Setting up conv5_2
I0625 20:16:44.359277 18821 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:44.359280 18821 net.cpp:156] Memory required for data: 829030784
I0625 20:16:44.359289 18821 layer_factory.hpp:77] Creating layer bn5_2
I0625 20:16:44.359300 18821 net.cpp:91] Creating Layer bn5_2
I0625 20:16:44.359308 18821 net.cpp:425] bn5_2 <- conv5_2
I0625 20:16:44.359314 18821 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0625 20:16:44.359483 18821 net.cpp:141] Setting up bn5_2
I0625 20:16:44.359493 18821 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:44.359498 18821 net.cpp:156] Memory required for data: 830865792
I0625 20:16:44.359508 18821 layer_factory.hpp:77] Creating layer scale5_2
I0625 20:16:44.359519 18821 net.cpp:91] Creating Layer scale5_2
I0625 20:16:44.359537 18821 net.cpp:425] scale5_2 <- conv5_2
I0625 20:16:44.359546 18821 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0625 20:16:44.359591 18821 layer_factory.hpp:77] Creating layer scale5_2
I0625 20:16:44.359694 18821 net.cpp:141] Setting up scale5_2
I0625 20:16:44.359704 18821 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:44.359707 18821 net.cpp:156] Memory required for data: 832700800
I0625 20:16:44.359715 18821 layer_factory.hpp:77] Creating layer relu5_2
I0625 20:16:44.359725 18821 net.cpp:91] Creating Layer relu5_2
I0625 20:16:44.359730 18821 net.cpp:425] relu5_2 <- conv5_2
I0625 20:16:44.359736 18821 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0625 20:16:44.360158 18821 net.cpp:141] Setting up relu5_2
I0625 20:16:44.360172 18821 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:16:44.360177 18821 net.cpp:156] Memory required for data: 834535808
I0625 20:16:44.360183 18821 layer_factory.hpp:77] Creating layer pool5
I0625 20:16:44.360193 18821 net.cpp:91] Creating Layer pool5
I0625 20:16:44.360198 18821 net.cpp:425] pool5 <- conv5_2
I0625 20:16:44.360206 18821 net.cpp:399] pool5 -> pool5
I0625 20:16:44.360381 18821 net.cpp:141] Setting up pool5
I0625 20:16:44.360394 18821 net.cpp:148] Top shape: 32 256 2 1 (16384)
I0625 20:16:44.360397 18821 net.cpp:156] Memory required for data: 834601344
I0625 20:16:44.360402 18821 layer_factory.hpp:77] Creating layer fc2
I0625 20:16:44.360412 18821 net.cpp:91] Creating Layer fc2
I0625 20:16:44.360417 18821 net.cpp:425] fc2 <- pool5
I0625 20:16:44.360424 18821 net.cpp:399] fc2 -> fc2
I0625 20:16:44.360534 18821 net.cpp:141] Setting up fc2
I0625 20:16:44.360544 18821 net.cpp:148] Top shape: 32 2 (64)
I0625 20:16:44.360548 18821 net.cpp:156] Memory required for data: 834601600
I0625 20:16:44.360556 18821 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0625 20:16:44.360565 18821 net.cpp:91] Creating Layer fc2_fc2_0_split
I0625 20:16:44.360569 18821 net.cpp:425] fc2_fc2_0_split <- fc2
I0625 20:16:44.360577 18821 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0625 20:16:44.360586 18821 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0625 20:16:44.360626 18821 net.cpp:141] Setting up fc2_fc2_0_split
I0625 20:16:44.360637 18821 net.cpp:148] Top shape: 32 2 (64)
I0625 20:16:44.360642 18821 net.cpp:148] Top shape: 32 2 (64)
I0625 20:16:44.360646 18821 net.cpp:156] Memory required for data: 834602112
I0625 20:16:44.360651 18821 layer_factory.hpp:77] Creating layer loss
I0625 20:16:44.360664 18821 net.cpp:91] Creating Layer loss
I0625 20:16:44.360671 18821 net.cpp:425] loss <- fc2_fc2_0_split_0
I0625 20:16:44.360676 18821 net.cpp:425] loss <- label_data_1_split_0
I0625 20:16:44.360684 18821 net.cpp:399] loss -> loss
I0625 20:16:44.360697 18821 layer_factory.hpp:77] Creating layer loss
I0625 20:16:44.360929 18821 net.cpp:141] Setting up loss
I0625 20:16:44.360939 18821 net.cpp:148] Top shape: (1)
I0625 20:16:44.360944 18821 net.cpp:151]     with loss weight 1
I0625 20:16:44.360965 18821 net.cpp:156] Memory required for data: 834602116
I0625 20:16:44.360970 18821 layer_factory.hpp:77] Creating layer accuracy
I0625 20:16:44.360978 18821 net.cpp:91] Creating Layer accuracy
I0625 20:16:44.360983 18821 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0625 20:16:44.360991 18821 net.cpp:425] accuracy <- label_data_1_split_1
I0625 20:16:44.360997 18821 net.cpp:399] accuracy -> accuracy
I0625 20:16:44.361009 18821 net.cpp:141] Setting up accuracy
I0625 20:16:44.361016 18821 net.cpp:148] Top shape: (1)
I0625 20:16:44.361019 18821 net.cpp:156] Memory required for data: 834602120
I0625 20:16:44.361024 18821 net.cpp:219] accuracy does not need backward computation.
I0625 20:16:44.361029 18821 net.cpp:217] loss needs backward computation.
I0625 20:16:44.361034 18821 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0625 20:16:44.361038 18821 net.cpp:217] fc2 needs backward computation.
I0625 20:16:44.361042 18821 net.cpp:217] pool5 needs backward computation.
I0625 20:16:44.361045 18821 net.cpp:217] relu5_2 needs backward computation.
I0625 20:16:44.361049 18821 net.cpp:217] scale5_2 needs backward computation.
I0625 20:16:44.361063 18821 net.cpp:217] bn5_2 needs backward computation.
I0625 20:16:44.361068 18821 net.cpp:217] conv5_2 needs backward computation.
I0625 20:16:44.361071 18821 net.cpp:217] relu5_1 needs backward computation.
I0625 20:16:44.361075 18821 net.cpp:217] scale5_1 needs backward computation.
I0625 20:16:44.361079 18821 net.cpp:217] bn5_1 needs backward computation.
I0625 20:16:44.361083 18821 net.cpp:217] conv5_1 needs backward computation.
I0625 20:16:44.361088 18821 net.cpp:217] pool4 needs backward computation.
I0625 20:16:44.361091 18821 net.cpp:217] relu4_2 needs backward computation.
I0625 20:16:44.361095 18821 net.cpp:217] scale4_2 needs backward computation.
I0625 20:16:44.361099 18821 net.cpp:217] bn4_2 needs backward computation.
I0625 20:16:44.361104 18821 net.cpp:217] conv4_2 needs backward computation.
I0625 20:16:44.361107 18821 net.cpp:217] relu4_1 needs backward computation.
I0625 20:16:44.361111 18821 net.cpp:217] scale4_1 needs backward computation.
I0625 20:16:44.361115 18821 net.cpp:217] bn4_1 needs backward computation.
I0625 20:16:44.361119 18821 net.cpp:217] conv4_1 needs backward computation.
I0625 20:16:44.361124 18821 net.cpp:217] pool3 needs backward computation.
I0625 20:16:44.361129 18821 net.cpp:217] relu3_2 needs backward computation.
I0625 20:16:44.361131 18821 net.cpp:217] scale3_2 needs backward computation.
I0625 20:16:44.361135 18821 net.cpp:217] bn3_2 needs backward computation.
I0625 20:16:44.361140 18821 net.cpp:217] conv3_2 needs backward computation.
I0625 20:16:44.361143 18821 net.cpp:217] relu3_1 needs backward computation.
I0625 20:16:44.361147 18821 net.cpp:217] scale3_1 needs backward computation.
I0625 20:16:44.361151 18821 net.cpp:217] bn3_1 needs backward computation.
I0625 20:16:44.361155 18821 net.cpp:217] conv3_1 needs backward computation.
I0625 20:16:44.361160 18821 net.cpp:217] pool2 needs backward computation.
I0625 20:16:44.361165 18821 net.cpp:217] relu2_2 needs backward computation.
I0625 20:16:44.361167 18821 net.cpp:217] scale2_2 needs backward computation.
I0625 20:16:44.361171 18821 net.cpp:217] bn2_2 needs backward computation.
I0625 20:16:44.361176 18821 net.cpp:217] conv2_2 needs backward computation.
I0625 20:16:44.361179 18821 net.cpp:217] relu2_1 needs backward computation.
I0625 20:16:44.361183 18821 net.cpp:217] scale2_1 needs backward computation.
I0625 20:16:44.361187 18821 net.cpp:217] bn2_1 needs backward computation.
I0625 20:16:44.361191 18821 net.cpp:217] conv2_1 needs backward computation.
I0625 20:16:44.361196 18821 net.cpp:217] pool1 needs backward computation.
I0625 20:16:44.361199 18821 net.cpp:217] relu1_2 needs backward computation.
I0625 20:16:44.361203 18821 net.cpp:217] scale1_2 needs backward computation.
I0625 20:16:44.361207 18821 net.cpp:217] bn1_2 needs backward computation.
I0625 20:16:44.361212 18821 net.cpp:217] conv1_2 needs backward computation.
I0625 20:16:44.361215 18821 net.cpp:217] relu1_1 needs backward computation.
I0625 20:16:44.361222 18821 net.cpp:217] scale1_1 needs backward computation.
I0625 20:16:44.361225 18821 net.cpp:217] bn1_1 needs backward computation.
I0625 20:16:44.361229 18821 net.cpp:217] conv1_1 needs backward computation.
I0625 20:16:44.361234 18821 net.cpp:219] label_data_1_split does not need backward computation.
I0625 20:16:44.361238 18821 net.cpp:219] data does not need backward computation.
I0625 20:16:44.361243 18821 net.cpp:261] This network produces output accuracy
I0625 20:16:44.361246 18821 net.cpp:261] This network produces output loss
I0625 20:16:44.361277 18821 net.cpp:274] Network initialization done.
I0625 20:16:44.362140 18821 solver.cpp:181] Creating test net (#0) specified by net file: models/bpnet/train_val.prototxt
I0625 20:16:44.362205 18821 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0625 20:16:44.362450 18821 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 100
    crop_h: 196
    crop_w: 256
  }
  data_param {
    source: "data/val_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  pooling_param {
    pool: AVE
    stride: 1
    kernel_h: 6
    kernel_w: 8
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0625 20:16:44.362673 18821 layer_factory.hpp:77] Creating layer data
I0625 20:16:44.362969 18821 net.cpp:91] Creating Layer data
I0625 20:16:44.362982 18821 net.cpp:399] data -> data
I0625 20:16:44.362993 18821 net.cpp:399] data -> label
I0625 20:16:44.364233 18834 db_lmdb.cpp:35] Opened lmdb data/val_lmdb
I0625 20:16:44.364608 18821 data_layer.cpp:42] output data size: 64,3,196,256
I0625 20:16:44.444375 18821 net.cpp:141] Setting up data
I0625 20:16:44.444401 18821 net.cpp:148] Top shape: 64 3 196 256 (9633792)
I0625 20:16:44.444407 18821 net.cpp:148] Top shape: 64 (64)
I0625 20:16:44.444411 18821 net.cpp:156] Memory required for data: 38535424
I0625 20:16:44.444418 18821 layer_factory.hpp:77] Creating layer label_data_1_split
I0625 20:16:44.444433 18821 net.cpp:91] Creating Layer label_data_1_split
I0625 20:16:44.444438 18821 net.cpp:425] label_data_1_split <- label
I0625 20:16:44.444447 18821 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0625 20:16:44.444459 18821 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0625 20:16:44.444524 18821 net.cpp:141] Setting up label_data_1_split
I0625 20:16:44.444533 18821 net.cpp:148] Top shape: 64 (64)
I0625 20:16:44.444538 18821 net.cpp:148] Top shape: 64 (64)
I0625 20:16:44.444541 18821 net.cpp:156] Memory required for data: 38535936
I0625 20:16:44.444545 18821 layer_factory.hpp:77] Creating layer conv1_1
I0625 20:16:44.444562 18821 net.cpp:91] Creating Layer conv1_1
I0625 20:16:44.444567 18821 net.cpp:425] conv1_1 <- data
I0625 20:16:44.444576 18821 net.cpp:399] conv1_1 -> conv1_1
I0625 20:16:44.445636 18821 net.cpp:141] Setting up conv1_1
I0625 20:16:44.445652 18821 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:44.445657 18821 net.cpp:156] Memory required for data: 141296384
I0625 20:16:44.445667 18821 layer_factory.hpp:77] Creating layer bn1_1
I0625 20:16:44.445678 18821 net.cpp:91] Creating Layer bn1_1
I0625 20:16:44.445683 18821 net.cpp:425] bn1_1 <- conv1_1
I0625 20:16:44.445693 18821 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0625 20:16:44.448933 18821 net.cpp:141] Setting up bn1_1
I0625 20:16:44.448947 18821 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:44.448952 18821 net.cpp:156] Memory required for data: 244056832
I0625 20:16:44.448966 18821 layer_factory.hpp:77] Creating layer scale1_1
I0625 20:16:44.448981 18821 net.cpp:91] Creating Layer scale1_1
I0625 20:16:44.448987 18821 net.cpp:425] scale1_1 <- conv1_1
I0625 20:16:44.449009 18821 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0625 20:16:44.449123 18821 layer_factory.hpp:77] Creating layer scale1_1
I0625 20:16:44.449250 18821 net.cpp:141] Setting up scale1_1
I0625 20:16:44.449260 18821 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:44.449265 18821 net.cpp:156] Memory required for data: 346817280
I0625 20:16:44.449275 18821 layer_factory.hpp:77] Creating layer relu1_1
I0625 20:16:44.449287 18821 net.cpp:91] Creating Layer relu1_1
I0625 20:16:44.449292 18821 net.cpp:425] relu1_1 <- conv1_1
I0625 20:16:44.449300 18821 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0625 20:16:44.449461 18821 net.cpp:141] Setting up relu1_1
I0625 20:16:44.449473 18821 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:44.449478 18821 net.cpp:156] Memory required for data: 449577728
I0625 20:16:44.449482 18821 layer_factory.hpp:77] Creating layer conv1_2
I0625 20:16:44.449493 18821 net.cpp:91] Creating Layer conv1_2
I0625 20:16:44.449497 18821 net.cpp:425] conv1_2 <- conv1_1
I0625 20:16:44.449506 18821 net.cpp:399] conv1_2 -> conv1_2
I0625 20:16:44.450443 18821 net.cpp:141] Setting up conv1_2
I0625 20:16:44.450458 18821 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:44.450462 18821 net.cpp:156] Memory required for data: 552338176
I0625 20:16:44.450469 18821 layer_factory.hpp:77] Creating layer bn1_2
I0625 20:16:44.450481 18821 net.cpp:91] Creating Layer bn1_2
I0625 20:16:44.450486 18821 net.cpp:425] bn1_2 <- conv1_2
I0625 20:16:44.450494 18821 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0625 20:16:44.450666 18821 net.cpp:141] Setting up bn1_2
I0625 20:16:44.450676 18821 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:44.450680 18821 net.cpp:156] Memory required for data: 655098624
I0625 20:16:44.450692 18821 layer_factory.hpp:77] Creating layer scale1_2
I0625 20:16:44.450705 18821 net.cpp:91] Creating Layer scale1_2
I0625 20:16:44.450709 18821 net.cpp:425] scale1_2 <- conv1_2
I0625 20:16:44.450716 18821 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0625 20:16:44.450764 18821 layer_factory.hpp:77] Creating layer scale1_2
I0625 20:16:44.450892 18821 net.cpp:141] Setting up scale1_2
I0625 20:16:44.450902 18821 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:44.450906 18821 net.cpp:156] Memory required for data: 757859072
I0625 20:16:44.450914 18821 layer_factory.hpp:77] Creating layer relu1_2
I0625 20:16:44.450922 18821 net.cpp:91] Creating Layer relu1_2
I0625 20:16:44.450925 18821 net.cpp:425] relu1_2 <- conv1_2
I0625 20:16:44.450933 18821 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0625 20:16:44.451362 18821 net.cpp:141] Setting up relu1_2
I0625 20:16:44.451375 18821 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:16:44.451380 18821 net.cpp:156] Memory required for data: 860619520
I0625 20:16:44.451385 18821 layer_factory.hpp:77] Creating layer pool1
I0625 20:16:44.451396 18821 net.cpp:91] Creating Layer pool1
I0625 20:16:44.451401 18821 net.cpp:425] pool1 <- conv1_2
I0625 20:16:44.451408 18821 net.cpp:399] pool1 -> pool1
I0625 20:16:44.451460 18821 net.cpp:141] Setting up pool1
I0625 20:16:44.451470 18821 net.cpp:148] Top shape: 64 32 49 64 (6422528)
I0625 20:16:44.451473 18821 net.cpp:156] Memory required for data: 886309632
I0625 20:16:44.451478 18821 layer_factory.hpp:77] Creating layer conv2_1
I0625 20:16:44.451490 18821 net.cpp:91] Creating Layer conv2_1
I0625 20:16:44.451494 18821 net.cpp:425] conv2_1 <- pool1
I0625 20:16:44.451503 18821 net.cpp:399] conv2_1 -> conv2_1
I0625 20:16:44.452517 18821 net.cpp:141] Setting up conv2_1
I0625 20:16:44.452533 18821 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:44.452538 18821 net.cpp:156] Memory required for data: 937689856
I0625 20:16:44.452544 18821 layer_factory.hpp:77] Creating layer bn2_1
I0625 20:16:44.452553 18821 net.cpp:91] Creating Layer bn2_1
I0625 20:16:44.452558 18821 net.cpp:425] bn2_1 <- conv2_1
I0625 20:16:44.452566 18821 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0625 20:16:44.452739 18821 net.cpp:141] Setting up bn2_1
I0625 20:16:44.452759 18821 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:44.452762 18821 net.cpp:156] Memory required for data: 989070080
I0625 20:16:44.452772 18821 layer_factory.hpp:77] Creating layer scale2_1
I0625 20:16:44.452782 18821 net.cpp:91] Creating Layer scale2_1
I0625 20:16:44.452786 18821 net.cpp:425] scale2_1 <- conv2_1
I0625 20:16:44.452795 18821 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0625 20:16:44.452836 18821 layer_factory.hpp:77] Creating layer scale2_1
I0625 20:16:44.452950 18821 net.cpp:141] Setting up scale2_1
I0625 20:16:44.452960 18821 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:44.452963 18821 net.cpp:156] Memory required for data: 1040450304
I0625 20:16:44.452976 18821 layer_factory.hpp:77] Creating layer relu2_1
I0625 20:16:44.452985 18821 net.cpp:91] Creating Layer relu2_1
I0625 20:16:44.452988 18821 net.cpp:425] relu2_1 <- conv2_1
I0625 20:16:44.452996 18821 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0625 20:16:44.453150 18821 net.cpp:141] Setting up relu2_1
I0625 20:16:44.453161 18821 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:44.453164 18821 net.cpp:156] Memory required for data: 1091830528
I0625 20:16:44.453168 18821 layer_factory.hpp:77] Creating layer conv2_2
I0625 20:16:44.453181 18821 net.cpp:91] Creating Layer conv2_2
I0625 20:16:44.453186 18821 net.cpp:425] conv2_2 <- conv2_1
I0625 20:16:44.453194 18821 net.cpp:399] conv2_2 -> conv2_2
I0625 20:16:44.454267 18821 net.cpp:141] Setting up conv2_2
I0625 20:16:44.454280 18821 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:44.454285 18821 net.cpp:156] Memory required for data: 1143210752
I0625 20:16:44.454293 18821 layer_factory.hpp:77] Creating layer bn2_2
I0625 20:16:44.454304 18821 net.cpp:91] Creating Layer bn2_2
I0625 20:16:44.454309 18821 net.cpp:425] bn2_2 <- conv2_2
I0625 20:16:44.454318 18821 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0625 20:16:44.454484 18821 net.cpp:141] Setting up bn2_2
I0625 20:16:44.454494 18821 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:44.454499 18821 net.cpp:156] Memory required for data: 1194590976
I0625 20:16:44.454507 18821 layer_factory.hpp:77] Creating layer scale2_2
I0625 20:16:44.454519 18821 net.cpp:91] Creating Layer scale2_2
I0625 20:16:44.454524 18821 net.cpp:425] scale2_2 <- conv2_2
I0625 20:16:44.454530 18821 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0625 20:16:44.454573 18821 layer_factory.hpp:77] Creating layer scale2_2
I0625 20:16:44.454690 18821 net.cpp:141] Setting up scale2_2
I0625 20:16:44.454699 18821 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:44.454704 18821 net.cpp:156] Memory required for data: 1245971200
I0625 20:16:44.454710 18821 layer_factory.hpp:77] Creating layer relu2_2
I0625 20:16:44.454717 18821 net.cpp:91] Creating Layer relu2_2
I0625 20:16:44.454721 18821 net.cpp:425] relu2_2 <- conv2_2
I0625 20:16:44.454730 18821 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0625 20:16:44.454892 18821 net.cpp:141] Setting up relu2_2
I0625 20:16:44.454902 18821 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:16:44.454907 18821 net.cpp:156] Memory required for data: 1297351424
I0625 20:16:44.454911 18821 layer_factory.hpp:77] Creating layer pool2
I0625 20:16:44.454919 18821 net.cpp:91] Creating Layer pool2
I0625 20:16:44.454924 18821 net.cpp:425] pool2 <- conv2_2
I0625 20:16:44.454931 18821 net.cpp:399] pool2 -> pool2
I0625 20:16:44.454978 18821 net.cpp:141] Setting up pool2
I0625 20:16:44.454988 18821 net.cpp:148] Top shape: 64 64 25 32 (3276800)
I0625 20:16:44.454991 18821 net.cpp:156] Memory required for data: 1310458624
I0625 20:16:44.454995 18821 layer_factory.hpp:77] Creating layer conv3_1
I0625 20:16:44.455006 18821 net.cpp:91] Creating Layer conv3_1
I0625 20:16:44.455011 18821 net.cpp:425] conv3_1 <- pool2
I0625 20:16:44.455018 18821 net.cpp:399] conv3_1 -> conv3_1
I0625 20:16:44.457597 18821 net.cpp:141] Setting up conv3_1
I0625 20:16:44.457612 18821 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:44.457617 18821 net.cpp:156] Memory required for data: 1336673024
I0625 20:16:44.457638 18821 layer_factory.hpp:77] Creating layer bn3_1
I0625 20:16:44.457648 18821 net.cpp:91] Creating Layer bn3_1
I0625 20:16:44.457653 18821 net.cpp:425] bn3_1 <- conv3_1
I0625 20:16:44.457662 18821 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0625 20:16:44.457828 18821 net.cpp:141] Setting up bn3_1
I0625 20:16:44.457837 18821 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:44.457841 18821 net.cpp:156] Memory required for data: 1362887424
I0625 20:16:44.457850 18821 layer_factory.hpp:77] Creating layer scale3_1
I0625 20:16:44.457859 18821 net.cpp:91] Creating Layer scale3_1
I0625 20:16:44.457864 18821 net.cpp:425] scale3_1 <- conv3_1
I0625 20:16:44.457871 18821 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0625 20:16:44.457916 18821 layer_factory.hpp:77] Creating layer scale3_1
I0625 20:16:44.458024 18821 net.cpp:141] Setting up scale3_1
I0625 20:16:44.458034 18821 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:44.458037 18821 net.cpp:156] Memory required for data: 1389101824
I0625 20:16:44.458045 18821 layer_factory.hpp:77] Creating layer relu3_1
I0625 20:16:44.458052 18821 net.cpp:91] Creating Layer relu3_1
I0625 20:16:44.458056 18821 net.cpp:425] relu3_1 <- conv3_1
I0625 20:16:44.458065 18821 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0625 20:16:44.458215 18821 net.cpp:141] Setting up relu3_1
I0625 20:16:44.458226 18821 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:44.458230 18821 net.cpp:156] Memory required for data: 1415316224
I0625 20:16:44.458235 18821 layer_factory.hpp:77] Creating layer conv3_2
I0625 20:16:44.458247 18821 net.cpp:91] Creating Layer conv3_2
I0625 20:16:44.458252 18821 net.cpp:425] conv3_2 <- conv3_1
I0625 20:16:44.458261 18821 net.cpp:399] conv3_2 -> conv3_2
I0625 20:16:44.460201 18821 net.cpp:141] Setting up conv3_2
I0625 20:16:44.460216 18821 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:44.460219 18821 net.cpp:156] Memory required for data: 1441530624
I0625 20:16:44.460227 18821 layer_factory.hpp:77] Creating layer bn3_2
I0625 20:16:44.460237 18821 net.cpp:91] Creating Layer bn3_2
I0625 20:16:44.460242 18821 net.cpp:425] bn3_2 <- conv3_2
I0625 20:16:44.460248 18821 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0625 20:16:44.460418 18821 net.cpp:141] Setting up bn3_2
I0625 20:16:44.460429 18821 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:44.460433 18821 net.cpp:156] Memory required for data: 1467745024
I0625 20:16:44.460450 18821 layer_factory.hpp:77] Creating layer scale3_2
I0625 20:16:44.460464 18821 net.cpp:91] Creating Layer scale3_2
I0625 20:16:44.460471 18821 net.cpp:425] scale3_2 <- conv3_2
I0625 20:16:44.460479 18821 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0625 20:16:44.460525 18821 layer_factory.hpp:77] Creating layer scale3_2
I0625 20:16:44.460634 18821 net.cpp:141] Setting up scale3_2
I0625 20:16:44.460644 18821 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:44.460647 18821 net.cpp:156] Memory required for data: 1493959424
I0625 20:16:44.460654 18821 layer_factory.hpp:77] Creating layer relu3_2
I0625 20:16:44.460664 18821 net.cpp:91] Creating Layer relu3_2
I0625 20:16:44.460669 18821 net.cpp:425] relu3_2 <- conv3_2
I0625 20:16:44.460675 18821 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0625 20:16:44.460825 18821 net.cpp:141] Setting up relu3_2
I0625 20:16:44.460836 18821 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:16:44.460840 18821 net.cpp:156] Memory required for data: 1520173824
I0625 20:16:44.460844 18821 layer_factory.hpp:77] Creating layer pool3
I0625 20:16:44.460852 18821 net.cpp:91] Creating Layer pool3
I0625 20:16:44.460857 18821 net.cpp:425] pool3 <- conv3_2
I0625 20:16:44.460863 18821 net.cpp:399] pool3 -> pool3
I0625 20:16:44.460914 18821 net.cpp:141] Setting up pool3
I0625 20:16:44.460924 18821 net.cpp:148] Top shape: 64 128 13 16 (1703936)
I0625 20:16:44.460928 18821 net.cpp:156] Memory required for data: 1526989568
I0625 20:16:44.460932 18821 layer_factory.hpp:77] Creating layer conv4_1
I0625 20:16:44.460944 18821 net.cpp:91] Creating Layer conv4_1
I0625 20:16:44.460959 18821 net.cpp:425] conv4_1 <- pool3
I0625 20:16:44.460971 18821 net.cpp:399] conv4_1 -> conv4_1
I0625 20:16:44.463717 18821 net.cpp:141] Setting up conv4_1
I0625 20:16:44.463732 18821 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:44.463737 18821 net.cpp:156] Memory required for data: 1540621056
I0625 20:16:44.463743 18821 layer_factory.hpp:77] Creating layer bn4_1
I0625 20:16:44.463755 18821 net.cpp:91] Creating Layer bn4_1
I0625 20:16:44.463760 18821 net.cpp:425] bn4_1 <- conv4_1
I0625 20:16:44.463768 18821 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0625 20:16:44.463939 18821 net.cpp:141] Setting up bn4_1
I0625 20:16:44.463949 18821 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:44.463953 18821 net.cpp:156] Memory required for data: 1554252544
I0625 20:16:44.463963 18821 layer_factory.hpp:77] Creating layer scale4_1
I0625 20:16:44.463973 18821 net.cpp:91] Creating Layer scale4_1
I0625 20:16:44.463978 18821 net.cpp:425] scale4_1 <- conv4_1
I0625 20:16:44.463984 18821 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0625 20:16:44.464031 18821 layer_factory.hpp:77] Creating layer scale4_1
I0625 20:16:44.464135 18821 net.cpp:141] Setting up scale4_1
I0625 20:16:44.464144 18821 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:44.464148 18821 net.cpp:156] Memory required for data: 1567884032
I0625 20:16:44.464155 18821 layer_factory.hpp:77] Creating layer relu4_1
I0625 20:16:44.464169 18821 net.cpp:91] Creating Layer relu4_1
I0625 20:16:44.464174 18821 net.cpp:425] relu4_1 <- conv4_1
I0625 20:16:44.464180 18821 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0625 20:16:44.464332 18821 net.cpp:141] Setting up relu4_1
I0625 20:16:44.464344 18821 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:44.464347 18821 net.cpp:156] Memory required for data: 1581515520
I0625 20:16:44.464351 18821 layer_factory.hpp:77] Creating layer conv4_2
I0625 20:16:44.464365 18821 net.cpp:91] Creating Layer conv4_2
I0625 20:16:44.464370 18821 net.cpp:425] conv4_2 <- conv4_1
I0625 20:16:44.464377 18821 net.cpp:399] conv4_2 -> conv4_2
I0625 20:16:44.469924 18821 net.cpp:141] Setting up conv4_2
I0625 20:16:44.469939 18821 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:44.469944 18821 net.cpp:156] Memory required for data: 1595147008
I0625 20:16:44.469951 18821 layer_factory.hpp:77] Creating layer bn4_2
I0625 20:16:44.469964 18821 net.cpp:91] Creating Layer bn4_2
I0625 20:16:44.469969 18821 net.cpp:425] bn4_2 <- conv4_2
I0625 20:16:44.469976 18821 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0625 20:16:44.470154 18821 net.cpp:141] Setting up bn4_2
I0625 20:16:44.470165 18821 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:44.470168 18821 net.cpp:156] Memory required for data: 1608778496
I0625 20:16:44.470177 18821 layer_factory.hpp:77] Creating layer scale4_2
I0625 20:16:44.470187 18821 net.cpp:91] Creating Layer scale4_2
I0625 20:16:44.470191 18821 net.cpp:425] scale4_2 <- conv4_2
I0625 20:16:44.470197 18821 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0625 20:16:44.470248 18821 layer_factory.hpp:77] Creating layer scale4_2
I0625 20:16:44.470355 18821 net.cpp:141] Setting up scale4_2
I0625 20:16:44.470365 18821 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:44.470368 18821 net.cpp:156] Memory required for data: 1622409984
I0625 20:16:44.470376 18821 layer_factory.hpp:77] Creating layer relu4_2
I0625 20:16:44.470384 18821 net.cpp:91] Creating Layer relu4_2
I0625 20:16:44.470388 18821 net.cpp:425] relu4_2 <- conv4_2
I0625 20:16:44.470397 18821 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0625 20:16:44.470830 18821 net.cpp:141] Setting up relu4_2
I0625 20:16:44.470844 18821 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:16:44.470849 18821 net.cpp:156] Memory required for data: 1636041472
I0625 20:16:44.470854 18821 layer_factory.hpp:77] Creating layer pool4
I0625 20:16:44.470865 18821 net.cpp:91] Creating Layer pool4
I0625 20:16:44.470870 18821 net.cpp:425] pool4 <- conv4_2
I0625 20:16:44.470876 18821 net.cpp:399] pool4 -> pool4
I0625 20:16:44.470930 18821 net.cpp:141] Setting up pool4
I0625 20:16:44.470950 18821 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:44.470955 18821 net.cpp:156] Memory required for data: 1639711488
I0625 20:16:44.470959 18821 layer_factory.hpp:77] Creating layer conv5_1
I0625 20:16:44.470973 18821 net.cpp:91] Creating Layer conv5_1
I0625 20:16:44.470978 18821 net.cpp:425] conv5_1 <- pool4
I0625 20:16:44.470986 18821 net.cpp:399] conv5_1 -> conv5_1
I0625 20:16:44.476580 18821 net.cpp:141] Setting up conv5_1
I0625 20:16:44.476599 18821 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:44.476604 18821 net.cpp:156] Memory required for data: 1643381504
I0625 20:16:44.476611 18821 layer_factory.hpp:77] Creating layer bn5_1
I0625 20:16:44.476624 18821 net.cpp:91] Creating Layer bn5_1
I0625 20:16:44.476629 18821 net.cpp:425] bn5_1 <- conv5_1
I0625 20:16:44.476637 18821 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0625 20:16:44.476820 18821 net.cpp:141] Setting up bn5_1
I0625 20:16:44.476830 18821 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:44.476835 18821 net.cpp:156] Memory required for data: 1647051520
I0625 20:16:44.476845 18821 layer_factory.hpp:77] Creating layer scale5_1
I0625 20:16:44.476855 18821 net.cpp:91] Creating Layer scale5_1
I0625 20:16:44.476858 18821 net.cpp:425] scale5_1 <- conv5_1
I0625 20:16:44.476867 18821 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0625 20:16:44.476914 18821 layer_factory.hpp:77] Creating layer scale5_1
I0625 20:16:44.477022 18821 net.cpp:141] Setting up scale5_1
I0625 20:16:44.477032 18821 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:44.477036 18821 net.cpp:156] Memory required for data: 1650721536
I0625 20:16:44.477047 18821 layer_factory.hpp:77] Creating layer relu5_1
I0625 20:16:44.477056 18821 net.cpp:91] Creating Layer relu5_1
I0625 20:16:44.477059 18821 net.cpp:425] relu5_1 <- conv5_1
I0625 20:16:44.477069 18821 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0625 20:16:44.477229 18821 net.cpp:141] Setting up relu5_1
I0625 20:16:44.477241 18821 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:44.477246 18821 net.cpp:156] Memory required for data: 1654391552
I0625 20:16:44.477249 18821 layer_factory.hpp:77] Creating layer conv5_2
I0625 20:16:44.477262 18821 net.cpp:91] Creating Layer conv5_2
I0625 20:16:44.477267 18821 net.cpp:425] conv5_2 <- conv5_1
I0625 20:16:44.477277 18821 net.cpp:399] conv5_2 -> conv5_2
I0625 20:16:44.483335 18821 net.cpp:141] Setting up conv5_2
I0625 20:16:44.483355 18821 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:44.483361 18821 net.cpp:156] Memory required for data: 1658061568
I0625 20:16:44.483368 18821 layer_factory.hpp:77] Creating layer bn5_2
I0625 20:16:44.483381 18821 net.cpp:91] Creating Layer bn5_2
I0625 20:16:44.483387 18821 net.cpp:425] bn5_2 <- conv5_2
I0625 20:16:44.483397 18821 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0625 20:16:44.483584 18821 net.cpp:141] Setting up bn5_2
I0625 20:16:44.483595 18821 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:44.483599 18821 net.cpp:156] Memory required for data: 1661731584
I0625 20:16:44.483614 18821 layer_factory.hpp:77] Creating layer scale5_2
I0625 20:16:44.483625 18821 net.cpp:91] Creating Layer scale5_2
I0625 20:16:44.483630 18821 net.cpp:425] scale5_2 <- conv5_2
I0625 20:16:44.483639 18821 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0625 20:16:44.483687 18821 layer_factory.hpp:77] Creating layer scale5_2
I0625 20:16:44.483795 18821 net.cpp:141] Setting up scale5_2
I0625 20:16:44.483805 18821 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:44.483809 18821 net.cpp:156] Memory required for data: 1665401600
I0625 20:16:44.483816 18821 layer_factory.hpp:77] Creating layer relu5_2
I0625 20:16:44.483825 18821 net.cpp:91] Creating Layer relu5_2
I0625 20:16:44.483829 18821 net.cpp:425] relu5_2 <- conv5_2
I0625 20:16:44.483834 18821 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0625 20:16:44.483999 18821 net.cpp:141] Setting up relu5_2
I0625 20:16:44.484011 18821 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:16:44.484015 18821 net.cpp:156] Memory required for data: 1669071616
I0625 20:16:44.484040 18821 layer_factory.hpp:77] Creating layer pool5
I0625 20:16:44.484050 18821 net.cpp:91] Creating Layer pool5
I0625 20:16:44.484056 18821 net.cpp:425] pool5 <- conv5_2
I0625 20:16:44.484066 18821 net.cpp:399] pool5 -> pool5
I0625 20:16:44.484241 18821 net.cpp:141] Setting up pool5
I0625 20:16:44.484256 18821 net.cpp:148] Top shape: 64 256 2 1 (32768)
I0625 20:16:44.484261 18821 net.cpp:156] Memory required for data: 1669202688
I0625 20:16:44.484264 18821 layer_factory.hpp:77] Creating layer fc2
I0625 20:16:44.484272 18821 net.cpp:91] Creating Layer fc2
I0625 20:16:44.484277 18821 net.cpp:425] fc2 <- pool5
I0625 20:16:44.484282 18821 net.cpp:399] fc2 -> fc2
I0625 20:16:44.484443 18821 net.cpp:141] Setting up fc2
I0625 20:16:44.484455 18821 net.cpp:148] Top shape: 64 2 (128)
I0625 20:16:44.484459 18821 net.cpp:156] Memory required for data: 1669203200
I0625 20:16:44.484467 18821 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0625 20:16:44.484477 18821 net.cpp:91] Creating Layer fc2_fc2_0_split
I0625 20:16:44.484483 18821 net.cpp:425] fc2_fc2_0_split <- fc2
I0625 20:16:44.484489 18821 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0625 20:16:44.484498 18821 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0625 20:16:44.484544 18821 net.cpp:141] Setting up fc2_fc2_0_split
I0625 20:16:44.484552 18821 net.cpp:148] Top shape: 64 2 (128)
I0625 20:16:44.484557 18821 net.cpp:148] Top shape: 64 2 (128)
I0625 20:16:44.484561 18821 net.cpp:156] Memory required for data: 1669204224
I0625 20:16:44.484565 18821 layer_factory.hpp:77] Creating layer loss
I0625 20:16:44.484572 18821 net.cpp:91] Creating Layer loss
I0625 20:16:44.484577 18821 net.cpp:425] loss <- fc2_fc2_0_split_0
I0625 20:16:44.484582 18821 net.cpp:425] loss <- label_data_1_split_0
I0625 20:16:44.484591 18821 net.cpp:399] loss -> loss
I0625 20:16:44.484601 18821 layer_factory.hpp:77] Creating layer loss
I0625 20:16:44.485188 18821 net.cpp:141] Setting up loss
I0625 20:16:44.485201 18821 net.cpp:148] Top shape: (1)
I0625 20:16:44.485205 18821 net.cpp:151]     with loss weight 1
I0625 20:16:44.485219 18821 net.cpp:156] Memory required for data: 1669204228
I0625 20:16:44.485224 18821 layer_factory.hpp:77] Creating layer accuracy
I0625 20:16:44.485234 18821 net.cpp:91] Creating Layer accuracy
I0625 20:16:44.485239 18821 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0625 20:16:44.485244 18821 net.cpp:425] accuracy <- label_data_1_split_1
I0625 20:16:44.485250 18821 net.cpp:399] accuracy -> accuracy
I0625 20:16:44.485261 18821 net.cpp:141] Setting up accuracy
I0625 20:16:44.485267 18821 net.cpp:148] Top shape: (1)
I0625 20:16:44.485271 18821 net.cpp:156] Memory required for data: 1669204232
I0625 20:16:44.485276 18821 net.cpp:219] accuracy does not need backward computation.
I0625 20:16:44.485281 18821 net.cpp:217] loss needs backward computation.
I0625 20:16:44.485286 18821 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0625 20:16:44.485291 18821 net.cpp:217] fc2 needs backward computation.
I0625 20:16:44.485294 18821 net.cpp:217] pool5 needs backward computation.
I0625 20:16:44.485298 18821 net.cpp:217] relu5_2 needs backward computation.
I0625 20:16:44.485301 18821 net.cpp:217] scale5_2 needs backward computation.
I0625 20:16:44.485306 18821 net.cpp:217] bn5_2 needs backward computation.
I0625 20:16:44.485309 18821 net.cpp:217] conv5_2 needs backward computation.
I0625 20:16:44.485313 18821 net.cpp:217] relu5_1 needs backward computation.
I0625 20:16:44.485317 18821 net.cpp:217] scale5_1 needs backward computation.
I0625 20:16:44.485321 18821 net.cpp:217] bn5_1 needs backward computation.
I0625 20:16:44.485326 18821 net.cpp:217] conv5_1 needs backward computation.
I0625 20:16:44.485329 18821 net.cpp:217] pool4 needs backward computation.
I0625 20:16:44.485333 18821 net.cpp:217] relu4_2 needs backward computation.
I0625 20:16:44.485337 18821 net.cpp:217] scale4_2 needs backward computation.
I0625 20:16:44.485342 18821 net.cpp:217] bn4_2 needs backward computation.
I0625 20:16:44.485345 18821 net.cpp:217] conv4_2 needs backward computation.
I0625 20:16:44.485359 18821 net.cpp:217] relu4_1 needs backward computation.
I0625 20:16:44.485364 18821 net.cpp:217] scale4_1 needs backward computation.
I0625 20:16:44.485368 18821 net.cpp:217] bn4_1 needs backward computation.
I0625 20:16:44.485373 18821 net.cpp:217] conv4_1 needs backward computation.
I0625 20:16:44.485376 18821 net.cpp:217] pool3 needs backward computation.
I0625 20:16:44.485380 18821 net.cpp:217] relu3_2 needs backward computation.
I0625 20:16:44.485384 18821 net.cpp:217] scale3_2 needs backward computation.
I0625 20:16:44.485388 18821 net.cpp:217] bn3_2 needs backward computation.
I0625 20:16:44.485393 18821 net.cpp:217] conv3_2 needs backward computation.
I0625 20:16:44.485395 18821 net.cpp:217] relu3_1 needs backward computation.
I0625 20:16:44.485399 18821 net.cpp:217] scale3_1 needs backward computation.
I0625 20:16:44.485404 18821 net.cpp:217] bn3_1 needs backward computation.
I0625 20:16:44.485407 18821 net.cpp:217] conv3_1 needs backward computation.
I0625 20:16:44.485411 18821 net.cpp:217] pool2 needs backward computation.
I0625 20:16:44.485415 18821 net.cpp:217] relu2_2 needs backward computation.
I0625 20:16:44.485419 18821 net.cpp:217] scale2_2 needs backward computation.
I0625 20:16:44.485424 18821 net.cpp:217] bn2_2 needs backward computation.
I0625 20:16:44.485427 18821 net.cpp:217] conv2_2 needs backward computation.
I0625 20:16:44.485431 18821 net.cpp:217] relu2_1 needs backward computation.
I0625 20:16:44.485435 18821 net.cpp:217] scale2_1 needs backward computation.
I0625 20:16:44.485438 18821 net.cpp:217] bn2_1 needs backward computation.
I0625 20:16:44.485442 18821 net.cpp:217] conv2_1 needs backward computation.
I0625 20:16:44.485446 18821 net.cpp:217] pool1 needs backward computation.
I0625 20:16:44.485450 18821 net.cpp:217] relu1_2 needs backward computation.
I0625 20:16:44.485455 18821 net.cpp:217] scale1_2 needs backward computation.
I0625 20:16:44.485458 18821 net.cpp:217] bn1_2 needs backward computation.
I0625 20:16:44.485462 18821 net.cpp:217] conv1_2 needs backward computation.
I0625 20:16:44.485466 18821 net.cpp:217] relu1_1 needs backward computation.
I0625 20:16:44.485471 18821 net.cpp:217] scale1_1 needs backward computation.
I0625 20:16:44.485474 18821 net.cpp:217] bn1_1 needs backward computation.
I0625 20:16:44.485478 18821 net.cpp:217] conv1_1 needs backward computation.
I0625 20:16:44.485483 18821 net.cpp:219] label_data_1_split does not need backward computation.
I0625 20:16:44.485487 18821 net.cpp:219] data does not need backward computation.
I0625 20:16:44.485491 18821 net.cpp:261] This network produces output accuracy
I0625 20:16:44.485496 18821 net.cpp:261] This network produces output loss
I0625 20:16:44.485527 18821 net.cpp:274] Network initialization done.
I0625 20:16:44.485669 18821 solver.cpp:60] Solver scaffolding done.
I0625 20:16:44.487428 18821 caffe.cpp:209] Resuming from data/models/bpnet_iter_2000.solverstate
I0625 20:16:44.514314 18821 sgd_solver.cpp:318] SGDSolver: restoring history
I0625 20:16:44.522119 18821 caffe.cpp:219] Starting Optimization
I0625 20:16:44.522140 18821 solver.cpp:279] Solving BPnet
I0625 20:16:44.522145 18821 solver.cpp:280] Learning Rate Policy: step
I0625 20:16:44.524324 18821 solver.cpp:337] Iteration 2000, Testing net (#0)
I0625 20:16:47.409322 18821 solver.cpp:404]     Test net output #0: accuracy = 0.775146
I0625 20:16:47.409365 18821 solver.cpp:404]     Test net output #1: loss = 0.479114 (* 1 = 0.479114 loss)
I0625 20:16:47.493551 18821 solver.cpp:228] Iteration 2000, loss = 0.405715
I0625 20:16:47.493576 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:16:47.493583 18821 solver.cpp:244]     Train net output #1: loss = 0.405715 (* 1 = 0.405715 loss)
I0625 20:16:47.493594 18821 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0625 20:16:49.029983 18821 solver.cpp:228] Iteration 2020, loss = 0.455495
I0625 20:16:49.030009 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:16:49.030016 18821 solver.cpp:244]     Train net output #1: loss = 0.455495 (* 1 = 0.455495 loss)
I0625 20:16:49.030041 18821 sgd_solver.cpp:106] Iteration 2020, lr = 0.0001
I0625 20:16:50.609493 18821 solver.cpp:228] Iteration 2040, loss = 0.33224
I0625 20:16:50.609519 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:16:50.609526 18821 solver.cpp:244]     Train net output #1: loss = 0.33224 (* 1 = 0.33224 loss)
I0625 20:16:50.609530 18821 sgd_solver.cpp:106] Iteration 2040, lr = 0.0001
I0625 20:16:52.188627 18821 solver.cpp:228] Iteration 2060, loss = 0.361218
I0625 20:16:52.188652 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:16:52.188659 18821 solver.cpp:244]     Train net output #1: loss = 0.361218 (* 1 = 0.361218 loss)
I0625 20:16:52.188664 18821 sgd_solver.cpp:106] Iteration 2060, lr = 0.0001
I0625 20:16:53.768786 18821 solver.cpp:228] Iteration 2080, loss = 0.370158
I0625 20:16:53.768813 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:16:53.768821 18821 solver.cpp:244]     Train net output #1: loss = 0.370158 (* 1 = 0.370158 loss)
I0625 20:16:53.768826 18821 sgd_solver.cpp:106] Iteration 2080, lr = 0.0001
I0625 20:16:55.325209 18821 solver.cpp:337] Iteration 2100, Testing net (#0)
I0625 20:16:55.500742 18821 blocking_queue.cpp:50] Data layer prefetch queue empty
I0625 20:16:58.333962 18821 solver.cpp:404]     Test net output #0: accuracy = 0.789795
I0625 20:16:58.333995 18821 solver.cpp:404]     Test net output #1: loss = 0.468302 (* 1 = 0.468302 loss)
I0625 20:16:58.360797 18821 solver.cpp:228] Iteration 2100, loss = 0.348214
I0625 20:16:58.360823 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:16:58.360831 18821 solver.cpp:244]     Train net output #1: loss = 0.348214 (* 1 = 0.348214 loss)
I0625 20:16:58.360836 18821 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0625 20:16:59.950783 18821 solver.cpp:228] Iteration 2120, loss = 0.340887
I0625 20:16:59.950820 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:16:59.950829 18821 solver.cpp:244]     Train net output #1: loss = 0.340887 (* 1 = 0.340887 loss)
I0625 20:16:59.950834 18821 sgd_solver.cpp:106] Iteration 2120, lr = 0.0001
I0625 20:17:01.534154 18821 solver.cpp:228] Iteration 2140, loss = 0.37997
I0625 20:17:01.534190 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:17:01.534198 18821 solver.cpp:244]     Train net output #1: loss = 0.37997 (* 1 = 0.37997 loss)
I0625 20:17:01.534203 18821 sgd_solver.cpp:106] Iteration 2140, lr = 0.0001
I0625 20:17:03.151360 18821 solver.cpp:228] Iteration 2160, loss = 0.43144
I0625 20:17:03.151386 18821 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:17:03.151404 18821 solver.cpp:244]     Train net output #1: loss = 0.43144 (* 1 = 0.43144 loss)
I0625 20:17:03.151408 18821 sgd_solver.cpp:106] Iteration 2160, lr = 0.0001
I0625 20:17:04.759799 18821 solver.cpp:228] Iteration 2180, loss = 0.54044
I0625 20:17:04.759826 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:17:04.759835 18821 solver.cpp:244]     Train net output #1: loss = 0.54044 (* 1 = 0.54044 loss)
I0625 20:17:04.759838 18821 sgd_solver.cpp:106] Iteration 2180, lr = 0.0001
I0625 20:17:06.328655 18821 solver.cpp:337] Iteration 2200, Testing net (#0)
I0625 20:17:09.306838 18821 solver.cpp:404]     Test net output #0: accuracy = 0.788818
I0625 20:17:09.306869 18821 solver.cpp:404]     Test net output #1: loss = 0.467086 (* 1 = 0.467086 loss)
I0625 20:17:09.334339 18821 solver.cpp:228] Iteration 2200, loss = 0.384328
I0625 20:17:09.334367 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:17:09.334374 18821 solver.cpp:244]     Train net output #1: loss = 0.384328 (* 1 = 0.384328 loss)
I0625 20:17:09.334379 18821 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0625 20:17:10.935655 18821 solver.cpp:228] Iteration 2220, loss = 0.535138
I0625 20:17:10.935683 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:17:10.935691 18821 solver.cpp:244]     Train net output #1: loss = 0.535138 (* 1 = 0.535138 loss)
I0625 20:17:10.935695 18821 sgd_solver.cpp:106] Iteration 2220, lr = 0.0001
I0625 20:17:12.528218 18821 solver.cpp:228] Iteration 2240, loss = 0.463428
I0625 20:17:12.528257 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:17:12.528265 18821 solver.cpp:244]     Train net output #1: loss = 0.463428 (* 1 = 0.463428 loss)
I0625 20:17:12.528270 18821 sgd_solver.cpp:106] Iteration 2240, lr = 0.0001
I0625 20:17:14.116077 18821 solver.cpp:228] Iteration 2260, loss = 0.348263
I0625 20:17:14.116222 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:17:14.116233 18821 solver.cpp:244]     Train net output #1: loss = 0.348263 (* 1 = 0.348263 loss)
I0625 20:17:14.116238 18821 sgd_solver.cpp:106] Iteration 2260, lr = 0.0001
I0625 20:17:15.703501 18821 solver.cpp:228] Iteration 2280, loss = 0.524736
I0625 20:17:15.703537 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:17:15.703546 18821 solver.cpp:244]     Train net output #1: loss = 0.524736 (* 1 = 0.524736 loss)
I0625 20:17:15.703550 18821 sgd_solver.cpp:106] Iteration 2280, lr = 0.0001
I0625 20:17:17.268290 18821 solver.cpp:337] Iteration 2300, Testing net (#0)
I0625 20:17:20.138296 18821 solver.cpp:404]     Test net output #0: accuracy = 0.787598
I0625 20:17:20.138339 18821 solver.cpp:404]     Test net output #1: loss = 0.462181 (* 1 = 0.462181 loss)
I0625 20:17:20.165890 18821 solver.cpp:228] Iteration 2300, loss = 0.406601
I0625 20:17:20.165917 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:17:20.165925 18821 solver.cpp:244]     Train net output #1: loss = 0.406601 (* 1 = 0.406601 loss)
I0625 20:17:20.165928 18821 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0625 20:17:21.760768 18821 solver.cpp:228] Iteration 2320, loss = 0.371392
I0625 20:17:21.760804 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:17:21.760812 18821 solver.cpp:244]     Train net output #1: loss = 0.371392 (* 1 = 0.371392 loss)
I0625 20:17:21.760815 18821 sgd_solver.cpp:106] Iteration 2320, lr = 0.0001
I0625 20:17:23.353868 18821 solver.cpp:228] Iteration 2340, loss = 0.394631
I0625 20:17:23.353893 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:17:23.353910 18821 solver.cpp:244]     Train net output #1: loss = 0.394631 (* 1 = 0.394631 loss)
I0625 20:17:23.353915 18821 sgd_solver.cpp:106] Iteration 2340, lr = 0.0001
I0625 20:17:24.944809 18821 solver.cpp:228] Iteration 2360, loss = 0.44016
I0625 20:17:24.944834 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:17:24.944841 18821 solver.cpp:244]     Train net output #1: loss = 0.44016 (* 1 = 0.44016 loss)
I0625 20:17:24.944845 18821 sgd_solver.cpp:106] Iteration 2360, lr = 0.0001
I0625 20:17:26.537644 18821 solver.cpp:228] Iteration 2380, loss = 0.431168
I0625 20:17:26.537669 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:17:26.537678 18821 solver.cpp:244]     Train net output #1: loss = 0.431168 (* 1 = 0.431168 loss)
I0625 20:17:26.537683 18821 sgd_solver.cpp:106] Iteration 2380, lr = 0.0001
I0625 20:17:28.106230 18821 solver.cpp:337] Iteration 2400, Testing net (#0)
I0625 20:17:31.094096 18821 solver.cpp:404]     Test net output #0: accuracy = 0.778809
I0625 20:17:31.094127 18821 solver.cpp:404]     Test net output #1: loss = 0.468953 (* 1 = 0.468953 loss)
I0625 20:17:31.121878 18821 solver.cpp:228] Iteration 2400, loss = 0.602571
I0625 20:17:31.121907 18821 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 20:17:31.121915 18821 solver.cpp:244]     Train net output #1: loss = 0.602571 (* 1 = 0.602571 loss)
I0625 20:17:31.121920 18821 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0625 20:17:32.720666 18821 solver.cpp:228] Iteration 2420, loss = 0.437612
I0625 20:17:32.720696 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:17:32.720703 18821 solver.cpp:244]     Train net output #1: loss = 0.437612 (* 1 = 0.437612 loss)
I0625 20:17:32.720708 18821 sgd_solver.cpp:106] Iteration 2420, lr = 0.0001
I0625 20:17:34.312556 18821 solver.cpp:228] Iteration 2440, loss = 0.392962
I0625 20:17:34.312582 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:17:34.312590 18821 solver.cpp:244]     Train net output #1: loss = 0.392962 (* 1 = 0.392962 loss)
I0625 20:17:34.312594 18821 sgd_solver.cpp:106] Iteration 2440, lr = 0.0001
I0625 20:17:35.903661 18821 solver.cpp:228] Iteration 2460, loss = 0.486385
I0625 20:17:35.903689 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:17:35.903697 18821 solver.cpp:244]     Train net output #1: loss = 0.486385 (* 1 = 0.486385 loss)
I0625 20:17:35.903723 18821 sgd_solver.cpp:106] Iteration 2460, lr = 0.0001
I0625 20:17:37.495734 18821 solver.cpp:228] Iteration 2480, loss = 0.311546
I0625 20:17:37.495760 18821 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 20:17:37.495767 18821 solver.cpp:244]     Train net output #1: loss = 0.311546 (* 1 = 0.311546 loss)
I0625 20:17:37.495772 18821 sgd_solver.cpp:106] Iteration 2480, lr = 0.0001
I0625 20:17:39.063951 18821 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_2500.caffemodel
I0625 20:17:39.087671 18821 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_2500.solverstate
I0625 20:17:39.098558 18821 solver.cpp:337] Iteration 2500, Testing net (#0)
I0625 20:17:42.071460 18821 solver.cpp:404]     Test net output #0: accuracy = 0.781006
I0625 20:17:42.071491 18821 solver.cpp:404]     Test net output #1: loss = 0.46393 (* 1 = 0.46393 loss)
I0625 20:17:42.098381 18821 solver.cpp:228] Iteration 2500, loss = 0.298961
I0625 20:17:42.098410 18821 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0625 20:17:42.098417 18821 solver.cpp:244]     Train net output #1: loss = 0.298961 (* 1 = 0.298961 loss)
I0625 20:17:42.098423 18821 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0625 20:17:43.702785 18821 solver.cpp:228] Iteration 2520, loss = 0.449305
I0625 20:17:43.702816 18821 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:17:43.702823 18821 solver.cpp:244]     Train net output #1: loss = 0.449305 (* 1 = 0.449305 loss)
I0625 20:17:43.702828 18821 sgd_solver.cpp:106] Iteration 2520, lr = 0.0001
I0625 20:17:45.297341 18821 solver.cpp:228] Iteration 2540, loss = 0.311484
I0625 20:17:45.297443 18821 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 20:17:45.297452 18821 solver.cpp:244]     Train net output #1: loss = 0.311484 (* 1 = 0.311484 loss)
I0625 20:17:45.297457 18821 sgd_solver.cpp:106] Iteration 2540, lr = 0.0001
I0625 20:17:46.890971 18821 solver.cpp:228] Iteration 2560, loss = 0.491552
I0625 20:17:46.890997 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:17:46.891005 18821 solver.cpp:244]     Train net output #1: loss = 0.491552 (* 1 = 0.491552 loss)
I0625 20:17:46.891010 18821 sgd_solver.cpp:106] Iteration 2560, lr = 0.0001
I0625 20:17:48.484544 18821 solver.cpp:228] Iteration 2580, loss = 0.364416
I0625 20:17:48.484570 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:17:48.484577 18821 solver.cpp:244]     Train net output #1: loss = 0.364416 (* 1 = 0.364416 loss)
I0625 20:17:48.484582 18821 sgd_solver.cpp:106] Iteration 2580, lr = 0.0001
I0625 20:17:50.054322 18821 solver.cpp:337] Iteration 2600, Testing net (#0)
I0625 20:17:53.004866 18821 solver.cpp:404]     Test net output #0: accuracy = 0.773926
I0625 20:17:53.004905 18821 solver.cpp:404]     Test net output #1: loss = 0.47002 (* 1 = 0.47002 loss)
I0625 20:17:53.032542 18821 solver.cpp:228] Iteration 2600, loss = 0.442617
I0625 20:17:53.032574 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:17:53.032585 18821 solver.cpp:244]     Train net output #1: loss = 0.442617 (* 1 = 0.442617 loss)
I0625 20:17:53.032593 18821 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0625 20:17:54.635233 18821 solver.cpp:228] Iteration 2620, loss = 0.533104
I0625 20:17:54.635262 18821 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:17:54.635269 18821 solver.cpp:244]     Train net output #1: loss = 0.533104 (* 1 = 0.533104 loss)
I0625 20:17:54.635274 18821 sgd_solver.cpp:106] Iteration 2620, lr = 0.0001
I0625 20:17:56.229701 18821 solver.cpp:228] Iteration 2640, loss = 0.392413
I0625 20:17:56.229728 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:17:56.229735 18821 solver.cpp:244]     Train net output #1: loss = 0.392413 (* 1 = 0.392413 loss)
I0625 20:17:56.229740 18821 sgd_solver.cpp:106] Iteration 2640, lr = 0.0001
I0625 20:17:57.823674 18821 solver.cpp:228] Iteration 2660, loss = 0.492177
I0625 20:17:57.823711 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:17:57.823719 18821 solver.cpp:244]     Train net output #1: loss = 0.492177 (* 1 = 0.492177 loss)
I0625 20:17:57.823724 18821 sgd_solver.cpp:106] Iteration 2660, lr = 0.0001
I0625 20:17:59.418437 18821 solver.cpp:228] Iteration 2680, loss = 0.541442
I0625 20:17:59.418473 18821 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 20:17:59.418480 18821 solver.cpp:244]     Train net output #1: loss = 0.541442 (* 1 = 0.541442 loss)
I0625 20:17:59.418485 18821 sgd_solver.cpp:106] Iteration 2680, lr = 0.0001
I0625 20:18:00.991173 18821 solver.cpp:337] Iteration 2700, Testing net (#0)
I0625 20:18:03.953538 18821 solver.cpp:404]     Test net output #0: accuracy = 0.783936
I0625 20:18:03.953570 18821 solver.cpp:404]     Test net output #1: loss = 0.47158 (* 1 = 0.47158 loss)
I0625 20:18:03.981202 18821 solver.cpp:228] Iteration 2700, loss = 0.58475
I0625 20:18:03.981230 18821 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:18:03.981238 18821 solver.cpp:244]     Train net output #1: loss = 0.58475 (* 1 = 0.58475 loss)
I0625 20:18:03.981243 18821 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0625 20:18:05.584034 18821 solver.cpp:228] Iteration 2720, loss = 0.445268
I0625 20:18:05.584064 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:18:05.584071 18821 solver.cpp:244]     Train net output #1: loss = 0.445268 (* 1 = 0.445268 loss)
I0625 20:18:05.584076 18821 sgd_solver.cpp:106] Iteration 2720, lr = 0.0001
I0625 20:18:07.179265 18821 solver.cpp:228] Iteration 2740, loss = 0.48928
I0625 20:18:07.179292 18821 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 20:18:07.179311 18821 solver.cpp:244]     Train net output #1: loss = 0.48928 (* 1 = 0.48928 loss)
I0625 20:18:07.179340 18821 sgd_solver.cpp:106] Iteration 2740, lr = 0.0001
I0625 20:18:08.775766 18821 solver.cpp:228] Iteration 2760, loss = 0.366442
I0625 20:18:08.775794 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:18:08.775802 18821 solver.cpp:244]     Train net output #1: loss = 0.366442 (* 1 = 0.366442 loss)
I0625 20:18:08.775807 18821 sgd_solver.cpp:106] Iteration 2760, lr = 0.0001
I0625 20:18:10.391249 18821 solver.cpp:228] Iteration 2780, loss = 0.376528
I0625 20:18:10.391275 18821 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 20:18:10.391283 18821 solver.cpp:244]     Train net output #1: loss = 0.376528 (* 1 = 0.376528 loss)
I0625 20:18:10.391288 18821 sgd_solver.cpp:106] Iteration 2780, lr = 0.0001
I0625 20:18:11.990892 18821 solver.cpp:337] Iteration 2800, Testing net (#0)
I0625 20:18:15.001165 18821 solver.cpp:404]     Test net output #0: accuracy = 0.787109
I0625 20:18:15.001204 18821 solver.cpp:404]     Test net output #1: loss = 0.465145 (* 1 = 0.465145 loss)
I0625 20:18:15.028941 18821 solver.cpp:228] Iteration 2800, loss = 0.579147
I0625 20:18:15.028970 18821 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:18:15.028976 18821 solver.cpp:244]     Train net output #1: loss = 0.579147 (* 1 = 0.579147 loss)
I0625 20:18:15.028982 18821 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0625 20:18:16.639173 18821 solver.cpp:228] Iteration 2820, loss = 0.388907
I0625 20:18:16.639292 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:18:16.639302 18821 solver.cpp:244]     Train net output #1: loss = 0.388907 (* 1 = 0.388907 loss)
I0625 20:18:16.639307 18821 sgd_solver.cpp:106] Iteration 2820, lr = 0.0001
I0625 20:18:18.240926 18821 solver.cpp:228] Iteration 2840, loss = 0.393552
I0625 20:18:18.240964 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:18:18.240972 18821 solver.cpp:244]     Train net output #1: loss = 0.393552 (* 1 = 0.393552 loss)
I0625 20:18:18.240977 18821 sgd_solver.cpp:106] Iteration 2840, lr = 0.0001
I0625 20:18:19.853585 18821 solver.cpp:228] Iteration 2860, loss = 0.263701
I0625 20:18:19.853618 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:18:19.853629 18821 solver.cpp:244]     Train net output #1: loss = 0.263701 (* 1 = 0.263701 loss)
I0625 20:18:19.853636 18821 sgd_solver.cpp:106] Iteration 2860, lr = 0.0001
I0625 20:18:21.489657 18821 solver.cpp:228] Iteration 2880, loss = 0.369116
I0625 20:18:21.489687 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:18:21.489697 18821 solver.cpp:244]     Train net output #1: loss = 0.369116 (* 1 = 0.369116 loss)
I0625 20:18:21.489704 18821 sgd_solver.cpp:106] Iteration 2880, lr = 0.0001
I0625 20:18:23.086545 18821 solver.cpp:337] Iteration 2900, Testing net (#0)
I0625 20:18:26.087766 18821 solver.cpp:404]     Test net output #0: accuracy = 0.781006
I0625 20:18:26.087800 18821 solver.cpp:404]     Test net output #1: loss = 0.469545 (* 1 = 0.469545 loss)
I0625 20:18:26.115502 18821 solver.cpp:228] Iteration 2900, loss = 0.51928
I0625 20:18:26.115535 18821 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:18:26.115546 18821 solver.cpp:244]     Train net output #1: loss = 0.51928 (* 1 = 0.51928 loss)
I0625 20:18:26.115553 18821 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0625 20:18:27.724351 18821 solver.cpp:228] Iteration 2920, loss = 0.448983
I0625 20:18:27.724378 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:18:27.724388 18821 solver.cpp:244]     Train net output #1: loss = 0.448983 (* 1 = 0.448983 loss)
I0625 20:18:27.724395 18821 sgd_solver.cpp:106] Iteration 2920, lr = 0.0001
I0625 20:18:29.325711 18821 solver.cpp:228] Iteration 2940, loss = 0.482891
I0625 20:18:29.325739 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:18:29.325749 18821 solver.cpp:244]     Train net output #1: loss = 0.482891 (* 1 = 0.482891 loss)
I0625 20:18:29.325757 18821 sgd_solver.cpp:106] Iteration 2940, lr = 0.0001
I0625 20:18:30.958219 18821 solver.cpp:228] Iteration 2960, loss = 0.443648
I0625 20:18:30.958246 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:18:30.958257 18821 solver.cpp:244]     Train net output #1: loss = 0.443648 (* 1 = 0.443648 loss)
I0625 20:18:30.958264 18821 sgd_solver.cpp:106] Iteration 2960, lr = 0.0001
I0625 20:18:32.655266 18821 solver.cpp:228] Iteration 2980, loss = 0.462642
I0625 20:18:32.655292 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:18:32.655303 18821 solver.cpp:244]     Train net output #1: loss = 0.462642 (* 1 = 0.462642 loss)
I0625 20:18:32.655310 18821 sgd_solver.cpp:106] Iteration 2980, lr = 0.0001
I0625 20:18:34.387060 18821 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_3000.caffemodel
I0625 20:18:34.408354 18821 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_3000.solverstate
I0625 20:18:34.419505 18821 solver.cpp:337] Iteration 3000, Testing net (#0)
I0625 20:18:37.448160 18821 solver.cpp:404]     Test net output #0: accuracy = 0.791504
I0625 20:18:37.448195 18821 solver.cpp:404]     Test net output #1: loss = 0.470152 (* 1 = 0.470152 loss)
I0625 20:18:37.476100 18821 solver.cpp:228] Iteration 3000, loss = 0.449291
I0625 20:18:37.476130 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:18:37.476140 18821 solver.cpp:244]     Train net output #1: loss = 0.449291 (* 1 = 0.449291 loss)
I0625 20:18:37.476169 18821 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0625 20:18:39.094383 18821 solver.cpp:228] Iteration 3020, loss = 0.436007
I0625 20:18:39.094419 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:18:39.094430 18821 solver.cpp:244]     Train net output #1: loss = 0.436007 (* 1 = 0.436007 loss)
I0625 20:18:39.094437 18821 sgd_solver.cpp:106] Iteration 3020, lr = 0.0001
I0625 20:18:40.720065 18821 solver.cpp:228] Iteration 3040, loss = 0.524534
I0625 20:18:40.720093 18821 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:18:40.720103 18821 solver.cpp:244]     Train net output #1: loss = 0.524534 (* 1 = 0.524534 loss)
I0625 20:18:40.720110 18821 sgd_solver.cpp:106] Iteration 3040, lr = 0.0001
I0625 20:18:42.327808 18821 solver.cpp:228] Iteration 3060, loss = 0.490966
I0625 20:18:42.327836 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:18:42.327846 18821 solver.cpp:244]     Train net output #1: loss = 0.490966 (* 1 = 0.490966 loss)
I0625 20:18:42.327852 18821 sgd_solver.cpp:106] Iteration 3060, lr = 0.0001
I0625 20:18:43.926197 18821 solver.cpp:228] Iteration 3080, loss = 0.414001
I0625 20:18:43.926223 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:18:43.926232 18821 solver.cpp:244]     Train net output #1: loss = 0.414001 (* 1 = 0.414001 loss)
I0625 20:18:43.926239 18821 sgd_solver.cpp:106] Iteration 3080, lr = 0.0001
I0625 20:18:45.500336 18821 solver.cpp:337] Iteration 3100, Testing net (#0)
I0625 20:18:48.498813 18821 solver.cpp:404]     Test net output #0: accuracy = 0.776123
I0625 20:18:48.498968 18821 solver.cpp:404]     Test net output #1: loss = 0.468155 (* 1 = 0.468155 loss)
I0625 20:18:48.526695 18821 solver.cpp:228] Iteration 3100, loss = 0.365715
I0625 20:18:48.526721 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:18:48.526732 18821 solver.cpp:244]     Train net output #1: loss = 0.365715 (* 1 = 0.365715 loss)
I0625 20:18:48.526739 18821 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0625 20:18:50.132117 18821 solver.cpp:228] Iteration 3120, loss = 0.457573
I0625 20:18:50.132146 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:18:50.132156 18821 solver.cpp:244]     Train net output #1: loss = 0.457573 (* 1 = 0.457573 loss)
I0625 20:18:50.132164 18821 sgd_solver.cpp:106] Iteration 3120, lr = 0.0001
I0625 20:18:51.741750 18821 solver.cpp:228] Iteration 3140, loss = 0.392559
I0625 20:18:51.741783 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:18:51.741794 18821 solver.cpp:244]     Train net output #1: loss = 0.392559 (* 1 = 0.392559 loss)
I0625 20:18:51.741801 18821 sgd_solver.cpp:106] Iteration 3140, lr = 0.0001
I0625 20:18:53.376083 18821 solver.cpp:228] Iteration 3160, loss = 0.437876
I0625 20:18:53.376111 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:18:53.376121 18821 solver.cpp:244]     Train net output #1: loss = 0.437876 (* 1 = 0.437876 loss)
I0625 20:18:53.376128 18821 sgd_solver.cpp:106] Iteration 3160, lr = 0.0001
I0625 20:18:55.013609 18821 solver.cpp:228] Iteration 3180, loss = 0.543469
I0625 20:18:55.013638 18821 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 20:18:55.013648 18821 solver.cpp:244]     Train net output #1: loss = 0.543469 (* 1 = 0.543469 loss)
I0625 20:18:55.013653 18821 sgd_solver.cpp:106] Iteration 3180, lr = 0.0001
I0625 20:18:56.663614 18821 solver.cpp:337] Iteration 3200, Testing net (#0)
I0625 20:18:59.755498 18821 solver.cpp:404]     Test net output #0: accuracy = 0.788574
I0625 20:18:59.755532 18821 solver.cpp:404]     Test net output #1: loss = 0.46548 (* 1 = 0.46548 loss)
I0625 20:18:59.784828 18821 solver.cpp:228] Iteration 3200, loss = 0.420467
I0625 20:18:59.784858 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:18:59.784868 18821 solver.cpp:244]     Train net output #1: loss = 0.420467 (* 1 = 0.420467 loss)
I0625 20:18:59.784875 18821 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0625 20:19:01.432051 18821 solver.cpp:228] Iteration 3220, loss = 0.229276
I0625 20:19:01.432077 18821 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0625 20:19:01.432087 18821 solver.cpp:244]     Train net output #1: loss = 0.229276 (* 1 = 0.229276 loss)
I0625 20:19:01.432095 18821 sgd_solver.cpp:106] Iteration 3220, lr = 0.0001
I0625 20:19:03.044761 18821 solver.cpp:228] Iteration 3240, loss = 0.375344
I0625 20:19:03.044788 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:19:03.044798 18821 solver.cpp:244]     Train net output #1: loss = 0.375344 (* 1 = 0.375344 loss)
I0625 20:19:03.044806 18821 sgd_solver.cpp:106] Iteration 3240, lr = 0.0001
I0625 20:19:04.642256 18821 solver.cpp:228] Iteration 3260, loss = 0.365966
I0625 20:19:04.642283 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:19:04.642293 18821 solver.cpp:244]     Train net output #1: loss = 0.365966 (* 1 = 0.365966 loss)
I0625 20:19:04.642300 18821 sgd_solver.cpp:106] Iteration 3260, lr = 0.0001
I0625 20:19:06.239553 18821 solver.cpp:228] Iteration 3280, loss = 0.320556
I0625 20:19:06.239580 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:19:06.239590 18821 solver.cpp:244]     Train net output #1: loss = 0.320556 (* 1 = 0.320556 loss)
I0625 20:19:06.239598 18821 sgd_solver.cpp:106] Iteration 3280, lr = 0.0001
I0625 20:19:07.812985 18821 solver.cpp:337] Iteration 3300, Testing net (#0)
I0625 20:19:10.776618 18821 solver.cpp:404]     Test net output #0: accuracy = 0.792969
I0625 20:19:10.776649 18821 solver.cpp:404]     Test net output #1: loss = 0.461012 (* 1 = 0.461012 loss)
I0625 20:19:10.804610 18821 solver.cpp:228] Iteration 3300, loss = 0.264303
I0625 20:19:10.804638 18821 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0625 20:19:10.804648 18821 solver.cpp:244]     Train net output #1: loss = 0.264303 (* 1 = 0.264303 loss)
I0625 20:19:10.804656 18821 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0625 20:19:12.411880 18821 solver.cpp:228] Iteration 3320, loss = 0.410383
I0625 20:19:12.411908 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:19:12.411919 18821 solver.cpp:244]     Train net output #1: loss = 0.410383 (* 1 = 0.410383 loss)
I0625 20:19:12.411926 18821 sgd_solver.cpp:106] Iteration 3320, lr = 0.0001
I0625 20:19:14.012295 18821 solver.cpp:228] Iteration 3340, loss = 0.596761
I0625 20:19:14.012320 18821 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:19:14.012331 18821 solver.cpp:244]     Train net output #1: loss = 0.596761 (* 1 = 0.596761 loss)
I0625 20:19:14.012337 18821 sgd_solver.cpp:106] Iteration 3340, lr = 0.0001
I0625 20:19:15.613324 18821 solver.cpp:228] Iteration 3360, loss = 0.556985
I0625 20:19:15.613351 18821 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0625 20:19:15.613363 18821 solver.cpp:244]     Train net output #1: loss = 0.556985 (* 1 = 0.556985 loss)
I0625 20:19:15.613369 18821 sgd_solver.cpp:106] Iteration 3360, lr = 0.0001
I0625 20:19:17.214303 18821 solver.cpp:228] Iteration 3380, loss = 0.405
I0625 20:19:17.214329 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:19:17.214339 18821 solver.cpp:244]     Train net output #1: loss = 0.405 (* 1 = 0.405 loss)
I0625 20:19:17.214344 18821 sgd_solver.cpp:106] Iteration 3380, lr = 0.0001
I0625 20:19:18.793349 18821 solver.cpp:337] Iteration 3400, Testing net (#0)
I0625 20:19:21.808307 18821 solver.cpp:404]     Test net output #0: accuracy = 0.787842
I0625 20:19:21.808337 18821 solver.cpp:404]     Test net output #1: loss = 0.460764 (* 1 = 0.460764 loss)
I0625 20:19:21.836117 18821 solver.cpp:228] Iteration 3400, loss = 0.370572
I0625 20:19:21.836141 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:19:21.836149 18821 solver.cpp:244]     Train net output #1: loss = 0.370572 (* 1 = 0.370572 loss)
I0625 20:19:21.836154 18821 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0625 20:19:23.445757 18821 solver.cpp:228] Iteration 3420, loss = 0.391404
I0625 20:19:23.445793 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:19:23.445801 18821 solver.cpp:244]     Train net output #1: loss = 0.391404 (* 1 = 0.391404 loss)
I0625 20:19:23.445806 18821 sgd_solver.cpp:106] Iteration 3420, lr = 0.0001
I0625 20:19:25.045920 18821 solver.cpp:228] Iteration 3440, loss = 0.396507
I0625 20:19:25.045945 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:19:25.045964 18821 solver.cpp:244]     Train net output #1: loss = 0.396507 (* 1 = 0.396507 loss)
I0625 20:19:25.045969 18821 sgd_solver.cpp:106] Iteration 3440, lr = 0.0001
I0625 20:19:26.646527 18821 solver.cpp:228] Iteration 3460, loss = 0.374657
I0625 20:19:26.646553 18821 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 20:19:26.646561 18821 solver.cpp:244]     Train net output #1: loss = 0.374657 (* 1 = 0.374657 loss)
I0625 20:19:26.646566 18821 sgd_solver.cpp:106] Iteration 3460, lr = 0.0001
I0625 20:19:28.245813 18821 solver.cpp:228] Iteration 3480, loss = 0.400257
I0625 20:19:28.245849 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:19:28.245857 18821 solver.cpp:244]     Train net output #1: loss = 0.400257 (* 1 = 0.400257 loss)
I0625 20:19:28.245862 18821 sgd_solver.cpp:106] Iteration 3480, lr = 0.0001
I0625 20:19:29.822232 18821 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_3500.caffemodel
I0625 20:19:29.842401 18821 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_3500.solverstate
I0625 20:19:29.852666 18821 solver.cpp:337] Iteration 3500, Testing net (#0)
I0625 20:19:32.856119 18821 solver.cpp:404]     Test net output #0: accuracy = 0.781982
I0625 20:19:32.856158 18821 solver.cpp:404]     Test net output #1: loss = 0.464059 (* 1 = 0.464059 loss)
I0625 20:19:32.883994 18821 solver.cpp:228] Iteration 3500, loss = 0.449813
I0625 20:19:32.884026 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:19:32.884033 18821 solver.cpp:244]     Train net output #1: loss = 0.449813 (* 1 = 0.449813 loss)
I0625 20:19:32.884039 18821 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0625 20:19:34.499519 18821 solver.cpp:228] Iteration 3520, loss = 0.476269
I0625 20:19:34.499555 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:19:34.499562 18821 solver.cpp:244]     Train net output #1: loss = 0.476269 (* 1 = 0.476269 loss)
I0625 20:19:34.499567 18821 sgd_solver.cpp:106] Iteration 3520, lr = 0.0001
I0625 20:19:36.098436 18821 solver.cpp:228] Iteration 3540, loss = 0.357281
I0625 20:19:36.098464 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:19:36.098482 18821 solver.cpp:244]     Train net output #1: loss = 0.357281 (* 1 = 0.357281 loss)
I0625 20:19:36.098487 18821 sgd_solver.cpp:106] Iteration 3540, lr = 0.0001
I0625 20:19:37.699276 18821 solver.cpp:228] Iteration 3560, loss = 0.498326
I0625 20:19:37.699302 18821 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:19:37.699309 18821 solver.cpp:244]     Train net output #1: loss = 0.498326 (* 1 = 0.498326 loss)
I0625 20:19:37.699316 18821 sgd_solver.cpp:106] Iteration 3560, lr = 0.0001
I0625 20:19:39.299548 18821 solver.cpp:228] Iteration 3580, loss = 0.46137
I0625 20:19:39.299576 18821 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:19:39.299582 18821 solver.cpp:244]     Train net output #1: loss = 0.46137 (* 1 = 0.46137 loss)
I0625 20:19:39.299608 18821 sgd_solver.cpp:106] Iteration 3580, lr = 0.0001
I0625 20:19:40.890907 18821 solver.cpp:337] Iteration 3600, Testing net (#0)
I0625 20:19:43.908920 18821 solver.cpp:404]     Test net output #0: accuracy = 0.78418
I0625 20:19:43.908951 18821 solver.cpp:404]     Test net output #1: loss = 0.46525 (* 1 = 0.46525 loss)
I0625 20:19:43.937057 18821 solver.cpp:228] Iteration 3600, loss = 0.382216
I0625 20:19:43.937091 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:19:43.937103 18821 solver.cpp:244]     Train net output #1: loss = 0.382216 (* 1 = 0.382216 loss)
I0625 20:19:43.937110 18821 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0625 20:19:45.546402 18821 solver.cpp:228] Iteration 3620, loss = 0.490115
I0625 20:19:45.546428 18821 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:19:45.546435 18821 solver.cpp:244]     Train net output #1: loss = 0.490115 (* 1 = 0.490115 loss)
I0625 20:19:45.546440 18821 sgd_solver.cpp:106] Iteration 3620, lr = 0.0001
I0625 20:19:47.147610 18821 solver.cpp:228] Iteration 3640, loss = 0.23952
I0625 20:19:47.147636 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:19:47.147644 18821 solver.cpp:244]     Train net output #1: loss = 0.23952 (* 1 = 0.23952 loss)
I0625 20:19:47.147650 18821 sgd_solver.cpp:106] Iteration 3640, lr = 0.0001
I0625 20:19:48.748145 18821 solver.cpp:228] Iteration 3660, loss = 0.402343
I0625 20:19:48.748183 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:19:48.748189 18821 solver.cpp:244]     Train net output #1: loss = 0.402343 (* 1 = 0.402343 loss)
I0625 20:19:48.748194 18821 sgd_solver.cpp:106] Iteration 3660, lr = 0.0001
I0625 20:19:50.349277 18821 solver.cpp:228] Iteration 3680, loss = 0.324586
I0625 20:19:50.349436 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:19:50.349447 18821 solver.cpp:244]     Train net output #1: loss = 0.324586 (* 1 = 0.324586 loss)
I0625 20:19:50.349452 18821 sgd_solver.cpp:106] Iteration 3680, lr = 0.0001
I0625 20:19:51.937511 18821 solver.cpp:337] Iteration 3700, Testing net (#0)
I0625 20:19:54.823887 18821 solver.cpp:404]     Test net output #0: accuracy = 0.778809
I0625 20:19:54.823918 18821 solver.cpp:404]     Test net output #1: loss = 0.464931 (* 1 = 0.464931 loss)
I0625 20:19:54.851622 18821 solver.cpp:228] Iteration 3700, loss = 0.351703
I0625 20:19:54.851650 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:19:54.851658 18821 solver.cpp:244]     Train net output #1: loss = 0.351703 (* 1 = 0.351703 loss)
I0625 20:19:54.851663 18821 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0625 20:19:56.462880 18821 solver.cpp:228] Iteration 3720, loss = 0.589749
I0625 20:19:56.462908 18821 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0625 20:19:56.462914 18821 solver.cpp:244]     Train net output #1: loss = 0.589749 (* 1 = 0.589749 loss)
I0625 20:19:56.462920 18821 sgd_solver.cpp:106] Iteration 3720, lr = 0.0001
I0625 20:19:58.068197 18821 solver.cpp:228] Iteration 3740, loss = 0.545747
I0625 20:19:58.068222 18821 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:19:58.068229 18821 solver.cpp:244]     Train net output #1: loss = 0.545747 (* 1 = 0.545747 loss)
I0625 20:19:58.068234 18821 sgd_solver.cpp:106] Iteration 3740, lr = 0.0001
I0625 20:19:59.672296 18821 solver.cpp:228] Iteration 3760, loss = 0.446309
I0625 20:19:59.672322 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:19:59.672330 18821 solver.cpp:244]     Train net output #1: loss = 0.446309 (* 1 = 0.446309 loss)
I0625 20:19:59.672335 18821 sgd_solver.cpp:106] Iteration 3760, lr = 0.0001
I0625 20:20:01.274704 18821 solver.cpp:228] Iteration 3780, loss = 0.406867
I0625 20:20:01.274730 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:20:01.274739 18821 solver.cpp:244]     Train net output #1: loss = 0.406867 (* 1 = 0.406867 loss)
I0625 20:20:01.274744 18821 sgd_solver.cpp:106] Iteration 3780, lr = 0.0001
I0625 20:20:02.852146 18821 solver.cpp:337] Iteration 3800, Testing net (#0)
I0625 20:20:05.736618 18821 solver.cpp:404]     Test net output #0: accuracy = 0.782471
I0625 20:20:05.736660 18821 solver.cpp:404]     Test net output #1: loss = 0.471048 (* 1 = 0.471048 loss)
I0625 20:20:05.764302 18821 solver.cpp:228] Iteration 3800, loss = 0.34781
I0625 20:20:05.764329 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:20:05.764338 18821 solver.cpp:244]     Train net output #1: loss = 0.34781 (* 1 = 0.34781 loss)
I0625 20:20:05.764343 18821 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0625 20:20:07.366617 18821 solver.cpp:228] Iteration 3820, loss = 0.569514
I0625 20:20:07.366642 18821 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:20:07.366650 18821 solver.cpp:244]     Train net output #1: loss = 0.569514 (* 1 = 0.569514 loss)
I0625 20:20:07.366654 18821 sgd_solver.cpp:106] Iteration 3820, lr = 0.0001
I0625 20:20:08.968449 18821 solver.cpp:228] Iteration 3840, loss = 0.345513
I0625 20:20:08.968477 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:20:08.968484 18821 solver.cpp:244]     Train net output #1: loss = 0.345513 (* 1 = 0.345513 loss)
I0625 20:20:08.968489 18821 sgd_solver.cpp:106] Iteration 3840, lr = 0.0001
I0625 20:20:10.569944 18821 solver.cpp:228] Iteration 3860, loss = 0.370742
I0625 20:20:10.569972 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:20:10.569978 18821 solver.cpp:244]     Train net output #1: loss = 0.370742 (* 1 = 0.370742 loss)
I0625 20:20:10.569983 18821 sgd_solver.cpp:106] Iteration 3860, lr = 0.0001
I0625 20:20:12.170452 18821 solver.cpp:228] Iteration 3880, loss = 0.390958
I0625 20:20:12.170480 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:20:12.170488 18821 solver.cpp:244]     Train net output #1: loss = 0.390958 (* 1 = 0.390958 loss)
I0625 20:20:12.170516 18821 sgd_solver.cpp:106] Iteration 3880, lr = 0.0001
I0625 20:20:13.747134 18821 solver.cpp:337] Iteration 3900, Testing net (#0)
I0625 20:20:16.632206 18821 solver.cpp:404]     Test net output #0: accuracy = 0.781494
I0625 20:20:16.632248 18821 solver.cpp:404]     Test net output #1: loss = 0.46701 (* 1 = 0.46701 loss)
I0625 20:20:16.660162 18821 solver.cpp:228] Iteration 3900, loss = 0.348675
I0625 20:20:16.660190 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:20:16.660198 18821 solver.cpp:244]     Train net output #1: loss = 0.348675 (* 1 = 0.348675 loss)
I0625 20:20:16.660203 18821 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0625 20:20:18.264634 18821 solver.cpp:228] Iteration 3920, loss = 0.537126
I0625 20:20:18.264660 18821 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 20:20:18.264679 18821 solver.cpp:244]     Train net output #1: loss = 0.537126 (* 1 = 0.537126 loss)
I0625 20:20:18.264683 18821 sgd_solver.cpp:106] Iteration 3920, lr = 0.0001
I0625 20:20:19.868145 18821 solver.cpp:228] Iteration 3940, loss = 0.491644
I0625 20:20:19.868170 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:20:19.868177 18821 solver.cpp:244]     Train net output #1: loss = 0.491644 (* 1 = 0.491644 loss)
I0625 20:20:19.868181 18821 sgd_solver.cpp:106] Iteration 3940, lr = 0.0001
I0625 20:20:21.472623 18821 solver.cpp:228] Iteration 3960, loss = 0.425395
I0625 20:20:21.472733 18821 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:20:21.472743 18821 solver.cpp:244]     Train net output #1: loss = 0.425395 (* 1 = 0.425395 loss)
I0625 20:20:21.472748 18821 sgd_solver.cpp:106] Iteration 3960, lr = 0.0001
I0625 20:20:23.073760 18821 solver.cpp:228] Iteration 3980, loss = 0.276842
I0625 20:20:23.073806 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:20:23.073812 18821 solver.cpp:244]     Train net output #1: loss = 0.276842 (* 1 = 0.276842 loss)
I0625 20:20:23.073817 18821 sgd_solver.cpp:106] Iteration 3980, lr = 0.0001
I0625 20:20:24.649982 18821 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_4000.caffemodel
I0625 20:20:24.670249 18821 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_4000.solverstate
I0625 20:20:24.680304 18821 solver.cpp:337] Iteration 4000, Testing net (#0)
I0625 20:20:27.565882 18821 solver.cpp:404]     Test net output #0: accuracy = 0.778076
I0625 20:20:27.565924 18821 solver.cpp:404]     Test net output #1: loss = 0.463707 (* 1 = 0.463707 loss)
I0625 20:20:27.594094 18821 solver.cpp:228] Iteration 4000, loss = 0.419023
I0625 20:20:27.594133 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:20:27.594146 18821 solver.cpp:244]     Train net output #1: loss = 0.419023 (* 1 = 0.419023 loss)
I0625 20:20:27.594152 18821 sgd_solver.cpp:106] Iteration 4000, lr = 1e-05
I0625 20:20:29.200768 18821 solver.cpp:228] Iteration 4020, loss = 0.269357
I0625 20:20:29.200798 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:20:29.200808 18821 solver.cpp:244]     Train net output #1: loss = 0.269357 (* 1 = 0.269357 loss)
I0625 20:20:29.200812 18821 sgd_solver.cpp:106] Iteration 4020, lr = 1e-05
I0625 20:20:30.814978 18821 solver.cpp:228] Iteration 4040, loss = 0.273352
I0625 20:20:30.815004 18821 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0625 20:20:30.815013 18821 solver.cpp:244]     Train net output #1: loss = 0.273352 (* 1 = 0.273352 loss)
I0625 20:20:30.815018 18821 sgd_solver.cpp:106] Iteration 4040, lr = 1e-05
I0625 20:20:32.430647 18821 solver.cpp:228] Iteration 4060, loss = 0.435062
I0625 20:20:32.430676 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:20:32.430685 18821 solver.cpp:244]     Train net output #1: loss = 0.435062 (* 1 = 0.435062 loss)
I0625 20:20:32.430690 18821 sgd_solver.cpp:106] Iteration 4060, lr = 1e-05
I0625 20:20:34.048959 18821 solver.cpp:228] Iteration 4080, loss = 0.37255
I0625 20:20:34.048986 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:20:34.048993 18821 solver.cpp:244]     Train net output #1: loss = 0.37255 (* 1 = 0.37255 loss)
I0625 20:20:34.048998 18821 sgd_solver.cpp:106] Iteration 4080, lr = 1e-05
I0625 20:20:35.644637 18821 solver.cpp:337] Iteration 4100, Testing net (#0)
I0625 20:20:38.627087 18821 solver.cpp:404]     Test net output #0: accuracy = 0.783691
I0625 20:20:38.627128 18821 solver.cpp:404]     Test net output #1: loss = 0.464174 (* 1 = 0.464174 loss)
I0625 20:20:38.654857 18821 solver.cpp:228] Iteration 4100, loss = 0.637604
I0625 20:20:38.654886 18821 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:20:38.654893 18821 solver.cpp:244]     Train net output #1: loss = 0.637604 (* 1 = 0.637604 loss)
I0625 20:20:38.654899 18821 sgd_solver.cpp:106] Iteration 4100, lr = 1e-05
I0625 20:20:40.263334 18821 solver.cpp:228] Iteration 4120, loss = 0.46368
I0625 20:20:40.263371 18821 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:20:40.263378 18821 solver.cpp:244]     Train net output #1: loss = 0.46368 (* 1 = 0.46368 loss)
I0625 20:20:40.263383 18821 sgd_solver.cpp:106] Iteration 4120, lr = 1e-05
I0625 20:20:41.865188 18821 solver.cpp:228] Iteration 4140, loss = 0.336159
I0625 20:20:41.865226 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:20:41.865233 18821 solver.cpp:244]     Train net output #1: loss = 0.336159 (* 1 = 0.336159 loss)
I0625 20:20:41.865238 18821 sgd_solver.cpp:106] Iteration 4140, lr = 1e-05
I0625 20:20:43.466254 18821 solver.cpp:228] Iteration 4160, loss = 0.429478
I0625 20:20:43.466281 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:20:43.466290 18821 solver.cpp:244]     Train net output #1: loss = 0.429478 (* 1 = 0.429478 loss)
I0625 20:20:43.466295 18821 sgd_solver.cpp:106] Iteration 4160, lr = 1e-05
I0625 20:20:45.067658 18821 solver.cpp:228] Iteration 4180, loss = 0.3518
I0625 20:20:45.067684 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:20:45.067703 18821 solver.cpp:244]     Train net output #1: loss = 0.3518 (* 1 = 0.3518 loss)
I0625 20:20:45.067708 18821 sgd_solver.cpp:106] Iteration 4180, lr = 1e-05
I0625 20:20:46.644719 18821 solver.cpp:337] Iteration 4200, Testing net (#0)
I0625 20:20:48.857823 18821 blocking_queue.cpp:50] Data layer prefetch queue empty
I0625 20:20:49.649060 18821 solver.cpp:404]     Test net output #0: accuracy = 0.787842
I0625 20:20:49.649102 18821 solver.cpp:404]     Test net output #1: loss = 0.461865 (* 1 = 0.461865 loss)
I0625 20:20:49.676985 18821 solver.cpp:228] Iteration 4200, loss = 0.430641
I0625 20:20:49.677021 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:20:49.677031 18821 solver.cpp:244]     Train net output #1: loss = 0.430641 (* 1 = 0.430641 loss)
I0625 20:20:49.677038 18821 sgd_solver.cpp:106] Iteration 4200, lr = 1e-05
I0625 20:20:51.284791 18821 solver.cpp:228] Iteration 4220, loss = 0.612984
I0625 20:20:51.284818 18821 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 20:20:51.284829 18821 solver.cpp:244]     Train net output #1: loss = 0.612984 (* 1 = 0.612984 loss)
I0625 20:20:51.284835 18821 sgd_solver.cpp:106] Iteration 4220, lr = 1e-05
I0625 20:20:52.886415 18821 solver.cpp:228] Iteration 4240, loss = 0.467056
I0625 20:20:52.886559 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:20:52.886574 18821 solver.cpp:244]     Train net output #1: loss = 0.467056 (* 1 = 0.467056 loss)
I0625 20:20:52.886581 18821 sgd_solver.cpp:106] Iteration 4240, lr = 1e-05
I0625 20:20:54.487774 18821 solver.cpp:228] Iteration 4260, loss = 0.339668
I0625 20:20:54.487803 18821 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 20:20:54.487814 18821 solver.cpp:244]     Train net output #1: loss = 0.339668 (* 1 = 0.339668 loss)
I0625 20:20:54.487821 18821 sgd_solver.cpp:106] Iteration 4260, lr = 1e-05
I0625 20:20:56.088127 18821 solver.cpp:228] Iteration 4280, loss = 0.566787
I0625 20:20:56.088166 18821 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 20:20:56.088177 18821 solver.cpp:244]     Train net output #1: loss = 0.566787 (* 1 = 0.566787 loss)
I0625 20:20:56.088184 18821 sgd_solver.cpp:106] Iteration 4280, lr = 1e-05
I0625 20:20:57.689169 18821 solver.cpp:337] Iteration 4300, Testing net (#0)
I0625 20:21:00.672905 18821 solver.cpp:404]     Test net output #0: accuracy = 0.791748
I0625 20:21:00.672947 18821 solver.cpp:404]     Test net output #1: loss = 0.467275 (* 1 = 0.467275 loss)
I0625 20:21:00.700646 18821 solver.cpp:228] Iteration 4300, loss = 0.415227
I0625 20:21:00.700677 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:21:00.700685 18821 solver.cpp:244]     Train net output #1: loss = 0.415227 (* 1 = 0.415227 loss)
I0625 20:21:00.700690 18821 sgd_solver.cpp:106] Iteration 4300, lr = 1e-05
I0625 20:21:02.309463 18821 solver.cpp:228] Iteration 4320, loss = 0.39161
I0625 20:21:02.309487 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:21:02.309505 18821 solver.cpp:244]     Train net output #1: loss = 0.39161 (* 1 = 0.39161 loss)
I0625 20:21:02.309509 18821 sgd_solver.cpp:106] Iteration 4320, lr = 1e-05
I0625 20:21:03.911414 18821 solver.cpp:228] Iteration 4340, loss = 0.377859
I0625 20:21:03.911453 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:21:03.911459 18821 solver.cpp:244]     Train net output #1: loss = 0.377859 (* 1 = 0.377859 loss)
I0625 20:21:03.911464 18821 sgd_solver.cpp:106] Iteration 4340, lr = 1e-05
I0625 20:21:05.512940 18821 solver.cpp:228] Iteration 4360, loss = 0.387556
I0625 20:21:05.512966 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:21:05.512974 18821 solver.cpp:244]     Train net output #1: loss = 0.387556 (* 1 = 0.387556 loss)
I0625 20:21:05.512979 18821 sgd_solver.cpp:106] Iteration 4360, lr = 1e-05
I0625 20:21:07.113801 18821 solver.cpp:228] Iteration 4380, loss = 0.364054
I0625 20:21:07.113827 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:21:07.113834 18821 solver.cpp:244]     Train net output #1: loss = 0.364054 (* 1 = 0.364054 loss)
I0625 20:21:07.113838 18821 sgd_solver.cpp:106] Iteration 4380, lr = 1e-05
I0625 20:21:08.709338 18821 solver.cpp:337] Iteration 4400, Testing net (#0)
I0625 20:21:11.601088 18821 solver.cpp:404]     Test net output #0: accuracy = 0.797852
I0625 20:21:11.601120 18821 solver.cpp:404]     Test net output #1: loss = 0.461608 (* 1 = 0.461608 loss)
I0625 20:21:11.628919 18821 solver.cpp:228] Iteration 4400, loss = 0.332816
I0625 20:21:11.628947 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:21:11.628954 18821 solver.cpp:244]     Train net output #1: loss = 0.332816 (* 1 = 0.332816 loss)
I0625 20:21:11.628959 18821 sgd_solver.cpp:106] Iteration 4400, lr = 1e-05
I0625 20:21:13.242435 18821 solver.cpp:228] Iteration 4420, loss = 0.59323
I0625 20:21:13.242473 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:21:13.242481 18821 solver.cpp:244]     Train net output #1: loss = 0.59323 (* 1 = 0.59323 loss)
I0625 20:21:13.242486 18821 sgd_solver.cpp:106] Iteration 4420, lr = 1e-05
I0625 20:21:14.843886 18821 solver.cpp:228] Iteration 4440, loss = 0.623624
I0625 20:21:14.843915 18821 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:21:14.843924 18821 solver.cpp:244]     Train net output #1: loss = 0.623624 (* 1 = 0.623624 loss)
I0625 20:21:14.843952 18821 sgd_solver.cpp:106] Iteration 4440, lr = 1e-05
I0625 20:21:16.444622 18821 solver.cpp:228] Iteration 4460, loss = 0.50965
I0625 20:21:16.444658 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:21:16.444665 18821 solver.cpp:244]     Train net output #1: loss = 0.50965 (* 1 = 0.50965 loss)
I0625 20:21:16.444670 18821 sgd_solver.cpp:106] Iteration 4460, lr = 1e-05
I0625 20:21:18.048393 18821 solver.cpp:228] Iteration 4480, loss = 0.420566
I0625 20:21:18.048418 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:21:18.048425 18821 solver.cpp:244]     Train net output #1: loss = 0.420566 (* 1 = 0.420566 loss)
I0625 20:21:18.048430 18821 sgd_solver.cpp:106] Iteration 4480, lr = 1e-05
I0625 20:21:19.625358 18821 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_4500.caffemodel
I0625 20:21:19.645174 18821 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_4500.solverstate
I0625 20:21:19.654685 18821 solver.cpp:337] Iteration 4500, Testing net (#0)
I0625 20:21:22.661237 18821 solver.cpp:404]     Test net output #0: accuracy = 0.791748
I0625 20:21:22.661267 18821 solver.cpp:404]     Test net output #1: loss = 0.460125 (* 1 = 0.460125 loss)
I0625 20:21:22.688740 18821 solver.cpp:228] Iteration 4500, loss = 0.380946
I0625 20:21:22.688772 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:21:22.688781 18821 solver.cpp:244]     Train net output #1: loss = 0.380946 (* 1 = 0.380946 loss)
I0625 20:21:22.688786 18821 sgd_solver.cpp:106] Iteration 4500, lr = 1e-05
I0625 20:21:24.297260 18821 solver.cpp:228] Iteration 4520, loss = 0.541433
I0625 20:21:24.297385 18821 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:21:24.297395 18821 solver.cpp:244]     Train net output #1: loss = 0.541433 (* 1 = 0.541433 loss)
I0625 20:21:24.297400 18821 sgd_solver.cpp:106] Iteration 4520, lr = 1e-05
I0625 20:21:25.898591 18821 solver.cpp:228] Iteration 4540, loss = 0.526078
I0625 20:21:25.898615 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:21:25.898622 18821 solver.cpp:244]     Train net output #1: loss = 0.526078 (* 1 = 0.526078 loss)
I0625 20:21:25.898627 18821 sgd_solver.cpp:106] Iteration 4540, lr = 1e-05
I0625 20:21:27.499644 18821 solver.cpp:228] Iteration 4560, loss = 0.316201
I0625 20:21:27.499668 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:21:27.499675 18821 solver.cpp:244]     Train net output #1: loss = 0.316201 (* 1 = 0.316201 loss)
I0625 20:21:27.499680 18821 sgd_solver.cpp:106] Iteration 4560, lr = 1e-05
I0625 20:21:29.101771 18821 solver.cpp:228] Iteration 4580, loss = 0.500251
I0625 20:21:29.101797 18821 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:21:29.101804 18821 solver.cpp:244]     Train net output #1: loss = 0.500251 (* 1 = 0.500251 loss)
I0625 20:21:29.101809 18821 sgd_solver.cpp:106] Iteration 4580, lr = 1e-05
I0625 20:21:30.693212 18821 solver.cpp:337] Iteration 4600, Testing net (#0)
I0625 20:21:33.705377 18821 solver.cpp:404]     Test net output #0: accuracy = 0.787354
I0625 20:21:33.705420 18821 solver.cpp:404]     Test net output #1: loss = 0.460059 (* 1 = 0.460059 loss)
I0625 20:21:33.732962 18821 solver.cpp:228] Iteration 4600, loss = 0.438978
I0625 20:21:33.732995 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:21:33.733002 18821 solver.cpp:244]     Train net output #1: loss = 0.438978 (* 1 = 0.438978 loss)
I0625 20:21:33.733007 18821 sgd_solver.cpp:106] Iteration 4600, lr = 1e-05
I0625 20:21:35.343998 18821 solver.cpp:228] Iteration 4620, loss = 0.392352
I0625 20:21:35.344091 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:21:35.344101 18821 solver.cpp:244]     Train net output #1: loss = 0.392352 (* 1 = 0.392352 loss)
I0625 20:21:35.344106 18821 sgd_solver.cpp:106] Iteration 4620, lr = 1e-05
I0625 20:21:36.953754 18821 solver.cpp:228] Iteration 4640, loss = 0.391602
I0625 20:21:36.953784 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:21:36.953793 18821 solver.cpp:244]     Train net output #1: loss = 0.391602 (* 1 = 0.391602 loss)
I0625 20:21:36.953797 18821 sgd_solver.cpp:106] Iteration 4640, lr = 1e-05
I0625 20:21:38.567278 18821 solver.cpp:228] Iteration 4660, loss = 0.419527
I0625 20:21:38.567313 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:21:38.567320 18821 solver.cpp:244]     Train net output #1: loss = 0.419527 (* 1 = 0.419527 loss)
I0625 20:21:38.567324 18821 sgd_solver.cpp:106] Iteration 4660, lr = 1e-05
I0625 20:21:40.174464 18821 solver.cpp:228] Iteration 4680, loss = 0.485506
I0625 20:21:40.174491 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:21:40.174499 18821 solver.cpp:244]     Train net output #1: loss = 0.485506 (* 1 = 0.485506 loss)
I0625 20:21:40.174504 18821 sgd_solver.cpp:106] Iteration 4680, lr = 1e-05
I0625 20:21:41.754909 18821 solver.cpp:337] Iteration 4700, Testing net (#0)
I0625 20:21:44.808588 18821 solver.cpp:404]     Test net output #0: accuracy = 0.785156
I0625 20:21:44.808627 18821 solver.cpp:404]     Test net output #1: loss = 0.465522 (* 1 = 0.465522 loss)
I0625 20:21:44.836197 18821 solver.cpp:228] Iteration 4700, loss = 0.484432
I0625 20:21:44.836236 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:21:44.836243 18821 solver.cpp:244]     Train net output #1: loss = 0.484432 (* 1 = 0.484432 loss)
I0625 20:21:44.836248 18821 sgd_solver.cpp:106] Iteration 4700, lr = 1e-05
I0625 20:21:46.453128 18821 solver.cpp:228] Iteration 4720, loss = 0.630894
I0625 20:21:46.453156 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:21:46.453164 18821 solver.cpp:244]     Train net output #1: loss = 0.630894 (* 1 = 0.630894 loss)
I0625 20:21:46.453192 18821 sgd_solver.cpp:106] Iteration 4720, lr = 1e-05
I0625 20:21:48.092752 18821 solver.cpp:228] Iteration 4740, loss = 0.434249
I0625 20:21:48.092778 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:21:48.092787 18821 solver.cpp:244]     Train net output #1: loss = 0.434249 (* 1 = 0.434249 loss)
I0625 20:21:48.092790 18821 sgd_solver.cpp:106] Iteration 4740, lr = 1e-05
I0625 20:21:49.766881 18821 solver.cpp:228] Iteration 4760, loss = 0.433812
I0625 20:21:49.766907 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:21:49.766916 18821 solver.cpp:244]     Train net output #1: loss = 0.433812 (* 1 = 0.433812 loss)
I0625 20:21:49.766921 18821 sgd_solver.cpp:106] Iteration 4760, lr = 1e-05
I0625 20:21:51.379948 18821 solver.cpp:228] Iteration 4780, loss = 0.433363
I0625 20:21:51.379976 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:21:51.379982 18821 solver.cpp:244]     Train net output #1: loss = 0.433363 (* 1 = 0.433363 loss)
I0625 20:21:51.379987 18821 sgd_solver.cpp:106] Iteration 4780, lr = 1e-05
I0625 20:21:52.973455 18821 solver.cpp:337] Iteration 4800, Testing net (#0)
I0625 20:21:56.010222 18821 solver.cpp:404]     Test net output #0: accuracy = 0.782959
I0625 20:21:56.023458 18821 solver.cpp:404]     Test net output #1: loss = 0.465986 (* 1 = 0.465986 loss)
I0625 20:21:56.050235 18821 solver.cpp:228] Iteration 4800, loss = 0.514142
I0625 20:21:56.050268 18821 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:21:56.050279 18821 solver.cpp:244]     Train net output #1: loss = 0.514142 (* 1 = 0.514142 loss)
I0625 20:21:56.050287 18821 sgd_solver.cpp:106] Iteration 4800, lr = 1e-05
I0625 20:21:57.701783 18821 solver.cpp:228] Iteration 4820, loss = 0.346364
I0625 20:21:57.701812 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:21:57.701820 18821 solver.cpp:244]     Train net output #1: loss = 0.346364 (* 1 = 0.346364 loss)
I0625 20:21:57.701825 18821 sgd_solver.cpp:106] Iteration 4820, lr = 1e-05
I0625 20:21:59.337858 18821 solver.cpp:228] Iteration 4840, loss = 0.3517
I0625 20:21:59.337885 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:21:59.337893 18821 solver.cpp:244]     Train net output #1: loss = 0.3517 (* 1 = 0.3517 loss)
I0625 20:21:59.337898 18821 sgd_solver.cpp:106] Iteration 4840, lr = 1e-05
I0625 20:22:00.964242 18821 solver.cpp:228] Iteration 4860, loss = 0.391285
I0625 20:22:00.964269 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:22:00.964287 18821 solver.cpp:244]     Train net output #1: loss = 0.391285 (* 1 = 0.391285 loss)
I0625 20:22:00.964293 18821 sgd_solver.cpp:106] Iteration 4860, lr = 1e-05
I0625 20:22:02.595582 18821 solver.cpp:228] Iteration 4880, loss = 0.472415
I0625 20:22:02.595618 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:22:02.595626 18821 solver.cpp:244]     Train net output #1: loss = 0.472415 (* 1 = 0.472415 loss)
I0625 20:22:02.595631 18821 sgd_solver.cpp:106] Iteration 4880, lr = 1e-05
I0625 20:22:04.188318 18821 solver.cpp:337] Iteration 4900, Testing net (#0)
I0625 20:22:07.208452 18821 solver.cpp:404]     Test net output #0: accuracy = 0.783936
I0625 20:22:07.208482 18821 solver.cpp:404]     Test net output #1: loss = 0.465897 (* 1 = 0.465897 loss)
I0625 20:22:07.236357 18821 solver.cpp:228] Iteration 4900, loss = 0.532047
I0625 20:22:07.236384 18821 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:22:07.236392 18821 solver.cpp:244]     Train net output #1: loss = 0.532047 (* 1 = 0.532047 loss)
I0625 20:22:07.236397 18821 sgd_solver.cpp:106] Iteration 4900, lr = 1e-05
I0625 20:22:08.855523 18821 solver.cpp:228] Iteration 4920, loss = 0.56258
I0625 20:22:08.855561 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:22:08.855567 18821 solver.cpp:244]     Train net output #1: loss = 0.56258 (* 1 = 0.56258 loss)
I0625 20:22:08.855572 18821 sgd_solver.cpp:106] Iteration 4920, lr = 1e-05
I0625 20:22:10.469952 18821 solver.cpp:228] Iteration 4940, loss = 0.357025
I0625 20:22:10.469979 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:22:10.469986 18821 solver.cpp:244]     Train net output #1: loss = 0.357025 (* 1 = 0.357025 loss)
I0625 20:22:10.469990 18821 sgd_solver.cpp:106] Iteration 4940, lr = 1e-05
I0625 20:22:12.134066 18821 solver.cpp:228] Iteration 4960, loss = 0.375909
I0625 20:22:12.134093 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:22:12.134100 18821 solver.cpp:244]     Train net output #1: loss = 0.375909 (* 1 = 0.375909 loss)
I0625 20:22:12.134104 18821 sgd_solver.cpp:106] Iteration 4960, lr = 1e-05
I0625 20:22:13.777489 18821 solver.cpp:228] Iteration 4980, loss = 0.382237
I0625 20:22:13.777518 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:22:13.777526 18821 solver.cpp:244]     Train net output #1: loss = 0.382237 (* 1 = 0.382237 loss)
I0625 20:22:13.777532 18821 sgd_solver.cpp:106] Iteration 4980, lr = 1e-05
I0625 20:22:15.390691 18821 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_5000.caffemodel
I0625 20:22:15.411054 18821 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_5000.solverstate
I0625 20:22:15.420727 18821 solver.cpp:337] Iteration 5000, Testing net (#0)
I0625 20:22:18.548471 18821 solver.cpp:404]     Test net output #0: accuracy = 0.782959
I0625 20:22:18.548501 18821 solver.cpp:404]     Test net output #1: loss = 0.469236 (* 1 = 0.469236 loss)
I0625 20:22:18.576140 18821 solver.cpp:228] Iteration 5000, loss = 0.662247
I0625 20:22:18.576170 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:22:18.576179 18821 solver.cpp:244]     Train net output #1: loss = 0.662247 (* 1 = 0.662247 loss)
I0625 20:22:18.576184 18821 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0625 20:22:20.216475 18821 solver.cpp:228] Iteration 5020, loss = 0.335703
I0625 20:22:20.216507 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:22:20.216518 18821 solver.cpp:244]     Train net output #1: loss = 0.335703 (* 1 = 0.335703 loss)
I0625 20:22:20.216526 18821 sgd_solver.cpp:106] Iteration 5020, lr = 1e-05
I0625 20:22:21.850543 18821 solver.cpp:228] Iteration 5040, loss = 0.301954
I0625 20:22:21.850569 18821 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 20:22:21.850576 18821 solver.cpp:244]     Train net output #1: loss = 0.301954 (* 1 = 0.301954 loss)
I0625 20:22:21.850581 18821 sgd_solver.cpp:106] Iteration 5040, lr = 1e-05
I0625 20:22:23.475273 18821 solver.cpp:228] Iteration 5060, loss = 0.536136
I0625 20:22:23.475299 18821 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:22:23.475306 18821 solver.cpp:244]     Train net output #1: loss = 0.536136 (* 1 = 0.536136 loss)
I0625 20:22:23.475311 18821 sgd_solver.cpp:106] Iteration 5060, lr = 1e-05
I0625 20:22:25.091804 18821 solver.cpp:228] Iteration 5080, loss = 0.351516
I0625 20:22:25.091841 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:22:25.091848 18821 solver.cpp:244]     Train net output #1: loss = 0.351516 (* 1 = 0.351516 loss)
I0625 20:22:25.091853 18821 sgd_solver.cpp:106] Iteration 5080, lr = 1e-05
I0625 20:22:26.693742 18821 solver.cpp:337] Iteration 5100, Testing net (#0)
I0625 20:22:29.769439 18821 solver.cpp:404]     Test net output #0: accuracy = 0.786133
I0625 20:22:29.769469 18821 solver.cpp:404]     Test net output #1: loss = 0.468831 (* 1 = 0.468831 loss)
I0625 20:22:29.798315 18821 solver.cpp:228] Iteration 5100, loss = 0.317201
I0625 20:22:29.798339 18821 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 20:22:29.798348 18821 solver.cpp:244]     Train net output #1: loss = 0.317201 (* 1 = 0.317201 loss)
I0625 20:22:29.798353 18821 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0625 20:22:31.449123 18821 solver.cpp:228] Iteration 5120, loss = 0.44203
I0625 20:22:31.449162 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:22:31.449169 18821 solver.cpp:244]     Train net output #1: loss = 0.44203 (* 1 = 0.44203 loss)
I0625 20:22:31.449174 18821 sgd_solver.cpp:106] Iteration 5120, lr = 1e-05
I0625 20:22:33.065737 18821 solver.cpp:228] Iteration 5140, loss = 0.549384
I0625 20:22:33.065775 18821 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:22:33.065783 18821 solver.cpp:244]     Train net output #1: loss = 0.549384 (* 1 = 0.549384 loss)
I0625 20:22:33.065788 18821 sgd_solver.cpp:106] Iteration 5140, lr = 1e-05
I0625 20:22:34.680033 18821 solver.cpp:228] Iteration 5160, loss = 0.45188
I0625 20:22:34.680060 18821 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:22:34.680068 18821 solver.cpp:244]     Train net output #1: loss = 0.45188 (* 1 = 0.45188 loss)
I0625 20:22:34.680073 18821 sgd_solver.cpp:106] Iteration 5160, lr = 1e-05
I0625 20:22:36.318294 18821 solver.cpp:228] Iteration 5180, loss = 0.251524
I0625 20:22:36.318331 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:22:36.318339 18821 solver.cpp:244]     Train net output #1: loss = 0.251524 (* 1 = 0.251524 loss)
I0625 20:22:36.318344 18821 sgd_solver.cpp:106] Iteration 5180, lr = 1e-05
I0625 20:22:37.946877 18821 solver.cpp:337] Iteration 5200, Testing net (#0)
I0625 20:22:40.969593 18821 solver.cpp:404]     Test net output #0: accuracy = 0.785645
I0625 20:22:40.969622 18821 solver.cpp:404]     Test net output #1: loss = 0.468797 (* 1 = 0.468797 loss)
I0625 20:22:40.997449 18821 solver.cpp:228] Iteration 5200, loss = 0.308821
I0625 20:22:40.997478 18821 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0625 20:22:40.997486 18821 solver.cpp:244]     Train net output #1: loss = 0.308821 (* 1 = 0.308821 loss)
I0625 20:22:40.997491 18821 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0625 20:22:42.608232 18821 solver.cpp:228] Iteration 5220, loss = 0.362552
I0625 20:22:42.608266 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:22:42.608278 18821 solver.cpp:244]     Train net output #1: loss = 0.362552 (* 1 = 0.362552 loss)
I0625 20:22:42.608283 18821 sgd_solver.cpp:106] Iteration 5220, lr = 1e-05
I0625 20:22:44.211931 18821 solver.cpp:228] Iteration 5240, loss = 0.381583
I0625 20:22:44.211958 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:22:44.211966 18821 solver.cpp:244]     Train net output #1: loss = 0.381583 (* 1 = 0.381583 loss)
I0625 20:22:44.211971 18821 sgd_solver.cpp:106] Iteration 5240, lr = 1e-05
I0625 20:22:45.821120 18821 solver.cpp:228] Iteration 5260, loss = 0.437185
I0625 20:22:45.821144 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:22:45.821152 18821 solver.cpp:244]     Train net output #1: loss = 0.437185 (* 1 = 0.437185 loss)
I0625 20:22:45.821156 18821 sgd_solver.cpp:106] Iteration 5260, lr = 1e-05
I0625 20:22:47.439628 18821 solver.cpp:228] Iteration 5280, loss = 0.592055
I0625 20:22:47.439656 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:22:47.439663 18821 solver.cpp:244]     Train net output #1: loss = 0.592055 (* 1 = 0.592055 loss)
I0625 20:22:47.439667 18821 sgd_solver.cpp:106] Iteration 5280, lr = 1e-05
I0625 20:22:49.031503 18821 solver.cpp:337] Iteration 5300, Testing net (#0)
I0625 20:22:52.049969 18821 solver.cpp:404]     Test net output #0: accuracy = 0.787109
I0625 20:22:52.050009 18821 solver.cpp:404]     Test net output #1: loss = 0.464147 (* 1 = 0.464147 loss)
I0625 20:22:52.078186 18821 solver.cpp:228] Iteration 5300, loss = 0.572784
I0625 20:22:52.078225 18821 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:22:52.078236 18821 solver.cpp:244]     Train net output #1: loss = 0.572784 (* 1 = 0.572784 loss)
I0625 20:22:52.078244 18821 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0625 20:22:53.689290 18821 solver.cpp:228] Iteration 5320, loss = 0.380316
I0625 20:22:53.689314 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:22:53.689322 18821 solver.cpp:244]     Train net output #1: loss = 0.380316 (* 1 = 0.380316 loss)
I0625 20:22:53.689327 18821 sgd_solver.cpp:106] Iteration 5320, lr = 1e-05
I0625 20:22:55.291786 18821 solver.cpp:228] Iteration 5340, loss = 0.299909
I0625 20:22:55.291823 18821 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0625 20:22:55.291831 18821 solver.cpp:244]     Train net output #1: loss = 0.299909 (* 1 = 0.299909 loss)
I0625 20:22:55.291836 18821 sgd_solver.cpp:106] Iteration 5340, lr = 1e-05
I0625 20:22:56.893507 18821 solver.cpp:228] Iteration 5360, loss = 0.556326
I0625 20:22:56.893645 18821 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 20:22:56.893654 18821 solver.cpp:244]     Train net output #1: loss = 0.556326 (* 1 = 0.556326 loss)
I0625 20:22:56.893659 18821 sgd_solver.cpp:106] Iteration 5360, lr = 1e-05
I0625 20:22:58.499038 18821 solver.cpp:228] Iteration 5380, loss = 0.383551
I0625 20:22:58.499066 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:22:58.499074 18821 solver.cpp:244]     Train net output #1: loss = 0.383551 (* 1 = 0.383551 loss)
I0625 20:22:58.499079 18821 sgd_solver.cpp:106] Iteration 5380, lr = 1e-05
I0625 20:23:00.078269 18821 solver.cpp:337] Iteration 5400, Testing net (#0)
I0625 20:23:03.104707 18821 solver.cpp:404]     Test net output #0: accuracy = 0.792236
I0625 20:23:03.104743 18821 solver.cpp:404]     Test net output #1: loss = 0.466558 (* 1 = 0.466558 loss)
I0625 20:23:03.133074 18821 solver.cpp:228] Iteration 5400, loss = 0.50166
I0625 20:23:03.133103 18821 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:23:03.133113 18821 solver.cpp:244]     Train net output #1: loss = 0.50166 (* 1 = 0.50166 loss)
I0625 20:23:03.133121 18821 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0625 20:23:04.758520 18821 solver.cpp:228] Iteration 5420, loss = 0.330952
I0625 20:23:04.758549 18821 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 20:23:04.758561 18821 solver.cpp:244]     Train net output #1: loss = 0.330952 (* 1 = 0.330952 loss)
I0625 20:23:04.758569 18821 sgd_solver.cpp:106] Iteration 5420, lr = 1e-05
I0625 20:23:06.371175 18821 solver.cpp:228] Iteration 5440, loss = 0.371188
I0625 20:23:06.371201 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:23:06.371212 18821 solver.cpp:244]     Train net output #1: loss = 0.371188 (* 1 = 0.371188 loss)
I0625 20:23:06.371217 18821 sgd_solver.cpp:106] Iteration 5440, lr = 1e-05
I0625 20:23:07.982764 18821 solver.cpp:228] Iteration 5460, loss = 0.391323
I0625 20:23:07.982790 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:23:07.982800 18821 solver.cpp:244]     Train net output #1: loss = 0.391323 (* 1 = 0.391323 loss)
I0625 20:23:07.982806 18821 sgd_solver.cpp:106] Iteration 5460, lr = 1e-05
I0625 20:23:09.633559 18821 solver.cpp:228] Iteration 5480, loss = 0.542107
I0625 20:23:09.633587 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:23:09.633599 18821 solver.cpp:244]     Train net output #1: loss = 0.542107 (* 1 = 0.542107 loss)
I0625 20:23:09.633605 18821 sgd_solver.cpp:106] Iteration 5480, lr = 1e-05
I0625 20:23:11.255267 18821 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_5500.caffemodel
I0625 20:23:11.275748 18821 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_5500.solverstate
I0625 20:23:11.285761 18821 solver.cpp:337] Iteration 5500, Testing net (#0)
I0625 20:23:14.299846 18821 solver.cpp:404]     Test net output #0: accuracy = 0.794922
I0625 20:23:14.299890 18821 solver.cpp:404]     Test net output #1: loss = 0.462193 (* 1 = 0.462193 loss)
I0625 20:23:14.327626 18821 solver.cpp:228] Iteration 5500, loss = 0.280535
I0625 20:23:14.327653 18821 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0625 20:23:14.327661 18821 solver.cpp:244]     Train net output #1: loss = 0.280535 (* 1 = 0.280535 loss)
I0625 20:23:14.327666 18821 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0625 20:23:15.983090 18821 solver.cpp:228] Iteration 5520, loss = 0.239187
I0625 20:23:15.983117 18821 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0625 20:23:15.983125 18821 solver.cpp:244]     Train net output #1: loss = 0.239187 (* 1 = 0.239187 loss)
I0625 20:23:15.983130 18821 sgd_solver.cpp:106] Iteration 5520, lr = 1e-05
I0625 20:23:17.594635 18821 solver.cpp:228] Iteration 5540, loss = 0.439183
I0625 20:23:17.594671 18821 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:23:17.594679 18821 solver.cpp:244]     Train net output #1: loss = 0.439183 (* 1 = 0.439183 loss)
I0625 20:23:17.594684 18821 sgd_solver.cpp:106] Iteration 5540, lr = 1e-05
I0625 20:23:19.217218 18821 solver.cpp:228] Iteration 5560, loss = 0.41313
I0625 20:23:19.217247 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:23:19.217254 18821 solver.cpp:244]     Train net output #1: loss = 0.41313 (* 1 = 0.41313 loss)
I0625 20:23:19.217259 18821 sgd_solver.cpp:106] Iteration 5560, lr = 1e-05
I0625 20:23:20.820055 18821 solver.cpp:228] Iteration 5580, loss = 0.249817
I0625 20:23:20.820080 18821 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 20:23:20.820087 18821 solver.cpp:244]     Train net output #1: loss = 0.249817 (* 1 = 0.249817 loss)
I0625 20:23:20.820092 18821 sgd_solver.cpp:106] Iteration 5580, lr = 1e-05
I0625 20:23:22.411465 18821 solver.cpp:337] Iteration 5600, Testing net (#0)
I0625 20:23:25.504046 18821 solver.cpp:404]     Test net output #0: accuracy = 0.792236
I0625 20:23:25.504086 18821 solver.cpp:404]     Test net output #1: loss = 0.457144 (* 1 = 0.457144 loss)
I0625 20:23:25.531793 18821 solver.cpp:228] Iteration 5600, loss = 0.620509
I0625 20:23:25.531826 18821 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:23:25.531832 18821 solver.cpp:244]     Train net output #1: loss = 0.620509 (* 1 = 0.620509 loss)
I0625 20:23:25.531838 18821 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0625 20:23:27.186260 18821 solver.cpp:228] Iteration 5620, loss = 0.380777
I0625 20:23:27.186393 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:23:27.186404 18821 solver.cpp:244]     Train net output #1: loss = 0.380777 (* 1 = 0.380777 loss)
I0625 20:23:27.186409 18821 sgd_solver.cpp:106] Iteration 5620, lr = 1e-05
I0625 20:23:28.794163 18821 solver.cpp:228] Iteration 5640, loss = 0.492878
I0625 20:23:28.794188 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:23:28.794206 18821 solver.cpp:244]     Train net output #1: loss = 0.492878 (* 1 = 0.492878 loss)
I0625 20:23:28.794211 18821 sgd_solver.cpp:106] Iteration 5640, lr = 1e-05
I0625 20:23:30.436880 18821 solver.cpp:228] Iteration 5660, loss = 0.485182
I0625 20:23:30.436913 18821 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:23:30.436921 18821 solver.cpp:244]     Train net output #1: loss = 0.485182 (* 1 = 0.485182 loss)
I0625 20:23:30.436928 18821 sgd_solver.cpp:106] Iteration 5660, lr = 1e-05
I0625 20:23:32.069684 18821 solver.cpp:228] Iteration 5680, loss = 0.403614
I0625 20:23:32.069710 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:23:32.069716 18821 solver.cpp:244]     Train net output #1: loss = 0.403614 (* 1 = 0.403614 loss)
I0625 20:23:32.069721 18821 sgd_solver.cpp:106] Iteration 5680, lr = 1e-05
I0625 20:23:33.646872 18821 solver.cpp:337] Iteration 5700, Testing net (#0)
I0625 20:23:36.658077 18821 solver.cpp:404]     Test net output #0: accuracy = 0.786621
I0625 20:23:36.658119 18821 solver.cpp:404]     Test net output #1: loss = 0.462135 (* 1 = 0.462135 loss)
I0625 20:23:36.685992 18821 solver.cpp:228] Iteration 5700, loss = 0.481446
I0625 20:23:36.686022 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:23:36.686028 18821 solver.cpp:244]     Train net output #1: loss = 0.481446 (* 1 = 0.481446 loss)
I0625 20:23:36.686033 18821 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0625 20:23:38.293064 18821 solver.cpp:228] Iteration 5720, loss = 0.658673
I0625 20:23:38.293089 18821 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0625 20:23:38.293097 18821 solver.cpp:244]     Train net output #1: loss = 0.658673 (* 1 = 0.658673 loss)
I0625 20:23:38.293102 18821 sgd_solver.cpp:106] Iteration 5720, lr = 1e-05
I0625 20:23:39.910339 18821 solver.cpp:228] Iteration 5740, loss = 0.27389
I0625 20:23:39.910369 18821 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:23:39.910380 18821 solver.cpp:244]     Train net output #1: loss = 0.27389 (* 1 = 0.27389 loss)
I0625 20:23:39.910387 18821 sgd_solver.cpp:106] Iteration 5740, lr = 1e-05
I0625 20:23:41.529183 18821 solver.cpp:228] Iteration 5760, loss = 0.376494
I0625 20:23:41.529223 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:23:41.529233 18821 solver.cpp:244]     Train net output #1: loss = 0.376494 (* 1 = 0.376494 loss)
I0625 20:23:41.529240 18821 sgd_solver.cpp:106] Iteration 5760, lr = 1e-05
I0625 20:23:43.141566 18821 solver.cpp:228] Iteration 5780, loss = 0.630669
I0625 20:23:43.141595 18821 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:23:43.141607 18821 solver.cpp:244]     Train net output #1: loss = 0.630669 (* 1 = 0.630669 loss)
I0625 20:23:43.141614 18821 sgd_solver.cpp:106] Iteration 5780, lr = 1e-05
I0625 20:23:44.718767 18821 solver.cpp:337] Iteration 5800, Testing net (#0)
I0625 20:23:47.722029 18821 solver.cpp:404]     Test net output #0: accuracy = 0.785645
I0625 20:23:47.722064 18821 solver.cpp:404]     Test net output #1: loss = 0.464611 (* 1 = 0.464611 loss)
I0625 20:23:47.749904 18821 solver.cpp:228] Iteration 5800, loss = 0.475163
I0625 20:23:47.749933 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:23:47.749943 18821 solver.cpp:244]     Train net output #1: loss = 0.475163 (* 1 = 0.475163 loss)
I0625 20:23:47.749950 18821 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0625 20:23:49.357427 18821 solver.cpp:228] Iteration 5820, loss = 0.37673
I0625 20:23:49.357458 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:23:49.357468 18821 solver.cpp:244]     Train net output #1: loss = 0.37673 (* 1 = 0.37673 loss)
I0625 20:23:49.357504 18821 sgd_solver.cpp:106] Iteration 5820, lr = 1e-05
I0625 20:23:50.958398 18821 solver.cpp:228] Iteration 5840, loss = 0.554665
I0625 20:23:50.958427 18821 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0625 20:23:50.958436 18821 solver.cpp:244]     Train net output #1: loss = 0.554665 (* 1 = 0.554665 loss)
I0625 20:23:50.958441 18821 sgd_solver.cpp:106] Iteration 5840, lr = 1e-05
I0625 20:23:52.560003 18821 solver.cpp:228] Iteration 5860, loss = 0.441869
I0625 20:23:52.560039 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:23:52.560046 18821 solver.cpp:244]     Train net output #1: loss = 0.441869 (* 1 = 0.441869 loss)
I0625 20:23:52.560050 18821 sgd_solver.cpp:106] Iteration 5860, lr = 1e-05
I0625 20:23:54.160784 18821 solver.cpp:228] Iteration 5880, loss = 0.411889
I0625 20:23:54.160825 18821 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:23:54.160831 18821 solver.cpp:244]     Train net output #1: loss = 0.411889 (* 1 = 0.411889 loss)
I0625 20:23:54.160836 18821 sgd_solver.cpp:106] Iteration 5880, lr = 1e-05
I0625 20:23:55.814637 18821 solver.cpp:337] Iteration 5900, Testing net (#0)
I0625 20:23:59.067885 18821 solver.cpp:404]     Test net output #0: accuracy = 0.782715
I0625 20:23:59.068032 18821 solver.cpp:404]     Test net output #1: loss = 0.469339 (* 1 = 0.469339 loss)
I0625 20:23:59.095427 18821 solver.cpp:228] Iteration 5900, loss = 0.561873
I0625 20:23:59.095459 18821 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:23:59.095466 18821 solver.cpp:244]     Train net output #1: loss = 0.561873 (* 1 = 0.561873 loss)
I0625 20:23:59.095473 18821 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0625 20:24:00.834012 18821 solver.cpp:228] Iteration 5920, loss = 0.430078
I0625 20:24:00.834038 18821 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:24:00.834045 18821 solver.cpp:244]     Train net output #1: loss = 0.430078 (* 1 = 0.430078 loss)
I0625 20:24:00.834051 18821 sgd_solver.cpp:106] Iteration 5920, lr = 1e-05
I0625 20:24:02.445139 18821 solver.cpp:228] Iteration 5940, loss = 0.555281
I0625 20:24:02.445165 18821 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:24:02.445173 18821 solver.cpp:244]     Train net output #1: loss = 0.555281 (* 1 = 0.555281 loss)
I0625 20:24:02.445178 18821 sgd_solver.cpp:106] Iteration 5940, lr = 1e-05
I0625 20:24:04.070363 18821 solver.cpp:228] Iteration 5960, loss = 0.736925
I0625 20:24:04.070392 18821 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0625 20:24:04.070400 18821 solver.cpp:244]     Train net output #1: loss = 0.736925 (* 1 = 0.736925 loss)
I0625 20:24:04.070405 18821 sgd_solver.cpp:106] Iteration 5960, lr = 1e-05
I0625 20:24:05.693336 18821 solver.cpp:228] Iteration 5980, loss = 0.581557
I0625 20:24:05.693361 18821 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:24:05.693368 18821 solver.cpp:244]     Train net output #1: loss = 0.581557 (* 1 = 0.581557 loss)
I0625 20:24:05.693373 18821 sgd_solver.cpp:106] Iteration 5980, lr = 1e-05
I0625 20:24:07.302237 18821 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_6000.caffemodel
I0625 20:24:07.322204 18821 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_6000.solverstate
I0625 20:24:07.355864 18821 solver.cpp:317] Iteration 6000, loss = 0.425618
I0625 20:24:07.355887 18821 solver.cpp:337] Iteration 6000, Testing net (#0)
I0625 20:24:08.899636 18821 blocking_queue.cpp:50] Data layer prefetch queue empty
I0625 20:24:10.348752 18821 solver.cpp:404]     Test net output #0: accuracy = 0.785156
I0625 20:24:10.348791 18821 solver.cpp:404]     Test net output #1: loss = 0.463262 (* 1 = 0.463262 loss)
I0625 20:24:10.348795 18821 solver.cpp:322] Optimization Done.
I0625 20:24:10.348798 18821 caffe.cpp:222] Optimization Done.
I0625 20:54:14.955435 20137 caffe.cpp:185] Using GPUs 0
I0625 20:54:14.970645 20137 caffe.cpp:190] GPU 0: Graphics Device
I0625 20:54:15.491912 20137 solver.cpp:48] Initializing solver from parameters: 
test_iter: 64
test_interval: 100
base_lr: 0.001
display: 20
max_iter: 6000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 500
snapshot_prefix: "data/models/bpnet"
solver_mode: GPU
device_id: 0
net: "models/bpnet/train_val.prototxt"
test_initialization: true
iter_size: 1
I0625 20:54:15.492046 20137 solver.cpp:91] Creating training net from net file: models/bpnet/train_val.prototxt
I0625 20:54:15.492913 20137 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0625 20:54:15.493160 20137 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 100
    crop_h: 196
    crop_w: 256
    rotation_range: 10
    scale_jitter_range: 0.1
    contrast_jitter_range: 0.3
  }
  data_param {
    source: "data/train_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  pooling_param {
    pool: AVE
    stride: 1
    kernel_h: 6
    kernel_w: 8
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0625 20:54:15.494107 20137 layer_factory.hpp:77] Creating layer data
I0625 20:54:15.494550 20137 net.cpp:91] Creating Layer data
I0625 20:54:15.494563 20137 net.cpp:399] data -> data
I0625 20:54:15.494591 20137 net.cpp:399] data -> label
I0625 20:54:15.495429 20141 db_lmdb.cpp:35] Opened lmdb data/train_lmdb
I0625 20:54:15.519987 20137 data_layer.cpp:42] output data size: 32,3,196,256
I0625 20:54:15.561175 20137 net.cpp:141] Setting up data
I0625 20:54:15.561204 20137 net.cpp:148] Top shape: 32 3 196 256 (4816896)
I0625 20:54:15.561209 20137 net.cpp:148] Top shape: 32 (32)
I0625 20:54:15.561213 20137 net.cpp:156] Memory required for data: 19267712
I0625 20:54:15.561220 20137 layer_factory.hpp:77] Creating layer label_data_1_split
I0625 20:54:15.561238 20137 net.cpp:91] Creating Layer label_data_1_split
I0625 20:54:15.561242 20137 net.cpp:425] label_data_1_split <- label
I0625 20:54:15.561251 20137 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0625 20:54:15.561259 20137 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0625 20:54:15.561297 20137 net.cpp:141] Setting up label_data_1_split
I0625 20:54:15.561303 20137 net.cpp:148] Top shape: 32 (32)
I0625 20:54:15.561308 20137 net.cpp:148] Top shape: 32 (32)
I0625 20:54:15.561311 20137 net.cpp:156] Memory required for data: 19267968
I0625 20:54:15.561316 20137 layer_factory.hpp:77] Creating layer conv1_1
I0625 20:54:15.561336 20137 net.cpp:91] Creating Layer conv1_1
I0625 20:54:15.561355 20137 net.cpp:425] conv1_1 <- data
I0625 20:54:15.561362 20137 net.cpp:399] conv1_1 -> conv1_1
I0625 20:54:15.952821 20137 net.cpp:141] Setting up conv1_1
I0625 20:54:15.952853 20137 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:54:15.952857 20137 net.cpp:156] Memory required for data: 70648192
I0625 20:54:15.952872 20137 layer_factory.hpp:77] Creating layer bn1_1
I0625 20:54:15.952891 20137 net.cpp:91] Creating Layer bn1_1
I0625 20:54:15.952895 20137 net.cpp:425] bn1_1 <- conv1_1
I0625 20:54:15.952901 20137 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0625 20:54:15.953088 20137 net.cpp:141] Setting up bn1_1
I0625 20:54:15.953097 20137 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:54:15.953101 20137 net.cpp:156] Memory required for data: 122028416
I0625 20:54:15.953119 20137 layer_factory.hpp:77] Creating layer scale1_1
I0625 20:54:15.953130 20137 net.cpp:91] Creating Layer scale1_1
I0625 20:54:15.953137 20137 net.cpp:425] scale1_1 <- conv1_1
I0625 20:54:15.953142 20137 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0625 20:54:15.953274 20137 layer_factory.hpp:77] Creating layer scale1_1
I0625 20:54:15.953421 20137 net.cpp:141] Setting up scale1_1
I0625 20:54:15.953433 20137 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:54:15.953436 20137 net.cpp:156] Memory required for data: 173408640
I0625 20:54:15.953444 20137 layer_factory.hpp:77] Creating layer relu1_1
I0625 20:54:15.953452 20137 net.cpp:91] Creating Layer relu1_1
I0625 20:54:15.953455 20137 net.cpp:425] relu1_1 <- conv1_1
I0625 20:54:15.953459 20137 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0625 20:54:15.953625 20137 net.cpp:141] Setting up relu1_1
I0625 20:54:15.953636 20137 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:54:15.953639 20137 net.cpp:156] Memory required for data: 224788864
I0625 20:54:15.953642 20137 layer_factory.hpp:77] Creating layer conv1_2
I0625 20:54:15.953652 20137 net.cpp:91] Creating Layer conv1_2
I0625 20:54:15.953656 20137 net.cpp:425] conv1_2 <- conv1_1
I0625 20:54:15.953665 20137 net.cpp:399] conv1_2 -> conv1_2
I0625 20:54:15.954697 20137 net.cpp:141] Setting up conv1_2
I0625 20:54:15.954715 20137 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:54:15.954718 20137 net.cpp:156] Memory required for data: 276169088
I0625 20:54:15.954725 20137 layer_factory.hpp:77] Creating layer bn1_2
I0625 20:54:15.954733 20137 net.cpp:91] Creating Layer bn1_2
I0625 20:54:15.954736 20137 net.cpp:425] bn1_2 <- conv1_2
I0625 20:54:15.954741 20137 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0625 20:54:15.954918 20137 net.cpp:141] Setting up bn1_2
I0625 20:54:15.954926 20137 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:54:15.954929 20137 net.cpp:156] Memory required for data: 327549312
I0625 20:54:15.954939 20137 layer_factory.hpp:77] Creating layer scale1_2
I0625 20:54:15.954949 20137 net.cpp:91] Creating Layer scale1_2
I0625 20:54:15.954952 20137 net.cpp:425] scale1_2 <- conv1_2
I0625 20:54:15.954957 20137 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0625 20:54:15.954993 20137 layer_factory.hpp:77] Creating layer scale1_2
I0625 20:54:15.955109 20137 net.cpp:141] Setting up scale1_2
I0625 20:54:15.955117 20137 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:54:15.955121 20137 net.cpp:156] Memory required for data: 378929536
I0625 20:54:15.955127 20137 layer_factory.hpp:77] Creating layer relu1_2
I0625 20:54:15.955132 20137 net.cpp:91] Creating Layer relu1_2
I0625 20:54:15.955134 20137 net.cpp:425] relu1_2 <- conv1_2
I0625 20:54:15.955140 20137 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0625 20:54:15.955315 20137 net.cpp:141] Setting up relu1_2
I0625 20:54:15.955328 20137 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:54:15.955332 20137 net.cpp:156] Memory required for data: 430309760
I0625 20:54:15.955335 20137 layer_factory.hpp:77] Creating layer pool1
I0625 20:54:15.955343 20137 net.cpp:91] Creating Layer pool1
I0625 20:54:15.955345 20137 net.cpp:425] pool1 <- conv1_2
I0625 20:54:15.955350 20137 net.cpp:399] pool1 -> pool1
I0625 20:54:15.955407 20137 net.cpp:141] Setting up pool1
I0625 20:54:15.955431 20137 net.cpp:148] Top shape: 32 32 49 64 (3211264)
I0625 20:54:15.955435 20137 net.cpp:156] Memory required for data: 443154816
I0625 20:54:15.955437 20137 layer_factory.hpp:77] Creating layer conv2_1
I0625 20:54:15.955448 20137 net.cpp:91] Creating Layer conv2_1
I0625 20:54:15.955454 20137 net.cpp:425] conv2_1 <- pool1
I0625 20:54:15.955461 20137 net.cpp:399] conv2_1 -> conv2_1
I0625 20:54:15.957914 20137 net.cpp:141] Setting up conv2_1
I0625 20:54:15.957931 20137 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:54:15.957934 20137 net.cpp:156] Memory required for data: 468844928
I0625 20:54:15.957939 20137 layer_factory.hpp:77] Creating layer bn2_1
I0625 20:54:15.957947 20137 net.cpp:91] Creating Layer bn2_1
I0625 20:54:15.957949 20137 net.cpp:425] bn2_1 <- conv2_1
I0625 20:54:15.957957 20137 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0625 20:54:15.959472 20137 net.cpp:141] Setting up bn2_1
I0625 20:54:15.959486 20137 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:54:15.959489 20137 net.cpp:156] Memory required for data: 494535040
I0625 20:54:15.959497 20137 layer_factory.hpp:77] Creating layer scale2_1
I0625 20:54:15.959504 20137 net.cpp:91] Creating Layer scale2_1
I0625 20:54:15.959508 20137 net.cpp:425] scale2_1 <- conv2_1
I0625 20:54:15.959513 20137 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0625 20:54:15.959555 20137 layer_factory.hpp:77] Creating layer scale2_1
I0625 20:54:15.959662 20137 net.cpp:141] Setting up scale2_1
I0625 20:54:15.959671 20137 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:54:15.959673 20137 net.cpp:156] Memory required for data: 520225152
I0625 20:54:15.959682 20137 layer_factory.hpp:77] Creating layer relu2_1
I0625 20:54:15.959688 20137 net.cpp:91] Creating Layer relu2_1
I0625 20:54:15.959692 20137 net.cpp:425] relu2_1 <- conv2_1
I0625 20:54:15.959697 20137 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0625 20:54:15.960176 20137 net.cpp:141] Setting up relu2_1
I0625 20:54:15.960191 20137 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:54:15.960194 20137 net.cpp:156] Memory required for data: 545915264
I0625 20:54:15.960198 20137 layer_factory.hpp:77] Creating layer conv2_2
I0625 20:54:15.960208 20137 net.cpp:91] Creating Layer conv2_2
I0625 20:54:15.960212 20137 net.cpp:425] conv2_2 <- conv2_1
I0625 20:54:15.960219 20137 net.cpp:399] conv2_2 -> conv2_2
I0625 20:54:15.961133 20137 net.cpp:141] Setting up conv2_2
I0625 20:54:15.961148 20137 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:54:15.961150 20137 net.cpp:156] Memory required for data: 571605376
I0625 20:54:15.961155 20137 layer_factory.hpp:77] Creating layer bn2_2
I0625 20:54:15.961164 20137 net.cpp:91] Creating Layer bn2_2
I0625 20:54:15.961169 20137 net.cpp:425] bn2_2 <- conv2_2
I0625 20:54:15.961175 20137 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0625 20:54:15.961347 20137 net.cpp:141] Setting up bn2_2
I0625 20:54:15.961355 20137 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:54:15.961359 20137 net.cpp:156] Memory required for data: 597295488
I0625 20:54:15.961365 20137 layer_factory.hpp:77] Creating layer scale2_2
I0625 20:54:15.961371 20137 net.cpp:91] Creating Layer scale2_2
I0625 20:54:15.961374 20137 net.cpp:425] scale2_2 <- conv2_2
I0625 20:54:15.961382 20137 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0625 20:54:15.961418 20137 layer_factory.hpp:77] Creating layer scale2_2
I0625 20:54:15.961524 20137 net.cpp:141] Setting up scale2_2
I0625 20:54:15.961532 20137 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:54:15.961535 20137 net.cpp:156] Memory required for data: 622985600
I0625 20:54:15.961540 20137 layer_factory.hpp:77] Creating layer relu2_2
I0625 20:54:15.961545 20137 net.cpp:91] Creating Layer relu2_2
I0625 20:54:15.961549 20137 net.cpp:425] relu2_2 <- conv2_2
I0625 20:54:15.961554 20137 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0625 20:54:15.962026 20137 net.cpp:141] Setting up relu2_2
I0625 20:54:15.962041 20137 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:54:15.962044 20137 net.cpp:156] Memory required for data: 648675712
I0625 20:54:15.962059 20137 layer_factory.hpp:77] Creating layer pool2
I0625 20:54:15.962069 20137 net.cpp:91] Creating Layer pool2
I0625 20:54:15.962072 20137 net.cpp:425] pool2 <- conv2_2
I0625 20:54:15.962079 20137 net.cpp:399] pool2 -> pool2
I0625 20:54:15.962122 20137 net.cpp:141] Setting up pool2
I0625 20:54:15.962133 20137 net.cpp:148] Top shape: 32 64 25 32 (1638400)
I0625 20:54:15.962136 20137 net.cpp:156] Memory required for data: 655229312
I0625 20:54:15.962139 20137 layer_factory.hpp:77] Creating layer conv3_1
I0625 20:54:15.962148 20137 net.cpp:91] Creating Layer conv3_1
I0625 20:54:15.962152 20137 net.cpp:425] conv3_1 <- pool2
I0625 20:54:15.962157 20137 net.cpp:399] conv3_1 -> conv3_1
I0625 20:54:15.964990 20137 net.cpp:141] Setting up conv3_1
I0625 20:54:15.965006 20137 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:54:15.965009 20137 net.cpp:156] Memory required for data: 668336512
I0625 20:54:15.965014 20137 layer_factory.hpp:77] Creating layer bn3_1
I0625 20:54:15.965024 20137 net.cpp:91] Creating Layer bn3_1
I0625 20:54:15.965029 20137 net.cpp:425] bn3_1 <- conv3_1
I0625 20:54:15.965032 20137 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0625 20:54:15.966508 20137 net.cpp:141] Setting up bn3_1
I0625 20:54:15.966522 20137 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:54:15.966526 20137 net.cpp:156] Memory required for data: 681443712
I0625 20:54:15.966533 20137 layer_factory.hpp:77] Creating layer scale3_1
I0625 20:54:15.966542 20137 net.cpp:91] Creating Layer scale3_1
I0625 20:54:15.966545 20137 net.cpp:425] scale3_1 <- conv3_1
I0625 20:54:15.966552 20137 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0625 20:54:15.966615 20137 layer_factory.hpp:77] Creating layer scale3_1
I0625 20:54:15.966779 20137 net.cpp:141] Setting up scale3_1
I0625 20:54:15.966792 20137 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:54:15.966795 20137 net.cpp:156] Memory required for data: 694550912
I0625 20:54:15.966801 20137 layer_factory.hpp:77] Creating layer relu3_1
I0625 20:54:15.966807 20137 net.cpp:91] Creating Layer relu3_1
I0625 20:54:15.966810 20137 net.cpp:425] relu3_1 <- conv3_1
I0625 20:54:15.966814 20137 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0625 20:54:15.966997 20137 net.cpp:141] Setting up relu3_1
I0625 20:54:15.967015 20137 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:54:15.967020 20137 net.cpp:156] Memory required for data: 707658112
I0625 20:54:15.967025 20137 layer_factory.hpp:77] Creating layer conv3_2
I0625 20:54:15.967041 20137 net.cpp:91] Creating Layer conv3_2
I0625 20:54:15.967048 20137 net.cpp:425] conv3_2 <- conv3_1
I0625 20:54:15.967057 20137 net.cpp:399] conv3_2 -> conv3_2
I0625 20:54:15.969341 20137 net.cpp:141] Setting up conv3_2
I0625 20:54:15.969357 20137 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:54:15.969360 20137 net.cpp:156] Memory required for data: 720765312
I0625 20:54:15.969365 20137 layer_factory.hpp:77] Creating layer bn3_2
I0625 20:54:15.969372 20137 net.cpp:91] Creating Layer bn3_2
I0625 20:54:15.969375 20137 net.cpp:425] bn3_2 <- conv3_2
I0625 20:54:15.969383 20137 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0625 20:54:15.969557 20137 net.cpp:141] Setting up bn3_2
I0625 20:54:15.969564 20137 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:54:15.969568 20137 net.cpp:156] Memory required for data: 733872512
I0625 20:54:15.969578 20137 layer_factory.hpp:77] Creating layer scale3_2
I0625 20:54:15.969586 20137 net.cpp:91] Creating Layer scale3_2
I0625 20:54:15.969589 20137 net.cpp:425] scale3_2 <- conv3_2
I0625 20:54:15.969594 20137 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0625 20:54:15.969630 20137 layer_factory.hpp:77] Creating layer scale3_2
I0625 20:54:15.969732 20137 net.cpp:141] Setting up scale3_2
I0625 20:54:15.969738 20137 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:54:15.969741 20137 net.cpp:156] Memory required for data: 746979712
I0625 20:54:15.969746 20137 layer_factory.hpp:77] Creating layer relu3_2
I0625 20:54:15.969753 20137 net.cpp:91] Creating Layer relu3_2
I0625 20:54:15.969755 20137 net.cpp:425] relu3_2 <- conv3_2
I0625 20:54:15.969772 20137 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0625 20:54:15.969940 20137 net.cpp:141] Setting up relu3_2
I0625 20:54:15.969951 20137 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:54:15.969954 20137 net.cpp:156] Memory required for data: 760086912
I0625 20:54:15.969957 20137 layer_factory.hpp:77] Creating layer pool3
I0625 20:54:15.969964 20137 net.cpp:91] Creating Layer pool3
I0625 20:54:15.969966 20137 net.cpp:425] pool3 <- conv3_2
I0625 20:54:15.969971 20137 net.cpp:399] pool3 -> pool3
I0625 20:54:15.970012 20137 net.cpp:141] Setting up pool3
I0625 20:54:15.970018 20137 net.cpp:148] Top shape: 32 128 13 16 (851968)
I0625 20:54:15.970021 20137 net.cpp:156] Memory required for data: 763494784
I0625 20:54:15.970023 20137 layer_factory.hpp:77] Creating layer conv4_1
I0625 20:54:15.970032 20137 net.cpp:91] Creating Layer conv4_1
I0625 20:54:15.970036 20137 net.cpp:425] conv4_1 <- pool3
I0625 20:54:15.970041 20137 net.cpp:399] conv4_1 -> conv4_1
I0625 20:54:15.973378 20137 net.cpp:141] Setting up conv4_1
I0625 20:54:15.973394 20137 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:54:15.973397 20137 net.cpp:156] Memory required for data: 770310528
I0625 20:54:15.973403 20137 layer_factory.hpp:77] Creating layer bn4_1
I0625 20:54:15.973409 20137 net.cpp:91] Creating Layer bn4_1
I0625 20:54:15.973413 20137 net.cpp:425] bn4_1 <- conv4_1
I0625 20:54:15.973419 20137 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0625 20:54:15.973598 20137 net.cpp:141] Setting up bn4_1
I0625 20:54:15.973606 20137 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:54:15.973608 20137 net.cpp:156] Memory required for data: 777126272
I0625 20:54:15.973615 20137 layer_factory.hpp:77] Creating layer scale4_1
I0625 20:54:15.973623 20137 net.cpp:91] Creating Layer scale4_1
I0625 20:54:15.973625 20137 net.cpp:425] scale4_1 <- conv4_1
I0625 20:54:15.973629 20137 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0625 20:54:15.973666 20137 layer_factory.hpp:77] Creating layer scale4_1
I0625 20:54:15.973767 20137 net.cpp:141] Setting up scale4_1
I0625 20:54:15.973775 20137 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:54:15.973778 20137 net.cpp:156] Memory required for data: 783942016
I0625 20:54:15.973783 20137 layer_factory.hpp:77] Creating layer relu4_1
I0625 20:54:15.973791 20137 net.cpp:91] Creating Layer relu4_1
I0625 20:54:15.973793 20137 net.cpp:425] relu4_1 <- conv4_1
I0625 20:54:15.973798 20137 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0625 20:54:15.973968 20137 net.cpp:141] Setting up relu4_1
I0625 20:54:15.973978 20137 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:54:15.973980 20137 net.cpp:156] Memory required for data: 790757760
I0625 20:54:15.973984 20137 layer_factory.hpp:77] Creating layer conv4_2
I0625 20:54:15.973992 20137 net.cpp:91] Creating Layer conv4_2
I0625 20:54:15.973996 20137 net.cpp:425] conv4_2 <- conv4_1
I0625 20:54:15.974002 20137 net.cpp:399] conv4_2 -> conv4_2
I0625 20:54:15.980446 20137 net.cpp:141] Setting up conv4_2
I0625 20:54:15.980463 20137 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:54:15.980466 20137 net.cpp:156] Memory required for data: 797573504
I0625 20:54:15.980471 20137 layer_factory.hpp:77] Creating layer bn4_2
I0625 20:54:15.980479 20137 net.cpp:91] Creating Layer bn4_2
I0625 20:54:15.980481 20137 net.cpp:425] bn4_2 <- conv4_2
I0625 20:54:15.980489 20137 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0625 20:54:15.980657 20137 net.cpp:141] Setting up bn4_2
I0625 20:54:15.980666 20137 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:54:15.980669 20137 net.cpp:156] Memory required for data: 804389248
I0625 20:54:15.980675 20137 layer_factory.hpp:77] Creating layer scale4_2
I0625 20:54:15.980681 20137 net.cpp:91] Creating Layer scale4_2
I0625 20:54:15.980684 20137 net.cpp:425] scale4_2 <- conv4_2
I0625 20:54:15.980689 20137 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0625 20:54:15.980726 20137 layer_factory.hpp:77] Creating layer scale4_2
I0625 20:54:15.980847 20137 net.cpp:141] Setting up scale4_2
I0625 20:54:15.980876 20137 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:54:15.980881 20137 net.cpp:156] Memory required for data: 811204992
I0625 20:54:15.980890 20137 layer_factory.hpp:77] Creating layer relu4_2
I0625 20:54:15.980902 20137 net.cpp:91] Creating Layer relu4_2
I0625 20:54:15.980907 20137 net.cpp:425] relu4_2 <- conv4_2
I0625 20:54:15.980914 20137 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0625 20:54:15.981147 20137 net.cpp:141] Setting up relu4_2
I0625 20:54:15.981164 20137 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:54:15.981169 20137 net.cpp:156] Memory required for data: 818020736
I0625 20:54:15.981174 20137 layer_factory.hpp:77] Creating layer pool4
I0625 20:54:15.981185 20137 net.cpp:91] Creating Layer pool4
I0625 20:54:15.981190 20137 net.cpp:425] pool4 <- conv4_2
I0625 20:54:15.981199 20137 net.cpp:399] pool4 -> pool4
I0625 20:54:15.981245 20137 net.cpp:141] Setting up pool4
I0625 20:54:15.981253 20137 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:54:15.981256 20137 net.cpp:156] Memory required for data: 819855744
I0625 20:54:15.981259 20137 layer_factory.hpp:77] Creating layer conv5_1
I0625 20:54:15.981267 20137 net.cpp:91] Creating Layer conv5_1
I0625 20:54:15.981271 20137 net.cpp:425] conv5_1 <- pool4
I0625 20:54:15.981276 20137 net.cpp:399] conv5_1 -> conv5_1
I0625 20:54:15.987839 20137 net.cpp:141] Setting up conv5_1
I0625 20:54:15.987856 20137 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:54:15.987860 20137 net.cpp:156] Memory required for data: 821690752
I0625 20:54:15.987864 20137 layer_factory.hpp:77] Creating layer bn5_1
I0625 20:54:15.987871 20137 net.cpp:91] Creating Layer bn5_1
I0625 20:54:15.987874 20137 net.cpp:425] bn5_1 <- conv5_1
I0625 20:54:15.987880 20137 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0625 20:54:15.988052 20137 net.cpp:141] Setting up bn5_1
I0625 20:54:15.988059 20137 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:54:15.988062 20137 net.cpp:156] Memory required for data: 823525760
I0625 20:54:15.988068 20137 layer_factory.hpp:77] Creating layer scale5_1
I0625 20:54:15.988075 20137 net.cpp:91] Creating Layer scale5_1
I0625 20:54:15.988078 20137 net.cpp:425] scale5_1 <- conv5_1
I0625 20:54:15.988082 20137 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0625 20:54:15.988118 20137 layer_factory.hpp:77] Creating layer scale5_1
I0625 20:54:15.988209 20137 net.cpp:141] Setting up scale5_1
I0625 20:54:15.988216 20137 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:54:15.988219 20137 net.cpp:156] Memory required for data: 825360768
I0625 20:54:15.988224 20137 layer_factory.hpp:77] Creating layer relu5_1
I0625 20:54:15.988229 20137 net.cpp:91] Creating Layer relu5_1
I0625 20:54:15.988232 20137 net.cpp:425] relu5_1 <- conv5_1
I0625 20:54:15.988236 20137 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0625 20:54:15.988697 20137 net.cpp:141] Setting up relu5_1
I0625 20:54:15.988709 20137 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:54:15.988713 20137 net.cpp:156] Memory required for data: 827195776
I0625 20:54:15.988716 20137 layer_factory.hpp:77] Creating layer conv5_2
I0625 20:54:15.988725 20137 net.cpp:91] Creating Layer conv5_2
I0625 20:54:15.988729 20137 net.cpp:425] conv5_2 <- conv5_1
I0625 20:54:15.988734 20137 net.cpp:399] conv5_2 -> conv5_2
I0625 20:54:15.994669 20137 net.cpp:141] Setting up conv5_2
I0625 20:54:15.994684 20137 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:54:15.994688 20137 net.cpp:156] Memory required for data: 829030784
I0625 20:54:15.994693 20137 layer_factory.hpp:77] Creating layer bn5_2
I0625 20:54:15.994700 20137 net.cpp:91] Creating Layer bn5_2
I0625 20:54:15.994704 20137 net.cpp:425] bn5_2 <- conv5_2
I0625 20:54:15.994709 20137 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0625 20:54:15.994882 20137 net.cpp:141] Setting up bn5_2
I0625 20:54:15.994890 20137 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:54:15.994892 20137 net.cpp:156] Memory required for data: 830865792
I0625 20:54:15.994899 20137 layer_factory.hpp:77] Creating layer scale5_2
I0625 20:54:15.994905 20137 net.cpp:91] Creating Layer scale5_2
I0625 20:54:15.994920 20137 net.cpp:425] scale5_2 <- conv5_2
I0625 20:54:15.994925 20137 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0625 20:54:15.994966 20137 layer_factory.hpp:77] Creating layer scale5_2
I0625 20:54:15.995062 20137 net.cpp:141] Setting up scale5_2
I0625 20:54:15.995069 20137 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:54:15.995072 20137 net.cpp:156] Memory required for data: 832700800
I0625 20:54:15.995079 20137 layer_factory.hpp:77] Creating layer relu5_2
I0625 20:54:15.995084 20137 net.cpp:91] Creating Layer relu5_2
I0625 20:54:15.995085 20137 net.cpp:425] relu5_2 <- conv5_2
I0625 20:54:15.995090 20137 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0625 20:54:15.995545 20137 net.cpp:141] Setting up relu5_2
I0625 20:54:15.995559 20137 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:54:15.995563 20137 net.cpp:156] Memory required for data: 834535808
I0625 20:54:15.995565 20137 layer_factory.hpp:77] Creating layer pool5
I0625 20:54:15.995573 20137 net.cpp:91] Creating Layer pool5
I0625 20:54:15.995576 20137 net.cpp:425] pool5 <- conv5_2
I0625 20:54:15.995580 20137 net.cpp:399] pool5 -> pool5
I0625 20:54:15.995762 20137 net.cpp:141] Setting up pool5
I0625 20:54:15.995774 20137 net.cpp:148] Top shape: 32 256 2 1 (16384)
I0625 20:54:15.995776 20137 net.cpp:156] Memory required for data: 834601344
I0625 20:54:15.995779 20137 layer_factory.hpp:77] Creating layer fc2
I0625 20:54:15.995785 20137 net.cpp:91] Creating Layer fc2
I0625 20:54:15.995789 20137 net.cpp:425] fc2 <- pool5
I0625 20:54:15.995795 20137 net.cpp:399] fc2 -> fc2
I0625 20:54:15.995900 20137 net.cpp:141] Setting up fc2
I0625 20:54:15.995908 20137 net.cpp:148] Top shape: 32 2 (64)
I0625 20:54:15.995910 20137 net.cpp:156] Memory required for data: 834601600
I0625 20:54:15.995916 20137 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0625 20:54:15.995923 20137 net.cpp:91] Creating Layer fc2_fc2_0_split
I0625 20:54:15.995925 20137 net.cpp:425] fc2_fc2_0_split <- fc2
I0625 20:54:15.995929 20137 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0625 20:54:15.995934 20137 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0625 20:54:15.995966 20137 net.cpp:141] Setting up fc2_fc2_0_split
I0625 20:54:15.995973 20137 net.cpp:148] Top shape: 32 2 (64)
I0625 20:54:15.995976 20137 net.cpp:148] Top shape: 32 2 (64)
I0625 20:54:15.995978 20137 net.cpp:156] Memory required for data: 834602112
I0625 20:54:15.995981 20137 layer_factory.hpp:77] Creating layer loss
I0625 20:54:15.995992 20137 net.cpp:91] Creating Layer loss
I0625 20:54:15.995998 20137 net.cpp:425] loss <- fc2_fc2_0_split_0
I0625 20:54:15.996001 20137 net.cpp:425] loss <- label_data_1_split_0
I0625 20:54:15.996006 20137 net.cpp:399] loss -> loss
I0625 20:54:15.996013 20137 layer_factory.hpp:77] Creating layer loss
I0625 20:54:15.996253 20137 net.cpp:141] Setting up loss
I0625 20:54:15.996263 20137 net.cpp:148] Top shape: (1)
I0625 20:54:15.996265 20137 net.cpp:151]     with loss weight 1
I0625 20:54:15.996280 20137 net.cpp:156] Memory required for data: 834602116
I0625 20:54:15.996284 20137 layer_factory.hpp:77] Creating layer accuracy
I0625 20:54:15.996289 20137 net.cpp:91] Creating Layer accuracy
I0625 20:54:15.996291 20137 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0625 20:54:15.996295 20137 net.cpp:425] accuracy <- label_data_1_split_1
I0625 20:54:15.996300 20137 net.cpp:399] accuracy -> accuracy
I0625 20:54:15.996309 20137 net.cpp:141] Setting up accuracy
I0625 20:54:15.996311 20137 net.cpp:148] Top shape: (1)
I0625 20:54:15.996314 20137 net.cpp:156] Memory required for data: 834602120
I0625 20:54:15.996316 20137 net.cpp:219] accuracy does not need backward computation.
I0625 20:54:15.996320 20137 net.cpp:217] loss needs backward computation.
I0625 20:54:15.996322 20137 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0625 20:54:15.996325 20137 net.cpp:217] fc2 needs backward computation.
I0625 20:54:15.996326 20137 net.cpp:217] pool5 needs backward computation.
I0625 20:54:15.996330 20137 net.cpp:217] relu5_2 needs backward computation.
I0625 20:54:15.996331 20137 net.cpp:217] scale5_2 needs backward computation.
I0625 20:54:15.996345 20137 net.cpp:217] bn5_2 needs backward computation.
I0625 20:54:15.996347 20137 net.cpp:217] conv5_2 needs backward computation.
I0625 20:54:15.996350 20137 net.cpp:217] relu5_1 needs backward computation.
I0625 20:54:15.996352 20137 net.cpp:217] scale5_1 needs backward computation.
I0625 20:54:15.996354 20137 net.cpp:217] bn5_1 needs backward computation.
I0625 20:54:15.996356 20137 net.cpp:217] conv5_1 needs backward computation.
I0625 20:54:15.996358 20137 net.cpp:217] pool4 needs backward computation.
I0625 20:54:15.996361 20137 net.cpp:217] relu4_2 needs backward computation.
I0625 20:54:15.996363 20137 net.cpp:217] scale4_2 needs backward computation.
I0625 20:54:15.996366 20137 net.cpp:217] bn4_2 needs backward computation.
I0625 20:54:15.996368 20137 net.cpp:217] conv4_2 needs backward computation.
I0625 20:54:15.996371 20137 net.cpp:217] relu4_1 needs backward computation.
I0625 20:54:15.996372 20137 net.cpp:217] scale4_1 needs backward computation.
I0625 20:54:15.996376 20137 net.cpp:217] bn4_1 needs backward computation.
I0625 20:54:15.996377 20137 net.cpp:217] conv4_1 needs backward computation.
I0625 20:54:15.996381 20137 net.cpp:217] pool3 needs backward computation.
I0625 20:54:15.996382 20137 net.cpp:217] relu3_2 needs backward computation.
I0625 20:54:15.996386 20137 net.cpp:217] scale3_2 needs backward computation.
I0625 20:54:15.996387 20137 net.cpp:217] bn3_2 needs backward computation.
I0625 20:54:15.996389 20137 net.cpp:217] conv3_2 needs backward computation.
I0625 20:54:15.996392 20137 net.cpp:217] relu3_1 needs backward computation.
I0625 20:54:15.996394 20137 net.cpp:217] scale3_1 needs backward computation.
I0625 20:54:15.996397 20137 net.cpp:217] bn3_1 needs backward computation.
I0625 20:54:15.996398 20137 net.cpp:217] conv3_1 needs backward computation.
I0625 20:54:15.996402 20137 net.cpp:217] pool2 needs backward computation.
I0625 20:54:15.996404 20137 net.cpp:217] relu2_2 needs backward computation.
I0625 20:54:15.996407 20137 net.cpp:217] scale2_2 needs backward computation.
I0625 20:54:15.996409 20137 net.cpp:217] bn2_2 needs backward computation.
I0625 20:54:15.996412 20137 net.cpp:217] conv2_2 needs backward computation.
I0625 20:54:15.996413 20137 net.cpp:217] relu2_1 needs backward computation.
I0625 20:54:15.996417 20137 net.cpp:217] scale2_1 needs backward computation.
I0625 20:54:15.996418 20137 net.cpp:217] bn2_1 needs backward computation.
I0625 20:54:15.996420 20137 net.cpp:217] conv2_1 needs backward computation.
I0625 20:54:15.996423 20137 net.cpp:217] pool1 needs backward computation.
I0625 20:54:15.996426 20137 net.cpp:217] relu1_2 needs backward computation.
I0625 20:54:15.996428 20137 net.cpp:217] scale1_2 needs backward computation.
I0625 20:54:15.996430 20137 net.cpp:217] bn1_2 needs backward computation.
I0625 20:54:15.996433 20137 net.cpp:217] conv1_2 needs backward computation.
I0625 20:54:15.996435 20137 net.cpp:217] relu1_1 needs backward computation.
I0625 20:54:15.996438 20137 net.cpp:217] scale1_1 needs backward computation.
I0625 20:54:15.996440 20137 net.cpp:217] bn1_1 needs backward computation.
I0625 20:54:15.996443 20137 net.cpp:217] conv1_1 needs backward computation.
I0625 20:54:15.996446 20137 net.cpp:219] label_data_1_split does not need backward computation.
I0625 20:54:15.996449 20137 net.cpp:219] data does not need backward computation.
I0625 20:54:15.996451 20137 net.cpp:261] This network produces output accuracy
I0625 20:54:15.996454 20137 net.cpp:261] This network produces output loss
I0625 20:54:15.996475 20137 net.cpp:274] Network initialization done.
I0625 20:54:15.997396 20137 solver.cpp:181] Creating test net (#0) specified by net file: models/bpnet/train_val.prototxt
I0625 20:54:15.997454 20137 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0625 20:54:15.997697 20137 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 100
    crop_h: 196
    crop_w: 256
  }
  data_param {
    source: "data/val_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  pooling_param {
    pool: AVE
    stride: 1
    kernel_h: 6
    kernel_w: 8
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0625 20:54:15.997856 20137 layer_factory.hpp:77] Creating layer data
I0625 20:54:15.997938 20137 net.cpp:91] Creating Layer data
I0625 20:54:15.997946 20137 net.cpp:399] data -> data
I0625 20:54:15.997952 20137 net.cpp:399] data -> label
I0625 20:54:15.999343 20150 db_lmdb.cpp:35] Opened lmdb data/val_lmdb
I0625 20:54:15.999748 20137 data_layer.cpp:42] output data size: 64,3,196,256
I0625 20:54:16.082700 20137 net.cpp:141] Setting up data
I0625 20:54:16.082725 20137 net.cpp:148] Top shape: 64 3 196 256 (9633792)
I0625 20:54:16.082728 20137 net.cpp:148] Top shape: 64 (64)
I0625 20:54:16.082731 20137 net.cpp:156] Memory required for data: 38535424
I0625 20:54:16.082736 20137 layer_factory.hpp:77] Creating layer label_data_1_split
I0625 20:54:16.082747 20137 net.cpp:91] Creating Layer label_data_1_split
I0625 20:54:16.082751 20137 net.cpp:425] label_data_1_split <- label
I0625 20:54:16.082756 20137 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0625 20:54:16.082763 20137 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0625 20:54:16.082896 20137 net.cpp:141] Setting up label_data_1_split
I0625 20:54:16.082906 20137 net.cpp:148] Top shape: 64 (64)
I0625 20:54:16.082908 20137 net.cpp:148] Top shape: 64 (64)
I0625 20:54:16.082911 20137 net.cpp:156] Memory required for data: 38535936
I0625 20:54:16.082913 20137 layer_factory.hpp:77] Creating layer conv1_1
I0625 20:54:16.082926 20137 net.cpp:91] Creating Layer conv1_1
I0625 20:54:16.082928 20137 net.cpp:425] conv1_1 <- data
I0625 20:54:16.082932 20137 net.cpp:399] conv1_1 -> conv1_1
I0625 20:54:16.084028 20137 net.cpp:141] Setting up conv1_1
I0625 20:54:16.084040 20137 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:54:16.084043 20137 net.cpp:156] Memory required for data: 141296384
I0625 20:54:16.084049 20137 layer_factory.hpp:77] Creating layer bn1_1
I0625 20:54:16.084058 20137 net.cpp:91] Creating Layer bn1_1
I0625 20:54:16.084060 20137 net.cpp:425] bn1_1 <- conv1_1
I0625 20:54:16.084065 20137 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0625 20:54:16.084313 20137 net.cpp:141] Setting up bn1_1
I0625 20:54:16.084321 20137 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:54:16.084323 20137 net.cpp:156] Memory required for data: 244056832
I0625 20:54:16.084332 20137 layer_factory.hpp:77] Creating layer scale1_1
I0625 20:54:16.084342 20137 net.cpp:91] Creating Layer scale1_1
I0625 20:54:16.084344 20137 net.cpp:425] scale1_1 <- conv1_1
I0625 20:54:16.084362 20137 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0625 20:54:16.087319 20137 layer_factory.hpp:77] Creating layer scale1_1
I0625 20:54:16.087431 20137 net.cpp:141] Setting up scale1_1
I0625 20:54:16.087438 20137 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:54:16.087441 20137 net.cpp:156] Memory required for data: 346817280
I0625 20:54:16.087447 20137 layer_factory.hpp:77] Creating layer relu1_1
I0625 20:54:16.087455 20137 net.cpp:91] Creating Layer relu1_1
I0625 20:54:16.087456 20137 net.cpp:425] relu1_1 <- conv1_1
I0625 20:54:16.087461 20137 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0625 20:54:16.087615 20137 net.cpp:141] Setting up relu1_1
I0625 20:54:16.087622 20137 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:54:16.087625 20137 net.cpp:156] Memory required for data: 449577728
I0625 20:54:16.087627 20137 layer_factory.hpp:77] Creating layer conv1_2
I0625 20:54:16.087636 20137 net.cpp:91] Creating Layer conv1_2
I0625 20:54:16.087638 20137 net.cpp:425] conv1_2 <- conv1_1
I0625 20:54:16.087643 20137 net.cpp:399] conv1_2 -> conv1_2
I0625 20:54:16.088543 20137 net.cpp:141] Setting up conv1_2
I0625 20:54:16.088556 20137 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:54:16.088558 20137 net.cpp:156] Memory required for data: 552338176
I0625 20:54:16.088562 20137 layer_factory.hpp:77] Creating layer bn1_2
I0625 20:54:16.088570 20137 net.cpp:91] Creating Layer bn1_2
I0625 20:54:16.088572 20137 net.cpp:425] bn1_2 <- conv1_2
I0625 20:54:16.088577 20137 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0625 20:54:16.088740 20137 net.cpp:141] Setting up bn1_2
I0625 20:54:16.088747 20137 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:54:16.088750 20137 net.cpp:156] Memory required for data: 655098624
I0625 20:54:16.088757 20137 layer_factory.hpp:77] Creating layer scale1_2
I0625 20:54:16.088765 20137 net.cpp:91] Creating Layer scale1_2
I0625 20:54:16.088768 20137 net.cpp:425] scale1_2 <- conv1_2
I0625 20:54:16.088771 20137 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0625 20:54:16.088804 20137 layer_factory.hpp:77] Creating layer scale1_2
I0625 20:54:16.088912 20137 net.cpp:141] Setting up scale1_2
I0625 20:54:16.088919 20137 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:54:16.088922 20137 net.cpp:156] Memory required for data: 757859072
I0625 20:54:16.088925 20137 layer_factory.hpp:77] Creating layer relu1_2
I0625 20:54:16.088929 20137 net.cpp:91] Creating Layer relu1_2
I0625 20:54:16.088932 20137 net.cpp:425] relu1_2 <- conv1_2
I0625 20:54:16.088937 20137 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0625 20:54:16.089346 20137 net.cpp:141] Setting up relu1_2
I0625 20:54:16.089359 20137 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:54:16.089361 20137 net.cpp:156] Memory required for data: 860619520
I0625 20:54:16.089365 20137 layer_factory.hpp:77] Creating layer pool1
I0625 20:54:16.089371 20137 net.cpp:91] Creating Layer pool1
I0625 20:54:16.089373 20137 net.cpp:425] pool1 <- conv1_2
I0625 20:54:16.089377 20137 net.cpp:399] pool1 -> pool1
I0625 20:54:16.089417 20137 net.cpp:141] Setting up pool1
I0625 20:54:16.089422 20137 net.cpp:148] Top shape: 64 32 49 64 (6422528)
I0625 20:54:16.089424 20137 net.cpp:156] Memory required for data: 886309632
I0625 20:54:16.089426 20137 layer_factory.hpp:77] Creating layer conv2_1
I0625 20:54:16.089435 20137 net.cpp:91] Creating Layer conv2_1
I0625 20:54:16.089437 20137 net.cpp:425] conv2_1 <- pool1
I0625 20:54:16.089442 20137 net.cpp:399] conv2_1 -> conv2_1
I0625 20:54:16.090453 20137 net.cpp:141] Setting up conv2_1
I0625 20:54:16.090466 20137 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:54:16.090467 20137 net.cpp:156] Memory required for data: 937689856
I0625 20:54:16.090472 20137 layer_factory.hpp:77] Creating layer bn2_1
I0625 20:54:16.090479 20137 net.cpp:91] Creating Layer bn2_1
I0625 20:54:16.090482 20137 net.cpp:425] bn2_1 <- conv2_1
I0625 20:54:16.090486 20137 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0625 20:54:16.090677 20137 net.cpp:141] Setting up bn2_1
I0625 20:54:16.090695 20137 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:54:16.090698 20137 net.cpp:156] Memory required for data: 989070080
I0625 20:54:16.090704 20137 layer_factory.hpp:77] Creating layer scale2_1
I0625 20:54:16.090711 20137 net.cpp:91] Creating Layer scale2_1
I0625 20:54:16.090714 20137 net.cpp:425] scale2_1 <- conv2_1
I0625 20:54:16.090718 20137 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0625 20:54:16.090752 20137 layer_factory.hpp:77] Creating layer scale2_1
I0625 20:54:16.090849 20137 net.cpp:141] Setting up scale2_1
I0625 20:54:16.090855 20137 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:54:16.090857 20137 net.cpp:156] Memory required for data: 1040450304
I0625 20:54:16.090865 20137 layer_factory.hpp:77] Creating layer relu2_1
I0625 20:54:16.090869 20137 net.cpp:91] Creating Layer relu2_1
I0625 20:54:16.090873 20137 net.cpp:425] relu2_1 <- conv2_1
I0625 20:54:16.090875 20137 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0625 20:54:16.091018 20137 net.cpp:141] Setting up relu2_1
I0625 20:54:16.091027 20137 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:54:16.091028 20137 net.cpp:156] Memory required for data: 1091830528
I0625 20:54:16.091032 20137 layer_factory.hpp:77] Creating layer conv2_2
I0625 20:54:16.091039 20137 net.cpp:91] Creating Layer conv2_2
I0625 20:54:16.091042 20137 net.cpp:425] conv2_2 <- conv2_1
I0625 20:54:16.091047 20137 net.cpp:399] conv2_2 -> conv2_2
I0625 20:54:16.092108 20137 net.cpp:141] Setting up conv2_2
I0625 20:54:16.092121 20137 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:54:16.092123 20137 net.cpp:156] Memory required for data: 1143210752
I0625 20:54:16.092128 20137 layer_factory.hpp:77] Creating layer bn2_2
I0625 20:54:16.092138 20137 net.cpp:91] Creating Layer bn2_2
I0625 20:54:16.092140 20137 net.cpp:425] bn2_2 <- conv2_2
I0625 20:54:16.092144 20137 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0625 20:54:16.092303 20137 net.cpp:141] Setting up bn2_2
I0625 20:54:16.092309 20137 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:54:16.092311 20137 net.cpp:156] Memory required for data: 1194590976
I0625 20:54:16.092317 20137 layer_factory.hpp:77] Creating layer scale2_2
I0625 20:54:16.092322 20137 net.cpp:91] Creating Layer scale2_2
I0625 20:54:16.092325 20137 net.cpp:425] scale2_2 <- conv2_2
I0625 20:54:16.092329 20137 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0625 20:54:16.092360 20137 layer_factory.hpp:77] Creating layer scale2_2
I0625 20:54:16.092456 20137 net.cpp:141] Setting up scale2_2
I0625 20:54:16.092464 20137 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:54:16.092466 20137 net.cpp:156] Memory required for data: 1245971200
I0625 20:54:16.092470 20137 layer_factory.hpp:77] Creating layer relu2_2
I0625 20:54:16.092475 20137 net.cpp:91] Creating Layer relu2_2
I0625 20:54:16.092478 20137 net.cpp:425] relu2_2 <- conv2_2
I0625 20:54:16.092481 20137 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0625 20:54:16.092638 20137 net.cpp:141] Setting up relu2_2
I0625 20:54:16.092645 20137 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:54:16.092648 20137 net.cpp:156] Memory required for data: 1297351424
I0625 20:54:16.092651 20137 layer_factory.hpp:77] Creating layer pool2
I0625 20:54:16.092656 20137 net.cpp:91] Creating Layer pool2
I0625 20:54:16.092658 20137 net.cpp:425] pool2 <- conv2_2
I0625 20:54:16.092663 20137 net.cpp:399] pool2 -> pool2
I0625 20:54:16.092697 20137 net.cpp:141] Setting up pool2
I0625 20:54:16.092705 20137 net.cpp:148] Top shape: 64 64 25 32 (3276800)
I0625 20:54:16.092706 20137 net.cpp:156] Memory required for data: 1310458624
I0625 20:54:16.092708 20137 layer_factory.hpp:77] Creating layer conv3_1
I0625 20:54:16.092715 20137 net.cpp:91] Creating Layer conv3_1
I0625 20:54:16.092717 20137 net.cpp:425] conv3_1 <- pool2
I0625 20:54:16.092721 20137 net.cpp:399] conv3_1 -> conv3_1
I0625 20:54:16.095273 20137 net.cpp:141] Setting up conv3_1
I0625 20:54:16.095285 20137 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:54:16.095288 20137 net.cpp:156] Memory required for data: 1336673024
I0625 20:54:16.095302 20137 layer_factory.hpp:77] Creating layer bn3_1
I0625 20:54:16.095311 20137 net.cpp:91] Creating Layer bn3_1
I0625 20:54:16.095314 20137 net.cpp:425] bn3_1 <- conv3_1
I0625 20:54:16.095319 20137 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0625 20:54:16.095468 20137 net.cpp:141] Setting up bn3_1
I0625 20:54:16.095475 20137 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:54:16.095477 20137 net.cpp:156] Memory required for data: 1362887424
I0625 20:54:16.095484 20137 layer_factory.hpp:77] Creating layer scale3_1
I0625 20:54:16.095489 20137 net.cpp:91] Creating Layer scale3_1
I0625 20:54:16.095491 20137 net.cpp:425] scale3_1 <- conv3_1
I0625 20:54:16.095496 20137 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0625 20:54:16.095526 20137 layer_factory.hpp:77] Creating layer scale3_1
I0625 20:54:16.095618 20137 net.cpp:141] Setting up scale3_1
I0625 20:54:16.095623 20137 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:54:16.095626 20137 net.cpp:156] Memory required for data: 1389101824
I0625 20:54:16.095630 20137 layer_factory.hpp:77] Creating layer relu3_1
I0625 20:54:16.095634 20137 net.cpp:91] Creating Layer relu3_1
I0625 20:54:16.095636 20137 net.cpp:425] relu3_1 <- conv3_1
I0625 20:54:16.095639 20137 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0625 20:54:16.095785 20137 net.cpp:141] Setting up relu3_1
I0625 20:54:16.095793 20137 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:54:16.095796 20137 net.cpp:156] Memory required for data: 1415316224
I0625 20:54:16.095798 20137 layer_factory.hpp:77] Creating layer conv3_2
I0625 20:54:16.095806 20137 net.cpp:91] Creating Layer conv3_2
I0625 20:54:16.095809 20137 net.cpp:425] conv3_2 <- conv3_1
I0625 20:54:16.095813 20137 net.cpp:399] conv3_2 -> conv3_2
I0625 20:54:16.097743 20137 net.cpp:141] Setting up conv3_2
I0625 20:54:16.097755 20137 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:54:16.097759 20137 net.cpp:156] Memory required for data: 1441530624
I0625 20:54:16.097762 20137 layer_factory.hpp:77] Creating layer bn3_2
I0625 20:54:16.097769 20137 net.cpp:91] Creating Layer bn3_2
I0625 20:54:16.097771 20137 net.cpp:425] bn3_2 <- conv3_2
I0625 20:54:16.097776 20137 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0625 20:54:16.097935 20137 net.cpp:141] Setting up bn3_2
I0625 20:54:16.097942 20137 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:54:16.097944 20137 net.cpp:156] Memory required for data: 1467745024
I0625 20:54:16.097955 20137 layer_factory.hpp:77] Creating layer scale3_2
I0625 20:54:16.097961 20137 net.cpp:91] Creating Layer scale3_2
I0625 20:54:16.097965 20137 net.cpp:425] scale3_2 <- conv3_2
I0625 20:54:16.097967 20137 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0625 20:54:16.098006 20137 layer_factory.hpp:77] Creating layer scale3_2
I0625 20:54:16.098098 20137 net.cpp:141] Setting up scale3_2
I0625 20:54:16.098104 20137 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:54:16.098106 20137 net.cpp:156] Memory required for data: 1493959424
I0625 20:54:16.098110 20137 layer_factory.hpp:77] Creating layer relu3_2
I0625 20:54:16.098114 20137 net.cpp:91] Creating Layer relu3_2
I0625 20:54:16.098116 20137 net.cpp:425] relu3_2 <- conv3_2
I0625 20:54:16.098121 20137 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0625 20:54:16.098258 20137 net.cpp:141] Setting up relu3_2
I0625 20:54:16.098266 20137 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:54:16.098268 20137 net.cpp:156] Memory required for data: 1520173824
I0625 20:54:16.098271 20137 layer_factory.hpp:77] Creating layer pool3
I0625 20:54:16.098276 20137 net.cpp:91] Creating Layer pool3
I0625 20:54:16.098279 20137 net.cpp:425] pool3 <- conv3_2
I0625 20:54:16.098284 20137 net.cpp:399] pool3 -> pool3
I0625 20:54:16.098320 20137 net.cpp:141] Setting up pool3
I0625 20:54:16.098326 20137 net.cpp:148] Top shape: 64 128 13 16 (1703936)
I0625 20:54:16.098328 20137 net.cpp:156] Memory required for data: 1526989568
I0625 20:54:16.098330 20137 layer_factory.hpp:77] Creating layer conv4_1
I0625 20:54:16.098338 20137 net.cpp:91] Creating Layer conv4_1
I0625 20:54:16.098351 20137 net.cpp:425] conv4_1 <- pool3
I0625 20:54:16.098354 20137 net.cpp:399] conv4_1 -> conv4_1
I0625 20:54:16.101150 20137 net.cpp:141] Setting up conv4_1
I0625 20:54:16.101163 20137 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:54:16.101166 20137 net.cpp:156] Memory required for data: 1540621056
I0625 20:54:16.101171 20137 layer_factory.hpp:77] Creating layer bn4_1
I0625 20:54:16.101176 20137 net.cpp:91] Creating Layer bn4_1
I0625 20:54:16.101179 20137 net.cpp:425] bn4_1 <- conv4_1
I0625 20:54:16.101184 20137 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0625 20:54:16.101348 20137 net.cpp:141] Setting up bn4_1
I0625 20:54:16.101354 20137 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:54:16.101357 20137 net.cpp:156] Memory required for data: 1554252544
I0625 20:54:16.101362 20137 layer_factory.hpp:77] Creating layer scale4_1
I0625 20:54:16.101367 20137 net.cpp:91] Creating Layer scale4_1
I0625 20:54:16.101371 20137 net.cpp:425] scale4_1 <- conv4_1
I0625 20:54:16.101374 20137 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0625 20:54:16.101407 20137 layer_factory.hpp:77] Creating layer scale4_1
I0625 20:54:16.101495 20137 net.cpp:141] Setting up scale4_1
I0625 20:54:16.101502 20137 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:54:16.101505 20137 net.cpp:156] Memory required for data: 1567884032
I0625 20:54:16.101508 20137 layer_factory.hpp:77] Creating layer relu4_1
I0625 20:54:16.101516 20137 net.cpp:91] Creating Layer relu4_1
I0625 20:54:16.101518 20137 net.cpp:425] relu4_1 <- conv4_1
I0625 20:54:16.101521 20137 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0625 20:54:16.101662 20137 net.cpp:141] Setting up relu4_1
I0625 20:54:16.101671 20137 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:54:16.101673 20137 net.cpp:156] Memory required for data: 1581515520
I0625 20:54:16.101675 20137 layer_factory.hpp:77] Creating layer conv4_2
I0625 20:54:16.101683 20137 net.cpp:91] Creating Layer conv4_2
I0625 20:54:16.101686 20137 net.cpp:425] conv4_2 <- conv4_1
I0625 20:54:16.101691 20137 net.cpp:399] conv4_2 -> conv4_2
I0625 20:54:16.107321 20137 net.cpp:141] Setting up conv4_2
I0625 20:54:16.107338 20137 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:54:16.107342 20137 net.cpp:156] Memory required for data: 1595147008
I0625 20:54:16.107347 20137 layer_factory.hpp:77] Creating layer bn4_2
I0625 20:54:16.107357 20137 net.cpp:91] Creating Layer bn4_2
I0625 20:54:16.107360 20137 net.cpp:425] bn4_2 <- conv4_2
I0625 20:54:16.107369 20137 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0625 20:54:16.107607 20137 net.cpp:141] Setting up bn4_2
I0625 20:54:16.107619 20137 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:54:16.107620 20137 net.cpp:156] Memory required for data: 1608778496
I0625 20:54:16.107627 20137 layer_factory.hpp:77] Creating layer scale4_2
I0625 20:54:16.107633 20137 net.cpp:91] Creating Layer scale4_2
I0625 20:54:16.107637 20137 net.cpp:425] scale4_2 <- conv4_2
I0625 20:54:16.107642 20137 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0625 20:54:16.107678 20137 layer_factory.hpp:77] Creating layer scale4_2
I0625 20:54:16.107820 20137 net.cpp:141] Setting up scale4_2
I0625 20:54:16.107834 20137 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:54:16.107839 20137 net.cpp:156] Memory required for data: 1622409984
I0625 20:54:16.107847 20137 layer_factory.hpp:77] Creating layer relu4_2
I0625 20:54:16.107854 20137 net.cpp:91] Creating Layer relu4_2
I0625 20:54:16.107859 20137 net.cpp:425] relu4_2 <- conv4_2
I0625 20:54:16.107864 20137 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0625 20:54:16.108309 20137 net.cpp:141] Setting up relu4_2
I0625 20:54:16.108321 20137 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:54:16.108324 20137 net.cpp:156] Memory required for data: 1636041472
I0625 20:54:16.108326 20137 layer_factory.hpp:77] Creating layer pool4
I0625 20:54:16.108332 20137 net.cpp:91] Creating Layer pool4
I0625 20:54:16.108335 20137 net.cpp:425] pool4 <- conv4_2
I0625 20:54:16.108342 20137 net.cpp:399] pool4 -> pool4
I0625 20:54:16.108384 20137 net.cpp:141] Setting up pool4
I0625 20:54:16.108402 20137 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:54:16.108404 20137 net.cpp:156] Memory required for data: 1639711488
I0625 20:54:16.108407 20137 layer_factory.hpp:77] Creating layer conv5_1
I0625 20:54:16.108417 20137 net.cpp:91] Creating Layer conv5_1
I0625 20:54:16.108419 20137 net.cpp:425] conv5_1 <- pool4
I0625 20:54:16.108424 20137 net.cpp:399] conv5_1 -> conv5_1
I0625 20:54:16.114164 20137 net.cpp:141] Setting up conv5_1
I0625 20:54:16.114182 20137 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:54:16.114187 20137 net.cpp:156] Memory required for data: 1643381504
I0625 20:54:16.114190 20137 layer_factory.hpp:77] Creating layer bn5_1
I0625 20:54:16.114199 20137 net.cpp:91] Creating Layer bn5_1
I0625 20:54:16.114202 20137 net.cpp:425] bn5_1 <- conv5_1
I0625 20:54:16.114207 20137 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0625 20:54:16.114385 20137 net.cpp:141] Setting up bn5_1
I0625 20:54:16.114392 20137 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:54:16.114395 20137 net.cpp:156] Memory required for data: 1647051520
I0625 20:54:16.114400 20137 layer_factory.hpp:77] Creating layer scale5_1
I0625 20:54:16.114408 20137 net.cpp:91] Creating Layer scale5_1
I0625 20:54:16.114411 20137 net.cpp:425] scale5_1 <- conv5_1
I0625 20:54:16.114414 20137 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0625 20:54:16.114449 20137 layer_factory.hpp:77] Creating layer scale5_1
I0625 20:54:16.114539 20137 net.cpp:141] Setting up scale5_1
I0625 20:54:16.114545 20137 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:54:16.114547 20137 net.cpp:156] Memory required for data: 1650721536
I0625 20:54:16.114552 20137 layer_factory.hpp:77] Creating layer relu5_1
I0625 20:54:16.114557 20137 net.cpp:91] Creating Layer relu5_1
I0625 20:54:16.114560 20137 net.cpp:425] relu5_1 <- conv5_1
I0625 20:54:16.114563 20137 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0625 20:54:16.114708 20137 net.cpp:141] Setting up relu5_1
I0625 20:54:16.114717 20137 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:54:16.114719 20137 net.cpp:156] Memory required for data: 1654391552
I0625 20:54:16.114722 20137 layer_factory.hpp:77] Creating layer conv5_2
I0625 20:54:16.114730 20137 net.cpp:91] Creating Layer conv5_2
I0625 20:54:16.114733 20137 net.cpp:425] conv5_2 <- conv5_1
I0625 20:54:16.114737 20137 net.cpp:399] conv5_2 -> conv5_2
I0625 20:54:16.120463 20137 net.cpp:141] Setting up conv5_2
I0625 20:54:16.120479 20137 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:54:16.120482 20137 net.cpp:156] Memory required for data: 1658061568
I0625 20:54:16.120487 20137 layer_factory.hpp:77] Creating layer bn5_2
I0625 20:54:16.120496 20137 net.cpp:91] Creating Layer bn5_2
I0625 20:54:16.120498 20137 net.cpp:425] bn5_2 <- conv5_2
I0625 20:54:16.120503 20137 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0625 20:54:16.120671 20137 net.cpp:141] Setting up bn5_2
I0625 20:54:16.120677 20137 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:54:16.120679 20137 net.cpp:156] Memory required for data: 1661731584
I0625 20:54:16.120685 20137 layer_factory.hpp:77] Creating layer scale5_2
I0625 20:54:16.120692 20137 net.cpp:91] Creating Layer scale5_2
I0625 20:54:16.120695 20137 net.cpp:425] scale5_2 <- conv5_2
I0625 20:54:16.120698 20137 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0625 20:54:16.120733 20137 layer_factory.hpp:77] Creating layer scale5_2
I0625 20:54:16.120822 20137 net.cpp:141] Setting up scale5_2
I0625 20:54:16.120829 20137 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:54:16.120832 20137 net.cpp:156] Memory required for data: 1665401600
I0625 20:54:16.120836 20137 layer_factory.hpp:77] Creating layer relu5_2
I0625 20:54:16.120841 20137 net.cpp:91] Creating Layer relu5_2
I0625 20:54:16.120843 20137 net.cpp:425] relu5_2 <- conv5_2
I0625 20:54:16.120847 20137 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0625 20:54:16.120996 20137 net.cpp:141] Setting up relu5_2
I0625 20:54:16.121004 20137 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:54:16.121006 20137 net.cpp:156] Memory required for data: 1669071616
I0625 20:54:16.121026 20137 layer_factory.hpp:77] Creating layer pool5
I0625 20:54:16.121033 20137 net.cpp:91] Creating Layer pool5
I0625 20:54:16.121036 20137 net.cpp:425] pool5 <- conv5_2
I0625 20:54:16.121039 20137 net.cpp:399] pool5 -> pool5
I0625 20:54:16.121201 20137 net.cpp:141] Setting up pool5
I0625 20:54:16.121209 20137 net.cpp:148] Top shape: 64 256 2 1 (32768)
I0625 20:54:16.121212 20137 net.cpp:156] Memory required for data: 1669202688
I0625 20:54:16.121214 20137 layer_factory.hpp:77] Creating layer fc2
I0625 20:54:16.121220 20137 net.cpp:91] Creating Layer fc2
I0625 20:54:16.121222 20137 net.cpp:425] fc2 <- pool5
I0625 20:54:16.121228 20137 net.cpp:399] fc2 -> fc2
I0625 20:54:16.121331 20137 net.cpp:141] Setting up fc2
I0625 20:54:16.121338 20137 net.cpp:148] Top shape: 64 2 (128)
I0625 20:54:16.121340 20137 net.cpp:156] Memory required for data: 1669203200
I0625 20:54:16.121345 20137 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0625 20:54:16.121350 20137 net.cpp:91] Creating Layer fc2_fc2_0_split
I0625 20:54:16.121351 20137 net.cpp:425] fc2_fc2_0_split <- fc2
I0625 20:54:16.121356 20137 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0625 20:54:16.121361 20137 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0625 20:54:16.121389 20137 net.cpp:141] Setting up fc2_fc2_0_split
I0625 20:54:16.121394 20137 net.cpp:148] Top shape: 64 2 (128)
I0625 20:54:16.121397 20137 net.cpp:148] Top shape: 64 2 (128)
I0625 20:54:16.121398 20137 net.cpp:156] Memory required for data: 1669204224
I0625 20:54:16.121400 20137 layer_factory.hpp:77] Creating layer loss
I0625 20:54:16.121405 20137 net.cpp:91] Creating Layer loss
I0625 20:54:16.121407 20137 net.cpp:425] loss <- fc2_fc2_0_split_0
I0625 20:54:16.121410 20137 net.cpp:425] loss <- label_data_1_split_0
I0625 20:54:16.121414 20137 net.cpp:399] loss -> loss
I0625 20:54:16.121419 20137 layer_factory.hpp:77] Creating layer loss
I0625 20:54:16.121934 20137 net.cpp:141] Setting up loss
I0625 20:54:16.121945 20137 net.cpp:148] Top shape: (1)
I0625 20:54:16.121948 20137 net.cpp:151]     with loss weight 1
I0625 20:54:16.121955 20137 net.cpp:156] Memory required for data: 1669204228
I0625 20:54:16.121958 20137 layer_factory.hpp:77] Creating layer accuracy
I0625 20:54:16.121963 20137 net.cpp:91] Creating Layer accuracy
I0625 20:54:16.121966 20137 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0625 20:54:16.121969 20137 net.cpp:425] accuracy <- label_data_1_split_1
I0625 20:54:16.121975 20137 net.cpp:399] accuracy -> accuracy
I0625 20:54:16.121981 20137 net.cpp:141] Setting up accuracy
I0625 20:54:16.121984 20137 net.cpp:148] Top shape: (1)
I0625 20:54:16.121986 20137 net.cpp:156] Memory required for data: 1669204232
I0625 20:54:16.121989 20137 net.cpp:219] accuracy does not need backward computation.
I0625 20:54:16.121991 20137 net.cpp:217] loss needs backward computation.
I0625 20:54:16.121994 20137 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0625 20:54:16.121996 20137 net.cpp:217] fc2 needs backward computation.
I0625 20:54:16.121999 20137 net.cpp:217] pool5 needs backward computation.
I0625 20:54:16.122000 20137 net.cpp:217] relu5_2 needs backward computation.
I0625 20:54:16.122004 20137 net.cpp:217] scale5_2 needs backward computation.
I0625 20:54:16.122004 20137 net.cpp:217] bn5_2 needs backward computation.
I0625 20:54:16.122006 20137 net.cpp:217] conv5_2 needs backward computation.
I0625 20:54:16.122009 20137 net.cpp:217] relu5_1 needs backward computation.
I0625 20:54:16.122011 20137 net.cpp:217] scale5_1 needs backward computation.
I0625 20:54:16.122014 20137 net.cpp:217] bn5_1 needs backward computation.
I0625 20:54:16.122015 20137 net.cpp:217] conv5_1 needs backward computation.
I0625 20:54:16.122017 20137 net.cpp:217] pool4 needs backward computation.
I0625 20:54:16.122020 20137 net.cpp:217] relu4_2 needs backward computation.
I0625 20:54:16.122022 20137 net.cpp:217] scale4_2 needs backward computation.
I0625 20:54:16.122025 20137 net.cpp:217] bn4_2 needs backward computation.
I0625 20:54:16.122026 20137 net.cpp:217] conv4_2 needs backward computation.
I0625 20:54:16.122038 20137 net.cpp:217] relu4_1 needs backward computation.
I0625 20:54:16.122041 20137 net.cpp:217] scale4_1 needs backward computation.
I0625 20:54:16.122043 20137 net.cpp:217] bn4_1 needs backward computation.
I0625 20:54:16.122045 20137 net.cpp:217] conv4_1 needs backward computation.
I0625 20:54:16.122051 20137 net.cpp:217] pool3 needs backward computation.
I0625 20:54:16.122054 20137 net.cpp:217] relu3_2 needs backward computation.
I0625 20:54:16.122056 20137 net.cpp:217] scale3_2 needs backward computation.
I0625 20:54:16.122058 20137 net.cpp:217] bn3_2 needs backward computation.
I0625 20:54:16.122061 20137 net.cpp:217] conv3_2 needs backward computation.
I0625 20:54:16.122062 20137 net.cpp:217] relu3_1 needs backward computation.
I0625 20:54:16.122066 20137 net.cpp:217] scale3_1 needs backward computation.
I0625 20:54:16.122067 20137 net.cpp:217] bn3_1 needs backward computation.
I0625 20:54:16.122069 20137 net.cpp:217] conv3_1 needs backward computation.
I0625 20:54:16.122071 20137 net.cpp:217] pool2 needs backward computation.
I0625 20:54:16.122073 20137 net.cpp:217] relu2_2 needs backward computation.
I0625 20:54:16.122076 20137 net.cpp:217] scale2_2 needs backward computation.
I0625 20:54:16.122078 20137 net.cpp:217] bn2_2 needs backward computation.
I0625 20:54:16.122081 20137 net.cpp:217] conv2_2 needs backward computation.
I0625 20:54:16.122082 20137 net.cpp:217] relu2_1 needs backward computation.
I0625 20:54:16.122086 20137 net.cpp:217] scale2_1 needs backward computation.
I0625 20:54:16.122087 20137 net.cpp:217] bn2_1 needs backward computation.
I0625 20:54:16.122089 20137 net.cpp:217] conv2_1 needs backward computation.
I0625 20:54:16.122092 20137 net.cpp:217] pool1 needs backward computation.
I0625 20:54:16.122093 20137 net.cpp:217] relu1_2 needs backward computation.
I0625 20:54:16.122095 20137 net.cpp:217] scale1_2 needs backward computation.
I0625 20:54:16.122098 20137 net.cpp:217] bn1_2 needs backward computation.
I0625 20:54:16.122100 20137 net.cpp:217] conv1_2 needs backward computation.
I0625 20:54:16.122102 20137 net.cpp:217] relu1_1 needs backward computation.
I0625 20:54:16.122104 20137 net.cpp:217] scale1_1 needs backward computation.
I0625 20:54:16.122107 20137 net.cpp:217] bn1_1 needs backward computation.
I0625 20:54:16.122109 20137 net.cpp:217] conv1_1 needs backward computation.
I0625 20:54:16.122112 20137 net.cpp:219] label_data_1_split does not need backward computation.
I0625 20:54:16.122115 20137 net.cpp:219] data does not need backward computation.
I0625 20:54:16.122117 20137 net.cpp:261] This network produces output accuracy
I0625 20:54:16.122119 20137 net.cpp:261] This network produces output loss
I0625 20:54:16.122138 20137 net.cpp:274] Network initialization done.
I0625 20:54:16.122274 20137 solver.cpp:60] Solver scaffolding done.
I0625 20:54:16.123982 20137 caffe.cpp:209] Resuming from data/models/bpnet_iter_2000.solverstate
I0625 20:54:16.151852 20137 sgd_solver.cpp:318] SGDSolver: restoring history
I0625 20:54:16.159760 20137 caffe.cpp:219] Starting Optimization
I0625 20:54:16.159782 20137 solver.cpp:279] Solving BPnet
I0625 20:54:16.159786 20137 solver.cpp:280] Learning Rate Policy: step
I0625 20:54:16.161903 20137 solver.cpp:337] Iteration 2000, Testing net (#0)
I0625 20:54:16.275341 20137 blocking_queue.cpp:50] Data layer prefetch queue empty
I0625 20:54:19.210381 20137 solver.cpp:404]     Test net output #0: accuracy = 0.784912
I0625 20:54:19.210408 20137 solver.cpp:404]     Test net output #1: loss = 0.445639 (* 1 = 0.445639 loss)
I0625 20:54:19.297022 20137 solver.cpp:228] Iteration 2000, loss = 0.427931
I0625 20:54:19.297056 20137 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:54:19.297065 20137 solver.cpp:244]     Train net output #1: loss = 0.427931 (* 1 = 0.427931 loss)
I0625 20:54:19.297076 20137 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0625 20:54:20.863551 20137 solver.cpp:228] Iteration 2020, loss = 0.63189
I0625 20:54:20.863576 20137 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:54:20.863584 20137 solver.cpp:244]     Train net output #1: loss = 0.63189 (* 1 = 0.63189 loss)
I0625 20:54:20.863602 20137 sgd_solver.cpp:106] Iteration 2020, lr = 0.0001
I0625 20:54:22.454905 20137 solver.cpp:228] Iteration 2040, loss = 0.368209
I0625 20:54:22.454941 20137 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:54:22.454948 20137 solver.cpp:244]     Train net output #1: loss = 0.368209 (* 1 = 0.368209 loss)
I0625 20:54:22.454953 20137 sgd_solver.cpp:106] Iteration 2040, lr = 0.0001
I0625 20:54:24.037168 20137 solver.cpp:228] Iteration 2060, loss = 0.420941
I0625 20:54:24.037194 20137 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0625 20:54:24.037200 20137 solver.cpp:244]     Train net output #1: loss = 0.420941 (* 1 = 0.420941 loss)
I0625 20:54:24.037205 20137 sgd_solver.cpp:106] Iteration 2060, lr = 0.0001
I0625 20:54:25.618615 20137 solver.cpp:228] Iteration 2080, loss = 0.401928
I0625 20:54:25.618641 20137 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:54:25.618649 20137 solver.cpp:244]     Train net output #1: loss = 0.401928 (* 1 = 0.401928 loss)
I0625 20:54:25.618654 20137 sgd_solver.cpp:106] Iteration 2080, lr = 0.0001
I0625 20:54:27.185559 20137 solver.cpp:337] Iteration 2100, Testing net (#0)
I0625 20:54:30.034526 20137 solver.cpp:404]     Test net output #0: accuracy = 0.799805
I0625 20:54:30.034564 20137 solver.cpp:404]     Test net output #1: loss = 0.426094 (* 1 = 0.426094 loss)
I0625 20:54:30.062503 20137 solver.cpp:228] Iteration 2100, loss = 0.48983
I0625 20:54:30.062530 20137 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:54:30.062541 20137 solver.cpp:244]     Train net output #1: loss = 0.48983 (* 1 = 0.48983 loss)
I0625 20:54:30.062546 20137 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0625 20:54:31.670066 20137 solver.cpp:228] Iteration 2120, loss = 0.276773
I0625 20:54:31.670089 20137 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0625 20:54:31.670097 20137 solver.cpp:244]     Train net output #1: loss = 0.276773 (* 1 = 0.276773 loss)
I0625 20:54:31.670101 20137 sgd_solver.cpp:106] Iteration 2120, lr = 0.0001
I0625 20:54:33.263938 20137 solver.cpp:228] Iteration 2140, loss = 0.614518
I0625 20:54:33.263973 20137 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:54:33.263980 20137 solver.cpp:244]     Train net output #1: loss = 0.614518 (* 1 = 0.614518 loss)
I0625 20:54:33.263984 20137 sgd_solver.cpp:106] Iteration 2140, lr = 0.0001
I0625 20:54:34.853394 20137 solver.cpp:228] Iteration 2160, loss = 0.421471
I0625 20:54:34.853418 20137 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:54:34.853426 20137 solver.cpp:244]     Train net output #1: loss = 0.421471 (* 1 = 0.421471 loss)
I0625 20:54:34.853431 20137 sgd_solver.cpp:106] Iteration 2160, lr = 0.0001
I0625 20:54:36.436583 20137 solver.cpp:228] Iteration 2180, loss = 0.509416
I0625 20:54:36.436609 20137 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:54:36.436616 20137 solver.cpp:244]     Train net output #1: loss = 0.509416 (* 1 = 0.509416 loss)
I0625 20:54:36.436621 20137 sgd_solver.cpp:106] Iteration 2180, lr = 0.0001
I0625 20:54:37.995537 20137 solver.cpp:337] Iteration 2200, Testing net (#0)
I0625 20:54:40.957207 20137 solver.cpp:404]     Test net output #0: accuracy = 0.791016
I0625 20:54:40.957237 20137 solver.cpp:404]     Test net output #1: loss = 0.431672 (* 1 = 0.431672 loss)
I0625 20:54:40.985563 20137 solver.cpp:228] Iteration 2200, loss = 0.422558
I0625 20:54:40.985587 20137 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:54:40.985594 20137 solver.cpp:244]     Train net output #1: loss = 0.422558 (* 1 = 0.422558 loss)
I0625 20:54:40.985599 20137 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0625 20:54:42.573549 20137 solver.cpp:228] Iteration 2220, loss = 0.411175
I0625 20:54:42.573575 20137 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:54:42.573592 20137 solver.cpp:244]     Train net output #1: loss = 0.411175 (* 1 = 0.411175 loss)
I0625 20:54:42.573621 20137 sgd_solver.cpp:106] Iteration 2220, lr = 0.0001
I0625 20:54:44.156702 20137 solver.cpp:228] Iteration 2240, loss = 0.421197
I0625 20:54:44.156724 20137 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:54:44.156731 20137 solver.cpp:244]     Train net output #1: loss = 0.421197 (* 1 = 0.421197 loss)
I0625 20:54:44.156736 20137 sgd_solver.cpp:106] Iteration 2240, lr = 0.0001
I0625 20:54:45.738600 20137 solver.cpp:228] Iteration 2260, loss = 0.541581
I0625 20:54:45.738754 20137 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:54:45.738765 20137 solver.cpp:244]     Train net output #1: loss = 0.541581 (* 1 = 0.541581 loss)
I0625 20:54:45.738770 20137 sgd_solver.cpp:106] Iteration 2260, lr = 0.0001
I0625 20:54:47.320755 20137 solver.cpp:228] Iteration 2280, loss = 0.404863
I0625 20:54:47.320791 20137 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:54:47.320798 20137 solver.cpp:244]     Train net output #1: loss = 0.404863 (* 1 = 0.404863 loss)
I0625 20:54:47.320803 20137 sgd_solver.cpp:106] Iteration 2280, lr = 0.0001
I0625 20:54:48.879492 20137 solver.cpp:337] Iteration 2300, Testing net (#0)
I0625 20:54:51.855747 20137 solver.cpp:404]     Test net output #0: accuracy = 0.790039
I0625 20:54:51.855788 20137 solver.cpp:404]     Test net output #1: loss = 0.432676 (* 1 = 0.432676 loss)
I0625 20:54:51.883615 20137 solver.cpp:228] Iteration 2300, loss = 0.411063
I0625 20:54:51.883651 20137 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:54:51.883662 20137 solver.cpp:244]     Train net output #1: loss = 0.411063 (* 1 = 0.411063 loss)
I0625 20:54:51.883671 20137 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0625 20:54:53.478392 20137 solver.cpp:228] Iteration 2320, loss = 0.534623
I0625 20:54:53.478418 20137 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:54:53.478425 20137 solver.cpp:244]     Train net output #1: loss = 0.534623 (* 1 = 0.534623 loss)
I0625 20:54:53.478430 20137 sgd_solver.cpp:106] Iteration 2320, lr = 0.0001
I0625 20:54:55.067235 20137 solver.cpp:228] Iteration 2340, loss = 0.467067
I0625 20:54:55.067272 20137 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:54:55.067279 20137 solver.cpp:244]     Train net output #1: loss = 0.467067 (* 1 = 0.467067 loss)
I0625 20:54:55.067286 20137 sgd_solver.cpp:106] Iteration 2340, lr = 0.0001
I0625 20:54:56.654759 20137 solver.cpp:228] Iteration 2360, loss = 0.346912
I0625 20:54:56.654795 20137 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 20:54:56.654803 20137 solver.cpp:244]     Train net output #1: loss = 0.346912 (* 1 = 0.346912 loss)
I0625 20:54:56.654808 20137 sgd_solver.cpp:106] Iteration 2360, lr = 0.0001
I0625 20:54:58.241933 20137 solver.cpp:228] Iteration 2380, loss = 0.416038
I0625 20:54:58.241957 20137 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:54:58.241974 20137 solver.cpp:244]     Train net output #1: loss = 0.416038 (* 1 = 0.416038 loss)
I0625 20:54:58.241979 20137 sgd_solver.cpp:106] Iteration 2380, lr = 0.0001
I0625 20:54:59.807060 20137 solver.cpp:337] Iteration 2400, Testing net (#0)
I0625 20:55:02.781976 20137 solver.cpp:404]     Test net output #0: accuracy = 0.793701
I0625 20:55:02.782004 20137 solver.cpp:404]     Test net output #1: loss = 0.425869 (* 1 = 0.425869 loss)
I0625 20:55:02.809278 20137 solver.cpp:228] Iteration 2400, loss = 0.464985
I0625 20:55:02.809305 20137 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:55:02.809314 20137 solver.cpp:244]     Train net output #1: loss = 0.464985 (* 1 = 0.464985 loss)
I0625 20:55:02.809319 20137 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0625 20:55:04.403951 20137 solver.cpp:228] Iteration 2420, loss = 0.323251
I0625 20:55:04.403975 20137 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:55:04.403981 20137 solver.cpp:244]     Train net output #1: loss = 0.323251 (* 1 = 0.323251 loss)
I0625 20:55:04.403985 20137 sgd_solver.cpp:106] Iteration 2420, lr = 0.0001
I0625 20:55:05.991694 20137 solver.cpp:228] Iteration 2440, loss = 0.53089
I0625 20:55:05.991717 20137 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:55:05.991735 20137 solver.cpp:244]     Train net output #1: loss = 0.53089 (* 1 = 0.53089 loss)
I0625 20:55:05.991739 20137 sgd_solver.cpp:106] Iteration 2440, lr = 0.0001
I0625 20:55:07.580279 20137 solver.cpp:228] Iteration 2460, loss = 0.380951
I0625 20:55:07.580325 20137 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:55:07.580332 20137 solver.cpp:244]     Train net output #1: loss = 0.380951 (* 1 = 0.380951 loss)
I0625 20:55:07.580359 20137 sgd_solver.cpp:106] Iteration 2460, lr = 0.0001
I0625 20:55:09.169658 20137 solver.cpp:228] Iteration 2480, loss = 0.432647
I0625 20:55:09.169682 20137 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:55:09.169689 20137 solver.cpp:244]     Train net output #1: loss = 0.432647 (* 1 = 0.432647 loss)
I0625 20:55:09.169694 20137 sgd_solver.cpp:106] Iteration 2480, lr = 0.0001
I0625 20:55:10.735760 20137 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_2500.caffemodel
I0625 20:55:10.759876 20137 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_2500.solverstate
I0625 20:55:10.771337 20137 solver.cpp:337] Iteration 2500, Testing net (#0)
I0625 20:55:13.718904 20137 solver.cpp:404]     Test net output #0: accuracy = 0.786377
I0625 20:55:13.718931 20137 solver.cpp:404]     Test net output #1: loss = 0.43525 (* 1 = 0.43525 loss)
I0625 20:55:13.746500 20137 solver.cpp:228] Iteration 2500, loss = 0.488755
I0625 20:55:13.746533 20137 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:55:13.746546 20137 solver.cpp:244]     Train net output #1: loss = 0.488755 (* 1 = 0.488755 loss)
I0625 20:55:13.746553 20137 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0625 20:55:15.341619 20137 solver.cpp:228] Iteration 2520, loss = 0.334791
I0625 20:55:15.341655 20137 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:55:15.341662 20137 solver.cpp:244]     Train net output #1: loss = 0.334791 (* 1 = 0.334791 loss)
I0625 20:55:15.341666 20137 sgd_solver.cpp:106] Iteration 2520, lr = 0.0001
I0625 20:55:16.932538 20137 solver.cpp:228] Iteration 2540, loss = 0.488171
I0625 20:55:16.932674 20137 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:55:16.932685 20137 solver.cpp:244]     Train net output #1: loss = 0.488171 (* 1 = 0.488171 loss)
I0625 20:55:16.932689 20137 sgd_solver.cpp:106] Iteration 2540, lr = 0.0001
