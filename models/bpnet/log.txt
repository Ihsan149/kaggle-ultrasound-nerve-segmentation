I0627 13:53:09.114418  5034 caffe.cpp:185] Using GPUs 0
I0627 13:53:09.129889  5034 caffe.cpp:190] GPU 0: Graphics Device
I0627 13:53:09.572520  5034 solver.cpp:48] Initializing solver from parameters: 
test_iter: 64
test_interval: 100
base_lr: 0.001
display: 20
max_iter: 6000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 500
snapshot_prefix: "data/models/bpnet"
solver_mode: GPU
device_id: 0
net: "models/bpnet/train_val.prototxt"
test_initialization: true
iter_size: 1
I0627 13:53:09.572631  5034 solver.cpp:91] Creating training net from net file: models/bpnet/train_val.prototxt
I0627 13:53:09.573186  5034 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0627 13:53:09.573334  5034 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 100
    crop_h: 196
    crop_w: 256
    rotation_range: 10
    scale_jitter_range: 0.1
    contrast_jitter_range: 0.1
  }
  data_param {
    source: "data/train_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_1"
  top: "pool5"
  pooling_param {
    pool: AVE
    stride: 1
    kernel_h: 6
    kernel_w: 8
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0627 13:53:09.573462  5034 layer_factory.hpp:77] Creating layer data
I0627 13:53:09.573850  5034 net.cpp:91] Creating Layer data
I0627 13:53:09.573861  5034 net.cpp:399] data -> data
I0627 13:53:09.573882  5034 net.cpp:399] data -> label
I0627 13:53:09.575222  5038 db_lmdb.cpp:35] Opened lmdb data/train_lmdb
I0627 13:53:09.599277  5034 data_layer.cpp:42] output data size: 32,3,196,256
I0627 13:53:09.638165  5034 net.cpp:141] Setting up data
I0627 13:53:09.638197  5034 net.cpp:148] Top shape: 32 3 196 256 (4816896)
I0627 13:53:09.638202  5034 net.cpp:148] Top shape: 32 (32)
I0627 13:53:09.638205  5034 net.cpp:156] Memory required for data: 19267712
I0627 13:53:09.638212  5034 layer_factory.hpp:77] Creating layer label_data_1_split
I0627 13:53:09.638229  5034 net.cpp:91] Creating Layer label_data_1_split
I0627 13:53:09.638233  5034 net.cpp:425] label_data_1_split <- label
I0627 13:53:09.638242  5034 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0627 13:53:09.638252  5034 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0627 13:53:09.638315  5034 net.cpp:141] Setting up label_data_1_split
I0627 13:53:09.638322  5034 net.cpp:148] Top shape: 32 (32)
I0627 13:53:09.638324  5034 net.cpp:148] Top shape: 32 (32)
I0627 13:53:09.638326  5034 net.cpp:156] Memory required for data: 19267968
I0627 13:53:09.638329  5034 layer_factory.hpp:77] Creating layer conv1_1
I0627 13:53:09.638345  5034 net.cpp:91] Creating Layer conv1_1
I0627 13:53:09.638348  5034 net.cpp:425] conv1_1 <- data
I0627 13:53:09.638352  5034 net.cpp:399] conv1_1 -> conv1_1
I0627 13:53:09.921191  5034 net.cpp:141] Setting up conv1_1
I0627 13:53:09.921218  5034 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0627 13:53:09.921239  5034 net.cpp:156] Memory required for data: 70648192
I0627 13:53:09.921252  5034 layer_factory.hpp:77] Creating layer bn1_1
I0627 13:53:09.921267  5034 net.cpp:91] Creating Layer bn1_1
I0627 13:53:09.921270  5034 net.cpp:425] bn1_1 <- conv1_1
I0627 13:53:09.921274  5034 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0627 13:53:09.921427  5034 net.cpp:141] Setting up bn1_1
I0627 13:53:09.921435  5034 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0627 13:53:09.921438  5034 net.cpp:156] Memory required for data: 122028416
I0627 13:53:09.921447  5034 layer_factory.hpp:77] Creating layer scale1_1
I0627 13:53:09.921457  5034 net.cpp:91] Creating Layer scale1_1
I0627 13:53:09.921458  5034 net.cpp:425] scale1_1 <- conv1_1
I0627 13:53:09.921463  5034 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0627 13:53:09.921497  5034 layer_factory.hpp:77] Creating layer scale1_1
I0627 13:53:09.921593  5034 net.cpp:141] Setting up scale1_1
I0627 13:53:09.921600  5034 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0627 13:53:09.921603  5034 net.cpp:156] Memory required for data: 173408640
I0627 13:53:09.921609  5034 layer_factory.hpp:77] Creating layer relu1_1
I0627 13:53:09.921614  5034 net.cpp:91] Creating Layer relu1_1
I0627 13:53:09.921617  5034 net.cpp:425] relu1_1 <- conv1_1
I0627 13:53:09.921620  5034 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0627 13:53:09.921752  5034 net.cpp:141] Setting up relu1_1
I0627 13:53:09.921761  5034 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0627 13:53:09.921764  5034 net.cpp:156] Memory required for data: 224788864
I0627 13:53:09.921766  5034 layer_factory.hpp:77] Creating layer pool1
I0627 13:53:09.921772  5034 net.cpp:91] Creating Layer pool1
I0627 13:53:09.921775  5034 net.cpp:425] pool1 <- conv1_1
I0627 13:53:09.921779  5034 net.cpp:399] pool1 -> pool1
I0627 13:53:09.921820  5034 net.cpp:141] Setting up pool1
I0627 13:53:09.921825  5034 net.cpp:148] Top shape: 32 32 49 64 (3211264)
I0627 13:53:09.921828  5034 net.cpp:156] Memory required for data: 237633920
I0627 13:53:09.921830  5034 layer_factory.hpp:77] Creating layer conv2_1
I0627 13:53:09.921838  5034 net.cpp:91] Creating Layer conv2_1
I0627 13:53:09.921840  5034 net.cpp:425] conv2_1 <- pool1
I0627 13:53:09.921844  5034 net.cpp:399] conv2_1 -> conv2_1
I0627 13:53:09.926420  5034 net.cpp:141] Setting up conv2_1
I0627 13:53:09.926435  5034 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0627 13:53:09.926439  5034 net.cpp:156] Memory required for data: 263324032
I0627 13:53:09.926443  5034 layer_factory.hpp:77] Creating layer bn2_1
I0627 13:53:09.926450  5034 net.cpp:91] Creating Layer bn2_1
I0627 13:53:09.926453  5034 net.cpp:425] bn2_1 <- conv2_1
I0627 13:53:09.926458  5034 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0627 13:53:09.927683  5034 net.cpp:141] Setting up bn2_1
I0627 13:53:09.927695  5034 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0627 13:53:09.927698  5034 net.cpp:156] Memory required for data: 289014144
I0627 13:53:09.927707  5034 layer_factory.hpp:77] Creating layer scale2_1
I0627 13:53:09.927716  5034 net.cpp:91] Creating Layer scale2_1
I0627 13:53:09.927718  5034 net.cpp:425] scale2_1 <- conv2_1
I0627 13:53:09.927721  5034 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0627 13:53:09.927757  5034 layer_factory.hpp:77] Creating layer scale2_1
I0627 13:53:09.927845  5034 net.cpp:141] Setting up scale2_1
I0627 13:53:09.927852  5034 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0627 13:53:09.927855  5034 net.cpp:156] Memory required for data: 314704256
I0627 13:53:09.927858  5034 layer_factory.hpp:77] Creating layer relu2_1
I0627 13:53:09.927863  5034 net.cpp:91] Creating Layer relu2_1
I0627 13:53:09.927866  5034 net.cpp:425] relu2_1 <- conv2_1
I0627 13:53:09.927870  5034 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0627 13:53:09.928004  5034 net.cpp:141] Setting up relu2_1
I0627 13:53:09.928011  5034 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0627 13:53:09.928014  5034 net.cpp:156] Memory required for data: 340394368
I0627 13:53:09.928017  5034 layer_factory.hpp:77] Creating layer pool2
I0627 13:53:09.928032  5034 net.cpp:91] Creating Layer pool2
I0627 13:53:09.928035  5034 net.cpp:425] pool2 <- conv2_1
I0627 13:53:09.928042  5034 net.cpp:399] pool2 -> pool2
I0627 13:53:09.928076  5034 net.cpp:141] Setting up pool2
I0627 13:53:09.928081  5034 net.cpp:148] Top shape: 32 64 25 32 (1638400)
I0627 13:53:09.928082  5034 net.cpp:156] Memory required for data: 346947968
I0627 13:53:09.928084  5034 layer_factory.hpp:77] Creating layer conv3_1
I0627 13:53:09.928093  5034 net.cpp:91] Creating Layer conv3_1
I0627 13:53:09.928097  5034 net.cpp:425] conv3_1 <- pool2
I0627 13:53:09.928100  5034 net.cpp:399] conv3_1 -> conv3_1
I0627 13:53:09.930368  5034 net.cpp:141] Setting up conv3_1
I0627 13:53:09.930382  5034 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0627 13:53:09.930383  5034 net.cpp:156] Memory required for data: 360055168
I0627 13:53:09.930388  5034 layer_factory.hpp:77] Creating layer bn3_1
I0627 13:53:09.930395  5034 net.cpp:91] Creating Layer bn3_1
I0627 13:53:09.930398  5034 net.cpp:425] bn3_1 <- conv3_1
I0627 13:53:09.930403  5034 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0627 13:53:09.931617  5034 net.cpp:141] Setting up bn3_1
I0627 13:53:09.931629  5034 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0627 13:53:09.931632  5034 net.cpp:156] Memory required for data: 373162368
I0627 13:53:09.931638  5034 layer_factory.hpp:77] Creating layer scale3_1
I0627 13:53:09.931645  5034 net.cpp:91] Creating Layer scale3_1
I0627 13:53:09.931648  5034 net.cpp:425] scale3_1 <- conv3_1
I0627 13:53:09.931651  5034 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0627 13:53:09.931687  5034 layer_factory.hpp:77] Creating layer scale3_1
I0627 13:53:09.931792  5034 net.cpp:141] Setting up scale3_1
I0627 13:53:09.931802  5034 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0627 13:53:09.931805  5034 net.cpp:156] Memory required for data: 386269568
I0627 13:53:09.931819  5034 layer_factory.hpp:77] Creating layer relu3_1
I0627 13:53:09.931829  5034 net.cpp:91] Creating Layer relu3_1
I0627 13:53:09.931833  5034 net.cpp:425] relu3_1 <- conv3_1
I0627 13:53:09.931836  5034 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0627 13:53:09.932250  5034 net.cpp:141] Setting up relu3_1
I0627 13:53:09.932261  5034 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0627 13:53:09.932265  5034 net.cpp:156] Memory required for data: 399376768
I0627 13:53:09.932267  5034 layer_factory.hpp:77] Creating layer pool3
I0627 13:53:09.932274  5034 net.cpp:91] Creating Layer pool3
I0627 13:53:09.932276  5034 net.cpp:425] pool3 <- conv3_1
I0627 13:53:09.932282  5034 net.cpp:399] pool3 -> pool3
I0627 13:53:09.932317  5034 net.cpp:141] Setting up pool3
I0627 13:53:09.932324  5034 net.cpp:148] Top shape: 32 128 13 16 (851968)
I0627 13:53:09.932327  5034 net.cpp:156] Memory required for data: 402784640
I0627 13:53:09.932329  5034 layer_factory.hpp:77] Creating layer conv4_1
I0627 13:53:09.932338  5034 net.cpp:91] Creating Layer conv4_1
I0627 13:53:09.932342  5034 net.cpp:425] conv4_1 <- pool3
I0627 13:53:09.932345  5034 net.cpp:399] conv4_1 -> conv4_1
I0627 13:53:09.934768  5034 net.cpp:141] Setting up conv4_1
I0627 13:53:09.934782  5034 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0627 13:53:09.934784  5034 net.cpp:156] Memory required for data: 409600384
I0627 13:53:09.934788  5034 layer_factory.hpp:77] Creating layer bn4_1
I0627 13:53:09.934795  5034 net.cpp:91] Creating Layer bn4_1
I0627 13:53:09.934798  5034 net.cpp:425] bn4_1 <- conv4_1
I0627 13:53:09.934803  5034 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0627 13:53:09.934945  5034 net.cpp:141] Setting up bn4_1
I0627 13:53:09.934953  5034 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0627 13:53:09.934955  5034 net.cpp:156] Memory required for data: 416416128
I0627 13:53:09.934962  5034 layer_factory.hpp:77] Creating layer scale4_1
I0627 13:53:09.934967  5034 net.cpp:91] Creating Layer scale4_1
I0627 13:53:09.934970  5034 net.cpp:425] scale4_1 <- conv4_1
I0627 13:53:09.934973  5034 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0627 13:53:09.935005  5034 layer_factory.hpp:77] Creating layer scale4_1
I0627 13:53:09.935097  5034 net.cpp:141] Setting up scale4_1
I0627 13:53:09.935106  5034 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0627 13:53:09.935107  5034 net.cpp:156] Memory required for data: 423231872
I0627 13:53:09.935112  5034 layer_factory.hpp:77] Creating layer relu4_1
I0627 13:53:09.935117  5034 net.cpp:91] Creating Layer relu4_1
I0627 13:53:09.935118  5034 net.cpp:425] relu4_1 <- conv4_1
I0627 13:53:09.935123  5034 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0627 13:53:09.935523  5034 net.cpp:141] Setting up relu4_1
I0627 13:53:09.935534  5034 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0627 13:53:09.935536  5034 net.cpp:156] Memory required for data: 430047616
I0627 13:53:09.935539  5034 layer_factory.hpp:77] Creating layer pool4
I0627 13:53:09.935546  5034 net.cpp:91] Creating Layer pool4
I0627 13:53:09.935549  5034 net.cpp:425] pool4 <- conv4_1
I0627 13:53:09.935552  5034 net.cpp:399] pool4 -> pool4
I0627 13:53:09.935588  5034 net.cpp:141] Setting up pool4
I0627 13:53:09.935593  5034 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0627 13:53:09.935595  5034 net.cpp:156] Memory required for data: 431882624
I0627 13:53:09.935597  5034 layer_factory.hpp:77] Creating layer conv5_1
I0627 13:53:09.935606  5034 net.cpp:91] Creating Layer conv5_1
I0627 13:53:09.935607  5034 net.cpp:425] conv5_1 <- pool4
I0627 13:53:09.935612  5034 net.cpp:399] conv5_1 -> conv5_1
I0627 13:53:09.941246  5034 net.cpp:141] Setting up conv5_1
I0627 13:53:09.941262  5034 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0627 13:53:09.941264  5034 net.cpp:156] Memory required for data: 433717632
I0627 13:53:09.941270  5034 layer_factory.hpp:77] Creating layer bn5_1
I0627 13:53:09.941278  5034 net.cpp:91] Creating Layer bn5_1
I0627 13:53:09.941282  5034 net.cpp:425] bn5_1 <- conv5_1
I0627 13:53:09.941287  5034 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0627 13:53:09.941438  5034 net.cpp:141] Setting up bn5_1
I0627 13:53:09.941445  5034 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0627 13:53:09.941448  5034 net.cpp:156] Memory required for data: 435552640
I0627 13:53:09.941454  5034 layer_factory.hpp:77] Creating layer scale5_1
I0627 13:53:09.941460  5034 net.cpp:91] Creating Layer scale5_1
I0627 13:53:09.941463  5034 net.cpp:425] scale5_1 <- conv5_1
I0627 13:53:09.941467  5034 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0627 13:53:09.941499  5034 layer_factory.hpp:77] Creating layer scale5_1
I0627 13:53:09.941578  5034 net.cpp:141] Setting up scale5_1
I0627 13:53:09.941588  5034 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0627 13:53:09.941591  5034 net.cpp:156] Memory required for data: 437387648
I0627 13:53:09.941594  5034 layer_factory.hpp:77] Creating layer relu5_1
I0627 13:53:09.941599  5034 net.cpp:91] Creating Layer relu5_1
I0627 13:53:09.941601  5034 net.cpp:425] relu5_1 <- conv5_1
I0627 13:53:09.941606  5034 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0627 13:53:09.941746  5034 net.cpp:141] Setting up relu5_1
I0627 13:53:09.941756  5034 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0627 13:53:09.941757  5034 net.cpp:156] Memory required for data: 439222656
I0627 13:53:09.941761  5034 layer_factory.hpp:77] Creating layer pool5
I0627 13:53:09.941766  5034 net.cpp:91] Creating Layer pool5
I0627 13:53:09.941768  5034 net.cpp:425] pool5 <- conv5_1
I0627 13:53:09.941773  5034 net.cpp:399] pool5 -> pool5
I0627 13:53:09.941928  5034 net.cpp:141] Setting up pool5
I0627 13:53:09.941937  5034 net.cpp:148] Top shape: 32 256 2 1 (16384)
I0627 13:53:09.941941  5034 net.cpp:156] Memory required for data: 439288192
I0627 13:53:09.941943  5034 layer_factory.hpp:77] Creating layer fc2
I0627 13:53:09.941949  5034 net.cpp:91] Creating Layer fc2
I0627 13:53:09.941952  5034 net.cpp:425] fc2 <- pool5
I0627 13:53:09.941956  5034 net.cpp:399] fc2 -> fc2
I0627 13:53:09.942044  5034 net.cpp:141] Setting up fc2
I0627 13:53:09.942052  5034 net.cpp:148] Top shape: 32 2 (64)
I0627 13:53:09.942054  5034 net.cpp:156] Memory required for data: 439288448
I0627 13:53:09.942059  5034 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0627 13:53:09.942076  5034 net.cpp:91] Creating Layer fc2_fc2_0_split
I0627 13:53:09.942078  5034 net.cpp:425] fc2_fc2_0_split <- fc2
I0627 13:53:09.942083  5034 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0627 13:53:09.942087  5034 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0627 13:53:09.942121  5034 net.cpp:141] Setting up fc2_fc2_0_split
I0627 13:53:09.942124  5034 net.cpp:148] Top shape: 32 2 (64)
I0627 13:53:09.942128  5034 net.cpp:148] Top shape: 32 2 (64)
I0627 13:53:09.942131  5034 net.cpp:156] Memory required for data: 439288960
I0627 13:53:09.942132  5034 layer_factory.hpp:77] Creating layer loss
I0627 13:53:09.942140  5034 net.cpp:91] Creating Layer loss
I0627 13:53:09.942143  5034 net.cpp:425] loss <- fc2_fc2_0_split_0
I0627 13:53:09.942147  5034 net.cpp:425] loss <- label_data_1_split_0
I0627 13:53:09.942150  5034 net.cpp:399] loss -> loss
I0627 13:53:09.942157  5034 layer_factory.hpp:77] Creating layer loss
I0627 13:53:09.942361  5034 net.cpp:141] Setting up loss
I0627 13:53:09.942370  5034 net.cpp:148] Top shape: (1)
I0627 13:53:09.942373  5034 net.cpp:151]     with loss weight 1
I0627 13:53:09.942389  5034 net.cpp:156] Memory required for data: 439288964
I0627 13:53:09.942391  5034 layer_factory.hpp:77] Creating layer accuracy
I0627 13:53:09.942397  5034 net.cpp:91] Creating Layer accuracy
I0627 13:53:09.942400  5034 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0627 13:53:09.942404  5034 net.cpp:425] accuracy <- label_data_1_split_1
I0627 13:53:09.942407  5034 net.cpp:399] accuracy -> accuracy
I0627 13:53:09.942414  5034 net.cpp:141] Setting up accuracy
I0627 13:53:09.942416  5034 net.cpp:148] Top shape: (1)
I0627 13:53:09.942419  5034 net.cpp:156] Memory required for data: 439288968
I0627 13:53:09.942420  5034 net.cpp:219] accuracy does not need backward computation.
I0627 13:53:09.942423  5034 net.cpp:217] loss needs backward computation.
I0627 13:53:09.942425  5034 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0627 13:53:09.942428  5034 net.cpp:217] fc2 needs backward computation.
I0627 13:53:09.942430  5034 net.cpp:217] pool5 needs backward computation.
I0627 13:53:09.942432  5034 net.cpp:217] relu5_1 needs backward computation.
I0627 13:53:09.942435  5034 net.cpp:217] scale5_1 needs backward computation.
I0627 13:53:09.942436  5034 net.cpp:217] bn5_1 needs backward computation.
I0627 13:53:09.942438  5034 net.cpp:217] conv5_1 needs backward computation.
I0627 13:53:09.942441  5034 net.cpp:217] pool4 needs backward computation.
I0627 13:53:09.942443  5034 net.cpp:217] relu4_1 needs backward computation.
I0627 13:53:09.942445  5034 net.cpp:217] scale4_1 needs backward computation.
I0627 13:53:09.942447  5034 net.cpp:217] bn4_1 needs backward computation.
I0627 13:53:09.942450  5034 net.cpp:217] conv4_1 needs backward computation.
I0627 13:53:09.942452  5034 net.cpp:217] pool3 needs backward computation.
I0627 13:53:09.942454  5034 net.cpp:217] relu3_1 needs backward computation.
I0627 13:53:09.942456  5034 net.cpp:217] scale3_1 needs backward computation.
I0627 13:53:09.942458  5034 net.cpp:217] bn3_1 needs backward computation.
I0627 13:53:09.942461  5034 net.cpp:217] conv3_1 needs backward computation.
I0627 13:53:09.942463  5034 net.cpp:217] pool2 needs backward computation.
I0627 13:53:09.942467  5034 net.cpp:217] relu2_1 needs backward computation.
I0627 13:53:09.942469  5034 net.cpp:217] scale2_1 needs backward computation.
I0627 13:53:09.942471  5034 net.cpp:217] bn2_1 needs backward computation.
I0627 13:53:09.942473  5034 net.cpp:217] conv2_1 needs backward computation.
I0627 13:53:09.942476  5034 net.cpp:217] pool1 needs backward computation.
I0627 13:53:09.942478  5034 net.cpp:217] relu1_1 needs backward computation.
I0627 13:53:09.942481  5034 net.cpp:217] scale1_1 needs backward computation.
I0627 13:53:09.942482  5034 net.cpp:217] bn1_1 needs backward computation.
I0627 13:53:09.942484  5034 net.cpp:217] conv1_1 needs backward computation.
I0627 13:53:09.942487  5034 net.cpp:219] label_data_1_split does not need backward computation.
I0627 13:53:09.942490  5034 net.cpp:219] data does not need backward computation.
I0627 13:53:09.942500  5034 net.cpp:261] This network produces output accuracy
I0627 13:53:09.942502  5034 net.cpp:261] This network produces output loss
I0627 13:53:09.942517  5034 net.cpp:274] Network initialization done.
I0627 13:53:09.943065  5034 solver.cpp:181] Creating test net (#0) specified by net file: models/bpnet/train_val.prototxt
I0627 13:53:09.943102  5034 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0627 13:53:09.943239  5034 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 50
    crop_h: 196
    crop_w: 256
  }
  data_param {
    source: "data/val_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_1"
  top: "pool5"
  pooling_param {
    pool: AVE
    stride: 1
    kernel_h: 6
    kernel_w: 8
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0627 13:53:09.943338  5034 layer_factory.hpp:77] Creating layer data
I0627 13:53:09.943409  5034 net.cpp:91] Creating Layer data
I0627 13:53:09.943421  5034 net.cpp:399] data -> data
I0627 13:53:09.943429  5034 net.cpp:399] data -> label
I0627 13:53:09.944571  5047 db_lmdb.cpp:35] Opened lmdb data/val_lmdb
I0627 13:53:09.944897  5034 data_layer.cpp:42] output data size: 64,3,196,256
I0627 13:53:10.025745  5034 net.cpp:141] Setting up data
I0627 13:53:10.025770  5034 net.cpp:148] Top shape: 64 3 196 256 (9633792)
I0627 13:53:10.025774  5034 net.cpp:148] Top shape: 64 (64)
I0627 13:53:10.025776  5034 net.cpp:156] Memory required for data: 38535424
I0627 13:53:10.025780  5034 layer_factory.hpp:77] Creating layer label_data_1_split
I0627 13:53:10.025792  5034 net.cpp:91] Creating Layer label_data_1_split
I0627 13:53:10.025796  5034 net.cpp:425] label_data_1_split <- label
I0627 13:53:10.025801  5034 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0627 13:53:10.025809  5034 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0627 13:53:10.025921  5034 net.cpp:141] Setting up label_data_1_split
I0627 13:53:10.025929  5034 net.cpp:148] Top shape: 64 (64)
I0627 13:53:10.025933  5034 net.cpp:148] Top shape: 64 (64)
I0627 13:53:10.025934  5034 net.cpp:156] Memory required for data: 38535936
I0627 13:53:10.025938  5034 layer_factory.hpp:77] Creating layer conv1_1
I0627 13:53:10.025955  5034 net.cpp:91] Creating Layer conv1_1
I0627 13:53:10.025959  5034 net.cpp:425] conv1_1 <- data
I0627 13:53:10.025964  5034 net.cpp:399] conv1_1 -> conv1_1
I0627 13:53:10.026968  5034 net.cpp:141] Setting up conv1_1
I0627 13:53:10.026981  5034 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0627 13:53:10.026984  5034 net.cpp:156] Memory required for data: 141296384
I0627 13:53:10.026990  5034 layer_factory.hpp:77] Creating layer bn1_1
I0627 13:53:10.026999  5034 net.cpp:91] Creating Layer bn1_1
I0627 13:53:10.027015  5034 net.cpp:425] bn1_1 <- conv1_1
I0627 13:53:10.027026  5034 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0627 13:53:10.027196  5034 net.cpp:141] Setting up bn1_1
I0627 13:53:10.027204  5034 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0627 13:53:10.027206  5034 net.cpp:156] Memory required for data: 244056832
I0627 13:53:10.027215  5034 layer_factory.hpp:77] Creating layer scale1_1
I0627 13:53:10.027223  5034 net.cpp:91] Creating Layer scale1_1
I0627 13:53:10.027226  5034 net.cpp:425] scale1_1 <- conv1_1
I0627 13:53:10.027230  5034 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0627 13:53:10.027264  5034 layer_factory.hpp:77] Creating layer scale1_1
I0627 13:53:10.027371  5034 net.cpp:141] Setting up scale1_1
I0627 13:53:10.027379  5034 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0627 13:53:10.027381  5034 net.cpp:156] Memory required for data: 346817280
I0627 13:53:10.027387  5034 layer_factory.hpp:77] Creating layer relu1_1
I0627 13:53:10.027392  5034 net.cpp:91] Creating Layer relu1_1
I0627 13:53:10.027396  5034 net.cpp:425] relu1_1 <- conv1_1
I0627 13:53:10.027400  5034 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0627 13:53:10.031131  5034 net.cpp:141] Setting up relu1_1
I0627 13:53:10.031144  5034 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0627 13:53:10.031147  5034 net.cpp:156] Memory required for data: 449577728
I0627 13:53:10.031150  5034 layer_factory.hpp:77] Creating layer pool1
I0627 13:53:10.031157  5034 net.cpp:91] Creating Layer pool1
I0627 13:53:10.031160  5034 net.cpp:425] pool1 <- conv1_1
I0627 13:53:10.031164  5034 net.cpp:399] pool1 -> pool1
I0627 13:53:10.031204  5034 net.cpp:141] Setting up pool1
I0627 13:53:10.031208  5034 net.cpp:148] Top shape: 64 32 49 64 (6422528)
I0627 13:53:10.031210  5034 net.cpp:156] Memory required for data: 475267840
I0627 13:53:10.031213  5034 layer_factory.hpp:77] Creating layer conv2_1
I0627 13:53:10.031220  5034 net.cpp:91] Creating Layer conv2_1
I0627 13:53:10.031224  5034 net.cpp:425] conv2_1 <- pool1
I0627 13:53:10.031226  5034 net.cpp:399] conv2_1 -> conv2_1
I0627 13:53:10.032199  5034 net.cpp:141] Setting up conv2_1
I0627 13:53:10.032212  5034 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0627 13:53:10.032214  5034 net.cpp:156] Memory required for data: 526648064
I0627 13:53:10.032218  5034 layer_factory.hpp:77] Creating layer bn2_1
I0627 13:53:10.032227  5034 net.cpp:91] Creating Layer bn2_1
I0627 13:53:10.032229  5034 net.cpp:425] bn2_1 <- conv2_1
I0627 13:53:10.032233  5034 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0627 13:53:10.032392  5034 net.cpp:141] Setting up bn2_1
I0627 13:53:10.032398  5034 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0627 13:53:10.032402  5034 net.cpp:156] Memory required for data: 578028288
I0627 13:53:10.032409  5034 layer_factory.hpp:77] Creating layer scale2_1
I0627 13:53:10.032415  5034 net.cpp:91] Creating Layer scale2_1
I0627 13:53:10.032418  5034 net.cpp:425] scale2_1 <- conv2_1
I0627 13:53:10.032421  5034 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0627 13:53:10.032452  5034 layer_factory.hpp:77] Creating layer scale2_1
I0627 13:53:10.032544  5034 net.cpp:141] Setting up scale2_1
I0627 13:53:10.032552  5034 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0627 13:53:10.032554  5034 net.cpp:156] Memory required for data: 629408512
I0627 13:53:10.032558  5034 layer_factory.hpp:77] Creating layer relu2_1
I0627 13:53:10.032562  5034 net.cpp:91] Creating Layer relu2_1
I0627 13:53:10.032564  5034 net.cpp:425] relu2_1 <- conv2_1
I0627 13:53:10.032568  5034 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0627 13:53:10.032706  5034 net.cpp:141] Setting up relu2_1
I0627 13:53:10.032716  5034 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0627 13:53:10.032717  5034 net.cpp:156] Memory required for data: 680788736
I0627 13:53:10.032721  5034 layer_factory.hpp:77] Creating layer pool2
I0627 13:53:10.032727  5034 net.cpp:91] Creating Layer pool2
I0627 13:53:10.032728  5034 net.cpp:425] pool2 <- conv2_1
I0627 13:53:10.032732  5034 net.cpp:399] pool2 -> pool2
I0627 13:53:10.032765  5034 net.cpp:141] Setting up pool2
I0627 13:53:10.032780  5034 net.cpp:148] Top shape: 64 64 25 32 (3276800)
I0627 13:53:10.032783  5034 net.cpp:156] Memory required for data: 693895936
I0627 13:53:10.032784  5034 layer_factory.hpp:77] Creating layer conv3_1
I0627 13:53:10.032793  5034 net.cpp:91] Creating Layer conv3_1
I0627 13:53:10.032795  5034 net.cpp:425] conv3_1 <- pool2
I0627 13:53:10.032799  5034 net.cpp:399] conv3_1 -> conv3_1
I0627 13:53:10.034040  5034 net.cpp:141] Setting up conv3_1
I0627 13:53:10.034054  5034 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0627 13:53:10.034056  5034 net.cpp:156] Memory required for data: 720110336
I0627 13:53:10.034060  5034 layer_factory.hpp:77] Creating layer bn3_1
I0627 13:53:10.034066  5034 net.cpp:91] Creating Layer bn3_1
I0627 13:53:10.034068  5034 net.cpp:425] bn3_1 <- conv3_1
I0627 13:53:10.034073  5034 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0627 13:53:10.034217  5034 net.cpp:141] Setting up bn3_1
I0627 13:53:10.034224  5034 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0627 13:53:10.034226  5034 net.cpp:156] Memory required for data: 746324736
I0627 13:53:10.034231  5034 layer_factory.hpp:77] Creating layer scale3_1
I0627 13:53:10.034238  5034 net.cpp:91] Creating Layer scale3_1
I0627 13:53:10.034240  5034 net.cpp:425] scale3_1 <- conv3_1
I0627 13:53:10.034245  5034 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0627 13:53:10.034278  5034 layer_factory.hpp:77] Creating layer scale3_1
I0627 13:53:10.034361  5034 net.cpp:141] Setting up scale3_1
I0627 13:53:10.034368  5034 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0627 13:53:10.034370  5034 net.cpp:156] Memory required for data: 772539136
I0627 13:53:10.034378  5034 layer_factory.hpp:77] Creating layer relu3_1
I0627 13:53:10.034382  5034 net.cpp:91] Creating Layer relu3_1
I0627 13:53:10.034385  5034 net.cpp:425] relu3_1 <- conv3_1
I0627 13:53:10.034389  5034 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0627 13:53:10.034525  5034 net.cpp:141] Setting up relu3_1
I0627 13:53:10.034533  5034 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0627 13:53:10.034535  5034 net.cpp:156] Memory required for data: 798753536
I0627 13:53:10.034538  5034 layer_factory.hpp:77] Creating layer pool3
I0627 13:53:10.034545  5034 net.cpp:91] Creating Layer pool3
I0627 13:53:10.034548  5034 net.cpp:425] pool3 <- conv3_1
I0627 13:53:10.034554  5034 net.cpp:399] pool3 -> pool3
I0627 13:53:10.034587  5034 net.cpp:141] Setting up pool3
I0627 13:53:10.034591  5034 net.cpp:148] Top shape: 64 128 13 16 (1703936)
I0627 13:53:10.034593  5034 net.cpp:156] Memory required for data: 805569280
I0627 13:53:10.034595  5034 layer_factory.hpp:77] Creating layer conv4_1
I0627 13:53:10.034603  5034 net.cpp:91] Creating Layer conv4_1
I0627 13:53:10.034605  5034 net.cpp:425] conv4_1 <- pool3
I0627 13:53:10.034610  5034 net.cpp:399] conv4_1 -> conv4_1
I0627 13:53:10.038331  5034 net.cpp:141] Setting up conv4_1
I0627 13:53:10.038346  5034 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0627 13:53:10.038347  5034 net.cpp:156] Memory required for data: 819200768
I0627 13:53:10.038352  5034 layer_factory.hpp:77] Creating layer bn4_1
I0627 13:53:10.038358  5034 net.cpp:91] Creating Layer bn4_1
I0627 13:53:10.038360  5034 net.cpp:425] bn4_1 <- conv4_1
I0627 13:53:10.038365  5034 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0627 13:53:10.038521  5034 net.cpp:141] Setting up bn4_1
I0627 13:53:10.038527  5034 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0627 13:53:10.038530  5034 net.cpp:156] Memory required for data: 832832256
I0627 13:53:10.038537  5034 layer_factory.hpp:77] Creating layer scale4_1
I0627 13:53:10.038548  5034 net.cpp:91] Creating Layer scale4_1
I0627 13:53:10.038552  5034 net.cpp:425] scale4_1 <- conv4_1
I0627 13:53:10.038554  5034 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0627 13:53:10.038586  5034 layer_factory.hpp:77] Creating layer scale4_1
I0627 13:53:10.038667  5034 net.cpp:141] Setting up scale4_1
I0627 13:53:10.038674  5034 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0627 13:53:10.038676  5034 net.cpp:156] Memory required for data: 846463744
I0627 13:53:10.038691  5034 layer_factory.hpp:77] Creating layer relu4_1
I0627 13:53:10.038696  5034 net.cpp:91] Creating Layer relu4_1
I0627 13:53:10.038698  5034 net.cpp:425] relu4_1 <- conv4_1
I0627 13:53:10.038702  5034 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0627 13:53:10.038844  5034 net.cpp:141] Setting up relu4_1
I0627 13:53:10.038853  5034 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0627 13:53:10.038856  5034 net.cpp:156] Memory required for data: 860095232
I0627 13:53:10.038858  5034 layer_factory.hpp:77] Creating layer pool4
I0627 13:53:10.038864  5034 net.cpp:91] Creating Layer pool4
I0627 13:53:10.038867  5034 net.cpp:425] pool4 <- conv4_1
I0627 13:53:10.038872  5034 net.cpp:399] pool4 -> pool4
I0627 13:53:10.038908  5034 net.cpp:141] Setting up pool4
I0627 13:53:10.038913  5034 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0627 13:53:10.038915  5034 net.cpp:156] Memory required for data: 863765248
I0627 13:53:10.038918  5034 layer_factory.hpp:77] Creating layer conv5_1
I0627 13:53:10.038925  5034 net.cpp:91] Creating Layer conv5_1
I0627 13:53:10.038928  5034 net.cpp:425] conv5_1 <- pool4
I0627 13:53:10.038933  5034 net.cpp:399] conv5_1 -> conv5_1
I0627 13:53:10.044572  5034 net.cpp:141] Setting up conv5_1
I0627 13:53:10.044589  5034 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0627 13:53:10.044591  5034 net.cpp:156] Memory required for data: 867435264
I0627 13:53:10.044596  5034 layer_factory.hpp:77] Creating layer bn5_1
I0627 13:53:10.044605  5034 net.cpp:91] Creating Layer bn5_1
I0627 13:53:10.044607  5034 net.cpp:425] bn5_1 <- conv5_1
I0627 13:53:10.044612  5034 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0627 13:53:10.044773  5034 net.cpp:141] Setting up bn5_1
I0627 13:53:10.044780  5034 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0627 13:53:10.044783  5034 net.cpp:156] Memory required for data: 871105280
I0627 13:53:10.044788  5034 layer_factory.hpp:77] Creating layer scale5_1
I0627 13:53:10.044795  5034 net.cpp:91] Creating Layer scale5_1
I0627 13:53:10.044797  5034 net.cpp:425] scale5_1 <- conv5_1
I0627 13:53:10.044802  5034 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0627 13:53:10.044834  5034 layer_factory.hpp:77] Creating layer scale5_1
I0627 13:53:10.044922  5034 net.cpp:141] Setting up scale5_1
I0627 13:53:10.044929  5034 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0627 13:53:10.044931  5034 net.cpp:156] Memory required for data: 874775296
I0627 13:53:10.044935  5034 layer_factory.hpp:77] Creating layer relu5_1
I0627 13:53:10.044940  5034 net.cpp:91] Creating Layer relu5_1
I0627 13:53:10.044942  5034 net.cpp:425] relu5_1 <- conv5_1
I0627 13:53:10.044945  5034 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0627 13:53:10.045089  5034 net.cpp:141] Setting up relu5_1
I0627 13:53:10.045097  5034 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0627 13:53:10.045099  5034 net.cpp:156] Memory required for data: 878445312
I0627 13:53:10.045102  5034 layer_factory.hpp:77] Creating layer pool5
I0627 13:53:10.045107  5034 net.cpp:91] Creating Layer pool5
I0627 13:53:10.045110  5034 net.cpp:425] pool5 <- conv5_1
I0627 13:53:10.045115  5034 net.cpp:399] pool5 -> pool5
I0627 13:53:10.045557  5034 net.cpp:141] Setting up pool5
I0627 13:53:10.045567  5034 net.cpp:148] Top shape: 64 256 2 1 (32768)
I0627 13:53:10.045570  5034 net.cpp:156] Memory required for data: 878576384
I0627 13:53:10.045573  5034 layer_factory.hpp:77] Creating layer fc2
I0627 13:53:10.045580  5034 net.cpp:91] Creating Layer fc2
I0627 13:53:10.045583  5034 net.cpp:425] fc2 <- pool5
I0627 13:53:10.045586  5034 net.cpp:399] fc2 -> fc2
I0627 13:53:10.045683  5034 net.cpp:141] Setting up fc2
I0627 13:53:10.045689  5034 net.cpp:148] Top shape: 64 2 (128)
I0627 13:53:10.045691  5034 net.cpp:156] Memory required for data: 878576896
I0627 13:53:10.045696  5034 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0627 13:53:10.045701  5034 net.cpp:91] Creating Layer fc2_fc2_0_split
I0627 13:53:10.045704  5034 net.cpp:425] fc2_fc2_0_split <- fc2
I0627 13:53:10.045707  5034 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0627 13:53:10.045712  5034 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0627 13:53:10.045759  5034 net.cpp:141] Setting up fc2_fc2_0_split
I0627 13:53:10.045765  5034 net.cpp:148] Top shape: 64 2 (128)
I0627 13:53:10.045768  5034 net.cpp:148] Top shape: 64 2 (128)
I0627 13:53:10.045770  5034 net.cpp:156] Memory required for data: 878577920
I0627 13:53:10.045773  5034 layer_factory.hpp:77] Creating layer loss
I0627 13:53:10.045779  5034 net.cpp:91] Creating Layer loss
I0627 13:53:10.045781  5034 net.cpp:425] loss <- fc2_fc2_0_split_0
I0627 13:53:10.045784  5034 net.cpp:425] loss <- label_data_1_split_0
I0627 13:53:10.045789  5034 net.cpp:399] loss -> loss
I0627 13:53:10.045794  5034 layer_factory.hpp:77] Creating layer loss
I0627 13:53:10.045995  5034 net.cpp:141] Setting up loss
I0627 13:53:10.046005  5034 net.cpp:148] Top shape: (1)
I0627 13:53:10.046006  5034 net.cpp:151]     with loss weight 1
I0627 13:53:10.046017  5034 net.cpp:156] Memory required for data: 878577924
I0627 13:53:10.046020  5034 layer_factory.hpp:77] Creating layer accuracy
I0627 13:53:10.046026  5034 net.cpp:91] Creating Layer accuracy
I0627 13:53:10.046028  5034 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0627 13:53:10.046032  5034 net.cpp:425] accuracy <- label_data_1_split_1
I0627 13:53:10.046036  5034 net.cpp:399] accuracy -> accuracy
I0627 13:53:10.046041  5034 net.cpp:141] Setting up accuracy
I0627 13:53:10.046044  5034 net.cpp:148] Top shape: (1)
I0627 13:53:10.046046  5034 net.cpp:156] Memory required for data: 878577928
I0627 13:53:10.046049  5034 net.cpp:219] accuracy does not need backward computation.
I0627 13:53:10.046051  5034 net.cpp:217] loss needs backward computation.
I0627 13:53:10.046054  5034 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0627 13:53:10.046056  5034 net.cpp:217] fc2 needs backward computation.
I0627 13:53:10.046058  5034 net.cpp:217] pool5 needs backward computation.
I0627 13:53:10.046061  5034 net.cpp:217] relu5_1 needs backward computation.
I0627 13:53:10.046063  5034 net.cpp:217] scale5_1 needs backward computation.
I0627 13:53:10.046066  5034 net.cpp:217] bn5_1 needs backward computation.
I0627 13:53:10.046067  5034 net.cpp:217] conv5_1 needs backward computation.
I0627 13:53:10.046069  5034 net.cpp:217] pool4 needs backward computation.
I0627 13:53:10.046072  5034 net.cpp:217] relu4_1 needs backward computation.
I0627 13:53:10.046074  5034 net.cpp:217] scale4_1 needs backward computation.
I0627 13:53:10.046077  5034 net.cpp:217] bn4_1 needs backward computation.
I0627 13:53:10.046078  5034 net.cpp:217] conv4_1 needs backward computation.
I0627 13:53:10.046082  5034 net.cpp:217] pool3 needs backward computation.
I0627 13:53:10.046083  5034 net.cpp:217] relu3_1 needs backward computation.
I0627 13:53:10.046085  5034 net.cpp:217] scale3_1 needs backward computation.
I0627 13:53:10.046087  5034 net.cpp:217] bn3_1 needs backward computation.
I0627 13:53:10.046090  5034 net.cpp:217] conv3_1 needs backward computation.
I0627 13:53:10.046092  5034 net.cpp:217] pool2 needs backward computation.
I0627 13:53:10.046095  5034 net.cpp:217] relu2_1 needs backward computation.
I0627 13:53:10.046097  5034 net.cpp:217] scale2_1 needs backward computation.
I0627 13:53:10.046099  5034 net.cpp:217] bn2_1 needs backward computation.
I0627 13:53:10.046102  5034 net.cpp:217] conv2_1 needs backward computation.
I0627 13:53:10.046104  5034 net.cpp:217] pool1 needs backward computation.
I0627 13:53:10.046106  5034 net.cpp:217] relu1_1 needs backward computation.
I0627 13:53:10.046108  5034 net.cpp:217] scale1_1 needs backward computation.
I0627 13:53:10.046110  5034 net.cpp:217] bn1_1 needs backward computation.
I0627 13:53:10.046113  5034 net.cpp:217] conv1_1 needs backward computation.
I0627 13:53:10.046115  5034 net.cpp:219] label_data_1_split does not need backward computation.
I0627 13:53:10.046118  5034 net.cpp:219] data does not need backward computation.
I0627 13:53:10.046120  5034 net.cpp:261] This network produces output accuracy
I0627 13:53:10.046123  5034 net.cpp:261] This network produces output loss
I0627 13:53:10.046136  5034 net.cpp:274] Network initialization done.
I0627 13:53:10.046236  5034 solver.cpp:60] Solver scaffolding done.
I0627 13:53:10.047094  5034 caffe.cpp:219] Starting Optimization
I0627 13:53:10.047101  5034 solver.cpp:279] Solving BPnet
I0627 13:53:10.047102  5034 solver.cpp:280] Learning Rate Policy: step
I0627 13:53:10.048110  5034 solver.cpp:337] Iteration 0, Testing net (#0)
I0627 13:53:10.049096  5034 blocking_queue.cpp:50] Data layer prefetch queue empty
I0627 13:53:12.251405  5034 solver.cpp:404]     Test net output #0: accuracy = 0.472412
I0627 13:53:12.251441  5034 solver.cpp:404]     Test net output #1: loss = 0.693147 (* 1 = 0.693147 loss)
I0627 13:53:12.291291  5034 solver.cpp:228] Iteration 0, loss = 0.693147
I0627 13:53:12.291321  5034 solver.cpp:244]     Train net output #0: accuracy = 0.4375
I0627 13:53:12.291328  5034 solver.cpp:244]     Train net output #1: loss = 0.693147 (* 1 = 0.693147 loss)
I0627 13:53:12.291342  5034 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0627 13:53:13.115355  5034 solver.cpp:228] Iteration 20, loss = 0.682406
I0627 13:53:13.115389  5034 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0627 13:53:13.115397  5034 solver.cpp:244]     Train net output #1: loss = 0.682406 (* 1 = 0.682406 loss)
I0627 13:53:13.115401  5034 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0627 13:53:13.953934  5034 solver.cpp:228] Iteration 40, loss = 0.628178
I0627 13:53:13.953969  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:53:13.953977  5034 solver.cpp:244]     Train net output #1: loss = 0.628178 (* 1 = 0.628178 loss)
I0627 13:53:13.953987  5034 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0627 13:53:14.724545  5034 solver.cpp:228] Iteration 60, loss = 0.665923
I0627 13:53:14.724586  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:53:14.724592  5034 solver.cpp:244]     Train net output #1: loss = 0.665923 (* 1 = 0.665923 loss)
I0627 13:53:14.724596  5034 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0627 13:53:15.495141  5034 solver.cpp:228] Iteration 80, loss = 0.680835
I0627 13:53:15.495179  5034 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0627 13:53:15.495187  5034 solver.cpp:244]     Train net output #1: loss = 0.680835 (* 1 = 0.680835 loss)
I0627 13:53:15.495192  5034 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0627 13:53:16.254799  5034 solver.cpp:337] Iteration 100, Testing net (#0)
I0627 13:53:18.361996  5034 solver.cpp:404]     Test net output #0: accuracy = 0.48291
I0627 13:53:18.362032  5034 solver.cpp:404]     Test net output #1: loss = 0.686313 (* 1 = 0.686313 loss)
I0627 13:53:18.374053  5034 solver.cpp:228] Iteration 100, loss = 0.576264
I0627 13:53:18.374080  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:53:18.374089  5034 solver.cpp:244]     Train net output #1: loss = 0.576264 (* 1 = 0.576264 loss)
I0627 13:53:18.374094  5034 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0627 13:53:19.147081  5034 solver.cpp:228] Iteration 120, loss = 0.61245
I0627 13:53:19.147110  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:53:19.147117  5034 solver.cpp:244]     Train net output #1: loss = 0.61245 (* 1 = 0.61245 loss)
I0627 13:53:19.147121  5034 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0627 13:53:19.921952  5034 solver.cpp:228] Iteration 140, loss = 0.630188
I0627 13:53:19.921988  5034 solver.cpp:244]     Train net output #0: accuracy = 0.53125
I0627 13:53:19.921994  5034 solver.cpp:244]     Train net output #1: loss = 0.630188 (* 1 = 0.630188 loss)
I0627 13:53:19.921999  5034 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0627 13:53:20.706360  5034 solver.cpp:228] Iteration 160, loss = 0.610284
I0627 13:53:20.706399  5034 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 13:53:20.706408  5034 solver.cpp:244]     Train net output #1: loss = 0.610284 (* 1 = 0.610284 loss)
I0627 13:53:20.706411  5034 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0627 13:53:21.486613  5034 solver.cpp:228] Iteration 180, loss = 0.602931
I0627 13:53:21.486652  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:53:21.486690  5034 solver.cpp:244]     Train net output #1: loss = 0.602931 (* 1 = 0.602931 loss)
I0627 13:53:21.486695  5034 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0627 13:53:22.252568  5034 solver.cpp:337] Iteration 200, Testing net (#0)
I0627 13:53:24.430199  5034 solver.cpp:404]     Test net output #0: accuracy = 0.521973
I0627 13:53:24.430235  5034 solver.cpp:404]     Test net output #1: loss = 0.717873 (* 1 = 0.717873 loss)
I0627 13:53:24.442508  5034 solver.cpp:228] Iteration 200, loss = 0.681945
I0627 13:53:24.442535  5034 solver.cpp:244]     Train net output #0: accuracy = 0.46875
I0627 13:53:24.442553  5034 solver.cpp:244]     Train net output #1: loss = 0.681945 (* 1 = 0.681945 loss)
I0627 13:53:24.442559  5034 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0627 13:53:25.226044  5034 solver.cpp:228] Iteration 220, loss = 0.674507
I0627 13:53:25.226071  5034 solver.cpp:244]     Train net output #0: accuracy = 0.53125
I0627 13:53:25.226079  5034 solver.cpp:244]     Train net output #1: loss = 0.674507 (* 1 = 0.674507 loss)
I0627 13:53:25.226084  5034 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0627 13:53:25.999239  5034 solver.cpp:228] Iteration 240, loss = 0.585057
I0627 13:53:25.999279  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:53:25.999285  5034 solver.cpp:244]     Train net output #1: loss = 0.585057 (* 1 = 0.585057 loss)
I0627 13:53:25.999290  5034 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0627 13:53:26.769834  5034 solver.cpp:228] Iteration 260, loss = 0.57558
I0627 13:53:26.769870  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:53:26.769877  5034 solver.cpp:244]     Train net output #1: loss = 0.57558 (* 1 = 0.57558 loss)
I0627 13:53:26.769882  5034 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0627 13:53:27.542156  5034 solver.cpp:228] Iteration 280, loss = 0.570512
I0627 13:53:27.542181  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:53:27.542189  5034 solver.cpp:244]     Train net output #1: loss = 0.570512 (* 1 = 0.570512 loss)
I0627 13:53:27.542193  5034 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0627 13:53:28.302909  5034 solver.cpp:337] Iteration 300, Testing net (#0)
I0627 13:53:30.405423  5034 solver.cpp:404]     Test net output #0: accuracy = 0.56543
I0627 13:53:30.405458  5034 solver.cpp:404]     Test net output #1: loss = 0.705185 (* 1 = 0.705185 loss)
I0627 13:53:30.417757  5034 solver.cpp:228] Iteration 300, loss = 0.593205
I0627 13:53:30.417794  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:53:30.417801  5034 solver.cpp:244]     Train net output #1: loss = 0.593205 (* 1 = 0.593205 loss)
I0627 13:53:30.417807  5034 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0627 13:53:31.196140  5034 solver.cpp:228] Iteration 320, loss = 0.647989
I0627 13:53:31.196167  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:53:31.196176  5034 solver.cpp:244]     Train net output #1: loss = 0.647989 (* 1 = 0.647989 loss)
I0627 13:53:31.196180  5034 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0627 13:53:31.968534  5034 solver.cpp:228] Iteration 340, loss = 0.559735
I0627 13:53:31.968562  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:53:31.968569  5034 solver.cpp:244]     Train net output #1: loss = 0.559735 (* 1 = 0.559735 loss)
I0627 13:53:31.968575  5034 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0627 13:53:32.741101  5034 solver.cpp:228] Iteration 360, loss = 0.630898
I0627 13:53:32.741142  5034 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 13:53:32.741149  5034 solver.cpp:244]     Train net output #1: loss = 0.630898 (* 1 = 0.630898 loss)
I0627 13:53:32.741153  5034 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0627 13:53:33.514013  5034 solver.cpp:228] Iteration 380, loss = 0.574054
I0627 13:53:33.514050  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:53:33.514058  5034 solver.cpp:244]     Train net output #1: loss = 0.574054 (* 1 = 0.574054 loss)
I0627 13:53:33.514087  5034 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0627 13:53:34.275849  5034 solver.cpp:337] Iteration 400, Testing net (#0)
I0627 13:53:36.376693  5034 solver.cpp:404]     Test net output #0: accuracy = 0.591553
I0627 13:53:36.376724  5034 solver.cpp:404]     Test net output #1: loss = 0.704803 (* 1 = 0.704803 loss)
I0627 13:53:36.389017  5034 solver.cpp:228] Iteration 400, loss = 0.519478
I0627 13:53:36.389042  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:53:36.389060  5034 solver.cpp:244]     Train net output #1: loss = 0.519478 (* 1 = 0.519478 loss)
I0627 13:53:36.389065  5034 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0627 13:53:37.168128  5034 solver.cpp:228] Iteration 420, loss = 0.508328
I0627 13:53:37.168159  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:53:37.168166  5034 solver.cpp:244]     Train net output #1: loss = 0.508328 (* 1 = 0.508328 loss)
I0627 13:53:37.168171  5034 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0627 13:53:37.941411  5034 solver.cpp:228] Iteration 440, loss = 0.649321
I0627 13:53:37.941437  5034 solver.cpp:244]     Train net output #0: accuracy = 0.53125
I0627 13:53:37.941457  5034 solver.cpp:244]     Train net output #1: loss = 0.649321 (* 1 = 0.649321 loss)
I0627 13:53:37.941462  5034 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0627 13:53:38.713948  5034 solver.cpp:228] Iteration 460, loss = 0.632244
I0627 13:53:38.713987  5034 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 13:53:38.713994  5034 solver.cpp:244]     Train net output #1: loss = 0.632244 (* 1 = 0.632244 loss)
I0627 13:53:38.713999  5034 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0627 13:53:39.486598  5034 solver.cpp:228] Iteration 480, loss = 0.600264
I0627 13:53:39.486762  5034 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 13:53:39.486771  5034 solver.cpp:244]     Train net output #1: loss = 0.600264 (* 1 = 0.600264 loss)
I0627 13:53:39.486776  5034 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0627 13:53:40.248294  5034 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_500.caffemodel
I0627 13:53:40.261889  5034 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_500.solverstate
I0627 13:53:40.266845  5034 solver.cpp:337] Iteration 500, Testing net (#0)
I0627 13:53:42.381429  5034 solver.cpp:404]     Test net output #0: accuracy = 0.599854
I0627 13:53:42.381464  5034 solver.cpp:404]     Test net output #1: loss = 0.700243 (* 1 = 0.700243 loss)
I0627 13:53:42.393618  5034 solver.cpp:228] Iteration 500, loss = 0.631469
I0627 13:53:42.393646  5034 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0627 13:53:42.393653  5034 solver.cpp:244]     Train net output #1: loss = 0.631469 (* 1 = 0.631469 loss)
I0627 13:53:42.393658  5034 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0627 13:53:43.171309  5034 solver.cpp:228] Iteration 520, loss = 0.601396
I0627 13:53:43.171339  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:53:43.171347  5034 solver.cpp:244]     Train net output #1: loss = 0.601396 (* 1 = 0.601396 loss)
I0627 13:53:43.171351  5034 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0627 13:53:43.945616  5034 solver.cpp:228] Iteration 540, loss = 0.603916
I0627 13:53:43.945642  5034 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 13:53:43.945662  5034 solver.cpp:244]     Train net output #1: loss = 0.603916 (* 1 = 0.603916 loss)
I0627 13:53:43.945665  5034 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0627 13:53:44.719369  5034 solver.cpp:228] Iteration 560, loss = 0.573916
I0627 13:53:44.719398  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:53:44.719405  5034 solver.cpp:244]     Train net output #1: loss = 0.573916 (* 1 = 0.573916 loss)
I0627 13:53:44.719409  5034 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0627 13:53:45.493638  5034 solver.cpp:228] Iteration 580, loss = 0.620777
I0627 13:53:45.493676  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:53:45.493683  5034 solver.cpp:244]     Train net output #1: loss = 0.620777 (* 1 = 0.620777 loss)
I0627 13:53:45.493688  5034 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0627 13:53:46.256304  5034 solver.cpp:337] Iteration 600, Testing net (#0)
I0627 13:53:48.342787  5034 solver.cpp:404]     Test net output #0: accuracy = 0.604248
I0627 13:53:48.342823  5034 solver.cpp:404]     Test net output #1: loss = 0.700909 (* 1 = 0.700909 loss)
I0627 13:53:48.354910  5034 solver.cpp:228] Iteration 600, loss = 0.528119
I0627 13:53:48.354935  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:53:48.354943  5034 solver.cpp:244]     Train net output #1: loss = 0.528119 (* 1 = 0.528119 loss)
I0627 13:53:48.354948  5034 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0627 13:53:49.134115  5034 solver.cpp:228] Iteration 620, loss = 0.603505
I0627 13:53:49.134142  5034 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 13:53:49.134150  5034 solver.cpp:244]     Train net output #1: loss = 0.603505 (* 1 = 0.603505 loss)
I0627 13:53:49.134155  5034 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0627 13:53:49.908143  5034 solver.cpp:228] Iteration 640, loss = 0.604977
I0627 13:53:49.908180  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:53:49.908187  5034 solver.cpp:244]     Train net output #1: loss = 0.604977 (* 1 = 0.604977 loss)
I0627 13:53:49.908192  5034 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0627 13:53:50.682693  5034 solver.cpp:228] Iteration 660, loss = 0.550765
I0627 13:53:50.682734  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:53:50.682740  5034 solver.cpp:244]     Train net output #1: loss = 0.550765 (* 1 = 0.550765 loss)
I0627 13:53:50.682745  5034 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0627 13:53:51.457260  5034 solver.cpp:228] Iteration 680, loss = 0.537624
I0627 13:53:51.457286  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:53:51.457305  5034 solver.cpp:244]     Train net output #1: loss = 0.537624 (* 1 = 0.537624 loss)
I0627 13:53:51.457310  5034 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0627 13:53:52.220201  5034 solver.cpp:337] Iteration 700, Testing net (#0)
I0627 13:53:54.309054  5034 solver.cpp:404]     Test net output #0: accuracy = 0.589111
I0627 13:53:54.309085  5034 solver.cpp:404]     Test net output #1: loss = 0.734928 (* 1 = 0.734928 loss)
I0627 13:53:54.321372  5034 solver.cpp:228] Iteration 700, loss = 0.528748
I0627 13:53:54.321399  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:53:54.321406  5034 solver.cpp:244]     Train net output #1: loss = 0.528748 (* 1 = 0.528748 loss)
I0627 13:53:54.321413  5034 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0627 13:53:55.103971  5034 solver.cpp:228] Iteration 720, loss = 0.498001
I0627 13:53:55.103997  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:53:55.104017  5034 solver.cpp:244]     Train net output #1: loss = 0.498001 (* 1 = 0.498001 loss)
I0627 13:53:55.104020  5034 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0627 13:53:55.877635  5034 solver.cpp:228] Iteration 740, loss = 0.669319
I0627 13:53:55.877672  5034 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 13:53:55.877679  5034 solver.cpp:244]     Train net output #1: loss = 0.669319 (* 1 = 0.669319 loss)
I0627 13:53:55.877683  5034 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0627 13:53:56.651613  5034 solver.cpp:228] Iteration 760, loss = 0.581239
I0627 13:53:56.651651  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:53:56.651659  5034 solver.cpp:244]     Train net output #1: loss = 0.581239 (* 1 = 0.581239 loss)
I0627 13:53:56.651664  5034 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0627 13:53:57.426153  5034 solver.cpp:228] Iteration 780, loss = 0.544343
I0627 13:53:57.426179  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:53:57.426187  5034 solver.cpp:244]     Train net output #1: loss = 0.544343 (* 1 = 0.544343 loss)
I0627 13:53:57.426192  5034 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0627 13:53:58.187845  5034 solver.cpp:337] Iteration 800, Testing net (#0)
I0627 13:54:00.353495  5034 solver.cpp:404]     Test net output #0: accuracy = 0.615967
I0627 13:54:00.353530  5034 solver.cpp:404]     Test net output #1: loss = 0.685209 (* 1 = 0.685209 loss)
I0627 13:54:00.366053  5034 solver.cpp:228] Iteration 800, loss = 0.651547
I0627 13:54:00.366077  5034 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 13:54:00.366086  5034 solver.cpp:244]     Train net output #1: loss = 0.651547 (* 1 = 0.651547 loss)
I0627 13:54:00.366089  5034 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0627 13:54:01.207926  5034 solver.cpp:228] Iteration 820, loss = 0.55311
I0627 13:54:01.207964  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:54:01.207972  5034 solver.cpp:244]     Train net output #1: loss = 0.55311 (* 1 = 0.55311 loss)
I0627 13:54:01.207975  5034 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0627 13:54:01.982138  5034 solver.cpp:228] Iteration 840, loss = 0.659995
I0627 13:54:01.982177  5034 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 13:54:01.982184  5034 solver.cpp:244]     Train net output #1: loss = 0.659995 (* 1 = 0.659995 loss)
I0627 13:54:01.982188  5034 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0627 13:54:02.758040  5034 solver.cpp:228] Iteration 860, loss = 0.616534
I0627 13:54:02.758080  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:54:02.758087  5034 solver.cpp:244]     Train net output #1: loss = 0.616534 (* 1 = 0.616534 loss)
I0627 13:54:02.758092  5034 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0627 13:54:03.534126  5034 solver.cpp:228] Iteration 880, loss = 0.593065
I0627 13:54:03.534164  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:54:03.534196  5034 solver.cpp:244]     Train net output #1: loss = 0.593065 (* 1 = 0.593065 loss)
I0627 13:54:03.534201  5034 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0627 13:54:04.298627  5034 solver.cpp:337] Iteration 900, Testing net (#0)
I0627 13:54:06.447685  5034 solver.cpp:404]     Test net output #0: accuracy = 0.609863
I0627 13:54:06.447718  5034 solver.cpp:404]     Test net output #1: loss = 0.683242 (* 1 = 0.683242 loss)
I0627 13:54:06.460217  5034 solver.cpp:228] Iteration 900, loss = 0.489856
I0627 13:54:06.460244  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:54:06.460252  5034 solver.cpp:244]     Train net output #1: loss = 0.489856 (* 1 = 0.489856 loss)
I0627 13:54:06.460256  5034 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0627 13:54:07.302759  5034 solver.cpp:228] Iteration 920, loss = 0.643474
I0627 13:54:07.302785  5034 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 13:54:07.302804  5034 solver.cpp:244]     Train net output #1: loss = 0.643474 (* 1 = 0.643474 loss)
I0627 13:54:07.302809  5034 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0627 13:54:08.079179  5034 solver.cpp:228] Iteration 940, loss = 0.550089
I0627 13:54:08.079206  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:54:08.079226  5034 solver.cpp:244]     Train net output #1: loss = 0.550089 (* 1 = 0.550089 loss)
I0627 13:54:08.079231  5034 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0627 13:54:08.855060  5034 solver.cpp:228] Iteration 960, loss = 0.560334
I0627 13:54:08.855098  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:54:08.855105  5034 solver.cpp:244]     Train net output #1: loss = 0.560334 (* 1 = 0.560334 loss)
I0627 13:54:08.855110  5034 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0627 13:54:09.630426  5034 solver.cpp:228] Iteration 980, loss = 0.550156
I0627 13:54:09.630592  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:54:09.630614  5034 solver.cpp:244]     Train net output #1: loss = 0.550156 (* 1 = 0.550156 loss)
I0627 13:54:09.630622  5034 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0627 13:54:10.395015  5034 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_1000.caffemodel
I0627 13:54:10.404650  5034 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_1000.solverstate
I0627 13:54:10.409644  5034 solver.cpp:337] Iteration 1000, Testing net (#0)
I0627 13:54:12.555065  5034 solver.cpp:404]     Test net output #0: accuracy = 0.606934
I0627 13:54:12.555095  5034 solver.cpp:404]     Test net output #1: loss = 0.713947 (* 1 = 0.713947 loss)
I0627 13:54:12.567643  5034 solver.cpp:228] Iteration 1000, loss = 0.613092
I0627 13:54:12.567672  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:54:12.567679  5034 solver.cpp:244]     Train net output #1: loss = 0.613092 (* 1 = 0.613092 loss)
I0627 13:54:12.567685  5034 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0627 13:54:13.350890  5034 solver.cpp:228] Iteration 1020, loss = 0.441027
I0627 13:54:13.350929  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:54:13.350936  5034 solver.cpp:244]     Train net output #1: loss = 0.441027 (* 1 = 0.441027 loss)
I0627 13:54:13.350940  5034 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0627 13:54:14.127532  5034 solver.cpp:228] Iteration 1040, loss = 0.579262
I0627 13:54:14.127571  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:54:14.127578  5034 solver.cpp:244]     Train net output #1: loss = 0.579262 (* 1 = 0.579262 loss)
I0627 13:54:14.127583  5034 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0627 13:54:14.903918  5034 solver.cpp:228] Iteration 1060, loss = 0.476566
I0627 13:54:14.903956  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:54:14.903964  5034 solver.cpp:244]     Train net output #1: loss = 0.476566 (* 1 = 0.476566 loss)
I0627 13:54:14.903970  5034 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0627 13:54:15.679765  5034 solver.cpp:228] Iteration 1080, loss = 0.480838
I0627 13:54:15.679805  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:54:15.679813  5034 solver.cpp:244]     Train net output #1: loss = 0.480838 (* 1 = 0.480838 loss)
I0627 13:54:15.679817  5034 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0627 13:54:16.444133  5034 solver.cpp:337] Iteration 1100, Testing net (#0)
I0627 13:54:18.590200  5034 solver.cpp:404]     Test net output #0: accuracy = 0.656982
I0627 13:54:18.590235  5034 solver.cpp:404]     Test net output #1: loss = 0.652043 (* 1 = 0.652043 loss)
I0627 13:54:18.602635  5034 solver.cpp:228] Iteration 1100, loss = 0.528923
I0627 13:54:18.602659  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:54:18.602666  5034 solver.cpp:244]     Train net output #1: loss = 0.528923 (* 1 = 0.528923 loss)
I0627 13:54:18.602671  5034 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0627 13:54:19.441730  5034 solver.cpp:228] Iteration 1120, loss = 0.66603
I0627 13:54:19.441754  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:54:19.441761  5034 solver.cpp:244]     Train net output #1: loss = 0.66603 (* 1 = 0.66603 loss)
I0627 13:54:19.441766  5034 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0627 13:54:20.217667  5034 solver.cpp:228] Iteration 1140, loss = 0.641384
I0627 13:54:20.217707  5034 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 13:54:20.217715  5034 solver.cpp:244]     Train net output #1: loss = 0.641384 (* 1 = 0.641384 loss)
I0627 13:54:20.217720  5034 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0627 13:54:20.993376  5034 solver.cpp:228] Iteration 1160, loss = 0.546427
I0627 13:54:20.993412  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:54:20.993419  5034 solver.cpp:244]     Train net output #1: loss = 0.546427 (* 1 = 0.546427 loss)
I0627 13:54:20.993424  5034 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0627 13:54:21.769536  5034 solver.cpp:228] Iteration 1180, loss = 0.527042
I0627 13:54:21.769565  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:54:21.769572  5034 solver.cpp:244]     Train net output #1: loss = 0.527042 (* 1 = 0.527042 loss)
I0627 13:54:21.769577  5034 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0627 13:54:22.533849  5034 solver.cpp:337] Iteration 1200, Testing net (#0)
I0627 13:54:24.699506  5034 solver.cpp:404]     Test net output #0: accuracy = 0.623047
I0627 13:54:24.699551  5034 solver.cpp:404]     Test net output #1: loss = 0.660966 (* 1 = 0.660966 loss)
I0627 13:54:24.712038  5034 solver.cpp:228] Iteration 1200, loss = 0.410403
I0627 13:54:24.712065  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:54:24.712072  5034 solver.cpp:244]     Train net output #1: loss = 0.410403 (* 1 = 0.410403 loss)
I0627 13:54:24.712077  5034 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0627 13:54:25.502434  5034 solver.cpp:228] Iteration 1220, loss = 0.719563
I0627 13:54:25.502459  5034 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 13:54:25.502465  5034 solver.cpp:244]     Train net output #1: loss = 0.719563 (* 1 = 0.719563 loss)
I0627 13:54:25.502470  5034 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0627 13:54:26.281365  5034 solver.cpp:228] Iteration 1240, loss = 0.485555
I0627 13:54:26.281404  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:54:26.281412  5034 solver.cpp:244]     Train net output #1: loss = 0.485555 (* 1 = 0.485555 loss)
I0627 13:54:26.281416  5034 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0627 13:54:27.060927  5034 solver.cpp:228] Iteration 1260, loss = 0.432944
I0627 13:54:27.060955  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:54:27.060962  5034 solver.cpp:244]     Train net output #1: loss = 0.432944 (* 1 = 0.432944 loss)
I0627 13:54:27.060967  5034 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0627 13:54:27.840608  5034 solver.cpp:228] Iteration 1280, loss = 0.601384
I0627 13:54:27.840636  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:54:27.840643  5034 solver.cpp:244]     Train net output #1: loss = 0.601384 (* 1 = 0.601384 loss)
I0627 13:54:27.840648  5034 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0627 13:54:28.607410  5034 solver.cpp:337] Iteration 1300, Testing net (#0)
I0627 13:54:30.776907  5034 solver.cpp:404]     Test net output #0: accuracy = 0.607178
I0627 13:54:30.776937  5034 solver.cpp:404]     Test net output #1: loss = 0.718154 (* 1 = 0.718154 loss)
I0627 13:54:30.789484  5034 solver.cpp:228] Iteration 1300, loss = 0.59649
I0627 13:54:30.789510  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:54:30.789518  5034 solver.cpp:244]     Train net output #1: loss = 0.59649 (* 1 = 0.59649 loss)
I0627 13:54:30.789523  5034 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0627 13:54:31.634304  5034 solver.cpp:228] Iteration 1320, loss = 0.39241
I0627 13:54:31.634328  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:54:31.634347  5034 solver.cpp:244]     Train net output #1: loss = 0.39241 (* 1 = 0.39241 loss)
I0627 13:54:31.634352  5034 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0627 13:54:32.412523  5034 solver.cpp:228] Iteration 1340, loss = 0.544045
I0627 13:54:32.412564  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:54:32.412571  5034 solver.cpp:244]     Train net output #1: loss = 0.544045 (* 1 = 0.544045 loss)
I0627 13:54:32.412575  5034 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0627 13:54:33.190331  5034 solver.cpp:228] Iteration 1360, loss = 0.416969
I0627 13:54:33.190358  5034 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0627 13:54:33.190377  5034 solver.cpp:244]     Train net output #1: loss = 0.416969 (* 1 = 0.416969 loss)
I0627 13:54:33.190382  5034 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0627 13:54:33.968804  5034 solver.cpp:228] Iteration 1380, loss = 0.487057
I0627 13:54:33.968850  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:54:33.968859  5034 solver.cpp:244]     Train net output #1: loss = 0.487057 (* 1 = 0.487057 loss)
I0627 13:54:33.968864  5034 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0627 13:54:34.800660  5034 solver.cpp:337] Iteration 1400, Testing net (#0)
I0627 13:54:36.972517  5034 solver.cpp:404]     Test net output #0: accuracy = 0.678223
I0627 13:54:36.972548  5034 solver.cpp:404]     Test net output #1: loss = 0.627058 (* 1 = 0.627058 loss)
I0627 13:54:36.985155  5034 solver.cpp:228] Iteration 1400, loss = 0.557265
I0627 13:54:36.985180  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:54:36.985188  5034 solver.cpp:244]     Train net output #1: loss = 0.557265 (* 1 = 0.557265 loss)
I0627 13:54:36.985193  5034 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0627 13:54:37.830230  5034 solver.cpp:228] Iteration 1420, loss = 0.542615
I0627 13:54:37.830271  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:54:37.830278  5034 solver.cpp:244]     Train net output #1: loss = 0.542615 (* 1 = 0.542615 loss)
I0627 13:54:37.830282  5034 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0627 13:54:38.608551  5034 solver.cpp:228] Iteration 1440, loss = 0.672141
I0627 13:54:38.608598  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:54:38.608606  5034 solver.cpp:244]     Train net output #1: loss = 0.672141 (* 1 = 0.672141 loss)
I0627 13:54:38.608611  5034 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0627 13:54:39.386561  5034 solver.cpp:228] Iteration 1460, loss = 0.527928
I0627 13:54:39.386598  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:54:39.386606  5034 solver.cpp:244]     Train net output #1: loss = 0.527928 (* 1 = 0.527928 loss)
I0627 13:54:39.386610  5034 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0627 13:54:40.164273  5034 solver.cpp:228] Iteration 1480, loss = 0.48629
I0627 13:54:40.164436  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:54:40.164448  5034 solver.cpp:244]     Train net output #1: loss = 0.48629 (* 1 = 0.48629 loss)
I0627 13:54:40.164453  5034 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0627 13:54:40.930860  5034 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_1500.caffemodel
I0627 13:54:40.940382  5034 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_1500.solverstate
I0627 13:54:40.945863  5034 solver.cpp:337] Iteration 1500, Testing net (#0)
I0627 13:54:42.237473  5034 blocking_queue.cpp:50] Data layer prefetch queue empty
I0627 13:54:43.105928  5034 solver.cpp:404]     Test net output #0: accuracy = 0.669434
I0627 13:54:43.105963  5034 solver.cpp:404]     Test net output #1: loss = 0.62405 (* 1 = 0.62405 loss)
I0627 13:54:43.118517  5034 solver.cpp:228] Iteration 1500, loss = 0.404746
I0627 13:54:43.118544  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:54:43.118552  5034 solver.cpp:244]     Train net output #1: loss = 0.404746 (* 1 = 0.404746 loss)
I0627 13:54:43.118558  5034 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0627 13:54:43.910157  5034 solver.cpp:228] Iteration 1520, loss = 0.516096
I0627 13:54:43.910183  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:54:43.910192  5034 solver.cpp:244]     Train net output #1: loss = 0.516096 (* 1 = 0.516096 loss)
I0627 13:54:43.910195  5034 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0627 13:54:44.749521  5034 solver.cpp:228] Iteration 1540, loss = 0.522585
I0627 13:54:44.749552  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:54:44.749559  5034 solver.cpp:244]     Train net output #1: loss = 0.522585 (* 1 = 0.522585 loss)
I0627 13:54:44.749564  5034 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0627 13:54:45.528825  5034 solver.cpp:228] Iteration 1560, loss = 0.509859
I0627 13:54:45.528862  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:54:45.528870  5034 solver.cpp:244]     Train net output #1: loss = 0.509859 (* 1 = 0.509859 loss)
I0627 13:54:45.528874  5034 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0627 13:54:46.308331  5034 solver.cpp:228] Iteration 1580, loss = 0.571273
I0627 13:54:46.308357  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:54:46.308377  5034 solver.cpp:244]     Train net output #1: loss = 0.571273 (* 1 = 0.571273 loss)
I0627 13:54:46.308382  5034 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0627 13:54:47.075847  5034 solver.cpp:337] Iteration 1600, Testing net (#0)
I0627 13:54:49.238683  5034 solver.cpp:404]     Test net output #0: accuracy = 0.615234
I0627 13:54:49.238715  5034 solver.cpp:404]     Test net output #1: loss = 0.692224 (* 1 = 0.692224 loss)
I0627 13:54:49.251283  5034 solver.cpp:228] Iteration 1600, loss = 0.601783
I0627 13:54:49.251310  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:54:49.251318  5034 solver.cpp:244]     Train net output #1: loss = 0.601783 (* 1 = 0.601783 loss)
I0627 13:54:49.251323  5034 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0627 13:54:50.036105  5034 solver.cpp:228] Iteration 1620, loss = 0.462209
I0627 13:54:50.036133  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:54:50.036151  5034 solver.cpp:244]     Train net output #1: loss = 0.462209 (* 1 = 0.462209 loss)
I0627 13:54:50.036155  5034 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0627 13:54:50.815572  5034 solver.cpp:228] Iteration 1640, loss = 0.501281
I0627 13:54:50.815599  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:54:50.815606  5034 solver.cpp:244]     Train net output #1: loss = 0.501281 (* 1 = 0.501281 loss)
I0627 13:54:50.815611  5034 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0627 13:54:51.593938  5034 solver.cpp:228] Iteration 1660, loss = 0.357512
I0627 13:54:51.593976  5034 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0627 13:54:51.593984  5034 solver.cpp:244]     Train net output #1: loss = 0.357512 (* 1 = 0.357512 loss)
I0627 13:54:51.594012  5034 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0627 13:54:52.372486  5034 solver.cpp:228] Iteration 1680, loss = 0.430298
I0627 13:54:52.372522  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:54:52.372530  5034 solver.cpp:244]     Train net output #1: loss = 0.430298 (* 1 = 0.430298 loss)
I0627 13:54:52.372534  5034 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0627 13:54:53.140270  5034 solver.cpp:337] Iteration 1700, Testing net (#0)
I0627 13:54:55.307301  5034 solver.cpp:404]     Test net output #0: accuracy = 0.689209
I0627 13:54:55.307334  5034 solver.cpp:404]     Test net output #1: loss = 0.602887 (* 1 = 0.602887 loss)
I0627 13:54:55.319783  5034 solver.cpp:228] Iteration 1700, loss = 0.541335
I0627 13:54:55.319810  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:54:55.319818  5034 solver.cpp:244]     Train net output #1: loss = 0.541335 (* 1 = 0.541335 loss)
I0627 13:54:55.319824  5034 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0627 13:54:56.108031  5034 solver.cpp:228] Iteration 1720, loss = 0.593766
I0627 13:54:56.108069  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:54:56.108078  5034 solver.cpp:244]     Train net output #1: loss = 0.593766 (* 1 = 0.593766 loss)
I0627 13:54:56.108083  5034 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0627 13:54:56.887537  5034 solver.cpp:228] Iteration 1740, loss = 0.683809
I0627 13:54:56.887567  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:54:56.887573  5034 solver.cpp:244]     Train net output #1: loss = 0.683809 (* 1 = 0.683809 loss)
I0627 13:54:56.887578  5034 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0627 13:54:57.666414  5034 solver.cpp:228] Iteration 1760, loss = 0.513763
I0627 13:54:57.666440  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:54:57.666458  5034 solver.cpp:244]     Train net output #1: loss = 0.513763 (* 1 = 0.513763 loss)
I0627 13:54:57.666462  5034 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0627 13:54:58.445940  5034 solver.cpp:228] Iteration 1780, loss = 0.525557
I0627 13:54:58.445976  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:54:58.445984  5034 solver.cpp:244]     Train net output #1: loss = 0.525557 (* 1 = 0.525557 loss)
I0627 13:54:58.445988  5034 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0627 13:54:59.221451  5034 solver.cpp:337] Iteration 1800, Testing net (#0)
I0627 13:55:01.383833  5034 solver.cpp:404]     Test net output #0: accuracy = 0.67749
I0627 13:55:01.383867  5034 solver.cpp:404]     Test net output #1: loss = 0.623621 (* 1 = 0.623621 loss)
I0627 13:55:01.397423  5034 solver.cpp:228] Iteration 1800, loss = 0.491648
I0627 13:55:01.397449  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:55:01.397457  5034 solver.cpp:244]     Train net output #1: loss = 0.491648 (* 1 = 0.491648 loss)
I0627 13:55:01.397462  5034 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0627 13:55:02.249918  5034 solver.cpp:228] Iteration 1820, loss = 0.590988
I0627 13:55:02.249958  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:55:02.249965  5034 solver.cpp:244]     Train net output #1: loss = 0.590988 (* 1 = 0.590988 loss)
I0627 13:55:02.249969  5034 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0627 13:55:03.029508  5034 solver.cpp:228] Iteration 1840, loss = 0.477291
I0627 13:55:03.029536  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:55:03.029554  5034 solver.cpp:244]     Train net output #1: loss = 0.477291 (* 1 = 0.477291 loss)
I0627 13:55:03.029559  5034 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0627 13:55:03.808209  5034 solver.cpp:228] Iteration 1860, loss = 0.659501
I0627 13:55:03.808246  5034 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 13:55:03.808254  5034 solver.cpp:244]     Train net output #1: loss = 0.659501 (* 1 = 0.659501 loss)
I0627 13:55:03.808259  5034 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0627 13:55:04.587821  5034 solver.cpp:228] Iteration 1880, loss = 0.576563
I0627 13:55:04.587849  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:55:04.587857  5034 solver.cpp:244]     Train net output #1: loss = 0.576563 (* 1 = 0.576563 loss)
I0627 13:55:04.587862  5034 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0627 13:55:05.377955  5034 solver.cpp:337] Iteration 1900, Testing net (#0)
I0627 13:55:07.524314  5034 solver.cpp:404]     Test net output #0: accuracy = 0.641846
I0627 13:55:07.524344  5034 solver.cpp:404]     Test net output #1: loss = 0.672068 (* 1 = 0.672068 loss)
I0627 13:55:07.536826  5034 solver.cpp:228] Iteration 1900, loss = 0.580114
I0627 13:55:07.536854  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:55:07.536861  5034 solver.cpp:244]     Train net output #1: loss = 0.580114 (* 1 = 0.580114 loss)
I0627 13:55:07.536866  5034 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0627 13:55:08.376690  5034 solver.cpp:228] Iteration 1920, loss = 0.486255
I0627 13:55:08.376730  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:55:08.376739  5034 solver.cpp:244]     Train net output #1: loss = 0.486255 (* 1 = 0.486255 loss)
I0627 13:55:08.376742  5034 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0627 13:55:09.155987  5034 solver.cpp:228] Iteration 1940, loss = 0.543244
I0627 13:55:09.156026  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:55:09.156034  5034 solver.cpp:244]     Train net output #1: loss = 0.543244 (* 1 = 0.543244 loss)
I0627 13:55:09.156039  5034 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0627 13:55:09.934738  5034 solver.cpp:228] Iteration 1960, loss = 0.351921
I0627 13:55:09.934778  5034 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0627 13:55:09.934785  5034 solver.cpp:244]     Train net output #1: loss = 0.351921 (* 1 = 0.351921 loss)
I0627 13:55:09.934789  5034 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0627 13:55:10.771106  5034 solver.cpp:228] Iteration 1980, loss = 0.33353
I0627 13:55:10.771216  5034 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0627 13:55:10.771227  5034 solver.cpp:244]     Train net output #1: loss = 0.33353 (* 1 = 0.33353 loss)
I0627 13:55:10.771231  5034 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0627 13:55:11.538334  5034 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_2000.caffemodel
I0627 13:55:11.547904  5034 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_2000.solverstate
I0627 13:55:11.552953  5034 solver.cpp:337] Iteration 2000, Testing net (#0)
I0627 13:55:13.667286  5034 solver.cpp:404]     Test net output #0: accuracy = 0.701172
I0627 13:55:13.667318  5034 solver.cpp:404]     Test net output #1: loss = 0.597445 (* 1 = 0.597445 loss)
I0627 13:55:13.679781  5034 solver.cpp:228] Iteration 2000, loss = 0.491569
I0627 13:55:13.679811  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:55:13.679818  5034 solver.cpp:244]     Train net output #1: loss = 0.491569 (* 1 = 0.491569 loss)
I0627 13:55:13.679824  5034 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0627 13:55:14.473301  5034 solver.cpp:228] Iteration 2020, loss = 0.37092
I0627 13:55:14.473338  5034 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0627 13:55:14.473346  5034 solver.cpp:244]     Train net output #1: loss = 0.37092 (* 1 = 0.37092 loss)
I0627 13:55:14.473351  5034 sgd_solver.cpp:106] Iteration 2020, lr = 0.0001
I0627 13:55:15.251885  5034 solver.cpp:228] Iteration 2040, loss = 0.570206
I0627 13:55:15.251911  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:55:15.251919  5034 solver.cpp:244]     Train net output #1: loss = 0.570206 (* 1 = 0.570206 loss)
I0627 13:55:15.251924  5034 sgd_solver.cpp:106] Iteration 2040, lr = 0.0001
I0627 13:55:16.030235  5034 solver.cpp:228] Iteration 2060, loss = 0.551484
I0627 13:55:16.030259  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:55:16.030277  5034 solver.cpp:244]     Train net output #1: loss = 0.551484 (* 1 = 0.551484 loss)
I0627 13:55:16.030282  5034 sgd_solver.cpp:106] Iteration 2060, lr = 0.0001
I0627 13:55:16.837879  5034 solver.cpp:228] Iteration 2080, loss = 0.501082
I0627 13:55:16.837906  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:55:16.837913  5034 solver.cpp:244]     Train net output #1: loss = 0.501082 (* 1 = 0.501082 loss)
I0627 13:55:16.837918  5034 sgd_solver.cpp:106] Iteration 2080, lr = 0.0001
I0627 13:55:17.630367  5034 solver.cpp:337] Iteration 2100, Testing net (#0)
I0627 13:55:19.782156  5034 solver.cpp:404]     Test net output #0: accuracy = 0.682373
I0627 13:55:19.782188  5034 solver.cpp:404]     Test net output #1: loss = 0.614681 (* 1 = 0.614681 loss)
I0627 13:55:19.794706  5034 solver.cpp:228] Iteration 2100, loss = 0.558804
I0627 13:55:19.794730  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:55:19.794739  5034 solver.cpp:244]     Train net output #1: loss = 0.558804 (* 1 = 0.558804 loss)
I0627 13:55:19.794742  5034 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0627 13:55:20.642678  5034 solver.cpp:228] Iteration 2120, loss = 0.635327
I0627 13:55:20.642705  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:55:20.642714  5034 solver.cpp:244]     Train net output #1: loss = 0.635327 (* 1 = 0.635327 loss)
I0627 13:55:20.642717  5034 sgd_solver.cpp:106] Iteration 2120, lr = 0.0001
I0627 13:55:21.536104  5034 solver.cpp:228] Iteration 2140, loss = 0.551338
I0627 13:55:21.536133  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:55:21.536140  5034 solver.cpp:244]     Train net output #1: loss = 0.551338 (* 1 = 0.551338 loss)
I0627 13:55:21.536144  5034 sgd_solver.cpp:106] Iteration 2140, lr = 0.0001
I0627 13:55:22.337035  5034 solver.cpp:228] Iteration 2160, loss = 0.539932
I0627 13:55:22.337061  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:55:22.337080  5034 solver.cpp:244]     Train net output #1: loss = 0.539932 (* 1 = 0.539932 loss)
I0627 13:55:22.337085  5034 sgd_solver.cpp:106] Iteration 2160, lr = 0.0001
I0627 13:55:23.121093  5034 solver.cpp:228] Iteration 2180, loss = 0.53587
I0627 13:55:23.121119  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:55:23.121137  5034 solver.cpp:244]     Train net output #1: loss = 0.53587 (* 1 = 0.53587 loss)
I0627 13:55:23.121141  5034 sgd_solver.cpp:106] Iteration 2180, lr = 0.0001
I0627 13:55:23.914477  5034 solver.cpp:337] Iteration 2200, Testing net (#0)
I0627 13:55:26.092118  5034 solver.cpp:404]     Test net output #0: accuracy = 0.6875
I0627 13:55:26.092170  5034 solver.cpp:404]     Test net output #1: loss = 0.611334 (* 1 = 0.611334 loss)
I0627 13:55:26.104666  5034 solver.cpp:228] Iteration 2200, loss = 0.472208
I0627 13:55:26.104692  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:55:26.104701  5034 solver.cpp:244]     Train net output #1: loss = 0.472208 (* 1 = 0.472208 loss)
I0627 13:55:26.104706  5034 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0627 13:55:26.948331  5034 solver.cpp:228] Iteration 2220, loss = 0.513949
I0627 13:55:26.948357  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:55:26.948365  5034 solver.cpp:244]     Train net output #1: loss = 0.513949 (* 1 = 0.513949 loss)
I0627 13:55:26.948369  5034 sgd_solver.cpp:106] Iteration 2220, lr = 0.0001
I0627 13:55:27.742228  5034 solver.cpp:228] Iteration 2240, loss = 0.597467
I0627 13:55:27.742259  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:55:27.742269  5034 solver.cpp:244]     Train net output #1: loss = 0.597467 (* 1 = 0.597467 loss)
I0627 13:55:27.742274  5034 sgd_solver.cpp:106] Iteration 2240, lr = 0.0001
I0627 13:55:28.551074  5034 solver.cpp:228] Iteration 2260, loss = 0.400938
I0627 13:55:28.551111  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:55:28.551120  5034 solver.cpp:244]     Train net output #1: loss = 0.400938 (* 1 = 0.400938 loss)
I0627 13:55:28.551125  5034 sgd_solver.cpp:106] Iteration 2260, lr = 0.0001
I0627 13:55:29.349272  5034 solver.cpp:228] Iteration 2280, loss = 0.375532
I0627 13:55:29.349299  5034 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0627 13:55:29.349308  5034 solver.cpp:244]     Train net output #1: loss = 0.375532 (* 1 = 0.375532 loss)
I0627 13:55:29.349313  5034 sgd_solver.cpp:106] Iteration 2280, lr = 0.0001
I0627 13:55:30.129052  5034 solver.cpp:337] Iteration 2300, Testing net (#0)
I0627 13:55:32.290500  5034 solver.cpp:404]     Test net output #0: accuracy = 0.671143
I0627 13:55:32.290552  5034 solver.cpp:404]     Test net output #1: loss = 0.630381 (* 1 = 0.630381 loss)
I0627 13:55:32.302892  5034 solver.cpp:228] Iteration 2300, loss = 0.597696
I0627 13:55:32.302927  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:55:32.302937  5034 solver.cpp:244]     Train net output #1: loss = 0.597696 (* 1 = 0.597696 loss)
I0627 13:55:32.302943  5034 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0627 13:55:33.094708  5034 solver.cpp:228] Iteration 2320, loss = 0.396774
I0627 13:55:33.094734  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:55:33.094743  5034 solver.cpp:244]     Train net output #1: loss = 0.396774 (* 1 = 0.396774 loss)
I0627 13:55:33.094748  5034 sgd_solver.cpp:106] Iteration 2320, lr = 0.0001
I0627 13:55:33.875372  5034 solver.cpp:228] Iteration 2340, loss = 0.47112
I0627 13:55:33.875414  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:55:33.875437  5034 solver.cpp:244]     Train net output #1: loss = 0.47112 (* 1 = 0.47112 loss)
I0627 13:55:33.875445  5034 sgd_solver.cpp:106] Iteration 2340, lr = 0.0001
I0627 13:55:34.652650  5034 solver.cpp:228] Iteration 2360, loss = 0.638423
I0627 13:55:34.652678  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:55:34.652685  5034 solver.cpp:244]     Train net output #1: loss = 0.638423 (* 1 = 0.638423 loss)
I0627 13:55:34.652689  5034 sgd_solver.cpp:106] Iteration 2360, lr = 0.0001
I0627 13:55:35.431941  5034 solver.cpp:228] Iteration 2380, loss = 0.466905
I0627 13:55:35.431999  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:55:35.432008  5034 solver.cpp:244]     Train net output #1: loss = 0.466905 (* 1 = 0.466905 loss)
I0627 13:55:35.432013  5034 sgd_solver.cpp:106] Iteration 2380, lr = 0.0001
I0627 13:55:36.199463  5034 solver.cpp:337] Iteration 2400, Testing net (#0)
I0627 13:55:38.325727  5034 solver.cpp:404]     Test net output #0: accuracy = 0.671631
I0627 13:55:38.325759  5034 solver.cpp:404]     Test net output #1: loss = 0.624877 (* 1 = 0.624877 loss)
I0627 13:55:38.338136  5034 solver.cpp:228] Iteration 2400, loss = 0.545312
I0627 13:55:38.338163  5034 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0627 13:55:38.338171  5034 solver.cpp:244]     Train net output #1: loss = 0.545312 (* 1 = 0.545312 loss)
I0627 13:55:38.338176  5034 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0627 13:55:39.121484  5034 solver.cpp:228] Iteration 2420, loss = 0.604824
I0627 13:55:39.121521  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:55:39.121529  5034 solver.cpp:244]     Train net output #1: loss = 0.604824 (* 1 = 0.604824 loss)
I0627 13:55:39.121533  5034 sgd_solver.cpp:106] Iteration 2420, lr = 0.0001
I0627 13:55:39.898860  5034 solver.cpp:228] Iteration 2440, loss = 0.493379
I0627 13:55:39.898885  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:55:39.898892  5034 solver.cpp:244]     Train net output #1: loss = 0.493379 (* 1 = 0.493379 loss)
I0627 13:55:39.898897  5034 sgd_solver.cpp:106] Iteration 2440, lr = 0.0001
I0627 13:55:40.678010  5034 solver.cpp:228] Iteration 2460, loss = 0.533928
I0627 13:55:40.678047  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:55:40.678056  5034 solver.cpp:244]     Train net output #1: loss = 0.533928 (* 1 = 0.533928 loss)
I0627 13:55:40.678059  5034 sgd_solver.cpp:106] Iteration 2460, lr = 0.0001
I0627 13:55:41.457191  5034 solver.cpp:228] Iteration 2480, loss = 0.475426
I0627 13:55:41.457340  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:55:41.457351  5034 solver.cpp:244]     Train net output #1: loss = 0.475426 (* 1 = 0.475426 loss)
I0627 13:55:41.457355  5034 sgd_solver.cpp:106] Iteration 2480, lr = 0.0001
I0627 13:55:42.224191  5034 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_2500.caffemodel
I0627 13:55:42.233737  5034 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_2500.solverstate
I0627 13:55:42.238631  5034 solver.cpp:337] Iteration 2500, Testing net (#0)
I0627 13:55:44.380669  5034 solver.cpp:404]     Test net output #0: accuracy = 0.685303
I0627 13:55:44.380712  5034 solver.cpp:404]     Test net output #1: loss = 0.613315 (* 1 = 0.613315 loss)
I0627 13:55:44.393106  5034 solver.cpp:228] Iteration 2500, loss = 0.39622
I0627 13:55:44.393132  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:55:44.393141  5034 solver.cpp:244]     Train net output #1: loss = 0.39622 (* 1 = 0.39622 loss)
I0627 13:55:44.393146  5034 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0627 13:55:45.178064  5034 solver.cpp:228] Iteration 2520, loss = 0.561826
I0627 13:55:45.178089  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:55:45.178097  5034 solver.cpp:244]     Train net output #1: loss = 0.561826 (* 1 = 0.561826 loss)
I0627 13:55:45.178102  5034 sgd_solver.cpp:106] Iteration 2520, lr = 0.0001
I0627 13:55:45.956902  5034 solver.cpp:228] Iteration 2540, loss = 0.605731
I0627 13:55:45.956931  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:55:45.956939  5034 solver.cpp:244]     Train net output #1: loss = 0.605731 (* 1 = 0.605731 loss)
I0627 13:55:45.956943  5034 sgd_solver.cpp:106] Iteration 2540, lr = 0.0001
I0627 13:55:46.761790  5034 solver.cpp:228] Iteration 2560, loss = 0.454139
I0627 13:55:46.761818  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:55:46.761826  5034 solver.cpp:244]     Train net output #1: loss = 0.454139 (* 1 = 0.454139 loss)
I0627 13:55:46.761831  5034 sgd_solver.cpp:106] Iteration 2560, lr = 0.0001
I0627 13:55:47.596801  5034 solver.cpp:228] Iteration 2580, loss = 0.367585
I0627 13:55:47.596827  5034 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0627 13:55:47.596846  5034 solver.cpp:244]     Train net output #1: loss = 0.367585 (* 1 = 0.367585 loss)
I0627 13:55:47.596850  5034 sgd_solver.cpp:106] Iteration 2580, lr = 0.0001
I0627 13:55:48.363405  5034 solver.cpp:337] Iteration 2600, Testing net (#0)
I0627 13:55:50.510777  5034 solver.cpp:404]     Test net output #0: accuracy = 0.671631
I0627 13:55:50.510812  5034 solver.cpp:404]     Test net output #1: loss = 0.627733 (* 1 = 0.627733 loss)
I0627 13:55:50.523205  5034 solver.cpp:228] Iteration 2600, loss = 0.571189
I0627 13:55:50.523232  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:55:50.523241  5034 solver.cpp:244]     Train net output #1: loss = 0.571189 (* 1 = 0.571189 loss)
I0627 13:55:50.523246  5034 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0627 13:55:51.368585  5034 solver.cpp:228] Iteration 2620, loss = 0.430521
I0627 13:55:51.368612  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:55:51.368630  5034 solver.cpp:244]     Train net output #1: loss = 0.430521 (* 1 = 0.430521 loss)
I0627 13:55:51.368635  5034 sgd_solver.cpp:106] Iteration 2620, lr = 0.0001
I0627 13:55:52.147023  5034 solver.cpp:228] Iteration 2640, loss = 0.451506
I0627 13:55:52.147048  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:55:52.147056  5034 solver.cpp:244]     Train net output #1: loss = 0.451506 (* 1 = 0.451506 loss)
I0627 13:55:52.147061  5034 sgd_solver.cpp:106] Iteration 2640, lr = 0.0001
I0627 13:55:52.925191  5034 solver.cpp:228] Iteration 2660, loss = 0.591057
I0627 13:55:52.925220  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:55:52.925228  5034 solver.cpp:244]     Train net output #1: loss = 0.591057 (* 1 = 0.591057 loss)
I0627 13:55:52.925256  5034 sgd_solver.cpp:106] Iteration 2660, lr = 0.0001
I0627 13:55:53.703037  5034 solver.cpp:228] Iteration 2680, loss = 0.402813
I0627 13:55:53.703063  5034 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0627 13:55:53.703071  5034 solver.cpp:244]     Train net output #1: loss = 0.402813 (* 1 = 0.402813 loss)
I0627 13:55:53.703076  5034 sgd_solver.cpp:106] Iteration 2680, lr = 0.0001
I0627 13:55:54.469992  5034 solver.cpp:337] Iteration 2700, Testing net (#0)
I0627 13:55:56.635745  5034 solver.cpp:404]     Test net output #0: accuracy = 0.684326
I0627 13:55:56.635778  5034 solver.cpp:404]     Test net output #1: loss = 0.615726 (* 1 = 0.615726 loss)
I0627 13:55:56.648206  5034 solver.cpp:228] Iteration 2700, loss = 0.58289
I0627 13:55:56.648232  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:55:56.648239  5034 solver.cpp:244]     Train net output #1: loss = 0.58289 (* 1 = 0.58289 loss)
I0627 13:55:56.648243  5034 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0627 13:55:57.433379  5034 solver.cpp:228] Iteration 2720, loss = 0.604775
I0627 13:55:57.433408  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:55:57.433416  5034 solver.cpp:244]     Train net output #1: loss = 0.604775 (* 1 = 0.604775 loss)
I0627 13:55:57.433420  5034 sgd_solver.cpp:106] Iteration 2720, lr = 0.0001
I0627 13:55:58.211700  5034 solver.cpp:228] Iteration 2740, loss = 0.445386
I0627 13:55:58.211725  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:55:58.211733  5034 solver.cpp:244]     Train net output #1: loss = 0.445386 (* 1 = 0.445386 loss)
I0627 13:55:58.211737  5034 sgd_solver.cpp:106] Iteration 2740, lr = 0.0001
I0627 13:55:59.017877  5034 solver.cpp:228] Iteration 2760, loss = 0.564612
I0627 13:55:59.017904  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:55:59.017910  5034 solver.cpp:244]     Train net output #1: loss = 0.564612 (* 1 = 0.564612 loss)
I0627 13:55:59.017915  5034 sgd_solver.cpp:106] Iteration 2760, lr = 0.0001
I0627 13:55:59.794736  5034 solver.cpp:228] Iteration 2780, loss = 0.536681
I0627 13:55:59.794762  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:55:59.794770  5034 solver.cpp:244]     Train net output #1: loss = 0.536681 (* 1 = 0.536681 loss)
I0627 13:55:59.794775  5034 sgd_solver.cpp:106] Iteration 2780, lr = 0.0001
I0627 13:56:00.562813  5034 solver.cpp:337] Iteration 2800, Testing net (#0)
I0627 13:56:02.723368  5034 solver.cpp:404]     Test net output #0: accuracy = 0.68457
I0627 13:56:02.723402  5034 solver.cpp:404]     Test net output #1: loss = 0.611753 (* 1 = 0.611753 loss)
I0627 13:56:02.735869  5034 solver.cpp:228] Iteration 2800, loss = 0.423174
I0627 13:56:02.735894  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:56:02.735901  5034 solver.cpp:244]     Train net output #1: loss = 0.423174 (* 1 = 0.423174 loss)
I0627 13:56:02.735906  5034 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0627 13:56:03.579994  5034 solver.cpp:228] Iteration 2820, loss = 0.530396
I0627 13:56:03.580024  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:56:03.580031  5034 solver.cpp:244]     Train net output #1: loss = 0.530396 (* 1 = 0.530396 loss)
I0627 13:56:03.580036  5034 sgd_solver.cpp:106] Iteration 2820, lr = 0.0001
I0627 13:56:04.359593  5034 solver.cpp:228] Iteration 2840, loss = 0.481294
I0627 13:56:04.359629  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:56:04.359637  5034 solver.cpp:244]     Train net output #1: loss = 0.481294 (* 1 = 0.481294 loss)
I0627 13:56:04.359642  5034 sgd_solver.cpp:106] Iteration 2840, lr = 0.0001
I0627 13:56:05.137948  5034 solver.cpp:228] Iteration 2860, loss = 0.451475
I0627 13:56:05.137975  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:56:05.137984  5034 solver.cpp:244]     Train net output #1: loss = 0.451475 (* 1 = 0.451475 loss)
I0627 13:56:05.137987  5034 sgd_solver.cpp:106] Iteration 2860, lr = 0.0001
I0627 13:56:05.917807  5034 solver.cpp:228] Iteration 2880, loss = 0.42402
I0627 13:56:05.917855  5034 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0627 13:56:05.917863  5034 solver.cpp:244]     Train net output #1: loss = 0.42402 (* 1 = 0.42402 loss)
I0627 13:56:05.917868  5034 sgd_solver.cpp:106] Iteration 2880, lr = 0.0001
I0627 13:56:06.747488  5034 solver.cpp:337] Iteration 2900, Testing net (#0)
I0627 13:56:08.909662  5034 solver.cpp:404]     Test net output #0: accuracy = 0.675537
I0627 13:56:08.909694  5034 solver.cpp:404]     Test net output #1: loss = 0.625528 (* 1 = 0.625528 loss)
I0627 13:56:08.923079  5034 solver.cpp:228] Iteration 2900, loss = 0.451769
I0627 13:56:08.923107  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:56:08.923115  5034 solver.cpp:244]     Train net output #1: loss = 0.451769 (* 1 = 0.451769 loss)
I0627 13:56:08.923120  5034 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0627 13:56:09.747694  5034 solver.cpp:228] Iteration 2920, loss = 0.396478
I0627 13:56:09.747721  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:56:09.747740  5034 solver.cpp:244]     Train net output #1: loss = 0.396478 (* 1 = 0.396478 loss)
I0627 13:56:09.747745  5034 sgd_solver.cpp:106] Iteration 2920, lr = 0.0001
I0627 13:56:10.542610  5034 solver.cpp:228] Iteration 2940, loss = 0.407686
I0627 13:56:10.542636  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:56:10.542644  5034 solver.cpp:244]     Train net output #1: loss = 0.407686 (* 1 = 0.407686 loss)
I0627 13:56:10.542649  5034 sgd_solver.cpp:106] Iteration 2940, lr = 0.0001
I0627 13:56:11.332805  5034 solver.cpp:228] Iteration 2960, loss = 0.552498
I0627 13:56:11.332836  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:56:11.332844  5034 solver.cpp:244]     Train net output #1: loss = 0.552498 (* 1 = 0.552498 loss)
I0627 13:56:11.332849  5034 sgd_solver.cpp:106] Iteration 2960, lr = 0.0001
I0627 13:56:12.114784  5034 solver.cpp:228] Iteration 2980, loss = 0.512879
I0627 13:56:12.114933  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:56:12.114953  5034 solver.cpp:244]     Train net output #1: loss = 0.512879 (* 1 = 0.512879 loss)
I0627 13:56:12.114962  5034 sgd_solver.cpp:106] Iteration 2980, lr = 0.0001
I0627 13:56:12.885946  5034 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_3000.caffemodel
I0627 13:56:12.895514  5034 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_3000.solverstate
I0627 13:56:12.900312  5034 solver.cpp:337] Iteration 3000, Testing net (#0)
I0627 13:56:15.064728  5034 solver.cpp:404]     Test net output #0: accuracy = 0.682861
I0627 13:56:15.064759  5034 solver.cpp:404]     Test net output #1: loss = 0.615025 (* 1 = 0.615025 loss)
I0627 13:56:15.077199  5034 solver.cpp:228] Iteration 3000, loss = 0.484979
I0627 13:56:15.077224  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:56:15.077232  5034 solver.cpp:244]     Train net output #1: loss = 0.484979 (* 1 = 0.484979 loss)
I0627 13:56:15.077237  5034 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0627 13:56:15.862922  5034 solver.cpp:228] Iteration 3020, loss = 0.523688
I0627 13:56:15.862946  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:56:15.862953  5034 solver.cpp:244]     Train net output #1: loss = 0.523688 (* 1 = 0.523688 loss)
I0627 13:56:15.862958  5034 sgd_solver.cpp:106] Iteration 3020, lr = 0.0001
I0627 13:56:16.653496  5034 solver.cpp:228] Iteration 3040, loss = 0.483913
I0627 13:56:16.653523  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:56:16.653532  5034 solver.cpp:244]     Train net output #1: loss = 0.483913 (* 1 = 0.483913 loss)
I0627 13:56:16.653535  5034 sgd_solver.cpp:106] Iteration 3040, lr = 0.0001
I0627 13:56:17.437778  5034 solver.cpp:228] Iteration 3060, loss = 0.547873
I0627 13:56:17.437815  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:56:17.437824  5034 solver.cpp:244]     Train net output #1: loss = 0.547873 (* 1 = 0.547873 loss)
I0627 13:56:17.437827  5034 sgd_solver.cpp:106] Iteration 3060, lr = 0.0001
I0627 13:56:18.285833  5034 solver.cpp:228] Iteration 3080, loss = 0.371984
I0627 13:56:18.285859  5034 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0627 13:56:18.285867  5034 solver.cpp:244]     Train net output #1: loss = 0.371984 (* 1 = 0.371984 loss)
I0627 13:56:18.285871  5034 sgd_solver.cpp:106] Iteration 3080, lr = 0.0001
I0627 13:56:19.065630  5034 solver.cpp:337] Iteration 3100, Testing net (#0)
I0627 13:56:19.347196  5034 blocking_queue.cpp:50] Data layer prefetch queue empty
I0627 13:56:21.229601  5034 solver.cpp:404]     Test net output #0: accuracy = 0.694092
I0627 13:56:21.229640  5034 solver.cpp:404]     Test net output #1: loss = 0.604885 (* 1 = 0.604885 loss)
I0627 13:56:21.242029  5034 solver.cpp:228] Iteration 3100, loss = 0.361106
I0627 13:56:21.242058  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:56:21.242064  5034 solver.cpp:244]     Train net output #1: loss = 0.361106 (* 1 = 0.361106 loss)
I0627 13:56:21.242070  5034 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0627 13:56:22.036315  5034 solver.cpp:228] Iteration 3120, loss = 0.455925
I0627 13:56:22.036352  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:56:22.036360  5034 solver.cpp:244]     Train net output #1: loss = 0.455925 (* 1 = 0.455925 loss)
I0627 13:56:22.036365  5034 sgd_solver.cpp:106] Iteration 3120, lr = 0.0001
I0627 13:56:22.819075  5034 solver.cpp:228] Iteration 3140, loss = 0.462847
I0627 13:56:22.819103  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:56:22.819110  5034 solver.cpp:244]     Train net output #1: loss = 0.462847 (* 1 = 0.462847 loss)
I0627 13:56:22.819115  5034 sgd_solver.cpp:106] Iteration 3140, lr = 0.0001
I0627 13:56:23.602200  5034 solver.cpp:228] Iteration 3160, loss = 0.516361
I0627 13:56:23.602239  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:56:23.602246  5034 solver.cpp:244]     Train net output #1: loss = 0.516361 (* 1 = 0.516361 loss)
I0627 13:56:23.602272  5034 sgd_solver.cpp:106] Iteration 3160, lr = 0.0001
I0627 13:56:24.384434  5034 solver.cpp:228] Iteration 3180, loss = 0.463446
I0627 13:56:24.384471  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:56:24.384479  5034 solver.cpp:244]     Train net output #1: loss = 0.463446 (* 1 = 0.463446 loss)
I0627 13:56:24.384482  5034 sgd_solver.cpp:106] Iteration 3180, lr = 0.0001
I0627 13:56:25.155199  5034 solver.cpp:337] Iteration 3200, Testing net (#0)
I0627 13:56:27.313544  5034 solver.cpp:404]     Test net output #0: accuracy = 0.669922
I0627 13:56:27.313580  5034 solver.cpp:404]     Test net output #1: loss = 0.629478 (* 1 = 0.629478 loss)
I0627 13:56:27.326043  5034 solver.cpp:228] Iteration 3200, loss = 0.462021
I0627 13:56:27.326067  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:56:27.326074  5034 solver.cpp:244]     Train net output #1: loss = 0.462021 (* 1 = 0.462021 loss)
I0627 13:56:27.326079  5034 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0627 13:56:28.174098  5034 solver.cpp:228] Iteration 3220, loss = 0.40941
I0627 13:56:28.174127  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:56:28.174135  5034 solver.cpp:244]     Train net output #1: loss = 0.40941 (* 1 = 0.40941 loss)
I0627 13:56:28.174139  5034 sgd_solver.cpp:106] Iteration 3220, lr = 0.0001
I0627 13:56:28.971482  5034 solver.cpp:228] Iteration 3240, loss = 0.341088
I0627 13:56:28.971508  5034 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0627 13:56:28.971525  5034 solver.cpp:244]     Train net output #1: loss = 0.341088 (* 1 = 0.341088 loss)
I0627 13:56:28.971530  5034 sgd_solver.cpp:106] Iteration 3240, lr = 0.0001
I0627 13:56:29.778286  5034 solver.cpp:228] Iteration 3260, loss = 0.469589
I0627 13:56:29.778311  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:56:29.778319  5034 solver.cpp:244]     Train net output #1: loss = 0.469589 (* 1 = 0.469589 loss)
I0627 13:56:29.778323  5034 sgd_solver.cpp:106] Iteration 3260, lr = 0.0001
I0627 13:56:30.601444  5034 solver.cpp:228] Iteration 3280, loss = 0.509352
I0627 13:56:30.601470  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:56:30.601488  5034 solver.cpp:244]     Train net output #1: loss = 0.509352 (* 1 = 0.509352 loss)
I0627 13:56:30.601492  5034 sgd_solver.cpp:106] Iteration 3280, lr = 0.0001
I0627 13:56:31.416200  5034 solver.cpp:337] Iteration 3300, Testing net (#0)
I0627 13:56:33.583757  5034 solver.cpp:404]     Test net output #0: accuracy = 0.679443
I0627 13:56:33.583791  5034 solver.cpp:404]     Test net output #1: loss = 0.622579 (* 1 = 0.622579 loss)
I0627 13:56:33.596292  5034 solver.cpp:228] Iteration 3300, loss = 0.435485
I0627 13:56:33.596318  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:56:33.596325  5034 solver.cpp:244]     Train net output #1: loss = 0.435485 (* 1 = 0.435485 loss)
I0627 13:56:33.596330  5034 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0627 13:56:34.397137  5034 solver.cpp:228] Iteration 3320, loss = 0.481462
I0627 13:56:34.397173  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:56:34.397181  5034 solver.cpp:244]     Train net output #1: loss = 0.481462 (* 1 = 0.481462 loss)
I0627 13:56:34.397186  5034 sgd_solver.cpp:106] Iteration 3320, lr = 0.0001
I0627 13:56:35.225538  5034 solver.cpp:228] Iteration 3340, loss = 0.413007
I0627 13:56:35.225571  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:56:35.225581  5034 solver.cpp:244]     Train net output #1: loss = 0.413007 (* 1 = 0.413007 loss)
I0627 13:56:35.225589  5034 sgd_solver.cpp:106] Iteration 3340, lr = 0.0001
I0627 13:56:36.020987  5034 solver.cpp:228] Iteration 3360, loss = 0.462017
I0627 13:56:36.021013  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:56:36.021021  5034 solver.cpp:244]     Train net output #1: loss = 0.462017 (* 1 = 0.462017 loss)
I0627 13:56:36.021025  5034 sgd_solver.cpp:106] Iteration 3360, lr = 0.0001
I0627 13:56:36.809900  5034 solver.cpp:228] Iteration 3380, loss = 0.476922
I0627 13:56:36.809937  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:56:36.809945  5034 solver.cpp:244]     Train net output #1: loss = 0.476922 (* 1 = 0.476922 loss)
I0627 13:56:36.809949  5034 sgd_solver.cpp:106] Iteration 3380, lr = 0.0001
I0627 13:56:37.583319  5034 solver.cpp:337] Iteration 3400, Testing net (#0)
I0627 13:56:39.745138  5034 solver.cpp:404]     Test net output #0: accuracy = 0.698242
I0627 13:56:39.745173  5034 solver.cpp:404]     Test net output #1: loss = 0.599179 (* 1 = 0.599179 loss)
I0627 13:56:39.757587  5034 solver.cpp:228] Iteration 3400, loss = 0.399433
I0627 13:56:39.757616  5034 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0627 13:56:39.757622  5034 solver.cpp:244]     Train net output #1: loss = 0.399433 (* 1 = 0.399433 loss)
I0627 13:56:39.757627  5034 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0627 13:56:40.545375  5034 solver.cpp:228] Iteration 3420, loss = 0.541945
I0627 13:56:40.545402  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:56:40.545409  5034 solver.cpp:244]     Train net output #1: loss = 0.541945 (* 1 = 0.541945 loss)
I0627 13:56:40.545414  5034 sgd_solver.cpp:106] Iteration 3420, lr = 0.0001
I0627 13:56:41.327673  5034 solver.cpp:228] Iteration 3440, loss = 0.490888
I0627 13:56:41.327698  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:56:41.327705  5034 solver.cpp:244]     Train net output #1: loss = 0.490888 (* 1 = 0.490888 loss)
I0627 13:56:41.327709  5034 sgd_solver.cpp:106] Iteration 3440, lr = 0.0001
I0627 13:56:42.111644  5034 solver.cpp:228] Iteration 3460, loss = 0.52309
I0627 13:56:42.111672  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:56:42.111680  5034 solver.cpp:244]     Train net output #1: loss = 0.52309 (* 1 = 0.52309 loss)
I0627 13:56:42.111683  5034 sgd_solver.cpp:106] Iteration 3460, lr = 0.0001
I0627 13:56:42.910665  5034 solver.cpp:228] Iteration 3480, loss = 0.471465
I0627 13:56:42.910845  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:56:42.910859  5034 solver.cpp:244]     Train net output #1: loss = 0.471465 (* 1 = 0.471465 loss)
I0627 13:56:42.910866  5034 sgd_solver.cpp:106] Iteration 3480, lr = 0.0001
I0627 13:56:43.707053  5034 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_3500.caffemodel
I0627 13:56:43.716711  5034 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_3500.solverstate
I0627 13:56:43.721603  5034 solver.cpp:337] Iteration 3500, Testing net (#0)
I0627 13:56:45.893704  5034 solver.cpp:404]     Test net output #0: accuracy = 0.668457
I0627 13:56:45.893739  5034 solver.cpp:404]     Test net output #1: loss = 0.635129 (* 1 = 0.635129 loss)
I0627 13:56:45.907300  5034 solver.cpp:228] Iteration 3500, loss = 0.400627
I0627 13:56:45.907325  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:56:45.907332  5034 solver.cpp:244]     Train net output #1: loss = 0.400627 (* 1 = 0.400627 loss)
I0627 13:56:45.907337  5034 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0627 13:56:46.843685  5034 solver.cpp:228] Iteration 3520, loss = 0.463541
I0627 13:56:46.843711  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:56:46.843719  5034 solver.cpp:244]     Train net output #1: loss = 0.463541 (* 1 = 0.463541 loss)
I0627 13:56:46.843724  5034 sgd_solver.cpp:106] Iteration 3520, lr = 0.0001
I0627 13:56:47.626775  5034 solver.cpp:228] Iteration 3540, loss = 0.431731
I0627 13:56:47.626801  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:56:47.626808  5034 solver.cpp:244]     Train net output #1: loss = 0.431731 (* 1 = 0.431731 loss)
I0627 13:56:47.626812  5034 sgd_solver.cpp:106] Iteration 3540, lr = 0.0001
I0627 13:56:48.409379  5034 solver.cpp:228] Iteration 3560, loss = 0.34154
I0627 13:56:48.409404  5034 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0627 13:56:48.409422  5034 solver.cpp:244]     Train net output #1: loss = 0.34154 (* 1 = 0.34154 loss)
I0627 13:56:48.409427  5034 sgd_solver.cpp:106] Iteration 3560, lr = 0.0001
I0627 13:56:49.192225  5034 solver.cpp:228] Iteration 3580, loss = 0.450741
I0627 13:56:49.192261  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:56:49.192268  5034 solver.cpp:244]     Train net output #1: loss = 0.450741 (* 1 = 0.450741 loss)
I0627 13:56:49.192273  5034 sgd_solver.cpp:106] Iteration 3580, lr = 0.0001
I0627 13:56:49.962198  5034 solver.cpp:337] Iteration 3600, Testing net (#0)
I0627 13:56:52.080965  5034 solver.cpp:404]     Test net output #0: accuracy = 0.685303
I0627 13:56:52.080999  5034 solver.cpp:404]     Test net output #1: loss = 0.616526 (* 1 = 0.616526 loss)
I0627 13:56:52.094538  5034 solver.cpp:228] Iteration 3600, loss = 0.430123
I0627 13:56:52.094565  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:56:52.094573  5034 solver.cpp:244]     Train net output #1: loss = 0.430123 (* 1 = 0.430123 loss)
I0627 13:56:52.094578  5034 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0627 13:56:52.946481  5034 solver.cpp:228] Iteration 3620, loss = 0.581818
I0627 13:56:52.946507  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:56:52.946514  5034 solver.cpp:244]     Train net output #1: loss = 0.581818 (* 1 = 0.581818 loss)
I0627 13:56:52.946519  5034 sgd_solver.cpp:106] Iteration 3620, lr = 0.0001
I0627 13:56:53.797080  5034 solver.cpp:228] Iteration 3640, loss = 0.534314
I0627 13:56:53.797106  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:56:53.797113  5034 solver.cpp:244]     Train net output #1: loss = 0.534314 (* 1 = 0.534314 loss)
I0627 13:56:53.797118  5034 sgd_solver.cpp:106] Iteration 3640, lr = 0.0001
I0627 13:56:54.649020  5034 solver.cpp:228] Iteration 3660, loss = 0.514779
I0627 13:56:54.649049  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:56:54.649056  5034 solver.cpp:244]     Train net output #1: loss = 0.514779 (* 1 = 0.514779 loss)
I0627 13:56:54.649085  5034 sgd_solver.cpp:106] Iteration 3660, lr = 0.0001
I0627 13:56:55.459384  5034 solver.cpp:228] Iteration 3680, loss = 0.470304
I0627 13:56:55.459411  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:56:55.459421  5034 solver.cpp:244]     Train net output #1: loss = 0.470304 (* 1 = 0.470304 loss)
I0627 13:56:55.459426  5034 sgd_solver.cpp:106] Iteration 3680, lr = 0.0001
I0627 13:56:56.229205  5034 solver.cpp:337] Iteration 3700, Testing net (#0)
I0627 13:56:58.316961  5034 solver.cpp:404]     Test net output #0: accuracy = 0.689941
I0627 13:56:58.317000  5034 solver.cpp:404]     Test net output #1: loss = 0.608605 (* 1 = 0.608605 loss)
I0627 13:56:58.330183  5034 solver.cpp:228] Iteration 3700, loss = 0.444796
I0627 13:56:58.330210  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:56:58.330219  5034 solver.cpp:244]     Train net output #1: loss = 0.444796 (* 1 = 0.444796 loss)
I0627 13:56:58.330225  5034 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0627 13:56:59.179664  5034 solver.cpp:228] Iteration 3720, loss = 0.562212
I0627 13:56:59.179697  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:56:59.179705  5034 solver.cpp:244]     Train net output #1: loss = 0.562212 (* 1 = 0.562212 loss)
I0627 13:56:59.179709  5034 sgd_solver.cpp:106] Iteration 3720, lr = 0.0001
I0627 13:57:00.031847  5034 solver.cpp:228] Iteration 3740, loss = 0.483368
I0627 13:57:00.031874  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:57:00.031882  5034 solver.cpp:244]     Train net output #1: loss = 0.483368 (* 1 = 0.483368 loss)
I0627 13:57:00.031886  5034 sgd_solver.cpp:106] Iteration 3740, lr = 0.0001
I0627 13:57:00.860339  5034 solver.cpp:228] Iteration 3760, loss = 0.491576
I0627 13:57:00.860364  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:57:00.860383  5034 solver.cpp:244]     Train net output #1: loss = 0.491576 (* 1 = 0.491576 loss)
I0627 13:57:00.860388  5034 sgd_solver.cpp:106] Iteration 3760, lr = 0.0001
I0627 13:57:01.643551  5034 solver.cpp:228] Iteration 3780, loss = 0.523576
I0627 13:57:01.643576  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:57:01.643594  5034 solver.cpp:244]     Train net output #1: loss = 0.523576 (* 1 = 0.523576 loss)
I0627 13:57:01.643599  5034 sgd_solver.cpp:106] Iteration 3780, lr = 0.0001
I0627 13:57:02.415081  5034 solver.cpp:337] Iteration 3800, Testing net (#0)
I0627 13:57:04.503974  5034 solver.cpp:404]     Test net output #0: accuracy = 0.668701
I0627 13:57:04.504005  5034 solver.cpp:404]     Test net output #1: loss = 0.634201 (* 1 = 0.634201 loss)
I0627 13:57:04.516156  5034 solver.cpp:228] Iteration 3800, loss = 0.417773
I0627 13:57:04.516187  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:57:04.516196  5034 solver.cpp:244]     Train net output #1: loss = 0.417773 (* 1 = 0.417773 loss)
I0627 13:57:04.516201  5034 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0627 13:57:05.352166  5034 solver.cpp:228] Iteration 3820, loss = 0.494278
I0627 13:57:05.352191  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:57:05.352210  5034 solver.cpp:244]     Train net output #1: loss = 0.494278 (* 1 = 0.494278 loss)
I0627 13:57:05.352213  5034 sgd_solver.cpp:106] Iteration 3820, lr = 0.0001
I0627 13:57:06.152142  5034 solver.cpp:228] Iteration 3840, loss = 0.356072
I0627 13:57:06.152168  5034 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0627 13:57:06.152174  5034 solver.cpp:244]     Train net output #1: loss = 0.356072 (* 1 = 0.356072 loss)
I0627 13:57:06.152179  5034 sgd_solver.cpp:106] Iteration 3840, lr = 0.0001
I0627 13:57:07.005183  5034 solver.cpp:228] Iteration 3860, loss = 0.292505
I0627 13:57:07.005208  5034 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0627 13:57:07.005214  5034 solver.cpp:244]     Train net output #1: loss = 0.292505 (* 1 = 0.292505 loss)
I0627 13:57:07.005219  5034 sgd_solver.cpp:106] Iteration 3860, lr = 0.0001
I0627 13:57:07.852355  5034 solver.cpp:228] Iteration 3880, loss = 0.5296
I0627 13:57:07.852406  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:57:07.852414  5034 solver.cpp:244]     Train net output #1: loss = 0.5296 (* 1 = 0.5296 loss)
I0627 13:57:07.852419  5034 sgd_solver.cpp:106] Iteration 3880, lr = 0.0001
I0627 13:57:08.671618  5034 solver.cpp:337] Iteration 3900, Testing net (#0)
I0627 13:57:10.758030  5034 solver.cpp:404]     Test net output #0: accuracy = 0.680908
I0627 13:57:10.758069  5034 solver.cpp:404]     Test net output #1: loss = 0.623986 (* 1 = 0.623986 loss)
I0627 13:57:10.771625  5034 solver.cpp:228] Iteration 3900, loss = 0.354845
I0627 13:57:10.771649  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:57:10.771656  5034 solver.cpp:244]     Train net output #1: loss = 0.354845 (* 1 = 0.354845 loss)
I0627 13:57:10.771661  5034 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0627 13:57:11.595614  5034 solver.cpp:228] Iteration 3920, loss = 0.482583
I0627 13:57:11.595640  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:57:11.595648  5034 solver.cpp:244]     Train net output #1: loss = 0.482583 (* 1 = 0.482583 loss)
I0627 13:57:11.595651  5034 sgd_solver.cpp:106] Iteration 3920, lr = 0.0001
I0627 13:57:12.441015  5034 solver.cpp:228] Iteration 3940, loss = 0.52498
I0627 13:57:12.441042  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:57:12.441050  5034 solver.cpp:244]     Train net output #1: loss = 0.52498 (* 1 = 0.52498 loss)
I0627 13:57:12.441054  5034 sgd_solver.cpp:106] Iteration 3940, lr = 0.0001
I0627 13:57:13.258019  5034 solver.cpp:228] Iteration 3960, loss = 0.413352
I0627 13:57:13.258218  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:57:13.258226  5034 solver.cpp:244]     Train net output #1: loss = 0.413352 (* 1 = 0.413352 loss)
I0627 13:57:13.258230  5034 sgd_solver.cpp:106] Iteration 3960, lr = 0.0001
I0627 13:57:14.045802  5034 solver.cpp:228] Iteration 3980, loss = 0.362758
I0627 13:57:14.045838  5034 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0627 13:57:14.045846  5034 solver.cpp:244]     Train net output #1: loss = 0.362758 (* 1 = 0.362758 loss)
I0627 13:57:14.045850  5034 sgd_solver.cpp:106] Iteration 3980, lr = 0.0001
I0627 13:57:14.869099  5034 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_4000.caffemodel
I0627 13:57:14.878824  5034 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_4000.solverstate
I0627 13:57:14.883679  5034 solver.cpp:337] Iteration 4000, Testing net (#0)
I0627 13:57:16.985146  5034 solver.cpp:404]     Test net output #0: accuracy = 0.689209
I0627 13:57:16.985183  5034 solver.cpp:404]     Test net output #1: loss = 0.612726 (* 1 = 0.612726 loss)
I0627 13:57:16.997854  5034 solver.cpp:228] Iteration 4000, loss = 0.404026
I0627 13:57:16.997880  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:57:16.997887  5034 solver.cpp:244]     Train net output #1: loss = 0.404026 (* 1 = 0.404026 loss)
I0627 13:57:16.997892  5034 sgd_solver.cpp:106] Iteration 4000, lr = 1e-05
I0627 13:57:17.790592  5034 solver.cpp:228] Iteration 4020, loss = 0.479086
I0627 13:57:17.790628  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:57:17.790647  5034 solver.cpp:244]     Train net output #1: loss = 0.479086 (* 1 = 0.479086 loss)
I0627 13:57:17.790652  5034 sgd_solver.cpp:106] Iteration 4020, lr = 1e-05
I0627 13:57:18.578711  5034 solver.cpp:228] Iteration 4040, loss = 0.476489
I0627 13:57:18.578735  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:57:18.578753  5034 solver.cpp:244]     Train net output #1: loss = 0.476489 (* 1 = 0.476489 loss)
I0627 13:57:18.578758  5034 sgd_solver.cpp:106] Iteration 4040, lr = 1e-05
I0627 13:57:19.370055  5034 solver.cpp:228] Iteration 4060, loss = 0.553692
I0627 13:57:19.370080  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:57:19.370087  5034 solver.cpp:244]     Train net output #1: loss = 0.553692 (* 1 = 0.553692 loss)
I0627 13:57:19.370091  5034 sgd_solver.cpp:106] Iteration 4060, lr = 1e-05
I0627 13:57:20.187185  5034 solver.cpp:228] Iteration 4080, loss = 0.528271
I0627 13:57:20.187211  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:57:20.187229  5034 solver.cpp:244]     Train net output #1: loss = 0.528271 (* 1 = 0.528271 loss)
I0627 13:57:20.187234  5034 sgd_solver.cpp:106] Iteration 4080, lr = 1e-05
I0627 13:57:20.966862  5034 solver.cpp:337] Iteration 4100, Testing net (#0)
I0627 13:57:23.072106  5034 solver.cpp:404]     Test net output #0: accuracy = 0.675537
I0627 13:57:23.072141  5034 solver.cpp:404]     Test net output #1: loss = 0.629268 (* 1 = 0.629268 loss)
I0627 13:57:23.084319  5034 solver.cpp:228] Iteration 4100, loss = 0.488406
I0627 13:57:23.084347  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:57:23.084354  5034 solver.cpp:244]     Train net output #1: loss = 0.488406 (* 1 = 0.488406 loss)
I0627 13:57:23.084359  5034 sgd_solver.cpp:106] Iteration 4100, lr = 1e-05
I0627 13:57:23.889117  5034 solver.cpp:228] Iteration 4120, loss = 0.466529
I0627 13:57:23.889142  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:57:23.889160  5034 solver.cpp:244]     Train net output #1: loss = 0.466529 (* 1 = 0.466529 loss)
I0627 13:57:23.889164  5034 sgd_solver.cpp:106] Iteration 4120, lr = 1e-05
I0627 13:57:24.688230  5034 solver.cpp:228] Iteration 4140, loss = 0.418196
I0627 13:57:24.688253  5034 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0627 13:57:24.688272  5034 solver.cpp:244]     Train net output #1: loss = 0.418196 (* 1 = 0.418196 loss)
I0627 13:57:24.688277  5034 sgd_solver.cpp:106] Iteration 4140, lr = 1e-05
I0627 13:57:25.484674  5034 solver.cpp:228] Iteration 4160, loss = 0.394868
I0627 13:57:25.484701  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:57:25.484709  5034 solver.cpp:244]     Train net output #1: loss = 0.394868 (* 1 = 0.394868 loss)
I0627 13:57:25.484714  5034 sgd_solver.cpp:106] Iteration 4160, lr = 1e-05
I0627 13:57:26.273643  5034 solver.cpp:228] Iteration 4180, loss = 0.375763
I0627 13:57:26.273682  5034 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0627 13:57:26.273690  5034 solver.cpp:244]     Train net output #1: loss = 0.375763 (* 1 = 0.375763 loss)
I0627 13:57:26.273694  5034 sgd_solver.cpp:106] Iteration 4180, lr = 1e-05
I0627 13:57:27.060982  5034 solver.cpp:337] Iteration 4200, Testing net (#0)
I0627 13:57:29.169222  5034 solver.cpp:404]     Test net output #0: accuracy = 0.680664
I0627 13:57:29.169257  5034 solver.cpp:404]     Test net output #1: loss = 0.620212 (* 1 = 0.620212 loss)
I0627 13:57:29.181412  5034 solver.cpp:228] Iteration 4200, loss = 0.441472
I0627 13:57:29.181440  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:57:29.181448  5034 solver.cpp:244]     Train net output #1: loss = 0.441472 (* 1 = 0.441472 loss)
I0627 13:57:29.181454  5034 sgd_solver.cpp:106] Iteration 4200, lr = 1e-05
I0627 13:57:29.974364  5034 solver.cpp:228] Iteration 4220, loss = 0.50578
I0627 13:57:29.974390  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:57:29.974396  5034 solver.cpp:244]     Train net output #1: loss = 0.50578 (* 1 = 0.50578 loss)
I0627 13:57:29.974401  5034 sgd_solver.cpp:106] Iteration 4220, lr = 1e-05
I0627 13:57:30.761843  5034 solver.cpp:228] Iteration 4240, loss = 0.46772
I0627 13:57:30.761868  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:57:30.761875  5034 solver.cpp:244]     Train net output #1: loss = 0.46772 (* 1 = 0.46772 loss)
I0627 13:57:30.761880  5034 sgd_solver.cpp:106] Iteration 4240, lr = 1e-05
I0627 13:57:31.553961  5034 solver.cpp:228] Iteration 4260, loss = 0.494638
I0627 13:57:31.554000  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:57:31.554008  5034 solver.cpp:244]     Train net output #1: loss = 0.494638 (* 1 = 0.494638 loss)
I0627 13:57:31.554013  5034 sgd_solver.cpp:106] Iteration 4260, lr = 1e-05
I0627 13:57:32.342779  5034 solver.cpp:228] Iteration 4280, loss = 0.449527
I0627 13:57:32.342805  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:57:32.342824  5034 solver.cpp:244]     Train net output #1: loss = 0.449527 (* 1 = 0.449527 loss)
I0627 13:57:32.342828  5034 sgd_solver.cpp:106] Iteration 4280, lr = 1e-05
I0627 13:57:33.119724  5034 solver.cpp:337] Iteration 4300, Testing net (#0)
I0627 13:57:35.289016  5034 solver.cpp:404]     Test net output #0: accuracy = 0.679443
I0627 13:57:35.289046  5034 solver.cpp:404]     Test net output #1: loss = 0.620371 (* 1 = 0.620371 loss)
I0627 13:57:35.301511  5034 solver.cpp:228] Iteration 4300, loss = 0.420128
I0627 13:57:35.301539  5034 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0627 13:57:35.301548  5034 solver.cpp:244]     Train net output #1: loss = 0.420128 (* 1 = 0.420128 loss)
I0627 13:57:35.301553  5034 sgd_solver.cpp:106] Iteration 4300, lr = 1e-05
I0627 13:57:36.150624  5034 solver.cpp:228] Iteration 4320, loss = 0.485353
I0627 13:57:36.150648  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:57:36.150655  5034 solver.cpp:244]     Train net output #1: loss = 0.485353 (* 1 = 0.485353 loss)
I0627 13:57:36.150660  5034 sgd_solver.cpp:106] Iteration 4320, lr = 1e-05
I0627 13:57:36.939888  5034 solver.cpp:228] Iteration 4340, loss = 0.431355
I0627 13:57:36.939925  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:57:36.939932  5034 solver.cpp:244]     Train net output #1: loss = 0.431355 (* 1 = 0.431355 loss)
I0627 13:57:36.939936  5034 sgd_solver.cpp:106] Iteration 4340, lr = 1e-05
I0627 13:57:37.728775  5034 solver.cpp:228] Iteration 4360, loss = 0.473096
I0627 13:57:37.728829  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:57:37.728838  5034 solver.cpp:244]     Train net output #1: loss = 0.473096 (* 1 = 0.473096 loss)
I0627 13:57:37.728843  5034 sgd_solver.cpp:106] Iteration 4360, lr = 1e-05
I0627 13:57:38.518654  5034 solver.cpp:228] Iteration 4380, loss = 0.528936
I0627 13:57:38.518693  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:57:38.518700  5034 solver.cpp:244]     Train net output #1: loss = 0.528936 (* 1 = 0.528936 loss)
I0627 13:57:38.518705  5034 sgd_solver.cpp:106] Iteration 4380, lr = 1e-05
I0627 13:57:39.296002  5034 solver.cpp:337] Iteration 4400, Testing net (#0)
I0627 13:57:41.466464  5034 solver.cpp:404]     Test net output #0: accuracy = 0.677979
I0627 13:57:41.466495  5034 solver.cpp:404]     Test net output #1: loss = 0.624075 (* 1 = 0.624075 loss)
I0627 13:57:41.479014  5034 solver.cpp:228] Iteration 4400, loss = 0.527418
I0627 13:57:41.479041  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:57:41.479049  5034 solver.cpp:244]     Train net output #1: loss = 0.527418 (* 1 = 0.527418 loss)
I0627 13:57:41.479054  5034 sgd_solver.cpp:106] Iteration 4400, lr = 1e-05
I0627 13:57:42.267102  5034 solver.cpp:228] Iteration 4420, loss = 0.503968
I0627 13:57:42.267128  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:57:42.267135  5034 solver.cpp:244]     Train net output #1: loss = 0.503968 (* 1 = 0.503968 loss)
I0627 13:57:42.267140  5034 sgd_solver.cpp:106] Iteration 4420, lr = 1e-05
I0627 13:57:43.055501  5034 solver.cpp:228] Iteration 4440, loss = 0.65087
I0627 13:57:43.055538  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:57:43.055546  5034 solver.cpp:244]     Train net output #1: loss = 0.65087 (* 1 = 0.65087 loss)
I0627 13:57:43.055551  5034 sgd_solver.cpp:106] Iteration 4440, lr = 1e-05
I0627 13:57:43.844846  5034 solver.cpp:228] Iteration 4460, loss = 0.406545
I0627 13:57:43.845003  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:57:43.845015  5034 solver.cpp:244]     Train net output #1: loss = 0.406545 (* 1 = 0.406545 loss)
I0627 13:57:43.845019  5034 sgd_solver.cpp:106] Iteration 4460, lr = 1e-05
I0627 13:57:44.637774  5034 solver.cpp:228] Iteration 4480, loss = 0.372612
I0627 13:57:44.637811  5034 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0627 13:57:44.637820  5034 solver.cpp:244]     Train net output #1: loss = 0.372612 (* 1 = 0.372612 loss)
I0627 13:57:44.637825  5034 sgd_solver.cpp:106] Iteration 4480, lr = 1e-05
I0627 13:57:45.414055  5034 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_4500.caffemodel
I0627 13:57:45.423607  5034 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_4500.solverstate
I0627 13:57:45.428407  5034 solver.cpp:337] Iteration 4500, Testing net (#0)
I0627 13:57:47.572948  5034 solver.cpp:404]     Test net output #0: accuracy = 0.682373
I0627 13:57:47.572984  5034 solver.cpp:404]     Test net output #1: loss = 0.618946 (* 1 = 0.618946 loss)
I0627 13:57:47.586010  5034 solver.cpp:228] Iteration 4500, loss = 0.475943
I0627 13:57:47.586035  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:57:47.586043  5034 solver.cpp:244]     Train net output #1: loss = 0.475943 (* 1 = 0.475943 loss)
I0627 13:57:47.586047  5034 sgd_solver.cpp:106] Iteration 4500, lr = 1e-05
I0627 13:57:48.378619  5034 solver.cpp:228] Iteration 4520, loss = 0.469988
I0627 13:57:48.378646  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:57:48.378654  5034 solver.cpp:244]     Train net output #1: loss = 0.469988 (* 1 = 0.469988 loss)
I0627 13:57:48.378659  5034 sgd_solver.cpp:106] Iteration 4520, lr = 1e-05
I0627 13:57:49.166640  5034 solver.cpp:228] Iteration 4540, loss = 0.511004
I0627 13:57:49.166678  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:57:49.166685  5034 solver.cpp:244]     Train net output #1: loss = 0.511004 (* 1 = 0.511004 loss)
I0627 13:57:49.166689  5034 sgd_solver.cpp:106] Iteration 4540, lr = 1e-05
I0627 13:57:49.954351  5034 solver.cpp:228] Iteration 4560, loss = 0.551101
I0627 13:57:49.954377  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:57:49.954385  5034 solver.cpp:244]     Train net output #1: loss = 0.551101 (* 1 = 0.551101 loss)
I0627 13:57:49.954388  5034 sgd_solver.cpp:106] Iteration 4560, lr = 1e-05
I0627 13:57:50.745920  5034 solver.cpp:228] Iteration 4580, loss = 0.37902
I0627 13:57:50.745959  5034 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0627 13:57:50.745966  5034 solver.cpp:244]     Train net output #1: loss = 0.37902 (* 1 = 0.37902 loss)
I0627 13:57:50.745970  5034 sgd_solver.cpp:106] Iteration 4580, lr = 1e-05
I0627 13:57:51.522776  5034 solver.cpp:337] Iteration 4600, Testing net (#0)
I0627 13:57:53.690740  5034 solver.cpp:404]     Test net output #0: accuracy = 0.678711
I0627 13:57:53.690771  5034 solver.cpp:404]     Test net output #1: loss = 0.62198 (* 1 = 0.62198 loss)
I0627 13:57:53.703501  5034 solver.cpp:228] Iteration 4600, loss = 0.391755
I0627 13:57:53.703528  5034 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0627 13:57:53.703536  5034 solver.cpp:244]     Train net output #1: loss = 0.391755 (* 1 = 0.391755 loss)
I0627 13:57:53.703541  5034 sgd_solver.cpp:106] Iteration 4600, lr = 1e-05
I0627 13:57:54.563427  5034 solver.cpp:228] Iteration 4620, loss = 0.475104
I0627 13:57:54.563455  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:57:54.563464  5034 solver.cpp:244]     Train net output #1: loss = 0.475104 (* 1 = 0.475104 loss)
I0627 13:57:54.563469  5034 sgd_solver.cpp:106] Iteration 4620, lr = 1e-05
I0627 13:57:55.353080  5034 solver.cpp:228] Iteration 4640, loss = 0.42808
I0627 13:57:55.353104  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:57:55.353122  5034 solver.cpp:244]     Train net output #1: loss = 0.42808 (* 1 = 0.42808 loss)
I0627 13:57:55.353127  5034 sgd_solver.cpp:106] Iteration 4640, lr = 1e-05
I0627 13:57:56.155983  5034 solver.cpp:228] Iteration 4660, loss = 0.374674
I0627 13:57:56.156010  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:57:56.156028  5034 solver.cpp:244]     Train net output #1: loss = 0.374674 (* 1 = 0.374674 loss)
I0627 13:57:56.156033  5034 sgd_solver.cpp:106] Iteration 4660, lr = 1e-05
I0627 13:57:56.945595  5034 solver.cpp:228] Iteration 4680, loss = 0.503793
I0627 13:57:56.945622  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:57:56.945629  5034 solver.cpp:244]     Train net output #1: loss = 0.503793 (* 1 = 0.503793 loss)
I0627 13:57:56.945634  5034 sgd_solver.cpp:106] Iteration 4680, lr = 1e-05
I0627 13:57:57.722641  5034 solver.cpp:337] Iteration 4700, Testing net (#0)
I0627 13:57:57.882812  5034 blocking_queue.cpp:50] Data layer prefetch queue empty
I0627 13:57:59.879272  5034 solver.cpp:404]     Test net output #0: accuracy = 0.677734
I0627 13:57:59.879302  5034 solver.cpp:404]     Test net output #1: loss = 0.625853 (* 1 = 0.625853 loss)
I0627 13:57:59.891736  5034 solver.cpp:228] Iteration 4700, loss = 0.501974
I0627 13:57:59.891764  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:57:59.891772  5034 solver.cpp:244]     Train net output #1: loss = 0.501974 (* 1 = 0.501974 loss)
I0627 13:57:59.891777  5034 sgd_solver.cpp:106] Iteration 4700, lr = 1e-05
I0627 13:58:00.680735  5034 solver.cpp:228] Iteration 4720, loss = 0.481706
I0627 13:58:00.680760  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:58:00.680768  5034 solver.cpp:244]     Train net output #1: loss = 0.481706 (* 1 = 0.481706 loss)
I0627 13:58:00.680773  5034 sgd_solver.cpp:106] Iteration 4720, lr = 1e-05
I0627 13:58:01.467353  5034 solver.cpp:228] Iteration 4740, loss = 0.63453
I0627 13:58:01.467382  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:58:01.467389  5034 solver.cpp:244]     Train net output #1: loss = 0.63453 (* 1 = 0.63453 loss)
I0627 13:58:01.467394  5034 sgd_solver.cpp:106] Iteration 4740, lr = 1e-05
I0627 13:58:02.259604  5034 solver.cpp:228] Iteration 4760, loss = 0.457415
I0627 13:58:02.259641  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:58:02.259649  5034 solver.cpp:244]     Train net output #1: loss = 0.457415 (* 1 = 0.457415 loss)
I0627 13:58:02.259654  5034 sgd_solver.cpp:106] Iteration 4760, lr = 1e-05
I0627 13:58:03.047550  5034 solver.cpp:228] Iteration 4780, loss = 0.423199
I0627 13:58:03.047590  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:58:03.047598  5034 solver.cpp:244]     Train net output #1: loss = 0.423199 (* 1 = 0.423199 loss)
I0627 13:58:03.047602  5034 sgd_solver.cpp:106] Iteration 4780, lr = 1e-05
I0627 13:58:03.822960  5034 solver.cpp:337] Iteration 4800, Testing net (#0)
I0627 13:58:06.003597  5034 solver.cpp:404]     Test net output #0: accuracy = 0.680664
I0627 13:58:06.003631  5034 solver.cpp:404]     Test net output #1: loss = 0.619421 (* 1 = 0.619421 loss)
I0627 13:58:06.016124  5034 solver.cpp:228] Iteration 4800, loss = 0.467435
I0627 13:58:06.016149  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:58:06.016157  5034 solver.cpp:244]     Train net output #1: loss = 0.467435 (* 1 = 0.467435 loss)
I0627 13:58:06.016161  5034 sgd_solver.cpp:106] Iteration 4800, lr = 1e-05
I0627 13:58:06.806515  5034 solver.cpp:228] Iteration 4820, loss = 0.570564
I0627 13:58:06.806553  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:58:06.806561  5034 solver.cpp:244]     Train net output #1: loss = 0.570564 (* 1 = 0.570564 loss)
I0627 13:58:06.806565  5034 sgd_solver.cpp:106] Iteration 4820, lr = 1e-05
I0627 13:58:07.588909  5034 solver.cpp:228] Iteration 4840, loss = 0.459681
I0627 13:58:07.588937  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:58:07.588955  5034 solver.cpp:244]     Train net output #1: loss = 0.459681 (* 1 = 0.459681 loss)
I0627 13:58:07.588959  5034 sgd_solver.cpp:106] Iteration 4840, lr = 1e-05
I0627 13:58:08.371498  5034 solver.cpp:228] Iteration 4860, loss = 0.507339
I0627 13:58:08.371536  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:58:08.371542  5034 solver.cpp:244]     Train net output #1: loss = 0.507339 (* 1 = 0.507339 loss)
I0627 13:58:08.371547  5034 sgd_solver.cpp:106] Iteration 4860, lr = 1e-05
I0627 13:58:09.153872  5034 solver.cpp:228] Iteration 4880, loss = 0.371954
I0627 13:58:09.153910  5034 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0627 13:58:09.153918  5034 solver.cpp:244]     Train net output #1: loss = 0.371954 (* 1 = 0.371954 loss)
I0627 13:58:09.153923  5034 sgd_solver.cpp:106] Iteration 4880, lr = 1e-05
I0627 13:58:09.924355  5034 solver.cpp:337] Iteration 4900, Testing net (#0)
I0627 13:58:12.076901  5034 solver.cpp:404]     Test net output #0: accuracy = 0.680664
I0627 13:58:12.076936  5034 solver.cpp:404]     Test net output #1: loss = 0.619687 (* 1 = 0.619687 loss)
I0627 13:58:12.089354  5034 solver.cpp:228] Iteration 4900, loss = 0.442782
I0627 13:58:12.089385  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:58:12.089395  5034 solver.cpp:244]     Train net output #1: loss = 0.442782 (* 1 = 0.442782 loss)
I0627 13:58:12.089401  5034 sgd_solver.cpp:106] Iteration 4900, lr = 1e-05
I0627 13:58:12.905360  5034 solver.cpp:228] Iteration 4920, loss = 0.511056
I0627 13:58:12.905398  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:58:12.905405  5034 solver.cpp:244]     Train net output #1: loss = 0.511056 (* 1 = 0.511056 loss)
I0627 13:58:12.905411  5034 sgd_solver.cpp:106] Iteration 4920, lr = 1e-05
I0627 13:58:13.688029  5034 solver.cpp:228] Iteration 4940, loss = 0.282448
I0627 13:58:13.688066  5034 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0627 13:58:13.688073  5034 solver.cpp:244]     Train net output #1: loss = 0.282448 (* 1 = 0.282448 loss)
I0627 13:58:13.688078  5034 sgd_solver.cpp:106] Iteration 4940, lr = 1e-05
I0627 13:58:14.471601  5034 solver.cpp:228] Iteration 4960, loss = 0.46493
I0627 13:58:14.471751  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:58:14.471762  5034 solver.cpp:244]     Train net output #1: loss = 0.46493 (* 1 = 0.46493 loss)
I0627 13:58:14.471767  5034 sgd_solver.cpp:106] Iteration 4960, lr = 1e-05
I0627 13:58:15.254106  5034 solver.cpp:228] Iteration 4980, loss = 0.468159
I0627 13:58:15.254132  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:58:15.254149  5034 solver.cpp:244]     Train net output #1: loss = 0.468159 (* 1 = 0.468159 loss)
I0627 13:58:15.254154  5034 sgd_solver.cpp:106] Iteration 4980, lr = 1e-05
I0627 13:58:16.024813  5034 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_5000.caffemodel
I0627 13:58:16.034368  5034 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_5000.solverstate
I0627 13:58:16.039312  5034 solver.cpp:337] Iteration 5000, Testing net (#0)
I0627 13:58:18.209870  5034 solver.cpp:404]     Test net output #0: accuracy = 0.676025
I0627 13:58:18.209903  5034 solver.cpp:404]     Test net output #1: loss = 0.625639 (* 1 = 0.625639 loss)
I0627 13:58:18.222375  5034 solver.cpp:228] Iteration 5000, loss = 0.461279
I0627 13:58:18.222404  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:58:18.222412  5034 solver.cpp:244]     Train net output #1: loss = 0.461279 (* 1 = 0.461279 loss)
I0627 13:58:18.222417  5034 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0627 13:58:19.003265  5034 solver.cpp:228] Iteration 5020, loss = 0.48495
I0627 13:58:19.003296  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:58:19.003304  5034 solver.cpp:244]     Train net output #1: loss = 0.48495 (* 1 = 0.48495 loss)
I0627 13:58:19.003307  5034 sgd_solver.cpp:106] Iteration 5020, lr = 1e-05
I0627 13:58:19.786103  5034 solver.cpp:228] Iteration 5040, loss = 0.705738
I0627 13:58:19.786128  5034 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0627 13:58:19.786146  5034 solver.cpp:244]     Train net output #1: loss = 0.705738 (* 1 = 0.705738 loss)
I0627 13:58:19.786150  5034 sgd_solver.cpp:106] Iteration 5040, lr = 1e-05
I0627 13:58:20.569074  5034 solver.cpp:228] Iteration 5060, loss = 0.498162
I0627 13:58:20.569103  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:58:20.569109  5034 solver.cpp:244]     Train net output #1: loss = 0.498162 (* 1 = 0.498162 loss)
I0627 13:58:20.569114  5034 sgd_solver.cpp:106] Iteration 5060, lr = 1e-05
I0627 13:58:21.352051  5034 solver.cpp:228] Iteration 5080, loss = 0.426964
I0627 13:58:21.352092  5034 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0627 13:58:21.352099  5034 solver.cpp:244]     Train net output #1: loss = 0.426964 (* 1 = 0.426964 loss)
I0627 13:58:21.352103  5034 sgd_solver.cpp:106] Iteration 5080, lr = 1e-05
I0627 13:58:22.122941  5034 solver.cpp:337] Iteration 5100, Testing net (#0)
I0627 13:58:24.243212  5034 solver.cpp:404]     Test net output #0: accuracy = 0.681641
I0627 13:58:24.243247  5034 solver.cpp:404]     Test net output #1: loss = 0.616623 (* 1 = 0.616623 loss)
I0627 13:58:24.255691  5034 solver.cpp:228] Iteration 5100, loss = 0.426728
I0627 13:58:24.255720  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:58:24.255728  5034 solver.cpp:244]     Train net output #1: loss = 0.426728 (* 1 = 0.426728 loss)
I0627 13:58:24.255734  5034 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0627 13:58:25.033776  5034 solver.cpp:228] Iteration 5120, loss = 0.537097
I0627 13:58:25.033813  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:58:25.033820  5034 solver.cpp:244]     Train net output #1: loss = 0.537097 (* 1 = 0.537097 loss)
I0627 13:58:25.033824  5034 sgd_solver.cpp:106] Iteration 5120, lr = 1e-05
I0627 13:58:25.817004  5034 solver.cpp:228] Iteration 5140, loss = 0.458647
I0627 13:58:25.817029  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:58:25.817047  5034 solver.cpp:244]     Train net output #1: loss = 0.458647 (* 1 = 0.458647 loss)
I0627 13:58:25.817052  5034 sgd_solver.cpp:106] Iteration 5140, lr = 1e-05
I0627 13:58:26.600194  5034 solver.cpp:228] Iteration 5160, loss = 0.599383
I0627 13:58:26.600234  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:58:26.600240  5034 solver.cpp:244]     Train net output #1: loss = 0.599383 (* 1 = 0.599383 loss)
I0627 13:58:26.600245  5034 sgd_solver.cpp:106] Iteration 5160, lr = 1e-05
I0627 13:58:27.383194  5034 solver.cpp:228] Iteration 5180, loss = 0.448066
I0627 13:58:27.383224  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:58:27.383230  5034 solver.cpp:244]     Train net output #1: loss = 0.448066 (* 1 = 0.448066 loss)
I0627 13:58:27.383235  5034 sgd_solver.cpp:106] Iteration 5180, lr = 1e-05
I0627 13:58:28.153313  5034 solver.cpp:337] Iteration 5200, Testing net (#0)
I0627 13:58:30.313293  5034 solver.cpp:404]     Test net output #0: accuracy = 0.680176
I0627 13:58:30.313325  5034 solver.cpp:404]     Test net output #1: loss = 0.620136 (* 1 = 0.620136 loss)
I0627 13:58:30.325769  5034 solver.cpp:228] Iteration 5200, loss = 0.547786
I0627 13:58:30.325796  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:58:30.325804  5034 solver.cpp:244]     Train net output #1: loss = 0.547786 (* 1 = 0.547786 loss)
I0627 13:58:30.325809  5034 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0627 13:58:31.115689  5034 solver.cpp:228] Iteration 5220, loss = 0.510325
I0627 13:58:31.115715  5034 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0627 13:58:31.115723  5034 solver.cpp:244]     Train net output #1: loss = 0.510325 (* 1 = 0.510325 loss)
I0627 13:58:31.115728  5034 sgd_solver.cpp:106] Iteration 5220, lr = 1e-05
I0627 13:58:31.897460  5034 solver.cpp:228] Iteration 5240, loss = 0.306603
I0627 13:58:31.897485  5034 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0627 13:58:31.897492  5034 solver.cpp:244]     Train net output #1: loss = 0.306603 (* 1 = 0.306603 loss)
I0627 13:58:31.897497  5034 sgd_solver.cpp:106] Iteration 5240, lr = 1e-05
I0627 13:58:32.679355  5034 solver.cpp:228] Iteration 5260, loss = 0.484258
I0627 13:58:32.679383  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:58:32.679390  5034 solver.cpp:244]     Train net output #1: loss = 0.484258 (* 1 = 0.484258 loss)
I0627 13:58:32.679394  5034 sgd_solver.cpp:106] Iteration 5260, lr = 1e-05
I0627 13:58:33.462151  5034 solver.cpp:228] Iteration 5280, loss = 0.511829
I0627 13:58:33.462177  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:58:33.462183  5034 solver.cpp:244]     Train net output #1: loss = 0.511829 (* 1 = 0.511829 loss)
I0627 13:58:33.462188  5034 sgd_solver.cpp:106] Iteration 5280, lr = 1e-05
I0627 13:58:34.232285  5034 solver.cpp:337] Iteration 5300, Testing net (#0)
I0627 13:58:36.310773  5034 solver.cpp:404]     Test net output #0: accuracy = 0.677246
I0627 13:58:36.310806  5034 solver.cpp:404]     Test net output #1: loss = 0.619929 (* 1 = 0.619929 loss)
I0627 13:58:36.323185  5034 solver.cpp:228] Iteration 5300, loss = 0.511717
I0627 13:58:36.323211  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:58:36.323218  5034 solver.cpp:244]     Train net output #1: loss = 0.511717 (* 1 = 0.511717 loss)
I0627 13:58:36.323223  5034 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0627 13:58:37.107559  5034 solver.cpp:228] Iteration 5320, loss = 0.461376
I0627 13:58:37.107597  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:58:37.107604  5034 solver.cpp:244]     Train net output #1: loss = 0.461376 (* 1 = 0.461376 loss)
I0627 13:58:37.107609  5034 sgd_solver.cpp:106] Iteration 5320, lr = 1e-05
I0627 13:58:37.889094  5034 solver.cpp:228] Iteration 5340, loss = 0.491169
I0627 13:58:37.889132  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:58:37.889139  5034 solver.cpp:244]     Train net output #1: loss = 0.491169 (* 1 = 0.491169 loss)
I0627 13:58:37.889143  5034 sgd_solver.cpp:106] Iteration 5340, lr = 1e-05
I0627 13:58:38.671706  5034 solver.cpp:228] Iteration 5360, loss = 0.409014
I0627 13:58:38.671766  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:58:38.671774  5034 solver.cpp:244]     Train net output #1: loss = 0.409014 (* 1 = 0.409014 loss)
I0627 13:58:38.671778  5034 sgd_solver.cpp:106] Iteration 5360, lr = 1e-05
I0627 13:58:39.455003  5034 solver.cpp:228] Iteration 5380, loss = 0.443389
I0627 13:58:39.455029  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:58:39.455035  5034 solver.cpp:244]     Train net output #1: loss = 0.443389 (* 1 = 0.443389 loss)
I0627 13:58:39.455040  5034 sgd_solver.cpp:106] Iteration 5380, lr = 1e-05
I0627 13:58:40.225913  5034 solver.cpp:337] Iteration 5400, Testing net (#0)
I0627 13:58:42.383733  5034 solver.cpp:404]     Test net output #0: accuracy = 0.681396
I0627 13:58:42.383767  5034 solver.cpp:404]     Test net output #1: loss = 0.618884 (* 1 = 0.618884 loss)
I0627 13:58:42.396226  5034 solver.cpp:228] Iteration 5400, loss = 0.378871
I0627 13:58:42.396251  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:58:42.396258  5034 solver.cpp:244]     Train net output #1: loss = 0.378871 (* 1 = 0.378871 loss)
I0627 13:58:42.396265  5034 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0627 13:58:43.186795  5034 solver.cpp:228] Iteration 5420, loss = 0.619799
I0627 13:58:43.186835  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:58:43.186842  5034 solver.cpp:244]     Train net output #1: loss = 0.619799 (* 1 = 0.619799 loss)
I0627 13:58:43.186846  5034 sgd_solver.cpp:106] Iteration 5420, lr = 1e-05
I0627 13:58:43.969722  5034 solver.cpp:228] Iteration 5440, loss = 0.479533
I0627 13:58:43.969750  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:58:43.969758  5034 solver.cpp:244]     Train net output #1: loss = 0.479533 (* 1 = 0.479533 loss)
I0627 13:58:43.969763  5034 sgd_solver.cpp:106] Iteration 5440, lr = 1e-05
I0627 13:58:44.774034  5034 solver.cpp:228] Iteration 5460, loss = 0.46952
I0627 13:58:44.774183  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:58:44.774194  5034 solver.cpp:244]     Train net output #1: loss = 0.46952 (* 1 = 0.46952 loss)
I0627 13:58:44.774197  5034 sgd_solver.cpp:106] Iteration 5460, lr = 1e-05
I0627 13:58:45.563241  5034 solver.cpp:228] Iteration 5480, loss = 0.472481
I0627 13:58:45.563268  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:58:45.563277  5034 solver.cpp:244]     Train net output #1: loss = 0.472481 (* 1 = 0.472481 loss)
I0627 13:58:45.563280  5034 sgd_solver.cpp:106] Iteration 5480, lr = 1e-05
I0627 13:58:46.341217  5034 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_5500.caffemodel
I0627 13:58:46.350778  5034 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_5500.solverstate
I0627 13:58:46.355576  5034 solver.cpp:337] Iteration 5500, Testing net (#0)
I0627 13:58:48.520496  5034 solver.cpp:404]     Test net output #0: accuracy = 0.678955
I0627 13:58:48.520530  5034 solver.cpp:404]     Test net output #1: loss = 0.619943 (* 1 = 0.619943 loss)
I0627 13:58:48.532955  5034 solver.cpp:228] Iteration 5500, loss = 0.557931
I0627 13:58:48.532984  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:58:48.532990  5034 solver.cpp:244]     Train net output #1: loss = 0.557931 (* 1 = 0.557931 loss)
I0627 13:58:48.532996  5034 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0627 13:58:49.327739  5034 solver.cpp:228] Iteration 5520, loss = 0.60716
I0627 13:58:49.327766  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:58:49.327774  5034 solver.cpp:244]     Train net output #1: loss = 0.60716 (* 1 = 0.60716 loss)
I0627 13:58:49.327778  5034 sgd_solver.cpp:106] Iteration 5520, lr = 1e-05
I0627 13:58:50.116128  5034 solver.cpp:228] Iteration 5540, loss = 0.398365
I0627 13:58:50.116156  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:58:50.116163  5034 solver.cpp:244]     Train net output #1: loss = 0.398365 (* 1 = 0.398365 loss)
I0627 13:58:50.116168  5034 sgd_solver.cpp:106] Iteration 5540, lr = 1e-05
I0627 13:58:50.909430  5034 solver.cpp:228] Iteration 5560, loss = 0.581562
I0627 13:58:50.909453  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:58:50.909461  5034 solver.cpp:244]     Train net output #1: loss = 0.581562 (* 1 = 0.581562 loss)
I0627 13:58:50.909466  5034 sgd_solver.cpp:106] Iteration 5560, lr = 1e-05
I0627 13:58:51.696653  5034 solver.cpp:228] Iteration 5580, loss = 0.508904
I0627 13:58:51.696691  5034 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0627 13:58:51.696698  5034 solver.cpp:244]     Train net output #1: loss = 0.508904 (* 1 = 0.508904 loss)
I0627 13:58:51.696703  5034 sgd_solver.cpp:106] Iteration 5580, lr = 1e-05
I0627 13:58:52.473289  5034 solver.cpp:337] Iteration 5600, Testing net (#0)
I0627 13:58:54.612002  5034 solver.cpp:404]     Test net output #0: accuracy = 0.678467
I0627 13:58:54.612036  5034 solver.cpp:404]     Test net output #1: loss = 0.622799 (* 1 = 0.622799 loss)
I0627 13:58:54.624481  5034 solver.cpp:228] Iteration 5600, loss = 0.473771
I0627 13:58:54.624508  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:58:54.624516  5034 solver.cpp:244]     Train net output #1: loss = 0.473771 (* 1 = 0.473771 loss)
I0627 13:58:54.624521  5034 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0627 13:58:55.474067  5034 solver.cpp:228] Iteration 5620, loss = 0.491374
I0627 13:58:55.474097  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:58:55.474105  5034 solver.cpp:244]     Train net output #1: loss = 0.491374 (* 1 = 0.491374 loss)
I0627 13:58:55.474110  5034 sgd_solver.cpp:106] Iteration 5620, lr = 1e-05
I0627 13:58:56.263301  5034 solver.cpp:228] Iteration 5640, loss = 0.453847
I0627 13:58:56.263326  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:58:56.263334  5034 solver.cpp:244]     Train net output #1: loss = 0.453847 (* 1 = 0.453847 loss)
I0627 13:58:56.263337  5034 sgd_solver.cpp:106] Iteration 5640, lr = 1e-05
I0627 13:58:57.054458  5034 solver.cpp:228] Iteration 5660, loss = 0.505619
I0627 13:58:57.054487  5034 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0627 13:58:57.054496  5034 solver.cpp:244]     Train net output #1: loss = 0.505619 (* 1 = 0.505619 loss)
I0627 13:58:57.054500  5034 sgd_solver.cpp:106] Iteration 5660, lr = 1e-05
I0627 13:58:57.842672  5034 solver.cpp:228] Iteration 5680, loss = 0.511539
I0627 13:58:57.842707  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:58:57.842715  5034 solver.cpp:244]     Train net output #1: loss = 0.511539 (* 1 = 0.511539 loss)
I0627 13:58:57.842718  5034 sgd_solver.cpp:106] Iteration 5680, lr = 1e-05
I0627 13:58:58.618305  5034 solver.cpp:337] Iteration 5700, Testing net (#0)
I0627 13:59:00.769141  5034 solver.cpp:404]     Test net output #0: accuracy = 0.680908
I0627 13:59:00.769175  5034 solver.cpp:404]     Test net output #1: loss = 0.618772 (* 1 = 0.618772 loss)
I0627 13:59:00.781569  5034 solver.cpp:228] Iteration 5700, loss = 0.368533
I0627 13:59:00.781594  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:59:00.781600  5034 solver.cpp:244]     Train net output #1: loss = 0.368533 (* 1 = 0.368533 loss)
I0627 13:59:00.781605  5034 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0627 13:59:01.581499  5034 solver.cpp:228] Iteration 5720, loss = 0.559285
I0627 13:59:01.581526  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:59:01.581532  5034 solver.cpp:244]     Train net output #1: loss = 0.559285 (* 1 = 0.559285 loss)
I0627 13:59:01.581537  5034 sgd_solver.cpp:106] Iteration 5720, lr = 1e-05
I0627 13:59:02.369740  5034 solver.cpp:228] Iteration 5740, loss = 0.441999
I0627 13:59:02.369765  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:59:02.369772  5034 solver.cpp:244]     Train net output #1: loss = 0.441999 (* 1 = 0.441999 loss)
I0627 13:59:02.369776  5034 sgd_solver.cpp:106] Iteration 5740, lr = 1e-05
I0627 13:59:03.157958  5034 solver.cpp:228] Iteration 5760, loss = 0.458782
I0627 13:59:03.157989  5034 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0627 13:59:03.157995  5034 solver.cpp:244]     Train net output #1: loss = 0.458782 (* 1 = 0.458782 loss)
I0627 13:59:03.158000  5034 sgd_solver.cpp:106] Iteration 5760, lr = 1e-05
I0627 13:59:03.947860  5034 solver.cpp:228] Iteration 5780, loss = 0.521257
I0627 13:59:03.947885  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:59:03.947892  5034 solver.cpp:244]     Train net output #1: loss = 0.521257 (* 1 = 0.521257 loss)
I0627 13:59:03.947897  5034 sgd_solver.cpp:106] Iteration 5780, lr = 1e-05
I0627 13:59:04.730142  5034 solver.cpp:337] Iteration 5800, Testing net (#0)
I0627 13:59:06.881423  5034 solver.cpp:404]     Test net output #0: accuracy = 0.677979
I0627 13:59:06.881454  5034 solver.cpp:404]     Test net output #1: loss = 0.621171 (* 1 = 0.621171 loss)
I0627 13:59:06.894017  5034 solver.cpp:228] Iteration 5800, loss = 0.507432
I0627 13:59:06.894043  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:59:06.894052  5034 solver.cpp:244]     Train net output #1: loss = 0.507432 (* 1 = 0.507432 loss)
I0627 13:59:06.894057  5034 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0627 13:59:07.740396  5034 solver.cpp:228] Iteration 5820, loss = 0.555937
I0627 13:59:07.740435  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:59:07.740443  5034 solver.cpp:244]     Train net output #1: loss = 0.555937 (* 1 = 0.555937 loss)
I0627 13:59:07.740447  5034 sgd_solver.cpp:106] Iteration 5820, lr = 1e-05
I0627 13:59:08.523156  5034 solver.cpp:228] Iteration 5840, loss = 0.408421
I0627 13:59:08.523195  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:59:08.523203  5034 solver.cpp:244]     Train net output #1: loss = 0.408421 (* 1 = 0.408421 loss)
I0627 13:59:08.523207  5034 sgd_solver.cpp:106] Iteration 5840, lr = 1e-05
I0627 13:59:09.306013  5034 solver.cpp:228] Iteration 5860, loss = 0.50464
I0627 13:59:09.306061  5034 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0627 13:59:09.306068  5034 solver.cpp:244]     Train net output #1: loss = 0.50464 (* 1 = 0.50464 loss)
I0627 13:59:09.306073  5034 sgd_solver.cpp:106] Iteration 5860, lr = 1e-05
I0627 13:59:10.088805  5034 solver.cpp:228] Iteration 5880, loss = 0.480866
I0627 13:59:10.088843  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:59:10.088851  5034 solver.cpp:244]     Train net output #1: loss = 0.480866 (* 1 = 0.480866 loss)
I0627 13:59:10.088855  5034 sgd_solver.cpp:106] Iteration 5880, lr = 1e-05
I0627 13:59:10.859961  5034 solver.cpp:337] Iteration 5900, Testing net (#0)
I0627 13:59:13.010799  5034 solver.cpp:404]     Test net output #0: accuracy = 0.677002
I0627 13:59:13.010835  5034 solver.cpp:404]     Test net output #1: loss = 0.620968 (* 1 = 0.620968 loss)
I0627 13:59:13.023329  5034 solver.cpp:228] Iteration 5900, loss = 0.512593
I0627 13:59:13.023356  5034 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0627 13:59:13.023363  5034 solver.cpp:244]     Train net output #1: loss = 0.512593 (* 1 = 0.512593 loss)
I0627 13:59:13.023368  5034 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0627 13:59:13.875092  5034 solver.cpp:228] Iteration 5920, loss = 0.378264
I0627 13:59:13.875119  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:59:13.875128  5034 solver.cpp:244]     Train net output #1: loss = 0.378264 (* 1 = 0.378264 loss)
I0627 13:59:13.875133  5034 sgd_solver.cpp:106] Iteration 5920, lr = 1e-05
I0627 13:59:14.658340  5034 solver.cpp:228] Iteration 5940, loss = 0.450775
I0627 13:59:14.658378  5034 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0627 13:59:14.658386  5034 solver.cpp:244]     Train net output #1: loss = 0.450775 (* 1 = 0.450775 loss)
I0627 13:59:14.658391  5034 sgd_solver.cpp:106] Iteration 5940, lr = 1e-05
I0627 13:59:15.442245  5034 solver.cpp:228] Iteration 5960, loss = 0.562883
I0627 13:59:15.442353  5034 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0627 13:59:15.442361  5034 solver.cpp:244]     Train net output #1: loss = 0.562883 (* 1 = 0.562883 loss)
I0627 13:59:15.442366  5034 sgd_solver.cpp:106] Iteration 5960, lr = 1e-05
I0627 13:59:16.224892  5034 solver.cpp:228] Iteration 5980, loss = 0.423215
I0627 13:59:16.224918  5034 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0627 13:59:16.224936  5034 solver.cpp:244]     Train net output #1: loss = 0.423215 (* 1 = 0.423215 loss)
I0627 13:59:16.224941  5034 sgd_solver.cpp:106] Iteration 5980, lr = 1e-05
I0627 13:59:16.995865  5034 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_6000.caffemodel
I0627 13:59:17.005456  5034 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_6000.solverstate
I0627 13:59:17.021795  5034 solver.cpp:317] Iteration 6000, loss = 0.373579
I0627 13:59:17.021831  5034 solver.cpp:337] Iteration 6000, Testing net (#0)
I0627 13:59:19.165729  5034 solver.cpp:404]     Test net output #0: accuracy = 0.681641
I0627 13:59:19.165771  5034 solver.cpp:404]     Test net output #1: loss = 0.617814 (* 1 = 0.617814 loss)
I0627 13:59:19.165776  5034 solver.cpp:322] Optimization Done.
I0627 13:59:19.165777  5034 caffe.cpp:222] Optimization Done.
