I0523 15:13:59.882629 21880 caffe.cpp:185] Using GPUs 0
I0523 15:13:59.885561 21880 caffe.cpp:190] GPU 0: GeForce GTX TITAN X
I0523 15:14:00.017076 21880 solver.cpp:48] Initializing solver from parameters: 
test_iter: 16
test_interval: 100
base_lr: 0.01
display: 20
max_iter: 10000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 3000
snapshot: 500
snapshot_prefix: "data/models/segnet"
solver_mode: GPU
device_id: 0
net: "models/segnet/train_val.prototxt"
test_initialization: true
I0523 15:14:00.017184 21880 solver.cpp:91] Creating training net from net file: models/segnet/train_val.prototxt
I0523 15:14:00.018520 21880 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0523 15:14:00.018899 21880 net.cpp:49] Initializing net from parameters: 
name: "segnet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "DenseImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 224
    mean_value: 100
  }
  dense_image_data_param {
    source: "data/train.txt"
    batch_size: 32
    shuffle: true
    new_height: 224
    new_width: 310
    is_color: false
    root_folder: "data/raw/train/"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 14
    upsample_w: 14
  }
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5_2_D"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2_D"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5_1_D"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1_D"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 28
    upsample_w: 28
  }
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4_2_D"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2_D"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4_1_D"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1_D"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
    upsample_h: 56
    upsample_w: 56
  }
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn3_2_D"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2_D"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3_1_D"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1_D"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
    upsample_h: 112
    upsample_w: 112
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2_2_D"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2_D"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2_1_D"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1_D"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
    upsample_h: 224
    upsample_w: 224
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1_2_D"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2_D"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "accuracy"
}
I0523 15:14:00.019131 21880 layer_factory.hpp:77] Creating layer data
I0523 15:14:00.019157 21880 net.cpp:91] Creating Layer data
I0523 15:14:00.019162 21880 net.cpp:399] data -> data
I0523 15:14:00.019179 21880 net.cpp:399] data -> label
I0523 15:14:00.019461 21880 dense_image_data_layer.cpp:38] Opening file data/train.txt
I0523 15:14:00.021559 21880 dense_image_data_layer.cpp:48] Shuffling data
I0523 15:14:00.022032 21880 dense_image_data_layer.cpp:53] A total of 4930 examples.
I0523 15:14:00.032487 21880 dense_image_data_layer.cpp:92] output data size: 1,1,224,224
I0523 15:14:00.033586 21880 net.cpp:141] Setting up data
I0523 15:14:00.033619 21880 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0523 15:14:00.033623 21880 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0523 15:14:00.033625 21880 net.cpp:156] Memory required for data: 401408
I0523 15:14:00.033632 21880 layer_factory.hpp:77] Creating layer label_data_1_split
I0523 15:14:00.033646 21880 net.cpp:91] Creating Layer label_data_1_split
I0523 15:14:00.033650 21880 net.cpp:425] label_data_1_split <- label
I0523 15:14:00.033659 21880 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0523 15:14:00.033668 21880 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0523 15:14:00.033726 21880 net.cpp:141] Setting up label_data_1_split
I0523 15:14:00.033731 21880 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0523 15:14:00.033745 21880 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0523 15:14:00.033746 21880 net.cpp:156] Memory required for data: 802816
I0523 15:14:00.033749 21880 layer_factory.hpp:77] Creating layer conv1_1
I0523 15:14:00.033761 21880 net.cpp:91] Creating Layer conv1_1
I0523 15:14:00.033764 21880 net.cpp:425] conv1_1 <- data
I0523 15:14:00.033768 21880 net.cpp:399] conv1_1 -> conv1_1
I0523 15:14:00.191020 21880 net.cpp:141] Setting up conv1_1
I0523 15:14:00.191051 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.191054 21880 net.cpp:156] Memory required for data: 7225344
I0523 15:14:00.191067 21880 layer_factory.hpp:77] Creating layer bn1_1
I0523 15:14:00.191082 21880 net.cpp:91] Creating Layer bn1_1
I0523 15:14:00.191087 21880 net.cpp:425] bn1_1 <- conv1_1
I0523 15:14:00.191092 21880 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0523 15:14:00.191273 21880 net.cpp:141] Setting up bn1_1
I0523 15:14:00.191280 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.191293 21880 net.cpp:156] Memory required for data: 13647872
I0523 15:14:00.191303 21880 layer_factory.hpp:77] Creating layer scale1_1
I0523 15:14:00.191311 21880 net.cpp:91] Creating Layer scale1_1
I0523 15:14:00.191313 21880 net.cpp:425] scale1_1 <- conv1_1
I0523 15:14:00.191318 21880 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0523 15:14:00.191350 21880 layer_factory.hpp:77] Creating layer scale1_1
I0523 15:14:00.191507 21880 net.cpp:141] Setting up scale1_1
I0523 15:14:00.191514 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.191525 21880 net.cpp:156] Memory required for data: 20070400
I0523 15:14:00.191531 21880 layer_factory.hpp:77] Creating layer relu1_1
I0523 15:14:00.191537 21880 net.cpp:91] Creating Layer relu1_1
I0523 15:14:00.191540 21880 net.cpp:425] relu1_1 <- conv1_1
I0523 15:14:00.191543 21880 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0523 15:14:00.191776 21880 net.cpp:141] Setting up relu1_1
I0523 15:14:00.191786 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.191797 21880 net.cpp:156] Memory required for data: 26492928
I0523 15:14:00.191800 21880 layer_factory.hpp:77] Creating layer conv1_2
I0523 15:14:00.191809 21880 net.cpp:91] Creating Layer conv1_2
I0523 15:14:00.191812 21880 net.cpp:425] conv1_2 <- conv1_1
I0523 15:14:00.191815 21880 net.cpp:399] conv1_2 -> conv1_2
I0523 15:14:00.193084 21880 net.cpp:141] Setting up conv1_2
I0523 15:14:00.193105 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.193109 21880 net.cpp:156] Memory required for data: 32915456
I0523 15:14:00.193112 21880 layer_factory.hpp:77] Creating layer bn1_2
I0523 15:14:00.193120 21880 net.cpp:91] Creating Layer bn1_2
I0523 15:14:00.193121 21880 net.cpp:425] bn1_2 <- conv1_2
I0523 15:14:00.193125 21880 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0523 15:14:00.193308 21880 net.cpp:141] Setting up bn1_2
I0523 15:14:00.193315 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.193326 21880 net.cpp:156] Memory required for data: 39337984
I0523 15:14:00.193333 21880 layer_factory.hpp:77] Creating layer scale1_2
I0523 15:14:00.193341 21880 net.cpp:91] Creating Layer scale1_2
I0523 15:14:00.193357 21880 net.cpp:425] scale1_2 <- conv1_2
I0523 15:14:00.193361 21880 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0523 15:14:00.193392 21880 layer_factory.hpp:77] Creating layer scale1_2
I0523 15:14:00.193554 21880 net.cpp:141] Setting up scale1_2
I0523 15:14:00.193559 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.193572 21880 net.cpp:156] Memory required for data: 45760512
I0523 15:14:00.193577 21880 layer_factory.hpp:77] Creating layer relu1_2
I0523 15:14:00.193583 21880 net.cpp:91] Creating Layer relu1_2
I0523 15:14:00.193584 21880 net.cpp:425] relu1_2 <- conv1_2
I0523 15:14:00.193588 21880 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0523 15:14:00.193730 21880 net.cpp:141] Setting up relu1_2
I0523 15:14:00.193735 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.193748 21880 net.cpp:156] Memory required for data: 52183040
I0523 15:14:00.193750 21880 layer_factory.hpp:77] Creating layer pool1
I0523 15:14:00.193754 21880 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0523 15:14:00.193758 21880 net.cpp:91] Creating Layer pool1
I0523 15:14:00.193761 21880 net.cpp:425] pool1 <- conv1_2
I0523 15:14:00.193764 21880 net.cpp:399] pool1 -> pool1
I0523 15:14:00.193771 21880 net.cpp:399] pool1 -> pool1_mask
I0523 15:14:00.193806 21880 net.cpp:141] Setting up pool1
I0523 15:14:00.193810 21880 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0523 15:14:00.193814 21880 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0523 15:14:00.193815 21880 net.cpp:156] Memory required for data: 55394304
I0523 15:14:00.193817 21880 layer_factory.hpp:77] Creating layer conv2_1
I0523 15:14:00.193825 21880 net.cpp:91] Creating Layer conv2_1
I0523 15:14:00.193826 21880 net.cpp:425] conv2_1 <- pool1
I0523 15:14:00.193830 21880 net.cpp:399] conv2_1 -> conv2_1
I0523 15:14:00.196733 21880 net.cpp:141] Setting up conv2_1
I0523 15:14:00.196759 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.196761 21880 net.cpp:156] Memory required for data: 58605568
I0523 15:14:00.196768 21880 layer_factory.hpp:77] Creating layer bn2_1
I0523 15:14:00.196776 21880 net.cpp:91] Creating Layer bn2_1
I0523 15:14:00.196779 21880 net.cpp:425] bn2_1 <- conv2_1
I0523 15:14:00.196784 21880 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0523 15:14:00.196949 21880 net.cpp:141] Setting up bn2_1
I0523 15:14:00.196954 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.196967 21880 net.cpp:156] Memory required for data: 61816832
I0523 15:14:00.196972 21880 layer_factory.hpp:77] Creating layer scale2_1
I0523 15:14:00.196979 21880 net.cpp:91] Creating Layer scale2_1
I0523 15:14:00.196981 21880 net.cpp:425] scale2_1 <- conv2_1
I0523 15:14:00.196986 21880 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0523 15:14:00.197017 21880 layer_factory.hpp:77] Creating layer scale2_1
I0523 15:14:00.197160 21880 net.cpp:141] Setting up scale2_1
I0523 15:14:00.197166 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.197180 21880 net.cpp:156] Memory required for data: 65028096
I0523 15:14:00.197188 21880 layer_factory.hpp:77] Creating layer relu2_1
I0523 15:14:00.197194 21880 net.cpp:91] Creating Layer relu2_1
I0523 15:14:00.197196 21880 net.cpp:425] relu2_1 <- conv2_1
I0523 15:14:00.197199 21880 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0523 15:14:00.198616 21880 net.cpp:141] Setting up relu2_1
I0523 15:14:00.198635 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.198638 21880 net.cpp:156] Memory required for data: 68239360
I0523 15:14:00.198640 21880 layer_factory.hpp:77] Creating layer conv2_2
I0523 15:14:00.198649 21880 net.cpp:91] Creating Layer conv2_2
I0523 15:14:00.198652 21880 net.cpp:425] conv2_2 <- conv2_1
I0523 15:14:00.198657 21880 net.cpp:399] conv2_2 -> conv2_2
I0523 15:14:00.200326 21880 net.cpp:141] Setting up conv2_2
I0523 15:14:00.200335 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.200348 21880 net.cpp:156] Memory required for data: 71450624
I0523 15:14:00.200353 21880 layer_factory.hpp:77] Creating layer bn2_2
I0523 15:14:00.200373 21880 net.cpp:91] Creating Layer bn2_2
I0523 15:14:00.200376 21880 net.cpp:425] bn2_2 <- conv2_2
I0523 15:14:00.200381 21880 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0523 15:14:00.200530 21880 net.cpp:141] Setting up bn2_2
I0523 15:14:00.200534 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.200547 21880 net.cpp:156] Memory required for data: 74661888
I0523 15:14:00.200552 21880 layer_factory.hpp:77] Creating layer scale2_2
I0523 15:14:00.200558 21880 net.cpp:91] Creating Layer scale2_2
I0523 15:14:00.200561 21880 net.cpp:425] scale2_2 <- conv2_2
I0523 15:14:00.200563 21880 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0523 15:14:00.200592 21880 layer_factory.hpp:77] Creating layer scale2_2
I0523 15:14:00.200714 21880 net.cpp:141] Setting up scale2_2
I0523 15:14:00.200719 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.200731 21880 net.cpp:156] Memory required for data: 77873152
I0523 15:14:00.200736 21880 layer_factory.hpp:77] Creating layer relu2_2
I0523 15:14:00.200741 21880 net.cpp:91] Creating Layer relu2_2
I0523 15:14:00.200742 21880 net.cpp:425] relu2_2 <- conv2_2
I0523 15:14:00.200747 21880 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0523 15:14:00.200968 21880 net.cpp:141] Setting up relu2_2
I0523 15:14:00.200976 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.200989 21880 net.cpp:156] Memory required for data: 81084416
I0523 15:14:00.200991 21880 layer_factory.hpp:77] Creating layer pool2
I0523 15:14:00.200995 21880 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0523 15:14:00.201000 21880 net.cpp:91] Creating Layer pool2
I0523 15:14:00.201002 21880 net.cpp:425] pool2 <- conv2_2
I0523 15:14:00.201006 21880 net.cpp:399] pool2 -> pool2
I0523 15:14:00.201011 21880 net.cpp:399] pool2 -> pool2_mask
I0523 15:14:00.201052 21880 net.cpp:141] Setting up pool2
I0523 15:14:00.201057 21880 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0523 15:14:00.201071 21880 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0523 15:14:00.201071 21880 net.cpp:156] Memory required for data: 82690048
I0523 15:14:00.201074 21880 layer_factory.hpp:77] Creating layer conv3_1
I0523 15:14:00.201081 21880 net.cpp:91] Creating Layer conv3_1
I0523 15:14:00.201082 21880 net.cpp:425] conv3_1 <- pool2
I0523 15:14:00.201086 21880 net.cpp:399] conv3_1 -> conv3_1
I0523 15:14:00.203989 21880 net.cpp:141] Setting up conv3_1
I0523 15:14:00.204010 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.204015 21880 net.cpp:156] Memory required for data: 84295680
I0523 15:14:00.204018 21880 layer_factory.hpp:77] Creating layer bn3_1
I0523 15:14:00.204023 21880 net.cpp:91] Creating Layer bn3_1
I0523 15:14:00.204026 21880 net.cpp:425] bn3_1 <- conv3_1
I0523 15:14:00.204031 21880 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0523 15:14:00.204447 21880 net.cpp:141] Setting up bn3_1
I0523 15:14:00.204454 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.204468 21880 net.cpp:156] Memory required for data: 85901312
I0523 15:14:00.204473 21880 layer_factory.hpp:77] Creating layer scale3_1
I0523 15:14:00.204478 21880 net.cpp:91] Creating Layer scale3_1
I0523 15:14:00.204481 21880 net.cpp:425] scale3_1 <- conv3_1
I0523 15:14:00.204488 21880 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0523 15:14:00.204516 21880 layer_factory.hpp:77] Creating layer scale3_1
I0523 15:14:00.204603 21880 net.cpp:141] Setting up scale3_1
I0523 15:14:00.204607 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.204619 21880 net.cpp:156] Memory required for data: 87506944
I0523 15:14:00.204623 21880 layer_factory.hpp:77] Creating layer relu3_1
I0523 15:14:00.204628 21880 net.cpp:91] Creating Layer relu3_1
I0523 15:14:00.204630 21880 net.cpp:425] relu3_1 <- conv3_1
I0523 15:14:00.204633 21880 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0523 15:14:00.204772 21880 net.cpp:141] Setting up relu3_1
I0523 15:14:00.204778 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.204790 21880 net.cpp:156] Memory required for data: 89112576
I0523 15:14:00.204802 21880 layer_factory.hpp:77] Creating layer conv3_2
I0523 15:14:00.204809 21880 net.cpp:91] Creating Layer conv3_2
I0523 15:14:00.204812 21880 net.cpp:425] conv3_2 <- conv3_1
I0523 15:14:00.204816 21880 net.cpp:399] conv3_2 -> conv3_2
I0523 15:14:00.209257 21880 net.cpp:141] Setting up conv3_2
I0523 15:14:00.209280 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.209282 21880 net.cpp:156] Memory required for data: 90718208
I0523 15:14:00.209287 21880 layer_factory.hpp:77] Creating layer bn3_2
I0523 15:14:00.209293 21880 net.cpp:91] Creating Layer bn3_2
I0523 15:14:00.209296 21880 net.cpp:425] bn3_2 <- conv3_2
I0523 15:14:00.209300 21880 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0523 15:14:00.209449 21880 net.cpp:141] Setting up bn3_2
I0523 15:14:00.209453 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.209465 21880 net.cpp:156] Memory required for data: 92323840
I0523 15:14:00.209475 21880 layer_factory.hpp:77] Creating layer scale3_2
I0523 15:14:00.209481 21880 net.cpp:91] Creating Layer scale3_2
I0523 15:14:00.209484 21880 net.cpp:425] scale3_2 <- conv3_2
I0523 15:14:00.209487 21880 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0523 15:14:00.209516 21880 layer_factory.hpp:77] Creating layer scale3_2
I0523 15:14:00.209606 21880 net.cpp:141] Setting up scale3_2
I0523 15:14:00.209610 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.209624 21880 net.cpp:156] Memory required for data: 93929472
I0523 15:14:00.209627 21880 layer_factory.hpp:77] Creating layer relu3_2
I0523 15:14:00.209632 21880 net.cpp:91] Creating Layer relu3_2
I0523 15:14:00.209635 21880 net.cpp:425] relu3_2 <- conv3_2
I0523 15:14:00.209638 21880 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0523 15:14:00.209780 21880 net.cpp:141] Setting up relu3_2
I0523 15:14:00.209787 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.209800 21880 net.cpp:156] Memory required for data: 95535104
I0523 15:14:00.209802 21880 layer_factory.hpp:77] Creating layer pool3
I0523 15:14:00.209806 21880 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0523 15:14:00.209810 21880 net.cpp:91] Creating Layer pool3
I0523 15:14:00.209812 21880 net.cpp:425] pool3 <- conv3_2
I0523 15:14:00.209815 21880 net.cpp:399] pool3 -> pool3
I0523 15:14:00.209820 21880 net.cpp:399] pool3 -> pool3_mask
I0523 15:14:00.209852 21880 net.cpp:141] Setting up pool3
I0523 15:14:00.209867 21880 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0523 15:14:00.209868 21880 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0523 15:14:00.209870 21880 net.cpp:156] Memory required for data: 96337920
I0523 15:14:00.209883 21880 layer_factory.hpp:77] Creating layer conv4_1
I0523 15:14:00.209889 21880 net.cpp:91] Creating Layer conv4_1
I0523 15:14:00.209892 21880 net.cpp:425] conv4_1 <- pool3
I0523 15:14:00.209897 21880 net.cpp:399] conv4_1 -> conv4_1
I0523 15:14:00.217905 21880 net.cpp:141] Setting up conv4_1
I0523 15:14:00.217919 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.217921 21880 net.cpp:156] Memory required for data: 97140736
I0523 15:14:00.217936 21880 layer_factory.hpp:77] Creating layer bn4_1
I0523 15:14:00.217943 21880 net.cpp:91] Creating Layer bn4_1
I0523 15:14:00.217947 21880 net.cpp:425] bn4_1 <- conv4_1
I0523 15:14:00.217952 21880 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0523 15:14:00.218107 21880 net.cpp:141] Setting up bn4_1
I0523 15:14:00.218112 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.218114 21880 net.cpp:156] Memory required for data: 97943552
I0523 15:14:00.218119 21880 layer_factory.hpp:77] Creating layer scale4_1
I0523 15:14:00.218127 21880 net.cpp:91] Creating Layer scale4_1
I0523 15:14:00.218129 21880 net.cpp:425] scale4_1 <- conv4_1
I0523 15:14:00.218132 21880 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0523 15:14:00.218163 21880 layer_factory.hpp:77] Creating layer scale4_1
I0523 15:14:00.218246 21880 net.cpp:141] Setting up scale4_1
I0523 15:14:00.218251 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.218261 21880 net.cpp:156] Memory required for data: 98746368
I0523 15:14:00.218266 21880 layer_factory.hpp:77] Creating layer relu4_1
I0523 15:14:00.218274 21880 net.cpp:91] Creating Layer relu4_1
I0523 15:14:00.218276 21880 net.cpp:425] relu4_1 <- conv4_1
I0523 15:14:00.218281 21880 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0523 15:14:00.218508 21880 net.cpp:141] Setting up relu4_1
I0523 15:14:00.218518 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.218530 21880 net.cpp:156] Memory required for data: 99549184
I0523 15:14:00.218533 21880 layer_factory.hpp:77] Creating layer conv4_2
I0523 15:14:00.218541 21880 net.cpp:91] Creating Layer conv4_2
I0523 15:14:00.218544 21880 net.cpp:425] conv4_2 <- conv4_1
I0523 15:14:00.218549 21880 net.cpp:399] conv4_2 -> conv4_2
I0523 15:14:00.234134 21880 net.cpp:141] Setting up conv4_2
I0523 15:14:00.234163 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.234166 21880 net.cpp:156] Memory required for data: 100352000
I0523 15:14:00.234174 21880 layer_factory.hpp:77] Creating layer bn4_2
I0523 15:14:00.234184 21880 net.cpp:91] Creating Layer bn4_2
I0523 15:14:00.234189 21880 net.cpp:425] bn4_2 <- conv4_2
I0523 15:14:00.234194 21880 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0523 15:14:00.234386 21880 net.cpp:141] Setting up bn4_2
I0523 15:14:00.234392 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.234405 21880 net.cpp:156] Memory required for data: 101154816
I0523 15:14:00.234411 21880 layer_factory.hpp:77] Creating layer scale4_2
I0523 15:14:00.234421 21880 net.cpp:91] Creating Layer scale4_2
I0523 15:14:00.234424 21880 net.cpp:425] scale4_2 <- conv4_2
I0523 15:14:00.234428 21880 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0523 15:14:00.234493 21880 layer_factory.hpp:77] Creating layer scale4_2
I0523 15:14:00.234596 21880 net.cpp:141] Setting up scale4_2
I0523 15:14:00.234602 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.234616 21880 net.cpp:156] Memory required for data: 101957632
I0523 15:14:00.234619 21880 layer_factory.hpp:77] Creating layer relu4_2
I0523 15:14:00.234624 21880 net.cpp:91] Creating Layer relu4_2
I0523 15:14:00.234627 21880 net.cpp:425] relu4_2 <- conv4_2
I0523 15:14:00.234630 21880 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0523 15:14:00.234771 21880 net.cpp:141] Setting up relu4_2
I0523 15:14:00.234777 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.234791 21880 net.cpp:156] Memory required for data: 102760448
I0523 15:14:00.234792 21880 layer_factory.hpp:77] Creating layer pool4
I0523 15:14:00.234796 21880 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0523 15:14:00.234799 21880 net.cpp:91] Creating Layer pool4
I0523 15:14:00.234802 21880 net.cpp:425] pool4 <- conv4_2
I0523 15:14:00.234805 21880 net.cpp:399] pool4 -> pool4
I0523 15:14:00.234812 21880 net.cpp:399] pool4 -> pool4_mask
I0523 15:14:00.234843 21880 net.cpp:141] Setting up pool4
I0523 15:14:00.234846 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.234849 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.234851 21880 net.cpp:156] Memory required for data: 103161856
I0523 15:14:00.234853 21880 layer_factory.hpp:77] Creating layer conv5_1
I0523 15:14:00.234860 21880 net.cpp:91] Creating Layer conv5_1
I0523 15:14:00.234863 21880 net.cpp:425] conv5_1 <- pool4
I0523 15:14:00.234868 21880 net.cpp:399] conv5_1 -> conv5_1
I0523 15:14:00.249790 21880 net.cpp:141] Setting up conv5_1
I0523 15:14:00.249819 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.249821 21880 net.cpp:156] Memory required for data: 103362560
I0523 15:14:00.249827 21880 layer_factory.hpp:77] Creating layer bn5_1
I0523 15:14:00.249835 21880 net.cpp:91] Creating Layer bn5_1
I0523 15:14:00.249840 21880 net.cpp:425] bn5_1 <- conv5_1
I0523 15:14:00.249845 21880 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0523 15:14:00.250025 21880 net.cpp:141] Setting up bn5_1
I0523 15:14:00.250035 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.250049 21880 net.cpp:156] Memory required for data: 103563264
I0523 15:14:00.250059 21880 layer_factory.hpp:77] Creating layer scale5_1
I0523 15:14:00.250069 21880 net.cpp:91] Creating Layer scale5_1
I0523 15:14:00.250074 21880 net.cpp:425] scale5_1 <- conv5_1
I0523 15:14:00.250080 21880 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0523 15:14:00.250129 21880 layer_factory.hpp:77] Creating layer scale5_1
I0523 15:14:00.250219 21880 net.cpp:141] Setting up scale5_1
I0523 15:14:00.250224 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.250226 21880 net.cpp:156] Memory required for data: 103763968
I0523 15:14:00.250241 21880 layer_factory.hpp:77] Creating layer relu5_1
I0523 15:14:00.250247 21880 net.cpp:91] Creating Layer relu5_1
I0523 15:14:00.250248 21880 net.cpp:425] relu5_1 <- conv5_1
I0523 15:14:00.250252 21880 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0523 15:14:00.250393 21880 net.cpp:141] Setting up relu5_1
I0523 15:14:00.250399 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.250411 21880 net.cpp:156] Memory required for data: 103964672
I0523 15:14:00.250414 21880 layer_factory.hpp:77] Creating layer conv5_2
I0523 15:14:00.250422 21880 net.cpp:91] Creating Layer conv5_2
I0523 15:14:00.250424 21880 net.cpp:425] conv5_2 <- conv5_1
I0523 15:14:00.250428 21880 net.cpp:399] conv5_2 -> conv5_2
I0523 15:14:00.265666 21880 net.cpp:141] Setting up conv5_2
I0523 15:14:00.265696 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.265698 21880 net.cpp:156] Memory required for data: 104165376
I0523 15:14:00.265705 21880 layer_factory.hpp:77] Creating layer bn5_2
I0523 15:14:00.265717 21880 net.cpp:91] Creating Layer bn5_2
I0523 15:14:00.265720 21880 net.cpp:425] bn5_2 <- conv5_2
I0523 15:14:00.265727 21880 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0523 15:14:00.265890 21880 net.cpp:141] Setting up bn5_2
I0523 15:14:00.265897 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.265908 21880 net.cpp:156] Memory required for data: 104366080
I0523 15:14:00.265914 21880 layer_factory.hpp:77] Creating layer scale5_2
I0523 15:14:00.265921 21880 net.cpp:91] Creating Layer scale5_2
I0523 15:14:00.265923 21880 net.cpp:425] scale5_2 <- conv5_2
I0523 15:14:00.265928 21880 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0523 15:14:00.265957 21880 layer_factory.hpp:77] Creating layer scale5_2
I0523 15:14:00.266049 21880 net.cpp:141] Setting up scale5_2
I0523 15:14:00.266053 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.266065 21880 net.cpp:156] Memory required for data: 104566784
I0523 15:14:00.266070 21880 layer_factory.hpp:77] Creating layer relu5_2
I0523 15:14:00.266074 21880 net.cpp:91] Creating Layer relu5_2
I0523 15:14:00.266077 21880 net.cpp:425] relu5_2 <- conv5_2
I0523 15:14:00.266079 21880 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0523 15:14:00.266331 21880 net.cpp:141] Setting up relu5_2
I0523 15:14:00.266351 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.266355 21880 net.cpp:156] Memory required for data: 104767488
I0523 15:14:00.266356 21880 layer_factory.hpp:77] Creating layer pool5
I0523 15:14:00.266360 21880 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0523 15:14:00.266365 21880 net.cpp:91] Creating Layer pool5
I0523 15:14:00.266366 21880 net.cpp:425] pool5 <- conv5_2
I0523 15:14:00.266371 21880 net.cpp:399] pool5 -> pool5
I0523 15:14:00.266376 21880 net.cpp:399] pool5 -> pool5_mask
I0523 15:14:00.266412 21880 net.cpp:141] Setting up pool5
I0523 15:14:00.266417 21880 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0523 15:14:00.266420 21880 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0523 15:14:00.266422 21880 net.cpp:156] Memory required for data: 104867840
I0523 15:14:00.266424 21880 layer_factory.hpp:77] Creating layer upsample5
I0523 15:14:00.266430 21880 net.cpp:91] Creating Layer upsample5
I0523 15:14:00.266433 21880 net.cpp:425] upsample5 <- pool5
I0523 15:14:00.266435 21880 net.cpp:425] upsample5 <- pool5_mask
I0523 15:14:00.266438 21880 net.cpp:399] upsample5 -> pool5_D
I0523 15:14:00.266477 21880 net.cpp:141] Setting up upsample5
I0523 15:14:00.266496 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.266500 21880 net.cpp:156] Memory required for data: 105068544
I0523 15:14:00.266504 21880 layer_factory.hpp:77] Creating layer conv5_2_D
I0523 15:14:00.266511 21880 net.cpp:91] Creating Layer conv5_2_D
I0523 15:14:00.266515 21880 net.cpp:425] conv5_2_D <- pool5_D
I0523 15:14:00.266518 21880 net.cpp:399] conv5_2_D -> conv5_2_D
I0523 15:14:00.281366 21880 net.cpp:141] Setting up conv5_2_D
I0523 15:14:00.281390 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.281394 21880 net.cpp:156] Memory required for data: 105269248
I0523 15:14:00.281399 21880 layer_factory.hpp:77] Creating layer bn5_2_D
I0523 15:14:00.281407 21880 net.cpp:91] Creating Layer bn5_2_D
I0523 15:14:00.281410 21880 net.cpp:425] bn5_2_D <- conv5_2_D
I0523 15:14:00.281414 21880 net.cpp:386] bn5_2_D -> conv5_2_D (in-place)
I0523 15:14:00.281569 21880 net.cpp:141] Setting up bn5_2_D
I0523 15:14:00.281574 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.281576 21880 net.cpp:156] Memory required for data: 105469952
I0523 15:14:00.281581 21880 layer_factory.hpp:77] Creating layer scale5_2_D
I0523 15:14:00.281587 21880 net.cpp:91] Creating Layer scale5_2_D
I0523 15:14:00.281589 21880 net.cpp:425] scale5_2_D <- conv5_2_D
I0523 15:14:00.281595 21880 net.cpp:386] scale5_2_D -> conv5_2_D (in-place)
I0523 15:14:00.281625 21880 layer_factory.hpp:77] Creating layer scale5_2_D
I0523 15:14:00.281707 21880 net.cpp:141] Setting up scale5_2_D
I0523 15:14:00.281711 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.281714 21880 net.cpp:156] Memory required for data: 105670656
I0523 15:14:00.281728 21880 layer_factory.hpp:77] Creating layer relu5_2_D
I0523 15:14:00.281733 21880 net.cpp:91] Creating Layer relu5_2_D
I0523 15:14:00.281734 21880 net.cpp:425] relu5_2_D <- conv5_2_D
I0523 15:14:00.281738 21880 net.cpp:386] relu5_2_D -> conv5_2_D (in-place)
I0523 15:14:00.281875 21880 net.cpp:141] Setting up relu5_2_D
I0523 15:14:00.281883 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.281884 21880 net.cpp:156] Memory required for data: 105871360
I0523 15:14:00.281886 21880 layer_factory.hpp:77] Creating layer conv5_1_D
I0523 15:14:00.281894 21880 net.cpp:91] Creating Layer conv5_1_D
I0523 15:14:00.281898 21880 net.cpp:425] conv5_1_D <- conv5_2_D
I0523 15:14:00.281901 21880 net.cpp:399] conv5_1_D -> conv5_1_D
I0523 15:14:00.297214 21880 net.cpp:141] Setting up conv5_1_D
I0523 15:14:00.297242 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.297245 21880 net.cpp:156] Memory required for data: 106072064
I0523 15:14:00.297252 21880 layer_factory.hpp:77] Creating layer bn5_1_D
I0523 15:14:00.297260 21880 net.cpp:91] Creating Layer bn5_1_D
I0523 15:14:00.297265 21880 net.cpp:425] bn5_1_D <- conv5_1_D
I0523 15:14:00.297271 21880 net.cpp:386] bn5_1_D -> conv5_1_D (in-place)
I0523 15:14:00.297435 21880 net.cpp:141] Setting up bn5_1_D
I0523 15:14:00.297441 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.297452 21880 net.cpp:156] Memory required for data: 106272768
I0523 15:14:00.297457 21880 layer_factory.hpp:77] Creating layer scale5_1_D
I0523 15:14:00.297464 21880 net.cpp:91] Creating Layer scale5_1_D
I0523 15:14:00.297466 21880 net.cpp:425] scale5_1_D <- conv5_1_D
I0523 15:14:00.297471 21880 net.cpp:386] scale5_1_D -> conv5_1_D (in-place)
I0523 15:14:00.297500 21880 layer_factory.hpp:77] Creating layer scale5_1_D
I0523 15:14:00.297591 21880 net.cpp:141] Setting up scale5_1_D
I0523 15:14:00.297597 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.297610 21880 net.cpp:156] Memory required for data: 106473472
I0523 15:14:00.297613 21880 layer_factory.hpp:77] Creating layer relu5_1_D
I0523 15:14:00.297618 21880 net.cpp:91] Creating Layer relu5_1_D
I0523 15:14:00.297621 21880 net.cpp:425] relu5_1_D <- conv5_1_D
I0523 15:14:00.297624 21880 net.cpp:386] relu5_1_D -> conv5_1_D (in-place)
I0523 15:14:00.297767 21880 net.cpp:141] Setting up relu5_1_D
I0523 15:14:00.297785 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.297797 21880 net.cpp:156] Memory required for data: 106674176
I0523 15:14:00.297801 21880 layer_factory.hpp:77] Creating layer upsample4
I0523 15:14:00.297806 21880 net.cpp:91] Creating Layer upsample4
I0523 15:14:00.297808 21880 net.cpp:425] upsample4 <- conv5_1_D
I0523 15:14:00.297812 21880 net.cpp:425] upsample4 <- pool4_mask
I0523 15:14:00.297816 21880 net.cpp:399] upsample4 -> pool4_D
I0523 15:14:00.297839 21880 net.cpp:141] Setting up upsample4
I0523 15:14:00.297842 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.297844 21880 net.cpp:156] Memory required for data: 107476992
I0523 15:14:00.297847 21880 layer_factory.hpp:77] Creating layer conv4_2_D
I0523 15:14:00.297854 21880 net.cpp:91] Creating Layer conv4_2_D
I0523 15:14:00.297857 21880 net.cpp:425] conv4_2_D <- pool4_D
I0523 15:14:00.297862 21880 net.cpp:399] conv4_2_D -> conv4_2_D
I0523 15:14:00.312733 21880 net.cpp:141] Setting up conv4_2_D
I0523 15:14:00.312760 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.312763 21880 net.cpp:156] Memory required for data: 108279808
I0523 15:14:00.312769 21880 layer_factory.hpp:77] Creating layer bn4_2_D
I0523 15:14:00.312778 21880 net.cpp:91] Creating Layer bn4_2_D
I0523 15:14:00.312783 21880 net.cpp:425] bn4_2_D <- conv4_2_D
I0523 15:14:00.312788 21880 net.cpp:386] bn4_2_D -> conv4_2_D (in-place)
I0523 15:14:00.312990 21880 net.cpp:141] Setting up bn4_2_D
I0523 15:14:00.312997 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.312999 21880 net.cpp:156] Memory required for data: 109082624
I0523 15:14:00.313005 21880 layer_factory.hpp:77] Creating layer scale4_2_D
I0523 15:14:00.313012 21880 net.cpp:91] Creating Layer scale4_2_D
I0523 15:14:00.313015 21880 net.cpp:425] scale4_2_D <- conv4_2_D
I0523 15:14:00.313019 21880 net.cpp:386] scale4_2_D -> conv4_2_D (in-place)
I0523 15:14:00.313051 21880 layer_factory.hpp:77] Creating layer scale4_2_D
I0523 15:14:00.313144 21880 net.cpp:141] Setting up scale4_2_D
I0523 15:14:00.313149 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.313153 21880 net.cpp:156] Memory required for data: 109885440
I0523 15:14:00.313156 21880 layer_factory.hpp:77] Creating layer relu4_2_D
I0523 15:14:00.313161 21880 net.cpp:91] Creating Layer relu4_2_D
I0523 15:14:00.313163 21880 net.cpp:425] relu4_2_D <- conv4_2_D
I0523 15:14:00.313166 21880 net.cpp:386] relu4_2_D -> conv4_2_D (in-place)
I0523 15:14:00.313419 21880 net.cpp:141] Setting up relu4_2_D
I0523 15:14:00.313428 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.313442 21880 net.cpp:156] Memory required for data: 110688256
I0523 15:14:00.313446 21880 layer_factory.hpp:77] Creating layer conv4_1_D
I0523 15:14:00.313453 21880 net.cpp:91] Creating Layer conv4_1_D
I0523 15:14:00.313457 21880 net.cpp:425] conv4_1_D <- conv4_2_D
I0523 15:14:00.313462 21880 net.cpp:399] conv4_1_D -> conv4_1_D
I0523 15:14:00.321692 21880 net.cpp:141] Setting up conv4_1_D
I0523 15:14:00.321717 21880 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0523 15:14:00.321720 21880 net.cpp:156] Memory required for data: 111089664
I0523 15:14:00.321727 21880 layer_factory.hpp:77] Creating layer bn4_1_D
I0523 15:14:00.321734 21880 net.cpp:91] Creating Layer bn4_1_D
I0523 15:14:00.321738 21880 net.cpp:425] bn4_1_D <- conv4_1_D
I0523 15:14:00.321743 21880 net.cpp:386] bn4_1_D -> conv4_1_D (in-place)
I0523 15:14:00.321918 21880 net.cpp:141] Setting up bn4_1_D
I0523 15:14:00.321923 21880 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0523 15:14:00.321935 21880 net.cpp:156] Memory required for data: 111491072
I0523 15:14:00.321940 21880 layer_factory.hpp:77] Creating layer scale4_1_D
I0523 15:14:00.321948 21880 net.cpp:91] Creating Layer scale4_1_D
I0523 15:14:00.321950 21880 net.cpp:425] scale4_1_D <- conv4_1_D
I0523 15:14:00.321954 21880 net.cpp:386] scale4_1_D -> conv4_1_D (in-place)
I0523 15:14:00.321985 21880 layer_factory.hpp:77] Creating layer scale4_1_D
I0523 15:14:00.322088 21880 net.cpp:141] Setting up scale4_1_D
I0523 15:14:00.322103 21880 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0523 15:14:00.322115 21880 net.cpp:156] Memory required for data: 111892480
I0523 15:14:00.322119 21880 layer_factory.hpp:77] Creating layer relu4_1_D
I0523 15:14:00.322132 21880 net.cpp:91] Creating Layer relu4_1_D
I0523 15:14:00.322135 21880 net.cpp:425] relu4_1_D <- conv4_1_D
I0523 15:14:00.322139 21880 net.cpp:386] relu4_1_D -> conv4_1_D (in-place)
I0523 15:14:00.322285 21880 net.cpp:141] Setting up relu4_1_D
I0523 15:14:00.322291 21880 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0523 15:14:00.322304 21880 net.cpp:156] Memory required for data: 112293888
I0523 15:14:00.322306 21880 layer_factory.hpp:77] Creating layer upsample3
I0523 15:14:00.322312 21880 net.cpp:91] Creating Layer upsample3
I0523 15:14:00.322315 21880 net.cpp:425] upsample3 <- conv4_1_D
I0523 15:14:00.322319 21880 net.cpp:425] upsample3 <- pool3_mask
I0523 15:14:00.322321 21880 net.cpp:399] upsample3 -> pool3_D
I0523 15:14:00.322345 21880 net.cpp:141] Setting up upsample3
I0523 15:14:00.322348 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.322350 21880 net.cpp:156] Memory required for data: 113899520
I0523 15:14:00.322352 21880 layer_factory.hpp:77] Creating layer conv3_2_D
I0523 15:14:00.322360 21880 net.cpp:91] Creating Layer conv3_2_D
I0523 15:14:00.322362 21880 net.cpp:425] conv3_2_D <- pool3_D
I0523 15:14:00.322367 21880 net.cpp:399] conv3_2_D -> conv3_2_D
I0523 15:14:00.326982 21880 net.cpp:141] Setting up conv3_2_D
I0523 15:14:00.327003 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.327006 21880 net.cpp:156] Memory required for data: 115505152
I0523 15:14:00.327011 21880 layer_factory.hpp:77] Creating layer bn3_2_D
I0523 15:14:00.327018 21880 net.cpp:91] Creating Layer bn3_2_D
I0523 15:14:00.327021 21880 net.cpp:425] bn3_2_D <- conv3_2_D
I0523 15:14:00.327025 21880 net.cpp:386] bn3_2_D -> conv3_2_D (in-place)
I0523 15:14:00.327186 21880 net.cpp:141] Setting up bn3_2_D
I0523 15:14:00.327191 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.327204 21880 net.cpp:156] Memory required for data: 117110784
I0523 15:14:00.327210 21880 layer_factory.hpp:77] Creating layer scale3_2_D
I0523 15:14:00.327216 21880 net.cpp:91] Creating Layer scale3_2_D
I0523 15:14:00.327219 21880 net.cpp:425] scale3_2_D <- conv3_2_D
I0523 15:14:00.327221 21880 net.cpp:386] scale3_2_D -> conv3_2_D (in-place)
I0523 15:14:00.327251 21880 layer_factory.hpp:77] Creating layer scale3_2_D
I0523 15:14:00.327369 21880 net.cpp:141] Setting up scale3_2_D
I0523 15:14:00.327374 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.327376 21880 net.cpp:156] Memory required for data: 118716416
I0523 15:14:00.327390 21880 layer_factory.hpp:77] Creating layer relu3_2_D
I0523 15:14:00.327394 21880 net.cpp:91] Creating Layer relu3_2_D
I0523 15:14:00.327396 21880 net.cpp:425] relu3_2_D <- conv3_2_D
I0523 15:14:00.327400 21880 net.cpp:386] relu3_2_D -> conv3_2_D (in-place)
I0523 15:14:00.327541 21880 net.cpp:141] Setting up relu3_2_D
I0523 15:14:00.327548 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.327559 21880 net.cpp:156] Memory required for data: 120322048
I0523 15:14:00.327563 21880 layer_factory.hpp:77] Creating layer conv3_1_D
I0523 15:14:00.327569 21880 net.cpp:91] Creating Layer conv3_1_D
I0523 15:14:00.327571 21880 net.cpp:425] conv3_1_D <- conv3_2_D
I0523 15:14:00.327576 21880 net.cpp:399] conv3_1_D -> conv3_1_D
I0523 15:14:00.330291 21880 net.cpp:141] Setting up conv3_1_D
I0523 15:14:00.330312 21880 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0523 15:14:00.330314 21880 net.cpp:156] Memory required for data: 121124864
I0523 15:14:00.330318 21880 layer_factory.hpp:77] Creating layer bn3_1_D
I0523 15:14:00.330323 21880 net.cpp:91] Creating Layer bn3_1_D
I0523 15:14:00.330327 21880 net.cpp:425] bn3_1_D <- conv3_1_D
I0523 15:14:00.330330 21880 net.cpp:386] bn3_1_D -> conv3_1_D (in-place)
I0523 15:14:00.330513 21880 net.cpp:141] Setting up bn3_1_D
I0523 15:14:00.330530 21880 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0523 15:14:00.330543 21880 net.cpp:156] Memory required for data: 121927680
I0523 15:14:00.330549 21880 layer_factory.hpp:77] Creating layer scale3_1_D
I0523 15:14:00.330555 21880 net.cpp:91] Creating Layer scale3_1_D
I0523 15:14:00.330559 21880 net.cpp:425] scale3_1_D <- conv3_1_D
I0523 15:14:00.330561 21880 net.cpp:386] scale3_1_D -> conv3_1_D (in-place)
I0523 15:14:00.330605 21880 layer_factory.hpp:77] Creating layer scale3_1_D
I0523 15:14:00.330719 21880 net.cpp:141] Setting up scale3_1_D
I0523 15:14:00.330724 21880 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0523 15:14:00.330736 21880 net.cpp:156] Memory required for data: 122730496
I0523 15:14:00.330740 21880 layer_factory.hpp:77] Creating layer relu3_1_D
I0523 15:14:00.330744 21880 net.cpp:91] Creating Layer relu3_1_D
I0523 15:14:00.330746 21880 net.cpp:425] relu3_1_D <- conv3_1_D
I0523 15:14:00.330750 21880 net.cpp:386] relu3_1_D -> conv3_1_D (in-place)
I0523 15:14:00.330974 21880 net.cpp:141] Setting up relu3_1_D
I0523 15:14:00.330982 21880 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0523 15:14:00.330996 21880 net.cpp:156] Memory required for data: 123533312
I0523 15:14:00.330997 21880 layer_factory.hpp:77] Creating layer upsample2
I0523 15:14:00.331003 21880 net.cpp:91] Creating Layer upsample2
I0523 15:14:00.331006 21880 net.cpp:425] upsample2 <- conv3_1_D
I0523 15:14:00.331009 21880 net.cpp:425] upsample2 <- pool2_mask
I0523 15:14:00.331013 21880 net.cpp:399] upsample2 -> pool2_D
I0523 15:14:00.331037 21880 net.cpp:141] Setting up upsample2
I0523 15:14:00.331040 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.331043 21880 net.cpp:156] Memory required for data: 126744576
I0523 15:14:00.331044 21880 layer_factory.hpp:77] Creating layer conv2_2_D
I0523 15:14:00.331051 21880 net.cpp:91] Creating Layer conv2_2_D
I0523 15:14:00.331054 21880 net.cpp:425] conv2_2_D <- pool2_D
I0523 15:14:00.331058 21880 net.cpp:399] conv2_2_D -> conv2_2_D
I0523 15:14:00.332729 21880 net.cpp:141] Setting up conv2_2_D
I0523 15:14:00.332739 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.332741 21880 net.cpp:156] Memory required for data: 129955840
I0523 15:14:00.332746 21880 layer_factory.hpp:77] Creating layer bn2_2_D
I0523 15:14:00.332751 21880 net.cpp:91] Creating Layer bn2_2_D
I0523 15:14:00.332754 21880 net.cpp:425] bn2_2_D <- conv2_2_D
I0523 15:14:00.332759 21880 net.cpp:386] bn2_2_D -> conv2_2_D (in-place)
I0523 15:14:00.332933 21880 net.cpp:141] Setting up bn2_2_D
I0523 15:14:00.332938 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.332950 21880 net.cpp:156] Memory required for data: 133167104
I0523 15:14:00.332955 21880 layer_factory.hpp:77] Creating layer scale2_2_D
I0523 15:14:00.332960 21880 net.cpp:91] Creating Layer scale2_2_D
I0523 15:14:00.332962 21880 net.cpp:425] scale2_2_D <- conv2_2_D
I0523 15:14:00.332965 21880 net.cpp:386] scale2_2_D -> conv2_2_D (in-place)
I0523 15:14:00.333005 21880 layer_factory.hpp:77] Creating layer scale2_2_D
I0523 15:14:00.333118 21880 net.cpp:141] Setting up scale2_2_D
I0523 15:14:00.333123 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.333125 21880 net.cpp:156] Memory required for data: 136378368
I0523 15:14:00.333129 21880 layer_factory.hpp:77] Creating layer relu2_2_D
I0523 15:14:00.333134 21880 net.cpp:91] Creating Layer relu2_2_D
I0523 15:14:00.333137 21880 net.cpp:425] relu2_2_D <- conv2_2_D
I0523 15:14:00.333139 21880 net.cpp:386] relu2_2_D -> conv2_2_D (in-place)
I0523 15:14:00.333277 21880 net.cpp:141] Setting up relu2_2_D
I0523 15:14:00.333283 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.333295 21880 net.cpp:156] Memory required for data: 139589632
I0523 15:14:00.333298 21880 layer_factory.hpp:77] Creating layer conv2_1_D
I0523 15:14:00.333305 21880 net.cpp:91] Creating Layer conv2_1_D
I0523 15:14:00.333308 21880 net.cpp:425] conv2_1_D <- conv2_2_D
I0523 15:14:00.333312 21880 net.cpp:399] conv2_1_D -> conv2_1_D
I0523 15:14:00.334434 21880 net.cpp:141] Setting up conv2_1_D
I0523 15:14:00.334442 21880 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0523 15:14:00.334463 21880 net.cpp:156] Memory required for data: 141195264
I0523 15:14:00.334468 21880 layer_factory.hpp:77] Creating layer bn2_1_D
I0523 15:14:00.334481 21880 net.cpp:91] Creating Layer bn2_1_D
I0523 15:14:00.334486 21880 net.cpp:425] bn2_1_D <- conv2_1_D
I0523 15:14:00.334491 21880 net.cpp:386] bn2_1_D -> conv2_1_D (in-place)
I0523 15:14:00.334666 21880 net.cpp:141] Setting up bn2_1_D
I0523 15:14:00.334671 21880 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0523 15:14:00.334684 21880 net.cpp:156] Memory required for data: 142800896
I0523 15:14:00.334689 21880 layer_factory.hpp:77] Creating layer scale2_1_D
I0523 15:14:00.334694 21880 net.cpp:91] Creating Layer scale2_1_D
I0523 15:14:00.334697 21880 net.cpp:425] scale2_1_D <- conv2_1_D
I0523 15:14:00.334699 21880 net.cpp:386] scale2_1_D -> conv2_1_D (in-place)
I0523 15:14:00.334739 21880 layer_factory.hpp:77] Creating layer scale2_1_D
I0523 15:14:00.334859 21880 net.cpp:141] Setting up scale2_1_D
I0523 15:14:00.334863 21880 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0523 15:14:00.334877 21880 net.cpp:156] Memory required for data: 144406528
I0523 15:14:00.334879 21880 layer_factory.hpp:77] Creating layer relu2_1_D
I0523 15:14:00.334883 21880 net.cpp:91] Creating Layer relu2_1_D
I0523 15:14:00.334887 21880 net.cpp:425] relu2_1_D <- conv2_1_D
I0523 15:14:00.334889 21880 net.cpp:386] relu2_1_D -> conv2_1_D (in-place)
I0523 15:14:00.335031 21880 net.cpp:141] Setting up relu2_1_D
I0523 15:14:00.335036 21880 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0523 15:14:00.335049 21880 net.cpp:156] Memory required for data: 146012160
I0523 15:14:00.335052 21880 layer_factory.hpp:77] Creating layer upsample1
I0523 15:14:00.335057 21880 net.cpp:91] Creating Layer upsample1
I0523 15:14:00.335058 21880 net.cpp:425] upsample1 <- conv2_1_D
I0523 15:14:00.335062 21880 net.cpp:425] upsample1 <- pool1_mask
I0523 15:14:00.335065 21880 net.cpp:399] upsample1 -> pool1_D
I0523 15:14:00.335099 21880 net.cpp:141] Setting up upsample1
I0523 15:14:00.335103 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.335104 21880 net.cpp:156] Memory required for data: 152434688
I0523 15:14:00.335117 21880 layer_factory.hpp:77] Creating layer conv1_2_D
I0523 15:14:00.335124 21880 net.cpp:91] Creating Layer conv1_2_D
I0523 15:14:00.335125 21880 net.cpp:425] conv1_2_D <- pool1_D
I0523 15:14:00.335130 21880 net.cpp:399] conv1_2_D -> conv1_2_D
I0523 15:14:00.336138 21880 net.cpp:141] Setting up conv1_2_D
I0523 15:14:00.336148 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.336159 21880 net.cpp:156] Memory required for data: 158857216
I0523 15:14:00.336163 21880 layer_factory.hpp:77] Creating layer bn1_2_D
I0523 15:14:00.336169 21880 net.cpp:91] Creating Layer bn1_2_D
I0523 15:14:00.336171 21880 net.cpp:425] bn1_2_D <- conv1_2_D
I0523 15:14:00.336175 21880 net.cpp:386] bn1_2_D -> conv1_2_D (in-place)
I0523 15:14:00.336377 21880 net.cpp:141] Setting up bn1_2_D
I0523 15:14:00.336382 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.336385 21880 net.cpp:156] Memory required for data: 165279744
I0523 15:14:00.336400 21880 layer_factory.hpp:77] Creating layer scale1_2_D
I0523 15:14:00.336403 21880 net.cpp:91] Creating Layer scale1_2_D
I0523 15:14:00.336405 21880 net.cpp:425] scale1_2_D <- conv1_2_D
I0523 15:14:00.336410 21880 net.cpp:386] scale1_2_D -> conv1_2_D (in-place)
I0523 15:14:00.336449 21880 layer_factory.hpp:77] Creating layer scale1_2_D
I0523 15:14:00.336627 21880 net.cpp:141] Setting up scale1_2_D
I0523 15:14:00.336632 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.336644 21880 net.cpp:156] Memory required for data: 171702272
I0523 15:14:00.336648 21880 layer_factory.hpp:77] Creating layer relu1_2_D
I0523 15:14:00.336653 21880 net.cpp:91] Creating Layer relu1_2_D
I0523 15:14:00.336655 21880 net.cpp:425] relu1_2_D <- conv1_2_D
I0523 15:14:00.336658 21880 net.cpp:386] relu1_2_D -> conv1_2_D (in-place)
I0523 15:14:00.336889 21880 net.cpp:141] Setting up relu1_2_D
I0523 15:14:00.336897 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.336908 21880 net.cpp:156] Memory required for data: 178124800
I0523 15:14:00.336911 21880 layer_factory.hpp:77] Creating layer conv1_1_D
I0523 15:14:00.336920 21880 net.cpp:91] Creating Layer conv1_1_D
I0523 15:14:00.336921 21880 net.cpp:425] conv1_1_D <- conv1_2_D
I0523 15:14:00.336926 21880 net.cpp:399] conv1_1_D -> conv1_1_D
I0523 15:14:00.338037 21880 net.cpp:141] Setting up conv1_1_D
I0523 15:14:00.338055 21880 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0523 15:14:00.338058 21880 net.cpp:156] Memory required for data: 178526208
I0523 15:14:00.338064 21880 layer_factory.hpp:77] Creating layer conv1_1_D_conv1_1_D_0_split
I0523 15:14:00.338070 21880 net.cpp:91] Creating Layer conv1_1_D_conv1_1_D_0_split
I0523 15:14:00.338073 21880 net.cpp:425] conv1_1_D_conv1_1_D_0_split <- conv1_1_D
I0523 15:14:00.338078 21880 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_0
I0523 15:14:00.338083 21880 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_1
I0523 15:14:00.338131 21880 net.cpp:141] Setting up conv1_1_D_conv1_1_D_0_split
I0523 15:14:00.338135 21880 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0523 15:14:00.338148 21880 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0523 15:14:00.338150 21880 net.cpp:156] Memory required for data: 179329024
I0523 15:14:00.338152 21880 layer_factory.hpp:77] Creating layer loss
I0523 15:14:00.338160 21880 net.cpp:91] Creating Layer loss
I0523 15:14:00.338163 21880 net.cpp:425] loss <- conv1_1_D_conv1_1_D_0_split_0
I0523 15:14:00.338166 21880 net.cpp:425] loss <- label_data_1_split_0
I0523 15:14:00.338171 21880 net.cpp:399] loss -> loss
I0523 15:14:00.338177 21880 layer_factory.hpp:77] Creating layer loss
I0523 15:14:00.338744 21880 net.cpp:141] Setting up loss
I0523 15:14:00.338752 21880 net.cpp:148] Top shape: (1)
I0523 15:14:00.338765 21880 net.cpp:151]     with loss weight 1
I0523 15:14:00.338779 21880 net.cpp:156] Memory required for data: 179329028
I0523 15:14:00.338781 21880 layer_factory.hpp:77] Creating layer accuracy
I0523 15:14:00.338789 21880 net.cpp:91] Creating Layer accuracy
I0523 15:14:00.338793 21880 net.cpp:425] accuracy <- conv1_1_D_conv1_1_D_0_split_1
I0523 15:14:00.338796 21880 net.cpp:425] accuracy <- label_data_1_split_1
I0523 15:14:00.338800 21880 net.cpp:399] accuracy -> accuracy
I0523 15:14:00.338806 21880 net.cpp:141] Setting up accuracy
I0523 15:14:00.338809 21880 net.cpp:148] Top shape: (1)
I0523 15:14:00.338811 21880 net.cpp:156] Memory required for data: 179329032
I0523 15:14:00.338814 21880 net.cpp:219] accuracy does not need backward computation.
I0523 15:14:00.338816 21880 net.cpp:217] loss needs backward computation.
I0523 15:14:00.338819 21880 net.cpp:217] conv1_1_D_conv1_1_D_0_split needs backward computation.
I0523 15:14:00.338821 21880 net.cpp:217] conv1_1_D needs backward computation.
I0523 15:14:00.338824 21880 net.cpp:217] relu1_2_D needs backward computation.
I0523 15:14:00.338825 21880 net.cpp:217] scale1_2_D needs backward computation.
I0523 15:14:00.338827 21880 net.cpp:217] bn1_2_D needs backward computation.
I0523 15:14:00.338829 21880 net.cpp:217] conv1_2_D needs backward computation.
I0523 15:14:00.338831 21880 net.cpp:217] upsample1 needs backward computation.
I0523 15:14:00.338834 21880 net.cpp:217] relu2_1_D needs backward computation.
I0523 15:14:00.338835 21880 net.cpp:217] scale2_1_D needs backward computation.
I0523 15:14:00.338837 21880 net.cpp:217] bn2_1_D needs backward computation.
I0523 15:14:00.338838 21880 net.cpp:217] conv2_1_D needs backward computation.
I0523 15:14:00.338841 21880 net.cpp:217] relu2_2_D needs backward computation.
I0523 15:14:00.338842 21880 net.cpp:217] scale2_2_D needs backward computation.
I0523 15:14:00.338845 21880 net.cpp:217] bn2_2_D needs backward computation.
I0523 15:14:00.338846 21880 net.cpp:217] conv2_2_D needs backward computation.
I0523 15:14:00.338848 21880 net.cpp:217] upsample2 needs backward computation.
I0523 15:14:00.338851 21880 net.cpp:217] relu3_1_D needs backward computation.
I0523 15:14:00.338861 21880 net.cpp:217] scale3_1_D needs backward computation.
I0523 15:14:00.338863 21880 net.cpp:217] bn3_1_D needs backward computation.
I0523 15:14:00.338865 21880 net.cpp:217] conv3_1_D needs backward computation.
I0523 15:14:00.338867 21880 net.cpp:217] relu3_2_D needs backward computation.
I0523 15:14:00.338871 21880 net.cpp:217] scale3_2_D needs backward computation.
I0523 15:14:00.338871 21880 net.cpp:217] bn3_2_D needs backward computation.
I0523 15:14:00.338873 21880 net.cpp:217] conv3_2_D needs backward computation.
I0523 15:14:00.338876 21880 net.cpp:217] upsample3 needs backward computation.
I0523 15:14:00.338878 21880 net.cpp:217] relu4_1_D needs backward computation.
I0523 15:14:00.338881 21880 net.cpp:217] scale4_1_D needs backward computation.
I0523 15:14:00.338882 21880 net.cpp:217] bn4_1_D needs backward computation.
I0523 15:14:00.338884 21880 net.cpp:217] conv4_1_D needs backward computation.
I0523 15:14:00.338897 21880 net.cpp:217] relu4_2_D needs backward computation.
I0523 15:14:00.338899 21880 net.cpp:217] scale4_2_D needs backward computation.
I0523 15:14:00.338901 21880 net.cpp:217] bn4_2_D needs backward computation.
I0523 15:14:00.338903 21880 net.cpp:217] conv4_2_D needs backward computation.
I0523 15:14:00.338906 21880 net.cpp:217] upsample4 needs backward computation.
I0523 15:14:00.338908 21880 net.cpp:217] relu5_1_D needs backward computation.
I0523 15:14:00.338910 21880 net.cpp:217] scale5_1_D needs backward computation.
I0523 15:14:00.338912 21880 net.cpp:217] bn5_1_D needs backward computation.
I0523 15:14:00.338914 21880 net.cpp:217] conv5_1_D needs backward computation.
I0523 15:14:00.338917 21880 net.cpp:217] relu5_2_D needs backward computation.
I0523 15:14:00.338919 21880 net.cpp:217] scale5_2_D needs backward computation.
I0523 15:14:00.338922 21880 net.cpp:217] bn5_2_D needs backward computation.
I0523 15:14:00.338923 21880 net.cpp:217] conv5_2_D needs backward computation.
I0523 15:14:00.338925 21880 net.cpp:217] upsample5 needs backward computation.
I0523 15:14:00.338928 21880 net.cpp:217] pool5 needs backward computation.
I0523 15:14:00.338940 21880 net.cpp:217] relu5_2 needs backward computation.
I0523 15:14:00.338943 21880 net.cpp:217] scale5_2 needs backward computation.
I0523 15:14:00.338945 21880 net.cpp:217] bn5_2 needs backward computation.
I0523 15:14:00.338948 21880 net.cpp:217] conv5_2 needs backward computation.
I0523 15:14:00.338950 21880 net.cpp:217] relu5_1 needs backward computation.
I0523 15:14:00.338953 21880 net.cpp:217] scale5_1 needs backward computation.
I0523 15:14:00.338954 21880 net.cpp:217] bn5_1 needs backward computation.
I0523 15:14:00.338956 21880 net.cpp:217] conv5_1 needs backward computation.
I0523 15:14:00.338958 21880 net.cpp:217] pool4 needs backward computation.
I0523 15:14:00.338961 21880 net.cpp:217] relu4_2 needs backward computation.
I0523 15:14:00.338963 21880 net.cpp:217] scale4_2 needs backward computation.
I0523 15:14:00.338965 21880 net.cpp:217] bn4_2 needs backward computation.
I0523 15:14:00.338968 21880 net.cpp:217] conv4_2 needs backward computation.
I0523 15:14:00.338969 21880 net.cpp:217] relu4_1 needs backward computation.
I0523 15:14:00.338971 21880 net.cpp:217] scale4_1 needs backward computation.
I0523 15:14:00.338973 21880 net.cpp:217] bn4_1 needs backward computation.
I0523 15:14:00.338975 21880 net.cpp:217] conv4_1 needs backward computation.
I0523 15:14:00.338978 21880 net.cpp:217] pool3 needs backward computation.
I0523 15:14:00.338980 21880 net.cpp:217] relu3_2 needs backward computation.
I0523 15:14:00.338982 21880 net.cpp:217] scale3_2 needs backward computation.
I0523 15:14:00.338984 21880 net.cpp:217] bn3_2 needs backward computation.
I0523 15:14:00.338986 21880 net.cpp:217] conv3_2 needs backward computation.
I0523 15:14:00.338989 21880 net.cpp:217] relu3_1 needs backward computation.
I0523 15:14:00.338990 21880 net.cpp:217] scale3_1 needs backward computation.
I0523 15:14:00.338992 21880 net.cpp:217] bn3_1 needs backward computation.
I0523 15:14:00.338994 21880 net.cpp:217] conv3_1 needs backward computation.
I0523 15:14:00.339000 21880 net.cpp:217] pool2 needs backward computation.
I0523 15:14:00.339002 21880 net.cpp:217] relu2_2 needs backward computation.
I0523 15:14:00.339004 21880 net.cpp:217] scale2_2 needs backward computation.
I0523 15:14:00.339006 21880 net.cpp:217] bn2_2 needs backward computation.
I0523 15:14:00.339009 21880 net.cpp:217] conv2_2 needs backward computation.
I0523 15:14:00.339010 21880 net.cpp:217] relu2_1 needs backward computation.
I0523 15:14:00.339012 21880 net.cpp:217] scale2_1 needs backward computation.
I0523 15:14:00.339015 21880 net.cpp:217] bn2_1 needs backward computation.
I0523 15:14:00.339016 21880 net.cpp:217] conv2_1 needs backward computation.
I0523 15:14:00.339020 21880 net.cpp:217] pool1 needs backward computation.
I0523 15:14:00.339021 21880 net.cpp:217] relu1_2 needs backward computation.
I0523 15:14:00.339023 21880 net.cpp:217] scale1_2 needs backward computation.
I0523 15:14:00.339025 21880 net.cpp:217] bn1_2 needs backward computation.
I0523 15:14:00.339027 21880 net.cpp:217] conv1_2 needs backward computation.
I0523 15:14:00.339030 21880 net.cpp:217] relu1_1 needs backward computation.
I0523 15:14:00.339031 21880 net.cpp:217] scale1_1 needs backward computation.
I0523 15:14:00.339033 21880 net.cpp:217] bn1_1 needs backward computation.
I0523 15:14:00.339035 21880 net.cpp:217] conv1_1 needs backward computation.
I0523 15:14:00.339038 21880 net.cpp:219] label_data_1_split does not need backward computation.
I0523 15:14:00.339041 21880 net.cpp:219] data does not need backward computation.
I0523 15:14:00.339043 21880 net.cpp:261] This network produces output accuracy
I0523 15:14:00.339046 21880 net.cpp:261] This network produces output loss
I0523 15:14:00.339076 21880 net.cpp:274] Network initialization done.
I0523 15:14:00.340481 21880 solver.cpp:181] Creating test net (#0) specified by net file: models/segnet/train_val.prototxt
I0523 15:14:00.340589 21880 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0523 15:14:00.340955 21880 net.cpp:49] Initializing net from parameters: 
name: "segnet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "DenseImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 224
    mean_value: 100
  }
  dense_image_data_param {
    source: "data/val.txt"
    batch_size: 4
    shuffle: true
    new_height: 224
    new_width: 310
    is_color: false
    root_folder: "data/raw/train/"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 14
    upsample_w: 14
  }
}
layer {
  name: "conv5_2_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5_2_D"
  type: "BatchNorm"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2_D"
  type: "Scale"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2_D"
  type: "ReLU"
  bottom: "conv5_2_D"
  top: "conv5_2_D"
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "conv5_2_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5_1_D"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1_D"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 28
    upsample_w: 28
  }
}
layer {
  name: "conv4_2_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4_2_D"
  type: "BatchNorm"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2_D"
  type: "Scale"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2_D"
  type: "ReLU"
  bottom: "conv4_2_D"
  top: "conv4_2_D"
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "conv4_2_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4_1_D"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1_D"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
    upsample_h: 56
    upsample_w: 56
  }
}
layer {
  name: "conv3_2_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn3_2_D"
  type: "BatchNorm"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2_D"
  type: "Scale"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2_D"
  type: "ReLU"
  bottom: "conv3_2_D"
  top: "conv3_2_D"
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "conv3_2_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3_1_D"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1_D"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
    upsample_h: 112
    upsample_w: 112
  }
}
layer {
  name: "conv2_2_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2_2_D"
  type: "BatchNorm"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2_D"
  type: "Scale"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2_D"
  type: "ReLU"
  bottom: "conv2_2_D"
  top: "conv2_2_D"
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "conv2_2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2_1_D"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1_D"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
    upsample_h: 224
    upsample_w: 224
  }
}
layer {
  name: "conv1_2_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1_2_D"
  type: "BatchNorm"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2_D"
  type: "Scale"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2_D"
  type: "ReLU"
  bottom: "conv1_2_D"
  top: "conv1_2_D"
}
layer {
  name: "conv1_1_D"
  type: "Convolution"
  bottom: "conv1_2_D"
  top: "conv1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "accuracy"
}
I0523 15:14:00.341171 21880 layer_factory.hpp:77] Creating layer data
I0523 15:14:00.341181 21880 net.cpp:91] Creating Layer data
I0523 15:14:00.341183 21880 net.cpp:399] data -> data
I0523 15:14:00.341189 21880 net.cpp:399] data -> label
I0523 15:14:00.341197 21880 dense_image_data_layer.cpp:38] Opening file data/val.txt
I0523 15:14:00.341503 21880 dense_image_data_layer.cpp:48] Shuffling data
I0523 15:14:00.341572 21880 dense_image_data_layer.cpp:53] A total of 705 examples.
I0523 15:14:00.346426 21880 dense_image_data_layer.cpp:92] output data size: 1,1,224,224
I0523 15:14:00.347766 21880 net.cpp:141] Setting up data
I0523 15:14:00.347782 21880 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0523 15:14:00.347787 21880 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0523 15:14:00.347790 21880 net.cpp:156] Memory required for data: 401408
I0523 15:14:00.347795 21880 layer_factory.hpp:77] Creating layer label_data_1_split
I0523 15:14:00.347806 21880 net.cpp:91] Creating Layer label_data_1_split
I0523 15:14:00.347810 21880 net.cpp:425] label_data_1_split <- label
I0523 15:14:00.347815 21880 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0523 15:14:00.347823 21880 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0523 15:14:00.347895 21880 net.cpp:141] Setting up label_data_1_split
I0523 15:14:00.347901 21880 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0523 15:14:00.347904 21880 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0523 15:14:00.347906 21880 net.cpp:156] Memory required for data: 802816
I0523 15:14:00.347908 21880 layer_factory.hpp:77] Creating layer conv1_1
I0523 15:14:00.347918 21880 net.cpp:91] Creating Layer conv1_1
I0523 15:14:00.347921 21880 net.cpp:425] conv1_1 <- data
I0523 15:14:00.347925 21880 net.cpp:399] conv1_1 -> conv1_1
I0523 15:14:00.349086 21880 net.cpp:141] Setting up conv1_1
I0523 15:14:00.349097 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.349099 21880 net.cpp:156] Memory required for data: 7225344
I0523 15:14:00.349105 21880 layer_factory.hpp:77] Creating layer bn1_1
I0523 15:14:00.349112 21880 net.cpp:91] Creating Layer bn1_1
I0523 15:14:00.349114 21880 net.cpp:425] bn1_1 <- conv1_1
I0523 15:14:00.349118 21880 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0523 15:14:00.349334 21880 net.cpp:141] Setting up bn1_1
I0523 15:14:00.349339 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.349341 21880 net.cpp:156] Memory required for data: 13647872
I0523 15:14:00.349349 21880 layer_factory.hpp:77] Creating layer scale1_1
I0523 15:14:00.349356 21880 net.cpp:91] Creating Layer scale1_1
I0523 15:14:00.349359 21880 net.cpp:425] scale1_1 <- conv1_1
I0523 15:14:00.349362 21880 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0523 15:14:00.349395 21880 layer_factory.hpp:77] Creating layer scale1_1
I0523 15:14:00.349861 21880 net.cpp:141] Setting up scale1_1
I0523 15:14:00.349870 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.349872 21880 net.cpp:156] Memory required for data: 20070400
I0523 15:14:00.349879 21880 layer_factory.hpp:77] Creating layer relu1_1
I0523 15:14:00.349885 21880 net.cpp:91] Creating Layer relu1_1
I0523 15:14:00.349900 21880 net.cpp:425] relu1_1 <- conv1_1
I0523 15:14:00.349903 21880 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0523 15:14:00.350050 21880 net.cpp:141] Setting up relu1_1
I0523 15:14:00.350057 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.350059 21880 net.cpp:156] Memory required for data: 26492928
I0523 15:14:00.350062 21880 layer_factory.hpp:77] Creating layer conv1_2
I0523 15:14:00.350069 21880 net.cpp:91] Creating Layer conv1_2
I0523 15:14:00.350071 21880 net.cpp:425] conv1_2 <- conv1_1
I0523 15:14:00.350075 21880 net.cpp:399] conv1_2 -> conv1_2
I0523 15:14:00.351217 21880 net.cpp:141] Setting up conv1_2
I0523 15:14:00.351229 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.351232 21880 net.cpp:156] Memory required for data: 32915456
I0523 15:14:00.351236 21880 layer_factory.hpp:77] Creating layer bn1_2
I0523 15:14:00.351241 21880 net.cpp:91] Creating Layer bn1_2
I0523 15:14:00.351244 21880 net.cpp:425] bn1_2 <- conv1_2
I0523 15:14:00.351248 21880 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0523 15:14:00.351528 21880 net.cpp:141] Setting up bn1_2
I0523 15:14:00.351536 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.351538 21880 net.cpp:156] Memory required for data: 39337984
I0523 15:14:00.351547 21880 layer_factory.hpp:77] Creating layer scale1_2
I0523 15:14:00.351563 21880 net.cpp:91] Creating Layer scale1_2
I0523 15:14:00.351565 21880 net.cpp:425] scale1_2 <- conv1_2
I0523 15:14:00.351569 21880 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0523 15:14:00.351601 21880 layer_factory.hpp:77] Creating layer scale1_2
I0523 15:14:00.351758 21880 net.cpp:141] Setting up scale1_2
I0523 15:14:00.351764 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.351766 21880 net.cpp:156] Memory required for data: 45760512
I0523 15:14:00.351770 21880 layer_factory.hpp:77] Creating layer relu1_2
I0523 15:14:00.351775 21880 net.cpp:91] Creating Layer relu1_2
I0523 15:14:00.351778 21880 net.cpp:425] relu1_2 <- conv1_2
I0523 15:14:00.351780 21880 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0523 15:14:00.352026 21880 net.cpp:141] Setting up relu1_2
I0523 15:14:00.352035 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.352037 21880 net.cpp:156] Memory required for data: 52183040
I0523 15:14:00.352041 21880 layer_factory.hpp:77] Creating layer pool1
I0523 15:14:00.352043 21880 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0523 15:14:00.352048 21880 net.cpp:91] Creating Layer pool1
I0523 15:14:00.352051 21880 net.cpp:425] pool1 <- conv1_2
I0523 15:14:00.352054 21880 net.cpp:399] pool1 -> pool1
I0523 15:14:00.352058 21880 net.cpp:399] pool1 -> pool1_mask
I0523 15:14:00.352093 21880 net.cpp:141] Setting up pool1
I0523 15:14:00.352098 21880 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0523 15:14:00.352102 21880 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0523 15:14:00.352103 21880 net.cpp:156] Memory required for data: 55394304
I0523 15:14:00.352105 21880 layer_factory.hpp:77] Creating layer conv2_1
I0523 15:14:00.352111 21880 net.cpp:91] Creating Layer conv2_1
I0523 15:14:00.352113 21880 net.cpp:425] conv2_1 <- pool1
I0523 15:14:00.352118 21880 net.cpp:399] conv2_1 -> conv2_1
I0523 15:14:00.353343 21880 net.cpp:141] Setting up conv2_1
I0523 15:14:00.353351 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.353354 21880 net.cpp:156] Memory required for data: 58605568
I0523 15:14:00.353358 21880 layer_factory.hpp:77] Creating layer bn2_1
I0523 15:14:00.353363 21880 net.cpp:91] Creating Layer bn2_1
I0523 15:14:00.353365 21880 net.cpp:425] bn2_1 <- conv2_1
I0523 15:14:00.353369 21880 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0523 15:14:00.353586 21880 net.cpp:141] Setting up bn2_1
I0523 15:14:00.353592 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.353595 21880 net.cpp:156] Memory required for data: 61816832
I0523 15:14:00.353600 21880 layer_factory.hpp:77] Creating layer scale2_1
I0523 15:14:00.353606 21880 net.cpp:91] Creating Layer scale2_1
I0523 15:14:00.353621 21880 net.cpp:425] scale2_1 <- conv2_1
I0523 15:14:00.353626 21880 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0523 15:14:00.353960 21880 layer_factory.hpp:77] Creating layer scale2_1
I0523 15:14:00.354380 21880 net.cpp:141] Setting up scale2_1
I0523 15:14:00.354387 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.354389 21880 net.cpp:156] Memory required for data: 65028096
I0523 15:14:00.354396 21880 layer_factory.hpp:77] Creating layer relu2_1
I0523 15:14:00.354401 21880 net.cpp:91] Creating Layer relu2_1
I0523 15:14:00.354403 21880 net.cpp:425] relu2_1 <- conv2_1
I0523 15:14:00.354408 21880 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0523 15:14:00.354581 21880 net.cpp:141] Setting up relu2_1
I0523 15:14:00.354589 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.354591 21880 net.cpp:156] Memory required for data: 68239360
I0523 15:14:00.354594 21880 layer_factory.hpp:77] Creating layer conv2_2
I0523 15:14:00.354601 21880 net.cpp:91] Creating Layer conv2_2
I0523 15:14:00.354604 21880 net.cpp:425] conv2_2 <- conv2_1
I0523 15:14:00.354607 21880 net.cpp:399] conv2_2 -> conv2_2
I0523 15:14:00.356415 21880 net.cpp:141] Setting up conv2_2
I0523 15:14:00.356425 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.356426 21880 net.cpp:156] Memory required for data: 71450624
I0523 15:14:00.356431 21880 layer_factory.hpp:77] Creating layer bn2_2
I0523 15:14:00.356438 21880 net.cpp:91] Creating Layer bn2_2
I0523 15:14:00.356441 21880 net.cpp:425] bn2_2 <- conv2_2
I0523 15:14:00.356444 21880 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0523 15:14:00.356628 21880 net.cpp:141] Setting up bn2_2
I0523 15:14:00.356633 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.356636 21880 net.cpp:156] Memory required for data: 74661888
I0523 15:14:00.356640 21880 layer_factory.hpp:77] Creating layer scale2_2
I0523 15:14:00.356647 21880 net.cpp:91] Creating Layer scale2_2
I0523 15:14:00.356648 21880 net.cpp:425] scale2_2 <- conv2_2
I0523 15:14:00.356652 21880 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0523 15:14:00.356683 21880 layer_factory.hpp:77] Creating layer scale2_2
I0523 15:14:00.356789 21880 net.cpp:141] Setting up scale2_2
I0523 15:14:00.356794 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.356796 21880 net.cpp:156] Memory required for data: 77873152
I0523 15:14:00.356801 21880 layer_factory.hpp:77] Creating layer relu2_2
I0523 15:14:00.356806 21880 net.cpp:91] Creating Layer relu2_2
I0523 15:14:00.356807 21880 net.cpp:425] relu2_2 <- conv2_2
I0523 15:14:00.356811 21880 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0523 15:14:00.356951 21880 net.cpp:141] Setting up relu2_2
I0523 15:14:00.356957 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.356959 21880 net.cpp:156] Memory required for data: 81084416
I0523 15:14:00.356961 21880 layer_factory.hpp:77] Creating layer pool2
I0523 15:14:00.356964 21880 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0523 15:14:00.356968 21880 net.cpp:91] Creating Layer pool2
I0523 15:14:00.356971 21880 net.cpp:425] pool2 <- conv2_2
I0523 15:14:00.356974 21880 net.cpp:399] pool2 -> pool2
I0523 15:14:00.356978 21880 net.cpp:399] pool2 -> pool2_mask
I0523 15:14:00.357014 21880 net.cpp:141] Setting up pool2
I0523 15:14:00.357018 21880 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0523 15:14:00.357022 21880 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0523 15:14:00.357023 21880 net.cpp:156] Memory required for data: 82690048
I0523 15:14:00.357025 21880 layer_factory.hpp:77] Creating layer conv3_1
I0523 15:14:00.357031 21880 net.cpp:91] Creating Layer conv3_1
I0523 15:14:00.357033 21880 net.cpp:425] conv3_1 <- pool2
I0523 15:14:00.357038 21880 net.cpp:399] conv3_1 -> conv3_1
I0523 15:14:00.359581 21880 net.cpp:141] Setting up conv3_1
I0523 15:14:00.359592 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.359596 21880 net.cpp:156] Memory required for data: 84295680
I0523 15:14:00.359598 21880 layer_factory.hpp:77] Creating layer bn3_1
I0523 15:14:00.359616 21880 net.cpp:91] Creating Layer bn3_1
I0523 15:14:00.359618 21880 net.cpp:425] bn3_1 <- conv3_1
I0523 15:14:00.359622 21880 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0523 15:14:00.359792 21880 net.cpp:141] Setting up bn3_1
I0523 15:14:00.359797 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.359799 21880 net.cpp:156] Memory required for data: 85901312
I0523 15:14:00.359804 21880 layer_factory.hpp:77] Creating layer scale3_1
I0523 15:14:00.359809 21880 net.cpp:91] Creating Layer scale3_1
I0523 15:14:00.359812 21880 net.cpp:425] scale3_1 <- conv3_1
I0523 15:14:00.359814 21880 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0523 15:14:00.359845 21880 layer_factory.hpp:77] Creating layer scale3_1
I0523 15:14:00.359941 21880 net.cpp:141] Setting up scale3_1
I0523 15:14:00.359944 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.359946 21880 net.cpp:156] Memory required for data: 87506944
I0523 15:14:00.359951 21880 layer_factory.hpp:77] Creating layer relu3_1
I0523 15:14:00.359954 21880 net.cpp:91] Creating Layer relu3_1
I0523 15:14:00.359956 21880 net.cpp:425] relu3_1 <- conv3_1
I0523 15:14:00.359959 21880 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0523 15:14:00.360177 21880 net.cpp:141] Setting up relu3_1
I0523 15:14:00.360186 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.360188 21880 net.cpp:156] Memory required for data: 89112576
I0523 15:14:00.360191 21880 layer_factory.hpp:77] Creating layer conv3_2
I0523 15:14:00.360198 21880 net.cpp:91] Creating Layer conv3_2
I0523 15:14:00.360200 21880 net.cpp:425] conv3_2 <- conv3_1
I0523 15:14:00.360203 21880 net.cpp:399] conv3_2 -> conv3_2
I0523 15:14:00.364727 21880 net.cpp:141] Setting up conv3_2
I0523 15:14:00.364739 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.364742 21880 net.cpp:156] Memory required for data: 90718208
I0523 15:14:00.364748 21880 layer_factory.hpp:77] Creating layer bn3_2
I0523 15:14:00.364753 21880 net.cpp:91] Creating Layer bn3_2
I0523 15:14:00.364755 21880 net.cpp:425] bn3_2 <- conv3_2
I0523 15:14:00.364759 21880 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0523 15:14:00.364934 21880 net.cpp:141] Setting up bn3_2
I0523 15:14:00.364939 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.364943 21880 net.cpp:156] Memory required for data: 92323840
I0523 15:14:00.364951 21880 layer_factory.hpp:77] Creating layer scale3_2
I0523 15:14:00.364958 21880 net.cpp:91] Creating Layer scale3_2
I0523 15:14:00.364960 21880 net.cpp:425] scale3_2 <- conv3_2
I0523 15:14:00.364964 21880 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0523 15:14:00.364995 21880 layer_factory.hpp:77] Creating layer scale3_2
I0523 15:14:00.365094 21880 net.cpp:141] Setting up scale3_2
I0523 15:14:00.365099 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.365102 21880 net.cpp:156] Memory required for data: 93929472
I0523 15:14:00.365105 21880 layer_factory.hpp:77] Creating layer relu3_2
I0523 15:14:00.365109 21880 net.cpp:91] Creating Layer relu3_2
I0523 15:14:00.365111 21880 net.cpp:425] relu3_2 <- conv3_2
I0523 15:14:00.365115 21880 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0523 15:14:00.365252 21880 net.cpp:141] Setting up relu3_2
I0523 15:14:00.365257 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.365259 21880 net.cpp:156] Memory required for data: 95535104
I0523 15:14:00.365262 21880 layer_factory.hpp:77] Creating layer pool3
I0523 15:14:00.365265 21880 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0523 15:14:00.365269 21880 net.cpp:91] Creating Layer pool3
I0523 15:14:00.365272 21880 net.cpp:425] pool3 <- conv3_2
I0523 15:14:00.365275 21880 net.cpp:399] pool3 -> pool3
I0523 15:14:00.365279 21880 net.cpp:399] pool3 -> pool3_mask
I0523 15:14:00.365314 21880 net.cpp:141] Setting up pool3
I0523 15:14:00.365319 21880 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0523 15:14:00.365321 21880 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0523 15:14:00.365324 21880 net.cpp:156] Memory required for data: 96337920
I0523 15:14:00.365335 21880 layer_factory.hpp:77] Creating layer conv4_1
I0523 15:14:00.365342 21880 net.cpp:91] Creating Layer conv4_1
I0523 15:14:00.365345 21880 net.cpp:425] conv4_1 <- pool3
I0523 15:14:00.365350 21880 net.cpp:399] conv4_1 -> conv4_1
I0523 15:14:00.373551 21880 net.cpp:141] Setting up conv4_1
I0523 15:14:00.373570 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.373574 21880 net.cpp:156] Memory required for data: 97140736
I0523 15:14:00.373579 21880 layer_factory.hpp:77] Creating layer bn4_1
I0523 15:14:00.373586 21880 net.cpp:91] Creating Layer bn4_1
I0523 15:14:00.373590 21880 net.cpp:425] bn4_1 <- conv4_1
I0523 15:14:00.373596 21880 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0523 15:14:00.373800 21880 net.cpp:141] Setting up bn4_1
I0523 15:14:00.373806 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.373810 21880 net.cpp:156] Memory required for data: 97943552
I0523 15:14:00.373814 21880 layer_factory.hpp:77] Creating layer scale4_1
I0523 15:14:00.373821 21880 net.cpp:91] Creating Layer scale4_1
I0523 15:14:00.373823 21880 net.cpp:425] scale4_1 <- conv4_1
I0523 15:14:00.373827 21880 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0523 15:14:00.373864 21880 layer_factory.hpp:77] Creating layer scale4_1
I0523 15:14:00.373971 21880 net.cpp:141] Setting up scale4_1
I0523 15:14:00.373976 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.373980 21880 net.cpp:156] Memory required for data: 98746368
I0523 15:14:00.373982 21880 layer_factory.hpp:77] Creating layer relu4_1
I0523 15:14:00.373991 21880 net.cpp:91] Creating Layer relu4_1
I0523 15:14:00.373993 21880 net.cpp:425] relu4_1 <- conv4_1
I0523 15:14:00.373997 21880 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0523 15:14:00.374178 21880 net.cpp:141] Setting up relu4_1
I0523 15:14:00.374188 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.374191 21880 net.cpp:156] Memory required for data: 99549184
I0523 15:14:00.374193 21880 layer_factory.hpp:77] Creating layer conv4_2
I0523 15:14:00.374202 21880 net.cpp:91] Creating Layer conv4_2
I0523 15:14:00.374204 21880 net.cpp:425] conv4_2 <- conv4_1
I0523 15:14:00.374208 21880 net.cpp:399] conv4_2 -> conv4_2
I0523 15:14:00.389971 21880 net.cpp:141] Setting up conv4_2
I0523 15:14:00.389991 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.389993 21880 net.cpp:156] Memory required for data: 100352000
I0523 15:14:00.390000 21880 layer_factory.hpp:77] Creating layer bn4_2
I0523 15:14:00.390009 21880 net.cpp:91] Creating Layer bn4_2
I0523 15:14:00.390013 21880 net.cpp:425] bn4_2 <- conv4_2
I0523 15:14:00.390019 21880 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0523 15:14:00.390214 21880 net.cpp:141] Setting up bn4_2
I0523 15:14:00.390220 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.390223 21880 net.cpp:156] Memory required for data: 101154816
I0523 15:14:00.390228 21880 layer_factory.hpp:77] Creating layer scale4_2
I0523 15:14:00.390235 21880 net.cpp:91] Creating Layer scale4_2
I0523 15:14:00.390238 21880 net.cpp:425] scale4_2 <- conv4_2
I0523 15:14:00.390241 21880 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0523 15:14:00.390275 21880 layer_factory.hpp:77] Creating layer scale4_2
I0523 15:14:00.390379 21880 net.cpp:141] Setting up scale4_2
I0523 15:14:00.390384 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.390386 21880 net.cpp:156] Memory required for data: 101957632
I0523 15:14:00.390390 21880 layer_factory.hpp:77] Creating layer relu4_2
I0523 15:14:00.390396 21880 net.cpp:91] Creating Layer relu4_2
I0523 15:14:00.390398 21880 net.cpp:425] relu4_2 <- conv4_2
I0523 15:14:00.390401 21880 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0523 15:14:00.390643 21880 net.cpp:141] Setting up relu4_2
I0523 15:14:00.390652 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.390655 21880 net.cpp:156] Memory required for data: 102760448
I0523 15:14:00.390657 21880 layer_factory.hpp:77] Creating layer pool4
I0523 15:14:00.390661 21880 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0523 15:14:00.390676 21880 net.cpp:91] Creating Layer pool4
I0523 15:14:00.390679 21880 net.cpp:425] pool4 <- conv4_2
I0523 15:14:00.390684 21880 net.cpp:399] pool4 -> pool4
I0523 15:14:00.390689 21880 net.cpp:399] pool4 -> pool4_mask
I0523 15:14:00.390732 21880 net.cpp:141] Setting up pool4
I0523 15:14:00.390736 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.390739 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.390741 21880 net.cpp:156] Memory required for data: 103161856
I0523 15:14:00.390743 21880 layer_factory.hpp:77] Creating layer conv5_1
I0523 15:14:00.390751 21880 net.cpp:91] Creating Layer conv5_1
I0523 15:14:00.390753 21880 net.cpp:425] conv5_1 <- pool4
I0523 15:14:00.390756 21880 net.cpp:399] conv5_1 -> conv5_1
I0523 15:14:00.406270 21880 net.cpp:141] Setting up conv5_1
I0523 15:14:00.406292 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.406297 21880 net.cpp:156] Memory required for data: 103362560
I0523 15:14:00.406307 21880 layer_factory.hpp:77] Creating layer bn5_1
I0523 15:14:00.406322 21880 net.cpp:91] Creating Layer bn5_1
I0523 15:14:00.406332 21880 net.cpp:425] bn5_1 <- conv5_1
I0523 15:14:00.406339 21880 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0523 15:14:00.406590 21880 net.cpp:141] Setting up bn5_1
I0523 15:14:00.406601 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.406605 21880 net.cpp:156] Memory required for data: 103563264
I0523 15:14:00.406615 21880 layer_factory.hpp:77] Creating layer scale5_1
I0523 15:14:00.406626 21880 net.cpp:91] Creating Layer scale5_1
I0523 15:14:00.406633 21880 net.cpp:425] scale5_1 <- conv5_1
I0523 15:14:00.406641 21880 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0523 15:14:00.406692 21880 layer_factory.hpp:77] Creating layer scale5_1
I0523 15:14:00.406807 21880 net.cpp:141] Setting up scale5_1
I0523 15:14:00.406816 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.406819 21880 net.cpp:156] Memory required for data: 103763968
I0523 15:14:00.406826 21880 layer_factory.hpp:77] Creating layer relu5_1
I0523 15:14:00.406836 21880 net.cpp:91] Creating Layer relu5_1
I0523 15:14:00.406839 21880 net.cpp:425] relu5_1 <- conv5_1
I0523 15:14:00.406848 21880 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0523 15:14:00.407042 21880 net.cpp:141] Setting up relu5_1
I0523 15:14:00.407049 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.407053 21880 net.cpp:156] Memory required for data: 103964672
I0523 15:14:00.407058 21880 layer_factory.hpp:77] Creating layer conv5_2
I0523 15:14:00.407071 21880 net.cpp:91] Creating Layer conv5_2
I0523 15:14:00.407075 21880 net.cpp:425] conv5_2 <- conv5_1
I0523 15:14:00.407083 21880 net.cpp:399] conv5_2 -> conv5_2
I0523 15:14:00.422659 21880 net.cpp:141] Setting up conv5_2
I0523 15:14:00.422688 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.422691 21880 net.cpp:156] Memory required for data: 104165376
I0523 15:14:00.422698 21880 layer_factory.hpp:77] Creating layer bn5_2
I0523 15:14:00.422708 21880 net.cpp:91] Creating Layer bn5_2
I0523 15:14:00.422713 21880 net.cpp:425] bn5_2 <- conv5_2
I0523 15:14:00.422719 21880 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0523 15:14:00.422930 21880 net.cpp:141] Setting up bn5_2
I0523 15:14:00.422935 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.422948 21880 net.cpp:156] Memory required for data: 104366080
I0523 15:14:00.422953 21880 layer_factory.hpp:77] Creating layer scale5_2
I0523 15:14:00.422960 21880 net.cpp:91] Creating Layer scale5_2
I0523 15:14:00.422963 21880 net.cpp:425] scale5_2 <- conv5_2
I0523 15:14:00.422967 21880 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0523 15:14:00.423017 21880 layer_factory.hpp:77] Creating layer scale5_2
I0523 15:14:00.423117 21880 net.cpp:141] Setting up scale5_2
I0523 15:14:00.423122 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.423125 21880 net.cpp:156] Memory required for data: 104566784
I0523 15:14:00.423128 21880 layer_factory.hpp:77] Creating layer relu5_2
I0523 15:14:00.423133 21880 net.cpp:91] Creating Layer relu5_2
I0523 15:14:00.423148 21880 net.cpp:425] relu5_2 <- conv5_2
I0523 15:14:00.423151 21880 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0523 15:14:00.423297 21880 net.cpp:141] Setting up relu5_2
I0523 15:14:00.423305 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.423306 21880 net.cpp:156] Memory required for data: 104767488
I0523 15:14:00.423310 21880 layer_factory.hpp:77] Creating layer pool5
I0523 15:14:00.423312 21880 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0523 15:14:00.423316 21880 net.cpp:91] Creating Layer pool5
I0523 15:14:00.423318 21880 net.cpp:425] pool5 <- conv5_2
I0523 15:14:00.423323 21880 net.cpp:399] pool5 -> pool5
I0523 15:14:00.423328 21880 net.cpp:399] pool5 -> pool5_mask
I0523 15:14:00.423369 21880 net.cpp:141] Setting up pool5
I0523 15:14:00.423374 21880 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0523 15:14:00.423377 21880 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0523 15:14:00.423378 21880 net.cpp:156] Memory required for data: 104867840
I0523 15:14:00.423380 21880 layer_factory.hpp:77] Creating layer upsample5
I0523 15:14:00.423385 21880 net.cpp:91] Creating Layer upsample5
I0523 15:14:00.423388 21880 net.cpp:425] upsample5 <- pool5
I0523 15:14:00.423390 21880 net.cpp:425] upsample5 <- pool5_mask
I0523 15:14:00.423393 21880 net.cpp:399] upsample5 -> pool5_D
I0523 15:14:00.423414 21880 net.cpp:141] Setting up upsample5
I0523 15:14:00.423418 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.423420 21880 net.cpp:156] Memory required for data: 105068544
I0523 15:14:00.423423 21880 layer_factory.hpp:77] Creating layer conv5_2_D
I0523 15:14:00.423431 21880 net.cpp:91] Creating Layer conv5_2_D
I0523 15:14:00.423434 21880 net.cpp:425] conv5_2_D <- pool5_D
I0523 15:14:00.423439 21880 net.cpp:399] conv5_2_D -> conv5_2_D
I0523 15:14:00.439096 21880 net.cpp:141] Setting up conv5_2_D
I0523 15:14:00.439127 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.439131 21880 net.cpp:156] Memory required for data: 105269248
I0523 15:14:00.439137 21880 layer_factory.hpp:77] Creating layer bn5_2_D
I0523 15:14:00.439148 21880 net.cpp:91] Creating Layer bn5_2_D
I0523 15:14:00.439152 21880 net.cpp:425] bn5_2_D <- conv5_2_D
I0523 15:14:00.439158 21880 net.cpp:386] bn5_2_D -> conv5_2_D (in-place)
I0523 15:14:00.439355 21880 net.cpp:141] Setting up bn5_2_D
I0523 15:14:00.439360 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.439363 21880 net.cpp:156] Memory required for data: 105469952
I0523 15:14:00.439378 21880 layer_factory.hpp:77] Creating layer scale5_2_D
I0523 15:14:00.439385 21880 net.cpp:91] Creating Layer scale5_2_D
I0523 15:14:00.439388 21880 net.cpp:425] scale5_2_D <- conv5_2_D
I0523 15:14:00.439391 21880 net.cpp:386] scale5_2_D -> conv5_2_D (in-place)
I0523 15:14:00.439437 21880 layer_factory.hpp:77] Creating layer scale5_2_D
I0523 15:14:00.439558 21880 net.cpp:141] Setting up scale5_2_D
I0523 15:14:00.439563 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.439564 21880 net.cpp:156] Memory required for data: 105670656
I0523 15:14:00.439587 21880 layer_factory.hpp:77] Creating layer relu5_2_D
I0523 15:14:00.439595 21880 net.cpp:91] Creating Layer relu5_2_D
I0523 15:14:00.439597 21880 net.cpp:425] relu5_2_D <- conv5_2_D
I0523 15:14:00.439600 21880 net.cpp:386] relu5_2_D -> conv5_2_D (in-place)
I0523 15:14:00.439846 21880 net.cpp:141] Setting up relu5_2_D
I0523 15:14:00.439853 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.439867 21880 net.cpp:156] Memory required for data: 105871360
I0523 15:14:00.439869 21880 layer_factory.hpp:77] Creating layer conv5_1_D
I0523 15:14:00.439877 21880 net.cpp:91] Creating Layer conv5_1_D
I0523 15:14:00.439880 21880 net.cpp:425] conv5_1_D <- conv5_2_D
I0523 15:14:00.439885 21880 net.cpp:399] conv5_1_D -> conv5_1_D
I0523 15:14:00.455083 21880 net.cpp:141] Setting up conv5_1_D
I0523 15:14:00.455112 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.455116 21880 net.cpp:156] Memory required for data: 106072064
I0523 15:14:00.455135 21880 layer_factory.hpp:77] Creating layer bn5_1_D
I0523 15:14:00.455145 21880 net.cpp:91] Creating Layer bn5_1_D
I0523 15:14:00.455149 21880 net.cpp:425] bn5_1_D <- conv5_1_D
I0523 15:14:00.455154 21880 net.cpp:386] bn5_1_D -> conv5_1_D (in-place)
I0523 15:14:00.455351 21880 net.cpp:141] Setting up bn5_1_D
I0523 15:14:00.455356 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.455369 21880 net.cpp:156] Memory required for data: 106272768
I0523 15:14:00.455374 21880 layer_factory.hpp:77] Creating layer scale5_1_D
I0523 15:14:00.455381 21880 net.cpp:91] Creating Layer scale5_1_D
I0523 15:14:00.455384 21880 net.cpp:425] scale5_1_D <- conv5_1_D
I0523 15:14:00.455386 21880 net.cpp:386] scale5_1_D -> conv5_1_D (in-place)
I0523 15:14:00.455433 21880 layer_factory.hpp:77] Creating layer scale5_1_D
I0523 15:14:00.455552 21880 net.cpp:141] Setting up scale5_1_D
I0523 15:14:00.455557 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.455559 21880 net.cpp:156] Memory required for data: 106473472
I0523 15:14:00.455574 21880 layer_factory.hpp:77] Creating layer relu5_1_D
I0523 15:14:00.455579 21880 net.cpp:91] Creating Layer relu5_1_D
I0523 15:14:00.455580 21880 net.cpp:425] relu5_1_D <- conv5_1_D
I0523 15:14:00.455585 21880 net.cpp:386] relu5_1_D -> conv5_1_D (in-place)
I0523 15:14:00.455806 21880 net.cpp:141] Setting up relu5_1_D
I0523 15:14:00.455813 21880 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0523 15:14:00.455826 21880 net.cpp:156] Memory required for data: 106674176
I0523 15:14:00.455828 21880 layer_factory.hpp:77] Creating layer upsample4
I0523 15:14:00.455833 21880 net.cpp:91] Creating Layer upsample4
I0523 15:14:00.455837 21880 net.cpp:425] upsample4 <- conv5_1_D
I0523 15:14:00.455839 21880 net.cpp:425] upsample4 <- pool4_mask
I0523 15:14:00.455843 21880 net.cpp:399] upsample4 -> pool4_D
I0523 15:14:00.455871 21880 net.cpp:141] Setting up upsample4
I0523 15:14:00.455885 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.455888 21880 net.cpp:156] Memory required for data: 107476992
I0523 15:14:00.455889 21880 layer_factory.hpp:77] Creating layer conv4_2_D
I0523 15:14:00.455907 21880 net.cpp:91] Creating Layer conv4_2_D
I0523 15:14:00.455909 21880 net.cpp:425] conv4_2_D <- pool4_D
I0523 15:14:00.455914 21880 net.cpp:399] conv4_2_D -> conv4_2_D
I0523 15:14:00.471230 21880 net.cpp:141] Setting up conv4_2_D
I0523 15:14:00.471261 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.471263 21880 net.cpp:156] Memory required for data: 108279808
I0523 15:14:00.471269 21880 layer_factory.hpp:77] Creating layer bn4_2_D
I0523 15:14:00.471279 21880 net.cpp:91] Creating Layer bn4_2_D
I0523 15:14:00.471282 21880 net.cpp:425] bn4_2_D <- conv4_2_D
I0523 15:14:00.471288 21880 net.cpp:386] bn4_2_D -> conv4_2_D (in-place)
I0523 15:14:00.471515 21880 net.cpp:141] Setting up bn4_2_D
I0523 15:14:00.471520 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.471534 21880 net.cpp:156] Memory required for data: 109082624
I0523 15:14:00.471539 21880 layer_factory.hpp:77] Creating layer scale4_2_D
I0523 15:14:00.471544 21880 net.cpp:91] Creating Layer scale4_2_D
I0523 15:14:00.471546 21880 net.cpp:425] scale4_2_D <- conv4_2_D
I0523 15:14:00.471550 21880 net.cpp:386] scale4_2_D -> conv4_2_D (in-place)
I0523 15:14:00.471611 21880 layer_factory.hpp:77] Creating layer scale4_2_D
I0523 15:14:00.471748 21880 net.cpp:141] Setting up scale4_2_D
I0523 15:14:00.471755 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.471766 21880 net.cpp:156] Memory required for data: 109885440
I0523 15:14:00.471771 21880 layer_factory.hpp:77] Creating layer relu4_2_D
I0523 15:14:00.471774 21880 net.cpp:91] Creating Layer relu4_2_D
I0523 15:14:00.471777 21880 net.cpp:425] relu4_2_D <- conv4_2_D
I0523 15:14:00.471781 21880 net.cpp:386] relu4_2_D -> conv4_2_D (in-place)
I0523 15:14:00.471930 21880 net.cpp:141] Setting up relu4_2_D
I0523 15:14:00.471937 21880 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0523 15:14:00.471949 21880 net.cpp:156] Memory required for data: 110688256
I0523 15:14:00.471962 21880 layer_factory.hpp:77] Creating layer conv4_1_D
I0523 15:14:00.471971 21880 net.cpp:91] Creating Layer conv4_1_D
I0523 15:14:00.471973 21880 net.cpp:425] conv4_1_D <- conv4_2_D
I0523 15:14:00.471978 21880 net.cpp:399] conv4_1_D -> conv4_1_D
I0523 15:14:00.480310 21880 net.cpp:141] Setting up conv4_1_D
I0523 15:14:00.480337 21880 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0523 15:14:00.480340 21880 net.cpp:156] Memory required for data: 111089664
I0523 15:14:00.480346 21880 layer_factory.hpp:77] Creating layer bn4_1_D
I0523 15:14:00.480355 21880 net.cpp:91] Creating Layer bn4_1_D
I0523 15:14:00.480360 21880 net.cpp:425] bn4_1_D <- conv4_1_D
I0523 15:14:00.480363 21880 net.cpp:386] bn4_1_D -> conv4_1_D (in-place)
I0523 15:14:00.480563 21880 net.cpp:141] Setting up bn4_1_D
I0523 15:14:00.480568 21880 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0523 15:14:00.480581 21880 net.cpp:156] Memory required for data: 111491072
I0523 15:14:00.480587 21880 layer_factory.hpp:77] Creating layer scale4_1_D
I0523 15:14:00.480592 21880 net.cpp:91] Creating Layer scale4_1_D
I0523 15:14:00.480595 21880 net.cpp:425] scale4_1_D <- conv4_1_D
I0523 15:14:00.480598 21880 net.cpp:386] scale4_1_D -> conv4_1_D (in-place)
I0523 15:14:00.480644 21880 layer_factory.hpp:77] Creating layer scale4_1_D
I0523 15:14:00.480768 21880 net.cpp:141] Setting up scale4_1_D
I0523 15:14:00.480773 21880 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0523 15:14:00.480785 21880 net.cpp:156] Memory required for data: 111892480
I0523 15:14:00.480789 21880 layer_factory.hpp:77] Creating layer relu4_1_D
I0523 15:14:00.480801 21880 net.cpp:91] Creating Layer relu4_1_D
I0523 15:14:00.480803 21880 net.cpp:425] relu4_1_D <- conv4_1_D
I0523 15:14:00.480806 21880 net.cpp:386] relu4_1_D -> conv4_1_D (in-place)
I0523 15:14:00.481040 21880 net.cpp:141] Setting up relu4_1_D
I0523 15:14:00.481048 21880 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0523 15:14:00.481061 21880 net.cpp:156] Memory required for data: 112293888
I0523 15:14:00.481065 21880 layer_factory.hpp:77] Creating layer upsample3
I0523 15:14:00.481070 21880 net.cpp:91] Creating Layer upsample3
I0523 15:14:00.481072 21880 net.cpp:425] upsample3 <- conv4_1_D
I0523 15:14:00.481076 21880 net.cpp:425] upsample3 <- pool3_mask
I0523 15:14:00.481079 21880 net.cpp:399] upsample3 -> pool3_D
I0523 15:14:00.481106 21880 net.cpp:141] Setting up upsample3
I0523 15:14:00.481120 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.481122 21880 net.cpp:156] Memory required for data: 113899520
I0523 15:14:00.481124 21880 layer_factory.hpp:77] Creating layer conv3_2_D
I0523 15:14:00.481142 21880 net.cpp:91] Creating Layer conv3_2_D
I0523 15:14:00.481144 21880 net.cpp:425] conv3_2_D <- pool3_D
I0523 15:14:00.481148 21880 net.cpp:399] conv3_2_D -> conv3_2_D
I0523 15:14:00.485746 21880 net.cpp:141] Setting up conv3_2_D
I0523 15:14:00.485766 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.485769 21880 net.cpp:156] Memory required for data: 115505152
I0523 15:14:00.485774 21880 layer_factory.hpp:77] Creating layer bn3_2_D
I0523 15:14:00.485780 21880 net.cpp:91] Creating Layer bn3_2_D
I0523 15:14:00.485781 21880 net.cpp:425] bn3_2_D <- conv3_2_D
I0523 15:14:00.485786 21880 net.cpp:386] bn3_2_D -> conv3_2_D (in-place)
I0523 15:14:00.485981 21880 net.cpp:141] Setting up bn3_2_D
I0523 15:14:00.485987 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.485999 21880 net.cpp:156] Memory required for data: 117110784
I0523 15:14:00.486004 21880 layer_factory.hpp:77] Creating layer scale3_2_D
I0523 15:14:00.486008 21880 net.cpp:91] Creating Layer scale3_2_D
I0523 15:14:00.486011 21880 net.cpp:425] scale3_2_D <- conv3_2_D
I0523 15:14:00.486014 21880 net.cpp:386] scale3_2_D -> conv3_2_D (in-place)
I0523 15:14:00.486058 21880 layer_factory.hpp:77] Creating layer scale3_2_D
I0523 15:14:00.486176 21880 net.cpp:141] Setting up scale3_2_D
I0523 15:14:00.486181 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.486183 21880 net.cpp:156] Memory required for data: 118716416
I0523 15:14:00.486199 21880 layer_factory.hpp:77] Creating layer relu3_2_D
I0523 15:14:00.486203 21880 net.cpp:91] Creating Layer relu3_2_D
I0523 15:14:00.486208 21880 net.cpp:425] relu3_2_D <- conv3_2_D
I0523 15:14:00.486212 21880 net.cpp:386] relu3_2_D -> conv3_2_D (in-place)
I0523 15:14:00.486353 21880 net.cpp:141] Setting up relu3_2_D
I0523 15:14:00.486361 21880 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0523 15:14:00.486362 21880 net.cpp:156] Memory required for data: 120322048
I0523 15:14:00.486366 21880 layer_factory.hpp:77] Creating layer conv3_1_D
I0523 15:14:00.486373 21880 net.cpp:91] Creating Layer conv3_1_D
I0523 15:14:00.486377 21880 net.cpp:425] conv3_1_D <- conv3_2_D
I0523 15:14:00.486380 21880 net.cpp:399] conv3_1_D -> conv3_1_D
I0523 15:14:00.488934 21880 net.cpp:141] Setting up conv3_1_D
I0523 15:14:00.488953 21880 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0523 15:14:00.488955 21880 net.cpp:156] Memory required for data: 121124864
I0523 15:14:00.488960 21880 layer_factory.hpp:77] Creating layer bn3_1_D
I0523 15:14:00.488965 21880 net.cpp:91] Creating Layer bn3_1_D
I0523 15:14:00.488967 21880 net.cpp:425] bn3_1_D <- conv3_1_D
I0523 15:14:00.488970 21880 net.cpp:386] bn3_1_D -> conv3_1_D (in-place)
I0523 15:14:00.489173 21880 net.cpp:141] Setting up bn3_1_D
I0523 15:14:00.489178 21880 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0523 15:14:00.489192 21880 net.cpp:156] Memory required for data: 121927680
I0523 15:14:00.489197 21880 layer_factory.hpp:77] Creating layer scale3_1_D
I0523 15:14:00.489202 21880 net.cpp:91] Creating Layer scale3_1_D
I0523 15:14:00.489204 21880 net.cpp:425] scale3_1_D <- conv3_1_D
I0523 15:14:00.489207 21880 net.cpp:386] scale3_1_D -> conv3_1_D (in-place)
I0523 15:14:00.489253 21880 layer_factory.hpp:77] Creating layer scale3_1_D
I0523 15:14:00.489378 21880 net.cpp:141] Setting up scale3_1_D
I0523 15:14:00.489383 21880 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0523 15:14:00.489385 21880 net.cpp:156] Memory required for data: 122730496
I0523 15:14:00.489389 21880 layer_factory.hpp:77] Creating layer relu3_1_D
I0523 15:14:00.489393 21880 net.cpp:91] Creating Layer relu3_1_D
I0523 15:14:00.489395 21880 net.cpp:425] relu3_1_D <- conv3_1_D
I0523 15:14:00.489398 21880 net.cpp:386] relu3_1_D -> conv3_1_D (in-place)
I0523 15:14:00.489549 21880 net.cpp:141] Setting up relu3_1_D
I0523 15:14:00.489555 21880 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0523 15:14:00.489567 21880 net.cpp:156] Memory required for data: 123533312
I0523 15:14:00.489569 21880 layer_factory.hpp:77] Creating layer upsample2
I0523 15:14:00.489574 21880 net.cpp:91] Creating Layer upsample2
I0523 15:14:00.489576 21880 net.cpp:425] upsample2 <- conv3_1_D
I0523 15:14:00.489579 21880 net.cpp:425] upsample2 <- pool2_mask
I0523 15:14:00.489584 21880 net.cpp:399] upsample2 -> pool2_D
I0523 15:14:00.489610 21880 net.cpp:141] Setting up upsample2
I0523 15:14:00.489624 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.489626 21880 net.cpp:156] Memory required for data: 126744576
I0523 15:14:00.489629 21880 layer_factory.hpp:77] Creating layer conv2_2_D
I0523 15:14:00.489645 21880 net.cpp:91] Creating Layer conv2_2_D
I0523 15:14:00.489646 21880 net.cpp:425] conv2_2_D <- pool2_D
I0523 15:14:00.489650 21880 net.cpp:399] conv2_2_D -> conv2_2_D
I0523 15:14:00.491360 21880 net.cpp:141] Setting up conv2_2_D
I0523 15:14:00.491369 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.491382 21880 net.cpp:156] Memory required for data: 129955840
I0523 15:14:00.491387 21880 layer_factory.hpp:77] Creating layer bn2_2_D
I0523 15:14:00.491394 21880 net.cpp:91] Creating Layer bn2_2_D
I0523 15:14:00.491395 21880 net.cpp:425] bn2_2_D <- conv2_2_D
I0523 15:14:00.491400 21880 net.cpp:386] bn2_2_D -> conv2_2_D (in-place)
I0523 15:14:00.491880 21880 net.cpp:141] Setting up bn2_2_D
I0523 15:14:00.491888 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.491901 21880 net.cpp:156] Memory required for data: 133167104
I0523 15:14:00.491906 21880 layer_factory.hpp:77] Creating layer scale2_2_D
I0523 15:14:00.491919 21880 net.cpp:91] Creating Layer scale2_2_D
I0523 15:14:00.491921 21880 net.cpp:425] scale2_2_D <- conv2_2_D
I0523 15:14:00.491925 21880 net.cpp:386] scale2_2_D -> conv2_2_D (in-place)
I0523 15:14:00.491976 21880 layer_factory.hpp:77] Creating layer scale2_2_D
I0523 15:14:00.492105 21880 net.cpp:141] Setting up scale2_2_D
I0523 15:14:00.492110 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.492122 21880 net.cpp:156] Memory required for data: 136378368
I0523 15:14:00.492126 21880 layer_factory.hpp:77] Creating layer relu2_2_D
I0523 15:14:00.492130 21880 net.cpp:91] Creating Layer relu2_2_D
I0523 15:14:00.492133 21880 net.cpp:425] relu2_2_D <- conv2_2_D
I0523 15:14:00.492136 21880 net.cpp:386] relu2_2_D -> conv2_2_D (in-place)
I0523 15:14:00.492378 21880 net.cpp:141] Setting up relu2_2_D
I0523 15:14:00.492398 21880 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0523 15:14:00.492400 21880 net.cpp:156] Memory required for data: 139589632
I0523 15:14:00.492403 21880 layer_factory.hpp:77] Creating layer conv2_1_D
I0523 15:14:00.492409 21880 net.cpp:91] Creating Layer conv2_1_D
I0523 15:14:00.492411 21880 net.cpp:425] conv2_1_D <- conv2_2_D
I0523 15:14:00.492415 21880 net.cpp:399] conv2_1_D -> conv2_1_D
I0523 15:14:00.493604 21880 net.cpp:141] Setting up conv2_1_D
I0523 15:14:00.493613 21880 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0523 15:14:00.493626 21880 net.cpp:156] Memory required for data: 141195264
I0523 15:14:00.493630 21880 layer_factory.hpp:77] Creating layer bn2_1_D
I0523 15:14:00.493634 21880 net.cpp:91] Creating Layer bn2_1_D
I0523 15:14:00.493638 21880 net.cpp:425] bn2_1_D <- conv2_1_D
I0523 15:14:00.493641 21880 net.cpp:386] bn2_1_D -> conv2_1_D (in-place)
I0523 15:14:00.493842 21880 net.cpp:141] Setting up bn2_1_D
I0523 15:14:00.493847 21880 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0523 15:14:00.493860 21880 net.cpp:156] Memory required for data: 142800896
I0523 15:14:00.493865 21880 layer_factory.hpp:77] Creating layer scale2_1_D
I0523 15:14:00.493870 21880 net.cpp:91] Creating Layer scale2_1_D
I0523 15:14:00.493871 21880 net.cpp:425] scale2_1_D <- conv2_1_D
I0523 15:14:00.493875 21880 net.cpp:386] scale2_1_D -> conv2_1_D (in-place)
I0523 15:14:00.493918 21880 layer_factory.hpp:77] Creating layer scale2_1_D
I0523 15:14:00.494048 21880 net.cpp:141] Setting up scale2_1_D
I0523 15:14:00.494053 21880 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0523 15:14:00.494065 21880 net.cpp:156] Memory required for data: 144406528
I0523 15:14:00.494069 21880 layer_factory.hpp:77] Creating layer relu2_1_D
I0523 15:14:00.494072 21880 net.cpp:91] Creating Layer relu2_1_D
I0523 15:14:00.494076 21880 net.cpp:425] relu2_1_D <- conv2_1_D
I0523 15:14:00.494077 21880 net.cpp:386] relu2_1_D -> conv2_1_D (in-place)
I0523 15:14:00.494223 21880 net.cpp:141] Setting up relu2_1_D
I0523 15:14:00.494230 21880 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0523 15:14:00.494241 21880 net.cpp:156] Memory required for data: 146012160
I0523 15:14:00.494243 21880 layer_factory.hpp:77] Creating layer upsample1
I0523 15:14:00.494248 21880 net.cpp:91] Creating Layer upsample1
I0523 15:14:00.494251 21880 net.cpp:425] upsample1 <- conv2_1_D
I0523 15:14:00.494253 21880 net.cpp:425] upsample1 <- pool1_mask
I0523 15:14:00.494257 21880 net.cpp:399] upsample1 -> pool1_D
I0523 15:14:00.494292 21880 net.cpp:141] Setting up upsample1
I0523 15:14:00.494297 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.494308 21880 net.cpp:156] Memory required for data: 152434688
I0523 15:14:00.494310 21880 layer_factory.hpp:77] Creating layer conv1_2_D
I0523 15:14:00.494318 21880 net.cpp:91] Creating Layer conv1_2_D
I0523 15:14:00.494319 21880 net.cpp:425] conv1_2_D <- pool1_D
I0523 15:14:00.494323 21880 net.cpp:399] conv1_2_D -> conv1_2_D
I0523 15:14:00.495437 21880 net.cpp:141] Setting up conv1_2_D
I0523 15:14:00.495447 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.495450 21880 net.cpp:156] Memory required for data: 158857216
I0523 15:14:00.495453 21880 layer_factory.hpp:77] Creating layer bn1_2_D
I0523 15:14:00.495467 21880 net.cpp:91] Creating Layer bn1_2_D
I0523 15:14:00.495471 21880 net.cpp:425] bn1_2_D <- conv1_2_D
I0523 15:14:00.495473 21880 net.cpp:386] bn1_2_D -> conv1_2_D (in-place)
I0523 15:14:00.495702 21880 net.cpp:141] Setting up bn1_2_D
I0523 15:14:00.495707 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.495708 21880 net.cpp:156] Memory required for data: 165279744
I0523 15:14:00.495713 21880 layer_factory.hpp:77] Creating layer scale1_2_D
I0523 15:14:00.495718 21880 net.cpp:91] Creating Layer scale1_2_D
I0523 15:14:00.495720 21880 net.cpp:425] scale1_2_D <- conv1_2_D
I0523 15:14:00.495724 21880 net.cpp:386] scale1_2_D -> conv1_2_D (in-place)
I0523 15:14:00.495760 21880 layer_factory.hpp:77] Creating layer scale1_2_D
I0523 15:14:00.495942 21880 net.cpp:141] Setting up scale1_2_D
I0523 15:14:00.495949 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.495950 21880 net.cpp:156] Memory required for data: 171702272
I0523 15:14:00.495954 21880 layer_factory.hpp:77] Creating layer relu1_2_D
I0523 15:14:00.495959 21880 net.cpp:91] Creating Layer relu1_2_D
I0523 15:14:00.495960 21880 net.cpp:425] relu1_2_D <- conv1_2_D
I0523 15:14:00.495964 21880 net.cpp:386] relu1_2_D -> conv1_2_D (in-place)
I0523 15:14:00.496109 21880 net.cpp:141] Setting up relu1_2_D
I0523 15:14:00.496115 21880 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0523 15:14:00.496117 21880 net.cpp:156] Memory required for data: 178124800
I0523 15:14:00.496119 21880 layer_factory.hpp:77] Creating layer conv1_1_D
I0523 15:14:00.496126 21880 net.cpp:91] Creating Layer conv1_1_D
I0523 15:14:00.496129 21880 net.cpp:425] conv1_1_D <- conv1_2_D
I0523 15:14:00.496134 21880 net.cpp:399] conv1_1_D -> conv1_1_D
I0523 15:14:00.497230 21880 net.cpp:141] Setting up conv1_1_D
I0523 15:14:00.497239 21880 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0523 15:14:00.497252 21880 net.cpp:156] Memory required for data: 178526208
I0523 15:14:00.497257 21880 layer_factory.hpp:77] Creating layer conv1_1_D_conv1_1_D_0_split
I0523 15:14:00.497263 21880 net.cpp:91] Creating Layer conv1_1_D_conv1_1_D_0_split
I0523 15:14:00.497265 21880 net.cpp:425] conv1_1_D_conv1_1_D_0_split <- conv1_1_D
I0523 15:14:00.497269 21880 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_0
I0523 15:14:00.497275 21880 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_1
I0523 15:14:00.497328 21880 net.cpp:141] Setting up conv1_1_D_conv1_1_D_0_split
I0523 15:14:00.497333 21880 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0523 15:14:00.497345 21880 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0523 15:14:00.497347 21880 net.cpp:156] Memory required for data: 179329024
I0523 15:14:00.497349 21880 layer_factory.hpp:77] Creating layer loss
I0523 15:14:00.497354 21880 net.cpp:91] Creating Layer loss
I0523 15:14:00.497356 21880 net.cpp:425] loss <- conv1_1_D_conv1_1_D_0_split_0
I0523 15:14:00.497359 21880 net.cpp:425] loss <- label_data_1_split_0
I0523 15:14:00.497362 21880 net.cpp:399] loss -> loss
I0523 15:14:00.497367 21880 layer_factory.hpp:77] Creating layer loss
I0523 15:14:00.497776 21880 net.cpp:141] Setting up loss
I0523 15:14:00.497786 21880 net.cpp:148] Top shape: (1)
I0523 15:14:00.497797 21880 net.cpp:151]     with loss weight 1
I0523 15:14:00.497805 21880 net.cpp:156] Memory required for data: 179329028
I0523 15:14:00.497808 21880 layer_factory.hpp:77] Creating layer accuracy
I0523 15:14:00.497813 21880 net.cpp:91] Creating Layer accuracy
I0523 15:14:00.497815 21880 net.cpp:425] accuracy <- conv1_1_D_conv1_1_D_0_split_1
I0523 15:14:00.497818 21880 net.cpp:425] accuracy <- label_data_1_split_1
I0523 15:14:00.497825 21880 net.cpp:399] accuracy -> accuracy
I0523 15:14:00.497831 21880 net.cpp:141] Setting up accuracy
I0523 15:14:00.497834 21880 net.cpp:148] Top shape: (1)
I0523 15:14:00.497836 21880 net.cpp:156] Memory required for data: 179329032
I0523 15:14:00.497838 21880 net.cpp:219] accuracy does not need backward computation.
I0523 15:14:00.497841 21880 net.cpp:217] loss needs backward computation.
I0523 15:14:00.497853 21880 net.cpp:217] conv1_1_D_conv1_1_D_0_split needs backward computation.
I0523 15:14:00.497854 21880 net.cpp:217] conv1_1_D needs backward computation.
I0523 15:14:00.497858 21880 net.cpp:217] relu1_2_D needs backward computation.
I0523 15:14:00.497859 21880 net.cpp:217] scale1_2_D needs backward computation.
I0523 15:14:00.497861 21880 net.cpp:217] bn1_2_D needs backward computation.
I0523 15:14:00.497862 21880 net.cpp:217] conv1_2_D needs backward computation.
I0523 15:14:00.497864 21880 net.cpp:217] upsample1 needs backward computation.
I0523 15:14:00.497867 21880 net.cpp:217] relu2_1_D needs backward computation.
I0523 15:14:00.497870 21880 net.cpp:217] scale2_1_D needs backward computation.
I0523 15:14:00.497872 21880 net.cpp:217] bn2_1_D needs backward computation.
I0523 15:14:00.497874 21880 net.cpp:217] conv2_1_D needs backward computation.
I0523 15:14:00.497876 21880 net.cpp:217] relu2_2_D needs backward computation.
I0523 15:14:00.497879 21880 net.cpp:217] scale2_2_D needs backward computation.
I0523 15:14:00.497880 21880 net.cpp:217] bn2_2_D needs backward computation.
I0523 15:14:00.497882 21880 net.cpp:217] conv2_2_D needs backward computation.
I0523 15:14:00.497884 21880 net.cpp:217] upsample2 needs backward computation.
I0523 15:14:00.497887 21880 net.cpp:217] relu3_1_D needs backward computation.
I0523 15:14:00.497890 21880 net.cpp:217] scale3_1_D needs backward computation.
I0523 15:14:00.497892 21880 net.cpp:217] bn3_1_D needs backward computation.
I0523 15:14:00.497895 21880 net.cpp:217] conv3_1_D needs backward computation.
I0523 15:14:00.497897 21880 net.cpp:217] relu3_2_D needs backward computation.
I0523 15:14:00.497900 21880 net.cpp:217] scale3_2_D needs backward computation.
I0523 15:14:00.497901 21880 net.cpp:217] bn3_2_D needs backward computation.
I0523 15:14:00.497903 21880 net.cpp:217] conv3_2_D needs backward computation.
I0523 15:14:00.497906 21880 net.cpp:217] upsample3 needs backward computation.
I0523 15:14:00.497908 21880 net.cpp:217] relu4_1_D needs backward computation.
I0523 15:14:00.497911 21880 net.cpp:217] scale4_1_D needs backward computation.
I0523 15:14:00.497913 21880 net.cpp:217] bn4_1_D needs backward computation.
I0523 15:14:00.497916 21880 net.cpp:217] conv4_1_D needs backward computation.
I0523 15:14:00.497920 21880 net.cpp:217] relu4_2_D needs backward computation.
I0523 15:14:00.497921 21880 net.cpp:217] scale4_2_D needs backward computation.
I0523 15:14:00.497923 21880 net.cpp:217] bn4_2_D needs backward computation.
I0523 15:14:00.497925 21880 net.cpp:217] conv4_2_D needs backward computation.
I0523 15:14:00.497928 21880 net.cpp:217] upsample4 needs backward computation.
I0523 15:14:00.497931 21880 net.cpp:217] relu5_1_D needs backward computation.
I0523 15:14:00.497934 21880 net.cpp:217] scale5_1_D needs backward computation.
I0523 15:14:00.497936 21880 net.cpp:217] bn5_1_D needs backward computation.
I0523 15:14:00.497938 21880 net.cpp:217] conv5_1_D needs backward computation.
I0523 15:14:00.497941 21880 net.cpp:217] relu5_2_D needs backward computation.
I0523 15:14:00.497943 21880 net.cpp:217] scale5_2_D needs backward computation.
I0523 15:14:00.497946 21880 net.cpp:217] bn5_2_D needs backward computation.
I0523 15:14:00.497947 21880 net.cpp:217] conv5_2_D needs backward computation.
I0523 15:14:00.497951 21880 net.cpp:217] upsample5 needs backward computation.
I0523 15:14:00.497954 21880 net.cpp:217] pool5 needs backward computation.
I0523 15:14:00.497957 21880 net.cpp:217] relu5_2 needs backward computation.
I0523 15:14:00.497959 21880 net.cpp:217] scale5_2 needs backward computation.
I0523 15:14:00.497961 21880 net.cpp:217] bn5_2 needs backward computation.
I0523 15:14:00.497963 21880 net.cpp:217] conv5_2 needs backward computation.
I0523 15:14:00.497967 21880 net.cpp:217] relu5_1 needs backward computation.
I0523 15:14:00.497968 21880 net.cpp:217] scale5_1 needs backward computation.
I0523 15:14:00.497970 21880 net.cpp:217] bn5_1 needs backward computation.
I0523 15:14:00.497972 21880 net.cpp:217] conv5_1 needs backward computation.
I0523 15:14:00.497979 21880 net.cpp:217] pool4 needs backward computation.
I0523 15:14:00.497982 21880 net.cpp:217] relu4_2 needs backward computation.
I0523 15:14:00.497984 21880 net.cpp:217] scale4_2 needs backward computation.
I0523 15:14:00.497987 21880 net.cpp:217] bn4_2 needs backward computation.
I0523 15:14:00.497989 21880 net.cpp:217] conv4_2 needs backward computation.
I0523 15:14:00.497992 21880 net.cpp:217] relu4_1 needs backward computation.
I0523 15:14:00.497993 21880 net.cpp:217] scale4_1 needs backward computation.
I0523 15:14:00.497995 21880 net.cpp:217] bn4_1 needs backward computation.
I0523 15:14:00.497998 21880 net.cpp:217] conv4_1 needs backward computation.
I0523 15:14:00.498000 21880 net.cpp:217] pool3 needs backward computation.
I0523 15:14:00.498003 21880 net.cpp:217] relu3_2 needs backward computation.
I0523 15:14:00.498006 21880 net.cpp:217] scale3_2 needs backward computation.
I0523 15:14:00.498008 21880 net.cpp:217] bn3_2 needs backward computation.
I0523 15:14:00.498010 21880 net.cpp:217] conv3_2 needs backward computation.
I0523 15:14:00.498013 21880 net.cpp:217] relu3_1 needs backward computation.
I0523 15:14:00.498015 21880 net.cpp:217] scale3_1 needs backward computation.
I0523 15:14:00.498018 21880 net.cpp:217] bn3_1 needs backward computation.
I0523 15:14:00.498019 21880 net.cpp:217] conv3_1 needs backward computation.
I0523 15:14:00.498023 21880 net.cpp:217] pool2 needs backward computation.
I0523 15:14:00.498025 21880 net.cpp:217] relu2_2 needs backward computation.
I0523 15:14:00.498028 21880 net.cpp:217] scale2_2 needs backward computation.
I0523 15:14:00.498030 21880 net.cpp:217] bn2_2 needs backward computation.
I0523 15:14:00.498033 21880 net.cpp:217] conv2_2 needs backward computation.
I0523 15:14:00.498034 21880 net.cpp:217] relu2_1 needs backward computation.
I0523 15:14:00.498037 21880 net.cpp:217] scale2_1 needs backward computation.
I0523 15:14:00.498039 21880 net.cpp:217] bn2_1 needs backward computation.
I0523 15:14:00.498041 21880 net.cpp:217] conv2_1 needs backward computation.
I0523 15:14:00.498045 21880 net.cpp:217] pool1 needs backward computation.
I0523 15:14:00.498047 21880 net.cpp:217] relu1_2 needs backward computation.
I0523 15:14:00.498049 21880 net.cpp:217] scale1_2 needs backward computation.
I0523 15:14:00.498051 21880 net.cpp:217] bn1_2 needs backward computation.
I0523 15:14:00.498054 21880 net.cpp:217] conv1_2 needs backward computation.
I0523 15:14:00.498056 21880 net.cpp:217] relu1_1 needs backward computation.
I0523 15:14:00.498059 21880 net.cpp:217] scale1_1 needs backward computation.
I0523 15:14:00.498060 21880 net.cpp:217] bn1_1 needs backward computation.
I0523 15:14:00.498062 21880 net.cpp:217] conv1_1 needs backward computation.
I0523 15:14:00.498067 21880 net.cpp:219] label_data_1_split does not need backward computation.
I0523 15:14:00.498070 21880 net.cpp:219] data does not need backward computation.
I0523 15:14:00.498072 21880 net.cpp:261] This network produces output accuracy
I0523 15:14:00.498075 21880 net.cpp:261] This network produces output loss
I0523 15:14:00.498106 21880 net.cpp:274] Network initialization done.
I0523 15:14:00.498330 21880 solver.cpp:60] Solver scaffolding done.
I0523 15:14:00.502480 21880 caffe.cpp:209] Resuming from data/models/segnet_iter_5000.solverstate
I0523 15:14:00.584270 21880 sgd_solver.cpp:318] SGDSolver: restoring history
I0523 15:14:00.594867 21880 caffe.cpp:219] Starting Optimization
I0523 15:14:00.594895 21880 solver.cpp:279] Solving segnet
I0523 15:14:00.594899 21880 solver.cpp:280] Learning Rate Policy: step
I0523 15:14:00.597647 21880 solver.cpp:337] Iteration 5000, Testing net (#0)
I0523 15:14:01.470727 21880 solver.cpp:404]     Test net output #0: accuracy = 0.98815
I0523 15:14:01.470755 21880 solver.cpp:404]     Test net output #1: loss = 0.0326981 (* 1 = 0.0326981 loss)
I0523 15:14:02.202735 21880 solver.cpp:228] Iteration 5000, loss = 0.0252585
I0523 15:14:02.202759 21880 solver.cpp:244]     Train net output #0: accuracy = 0.990705
I0523 15:14:02.202767 21880 solver.cpp:244]     Train net output #1: loss = 0.0252585 (* 1 = 0.0252585 loss)
I0523 15:14:02.202810 21880 sgd_solver.cpp:106] Iteration 5000, lr = 0.001
I0523 15:14:16.385725 21880 solver.cpp:228] Iteration 5020, loss = 0.0201454
I0523 15:14:16.385754 21880 solver.cpp:244]     Train net output #0: accuracy = 0.992276
I0523 15:14:16.385761 21880 solver.cpp:244]     Train net output #1: loss = 0.0201454 (* 1 = 0.0201454 loss)
I0523 15:14:16.385767 21880 sgd_solver.cpp:106] Iteration 5020, lr = 0.001
I0523 15:14:30.873921 21880 solver.cpp:228] Iteration 5040, loss = 0.0231382
I0523 15:14:30.874078 21880 solver.cpp:244]     Train net output #0: accuracy = 0.989082
I0523 15:14:30.874088 21880 solver.cpp:244]     Train net output #1: loss = 0.0231382 (* 1 = 0.0231382 loss)
I0523 15:14:30.874102 21880 sgd_solver.cpp:106] Iteration 5040, lr = 0.001
I0523 15:14:45.415004 21880 solver.cpp:228] Iteration 5060, loss = 0.0174377
I0523 15:14:45.415030 21880 solver.cpp:244]     Train net output #0: accuracy = 0.993896
I0523 15:14:45.415036 21880 solver.cpp:244]     Train net output #1: loss = 0.0174377 (* 1 = 0.0174377 loss)
I0523 15:14:45.415040 21880 sgd_solver.cpp:106] Iteration 5060, lr = 0.001
I0523 15:14:59.978575 21880 solver.cpp:228] Iteration 5080, loss = 0.020902
I0523 15:14:59.978603 21880 solver.cpp:244]     Train net output #0: accuracy = 0.992722
I0523 15:14:59.978611 21880 solver.cpp:244]     Train net output #1: loss = 0.020902 (* 1 = 0.020902 loss)
I0523 15:14:59.978616 21880 sgd_solver.cpp:106] Iteration 5080, lr = 0.001
I0523 15:15:14.190201 21880 solver.cpp:337] Iteration 5100, Testing net (#0)
I0523 15:15:15.049655 21880 solver.cpp:404]     Test net output #0: accuracy = 0.988033
I0523 15:15:15.049679 21880 solver.cpp:404]     Test net output #1: loss = 0.0302583 (* 1 = 0.0302583 loss)
I0523 15:15:15.455814 21880 solver.cpp:228] Iteration 5100, loss = 0.0230043
I0523 15:15:15.455842 21880 solver.cpp:244]     Train net output #0: accuracy = 0.990038
I0523 15:15:15.455849 21880 solver.cpp:244]     Train net output #1: loss = 0.0230043 (* 1 = 0.0230043 loss)
I0523 15:15:15.455855 21880 sgd_solver.cpp:106] Iteration 5100, lr = 0.001
I0523 15:15:30.105270 21880 solver.cpp:228] Iteration 5120, loss = 0.022822
I0523 15:15:30.105361 21880 solver.cpp:244]     Train net output #0: accuracy = 0.991537
I0523 15:15:30.105381 21880 solver.cpp:244]     Train net output #1: loss = 0.022822 (* 1 = 0.022822 loss)
I0523 15:15:30.105394 21880 sgd_solver.cpp:106] Iteration 5120, lr = 0.001
I0523 15:15:44.728390 21880 solver.cpp:228] Iteration 5140, loss = 0.0191662
I0523 15:15:44.728447 21880 solver.cpp:244]     Train net output #0: accuracy = 0.992472
I0523 15:15:44.728457 21880 solver.cpp:244]     Train net output #1: loss = 0.0191662 (* 1 = 0.0191662 loss)
I0523 15:15:44.728462 21880 sgd_solver.cpp:106] Iteration 5140, lr = 0.001
I0523 15:15:59.347085 21880 solver.cpp:228] Iteration 5160, loss = 0.0201113
I0523 15:15:59.347112 21880 solver.cpp:244]     Train net output #0: accuracy = 0.99189
I0523 15:15:59.347120 21880 solver.cpp:244]     Train net output #1: loss = 0.0201113 (* 1 = 0.0201113 loss)
I0523 15:15:59.347124 21880 sgd_solver.cpp:106] Iteration 5160, lr = 0.001
I0523 15:16:13.968029 21880 solver.cpp:228] Iteration 5180, loss = 0.0308152
I0523 15:16:13.968057 21880 solver.cpp:244]     Train net output #0: accuracy = 0.988404
I0523 15:16:13.968065 21880 solver.cpp:244]     Train net output #1: loss = 0.0308152 (* 1 = 0.0308152 loss)
I0523 15:16:13.968070 21880 sgd_solver.cpp:106] Iteration 5180, lr = 0.001
I0523 15:16:28.315613 21880 solver.cpp:337] Iteration 5200, Testing net (#0)
I0523 15:16:29.179019 21880 solver.cpp:404]     Test net output #0: accuracy = 0.982034
I0523 15:16:29.179044 21880 solver.cpp:404]     Test net output #1: loss = 0.042641 (* 1 = 0.042641 loss)
I0523 15:16:29.585136 21880 solver.cpp:228] Iteration 5200, loss = 0.026055
I0523 15:16:29.585162 21880 solver.cpp:244]     Train net output #0: accuracy = 0.990007
I0523 15:16:29.585170 21880 solver.cpp:244]     Train net output #1: loss = 0.026055 (* 1 = 0.026055 loss)
I0523 15:16:29.585173 21880 sgd_solver.cpp:106] Iteration 5200, lr = 0.001
I0523 15:16:44.213043 21880 solver.cpp:228] Iteration 5220, loss = 0.0271152
I0523 15:16:44.213080 21880 solver.cpp:244]     Train net output #0: accuracy = 0.989237
I0523 15:16:44.213088 21880 solver.cpp:244]     Train net output #1: loss = 0.0271152 (* 1 = 0.0271152 loss)
I0523 15:16:44.213093 21880 sgd_solver.cpp:106] Iteration 5220, lr = 0.001
I0523 15:16:58.843554 21880 solver.cpp:228] Iteration 5240, loss = 0.0187918
I0523 15:16:58.843664 21880 solver.cpp:244]     Train net output #0: accuracy = 0.993439
I0523 15:16:58.843683 21880 solver.cpp:244]     Train net output #1: loss = 0.0187918 (* 1 = 0.0187918 loss)
I0523 15:16:58.843688 21880 sgd_solver.cpp:106] Iteration 5240, lr = 0.001
I0523 15:17:13.474951 21880 solver.cpp:228] Iteration 5260, loss = 0.0215293
I0523 15:17:13.474978 21880 solver.cpp:244]     Train net output #0: accuracy = 0.992528
I0523 15:17:13.474985 21880 solver.cpp:244]     Train net output #1: loss = 0.0215293 (* 1 = 0.0215293 loss)
I0523 15:17:13.474992 21880 sgd_solver.cpp:106] Iteration 5260, lr = 0.001
I0523 15:17:28.101824 21880 solver.cpp:228] Iteration 5280, loss = 0.0283777
I0523 15:17:28.101850 21880 solver.cpp:244]     Train net output #0: accuracy = 0.99029
I0523 15:17:28.101857 21880 solver.cpp:244]     Train net output #1: loss = 0.0283777 (* 1 = 0.0283777 loss)
I0523 15:17:28.101862 21880 sgd_solver.cpp:106] Iteration 5280, lr = 0.001
I0523 15:17:42.324978 21880 solver.cpp:337] Iteration 5300, Testing net (#0)
I0523 15:17:43.217874 21880 solver.cpp:404]     Test net output #0: accuracy = 0.988081
I0523 15:17:43.217896 21880 solver.cpp:404]     Test net output #1: loss = 0.0350334 (* 1 = 0.0350334 loss)
I0523 15:17:43.627141 21880 solver.cpp:228] Iteration 5300, loss = 0.0245111
I0523 15:17:43.627166 21880 solver.cpp:244]     Train net output #0: accuracy = 0.990315
I0523 15:17:43.627174 21880 solver.cpp:244]     Train net output #1: loss = 0.0245111 (* 1 = 0.0245111 loss)
I0523 15:17:43.627180 21880 sgd_solver.cpp:106] Iteration 5300, lr = 0.001
I0523 15:17:58.247838 21880 solver.cpp:228] Iteration 5320, loss = 0.0229044
I0523 15:17:58.247865 21880 solver.cpp:244]     Train net output #0: accuracy = 0.990669
I0523 15:17:58.247872 21880 solver.cpp:244]     Train net output #1: loss = 0.0229044 (* 1 = 0.0229044 loss)
I0523 15:17:58.247877 21880 sgd_solver.cpp:106] Iteration 5320, lr = 0.001
I0523 15:18:12.888944 21880 solver.cpp:228] Iteration 5340, loss = 0.0310826
I0523 15:18:12.889024 21880 solver.cpp:244]     Train net output #0: accuracy = 0.987422
I0523 15:18:12.889042 21880 solver.cpp:244]     Train net output #1: loss = 0.0310826 (* 1 = 0.0310826 loss)
I0523 15:18:12.889047 21880 sgd_solver.cpp:106] Iteration 5340, lr = 0.001
I0523 15:18:27.526346 21880 solver.cpp:228] Iteration 5360, loss = 0.0227367
I0523 15:18:27.526373 21880 solver.cpp:244]     Train net output #0: accuracy = 0.99123
I0523 15:18:27.526381 21880 solver.cpp:244]     Train net output #1: loss = 0.0227367 (* 1 = 0.0227367 loss)
I0523 15:18:27.526386 21880 sgd_solver.cpp:106] Iteration 5360, lr = 0.001
I0523 15:18:42.157867 21880 solver.cpp:228] Iteration 5380, loss = 0.0198968
I0523 15:18:42.157892 21880 solver.cpp:244]     Train net output #0: accuracy = 0.992303
I0523 15:18:42.157899 21880 solver.cpp:244]     Train net output #1: loss = 0.0198968 (* 1 = 0.0198968 loss)
I0523 15:18:42.157904 21880 sgd_solver.cpp:106] Iteration 5380, lr = 0.001
I0523 15:18:56.380506 21880 solver.cpp:337] Iteration 5400, Testing net (#0)
I0523 15:18:57.244065 21880 solver.cpp:404]     Test net output #0: accuracy = 0.9858
I0523 15:18:57.244089 21880 solver.cpp:404]     Test net output #1: loss = 0.0362716 (* 1 = 0.0362716 loss)
I0523 15:18:57.649552 21880 solver.cpp:228] Iteration 5400, loss = 0.0174874
I0523 15:18:57.649577 21880 solver.cpp:244]     Train net output #0: accuracy = 0.993608
I0523 15:18:57.649585 21880 solver.cpp:244]     Train net output #1: loss = 0.0174874 (* 1 = 0.0174874 loss)
I0523 15:18:57.649590 21880 sgd_solver.cpp:106] Iteration 5400, lr = 0.001
I0523 15:19:12.548444 21880 solver.cpp:228] Iteration 5420, loss = 0.0242648
I0523 15:19:12.548473 21880 solver.cpp:244]     Train net output #0: accuracy = 0.989372
I0523 15:19:12.548480 21880 solver.cpp:244]     Train net output #1: loss = 0.0242648 (* 1 = 0.0242648 loss)
I0523 15:19:12.548485 21880 sgd_solver.cpp:106] Iteration 5420, lr = 0.001
I0523 15:19:27.177927 21880 solver.cpp:228] Iteration 5440, loss = 0.0195637
I0523 15:19:27.178023 21880 solver.cpp:244]     Train net output #0: accuracy = 0.99196
I0523 15:19:27.178033 21880 solver.cpp:244]     Train net output #1: loss = 0.0195637 (* 1 = 0.0195637 loss)
I0523 15:19:27.178048 21880 sgd_solver.cpp:106] Iteration 5440, lr = 0.001
I0523 15:19:41.834775 21880 solver.cpp:228] Iteration 5460, loss = 0.0269286
I0523 15:19:41.834803 21880 solver.cpp:244]     Train net output #0: accuracy = 0.990134
I0523 15:19:41.834810 21880 solver.cpp:244]     Train net output #1: loss = 0.0269286 (* 1 = 0.0269286 loss)
I0523 15:19:41.834815 21880 sgd_solver.cpp:106] Iteration 5460, lr = 0.001
I0523 15:19:56.477130 21880 solver.cpp:228] Iteration 5480, loss = 0.0220906
I0523 15:19:56.477156 21880 solver.cpp:244]     Train net output #0: accuracy = 0.992761
I0523 15:19:56.477164 21880 solver.cpp:244]     Train net output #1: loss = 0.0220906 (* 1 = 0.0220906 loss)
I0523 15:19:56.477170 21880 sgd_solver.cpp:106] Iteration 5480, lr = 0.001
I0523 15:20:10.709851 21880 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_5500.caffemodel
I0523 15:20:10.771206 21880 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_5500.solverstate
I0523 15:20:10.793184 21880 solver.cpp:337] Iteration 5500, Testing net (#0)
I0523 15:20:11.654616 21880 solver.cpp:404]     Test net output #0: accuracy = 0.986094
I0523 15:20:11.654652 21880 solver.cpp:404]     Test net output #1: loss = 0.0446189 (* 1 = 0.0446189 loss)
I0523 15:20:12.059864 21880 solver.cpp:228] Iteration 5500, loss = 0.026077
I0523 15:20:12.059890 21880 solver.cpp:244]     Train net output #0: accuracy = 0.988997
I0523 15:20:12.059898 21880 solver.cpp:244]     Train net output #1: loss = 0.026077 (* 1 = 0.026077 loss)
I0523 15:20:12.059903 21880 sgd_solver.cpp:106] Iteration 5500, lr = 0.001
I0523 15:20:26.696473 21880 solver.cpp:228] Iteration 5520, loss = 0.0207709
I0523 15:20:26.696501 21880 solver.cpp:244]     Train net output #0: accuracy = 0.989592
I0523 15:20:26.696508 21880 solver.cpp:244]     Train net output #1: loss = 0.0207709 (* 1 = 0.0207709 loss)
I0523 15:20:26.696513 21880 sgd_solver.cpp:106] Iteration 5520, lr = 0.001
I0523 15:20:41.327440 21880 solver.cpp:228] Iteration 5540, loss = 0.028134
I0523 15:20:41.327538 21880 solver.cpp:244]     Train net output #0: accuracy = 0.989285
I0523 15:20:41.327545 21880 solver.cpp:244]     Train net output #1: loss = 0.028134 (* 1 = 0.028134 loss)
I0523 15:20:41.327549 21880 sgd_solver.cpp:106] Iteration 5540, lr = 0.001
I0523 15:20:56.003669 21880 solver.cpp:228] Iteration 5560, loss = 0.0301244
I0523 15:20:56.003708 21880 solver.cpp:244]     Train net output #0: accuracy = 0.989021
I0523 15:20:56.003715 21880 solver.cpp:244]     Train net output #1: loss = 0.0301244 (* 1 = 0.0301244 loss)
I0523 15:20:56.003720 21880 sgd_solver.cpp:106] Iteration 5560, lr = 0.001
I0523 15:21:10.664095 21880 solver.cpp:228] Iteration 5580, loss = 0.0289837
I0523 15:21:10.664122 21880 solver.cpp:244]     Train net output #0: accuracy = 0.988852
I0523 15:21:10.664129 21880 solver.cpp:244]     Train net output #1: loss = 0.0289837 (* 1 = 0.0289837 loss)
I0523 15:21:10.664134 21880 sgd_solver.cpp:106] Iteration 5580, lr = 0.001
I0523 15:21:24.908385 21880 solver.cpp:337] Iteration 5600, Testing net (#0)
I0523 15:21:25.778612 21880 solver.cpp:404]     Test net output #0: accuracy = 0.987709
I0523 15:21:25.778635 21880 solver.cpp:404]     Test net output #1: loss = 0.0365102 (* 1 = 0.0365102 loss)
I0523 15:21:26.183413 21880 solver.cpp:228] Iteration 5600, loss = 0.0201269
I0523 15:21:26.183439 21880 solver.cpp:244]     Train net output #0: accuracy = 0.990952
I0523 15:21:26.183446 21880 solver.cpp:244]     Train net output #1: loss = 0.0201269 (* 1 = 0.0201269 loss)
I0523 15:21:26.183451 21880 sgd_solver.cpp:106] Iteration 5600, lr = 0.001
I0523 15:21:40.845397 21880 solver.cpp:228] Iteration 5620, loss = 0.0269023
I0523 15:21:40.845424 21880 solver.cpp:244]     Train net output #0: accuracy = 0.988412
I0523 15:21:40.845432 21880 solver.cpp:244]     Train net output #1: loss = 0.0269023 (* 1 = 0.0269023 loss)
I0523 15:21:40.845438 21880 sgd_solver.cpp:106] Iteration 5620, lr = 0.001
I0523 15:21:55.492367 21880 solver.cpp:228] Iteration 5640, loss = 0.0401943
I0523 15:21:55.492492 21880 solver.cpp:244]     Train net output #0: accuracy = 0.987193
I0523 15:21:55.492513 21880 solver.cpp:244]     Train net output #1: loss = 0.0401943 (* 1 = 0.0401943 loss)
I0523 15:21:55.492518 21880 sgd_solver.cpp:106] Iteration 5640, lr = 0.001
