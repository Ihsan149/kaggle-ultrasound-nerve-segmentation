I0624 17:17:22.903324 21500 caffe.cpp:185] Using GPUs 0
I0624 17:17:22.918680 21500 caffe.cpp:190] GPU 0: Graphics Device
I0624 17:17:23.351186 21500 solver.cpp:48] Initializing solver from parameters: 
test_iter: 16
test_interval: 100
base_lr: 0.01
display: 20
max_iter: 3000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 1000
snapshot: 500
snapshot_prefix: "data/models/bpgnet"
solver_mode: GPU
device_id: 0
net: "models/bpnet/train_val.prototxt"
test_initialization: true
iter_size: 1
I0624 17:17:23.351296 21500 solver.cpp:91] Creating training net from net file: models/bpnet/train_val.prototxt
I0624 17:17:23.352105 21500 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0624 17:17:23.352361 21500 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 100
    contrast_jitter_range: 0.1
  }
  data_param {
    source: "data/train_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 7
    stride: 1
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0624 17:17:23.352617 21500 layer_factory.hpp:77] Creating layer data
I0624 17:17:23.353014 21500 net.cpp:91] Creating Layer data
I0624 17:17:23.353026 21500 net.cpp:399] data -> data
I0624 17:17:23.353065 21500 net.cpp:399] data -> label
I0624 17:17:23.354378 21504 db_lmdb.cpp:35] Opened lmdb data/train_lmdb
I0624 17:17:23.379194 21500 data_layer.cpp:42] output data size: 32,3,224,224
I0624 17:17:23.419132 21500 net.cpp:141] Setting up data
I0624 17:17:23.419172 21500 net.cpp:148] Top shape: 32 3 224 224 (4816896)
I0624 17:17:23.419179 21500 net.cpp:148] Top shape: 32 (32)
I0624 17:17:23.419183 21500 net.cpp:156] Memory required for data: 19267712
I0624 17:17:23.419194 21500 layer_factory.hpp:77] Creating layer label_data_1_split
I0624 17:17:23.419216 21500 net.cpp:91] Creating Layer label_data_1_split
I0624 17:17:23.419221 21500 net.cpp:425] label_data_1_split <- label
I0624 17:17:23.419231 21500 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0624 17:17:23.419240 21500 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0624 17:17:23.419314 21500 net.cpp:141] Setting up label_data_1_split
I0624 17:17:23.419322 21500 net.cpp:148] Top shape: 32 (32)
I0624 17:17:23.419325 21500 net.cpp:148] Top shape: 32 (32)
I0624 17:17:23.419327 21500 net.cpp:156] Memory required for data: 19267968
I0624 17:17:23.419329 21500 layer_factory.hpp:77] Creating layer conv1_1
I0624 17:17:23.419344 21500 net.cpp:91] Creating Layer conv1_1
I0624 17:17:23.419349 21500 net.cpp:425] conv1_1 <- data
I0624 17:17:23.419353 21500 net.cpp:399] conv1_1 -> conv1_1
I0624 17:17:23.603634 21500 net.cpp:141] Setting up conv1_1
I0624 17:17:23.603659 21500 net.cpp:148] Top shape: 32 16 112 112 (6422528)
I0624 17:17:23.603662 21500 net.cpp:156] Memory required for data: 44958080
I0624 17:17:23.603673 21500 layer_factory.hpp:77] Creating layer bn1_1
I0624 17:17:23.603689 21500 net.cpp:91] Creating Layer bn1_1
I0624 17:17:23.603693 21500 net.cpp:425] bn1_1 <- conv1_1
I0624 17:17:23.603698 21500 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0624 17:17:23.604987 21500 net.cpp:141] Setting up bn1_1
I0624 17:17:23.605000 21500 net.cpp:148] Top shape: 32 16 112 112 (6422528)
I0624 17:17:23.605002 21500 net.cpp:156] Memory required for data: 70648192
I0624 17:17:23.605012 21500 layer_factory.hpp:77] Creating layer scale1_1
I0624 17:17:23.605021 21500 net.cpp:91] Creating Layer scale1_1
I0624 17:17:23.605023 21500 net.cpp:425] scale1_1 <- conv1_1
I0624 17:17:23.605029 21500 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0624 17:17:23.605068 21500 layer_factory.hpp:77] Creating layer scale1_1
I0624 17:17:23.605162 21500 net.cpp:141] Setting up scale1_1
I0624 17:17:23.605170 21500 net.cpp:148] Top shape: 32 16 112 112 (6422528)
I0624 17:17:23.605171 21500 net.cpp:156] Memory required for data: 96338304
I0624 17:17:23.605177 21500 layer_factory.hpp:77] Creating layer relu1_1
I0624 17:17:23.605183 21500 net.cpp:91] Creating Layer relu1_1
I0624 17:17:23.605188 21500 net.cpp:425] relu1_1 <- conv1_1
I0624 17:17:23.605192 21500 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0624 17:17:23.605322 21500 net.cpp:141] Setting up relu1_1
I0624 17:17:23.605330 21500 net.cpp:148] Top shape: 32 16 112 112 (6422528)
I0624 17:17:23.605332 21500 net.cpp:156] Memory required for data: 122028416
I0624 17:17:23.605335 21500 layer_factory.hpp:77] Creating layer conv1_2
I0624 17:17:23.605345 21500 net.cpp:91] Creating Layer conv1_2
I0624 17:17:23.605348 21500 net.cpp:425] conv1_2 <- conv1_1
I0624 17:17:23.605353 21500 net.cpp:399] conv1_2 -> conv1_2
I0624 17:17:23.606077 21500 net.cpp:141] Setting up conv1_2
I0624 17:17:23.606091 21500 net.cpp:148] Top shape: 32 16 112 112 (6422528)
I0624 17:17:23.606093 21500 net.cpp:156] Memory required for data: 147718528
I0624 17:17:23.606097 21500 layer_factory.hpp:77] Creating layer bn1_2
I0624 17:17:23.606103 21500 net.cpp:91] Creating Layer bn1_2
I0624 17:17:23.606106 21500 net.cpp:425] bn1_2 <- conv1_2
I0624 17:17:23.606111 21500 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0624 17:17:23.606243 21500 net.cpp:141] Setting up bn1_2
I0624 17:17:23.606250 21500 net.cpp:148] Top shape: 32 16 112 112 (6422528)
I0624 17:17:23.606252 21500 net.cpp:156] Memory required for data: 173408640
I0624 17:17:23.606261 21500 layer_factory.hpp:77] Creating layer scale1_2
I0624 17:17:23.606267 21500 net.cpp:91] Creating Layer scale1_2
I0624 17:17:23.606269 21500 net.cpp:425] scale1_2 <- conv1_2
I0624 17:17:23.606273 21500 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0624 17:17:23.606302 21500 layer_factory.hpp:77] Creating layer scale1_2
I0624 17:17:23.606384 21500 net.cpp:141] Setting up scale1_2
I0624 17:17:23.606390 21500 net.cpp:148] Top shape: 32 16 112 112 (6422528)
I0624 17:17:23.606394 21500 net.cpp:156] Memory required for data: 199098752
I0624 17:17:23.606397 21500 layer_factory.hpp:77] Creating layer relu1_2
I0624 17:17:23.606401 21500 net.cpp:91] Creating Layer relu1_2
I0624 17:17:23.606405 21500 net.cpp:425] relu1_2 <- conv1_2
I0624 17:17:23.606407 21500 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0624 17:17:23.606528 21500 net.cpp:141] Setting up relu1_2
I0624 17:17:23.606535 21500 net.cpp:148] Top shape: 32 16 112 112 (6422528)
I0624 17:17:23.606539 21500 net.cpp:156] Memory required for data: 224788864
I0624 17:17:23.606546 21500 layer_factory.hpp:77] Creating layer pool1
I0624 17:17:23.606551 21500 net.cpp:91] Creating Layer pool1
I0624 17:17:23.606554 21500 net.cpp:425] pool1 <- conv1_2
I0624 17:17:23.606559 21500 net.cpp:399] pool1 -> pool1
I0624 17:17:23.606600 21500 net.cpp:141] Setting up pool1
I0624 17:17:23.606604 21500 net.cpp:148] Top shape: 32 16 56 56 (1605632)
I0624 17:17:23.606621 21500 net.cpp:156] Memory required for data: 231211392
I0624 17:17:23.606622 21500 layer_factory.hpp:77] Creating layer conv2_1
I0624 17:17:23.606629 21500 net.cpp:91] Creating Layer conv2_1
I0624 17:17:23.606631 21500 net.cpp:425] conv2_1 <- pool1
I0624 17:17:23.606636 21500 net.cpp:399] conv2_1 -> conv2_1
I0624 17:17:23.607362 21500 net.cpp:141] Setting up conv2_1
I0624 17:17:23.607374 21500 net.cpp:148] Top shape: 32 32 56 56 (3211264)
I0624 17:17:23.607378 21500 net.cpp:156] Memory required for data: 244056448
I0624 17:17:23.607381 21500 layer_factory.hpp:77] Creating layer bn2_1
I0624 17:17:23.607388 21500 net.cpp:91] Creating Layer bn2_1
I0624 17:17:23.607390 21500 net.cpp:425] bn2_1 <- conv2_1
I0624 17:17:23.607394 21500 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0624 17:17:23.607522 21500 net.cpp:141] Setting up bn2_1
I0624 17:17:23.607527 21500 net.cpp:148] Top shape: 32 32 56 56 (3211264)
I0624 17:17:23.607530 21500 net.cpp:156] Memory required for data: 256901504
I0624 17:17:23.607535 21500 layer_factory.hpp:77] Creating layer scale2_1
I0624 17:17:23.607542 21500 net.cpp:91] Creating Layer scale2_1
I0624 17:17:23.607544 21500 net.cpp:425] scale2_1 <- conv2_1
I0624 17:17:23.607547 21500 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0624 17:17:23.607574 21500 layer_factory.hpp:77] Creating layer scale2_1
I0624 17:17:23.607653 21500 net.cpp:141] Setting up scale2_1
I0624 17:17:23.607659 21500 net.cpp:148] Top shape: 32 32 56 56 (3211264)
I0624 17:17:23.607661 21500 net.cpp:156] Memory required for data: 269746560
I0624 17:17:23.607668 21500 layer_factory.hpp:77] Creating layer relu2_1
I0624 17:17:23.607672 21500 net.cpp:91] Creating Layer relu2_1
I0624 17:17:23.607676 21500 net.cpp:425] relu2_1 <- conv2_1
I0624 17:17:23.607678 21500 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0624 17:17:23.608014 21500 net.cpp:141] Setting up relu2_1
I0624 17:17:23.608026 21500 net.cpp:148] Top shape: 32 32 56 56 (3211264)
I0624 17:17:23.608028 21500 net.cpp:156] Memory required for data: 282591616
I0624 17:17:23.608031 21500 layer_factory.hpp:77] Creating layer conv2_2
I0624 17:17:23.608039 21500 net.cpp:91] Creating Layer conv2_2
I0624 17:17:23.608042 21500 net.cpp:425] conv2_2 <- conv2_1
I0624 17:17:23.608047 21500 net.cpp:399] conv2_2 -> conv2_2
I0624 17:17:23.608577 21500 net.cpp:141] Setting up conv2_2
I0624 17:17:23.608587 21500 net.cpp:148] Top shape: 32 32 56 56 (3211264)
I0624 17:17:23.608589 21500 net.cpp:156] Memory required for data: 295436672
I0624 17:17:23.608593 21500 layer_factory.hpp:77] Creating layer bn2_2
I0624 17:17:23.608600 21500 net.cpp:91] Creating Layer bn2_2
I0624 17:17:23.608603 21500 net.cpp:425] bn2_2 <- conv2_2
I0624 17:17:23.608606 21500 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0624 17:17:23.608737 21500 net.cpp:141] Setting up bn2_2
I0624 17:17:23.608743 21500 net.cpp:148] Top shape: 32 32 56 56 (3211264)
I0624 17:17:23.608747 21500 net.cpp:156] Memory required for data: 308281728
I0624 17:17:23.608752 21500 layer_factory.hpp:77] Creating layer scale2_2
I0624 17:17:23.608757 21500 net.cpp:91] Creating Layer scale2_2
I0624 17:17:23.608760 21500 net.cpp:425] scale2_2 <- conv2_2
I0624 17:17:23.608764 21500 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0624 17:17:23.608791 21500 layer_factory.hpp:77] Creating layer scale2_2
I0624 17:17:23.608875 21500 net.cpp:141] Setting up scale2_2
I0624 17:17:23.608881 21500 net.cpp:148] Top shape: 32 32 56 56 (3211264)
I0624 17:17:23.608883 21500 net.cpp:156] Memory required for data: 321126784
I0624 17:17:23.608887 21500 layer_factory.hpp:77] Creating layer relu2_2
I0624 17:17:23.608891 21500 net.cpp:91] Creating Layer relu2_2
I0624 17:17:23.608894 21500 net.cpp:425] relu2_2 <- conv2_2
I0624 17:17:23.608897 21500 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0624 17:17:23.609230 21500 net.cpp:141] Setting up relu2_2
I0624 17:17:23.609241 21500 net.cpp:148] Top shape: 32 32 56 56 (3211264)
I0624 17:17:23.609244 21500 net.cpp:156] Memory required for data: 333971840
I0624 17:17:23.609247 21500 layer_factory.hpp:77] Creating layer pool2
I0624 17:17:23.609262 21500 net.cpp:91] Creating Layer pool2
I0624 17:17:23.609266 21500 net.cpp:425] pool2 <- conv2_2
I0624 17:17:23.609271 21500 net.cpp:399] pool2 -> pool2
I0624 17:17:23.609303 21500 net.cpp:141] Setting up pool2
I0624 17:17:23.609308 21500 net.cpp:148] Top shape: 32 32 28 28 (802816)
I0624 17:17:23.609310 21500 net.cpp:156] Memory required for data: 337183104
I0624 17:17:23.609313 21500 layer_factory.hpp:77] Creating layer conv3_1
I0624 17:17:23.609319 21500 net.cpp:91] Creating Layer conv3_1
I0624 17:17:23.609323 21500 net.cpp:425] conv3_1 <- pool2
I0624 17:17:23.609326 21500 net.cpp:399] conv3_1 -> conv3_1
I0624 17:17:23.611178 21500 net.cpp:141] Setting up conv3_1
I0624 17:17:23.611191 21500 net.cpp:148] Top shape: 32 64 28 28 (1605632)
I0624 17:17:23.611193 21500 net.cpp:156] Memory required for data: 343605632
I0624 17:17:23.611197 21500 layer_factory.hpp:77] Creating layer bn3_1
I0624 17:17:23.611203 21500 net.cpp:91] Creating Layer bn3_1
I0624 17:17:23.611207 21500 net.cpp:425] bn3_1 <- conv3_1
I0624 17:17:23.611210 21500 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0624 17:17:23.612442 21500 net.cpp:141] Setting up bn3_1
I0624 17:17:23.612452 21500 net.cpp:148] Top shape: 32 64 28 28 (1605632)
I0624 17:17:23.612455 21500 net.cpp:156] Memory required for data: 350028160
I0624 17:17:23.612462 21500 layer_factory.hpp:77] Creating layer scale3_1
I0624 17:17:23.612468 21500 net.cpp:91] Creating Layer scale3_1
I0624 17:17:23.612471 21500 net.cpp:425] scale3_1 <- conv3_1
I0624 17:17:23.612475 21500 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0624 17:17:23.612507 21500 layer_factory.hpp:77] Creating layer scale3_1
I0624 17:17:23.612586 21500 net.cpp:141] Setting up scale3_1
I0624 17:17:23.612596 21500 net.cpp:148] Top shape: 32 64 28 28 (1605632)
I0624 17:17:23.612598 21500 net.cpp:156] Memory required for data: 356450688
I0624 17:17:23.612602 21500 layer_factory.hpp:77] Creating layer relu3_1
I0624 17:17:23.612607 21500 net.cpp:91] Creating Layer relu3_1
I0624 17:17:23.612609 21500 net.cpp:425] relu3_1 <- conv3_1
I0624 17:17:23.612612 21500 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0624 17:17:23.612735 21500 net.cpp:141] Setting up relu3_1
I0624 17:17:23.612743 21500 net.cpp:148] Top shape: 32 64 28 28 (1605632)
I0624 17:17:23.612746 21500 net.cpp:156] Memory required for data: 362873216
I0624 17:17:23.612748 21500 layer_factory.hpp:77] Creating layer conv3_2
I0624 17:17:23.612756 21500 net.cpp:91] Creating Layer conv3_2
I0624 17:17:23.612757 21500 net.cpp:425] conv3_2 <- conv3_1
I0624 17:17:23.612761 21500 net.cpp:399] conv3_2 -> conv3_2
I0624 17:17:23.613665 21500 net.cpp:141] Setting up conv3_2
I0624 17:17:23.613678 21500 net.cpp:148] Top shape: 32 64 28 28 (1605632)
I0624 17:17:23.613680 21500 net.cpp:156] Memory required for data: 369295744
I0624 17:17:23.613684 21500 layer_factory.hpp:77] Creating layer bn3_2
I0624 17:17:23.613690 21500 net.cpp:91] Creating Layer bn3_2
I0624 17:17:23.613698 21500 net.cpp:425] bn3_2 <- conv3_2
I0624 17:17:23.613701 21500 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0624 17:17:23.613831 21500 net.cpp:141] Setting up bn3_2
I0624 17:17:23.613839 21500 net.cpp:148] Top shape: 32 64 28 28 (1605632)
I0624 17:17:23.613842 21500 net.cpp:156] Memory required for data: 375718272
I0624 17:17:23.613850 21500 layer_factory.hpp:77] Creating layer scale3_2
I0624 17:17:23.613857 21500 net.cpp:91] Creating Layer scale3_2
I0624 17:17:23.613858 21500 net.cpp:425] scale3_2 <- conv3_2
I0624 17:17:23.613862 21500 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0624 17:17:23.613891 21500 layer_factory.hpp:77] Creating layer scale3_2
I0624 17:17:23.613970 21500 net.cpp:141] Setting up scale3_2
I0624 17:17:23.613976 21500 net.cpp:148] Top shape: 32 64 28 28 (1605632)
I0624 17:17:23.613977 21500 net.cpp:156] Memory required for data: 382140800
I0624 17:17:23.613982 21500 layer_factory.hpp:77] Creating layer relu3_2
I0624 17:17:23.613986 21500 net.cpp:91] Creating Layer relu3_2
I0624 17:17:23.613989 21500 net.cpp:425] relu3_2 <- conv3_2
I0624 17:17:23.613992 21500 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0624 17:17:23.614125 21500 net.cpp:141] Setting up relu3_2
I0624 17:17:23.614132 21500 net.cpp:148] Top shape: 32 64 28 28 (1605632)
I0624 17:17:23.614135 21500 net.cpp:156] Memory required for data: 388563328
I0624 17:17:23.614137 21500 layer_factory.hpp:77] Creating layer pool3
I0624 17:17:23.614142 21500 net.cpp:91] Creating Layer pool3
I0624 17:17:23.614145 21500 net.cpp:425] pool3 <- conv3_2
I0624 17:17:23.614150 21500 net.cpp:399] pool3 -> pool3
I0624 17:17:23.614179 21500 net.cpp:141] Setting up pool3
I0624 17:17:23.614186 21500 net.cpp:148] Top shape: 32 64 14 14 (401408)
I0624 17:17:23.614187 21500 net.cpp:156] Memory required for data: 390168960
I0624 17:17:23.614190 21500 layer_factory.hpp:77] Creating layer conv4_1
I0624 17:17:23.614197 21500 net.cpp:91] Creating Layer conv4_1
I0624 17:17:23.614202 21500 net.cpp:425] conv4_1 <- pool3
I0624 17:17:23.614204 21500 net.cpp:399] conv4_1 -> conv4_1
I0624 17:17:23.616374 21500 net.cpp:141] Setting up conv4_1
I0624 17:17:23.616387 21500 net.cpp:148] Top shape: 32 128 14 14 (802816)
I0624 17:17:23.616390 21500 net.cpp:156] Memory required for data: 393380224
I0624 17:17:23.616394 21500 layer_factory.hpp:77] Creating layer bn4_1
I0624 17:17:23.616400 21500 net.cpp:91] Creating Layer bn4_1
I0624 17:17:23.616402 21500 net.cpp:425] bn4_1 <- conv4_1
I0624 17:17:23.616406 21500 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0624 17:17:23.616539 21500 net.cpp:141] Setting up bn4_1
I0624 17:17:23.616546 21500 net.cpp:148] Top shape: 32 128 14 14 (802816)
I0624 17:17:23.616549 21500 net.cpp:156] Memory required for data: 396591488
I0624 17:17:23.616554 21500 layer_factory.hpp:77] Creating layer scale4_1
I0624 17:17:23.616559 21500 net.cpp:91] Creating Layer scale4_1
I0624 17:17:23.616562 21500 net.cpp:425] scale4_1 <- conv4_1
I0624 17:17:23.616565 21500 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0624 17:17:23.616595 21500 layer_factory.hpp:77] Creating layer scale4_1
I0624 17:17:23.616665 21500 net.cpp:141] Setting up scale4_1
I0624 17:17:23.616672 21500 net.cpp:148] Top shape: 32 128 14 14 (802816)
I0624 17:17:23.616674 21500 net.cpp:156] Memory required for data: 399802752
I0624 17:17:23.616678 21500 layer_factory.hpp:77] Creating layer relu4_1
I0624 17:17:23.616684 21500 net.cpp:91] Creating Layer relu4_1
I0624 17:17:23.616688 21500 net.cpp:425] relu4_1 <- conv4_1
I0624 17:17:23.616690 21500 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0624 17:17:23.616812 21500 net.cpp:141] Setting up relu4_1
I0624 17:17:23.616821 21500 net.cpp:148] Top shape: 32 128 14 14 (802816)
I0624 17:17:23.616822 21500 net.cpp:156] Memory required for data: 403014016
I0624 17:17:23.616825 21500 layer_factory.hpp:77] Creating layer conv4_2
I0624 17:17:23.616832 21500 net.cpp:91] Creating Layer conv4_2
I0624 17:17:23.616835 21500 net.cpp:425] conv4_2 <- conv4_1
I0624 17:17:23.616839 21500 net.cpp:399] conv4_2 -> conv4_2
I0624 17:17:23.618557 21500 net.cpp:141] Setting up conv4_2
I0624 17:17:23.618569 21500 net.cpp:148] Top shape: 32 128 14 14 (802816)
I0624 17:17:23.618572 21500 net.cpp:156] Memory required for data: 406225280
I0624 17:17:23.618577 21500 layer_factory.hpp:77] Creating layer bn4_2
I0624 17:17:23.618583 21500 net.cpp:91] Creating Layer bn4_2
I0624 17:17:23.618587 21500 net.cpp:425] bn4_2 <- conv4_2
I0624 17:17:23.618590 21500 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0624 17:17:23.618721 21500 net.cpp:141] Setting up bn4_2
I0624 17:17:23.618728 21500 net.cpp:148] Top shape: 32 128 14 14 (802816)
I0624 17:17:23.618731 21500 net.cpp:156] Memory required for data: 409436544
I0624 17:17:23.618736 21500 layer_factory.hpp:77] Creating layer scale4_2
I0624 17:17:23.618741 21500 net.cpp:91] Creating Layer scale4_2
I0624 17:17:23.618744 21500 net.cpp:425] scale4_2 <- conv4_2
I0624 17:17:23.618747 21500 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0624 17:17:23.618777 21500 layer_factory.hpp:77] Creating layer scale4_2
I0624 17:17:23.618852 21500 net.cpp:141] Setting up scale4_2
I0624 17:17:23.618859 21500 net.cpp:148] Top shape: 32 128 14 14 (802816)
I0624 17:17:23.618860 21500 net.cpp:156] Memory required for data: 412647808
I0624 17:17:23.618875 21500 layer_factory.hpp:77] Creating layer relu4_2
I0624 17:17:23.618880 21500 net.cpp:91] Creating Layer relu4_2
I0624 17:17:23.618882 21500 net.cpp:425] relu4_2 <- conv4_2
I0624 17:17:23.618885 21500 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0624 17:17:23.619014 21500 net.cpp:141] Setting up relu4_2
I0624 17:17:23.619021 21500 net.cpp:148] Top shape: 32 128 14 14 (802816)
I0624 17:17:23.619024 21500 net.cpp:156] Memory required for data: 415859072
I0624 17:17:23.619026 21500 layer_factory.hpp:77] Creating layer pool4
I0624 17:17:23.619031 21500 net.cpp:91] Creating Layer pool4
I0624 17:17:23.619035 21500 net.cpp:425] pool4 <- conv4_2
I0624 17:17:23.619038 21500 net.cpp:399] pool4 -> pool4
I0624 17:17:23.619069 21500 net.cpp:141] Setting up pool4
I0624 17:17:23.619076 21500 net.cpp:148] Top shape: 32 128 7 7 (200704)
I0624 17:17:23.619078 21500 net.cpp:156] Memory required for data: 416661888
I0624 17:17:23.619081 21500 layer_factory.hpp:77] Creating layer conv5_1
I0624 17:17:23.619087 21500 net.cpp:91] Creating Layer conv5_1
I0624 17:17:23.619091 21500 net.cpp:425] conv5_1 <- pool4
I0624 17:17:23.619094 21500 net.cpp:399] conv5_1 -> conv5_1
I0624 17:17:23.620877 21500 net.cpp:141] Setting up conv5_1
I0624 17:17:23.620889 21500 net.cpp:148] Top shape: 32 128 7 7 (200704)
I0624 17:17:23.620892 21500 net.cpp:156] Memory required for data: 417464704
I0624 17:17:23.620896 21500 layer_factory.hpp:77] Creating layer bn5_1
I0624 17:17:23.620903 21500 net.cpp:91] Creating Layer bn5_1
I0624 17:17:23.620905 21500 net.cpp:425] bn5_1 <- conv5_1
I0624 17:17:23.620909 21500 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0624 17:17:23.621048 21500 net.cpp:141] Setting up bn5_1
I0624 17:17:23.621054 21500 net.cpp:148] Top shape: 32 128 7 7 (200704)
I0624 17:17:23.621057 21500 net.cpp:156] Memory required for data: 418267520
I0624 17:17:23.621062 21500 layer_factory.hpp:77] Creating layer scale5_1
I0624 17:17:23.621068 21500 net.cpp:91] Creating Layer scale5_1
I0624 17:17:23.621071 21500 net.cpp:425] scale5_1 <- conv5_1
I0624 17:17:23.621074 21500 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0624 17:17:23.621104 21500 layer_factory.hpp:77] Creating layer scale5_1
I0624 17:17:23.621177 21500 net.cpp:141] Setting up scale5_1
I0624 17:17:23.621183 21500 net.cpp:148] Top shape: 32 128 7 7 (200704)
I0624 17:17:23.621186 21500 net.cpp:156] Memory required for data: 419070336
I0624 17:17:23.621189 21500 layer_factory.hpp:77] Creating layer relu5_1
I0624 17:17:23.621193 21500 net.cpp:91] Creating Layer relu5_1
I0624 17:17:23.621197 21500 net.cpp:425] relu5_1 <- conv5_1
I0624 17:17:23.621201 21500 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0624 17:17:23.621543 21500 net.cpp:141] Setting up relu5_1
I0624 17:17:23.621554 21500 net.cpp:148] Top shape: 32 128 7 7 (200704)
I0624 17:17:23.621557 21500 net.cpp:156] Memory required for data: 419873152
I0624 17:17:23.621561 21500 layer_factory.hpp:77] Creating layer conv5_2
I0624 17:17:23.621567 21500 net.cpp:91] Creating Layer conv5_2
I0624 17:17:23.621570 21500 net.cpp:425] conv5_2 <- conv5_1
I0624 17:17:23.621575 21500 net.cpp:399] conv5_2 -> conv5_2
I0624 17:17:23.623131 21500 net.cpp:141] Setting up conv5_2
I0624 17:17:23.623143 21500 net.cpp:148] Top shape: 32 128 7 7 (200704)
I0624 17:17:23.623147 21500 net.cpp:156] Memory required for data: 420675968
I0624 17:17:23.623157 21500 layer_factory.hpp:77] Creating layer bn5_2
I0624 17:17:23.623163 21500 net.cpp:91] Creating Layer bn5_2
I0624 17:17:23.623167 21500 net.cpp:425] bn5_2 <- conv5_2
I0624 17:17:23.623170 21500 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0624 17:17:23.623325 21500 net.cpp:141] Setting up bn5_2
I0624 17:17:23.623334 21500 net.cpp:148] Top shape: 32 128 7 7 (200704)
I0624 17:17:23.623337 21500 net.cpp:156] Memory required for data: 421478784
I0624 17:17:23.623342 21500 layer_factory.hpp:77] Creating layer scale5_2
I0624 17:17:23.623348 21500 net.cpp:91] Creating Layer scale5_2
I0624 17:17:23.623352 21500 net.cpp:425] scale5_2 <- conv5_2
I0624 17:17:23.623355 21500 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0624 17:17:23.623399 21500 layer_factory.hpp:77] Creating layer scale5_2
I0624 17:17:23.623483 21500 net.cpp:141] Setting up scale5_2
I0624 17:17:23.623491 21500 net.cpp:148] Top shape: 32 128 7 7 (200704)
I0624 17:17:23.623492 21500 net.cpp:156] Memory required for data: 422281600
I0624 17:17:23.623497 21500 layer_factory.hpp:77] Creating layer relu5_2
I0624 17:17:23.623500 21500 net.cpp:91] Creating Layer relu5_2
I0624 17:17:23.623503 21500 net.cpp:425] relu5_2 <- conv5_2
I0624 17:17:23.623507 21500 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0624 17:17:23.623874 21500 net.cpp:141] Setting up relu5_2
I0624 17:17:23.623886 21500 net.cpp:148] Top shape: 32 128 7 7 (200704)
I0624 17:17:23.623889 21500 net.cpp:156] Memory required for data: 423084416
I0624 17:17:23.623893 21500 layer_factory.hpp:77] Creating layer pool5
I0624 17:17:23.623898 21500 net.cpp:91] Creating Layer pool5
I0624 17:17:23.623903 21500 net.cpp:425] pool5 <- conv5_2
I0624 17:17:23.623906 21500 net.cpp:399] pool5 -> pool5
I0624 17:17:23.624076 21500 net.cpp:141] Setting up pool5
I0624 17:17:23.624088 21500 net.cpp:148] Top shape: 32 128 1 1 (4096)
I0624 17:17:23.624089 21500 net.cpp:156] Memory required for data: 423100800
I0624 17:17:23.624092 21500 layer_factory.hpp:77] Creating layer fc2
I0624 17:17:23.624099 21500 net.cpp:91] Creating Layer fc2
I0624 17:17:23.624101 21500 net.cpp:425] fc2 <- pool5
I0624 17:17:23.624105 21500 net.cpp:399] fc2 -> fc2
I0624 17:17:23.624183 21500 net.cpp:141] Setting up fc2
I0624 17:17:23.624191 21500 net.cpp:148] Top shape: 32 2 (64)
I0624 17:17:23.624192 21500 net.cpp:156] Memory required for data: 423101056
I0624 17:17:23.624197 21500 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0624 17:17:23.624202 21500 net.cpp:91] Creating Layer fc2_fc2_0_split
I0624 17:17:23.624204 21500 net.cpp:425] fc2_fc2_0_split <- fc2
I0624 17:17:23.624208 21500 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0624 17:17:23.624212 21500 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0624 17:17:23.624240 21500 net.cpp:141] Setting up fc2_fc2_0_split
I0624 17:17:23.624243 21500 net.cpp:148] Top shape: 32 2 (64)
I0624 17:17:23.624246 21500 net.cpp:148] Top shape: 32 2 (64)
I0624 17:17:23.624248 21500 net.cpp:156] Memory required for data: 423101568
I0624 17:17:23.624250 21500 layer_factory.hpp:77] Creating layer loss
I0624 17:17:23.624260 21500 net.cpp:91] Creating Layer loss
I0624 17:17:23.624263 21500 net.cpp:425] loss <- fc2_fc2_0_split_0
I0624 17:17:23.624265 21500 net.cpp:425] loss <- label_data_1_split_0
I0624 17:17:23.624269 21500 net.cpp:399] loss -> loss
I0624 17:17:23.624275 21500 layer_factory.hpp:77] Creating layer loss
I0624 17:17:23.624470 21500 net.cpp:141] Setting up loss
I0624 17:17:23.624478 21500 net.cpp:148] Top shape: (1)
I0624 17:17:23.624481 21500 net.cpp:151]     with loss weight 1
I0624 17:17:23.624495 21500 net.cpp:156] Memory required for data: 423101572
I0624 17:17:23.624497 21500 layer_factory.hpp:77] Creating layer accuracy
I0624 17:17:23.624502 21500 net.cpp:91] Creating Layer accuracy
I0624 17:17:23.624505 21500 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0624 17:17:23.624508 21500 net.cpp:425] accuracy <- label_data_1_split_1
I0624 17:17:23.624512 21500 net.cpp:399] accuracy -> accuracy
I0624 17:17:23.624518 21500 net.cpp:141] Setting up accuracy
I0624 17:17:23.624521 21500 net.cpp:148] Top shape: (1)
I0624 17:17:23.624523 21500 net.cpp:156] Memory required for data: 423101576
I0624 17:17:23.624526 21500 net.cpp:219] accuracy does not need backward computation.
I0624 17:17:23.624528 21500 net.cpp:217] loss needs backward computation.
I0624 17:17:23.624531 21500 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0624 17:17:23.624533 21500 net.cpp:217] fc2 needs backward computation.
I0624 17:17:23.624536 21500 net.cpp:217] pool5 needs backward computation.
I0624 17:17:23.624538 21500 net.cpp:217] relu5_2 needs backward computation.
I0624 17:17:23.624541 21500 net.cpp:217] scale5_2 needs backward computation.
I0624 17:17:23.624542 21500 net.cpp:217] bn5_2 needs backward computation.
I0624 17:17:23.624553 21500 net.cpp:217] conv5_2 needs backward computation.
I0624 17:17:23.624557 21500 net.cpp:217] relu5_1 needs backward computation.
I0624 17:17:23.624558 21500 net.cpp:217] scale5_1 needs backward computation.
I0624 17:17:23.624560 21500 net.cpp:217] bn5_1 needs backward computation.
I0624 17:17:23.624562 21500 net.cpp:217] conv5_1 needs backward computation.
I0624 17:17:23.624564 21500 net.cpp:217] pool4 needs backward computation.
I0624 17:17:23.624567 21500 net.cpp:217] relu4_2 needs backward computation.
I0624 17:17:23.624568 21500 net.cpp:217] scale4_2 needs backward computation.
I0624 17:17:23.624570 21500 net.cpp:217] bn4_2 needs backward computation.
I0624 17:17:23.624572 21500 net.cpp:217] conv4_2 needs backward computation.
I0624 17:17:23.624575 21500 net.cpp:217] relu4_1 needs backward computation.
I0624 17:17:23.624577 21500 net.cpp:217] scale4_1 needs backward computation.
I0624 17:17:23.624579 21500 net.cpp:217] bn4_1 needs backward computation.
I0624 17:17:23.624582 21500 net.cpp:217] conv4_1 needs backward computation.
I0624 17:17:23.624583 21500 net.cpp:217] pool3 needs backward computation.
I0624 17:17:23.624585 21500 net.cpp:217] relu3_2 needs backward computation.
I0624 17:17:23.624588 21500 net.cpp:217] scale3_2 needs backward computation.
I0624 17:17:23.624589 21500 net.cpp:217] bn3_2 needs backward computation.
I0624 17:17:23.624591 21500 net.cpp:217] conv3_2 needs backward computation.
I0624 17:17:23.624594 21500 net.cpp:217] relu3_1 needs backward computation.
I0624 17:17:23.624596 21500 net.cpp:217] scale3_1 needs backward computation.
I0624 17:17:23.624598 21500 net.cpp:217] bn3_1 needs backward computation.
I0624 17:17:23.624599 21500 net.cpp:217] conv3_1 needs backward computation.
I0624 17:17:23.624603 21500 net.cpp:217] pool2 needs backward computation.
I0624 17:17:23.624605 21500 net.cpp:217] relu2_2 needs backward computation.
I0624 17:17:23.624608 21500 net.cpp:217] scale2_2 needs backward computation.
I0624 17:17:23.624609 21500 net.cpp:217] bn2_2 needs backward computation.
I0624 17:17:23.624611 21500 net.cpp:217] conv2_2 needs backward computation.
I0624 17:17:23.624614 21500 net.cpp:217] relu2_1 needs backward computation.
I0624 17:17:23.624615 21500 net.cpp:217] scale2_1 needs backward computation.
I0624 17:17:23.624617 21500 net.cpp:217] bn2_1 needs backward computation.
I0624 17:17:23.624619 21500 net.cpp:217] conv2_1 needs backward computation.
I0624 17:17:23.624622 21500 net.cpp:217] pool1 needs backward computation.
I0624 17:17:23.624624 21500 net.cpp:217] relu1_2 needs backward computation.
I0624 17:17:23.624626 21500 net.cpp:217] scale1_2 needs backward computation.
I0624 17:17:23.624629 21500 net.cpp:217] bn1_2 needs backward computation.
I0624 17:17:23.624630 21500 net.cpp:217] conv1_2 needs backward computation.
I0624 17:17:23.624634 21500 net.cpp:217] relu1_1 needs backward computation.
I0624 17:17:23.624635 21500 net.cpp:217] scale1_1 needs backward computation.
I0624 17:17:23.624637 21500 net.cpp:217] bn1_1 needs backward computation.
I0624 17:17:23.624639 21500 net.cpp:217] conv1_1 needs backward computation.
I0624 17:17:23.624642 21500 net.cpp:219] label_data_1_split does not need backward computation.
I0624 17:17:23.624645 21500 net.cpp:219] data does not need backward computation.
I0624 17:17:23.624647 21500 net.cpp:261] This network produces output accuracy
I0624 17:17:23.624650 21500 net.cpp:261] This network produces output loss
I0624 17:17:23.624667 21500 net.cpp:274] Network initialization done.
I0624 17:17:23.625478 21500 solver.cpp:181] Creating test net (#0) specified by net file: models/bpnet/train_val.prototxt
I0624 17:17:23.625530 21500 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0624 17:17:23.625761 21500 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 224
    mean_value: 100
    contrast_jitter_range: 0.1
  }
  data_param {
    source: "data/val_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  pooling_param {
    pool: AVE
    kernel_size: 7
    stride: 1
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0624 17:17:23.625891 21500 layer_factory.hpp:77] Creating layer data
I0624 17:17:23.625951 21500 net.cpp:91] Creating Layer data
I0624 17:17:23.625957 21500 net.cpp:399] data -> data
I0624 17:17:23.625963 21500 net.cpp:399] data -> label
I0624 17:17:23.626840 21506 db_lmdb.cpp:35] Opened lmdb data/val_lmdb
I0624 17:17:23.627182 21500 data_layer.cpp:42] output data size: 32,3,224,224
I0624 17:17:23.667965 21500 net.cpp:141] Setting up data
I0624 17:17:23.667989 21500 net.cpp:148] Top shape: 32 3 224 224 (4816896)
I0624 17:17:23.667994 21500 net.cpp:148] Top shape: 32 (32)
I0624 17:17:23.667996 21500 net.cpp:156] Memory required for data: 19267712
I0624 17:17:23.668001 21500 layer_factory.hpp:77] Creating layer label_data_1_split
I0624 17:17:23.668012 21500 net.cpp:91] Creating Layer label_data_1_split
I0624 17:17:23.668016 21500 net.cpp:425] label_data_1_split <- label
I0624 17:17:23.668021 21500 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0624 17:17:23.668030 21500 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0624 17:17:23.668134 21500 net.cpp:141] Setting up label_data_1_split
I0624 17:17:23.668143 21500 net.cpp:148] Top shape: 32 (32)
I0624 17:17:23.668145 21500 net.cpp:148] Top shape: 32 (32)
I0624 17:17:23.668148 21500 net.cpp:156] Memory required for data: 19267968
I0624 17:17:23.668149 21500 layer_factory.hpp:77] Creating layer conv1_1
I0624 17:17:23.668161 21500 net.cpp:91] Creating Layer conv1_1
I0624 17:17:23.668164 21500 net.cpp:425] conv1_1 <- data
I0624 17:17:23.668169 21500 net.cpp:399] conv1_1 -> conv1_1
I0624 17:17:23.669096 21500 net.cpp:141] Setting up conv1_1
I0624 17:17:23.669109 21500 net.cpp:148] Top shape: 32 16 112 112 (6422528)
I0624 17:17:23.669112 21500 net.cpp:156] Memory required for data: 44958080
I0624 17:17:23.669119 21500 layer_factory.hpp:77] Creating layer bn1_1
I0624 17:17:23.669126 21500 net.cpp:91] Creating Layer bn1_1
I0624 17:17:23.669128 21500 net.cpp:425] bn1_1 <- conv1_1
I0624 17:17:23.669133 21500 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0624 17:17:23.669291 21500 net.cpp:141] Setting up bn1_1
I0624 17:17:23.669297 21500 net.cpp:148] Top shape: 32 16 112 112 (6422528)
I0624 17:17:23.669301 21500 net.cpp:156] Memory required for data: 70648192
I0624 17:17:23.669308 21500 layer_factory.hpp:77] Creating layer scale1_1
I0624 17:17:23.669317 21500 net.cpp:91] Creating Layer scale1_1
I0624 17:17:23.669319 21500 net.cpp:425] scale1_1 <- conv1_1
I0624 17:17:23.669323 21500 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0624 17:17:23.669371 21500 layer_factory.hpp:77] Creating layer scale1_1
I0624 17:17:23.669473 21500 net.cpp:141] Setting up scale1_1
I0624 17:17:23.669481 21500 net.cpp:148] Top shape: 32 16 112 112 (6422528)
I0624 17:17:23.669483 21500 net.cpp:156] Memory required for data: 96338304
I0624 17:17:23.669489 21500 layer_factory.hpp:77] Creating layer relu1_1
I0624 17:17:23.669494 21500 net.cpp:91] Creating Layer relu1_1
I0624 17:17:23.669497 21500 net.cpp:425] relu1_1 <- conv1_1
I0624 17:17:23.669500 21500 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0624 17:17:23.669628 21500 net.cpp:141] Setting up relu1_1
I0624 17:17:23.669636 21500 net.cpp:148] Top shape: 32 16 112 112 (6422528)
I0624 17:17:23.669638 21500 net.cpp:156] Memory required for data: 122028416
I0624 17:17:23.669641 21500 layer_factory.hpp:77] Creating layer conv1_2
I0624 17:17:23.669648 21500 net.cpp:91] Creating Layer conv1_2
I0624 17:17:23.669651 21500 net.cpp:425] conv1_2 <- conv1_1
I0624 17:17:23.669656 21500 net.cpp:399] conv1_2 -> conv1_2
I0624 17:17:23.672159 21500 net.cpp:141] Setting up conv1_2
I0624 17:17:23.672173 21500 net.cpp:148] Top shape: 32 16 112 112 (6422528)
I0624 17:17:23.672176 21500 net.cpp:156] Memory required for data: 147718528
I0624 17:17:23.672180 21500 layer_factory.hpp:77] Creating layer bn1_2
I0624 17:17:23.672186 21500 net.cpp:91] Creating Layer bn1_2
I0624 17:17:23.672189 21500 net.cpp:425] bn1_2 <- conv1_2
I0624 17:17:23.672194 21500 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0624 17:17:23.672345 21500 net.cpp:141] Setting up bn1_2
I0624 17:17:23.672351 21500 net.cpp:148] Top shape: 32 16 112 112 (6422528)
I0624 17:17:23.672354 21500 net.cpp:156] Memory required for data: 173408640
I0624 17:17:23.672363 21500 layer_factory.hpp:77] Creating layer scale1_2
I0624 17:17:23.672369 21500 net.cpp:91] Creating Layer scale1_2
I0624 17:17:23.672371 21500 net.cpp:425] scale1_2 <- conv1_2
I0624 17:17:23.672375 21500 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0624 17:17:23.672406 21500 layer_factory.hpp:77] Creating layer scale1_2
I0624 17:17:23.672502 21500 net.cpp:141] Setting up scale1_2
I0624 17:17:23.672508 21500 net.cpp:148] Top shape: 32 16 112 112 (6422528)
I0624 17:17:23.672510 21500 net.cpp:156] Memory required for data: 199098752
I0624 17:17:23.672514 21500 layer_factory.hpp:77] Creating layer relu1_2
I0624 17:17:23.672518 21500 net.cpp:91] Creating Layer relu1_2
I0624 17:17:23.672521 21500 net.cpp:425] relu1_2 <- conv1_2
I0624 17:17:23.672524 21500 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0624 17:17:23.672895 21500 net.cpp:141] Setting up relu1_2
I0624 17:17:23.672906 21500 net.cpp:148] Top shape: 32 16 112 112 (6422528)
I0624 17:17:23.672909 21500 net.cpp:156] Memory required for data: 224788864
I0624 17:17:23.672912 21500 layer_factory.hpp:77] Creating layer pool1
I0624 17:17:23.672919 21500 net.cpp:91] Creating Layer pool1
I0624 17:17:23.672921 21500 net.cpp:425] pool1 <- conv1_2
I0624 17:17:23.672925 21500 net.cpp:399] pool1 -> pool1
I0624 17:17:23.672961 21500 net.cpp:141] Setting up pool1
I0624 17:17:23.672966 21500 net.cpp:148] Top shape: 32 16 56 56 (1605632)
I0624 17:17:23.672967 21500 net.cpp:156] Memory required for data: 231211392
I0624 17:17:23.672969 21500 layer_factory.hpp:77] Creating layer conv2_1
I0624 17:17:23.672976 21500 net.cpp:91] Creating Layer conv2_1
I0624 17:17:23.672979 21500 net.cpp:425] conv2_1 <- pool1
I0624 17:17:23.672982 21500 net.cpp:399] conv2_1 -> conv2_1
I0624 17:17:23.673741 21500 net.cpp:141] Setting up conv2_1
I0624 17:17:23.673753 21500 net.cpp:148] Top shape: 32 32 56 56 (3211264)
I0624 17:17:23.673756 21500 net.cpp:156] Memory required for data: 244056448
I0624 17:17:23.673760 21500 layer_factory.hpp:77] Creating layer bn2_1
I0624 17:17:23.673766 21500 net.cpp:91] Creating Layer bn2_1
I0624 17:17:23.673769 21500 net.cpp:425] bn2_1 <- conv2_1
I0624 17:17:23.673774 21500 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0624 17:17:23.673913 21500 net.cpp:141] Setting up bn2_1
I0624 17:17:23.673918 21500 net.cpp:148] Top shape: 32 32 56 56 (3211264)
I0624 17:17:23.673921 21500 net.cpp:156] Memory required for data: 256901504
I0624 17:17:23.673938 21500 layer_factory.hpp:77] Creating layer scale2_1
I0624 17:17:23.673943 21500 net.cpp:91] Creating Layer scale2_1
I0624 17:17:23.673945 21500 net.cpp:425] scale2_1 <- conv2_1
I0624 17:17:23.673949 21500 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0624 17:17:23.673981 21500 layer_factory.hpp:77] Creating layer scale2_1
I0624 17:17:23.674069 21500 net.cpp:141] Setting up scale2_1
I0624 17:17:23.674075 21500 net.cpp:148] Top shape: 32 32 56 56 (3211264)
I0624 17:17:23.674078 21500 net.cpp:156] Memory required for data: 269746560
I0624 17:17:23.674085 21500 layer_factory.hpp:77] Creating layer relu2_1
I0624 17:17:23.674089 21500 net.cpp:91] Creating Layer relu2_1
I0624 17:17:23.674091 21500 net.cpp:425] relu2_1 <- conv2_1
I0624 17:17:23.674095 21500 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0624 17:17:23.674221 21500 net.cpp:141] Setting up relu2_1
I0624 17:17:23.674228 21500 net.cpp:148] Top shape: 32 32 56 56 (3211264)
I0624 17:17:23.674231 21500 net.cpp:156] Memory required for data: 282591616
I0624 17:17:23.674233 21500 layer_factory.hpp:77] Creating layer conv2_2
I0624 17:17:23.674239 21500 net.cpp:91] Creating Layer conv2_2
I0624 17:17:23.674242 21500 net.cpp:425] conv2_2 <- conv2_1
I0624 17:17:23.674247 21500 net.cpp:399] conv2_2 -> conv2_2
I0624 17:17:23.675052 21500 net.cpp:141] Setting up conv2_2
I0624 17:17:23.675104 21500 net.cpp:148] Top shape: 32 32 56 56 (3211264)
I0624 17:17:23.675110 21500 net.cpp:156] Memory required for data: 295436672
I0624 17:17:23.675115 21500 layer_factory.hpp:77] Creating layer bn2_2
I0624 17:17:23.675122 21500 net.cpp:91] Creating Layer bn2_2
I0624 17:17:23.675125 21500 net.cpp:425] bn2_2 <- conv2_2
I0624 17:17:23.675129 21500 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0624 17:17:23.675287 21500 net.cpp:141] Setting up bn2_2
I0624 17:17:23.675295 21500 net.cpp:148] Top shape: 32 32 56 56 (3211264)
I0624 17:17:23.675297 21500 net.cpp:156] Memory required for data: 308281728
I0624 17:17:23.675303 21500 layer_factory.hpp:77] Creating layer scale2_2
I0624 17:17:23.675308 21500 net.cpp:91] Creating Layer scale2_2
I0624 17:17:23.675312 21500 net.cpp:425] scale2_2 <- conv2_2
I0624 17:17:23.675315 21500 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0624 17:17:23.675345 21500 layer_factory.hpp:77] Creating layer scale2_2
I0624 17:17:23.675431 21500 net.cpp:141] Setting up scale2_2
I0624 17:17:23.675437 21500 net.cpp:148] Top shape: 32 32 56 56 (3211264)
I0624 17:17:23.675441 21500 net.cpp:156] Memory required for data: 321126784
I0624 17:17:23.675444 21500 layer_factory.hpp:77] Creating layer relu2_2
I0624 17:17:23.675448 21500 net.cpp:91] Creating Layer relu2_2
I0624 17:17:23.675451 21500 net.cpp:425] relu2_2 <- conv2_2
I0624 17:17:23.675454 21500 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0624 17:17:23.675595 21500 net.cpp:141] Setting up relu2_2
I0624 17:17:23.675603 21500 net.cpp:148] Top shape: 32 32 56 56 (3211264)
I0624 17:17:23.675606 21500 net.cpp:156] Memory required for data: 333971840
I0624 17:17:23.675609 21500 layer_factory.hpp:77] Creating layer pool2
I0624 17:17:23.675614 21500 net.cpp:91] Creating Layer pool2
I0624 17:17:23.675616 21500 net.cpp:425] pool2 <- conv2_2
I0624 17:17:23.675621 21500 net.cpp:399] pool2 -> pool2
I0624 17:17:23.675652 21500 net.cpp:141] Setting up pool2
I0624 17:17:23.675657 21500 net.cpp:148] Top shape: 32 32 28 28 (802816)
I0624 17:17:23.675658 21500 net.cpp:156] Memory required for data: 337183104
I0624 17:17:23.675660 21500 layer_factory.hpp:77] Creating layer conv3_1
I0624 17:17:23.675668 21500 net.cpp:91] Creating Layer conv3_1
I0624 17:17:23.675669 21500 net.cpp:425] conv3_1 <- pool2
I0624 17:17:23.675673 21500 net.cpp:399] conv3_1 -> conv3_1
I0624 17:17:23.676728 21500 net.cpp:141] Setting up conv3_1
I0624 17:17:23.676740 21500 net.cpp:148] Top shape: 32 64 28 28 (1605632)
I0624 17:17:23.676743 21500 net.cpp:156] Memory required for data: 343605632
I0624 17:17:23.676748 21500 layer_factory.hpp:77] Creating layer bn3_1
I0624 17:17:23.676753 21500 net.cpp:91] Creating Layer bn3_1
I0624 17:17:23.676765 21500 net.cpp:425] bn3_1 <- conv3_1
I0624 17:17:23.676770 21500 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0624 17:17:23.676920 21500 net.cpp:141] Setting up bn3_1
I0624 17:17:23.676928 21500 net.cpp:148] Top shape: 32 64 28 28 (1605632)
I0624 17:17:23.676929 21500 net.cpp:156] Memory required for data: 350028160
I0624 17:17:23.676935 21500 layer_factory.hpp:77] Creating layer scale3_1
I0624 17:17:23.676940 21500 net.cpp:91] Creating Layer scale3_1
I0624 17:17:23.676944 21500 net.cpp:425] scale3_1 <- conv3_1
I0624 17:17:23.676947 21500 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0624 17:17:23.676977 21500 layer_factory.hpp:77] Creating layer scale3_1
I0624 17:17:23.677062 21500 net.cpp:141] Setting up scale3_1
I0624 17:17:23.677069 21500 net.cpp:148] Top shape: 32 64 28 28 (1605632)
I0624 17:17:23.677072 21500 net.cpp:156] Memory required for data: 356450688
I0624 17:17:23.677075 21500 layer_factory.hpp:77] Creating layer relu3_1
I0624 17:17:23.677079 21500 net.cpp:91] Creating Layer relu3_1
I0624 17:17:23.677083 21500 net.cpp:425] relu3_1 <- conv3_1
I0624 17:17:23.677085 21500 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0624 17:17:23.677213 21500 net.cpp:141] Setting up relu3_1
I0624 17:17:23.677222 21500 net.cpp:148] Top shape: 32 64 28 28 (1605632)
I0624 17:17:23.677223 21500 net.cpp:156] Memory required for data: 362873216
I0624 17:17:23.677225 21500 layer_factory.hpp:77] Creating layer conv3_2
I0624 17:17:23.677232 21500 net.cpp:91] Creating Layer conv3_2
I0624 17:17:23.677235 21500 net.cpp:425] conv3_2 <- conv3_1
I0624 17:17:23.677239 21500 net.cpp:399] conv3_2 -> conv3_2
I0624 17:17:23.678185 21500 net.cpp:141] Setting up conv3_2
I0624 17:17:23.678199 21500 net.cpp:148] Top shape: 32 64 28 28 (1605632)
I0624 17:17:23.678201 21500 net.cpp:156] Memory required for data: 369295744
I0624 17:17:23.678205 21500 layer_factory.hpp:77] Creating layer bn3_2
I0624 17:17:23.678212 21500 net.cpp:91] Creating Layer bn3_2
I0624 17:17:23.678215 21500 net.cpp:425] bn3_2 <- conv3_2
I0624 17:17:23.678218 21500 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0624 17:17:23.678362 21500 net.cpp:141] Setting up bn3_2
I0624 17:17:23.678369 21500 net.cpp:148] Top shape: 32 64 28 28 (1605632)
I0624 17:17:23.678371 21500 net.cpp:156] Memory required for data: 375718272
I0624 17:17:23.678380 21500 layer_factory.hpp:77] Creating layer scale3_2
I0624 17:17:23.678385 21500 net.cpp:91] Creating Layer scale3_2
I0624 17:17:23.678388 21500 net.cpp:425] scale3_2 <- conv3_2
I0624 17:17:23.678391 21500 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0624 17:17:23.678422 21500 layer_factory.hpp:77] Creating layer scale3_2
I0624 17:17:23.678506 21500 net.cpp:141] Setting up scale3_2
I0624 17:17:23.678514 21500 net.cpp:148] Top shape: 32 64 28 28 (1605632)
I0624 17:17:23.678515 21500 net.cpp:156] Memory required for data: 382140800
I0624 17:17:23.678519 21500 layer_factory.hpp:77] Creating layer relu3_2
I0624 17:17:23.678524 21500 net.cpp:91] Creating Layer relu3_2
I0624 17:17:23.678526 21500 net.cpp:425] relu3_2 <- conv3_2
I0624 17:17:23.678529 21500 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0624 17:17:23.678650 21500 net.cpp:141] Setting up relu3_2
I0624 17:17:23.678658 21500 net.cpp:148] Top shape: 32 64 28 28 (1605632)
I0624 17:17:23.678661 21500 net.cpp:156] Memory required for data: 388563328
I0624 17:17:23.678663 21500 layer_factory.hpp:77] Creating layer pool3
I0624 17:17:23.678668 21500 net.cpp:91] Creating Layer pool3
I0624 17:17:23.678671 21500 net.cpp:425] pool3 <- conv3_2
I0624 17:17:23.678674 21500 net.cpp:399] pool3 -> pool3
I0624 17:17:23.678707 21500 net.cpp:141] Setting up pool3
I0624 17:17:23.678711 21500 net.cpp:148] Top shape: 32 64 14 14 (401408)
I0624 17:17:23.678714 21500 net.cpp:156] Memory required for data: 390168960
I0624 17:17:23.678715 21500 layer_factory.hpp:77] Creating layer conv4_1
I0624 17:17:23.678721 21500 net.cpp:91] Creating Layer conv4_1
I0624 17:17:23.678725 21500 net.cpp:425] conv4_1 <- pool3
I0624 17:17:23.678728 21500 net.cpp:399] conv4_1 -> conv4_1
I0624 17:17:23.680968 21500 net.cpp:141] Setting up conv4_1
I0624 17:17:23.680991 21500 net.cpp:148] Top shape: 32 128 14 14 (802816)
I0624 17:17:23.680994 21500 net.cpp:156] Memory required for data: 393380224
I0624 17:17:23.680999 21500 layer_factory.hpp:77] Creating layer bn4_1
I0624 17:17:23.681005 21500 net.cpp:91] Creating Layer bn4_1
I0624 17:17:23.681007 21500 net.cpp:425] bn4_1 <- conv4_1
I0624 17:17:23.681012 21500 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0624 17:17:23.681156 21500 net.cpp:141] Setting up bn4_1
I0624 17:17:23.681162 21500 net.cpp:148] Top shape: 32 128 14 14 (802816)
I0624 17:17:23.681165 21500 net.cpp:156] Memory required for data: 396591488
I0624 17:17:23.681170 21500 layer_factory.hpp:77] Creating layer scale4_1
I0624 17:17:23.681176 21500 net.cpp:91] Creating Layer scale4_1
I0624 17:17:23.681180 21500 net.cpp:425] scale4_1 <- conv4_1
I0624 17:17:23.681182 21500 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0624 17:17:23.681213 21500 layer_factory.hpp:77] Creating layer scale4_1
I0624 17:17:23.681289 21500 net.cpp:141] Setting up scale4_1
I0624 17:17:23.681295 21500 net.cpp:148] Top shape: 32 128 14 14 (802816)
I0624 17:17:23.681298 21500 net.cpp:156] Memory required for data: 399802752
I0624 17:17:23.681303 21500 layer_factory.hpp:77] Creating layer relu4_1
I0624 17:17:23.681309 21500 net.cpp:91] Creating Layer relu4_1
I0624 17:17:23.681313 21500 net.cpp:425] relu4_1 <- conv4_1
I0624 17:17:23.681315 21500 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0624 17:17:23.681438 21500 net.cpp:141] Setting up relu4_1
I0624 17:17:23.681447 21500 net.cpp:148] Top shape: 32 128 14 14 (802816)
I0624 17:17:23.681448 21500 net.cpp:156] Memory required for data: 403014016
I0624 17:17:23.681452 21500 layer_factory.hpp:77] Creating layer conv4_2
I0624 17:17:23.681458 21500 net.cpp:91] Creating Layer conv4_2
I0624 17:17:23.681462 21500 net.cpp:425] conv4_2 <- conv4_1
I0624 17:17:23.681465 21500 net.cpp:399] conv4_2 -> conv4_2
I0624 17:17:23.683312 21500 net.cpp:141] Setting up conv4_2
I0624 17:17:23.683328 21500 net.cpp:148] Top shape: 32 128 14 14 (802816)
I0624 17:17:23.683331 21500 net.cpp:156] Memory required for data: 406225280
I0624 17:17:23.683336 21500 layer_factory.hpp:77] Creating layer bn4_2
I0624 17:17:23.683341 21500 net.cpp:91] Creating Layer bn4_2
I0624 17:17:23.683344 21500 net.cpp:425] bn4_2 <- conv4_2
I0624 17:17:23.683349 21500 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0624 17:17:23.683495 21500 net.cpp:141] Setting up bn4_2
I0624 17:17:23.683501 21500 net.cpp:148] Top shape: 32 128 14 14 (802816)
I0624 17:17:23.683504 21500 net.cpp:156] Memory required for data: 409436544
I0624 17:17:23.683509 21500 layer_factory.hpp:77] Creating layer scale4_2
I0624 17:17:23.683516 21500 net.cpp:91] Creating Layer scale4_2
I0624 17:17:23.683517 21500 net.cpp:425] scale4_2 <- conv4_2
I0624 17:17:23.683521 21500 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0624 17:17:23.683552 21500 layer_factory.hpp:77] Creating layer scale4_2
I0624 17:17:23.683630 21500 net.cpp:141] Setting up scale4_2
I0624 17:17:23.683636 21500 net.cpp:148] Top shape: 32 128 14 14 (802816)
I0624 17:17:23.683639 21500 net.cpp:156] Memory required for data: 412647808
I0624 17:17:23.683642 21500 layer_factory.hpp:77] Creating layer relu4_2
I0624 17:17:23.683646 21500 net.cpp:91] Creating Layer relu4_2
I0624 17:17:23.683650 21500 net.cpp:425] relu4_2 <- conv4_2
I0624 17:17:23.683652 21500 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0624 17:17:23.684010 21500 net.cpp:141] Setting up relu4_2
I0624 17:17:23.684021 21500 net.cpp:148] Top shape: 32 128 14 14 (802816)
I0624 17:17:23.684023 21500 net.cpp:156] Memory required for data: 415859072
I0624 17:17:23.684026 21500 layer_factory.hpp:77] Creating layer pool4
I0624 17:17:23.684033 21500 net.cpp:91] Creating Layer pool4
I0624 17:17:23.684036 21500 net.cpp:425] pool4 <- conv4_2
I0624 17:17:23.684041 21500 net.cpp:399] pool4 -> pool4
I0624 17:17:23.684077 21500 net.cpp:141] Setting up pool4
I0624 17:17:23.684082 21500 net.cpp:148] Top shape: 32 128 7 7 (200704)
I0624 17:17:23.684083 21500 net.cpp:156] Memory required for data: 416661888
I0624 17:17:23.684095 21500 layer_factory.hpp:77] Creating layer conv5_1
I0624 17:17:23.684103 21500 net.cpp:91] Creating Layer conv5_1
I0624 17:17:23.684105 21500 net.cpp:425] conv5_1 <- pool4
I0624 17:17:23.684110 21500 net.cpp:399] conv5_1 -> conv5_1
I0624 17:17:23.685878 21500 net.cpp:141] Setting up conv5_1
I0624 17:17:23.685890 21500 net.cpp:148] Top shape: 32 128 7 7 (200704)
I0624 17:17:23.685894 21500 net.cpp:156] Memory required for data: 417464704
I0624 17:17:23.685897 21500 layer_factory.hpp:77] Creating layer bn5_1
I0624 17:17:23.685904 21500 net.cpp:91] Creating Layer bn5_1
I0624 17:17:23.685905 21500 net.cpp:425] bn5_1 <- conv5_1
I0624 17:17:23.685910 21500 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0624 17:17:23.686064 21500 net.cpp:141] Setting up bn5_1
I0624 17:17:23.686071 21500 net.cpp:148] Top shape: 32 128 7 7 (200704)
I0624 17:17:23.686074 21500 net.cpp:156] Memory required for data: 418267520
I0624 17:17:23.686079 21500 layer_factory.hpp:77] Creating layer scale5_1
I0624 17:17:23.686085 21500 net.cpp:91] Creating Layer scale5_1
I0624 17:17:23.686089 21500 net.cpp:425] scale5_1 <- conv5_1
I0624 17:17:23.686091 21500 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0624 17:17:23.686122 21500 layer_factory.hpp:77] Creating layer scale5_1
I0624 17:17:23.686200 21500 net.cpp:141] Setting up scale5_1
I0624 17:17:23.686208 21500 net.cpp:148] Top shape: 32 128 7 7 (200704)
I0624 17:17:23.686209 21500 net.cpp:156] Memory required for data: 419070336
I0624 17:17:23.686213 21500 layer_factory.hpp:77] Creating layer relu5_1
I0624 17:17:23.686218 21500 net.cpp:91] Creating Layer relu5_1
I0624 17:17:23.686220 21500 net.cpp:425] relu5_1 <- conv5_1
I0624 17:17:23.686223 21500 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0624 17:17:23.686354 21500 net.cpp:141] Setting up relu5_1
I0624 17:17:23.686362 21500 net.cpp:148] Top shape: 32 128 7 7 (200704)
I0624 17:17:23.686365 21500 net.cpp:156] Memory required for data: 419873152
I0624 17:17:23.686367 21500 layer_factory.hpp:77] Creating layer conv5_2
I0624 17:17:23.686374 21500 net.cpp:91] Creating Layer conv5_2
I0624 17:17:23.686378 21500 net.cpp:425] conv5_2 <- conv5_1
I0624 17:17:23.686381 21500 net.cpp:399] conv5_2 -> conv5_2
I0624 17:17:23.688175 21500 net.cpp:141] Setting up conv5_2
I0624 17:17:23.688187 21500 net.cpp:148] Top shape: 32 128 7 7 (200704)
I0624 17:17:23.688190 21500 net.cpp:156] Memory required for data: 420675968
I0624 17:17:23.688194 21500 layer_factory.hpp:77] Creating layer bn5_2
I0624 17:17:23.688200 21500 net.cpp:91] Creating Layer bn5_2
I0624 17:17:23.688204 21500 net.cpp:425] bn5_2 <- conv5_2
I0624 17:17:23.688207 21500 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0624 17:17:23.688350 21500 net.cpp:141] Setting up bn5_2
I0624 17:17:23.688357 21500 net.cpp:148] Top shape: 32 128 7 7 (200704)
I0624 17:17:23.688360 21500 net.cpp:156] Memory required for data: 421478784
I0624 17:17:23.688365 21500 layer_factory.hpp:77] Creating layer scale5_2
I0624 17:17:23.688371 21500 net.cpp:91] Creating Layer scale5_2
I0624 17:17:23.688374 21500 net.cpp:425] scale5_2 <- conv5_2
I0624 17:17:23.688377 21500 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0624 17:17:23.688408 21500 layer_factory.hpp:77] Creating layer scale5_2
I0624 17:17:23.688488 21500 net.cpp:141] Setting up scale5_2
I0624 17:17:23.688493 21500 net.cpp:148] Top shape: 32 128 7 7 (200704)
I0624 17:17:23.688495 21500 net.cpp:156] Memory required for data: 422281600
I0624 17:17:23.688499 21500 layer_factory.hpp:77] Creating layer relu5_2
I0624 17:17:23.688504 21500 net.cpp:91] Creating Layer relu5_2
I0624 17:17:23.688506 21500 net.cpp:425] relu5_2 <- conv5_2
I0624 17:17:23.688509 21500 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0624 17:17:23.688639 21500 net.cpp:141] Setting up relu5_2
I0624 17:17:23.688647 21500 net.cpp:148] Top shape: 32 128 7 7 (200704)
I0624 17:17:23.688649 21500 net.cpp:156] Memory required for data: 423084416
I0624 17:17:23.688652 21500 layer_factory.hpp:77] Creating layer pool5
I0624 17:17:23.688657 21500 net.cpp:91] Creating Layer pool5
I0624 17:17:23.688659 21500 net.cpp:425] pool5 <- conv5_2
I0624 17:17:23.688674 21500 net.cpp:399] pool5 -> pool5
I0624 17:17:23.688814 21500 net.cpp:141] Setting up pool5
I0624 17:17:23.688823 21500 net.cpp:148] Top shape: 32 128 1 1 (4096)
I0624 17:17:23.688825 21500 net.cpp:156] Memory required for data: 423100800
I0624 17:17:23.688828 21500 layer_factory.hpp:77] Creating layer fc2
I0624 17:17:23.688834 21500 net.cpp:91] Creating Layer fc2
I0624 17:17:23.688838 21500 net.cpp:425] fc2 <- pool5
I0624 17:17:23.688841 21500 net.cpp:399] fc2 -> fc2
I0624 17:17:23.688920 21500 net.cpp:141] Setting up fc2
I0624 17:17:23.688925 21500 net.cpp:148] Top shape: 32 2 (64)
I0624 17:17:23.688928 21500 net.cpp:156] Memory required for data: 423101056
I0624 17:17:23.688932 21500 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0624 17:17:23.688937 21500 net.cpp:91] Creating Layer fc2_fc2_0_split
I0624 17:17:23.688941 21500 net.cpp:425] fc2_fc2_0_split <- fc2
I0624 17:17:23.688943 21500 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0624 17:17:23.688948 21500 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0624 17:17:23.688976 21500 net.cpp:141] Setting up fc2_fc2_0_split
I0624 17:17:23.688980 21500 net.cpp:148] Top shape: 32 2 (64)
I0624 17:17:23.688983 21500 net.cpp:148] Top shape: 32 2 (64)
I0624 17:17:23.688985 21500 net.cpp:156] Memory required for data: 423101568
I0624 17:17:23.688988 21500 layer_factory.hpp:77] Creating layer loss
I0624 17:17:23.688992 21500 net.cpp:91] Creating Layer loss
I0624 17:17:23.688995 21500 net.cpp:425] loss <- fc2_fc2_0_split_0
I0624 17:17:23.688998 21500 net.cpp:425] loss <- label_data_1_split_0
I0624 17:17:23.689002 21500 net.cpp:399] loss -> loss
I0624 17:17:23.689007 21500 layer_factory.hpp:77] Creating layer loss
I0624 17:17:23.689437 21500 net.cpp:141] Setting up loss
I0624 17:17:23.689448 21500 net.cpp:148] Top shape: (1)
I0624 17:17:23.689451 21500 net.cpp:151]     with loss weight 1
I0624 17:17:23.689460 21500 net.cpp:156] Memory required for data: 423101572
I0624 17:17:23.689461 21500 layer_factory.hpp:77] Creating layer accuracy
I0624 17:17:23.689466 21500 net.cpp:91] Creating Layer accuracy
I0624 17:17:23.689470 21500 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0624 17:17:23.689473 21500 net.cpp:425] accuracy <- label_data_1_split_1
I0624 17:17:23.689477 21500 net.cpp:399] accuracy -> accuracy
I0624 17:17:23.689483 21500 net.cpp:141] Setting up accuracy
I0624 17:17:23.689486 21500 net.cpp:148] Top shape: (1)
I0624 17:17:23.689488 21500 net.cpp:156] Memory required for data: 423101576
I0624 17:17:23.689491 21500 net.cpp:219] accuracy does not need backward computation.
I0624 17:17:23.689493 21500 net.cpp:217] loss needs backward computation.
I0624 17:17:23.689496 21500 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0624 17:17:23.689498 21500 net.cpp:217] fc2 needs backward computation.
I0624 17:17:23.689501 21500 net.cpp:217] pool5 needs backward computation.
I0624 17:17:23.689503 21500 net.cpp:217] relu5_2 needs backward computation.
I0624 17:17:23.689505 21500 net.cpp:217] scale5_2 needs backward computation.
I0624 17:17:23.689507 21500 net.cpp:217] bn5_2 needs backward computation.
I0624 17:17:23.689509 21500 net.cpp:217] conv5_2 needs backward computation.
I0624 17:17:23.689512 21500 net.cpp:217] relu5_1 needs backward computation.
I0624 17:17:23.689514 21500 net.cpp:217] scale5_1 needs backward computation.
I0624 17:17:23.689517 21500 net.cpp:217] bn5_1 needs backward computation.
I0624 17:17:23.689519 21500 net.cpp:217] conv5_1 needs backward computation.
I0624 17:17:23.689522 21500 net.cpp:217] pool4 needs backward computation.
I0624 17:17:23.689523 21500 net.cpp:217] relu4_2 needs backward computation.
I0624 17:17:23.689527 21500 net.cpp:217] scale4_2 needs backward computation.
I0624 17:17:23.689528 21500 net.cpp:217] bn4_2 needs backward computation.
I0624 17:17:23.689530 21500 net.cpp:217] conv4_2 needs backward computation.
I0624 17:17:23.689532 21500 net.cpp:217] relu4_1 needs backward computation.
I0624 17:17:23.689534 21500 net.cpp:217] scale4_1 needs backward computation.
I0624 17:17:23.689546 21500 net.cpp:217] bn4_1 needs backward computation.
I0624 17:17:23.689548 21500 net.cpp:217] conv4_1 needs backward computation.
I0624 17:17:23.689551 21500 net.cpp:217] pool3 needs backward computation.
I0624 17:17:23.689553 21500 net.cpp:217] relu3_2 needs backward computation.
I0624 17:17:23.689556 21500 net.cpp:217] scale3_2 needs backward computation.
I0624 17:17:23.689558 21500 net.cpp:217] bn3_2 needs backward computation.
I0624 17:17:23.689560 21500 net.cpp:217] conv3_2 needs backward computation.
I0624 17:17:23.689563 21500 net.cpp:217] relu3_1 needs backward computation.
I0624 17:17:23.689565 21500 net.cpp:217] scale3_1 needs backward computation.
I0624 17:17:23.689568 21500 net.cpp:217] bn3_1 needs backward computation.
I0624 17:17:23.689570 21500 net.cpp:217] conv3_1 needs backward computation.
I0624 17:17:23.689573 21500 net.cpp:217] pool2 needs backward computation.
I0624 17:17:23.689575 21500 net.cpp:217] relu2_2 needs backward computation.
I0624 17:17:23.689577 21500 net.cpp:217] scale2_2 needs backward computation.
I0624 17:17:23.689579 21500 net.cpp:217] bn2_2 needs backward computation.
I0624 17:17:23.689582 21500 net.cpp:217] conv2_2 needs backward computation.
I0624 17:17:23.689584 21500 net.cpp:217] relu2_1 needs backward computation.
I0624 17:17:23.689586 21500 net.cpp:217] scale2_1 needs backward computation.
I0624 17:17:23.689589 21500 net.cpp:217] bn2_1 needs backward computation.
I0624 17:17:23.689591 21500 net.cpp:217] conv2_1 needs backward computation.
I0624 17:17:23.689594 21500 net.cpp:217] pool1 needs backward computation.
I0624 17:17:23.689595 21500 net.cpp:217] relu1_2 needs backward computation.
I0624 17:17:23.689597 21500 net.cpp:217] scale1_2 needs backward computation.
I0624 17:17:23.689600 21500 net.cpp:217] bn1_2 needs backward computation.
I0624 17:17:23.689604 21500 net.cpp:217] conv1_2 needs backward computation.
I0624 17:17:23.689605 21500 net.cpp:217] relu1_1 needs backward computation.
I0624 17:17:23.689607 21500 net.cpp:217] scale1_1 needs backward computation.
I0624 17:17:23.689610 21500 net.cpp:217] bn1_1 needs backward computation.
I0624 17:17:23.689612 21500 net.cpp:217] conv1_1 needs backward computation.
I0624 17:17:23.689615 21500 net.cpp:219] label_data_1_split does not need backward computation.
I0624 17:17:23.689618 21500 net.cpp:219] data does not need backward computation.
I0624 17:17:23.689620 21500 net.cpp:261] This network produces output accuracy
I0624 17:17:23.689623 21500 net.cpp:261] This network produces output loss
I0624 17:17:23.689641 21500 net.cpp:274] Network initialization done.
I0624 17:17:23.689776 21500 solver.cpp:60] Solver scaffolding done.
I0624 17:17:23.691359 21500 caffe.cpp:219] Starting Optimization
I0624 17:17:23.691365 21500 solver.cpp:279] Solving BPnet
I0624 17:17:23.691366 21500 solver.cpp:280] Learning Rate Policy: step
I0624 17:17:23.692442 21500 solver.cpp:337] Iteration 0, Testing net (#0)
I0624 17:17:23.693347 21500 blocking_queue.cpp:50] Data layer prefetch queue empty
I0624 17:17:24.028800 21500 solver.cpp:404]     Test net output #0: accuracy = 0.404297
I0624 17:17:24.028833 21500 solver.cpp:404]     Test net output #1: loss = 0.693147 (* 1 = 0.693147 loss)
I0624 17:17:24.081019 21500 solver.cpp:228] Iteration 0, loss = 0.693147
I0624 17:17:24.081046 21500 solver.cpp:244]     Train net output #0: accuracy = 0.40625
I0624 17:17:24.081053 21500 solver.cpp:244]     Train net output #1: loss = 0.693147 (* 1 = 0.693147 loss)
I0624 17:17:24.081066 21500 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0624 17:17:25.025382 21500 solver.cpp:228] Iteration 20, loss = 0.598161
I0624 17:17:25.025413 21500 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 17:17:25.025419 21500 solver.cpp:244]     Train net output #1: loss = 0.598161 (* 1 = 0.598161 loss)
I0624 17:17:25.025424 21500 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0624 17:17:25.996624 21500 solver.cpp:228] Iteration 40, loss = 0.592658
I0624 17:17:25.996662 21500 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0624 17:17:25.996670 21500 solver.cpp:244]     Train net output #1: loss = 0.592658 (* 1 = 0.592658 loss)
I0624 17:17:25.996696 21500 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0624 17:17:26.966238 21500 solver.cpp:228] Iteration 60, loss = 0.59579
I0624 17:17:26.966262 21500 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0624 17:17:26.966269 21500 solver.cpp:244]     Train net output #1: loss = 0.59579 (* 1 = 0.59579 loss)
I0624 17:17:26.966274 21500 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0624 17:17:27.937193 21500 solver.cpp:228] Iteration 80, loss = 0.609483
I0624 17:17:27.937228 21500 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:17:27.937235 21500 solver.cpp:244]     Train net output #1: loss = 0.609483 (* 1 = 0.609483 loss)
I0624 17:17:27.937239 21500 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0624 17:17:28.894654 21500 solver.cpp:337] Iteration 100, Testing net (#0)
I0624 17:17:29.219106 21500 solver.cpp:404]     Test net output #0: accuracy = 0.728516
I0624 17:17:29.219141 21500 solver.cpp:404]     Test net output #1: loss = 0.564047 (* 1 = 0.564047 loss)
I0624 17:17:29.234673 21500 solver.cpp:228] Iteration 100, loss = 0.526948
I0624 17:17:29.234700 21500 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:17:29.234709 21500 solver.cpp:244]     Train net output #1: loss = 0.526948 (* 1 = 0.526948 loss)
I0624 17:17:29.234714 21500 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0624 17:17:30.208338 21500 solver.cpp:228] Iteration 120, loss = 0.572073
I0624 17:17:30.208374 21500 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0624 17:17:30.208381 21500 solver.cpp:244]     Train net output #1: loss = 0.572073 (* 1 = 0.572073 loss)
I0624 17:17:30.208385 21500 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0624 17:17:31.178375 21500 solver.cpp:228] Iteration 140, loss = 0.656869
I0624 17:17:31.178401 21500 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:17:31.178409 21500 solver.cpp:244]     Train net output #1: loss = 0.656869 (* 1 = 0.656869 loss)
I0624 17:17:31.178414 21500 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0624 17:17:32.149523 21500 solver.cpp:228] Iteration 160, loss = 0.617166
I0624 17:17:32.149547 21500 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 17:17:32.149565 21500 solver.cpp:244]     Train net output #1: loss = 0.617166 (* 1 = 0.617166 loss)
I0624 17:17:32.149569 21500 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0624 17:17:33.120944 21500 solver.cpp:228] Iteration 180, loss = 0.622181
I0624 17:17:33.120970 21500 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 17:17:33.120977 21500 solver.cpp:244]     Train net output #1: loss = 0.622181 (* 1 = 0.622181 loss)
I0624 17:17:33.120981 21500 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0624 17:17:34.077725 21500 solver.cpp:337] Iteration 200, Testing net (#0)
I0624 17:17:34.397626 21500 solver.cpp:404]     Test net output #0: accuracy = 0.734375
I0624 17:17:34.397655 21500 solver.cpp:404]     Test net output #1: loss = 0.521421 (* 1 = 0.521421 loss)
I0624 17:17:34.412924 21500 solver.cpp:228] Iteration 200, loss = 0.479371
I0624 17:17:34.412950 21500 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 17:17:34.412956 21500 solver.cpp:244]     Train net output #1: loss = 0.479371 (* 1 = 0.479371 loss)
I0624 17:17:34.412962 21500 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0624 17:17:35.386268 21500 solver.cpp:228] Iteration 220, loss = 0.545852
I0624 17:17:35.386294 21500 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:17:35.386302 21500 solver.cpp:244]     Train net output #1: loss = 0.545852 (* 1 = 0.545852 loss)
I0624 17:17:35.386307 21500 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0624 17:17:36.359901 21500 solver.cpp:228] Iteration 240, loss = 0.547861
I0624 17:17:36.359937 21500 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:17:36.359944 21500 solver.cpp:244]     Train net output #1: loss = 0.547861 (* 1 = 0.547861 loss)
I0624 17:17:36.359951 21500 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0624 17:17:37.332229 21500 solver.cpp:228] Iteration 260, loss = 0.422447
I0624 17:17:37.332265 21500 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:17:37.332273 21500 solver.cpp:244]     Train net output #1: loss = 0.422447 (* 1 = 0.422447 loss)
I0624 17:17:37.332276 21500 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0624 17:17:38.303757 21500 solver.cpp:228] Iteration 280, loss = 0.449548
I0624 17:17:38.303797 21500 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 17:17:38.303803 21500 solver.cpp:244]     Train net output #1: loss = 0.449548 (* 1 = 0.449548 loss)
I0624 17:17:38.303808 21500 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0624 17:17:39.263634 21500 solver.cpp:337] Iteration 300, Testing net (#0)
I0624 17:17:39.589947 21500 solver.cpp:404]     Test net output #0: accuracy = 0.703125
I0624 17:17:39.589984 21500 solver.cpp:404]     Test net output #1: loss = 0.558948 (* 1 = 0.558948 loss)
I0624 17:17:39.605046 21500 solver.cpp:228] Iteration 300, loss = 0.712469
I0624 17:17:39.605072 21500 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0624 17:17:39.605078 21500 solver.cpp:244]     Train net output #1: loss = 0.712469 (* 1 = 0.712469 loss)
I0624 17:17:39.605082 21500 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0624 17:17:40.578925 21500 solver.cpp:228] Iteration 320, loss = 0.382812
I0624 17:17:40.578953 21500 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 17:17:40.578959 21500 solver.cpp:244]     Train net output #1: loss = 0.382812 (* 1 = 0.382812 loss)
I0624 17:17:40.578964 21500 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0624 17:17:41.594168 21500 solver.cpp:228] Iteration 340, loss = 0.525397
I0624 17:17:41.594197 21500 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:17:41.594203 21500 solver.cpp:244]     Train net output #1: loss = 0.525397 (* 1 = 0.525397 loss)
I0624 17:17:41.594208 21500 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0624 17:17:42.589593 21500 solver.cpp:228] Iteration 360, loss = 0.604142
I0624 17:17:42.589620 21500 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:17:42.589627 21500 solver.cpp:244]     Train net output #1: loss = 0.604142 (* 1 = 0.604142 loss)
I0624 17:17:42.589632 21500 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0624 17:17:43.567680 21500 solver.cpp:228] Iteration 380, loss = 0.649996
I0624 17:17:43.567708 21500 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0624 17:17:43.567714 21500 solver.cpp:244]     Train net output #1: loss = 0.649996 (* 1 = 0.649996 loss)
I0624 17:17:43.567719 21500 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0624 17:17:44.534407 21500 solver.cpp:337] Iteration 400, Testing net (#0)
I0624 17:17:44.856355 21500 solver.cpp:404]     Test net output #0: accuracy = 0.777344
I0624 17:17:44.856389 21500 solver.cpp:404]     Test net output #1: loss = 0.489469 (* 1 = 0.489469 loss)
I0624 17:17:44.871943 21500 solver.cpp:228] Iteration 400, loss = 0.531819
I0624 17:17:44.871971 21500 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:17:44.871978 21500 solver.cpp:244]     Train net output #1: loss = 0.531819 (* 1 = 0.531819 loss)
I0624 17:17:44.871984 21500 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0624 17:17:45.855618 21500 solver.cpp:228] Iteration 420, loss = 0.5657
I0624 17:17:45.855654 21500 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 17:17:45.855661 21500 solver.cpp:244]     Train net output #1: loss = 0.5657 (* 1 = 0.5657 loss)
I0624 17:17:45.855665 21500 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0624 17:17:46.834216 21500 solver.cpp:228] Iteration 440, loss = 0.513112
I0624 17:17:46.834241 21500 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:17:46.834249 21500 solver.cpp:244]     Train net output #1: loss = 0.513112 (* 1 = 0.513112 loss)
I0624 17:17:46.834252 21500 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0624 17:17:47.816498 21500 solver.cpp:228] Iteration 460, loss = 0.389081
I0624 17:17:47.816524 21500 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 17:17:47.816560 21500 solver.cpp:244]     Train net output #1: loss = 0.389081 (* 1 = 0.389081 loss)
I0624 17:17:47.816565 21500 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0624 17:17:48.800631 21500 solver.cpp:228] Iteration 480, loss = 0.520991
I0624 17:17:48.800668 21500 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 17:17:48.800674 21500 solver.cpp:244]     Train net output #1: loss = 0.520991 (* 1 = 0.520991 loss)
I0624 17:17:48.800678 21500 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0624 17:17:49.765277 21500 solver.cpp:454] Snapshotting to binary proto file data/models/bpgnet_iter_500.caffemodel
I0624 17:17:49.773916 21500 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpgnet_iter_500.solverstate
I0624 17:17:49.776983 21500 solver.cpp:337] Iteration 500, Testing net (#0)
I0624 17:17:50.096680 21500 solver.cpp:404]     Test net output #0: accuracy = 0.753906
I0624 17:17:50.096709 21500 solver.cpp:404]     Test net output #1: loss = 0.471593 (* 1 = 0.471593 loss)
I0624 17:17:50.111766 21500 solver.cpp:228] Iteration 500, loss = 0.390131
I0624 17:17:50.111793 21500 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:17:50.111801 21500 solver.cpp:244]     Train net output #1: loss = 0.390131 (* 1 = 0.390131 loss)
I0624 17:17:50.111806 21500 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0624 17:17:51.095532 21500 solver.cpp:228] Iteration 520, loss = 0.698678
I0624 17:17:51.095557 21500 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:17:51.095564 21500 solver.cpp:244]     Train net output #1: loss = 0.698678 (* 1 = 0.698678 loss)
I0624 17:17:51.095569 21500 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0624 17:17:52.082197 21500 solver.cpp:228] Iteration 540, loss = 0.532036
I0624 17:17:52.082238 21500 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 17:17:52.082245 21500 solver.cpp:244]     Train net output #1: loss = 0.532036 (* 1 = 0.532036 loss)
I0624 17:17:52.082250 21500 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0624 17:17:53.066179 21500 solver.cpp:228] Iteration 560, loss = 0.523083
I0624 17:17:53.066428 21500 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 17:17:53.066438 21500 solver.cpp:244]     Train net output #1: loss = 0.523083 (* 1 = 0.523083 loss)
I0624 17:17:53.066442 21500 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0624 17:17:54.048444 21500 solver.cpp:228] Iteration 580, loss = 0.379786
I0624 17:17:54.048470 21500 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 17:17:54.048477 21500 solver.cpp:244]     Train net output #1: loss = 0.379786 (* 1 = 0.379786 loss)
I0624 17:17:54.048481 21500 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0624 17:17:55.021037 21500 solver.cpp:337] Iteration 600, Testing net (#0)
I0624 17:17:55.346242 21500 solver.cpp:404]     Test net output #0: accuracy = 0.767578
I0624 17:17:55.346276 21500 solver.cpp:404]     Test net output #1: loss = 0.51222 (* 1 = 0.51222 loss)
I0624 17:17:55.363705 21500 solver.cpp:228] Iteration 600, loss = 0.566936
I0624 17:17:55.363741 21500 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:17:55.363752 21500 solver.cpp:244]     Train net output #1: loss = 0.566936 (* 1 = 0.566936 loss)
I0624 17:17:55.363760 21500 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0624 17:17:56.351562 21500 solver.cpp:228] Iteration 620, loss = 0.448201
I0624 17:17:56.351591 21500 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:17:56.351599 21500 solver.cpp:244]     Train net output #1: loss = 0.448201 (* 1 = 0.448201 loss)
I0624 17:17:56.351604 21500 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0624 17:17:57.337519 21500 solver.cpp:228] Iteration 640, loss = 0.520421
I0624 17:17:57.337556 21500 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 17:17:57.337563 21500 solver.cpp:244]     Train net output #1: loss = 0.520421 (* 1 = 0.520421 loss)
I0624 17:17:57.337566 21500 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0624 17:17:58.320744 21500 solver.cpp:228] Iteration 660, loss = 0.444156
I0624 17:17:58.320770 21500 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 17:17:58.320813 21500 solver.cpp:244]     Train net output #1: loss = 0.444156 (* 1 = 0.444156 loss)
I0624 17:17:58.320821 21500 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0624 17:17:59.302804 21500 solver.cpp:228] Iteration 680, loss = 0.481086
I0624 17:17:59.302830 21500 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 17:17:59.302837 21500 solver.cpp:244]     Train net output #1: loss = 0.481086 (* 1 = 0.481086 loss)
I0624 17:17:59.302842 21500 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0624 17:18:00.271170 21500 solver.cpp:337] Iteration 700, Testing net (#0)
I0624 17:18:00.597229 21500 solver.cpp:404]     Test net output #0: accuracy = 0.755859
I0624 17:18:00.597262 21500 solver.cpp:404]     Test net output #1: loss = 0.498331 (* 1 = 0.498331 loss)
I0624 17:18:00.612808 21500 solver.cpp:228] Iteration 700, loss = 0.356127
I0624 17:18:00.612839 21500 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:18:00.612848 21500 solver.cpp:244]     Train net output #1: loss = 0.356127 (* 1 = 0.356127 loss)
I0624 17:18:00.612854 21500 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0624 17:18:01.599548 21500 solver.cpp:228] Iteration 720, loss = 0.314677
I0624 17:18:01.599575 21500 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:18:01.599581 21500 solver.cpp:244]     Train net output #1: loss = 0.314677 (* 1 = 0.314677 loss)
I0624 17:18:01.599586 21500 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0624 17:18:02.581328 21500 solver.cpp:228] Iteration 740, loss = 0.356391
I0624 17:18:02.581367 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:18:02.581372 21500 solver.cpp:244]     Train net output #1: loss = 0.356391 (* 1 = 0.356391 loss)
I0624 17:18:02.581377 21500 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0624 17:18:03.564476 21500 solver.cpp:228] Iteration 760, loss = 0.380099
I0624 17:18:03.564513 21500 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:18:03.564520 21500 solver.cpp:244]     Train net output #1: loss = 0.380099 (* 1 = 0.380099 loss)
I0624 17:18:03.564548 21500 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0624 17:18:04.548007 21500 solver.cpp:228] Iteration 780, loss = 0.311569
I0624 17:18:04.548045 21500 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 17:18:04.548053 21500 solver.cpp:244]     Train net output #1: loss = 0.311569 (* 1 = 0.311569 loss)
I0624 17:18:04.548058 21500 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0624 17:18:05.515111 21500 solver.cpp:337] Iteration 800, Testing net (#0)
I0624 17:18:05.833940 21500 solver.cpp:404]     Test net output #0: accuracy = 0.791016
I0624 17:18:05.833986 21500 solver.cpp:404]     Test net output #1: loss = 0.436966 (* 1 = 0.436966 loss)
I0624 17:18:05.850381 21500 solver.cpp:228] Iteration 800, loss = 0.408867
I0624 17:18:05.850414 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:18:05.850425 21500 solver.cpp:244]     Train net output #1: loss = 0.408867 (* 1 = 0.408867 loss)
I0624 17:18:05.850431 21500 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0624 17:18:06.838328 21500 solver.cpp:228] Iteration 820, loss = 0.4033
I0624 17:18:06.838356 21500 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:18:06.838362 21500 solver.cpp:244]     Train net output #1: loss = 0.4033 (* 1 = 0.4033 loss)
I0624 17:18:06.838367 21500 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0624 17:18:07.819810 21500 solver.cpp:228] Iteration 840, loss = 0.484749
I0624 17:18:07.819845 21500 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:18:07.819864 21500 solver.cpp:244]     Train net output #1: loss = 0.484749 (* 1 = 0.484749 loss)
I0624 17:18:07.819869 21500 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0624 17:18:08.802819 21500 solver.cpp:228] Iteration 860, loss = 0.416168
I0624 17:18:08.802855 21500 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 17:18:08.802863 21500 solver.cpp:244]     Train net output #1: loss = 0.416168 (* 1 = 0.416168 loss)
I0624 17:18:08.802867 21500 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0624 17:18:09.785858 21500 solver.cpp:228] Iteration 880, loss = 0.487131
I0624 17:18:09.785884 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:18:09.785890 21500 solver.cpp:244]     Train net output #1: loss = 0.487131 (* 1 = 0.487131 loss)
I0624 17:18:09.785895 21500 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0624 17:18:10.756588 21500 solver.cpp:337] Iteration 900, Testing net (#0)
I0624 17:18:11.083199 21500 solver.cpp:404]     Test net output #0: accuracy = 0.769531
I0624 17:18:11.083233 21500 solver.cpp:404]     Test net output #1: loss = 0.503492 (* 1 = 0.503492 loss)
I0624 17:18:11.098431 21500 solver.cpp:228] Iteration 900, loss = 0.678844
I0624 17:18:11.098459 21500 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0624 17:18:11.098469 21500 solver.cpp:244]     Train net output #1: loss = 0.678844 (* 1 = 0.678844 loss)
I0624 17:18:11.098475 21500 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0624 17:18:12.081928 21500 solver.cpp:228] Iteration 920, loss = 0.376067
I0624 17:18:12.081959 21500 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 17:18:12.081969 21500 solver.cpp:244]     Train net output #1: loss = 0.376067 (* 1 = 0.376067 loss)
I0624 17:18:12.081976 21500 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0624 17:18:13.064245 21500 solver.cpp:228] Iteration 940, loss = 0.431249
I0624 17:18:13.064271 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:18:13.064281 21500 solver.cpp:244]     Train net output #1: loss = 0.431249 (* 1 = 0.431249 loss)
I0624 17:18:13.064288 21500 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0624 17:18:14.048106 21500 solver.cpp:228] Iteration 960, loss = 0.466779
I0624 17:18:14.048132 21500 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:18:14.048142 21500 solver.cpp:244]     Train net output #1: loss = 0.466779 (* 1 = 0.466779 loss)
I0624 17:18:14.048149 21500 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0624 17:18:15.029419 21500 solver.cpp:228] Iteration 980, loss = 0.307291
I0624 17:18:15.029467 21500 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:18:15.029479 21500 solver.cpp:244]     Train net output #1: loss = 0.307291 (* 1 = 0.307291 loss)
I0624 17:18:15.029486 21500 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0624 17:18:15.997479 21500 solver.cpp:454] Snapshotting to binary proto file data/models/bpgnet_iter_1000.caffemodel
I0624 17:18:16.003800 21500 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpgnet_iter_1000.solverstate
I0624 17:18:16.006794 21500 solver.cpp:337] Iteration 1000, Testing net (#0)
I0624 17:18:16.331037 21500 solver.cpp:404]     Test net output #0: accuracy = 0.753906
I0624 17:18:16.331076 21500 solver.cpp:404]     Test net output #1: loss = 0.526924 (* 1 = 0.526924 loss)
I0624 17:18:16.347127 21500 solver.cpp:228] Iteration 1000, loss = 0.395254
I0624 17:18:16.347165 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:18:16.347177 21500 solver.cpp:244]     Train net output #1: loss = 0.395254 (* 1 = 0.395254 loss)
I0624 17:18:16.347185 21500 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0624 17:18:17.335419 21500 solver.cpp:228] Iteration 1020, loss = 0.473293
I0624 17:18:17.335448 21500 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 17:18:17.335458 21500 solver.cpp:244]     Train net output #1: loss = 0.473293 (* 1 = 0.473293 loss)
I0624 17:18:17.335465 21500 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0624 17:18:18.316293 21500 solver.cpp:228] Iteration 1040, loss = 0.350624
I0624 17:18:18.316321 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:18:18.316330 21500 solver.cpp:244]     Train net output #1: loss = 0.350624 (* 1 = 0.350624 loss)
I0624 17:18:18.316337 21500 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0624 17:18:19.296982 21500 solver.cpp:228] Iteration 1060, loss = 0.654107
I0624 17:18:19.297013 21500 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:18:19.297024 21500 solver.cpp:244]     Train net output #1: loss = 0.654107 (* 1 = 0.654107 loss)
I0624 17:18:19.297031 21500 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0624 17:18:20.281579 21500 solver.cpp:228] Iteration 1080, loss = 0.310886
I0624 17:18:20.281605 21500 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:18:20.281615 21500 solver.cpp:244]     Train net output #1: loss = 0.310886 (* 1 = 0.310886 loss)
I0624 17:18:20.281622 21500 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0624 17:18:21.251598 21500 solver.cpp:337] Iteration 1100, Testing net (#0)
I0624 17:18:21.577872 21500 solver.cpp:404]     Test net output #0: accuracy = 0.78125
I0624 17:18:21.577919 21500 solver.cpp:404]     Test net output #1: loss = 0.470897 (* 1 = 0.470897 loss)
I0624 17:18:21.594511 21500 solver.cpp:228] Iteration 1100, loss = 0.288239
I0624 17:18:21.594548 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:18:21.594564 21500 solver.cpp:244]     Train net output #1: loss = 0.288239 (* 1 = 0.288239 loss)
I0624 17:18:21.594575 21500 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0624 17:18:22.584763 21500 solver.cpp:228] Iteration 1120, loss = 0.37318
I0624 17:18:22.584792 21500 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 17:18:22.584802 21500 solver.cpp:244]     Train net output #1: loss = 0.37318 (* 1 = 0.37318 loss)
I0624 17:18:22.584810 21500 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0624 17:18:23.568037 21500 solver.cpp:228] Iteration 1140, loss = 0.359576
I0624 17:18:23.568203 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:18:23.568217 21500 solver.cpp:244]     Train net output #1: loss = 0.359576 (* 1 = 0.359576 loss)
I0624 17:18:23.568225 21500 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0624 17:18:24.552191 21500 solver.cpp:228] Iteration 1160, loss = 0.396462
I0624 17:18:24.552224 21500 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 17:18:24.552232 21500 solver.cpp:244]     Train net output #1: loss = 0.396462 (* 1 = 0.396462 loss)
I0624 17:18:24.552238 21500 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0624 17:18:25.540973 21500 solver.cpp:228] Iteration 1180, loss = 0.299232
I0624 17:18:25.541009 21500 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:18:25.541016 21500 solver.cpp:244]     Train net output #1: loss = 0.299232 (* 1 = 0.299232 loss)
I0624 17:18:25.541021 21500 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0624 17:18:26.512719 21500 solver.cpp:337] Iteration 1200, Testing net (#0)
I0624 17:18:26.822226 21500 solver.cpp:404]     Test net output #0: accuracy = 0.787109
I0624 17:18:26.822263 21500 solver.cpp:404]     Test net output #1: loss = 0.448056 (* 1 = 0.448056 loss)
I0624 17:18:26.838454 21500 solver.cpp:228] Iteration 1200, loss = 0.223781
I0624 17:18:26.838486 21500 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:18:26.838497 21500 solver.cpp:244]     Train net output #1: loss = 0.223781 (* 1 = 0.223781 loss)
I0624 17:18:26.838505 21500 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0624 17:18:27.826575 21500 solver.cpp:228] Iteration 1220, loss = 0.321119
I0624 17:18:27.826601 21500 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:18:27.826607 21500 solver.cpp:244]     Train net output #1: loss = 0.321119 (* 1 = 0.321119 loss)
I0624 17:18:27.826612 21500 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0624 17:18:28.811249 21500 solver.cpp:228] Iteration 1240, loss = 0.445763
I0624 17:18:28.811274 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:18:28.811280 21500 solver.cpp:244]     Train net output #1: loss = 0.445763 (* 1 = 0.445763 loss)
I0624 17:18:28.811285 21500 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0624 17:18:29.800163 21500 solver.cpp:228] Iteration 1260, loss = 0.378777
I0624 17:18:29.800199 21500 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 17:18:29.800206 21500 solver.cpp:244]     Train net output #1: loss = 0.378777 (* 1 = 0.378777 loss)
I0624 17:18:29.800210 21500 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0624 17:18:30.799240 21500 solver.cpp:228] Iteration 1280, loss = 0.359301
I0624 17:18:30.799268 21500 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:18:30.799275 21500 solver.cpp:244]     Train net output #1: loss = 0.359301 (* 1 = 0.359301 loss)
I0624 17:18:30.799279 21500 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0624 17:18:31.772402 21500 solver.cpp:337] Iteration 1300, Testing net (#0)
I0624 17:18:32.083511 21500 solver.cpp:404]     Test net output #0: accuracy = 0.791016
I0624 17:18:32.083559 21500 solver.cpp:404]     Test net output #1: loss = 0.490451 (* 1 = 0.490451 loss)
I0624 17:18:32.099721 21500 solver.cpp:228] Iteration 1300, loss = 0.287562
I0624 17:18:32.099752 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:18:32.099763 21500 solver.cpp:244]     Train net output #1: loss = 0.287562 (* 1 = 0.287562 loss)
I0624 17:18:32.099769 21500 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0624 17:18:33.095676 21500 solver.cpp:228] Iteration 1320, loss = 0.329288
I0624 17:18:33.095705 21500 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:18:33.095711 21500 solver.cpp:244]     Train net output #1: loss = 0.329288 (* 1 = 0.329288 loss)
I0624 17:18:33.095716 21500 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0624 17:18:34.082011 21500 solver.cpp:228] Iteration 1340, loss = 0.322238
I0624 17:18:34.082036 21500 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:18:34.082044 21500 solver.cpp:244]     Train net output #1: loss = 0.322238 (* 1 = 0.322238 loss)
I0624 17:18:34.082070 21500 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0624 17:18:35.067123 21500 solver.cpp:228] Iteration 1360, loss = 0.351509
I0624 17:18:35.067157 21500 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:18:35.067164 21500 solver.cpp:244]     Train net output #1: loss = 0.351509 (* 1 = 0.351509 loss)
I0624 17:18:35.067169 21500 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0624 17:18:36.051282 21500 solver.cpp:228] Iteration 1380, loss = 0.33497
I0624 17:18:36.051312 21500 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:18:36.051321 21500 solver.cpp:244]     Train net output #1: loss = 0.33497 (* 1 = 0.33497 loss)
I0624 17:18:36.051326 21500 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0624 17:18:37.025404 21500 solver.cpp:337] Iteration 1400, Testing net (#0)
I0624 17:18:37.332542 21500 solver.cpp:404]     Test net output #0: accuracy = 0.767578
I0624 17:18:37.332577 21500 solver.cpp:404]     Test net output #1: loss = 0.481645 (* 1 = 0.481645 loss)
I0624 17:18:37.348814 21500 solver.cpp:228] Iteration 1400, loss = 0.391396
I0624 17:18:37.348847 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:18:37.348857 21500 solver.cpp:244]     Train net output #1: loss = 0.391396 (* 1 = 0.391396 loss)
I0624 17:18:37.348865 21500 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0624 17:18:38.336614 21500 solver.cpp:228] Iteration 1420, loss = 0.26169
I0624 17:18:38.336639 21500 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:18:38.336647 21500 solver.cpp:244]     Train net output #1: loss = 0.26169 (* 1 = 0.26169 loss)
I0624 17:18:38.336650 21500 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0624 17:18:39.324818 21500 solver.cpp:228] Iteration 1440, loss = 0.339351
I0624 17:18:39.324846 21500 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:18:39.324854 21500 solver.cpp:244]     Train net output #1: loss = 0.339351 (* 1 = 0.339351 loss)
I0624 17:18:39.324858 21500 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0624 17:18:40.310174 21500 solver.cpp:228] Iteration 1460, loss = 0.254754
I0624 17:18:40.310200 21500 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0624 17:18:40.310207 21500 solver.cpp:244]     Train net output #1: loss = 0.254754 (* 1 = 0.254754 loss)
I0624 17:18:40.310212 21500 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0624 17:18:41.293599 21500 solver.cpp:228] Iteration 1480, loss = 0.229034
I0624 17:18:41.293625 21500 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 17:18:41.293632 21500 solver.cpp:244]     Train net output #1: loss = 0.229034 (* 1 = 0.229034 loss)
I0624 17:18:41.293637 21500 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0624 17:18:42.264186 21500 solver.cpp:454] Snapshotting to binary proto file data/models/bpgnet_iter_1500.caffemodel
I0624 17:18:42.270150 21500 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpgnet_iter_1500.solverstate
I0624 17:18:42.273092 21500 solver.cpp:337] Iteration 1500, Testing net (#0)
I0624 17:18:42.575906 21500 solver.cpp:404]     Test net output #0: accuracy = 0.789062
I0624 17:18:42.575944 21500 solver.cpp:404]     Test net output #1: loss = 0.459333 (* 1 = 0.459333 loss)
I0624 17:18:42.592717 21500 solver.cpp:228] Iteration 1500, loss = 0.487343
I0624 17:18:42.592748 21500 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:18:42.592759 21500 solver.cpp:244]     Train net output #1: loss = 0.487342 (* 1 = 0.487342 loss)
I0624 17:18:42.592766 21500 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0624 17:18:43.579118 21500 solver.cpp:228] Iteration 1520, loss = 0.234395
I0624 17:18:43.579146 21500 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 17:18:43.579157 21500 solver.cpp:244]     Train net output #1: loss = 0.234395 (* 1 = 0.234395 loss)
I0624 17:18:43.579162 21500 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0624 17:18:44.562338 21500 solver.cpp:228] Iteration 1540, loss = 0.378991
I0624 17:18:44.562391 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:18:44.562399 21500 solver.cpp:244]     Train net output #1: loss = 0.378991 (* 1 = 0.378991 loss)
I0624 17:18:44.562404 21500 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0624 17:18:45.548248 21500 solver.cpp:228] Iteration 1560, loss = 0.25901
I0624 17:18:45.548274 21500 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:18:45.548281 21500 solver.cpp:244]     Train net output #1: loss = 0.25901 (* 1 = 0.25901 loss)
I0624 17:18:45.548285 21500 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0624 17:18:46.534653 21500 solver.cpp:228] Iteration 1580, loss = 0.251695
I0624 17:18:46.534692 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:18:46.534698 21500 solver.cpp:244]     Train net output #1: loss = 0.251695 (* 1 = 0.251695 loss)
I0624 17:18:46.534703 21500 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0624 17:18:47.505524 21500 solver.cpp:337] Iteration 1600, Testing net (#0)
I0624 17:18:47.815336 21500 solver.cpp:404]     Test net output #0: accuracy = 0.800781
I0624 17:18:47.815376 21500 solver.cpp:404]     Test net output #1: loss = 0.482657 (* 1 = 0.482657 loss)
I0624 17:18:47.831532 21500 solver.cpp:228] Iteration 1600, loss = 0.429971
I0624 17:18:47.831567 21500 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:18:47.831578 21500 solver.cpp:244]     Train net output #1: loss = 0.429971 (* 1 = 0.429971 loss)
I0624 17:18:47.831584 21500 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0624 17:18:48.819933 21500 solver.cpp:228] Iteration 1620, loss = 0.414359
I0624 17:18:48.819965 21500 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:18:48.819972 21500 solver.cpp:244]     Train net output #1: loss = 0.414359 (* 1 = 0.414359 loss)
I0624 17:18:48.819977 21500 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0624 17:18:49.802242 21500 solver.cpp:228] Iteration 1640, loss = 0.283269
I0624 17:18:49.802278 21500 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:18:49.802284 21500 solver.cpp:244]     Train net output #1: loss = 0.283269 (* 1 = 0.283269 loss)
I0624 17:18:49.802287 21500 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0624 17:18:50.788337 21500 solver.cpp:228] Iteration 1660, loss = 0.249472
I0624 17:18:50.788364 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:18:50.788372 21500 solver.cpp:244]     Train net output #1: loss = 0.249472 (* 1 = 0.249472 loss)
I0624 17:18:50.788377 21500 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0624 17:18:51.773697 21500 solver.cpp:228] Iteration 1680, loss = 0.185855
I0624 17:18:51.773723 21500 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0624 17:18:51.773730 21500 solver.cpp:244]     Train net output #1: loss = 0.185855 (* 1 = 0.185855 loss)
I0624 17:18:51.773736 21500 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0624 17:18:52.746543 21500 solver.cpp:337] Iteration 1700, Testing net (#0)
I0624 17:18:53.070740 21500 solver.cpp:404]     Test net output #0: accuracy = 0.785156
I0624 17:18:53.070776 21500 solver.cpp:404]     Test net output #1: loss = 0.495361 (* 1 = 0.495361 loss)
I0624 17:18:53.086660 21500 solver.cpp:228] Iteration 1700, loss = 0.374506
I0624 17:18:53.086688 21500 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:18:53.086694 21500 solver.cpp:244]     Train net output #1: loss = 0.374506 (* 1 = 0.374506 loss)
I0624 17:18:53.086699 21500 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0624 17:18:54.072489 21500 solver.cpp:228] Iteration 1720, loss = 0.322836
I0624 17:18:54.072626 21500 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:18:54.072636 21500 solver.cpp:244]     Train net output #1: loss = 0.322836 (* 1 = 0.322836 loss)
I0624 17:18:54.072641 21500 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0624 17:18:55.060526 21500 solver.cpp:228] Iteration 1740, loss = 0.190129
I0624 17:18:55.060554 21500 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:18:55.060561 21500 solver.cpp:244]     Train net output #1: loss = 0.190129 (* 1 = 0.190129 loss)
I0624 17:18:55.060565 21500 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0624 17:18:56.048326 21500 solver.cpp:228] Iteration 1760, loss = 0.260003
I0624 17:18:56.048364 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:18:56.048372 21500 solver.cpp:244]     Train net output #1: loss = 0.260003 (* 1 = 0.260003 loss)
I0624 17:18:56.048377 21500 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0624 17:18:57.032491 21500 solver.cpp:228] Iteration 1780, loss = 0.366954
I0624 17:18:57.032518 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:18:57.032526 21500 solver.cpp:244]     Train net output #1: loss = 0.366954 (* 1 = 0.366954 loss)
I0624 17:18:57.032531 21500 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0624 17:18:58.004138 21500 solver.cpp:337] Iteration 1800, Testing net (#0)
I0624 17:18:58.330484 21500 solver.cpp:404]     Test net output #0: accuracy = 0.78125
I0624 17:18:58.330518 21500 solver.cpp:404]     Test net output #1: loss = 0.523725 (* 1 = 0.523725 loss)
I0624 17:18:58.346093 21500 solver.cpp:228] Iteration 1800, loss = 0.615244
I0624 17:18:58.346120 21500 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0624 17:18:58.346127 21500 solver.cpp:244]     Train net output #1: loss = 0.615244 (* 1 = 0.615244 loss)
I0624 17:18:58.346133 21500 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0624 17:18:59.331822 21500 solver.cpp:228] Iteration 1820, loss = 0.321809
I0624 17:18:59.331851 21500 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:18:59.331857 21500 solver.cpp:244]     Train net output #1: loss = 0.321809 (* 1 = 0.321809 loss)
I0624 17:18:59.331861 21500 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0624 17:19:00.318208 21500 solver.cpp:228] Iteration 1840, loss = 0.395117
I0624 17:19:00.318234 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:19:00.318243 21500 solver.cpp:244]     Train net output #1: loss = 0.395117 (* 1 = 0.395117 loss)
I0624 17:19:00.318248 21500 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0624 17:19:01.302150 21500 solver.cpp:228] Iteration 1860, loss = 0.21727
I0624 17:19:01.302178 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:19:01.302186 21500 solver.cpp:244]     Train net output #1: loss = 0.21727 (* 1 = 0.21727 loss)
I0624 17:19:01.302189 21500 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0624 17:19:02.291486 21500 solver.cpp:228] Iteration 1880, loss = 0.402796
I0624 17:19:02.291522 21500 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:19:02.291528 21500 solver.cpp:244]     Train net output #1: loss = 0.402796 (* 1 = 0.402796 loss)
I0624 17:19:02.291533 21500 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0624 17:19:03.267874 21500 solver.cpp:337] Iteration 1900, Testing net (#0)
I0624 17:19:03.592468 21500 solver.cpp:404]     Test net output #0: accuracy = 0.806641
I0624 17:19:03.592509 21500 solver.cpp:404]     Test net output #1: loss = 0.47518 (* 1 = 0.47518 loss)
I0624 17:19:03.608558 21500 solver.cpp:228] Iteration 1900, loss = 0.264517
I0624 17:19:03.608593 21500 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:19:03.608603 21500 solver.cpp:244]     Train net output #1: loss = 0.264517 (* 1 = 0.264517 loss)
I0624 17:19:03.608610 21500 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0624 17:19:04.603077 21500 solver.cpp:228] Iteration 1920, loss = 0.39033
I0624 17:19:04.603106 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:19:04.603114 21500 solver.cpp:244]     Train net output #1: loss = 0.390329 (* 1 = 0.390329 loss)
I0624 17:19:04.603142 21500 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0624 17:19:05.606564 21500 solver.cpp:228] Iteration 1940, loss = 0.34428
I0624 17:19:05.606592 21500 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 17:19:05.606600 21500 solver.cpp:244]     Train net output #1: loss = 0.34428 (* 1 = 0.34428 loss)
I0624 17:19:05.606604 21500 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0624 17:19:06.606930 21500 solver.cpp:228] Iteration 1960, loss = 0.254697
I0624 17:19:06.606956 21500 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:19:06.606962 21500 solver.cpp:244]     Train net output #1: loss = 0.254697 (* 1 = 0.254697 loss)
I0624 17:19:06.606967 21500 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0624 17:19:07.601084 21500 solver.cpp:228] Iteration 1980, loss = 0.272652
I0624 17:19:07.601110 21500 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 17:19:07.601117 21500 solver.cpp:244]     Train net output #1: loss = 0.272652 (* 1 = 0.272652 loss)
I0624 17:19:07.601121 21500 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0624 17:19:08.573052 21500 solver.cpp:454] Snapshotting to binary proto file data/models/bpgnet_iter_2000.caffemodel
I0624 17:19:08.578992 21500 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpgnet_iter_2000.solverstate
I0624 17:19:08.581962 21500 solver.cpp:337] Iteration 2000, Testing net (#0)
I0624 17:19:08.907405 21500 solver.cpp:404]     Test net output #0: accuracy = 0.769531
I0624 17:19:08.907441 21500 solver.cpp:404]     Test net output #1: loss = 0.518147 (* 1 = 0.518147 loss)
I0624 17:19:08.922917 21500 solver.cpp:228] Iteration 2000, loss = 0.321651
I0624 17:19:08.922946 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:19:08.922953 21500 solver.cpp:244]     Train net output #1: loss = 0.321651 (* 1 = 0.321651 loss)
I0624 17:19:08.922960 21500 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0624 17:19:09.912703 21500 solver.cpp:228] Iteration 2020, loss = 0.344136
I0624 17:19:09.912730 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:19:09.912737 21500 solver.cpp:244]     Train net output #1: loss = 0.344135 (* 1 = 0.344135 loss)
I0624 17:19:09.912742 21500 sgd_solver.cpp:106] Iteration 2020, lr = 0.0001
I0624 17:19:10.896811 21500 solver.cpp:228] Iteration 2040, loss = 0.259336
I0624 17:19:10.896834 21500 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:19:10.896841 21500 solver.cpp:244]     Train net output #1: loss = 0.259336 (* 1 = 0.259336 loss)
I0624 17:19:10.896845 21500 sgd_solver.cpp:106] Iteration 2040, lr = 0.0001
I0624 17:19:11.885329 21500 solver.cpp:228] Iteration 2060, loss = 0.195772
I0624 17:19:11.885368 21500 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0624 17:19:11.885375 21500 solver.cpp:244]     Train net output #1: loss = 0.195772 (* 1 = 0.195772 loss)
I0624 17:19:11.885381 21500 sgd_solver.cpp:106] Iteration 2060, lr = 0.0001
I0624 17:19:12.874588 21500 solver.cpp:228] Iteration 2080, loss = 0.263516
I0624 17:19:12.874614 21500 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:19:12.874621 21500 solver.cpp:244]     Train net output #1: loss = 0.263516 (* 1 = 0.263516 loss)
I0624 17:19:12.874625 21500 sgd_solver.cpp:106] Iteration 2080, lr = 0.0001
I0624 17:19:13.845259 21500 solver.cpp:337] Iteration 2100, Testing net (#0)
I0624 17:19:14.162428 21500 solver.cpp:404]     Test net output #0: accuracy = 0.787109
I0624 17:19:14.162468 21500 solver.cpp:404]     Test net output #1: loss = 0.492886 (* 1 = 0.492886 loss)
I0624 17:19:14.177669 21500 solver.cpp:228] Iteration 2100, loss = 0.472225
I0624 17:19:14.177696 21500 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0624 17:19:14.177703 21500 solver.cpp:244]     Train net output #1: loss = 0.472224 (* 1 = 0.472224 loss)
I0624 17:19:14.177709 21500 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0624 17:19:15.169759 21500 solver.cpp:228] Iteration 2120, loss = 0.236795
I0624 17:19:15.169806 21500 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:19:15.169812 21500 solver.cpp:244]     Train net output #1: loss = 0.236795 (* 1 = 0.236795 loss)
I0624 17:19:15.169817 21500 sgd_solver.cpp:106] Iteration 2120, lr = 0.0001
I0624 17:19:16.153551 21500 solver.cpp:228] Iteration 2140, loss = 0.187117
I0624 17:19:16.153576 21500 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:19:16.153584 21500 solver.cpp:244]     Train net output #1: loss = 0.187117 (* 1 = 0.187117 loss)
I0624 17:19:16.153587 21500 sgd_solver.cpp:106] Iteration 2140, lr = 0.0001
I0624 17:19:17.141721 21500 solver.cpp:228] Iteration 2160, loss = 0.299236
I0624 17:19:17.141759 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:19:17.141765 21500 solver.cpp:244]     Train net output #1: loss = 0.299236 (* 1 = 0.299236 loss)
I0624 17:19:17.141770 21500 sgd_solver.cpp:106] Iteration 2160, lr = 0.0001
I0624 17:19:18.132258 21500 solver.cpp:228] Iteration 2180, loss = 0.346652
I0624 17:19:18.132303 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:19:18.132310 21500 solver.cpp:244]     Train net output #1: loss = 0.346652 (* 1 = 0.346652 loss)
I0624 17:19:18.132314 21500 sgd_solver.cpp:106] Iteration 2180, lr = 0.0001
I0624 17:19:19.106238 21500 solver.cpp:337] Iteration 2200, Testing net (#0)
I0624 17:19:19.430081 21500 solver.cpp:404]     Test net output #0: accuracy = 0.785156
I0624 17:19:19.430116 21500 solver.cpp:404]     Test net output #1: loss = 0.515682 (* 1 = 0.515682 loss)
I0624 17:19:19.445340 21500 solver.cpp:228] Iteration 2200, loss = 0.303699
I0624 17:19:19.445371 21500 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:19:19.445379 21500 solver.cpp:244]     Train net output #1: loss = 0.303699 (* 1 = 0.303699 loss)
I0624 17:19:19.445382 21500 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0624 17:19:20.433712 21500 solver.cpp:228] Iteration 2220, loss = 0.201556
I0624 17:19:20.433748 21500 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0624 17:19:20.433753 21500 solver.cpp:244]     Train net output #1: loss = 0.201556 (* 1 = 0.201556 loss)
I0624 17:19:20.433758 21500 sgd_solver.cpp:106] Iteration 2220, lr = 0.0001
I0624 17:19:21.422363 21500 solver.cpp:228] Iteration 2240, loss = 0.182114
I0624 17:19:21.422391 21500 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0624 17:19:21.422399 21500 solver.cpp:244]     Train net output #1: loss = 0.182114 (* 1 = 0.182114 loss)
I0624 17:19:21.422404 21500 sgd_solver.cpp:106] Iteration 2240, lr = 0.0001
I0624 17:19:22.410508 21500 solver.cpp:228] Iteration 2260, loss = 0.292316
I0624 17:19:22.410544 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:19:22.410552 21500 solver.cpp:244]     Train net output #1: loss = 0.292316 (* 1 = 0.292316 loss)
I0624 17:19:22.410557 21500 sgd_solver.cpp:106] Iteration 2260, lr = 0.0001
I0624 17:19:23.396023 21500 solver.cpp:228] Iteration 2280, loss = 0.213607
I0624 17:19:23.396049 21500 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:19:23.396056 21500 solver.cpp:244]     Train net output #1: loss = 0.213607 (* 1 = 0.213607 loss)
I0624 17:19:23.396060 21500 sgd_solver.cpp:106] Iteration 2280, lr = 0.0001
I0624 17:19:24.369580 21500 solver.cpp:337] Iteration 2300, Testing net (#0)
I0624 17:19:24.694948 21500 solver.cpp:404]     Test net output #0: accuracy = 0.792969
I0624 17:19:24.694983 21500 solver.cpp:404]     Test net output #1: loss = 0.481843 (* 1 = 0.481843 loss)
I0624 17:19:24.710463 21500 solver.cpp:228] Iteration 2300, loss = 0.235053
I0624 17:19:24.710489 21500 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 17:19:24.710497 21500 solver.cpp:244]     Train net output #1: loss = 0.235053 (* 1 = 0.235053 loss)
I0624 17:19:24.710502 21500 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0624 17:19:25.699851 21500 solver.cpp:228] Iteration 2320, loss = 0.223987
I0624 17:19:25.699877 21500 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 17:19:25.699883 21500 solver.cpp:244]     Train net output #1: loss = 0.223987 (* 1 = 0.223987 loss)
I0624 17:19:25.699888 21500 sgd_solver.cpp:106] Iteration 2320, lr = 0.0001
I0624 17:19:26.688616 21500 solver.cpp:228] Iteration 2340, loss = 0.429616
I0624 17:19:26.688654 21500 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0624 17:19:26.688662 21500 solver.cpp:244]     Train net output #1: loss = 0.429616 (* 1 = 0.429616 loss)
I0624 17:19:26.688668 21500 sgd_solver.cpp:106] Iteration 2340, lr = 0.0001
I0624 17:19:27.674515 21500 solver.cpp:228] Iteration 2360, loss = 0.248093
I0624 17:19:27.674541 21500 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:19:27.674548 21500 solver.cpp:244]     Train net output #1: loss = 0.248093 (* 1 = 0.248093 loss)
I0624 17:19:27.674552 21500 sgd_solver.cpp:106] Iteration 2360, lr = 0.0001
I0624 17:19:28.663791 21500 solver.cpp:228] Iteration 2380, loss = 0.348629
I0624 17:19:28.663820 21500 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:19:28.663825 21500 solver.cpp:244]     Train net output #1: loss = 0.348629 (* 1 = 0.348629 loss)
I0624 17:19:28.663830 21500 sgd_solver.cpp:106] Iteration 2380, lr = 0.0001
I0624 17:19:29.639799 21500 solver.cpp:337] Iteration 2400, Testing net (#0)
I0624 17:19:29.966542 21500 solver.cpp:404]     Test net output #0: accuracy = 0.787109
I0624 17:19:29.966572 21500 solver.cpp:404]     Test net output #1: loss = 0.510561 (* 1 = 0.510561 loss)
I0624 17:19:29.981662 21500 solver.cpp:228] Iteration 2400, loss = 0.268727
I0624 17:19:29.981691 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:19:29.981698 21500 solver.cpp:244]     Train net output #1: loss = 0.268727 (* 1 = 0.268727 loss)
I0624 17:19:29.981704 21500 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0624 17:19:30.974556 21500 solver.cpp:228] Iteration 2420, loss = 0.313714
I0624 17:19:30.974581 21500 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:19:30.974599 21500 solver.cpp:244]     Train net output #1: loss = 0.313714 (* 1 = 0.313714 loss)
I0624 17:19:30.974603 21500 sgd_solver.cpp:106] Iteration 2420, lr = 0.0001
I0624 17:19:31.961419 21500 solver.cpp:228] Iteration 2440, loss = 0.472801
I0624 17:19:31.961443 21500 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0624 17:19:31.961452 21500 solver.cpp:244]     Train net output #1: loss = 0.472801 (* 1 = 0.472801 loss)
I0624 17:19:31.961455 21500 sgd_solver.cpp:106] Iteration 2440, lr = 0.0001
I0624 17:19:32.947794 21500 solver.cpp:228] Iteration 2460, loss = 0.32376
I0624 17:19:32.947831 21500 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0624 17:19:32.947839 21500 solver.cpp:244]     Train net output #1: loss = 0.32376 (* 1 = 0.32376 loss)
I0624 17:19:32.947844 21500 sgd_solver.cpp:106] Iteration 2460, lr = 0.0001
I0624 17:19:33.934985 21500 solver.cpp:228] Iteration 2480, loss = 0.229953
I0624 17:19:33.935009 21500 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 17:19:33.935027 21500 solver.cpp:244]     Train net output #1: loss = 0.229952 (* 1 = 0.229952 loss)
I0624 17:19:33.935031 21500 sgd_solver.cpp:106] Iteration 2480, lr = 0.0001
I0624 17:19:34.908684 21500 solver.cpp:454] Snapshotting to binary proto file data/models/bpgnet_iter_2500.caffemodel
I0624 17:19:34.914649 21500 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpgnet_iter_2500.solverstate
I0624 17:19:34.917575 21500 solver.cpp:337] Iteration 2500, Testing net (#0)
I0624 17:19:35.242601 21500 solver.cpp:404]     Test net output #0: accuracy = 0.775391
I0624 17:19:35.242637 21500 solver.cpp:404]     Test net output #1: loss = 0.517161 (* 1 = 0.517161 loss)
I0624 17:19:35.257863 21500 solver.cpp:228] Iteration 2500, loss = 0.483256
I0624 17:19:35.257894 21500 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:19:35.257901 21500 solver.cpp:244]     Train net output #1: loss = 0.483255 (* 1 = 0.483255 loss)
I0624 17:19:35.257906 21500 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0624 17:19:36.249202 21500 solver.cpp:228] Iteration 2520, loss = 0.224462
I0624 17:19:36.249229 21500 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 17:19:36.249236 21500 solver.cpp:244]     Train net output #1: loss = 0.224462 (* 1 = 0.224462 loss)
I0624 17:19:36.249241 21500 sgd_solver.cpp:106] Iteration 2520, lr = 0.0001
I0624 17:19:37.235388 21500 solver.cpp:228] Iteration 2540, loss = 0.163582
I0624 17:19:37.235415 21500 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0624 17:19:37.235424 21500 solver.cpp:244]     Train net output #1: loss = 0.163582 (* 1 = 0.163582 loss)
I0624 17:19:37.235430 21500 sgd_solver.cpp:106] Iteration 2540, lr = 0.0001
I0624 17:19:38.224236 21500 solver.cpp:228] Iteration 2560, loss = 0.323189
I0624 17:19:38.224262 21500 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:19:38.224269 21500 solver.cpp:244]     Train net output #1: loss = 0.323188 (* 1 = 0.323188 loss)
I0624 17:19:38.224273 21500 sgd_solver.cpp:106] Iteration 2560, lr = 0.0001
I0624 17:19:39.213198 21500 solver.cpp:228] Iteration 2580, loss = 0.240537
I0624 17:19:39.213237 21500 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:19:39.213243 21500 solver.cpp:244]     Train net output #1: loss = 0.240536 (* 1 = 0.240536 loss)
I0624 17:19:39.213248 21500 sgd_solver.cpp:106] Iteration 2580, lr = 0.0001
I0624 17:19:40.184779 21500 solver.cpp:337] Iteration 2600, Testing net (#0)
I0624 17:19:40.510205 21500 solver.cpp:404]     Test net output #0: accuracy = 0.791016
I0624 17:19:40.510234 21500 solver.cpp:404]     Test net output #1: loss = 0.487375 (* 1 = 0.487375 loss)
I0624 17:19:40.525411 21500 solver.cpp:228] Iteration 2600, loss = 0.256063
I0624 17:19:40.525439 21500 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 17:19:40.525446 21500 solver.cpp:244]     Train net output #1: loss = 0.256063 (* 1 = 0.256063 loss)
I0624 17:19:40.525451 21500 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0624 17:19:41.513437 21500 solver.cpp:228] Iteration 2620, loss = 0.152649
I0624 17:19:41.513464 21500 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0624 17:19:41.513483 21500 solver.cpp:244]     Train net output #1: loss = 0.152649 (* 1 = 0.152649 loss)
I0624 17:19:41.513486 21500 sgd_solver.cpp:106] Iteration 2620, lr = 0.0001
I0624 17:19:42.499485 21500 solver.cpp:228] Iteration 2640, loss = 0.239844
I0624 17:19:42.499511 21500 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 17:19:42.499518 21500 solver.cpp:244]     Train net output #1: loss = 0.239844 (* 1 = 0.239844 loss)
I0624 17:19:42.499531 21500 sgd_solver.cpp:106] Iteration 2640, lr = 0.0001
I0624 17:19:43.485751 21500 solver.cpp:228] Iteration 2660, loss = 0.217354
I0624 17:19:43.485786 21500 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:19:43.485793 21500 solver.cpp:244]     Train net output #1: loss = 0.217354 (* 1 = 0.217354 loss)
I0624 17:19:43.485800 21500 sgd_solver.cpp:106] Iteration 2660, lr = 0.0001
I0624 17:19:44.471918 21500 solver.cpp:228] Iteration 2680, loss = 0.216498
I0624 17:19:44.471954 21500 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:19:44.471961 21500 solver.cpp:244]     Train net output #1: loss = 0.216498 (* 1 = 0.216498 loss)
I0624 17:19:44.471966 21500 sgd_solver.cpp:106] Iteration 2680, lr = 0.0001
I0624 17:19:45.445853 21500 solver.cpp:337] Iteration 2700, Testing net (#0)
I0624 17:19:45.770969 21500 solver.cpp:404]     Test net output #0: accuracy = 0.783203
I0624 17:19:45.771020 21500 solver.cpp:404]     Test net output #1: loss = 0.506108 (* 1 = 0.506108 loss)
I0624 17:19:45.786687 21500 solver.cpp:228] Iteration 2700, loss = 0.190101
I0624 17:19:45.786713 21500 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0624 17:19:45.786721 21500 solver.cpp:244]     Train net output #1: loss = 0.190101 (* 1 = 0.190101 loss)
I0624 17:19:45.786726 21500 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0624 17:19:46.778285 21500 solver.cpp:228] Iteration 2720, loss = 0.267925
I0624 17:19:46.778316 21500 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:19:46.778322 21500 solver.cpp:244]     Train net output #1: loss = 0.267924 (* 1 = 0.267924 loss)
I0624 17:19:46.778327 21500 sgd_solver.cpp:106] Iteration 2720, lr = 0.0001
I0624 17:19:47.768455 21500 solver.cpp:228] Iteration 2740, loss = 0.322558
I0624 17:19:47.768481 21500 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 17:19:47.768488 21500 solver.cpp:244]     Train net output #1: loss = 0.322558 (* 1 = 0.322558 loss)
I0624 17:19:47.768492 21500 sgd_solver.cpp:106] Iteration 2740, lr = 0.0001
I0624 17:19:48.756518 21500 solver.cpp:228] Iteration 2760, loss = 0.160364
I0624 17:19:48.756556 21500 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:19:48.756563 21500 solver.cpp:244]     Train net output #1: loss = 0.160363 (* 1 = 0.160363 loss)
I0624 17:19:48.756568 21500 sgd_solver.cpp:106] Iteration 2760, lr = 0.0001
I0624 17:19:49.742496 21500 solver.cpp:228] Iteration 2780, loss = 0.290207
I0624 17:19:49.742530 21500 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 17:19:49.742538 21500 solver.cpp:244]     Train net output #1: loss = 0.290207 (* 1 = 0.290207 loss)
I0624 17:19:49.742542 21500 sgd_solver.cpp:106] Iteration 2780, lr = 0.0001
I0624 17:19:50.718224 21500 solver.cpp:337] Iteration 2800, Testing net (#0)
I0624 17:19:50.973172 21500 solver.cpp:404]     Test net output #0: accuracy = 0.800781
I0624 17:19:50.973201 21500 solver.cpp:404]     Test net output #1: loss = 0.509277 (* 1 = 0.509277 loss)
I0624 17:19:50.988373 21500 solver.cpp:228] Iteration 2800, loss = 0.306282
I0624 17:19:50.988400 21500 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:19:50.988407 21500 solver.cpp:244]     Train net output #1: loss = 0.306282 (* 1 = 0.306282 loss)
I0624 17:19:50.988414 21500 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0624 17:19:51.980059 21500 solver.cpp:228] Iteration 2820, loss = 0.368014
I0624 17:19:51.980108 21500 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0624 17:19:51.980114 21500 solver.cpp:244]     Train net output #1: loss = 0.368014 (* 1 = 0.368014 loss)
I0624 17:19:51.980118 21500 sgd_solver.cpp:106] Iteration 2820, lr = 0.0001
I0624 17:19:52.966862 21500 solver.cpp:228] Iteration 2840, loss = 0.2475
I0624 17:19:52.966888 21500 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0624 17:19:52.966897 21500 solver.cpp:244]     Train net output #1: loss = 0.2475 (* 1 = 0.2475 loss)
I0624 17:19:52.966902 21500 sgd_solver.cpp:106] Iteration 2840, lr = 0.0001
I0624 17:19:53.953125 21500 solver.cpp:228] Iteration 2860, loss = 0.13688
I0624 17:19:53.953148 21500 solver.cpp:244]     Train net output #0: accuracy = 0.96875
I0624 17:19:53.953166 21500 solver.cpp:244]     Train net output #1: loss = 0.13688 (* 1 = 0.13688 loss)
I0624 17:19:53.953171 21500 sgd_solver.cpp:106] Iteration 2860, lr = 0.0001
I0624 17:19:54.942435 21500 solver.cpp:228] Iteration 2880, loss = 0.233598
I0624 17:19:54.942555 21500 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 17:19:54.942565 21500 solver.cpp:244]     Train net output #1: loss = 0.233597 (* 1 = 0.233597 loss)
I0624 17:19:54.942570 21500 sgd_solver.cpp:106] Iteration 2880, lr = 0.0001
I0624 17:19:55.914845 21500 solver.cpp:337] Iteration 2900, Testing net (#0)
I0624 17:19:56.238307 21500 solver.cpp:404]     Test net output #0: accuracy = 0.783203
I0624 17:19:56.238346 21500 solver.cpp:404]     Test net output #1: loss = 0.52653 (* 1 = 0.52653 loss)
I0624 17:19:56.253975 21500 solver.cpp:228] Iteration 2900, loss = 0.278513
I0624 17:19:56.254004 21500 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 17:19:56.254014 21500 solver.cpp:244]     Train net output #1: loss = 0.278512 (* 1 = 0.278512 loss)
I0624 17:19:56.254019 21500 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0624 17:19:57.247241 21500 solver.cpp:228] Iteration 2920, loss = 0.236009
I0624 17:19:57.247277 21500 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0624 17:19:57.247284 21500 solver.cpp:244]     Train net output #1: loss = 0.236009 (* 1 = 0.236009 loss)
I0624 17:19:57.247288 21500 sgd_solver.cpp:106] Iteration 2920, lr = 0.0001
I0624 17:19:58.232326 21500 solver.cpp:228] Iteration 2940, loss = 0.172352
I0624 17:19:58.232349 21500 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:19:58.232357 21500 solver.cpp:244]     Train net output #1: loss = 0.172352 (* 1 = 0.172352 loss)
I0624 17:19:58.232362 21500 sgd_solver.cpp:106] Iteration 2940, lr = 0.0001
I0624 17:19:59.217649 21500 solver.cpp:228] Iteration 2960, loss = 0.154646
I0624 17:19:59.217674 21500 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:19:59.217681 21500 solver.cpp:244]     Train net output #1: loss = 0.154646 (* 1 = 0.154646 loss)
I0624 17:19:59.217685 21500 sgd_solver.cpp:106] Iteration 2960, lr = 0.0001
I0624 17:20:00.206034 21500 solver.cpp:228] Iteration 2980, loss = 0.287266
I0624 17:20:00.206063 21500 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0624 17:20:00.206069 21500 solver.cpp:244]     Train net output #1: loss = 0.287266 (* 1 = 0.287266 loss)
I0624 17:20:00.206074 21500 sgd_solver.cpp:106] Iteration 2980, lr = 0.0001
I0624 17:20:01.180539 21500 solver.cpp:454] Snapshotting to binary proto file data/models/bpgnet_iter_3000.caffemodel
I0624 17:20:01.186547 21500 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpgnet_iter_3000.solverstate
I0624 17:20:01.202648 21500 solver.cpp:317] Iteration 3000, loss = 0.234284
I0624 17:20:01.202672 21500 solver.cpp:337] Iteration 3000, Testing net (#0)
I0624 17:20:01.523295 21500 solver.cpp:404]     Test net output #0: accuracy = 0.794922
I0624 17:20:01.523329 21500 solver.cpp:404]     Test net output #1: loss = 0.487503 (* 1 = 0.487503 loss)
I0624 17:20:01.523334 21500 solver.cpp:322] Optimization Done.
I0624 17:20:01.523336 21500 caffe.cpp:222] Optimization Done.
