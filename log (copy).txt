I0524 17:36:11.428194  8086 caffe.cpp:185] Using GPUs 0
I0524 17:36:11.435427  8086 caffe.cpp:190] GPU 0: GeForce GTX TITAN X
I0524 17:36:11.861419  8086 solver.cpp:48] Initializing solver from parameters: 
test_iter: 16
test_interval: 100
base_lr: 0.01
display: 20
max_iter: 10000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 3000
snapshot: 500
snapshot_prefix: "data/models/segnet"
solver_mode: GPU
device_id: 0
net: "models/segnet/train_val.prototxt"
test_initialization: true
I0524 17:36:11.862041  8086 solver.cpp:91] Creating training net from net file: models/segnet/train_val.prototxt
I0524 17:36:11.863951  8086 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0524 17:36:11.864439  8086 net.cpp:49] Initializing net from parameters: 
name: "segnet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "DenseImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 224
    mean_value: 100
  }
  dense_image_data_param {
    source: "data/train.txt"
    batch_size: 32
    shuffle: true
    new_height: 224
    new_width: 310
    is_color: false
    root_folder: "data/raw/train/"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_1"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 14
    upsample_w: 14
  }
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5_1_D"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1_D"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 28
    upsample_w: 28
  }
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4_1_D"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1_D"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
    upsample_h: 56
    upsample_w: 56
  }
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3_1_D"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1_D"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
    upsample_h: 112
    upsample_w: 112
  }
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2_1_D"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1_D"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
    upsample_h: 224
    upsample_w: 224
  }
}
layer {
  name: "conv1_1_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "accuracy"
}
I0524 17:36:11.864795  8086 layer_factory.hpp:77] Creating layer data
I0524 17:36:11.865586  8086 net.cpp:91] Creating Layer data
I0524 17:36:11.865607  8086 net.cpp:399] data -> data
I0524 17:36:11.865643  8086 net.cpp:399] data -> label
I0524 17:36:11.866225  8086 dense_image_data_layer.cpp:38] Opening file data/train.txt
I0524 17:36:11.871047  8086 dense_image_data_layer.cpp:48] Shuffling data
I0524 17:36:11.872298  8086 dense_image_data_layer.cpp:53] A total of 4930 examples.
I0524 17:36:12.150022  8086 dense_image_data_layer.cpp:92] output data size: 1,1,224,224
I0524 17:36:12.152848  8086 net.cpp:141] Setting up data
I0524 17:36:12.152886  8086 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0524 17:36:12.152897  8086 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0524 17:36:12.152904  8086 net.cpp:156] Memory required for data: 401408
I0524 17:36:12.152916  8086 layer_factory.hpp:77] Creating layer label_data_1_split
I0524 17:36:12.153360  8086 net.cpp:91] Creating Layer label_data_1_split
I0524 17:36:12.153405  8086 net.cpp:425] label_data_1_split <- label
I0524 17:36:12.153426  8086 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0524 17:36:12.153445  8086 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0524 17:36:12.153852  8086 net.cpp:141] Setting up label_data_1_split
I0524 17:36:12.153875  8086 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0524 17:36:12.153883  8086 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0524 17:36:12.153888  8086 net.cpp:156] Memory required for data: 802816
I0524 17:36:12.153895  8086 layer_factory.hpp:77] Creating layer conv1_1
I0524 17:36:12.153923  8086 net.cpp:91] Creating Layer conv1_1
I0524 17:36:12.153929  8086 net.cpp:425] conv1_1 <- data
I0524 17:36:12.153940  8086 net.cpp:399] conv1_1 -> conv1_1
I0524 17:36:12.537703  8086 net.cpp:141] Setting up conv1_1
I0524 17:36:12.537732  8086 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0524 17:36:12.537736  8086 net.cpp:156] Memory required for data: 7225344
I0524 17:36:12.537750  8086 layer_factory.hpp:77] Creating layer bn1_1
I0524 17:36:12.537766  8086 net.cpp:91] Creating Layer bn1_1
I0524 17:36:12.537771  8086 net.cpp:425] bn1_1 <- conv1_1
I0524 17:36:12.537777  8086 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0524 17:36:12.538039  8086 net.cpp:141] Setting up bn1_1
I0524 17:36:12.538051  8086 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0524 17:36:12.538055  8086 net.cpp:156] Memory required for data: 13647872
I0524 17:36:12.538069  8086 layer_factory.hpp:77] Creating layer scale1_1
I0524 17:36:12.538080  8086 net.cpp:91] Creating Layer scale1_1
I0524 17:36:12.538084  8086 net.cpp:425] scale1_1 <- conv1_1
I0524 17:36:12.538089  8086 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0524 17:36:12.538141  8086 layer_factory.hpp:77] Creating layer scale1_1
I0524 17:36:12.538347  8086 net.cpp:141] Setting up scale1_1
I0524 17:36:12.538358  8086 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0524 17:36:12.538362  8086 net.cpp:156] Memory required for data: 20070400
I0524 17:36:12.538369  8086 layer_factory.hpp:77] Creating layer relu1_1
I0524 17:36:12.538375  8086 net.cpp:91] Creating Layer relu1_1
I0524 17:36:12.538378  8086 net.cpp:425] relu1_1 <- conv1_1
I0524 17:36:12.538385  8086 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0524 17:36:12.538707  8086 net.cpp:141] Setting up relu1_1
I0524 17:36:12.538722  8086 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0524 17:36:12.538725  8086 net.cpp:156] Memory required for data: 26492928
I0524 17:36:12.538729  8086 layer_factory.hpp:77] Creating layer pool1
I0524 17:36:12.538733  8086 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0524 17:36:12.538739  8086 net.cpp:91] Creating Layer pool1
I0524 17:36:12.538743  8086 net.cpp:425] pool1 <- conv1_1
I0524 17:36:12.538749  8086 net.cpp:399] pool1 -> pool1
I0524 17:36:12.538758  8086 net.cpp:399] pool1 -> pool1_mask
I0524 17:36:12.538810  8086 net.cpp:141] Setting up pool1
I0524 17:36:12.538817  8086 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0524 17:36:12.538820  8086 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0524 17:36:12.538823  8086 net.cpp:156] Memory required for data: 29704192
I0524 17:36:12.538826  8086 layer_factory.hpp:77] Creating layer conv2_1
I0524 17:36:12.538837  8086 net.cpp:91] Creating Layer conv2_1
I0524 17:36:12.538841  8086 net.cpp:425] conv2_1 <- pool1
I0524 17:36:12.538846  8086 net.cpp:399] conv2_1 -> conv2_1
I0524 17:36:12.540546  8086 net.cpp:141] Setting up conv2_1
I0524 17:36:12.540563  8086 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0524 17:36:12.540567  8086 net.cpp:156] Memory required for data: 32915456
I0524 17:36:12.540573  8086 layer_factory.hpp:77] Creating layer bn2_1
I0524 17:36:12.540585  8086 net.cpp:91] Creating Layer bn2_1
I0524 17:36:12.540590  8086 net.cpp:425] bn2_1 <- conv2_1
I0524 17:36:12.540594  8086 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0524 17:36:12.541265  8086 net.cpp:141] Setting up bn2_1
I0524 17:36:12.541280  8086 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0524 17:36:12.541283  8086 net.cpp:156] Memory required for data: 36126720
I0524 17:36:12.541316  8086 layer_factory.hpp:77] Creating layer scale2_1
I0524 17:36:12.541326  8086 net.cpp:91] Creating Layer scale2_1
I0524 17:36:12.541328  8086 net.cpp:425] scale2_1 <- conv2_1
I0524 17:36:12.541334  8086 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0524 17:36:12.541384  8086 layer_factory.hpp:77] Creating layer scale2_1
I0524 17:36:12.541517  8086 net.cpp:141] Setting up scale2_1
I0524 17:36:12.541527  8086 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0524 17:36:12.541529  8086 net.cpp:156] Memory required for data: 39337984
I0524 17:36:12.541535  8086 layer_factory.hpp:77] Creating layer relu2_1
I0524 17:36:12.541541  8086 net.cpp:91] Creating Layer relu2_1
I0524 17:36:12.541544  8086 net.cpp:425] relu2_1 <- conv2_1
I0524 17:36:12.541550  8086 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0524 17:36:12.541743  8086 net.cpp:141] Setting up relu2_1
I0524 17:36:12.541755  8086 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0524 17:36:12.541759  8086 net.cpp:156] Memory required for data: 42549248
I0524 17:36:12.541762  8086 layer_factory.hpp:77] Creating layer pool2
I0524 17:36:12.541766  8086 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0524 17:36:12.541781  8086 net.cpp:91] Creating Layer pool2
I0524 17:36:12.541785  8086 net.cpp:425] pool2 <- conv2_1
I0524 17:36:12.541790  8086 net.cpp:399] pool2 -> pool2
I0524 17:36:12.541797  8086 net.cpp:399] pool2 -> pool2_mask
I0524 17:36:12.541843  8086 net.cpp:141] Setting up pool2
I0524 17:36:12.541852  8086 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0524 17:36:12.541856  8086 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0524 17:36:12.541858  8086 net.cpp:156] Memory required for data: 44154880
I0524 17:36:12.541862  8086 layer_factory.hpp:77] Creating layer conv3_1
I0524 17:36:12.541872  8086 net.cpp:91] Creating Layer conv3_1
I0524 17:36:12.541874  8086 net.cpp:425] conv3_1 <- pool2
I0524 17:36:12.541882  8086 net.cpp:399] conv3_1 -> conv3_1
I0524 17:36:12.548964  8086 net.cpp:141] Setting up conv3_1
I0524 17:36:12.548990  8086 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0524 17:36:12.548993  8086 net.cpp:156] Memory required for data: 45760512
I0524 17:36:12.549000  8086 layer_factory.hpp:77] Creating layer bn3_1
I0524 17:36:12.549013  8086 net.cpp:91] Creating Layer bn3_1
I0524 17:36:12.549018  8086 net.cpp:425] bn3_1 <- conv3_1
I0524 17:36:12.549026  8086 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0524 17:36:12.549662  8086 net.cpp:141] Setting up bn3_1
I0524 17:36:12.549677  8086 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0524 17:36:12.549681  8086 net.cpp:156] Memory required for data: 47366144
I0524 17:36:12.549690  8086 layer_factory.hpp:77] Creating layer scale3_1
I0524 17:36:12.549700  8086 net.cpp:91] Creating Layer scale3_1
I0524 17:36:12.549703  8086 net.cpp:425] scale3_1 <- conv3_1
I0524 17:36:12.549708  8086 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0524 17:36:12.549757  8086 layer_factory.hpp:77] Creating layer scale3_1
I0524 17:36:12.549880  8086 net.cpp:141] Setting up scale3_1
I0524 17:36:12.549891  8086 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0524 17:36:12.549895  8086 net.cpp:156] Memory required for data: 48971776
I0524 17:36:12.549906  8086 layer_factory.hpp:77] Creating layer relu3_1
I0524 17:36:12.549916  8086 net.cpp:91] Creating Layer relu3_1
I0524 17:36:12.549918  8086 net.cpp:425] relu3_1 <- conv3_1
I0524 17:36:12.549923  8086 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0524 17:36:12.550114  8086 net.cpp:141] Setting up relu3_1
I0524 17:36:12.550127  8086 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0524 17:36:12.550129  8086 net.cpp:156] Memory required for data: 50577408
I0524 17:36:12.550132  8086 layer_factory.hpp:77] Creating layer pool3
I0524 17:36:12.550137  8086 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0524 17:36:12.550146  8086 net.cpp:91] Creating Layer pool3
I0524 17:36:12.550149  8086 net.cpp:425] pool3 <- conv3_1
I0524 17:36:12.550155  8086 net.cpp:399] pool3 -> pool3
I0524 17:36:12.550181  8086 net.cpp:399] pool3 -> pool3_mask
I0524 17:36:12.550238  8086 net.cpp:141] Setting up pool3
I0524 17:36:12.550246  8086 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0524 17:36:12.550251  8086 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0524 17:36:12.550253  8086 net.cpp:156] Memory required for data: 51380224
I0524 17:36:12.550256  8086 layer_factory.hpp:77] Creating layer conv4_1
I0524 17:36:12.550267  8086 net.cpp:91] Creating Layer conv4_1
I0524 17:36:12.550271  8086 net.cpp:425] conv4_1 <- pool3
I0524 17:36:12.550277  8086 net.cpp:399] conv4_1 -> conv4_1
I0524 17:36:12.561990  8086 net.cpp:141] Setting up conv4_1
I0524 17:36:12.562011  8086 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0524 17:36:12.562014  8086 net.cpp:156] Memory required for data: 52183040
I0524 17:36:12.562021  8086 layer_factory.hpp:77] Creating layer bn4_1
I0524 17:36:12.562029  8086 net.cpp:91] Creating Layer bn4_1
I0524 17:36:12.562032  8086 net.cpp:425] bn4_1 <- conv4_1
I0524 17:36:12.562039  8086 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0524 17:36:12.562235  8086 net.cpp:141] Setting up bn4_1
I0524 17:36:12.562245  8086 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0524 17:36:12.562248  8086 net.cpp:156] Memory required for data: 52985856
I0524 17:36:12.562255  8086 layer_factory.hpp:77] Creating layer scale4_1
I0524 17:36:12.562263  8086 net.cpp:91] Creating Layer scale4_1
I0524 17:36:12.562266  8086 net.cpp:425] scale4_1 <- conv4_1
I0524 17:36:12.562271  8086 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0524 17:36:12.562314  8086 layer_factory.hpp:77] Creating layer scale4_1
I0524 17:36:12.562427  8086 net.cpp:141] Setting up scale4_1
I0524 17:36:12.562438  8086 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0524 17:36:12.562440  8086 net.cpp:156] Memory required for data: 53788672
I0524 17:36:12.562445  8086 layer_factory.hpp:77] Creating layer relu4_1
I0524 17:36:12.562453  8086 net.cpp:91] Creating Layer relu4_1
I0524 17:36:12.562456  8086 net.cpp:425] relu4_1 <- conv4_1
I0524 17:36:12.562460  8086 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0524 17:36:12.562773  8086 net.cpp:141] Setting up relu4_1
I0524 17:36:12.562788  8086 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0524 17:36:12.562791  8086 net.cpp:156] Memory required for data: 54591488
I0524 17:36:12.562795  8086 layer_factory.hpp:77] Creating layer pool4
I0524 17:36:12.562798  8086 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0524 17:36:12.562804  8086 net.cpp:91] Creating Layer pool4
I0524 17:36:12.562809  8086 net.cpp:425] pool4 <- conv4_1
I0524 17:36:12.562814  8086 net.cpp:399] pool4 -> pool4
I0524 17:36:12.562821  8086 net.cpp:399] pool4 -> pool4_mask
I0524 17:36:12.562870  8086 net.cpp:141] Setting up pool4
I0524 17:36:12.562876  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.562880  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.562883  8086 net.cpp:156] Memory required for data: 54992896
I0524 17:36:12.562886  8086 layer_factory.hpp:77] Creating layer conv5_1
I0524 17:36:12.562896  8086 net.cpp:91] Creating Layer conv5_1
I0524 17:36:12.562899  8086 net.cpp:425] conv5_1 <- pool4
I0524 17:36:12.562904  8086 net.cpp:399] conv5_1 -> conv5_1
I0524 17:36:12.583921  8086 net.cpp:141] Setting up conv5_1
I0524 17:36:12.583940  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.583945  8086 net.cpp:156] Memory required for data: 55193600
I0524 17:36:12.583950  8086 layer_factory.hpp:77] Creating layer bn5_1
I0524 17:36:12.583958  8086 net.cpp:91] Creating Layer bn5_1
I0524 17:36:12.583962  8086 net.cpp:425] bn5_1 <- conv5_1
I0524 17:36:12.583968  8086 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0524 17:36:12.584179  8086 net.cpp:141] Setting up bn5_1
I0524 17:36:12.584188  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.584197  8086 net.cpp:156] Memory required for data: 55394304
I0524 17:36:12.584211  8086 layer_factory.hpp:77] Creating layer scale5_1
I0524 17:36:12.584223  8086 net.cpp:91] Creating Layer scale5_1
I0524 17:36:12.584229  8086 net.cpp:425] scale5_1 <- conv5_1
I0524 17:36:12.584265  8086 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0524 17:36:12.584339  8086 layer_factory.hpp:77] Creating layer scale5_1
I0524 17:36:12.584483  8086 net.cpp:141] Setting up scale5_1
I0524 17:36:12.584494  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.584497  8086 net.cpp:156] Memory required for data: 55595008
I0524 17:36:12.584502  8086 layer_factory.hpp:77] Creating layer relu5_1
I0524 17:36:12.584508  8086 net.cpp:91] Creating Layer relu5_1
I0524 17:36:12.584511  8086 net.cpp:425] relu5_1 <- conv5_1
I0524 17:36:12.584516  8086 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0524 17:36:12.584705  8086 net.cpp:141] Setting up relu5_1
I0524 17:36:12.584717  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.584719  8086 net.cpp:156] Memory required for data: 55795712
I0524 17:36:12.584723  8086 layer_factory.hpp:77] Creating layer pool5
I0524 17:36:12.584727  8086 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0524 17:36:12.584733  8086 net.cpp:91] Creating Layer pool5
I0524 17:36:12.584738  8086 net.cpp:425] pool5 <- conv5_1
I0524 17:36:12.584743  8086 net.cpp:399] pool5 -> pool5
I0524 17:36:12.584748  8086 net.cpp:399] pool5 -> pool5_mask
I0524 17:36:12.584790  8086 net.cpp:141] Setting up pool5
I0524 17:36:12.584797  8086 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0524 17:36:12.584801  8086 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0524 17:36:12.584803  8086 net.cpp:156] Memory required for data: 55896064
I0524 17:36:12.584806  8086 layer_factory.hpp:77] Creating layer upsample5
I0524 17:36:12.584817  8086 net.cpp:91] Creating Layer upsample5
I0524 17:36:12.584820  8086 net.cpp:425] upsample5 <- pool5
I0524 17:36:12.584825  8086 net.cpp:425] upsample5 <- pool5_mask
I0524 17:36:12.584828  8086 net.cpp:399] upsample5 -> pool5_D
I0524 17:36:12.584856  8086 net.cpp:141] Setting up upsample5
I0524 17:36:12.584861  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.584863  8086 net.cpp:156] Memory required for data: 56096768
I0524 17:36:12.584866  8086 layer_factory.hpp:77] Creating layer conv5_1_D
I0524 17:36:12.584877  8086 net.cpp:91] Creating Layer conv5_1_D
I0524 17:36:12.584879  8086 net.cpp:425] conv5_1_D <- pool5_D
I0524 17:36:12.584885  8086 net.cpp:399] conv5_1_D -> conv5_1_D
I0524 17:36:12.604595  8086 net.cpp:141] Setting up conv5_1_D
I0524 17:36:12.604615  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.604619  8086 net.cpp:156] Memory required for data: 56297472
I0524 17:36:12.604624  8086 layer_factory.hpp:77] Creating layer bn5_1_D
I0524 17:36:12.604635  8086 net.cpp:91] Creating Layer bn5_1_D
I0524 17:36:12.604638  8086 net.cpp:425] bn5_1_D <- conv5_1_D
I0524 17:36:12.604645  8086 net.cpp:386] bn5_1_D -> conv5_1_D (in-place)
I0524 17:36:12.604817  8086 net.cpp:141] Setting up bn5_1_D
I0524 17:36:12.604825  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.604828  8086 net.cpp:156] Memory required for data: 56498176
I0524 17:36:12.604845  8086 layer_factory.hpp:77] Creating layer scale5_1_D
I0524 17:36:12.604852  8086 net.cpp:91] Creating Layer scale5_1_D
I0524 17:36:12.604856  8086 net.cpp:425] scale5_1_D <- conv5_1_D
I0524 17:36:12.604859  8086 net.cpp:386] scale5_1_D -> conv5_1_D (in-place)
I0524 17:36:12.604899  8086 layer_factory.hpp:77] Creating layer scale5_1_D
I0524 17:36:12.605002  8086 net.cpp:141] Setting up scale5_1_D
I0524 17:36:12.605010  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.605013  8086 net.cpp:156] Memory required for data: 56698880
I0524 17:36:12.605018  8086 layer_factory.hpp:77] Creating layer relu5_1_D
I0524 17:36:12.605023  8086 net.cpp:91] Creating Layer relu5_1_D
I0524 17:36:12.605026  8086 net.cpp:425] relu5_1_D <- conv5_1_D
I0524 17:36:12.605031  8086 net.cpp:386] relu5_1_D -> conv5_1_D (in-place)
I0524 17:36:12.605201  8086 net.cpp:141] Setting up relu5_1_D
I0524 17:36:12.605211  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.605214  8086 net.cpp:156] Memory required for data: 56899584
I0524 17:36:12.605242  8086 layer_factory.hpp:77] Creating layer upsample4
I0524 17:36:12.605254  8086 net.cpp:91] Creating Layer upsample4
I0524 17:36:12.605257  8086 net.cpp:425] upsample4 <- conv5_1_D
I0524 17:36:12.605262  8086 net.cpp:425] upsample4 <- pool4_mask
I0524 17:36:12.605267  8086 net.cpp:399] upsample4 -> pool4_D
I0524 17:36:12.605298  8086 net.cpp:141] Setting up upsample4
I0524 17:36:12.605304  8086 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0524 17:36:12.605307  8086 net.cpp:156] Memory required for data: 57702400
I0524 17:36:12.605310  8086 layer_factory.hpp:77] Creating layer conv4_1_D
I0524 17:36:12.605320  8086 net.cpp:91] Creating Layer conv4_1_D
I0524 17:36:12.605324  8086 net.cpp:425] conv4_1_D <- pool4_D
I0524 17:36:12.605329  8086 net.cpp:399] conv4_1_D -> conv4_1_D
I0524 17:36:12.615335  8086 net.cpp:141] Setting up conv4_1_D
I0524 17:36:12.615350  8086 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0524 17:36:12.615352  8086 net.cpp:156] Memory required for data: 58103808
I0524 17:36:12.615357  8086 layer_factory.hpp:77] Creating layer bn4_1_D
I0524 17:36:12.615367  8086 net.cpp:91] Creating Layer bn4_1_D
I0524 17:36:12.615371  8086 net.cpp:425] bn4_1_D <- conv4_1_D
I0524 17:36:12.615375  8086 net.cpp:386] bn4_1_D -> conv4_1_D (in-place)
I0524 17:36:12.615550  8086 net.cpp:141] Setting up bn4_1_D
I0524 17:36:12.615558  8086 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0524 17:36:12.615561  8086 net.cpp:156] Memory required for data: 58505216
I0524 17:36:12.615567  8086 layer_factory.hpp:77] Creating layer scale4_1_D
I0524 17:36:12.615573  8086 net.cpp:91] Creating Layer scale4_1_D
I0524 17:36:12.615576  8086 net.cpp:425] scale4_1_D <- conv4_1_D
I0524 17:36:12.615582  8086 net.cpp:386] scale4_1_D -> conv4_1_D (in-place)
I0524 17:36:12.615618  8086 layer_factory.hpp:77] Creating layer scale4_1_D
I0524 17:36:12.615715  8086 net.cpp:141] Setting up scale4_1_D
I0524 17:36:12.615723  8086 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0524 17:36:12.615726  8086 net.cpp:156] Memory required for data: 58906624
I0524 17:36:12.615731  8086 layer_factory.hpp:77] Creating layer relu4_1_D
I0524 17:36:12.615736  8086 net.cpp:91] Creating Layer relu4_1_D
I0524 17:36:12.615738  8086 net.cpp:425] relu4_1_D <- conv4_1_D
I0524 17:36:12.615741  8086 net.cpp:386] relu4_1_D -> conv4_1_D (in-place)
I0524 17:36:12.616019  8086 net.cpp:141] Setting up relu4_1_D
I0524 17:36:12.616032  8086 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0524 17:36:12.616034  8086 net.cpp:156] Memory required for data: 59308032
I0524 17:36:12.616037  8086 layer_factory.hpp:77] Creating layer upsample3
I0524 17:36:12.616045  8086 net.cpp:91] Creating Layer upsample3
I0524 17:36:12.616049  8086 net.cpp:425] upsample3 <- conv4_1_D
I0524 17:36:12.616052  8086 net.cpp:425] upsample3 <- pool3_mask
I0524 17:36:12.616056  8086 net.cpp:399] upsample3 -> pool3_D
I0524 17:36:12.616087  8086 net.cpp:141] Setting up upsample3
I0524 17:36:12.616092  8086 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0524 17:36:12.616096  8086 net.cpp:156] Memory required for data: 60913664
I0524 17:36:12.616097  8086 layer_factory.hpp:77] Creating layer conv3_1_D
I0524 17:36:12.616106  8086 net.cpp:91] Creating Layer conv3_1_D
I0524 17:36:12.616108  8086 net.cpp:425] conv3_1_D <- pool3_D
I0524 17:36:12.616113  8086 net.cpp:399] conv3_1_D -> conv3_1_D
I0524 17:36:12.619292  8086 net.cpp:141] Setting up conv3_1_D
I0524 17:36:12.619305  8086 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0524 17:36:12.619308  8086 net.cpp:156] Memory required for data: 61716480
I0524 17:36:12.619314  8086 layer_factory.hpp:77] Creating layer bn3_1_D
I0524 17:36:12.619321  8086 net.cpp:91] Creating Layer bn3_1_D
I0524 17:36:12.619330  8086 net.cpp:425] bn3_1_D <- conv3_1_D
I0524 17:36:12.619335  8086 net.cpp:386] bn3_1_D -> conv3_1_D (in-place)
I0524 17:36:12.619523  8086 net.cpp:141] Setting up bn3_1_D
I0524 17:36:12.619531  8086 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0524 17:36:12.619534  8086 net.cpp:156] Memory required for data: 62519296
I0524 17:36:12.619540  8086 layer_factory.hpp:77] Creating layer scale3_1_D
I0524 17:36:12.619559  8086 net.cpp:91] Creating Layer scale3_1_D
I0524 17:36:12.619561  8086 net.cpp:425] scale3_1_D <- conv3_1_D
I0524 17:36:12.619565  8086 net.cpp:386] scale3_1_D -> conv3_1_D (in-place)
I0524 17:36:12.619607  8086 layer_factory.hpp:77] Creating layer scale3_1_D
I0524 17:36:12.619720  8086 net.cpp:141] Setting up scale3_1_D
I0524 17:36:12.619729  8086 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0524 17:36:12.619731  8086 net.cpp:156] Memory required for data: 63322112
I0524 17:36:12.619735  8086 layer_factory.hpp:77] Creating layer relu3_1_D
I0524 17:36:12.619740  8086 net.cpp:91] Creating Layer relu3_1_D
I0524 17:36:12.619743  8086 net.cpp:425] relu3_1_D <- conv3_1_D
I0524 17:36:12.619747  8086 net.cpp:386] relu3_1_D -> conv3_1_D (in-place)
I0524 17:36:12.619921  8086 net.cpp:141] Setting up relu3_1_D
I0524 17:36:12.619931  8086 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0524 17:36:12.619935  8086 net.cpp:156] Memory required for data: 64124928
I0524 17:36:12.619937  8086 layer_factory.hpp:77] Creating layer upsample2
I0524 17:36:12.619943  8086 net.cpp:91] Creating Layer upsample2
I0524 17:36:12.619946  8086 net.cpp:425] upsample2 <- conv3_1_D
I0524 17:36:12.619949  8086 net.cpp:425] upsample2 <- pool2_mask
I0524 17:36:12.619956  8086 net.cpp:399] upsample2 -> pool2_D
I0524 17:36:12.619983  8086 net.cpp:141] Setting up upsample2
I0524 17:36:12.619988  8086 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0524 17:36:12.619992  8086 net.cpp:156] Memory required for data: 67336192
I0524 17:36:12.619993  8086 layer_factory.hpp:77] Creating layer conv2_1_D
I0524 17:36:12.620003  8086 net.cpp:91] Creating Layer conv2_1_D
I0524 17:36:12.620007  8086 net.cpp:425] conv2_1_D <- pool2_D
I0524 17:36:12.620010  8086 net.cpp:399] conv2_1_D -> conv2_1_D
I0524 17:36:12.621708  8086 net.cpp:141] Setting up conv2_1_D
I0524 17:36:12.621721  8086 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0524 17:36:12.621726  8086 net.cpp:156] Memory required for data: 68941824
I0524 17:36:12.621729  8086 layer_factory.hpp:77] Creating layer bn2_1_D
I0524 17:36:12.621737  8086 net.cpp:91] Creating Layer bn2_1_D
I0524 17:36:12.621740  8086 net.cpp:425] bn2_1_D <- conv2_1_D
I0524 17:36:12.621747  8086 net.cpp:386] bn2_1_D -> conv2_1_D (in-place)
I0524 17:36:12.621929  8086 net.cpp:141] Setting up bn2_1_D
I0524 17:36:12.621938  8086 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0524 17:36:12.621942  8086 net.cpp:156] Memory required for data: 70547456
I0524 17:36:12.621948  8086 layer_factory.hpp:77] Creating layer scale2_1_D
I0524 17:36:12.621954  8086 net.cpp:91] Creating Layer scale2_1_D
I0524 17:36:12.621958  8086 net.cpp:425] scale2_1_D <- conv2_1_D
I0524 17:36:12.621961  8086 net.cpp:386] scale2_1_D -> conv2_1_D (in-place)
I0524 17:36:12.622004  8086 layer_factory.hpp:77] Creating layer scale2_1_D
I0524 17:36:12.622128  8086 net.cpp:141] Setting up scale2_1_D
I0524 17:36:12.622138  8086 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0524 17:36:12.622139  8086 net.cpp:156] Memory required for data: 72153088
I0524 17:36:12.622144  8086 layer_factory.hpp:77] Creating layer relu2_1_D
I0524 17:36:12.622149  8086 net.cpp:91] Creating Layer relu2_1_D
I0524 17:36:12.622153  8086 net.cpp:425] relu2_1_D <- conv2_1_D
I0524 17:36:12.622159  8086 net.cpp:386] relu2_1_D -> conv2_1_D (in-place)
I0524 17:36:12.622316  8086 net.cpp:141] Setting up relu2_1_D
I0524 17:36:12.622328  8086 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0524 17:36:12.622330  8086 net.cpp:156] Memory required for data: 73758720
I0524 17:36:12.622334  8086 layer_factory.hpp:77] Creating layer upsample1
I0524 17:36:12.622339  8086 net.cpp:91] Creating Layer upsample1
I0524 17:36:12.622342  8086 net.cpp:425] upsample1 <- conv2_1_D
I0524 17:36:12.622346  8086 net.cpp:425] upsample1 <- pool1_mask
I0524 17:36:12.622350  8086 net.cpp:399] upsample1 -> pool1_D
I0524 17:36:12.622380  8086 net.cpp:141] Setting up upsample1
I0524 17:36:12.622385  8086 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0524 17:36:12.622386  8086 net.cpp:156] Memory required for data: 80181248
I0524 17:36:12.622400  8086 layer_factory.hpp:77] Creating layer conv1_1_D
I0524 17:36:12.622411  8086 net.cpp:91] Creating Layer conv1_1_D
I0524 17:36:12.622414  8086 net.cpp:425] conv1_1_D <- pool1_D
I0524 17:36:12.622421  8086 net.cpp:399] conv1_1_D -> conv1_1_D
I0524 17:36:12.623565  8086 net.cpp:141] Setting up conv1_1_D
I0524 17:36:12.623580  8086 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0524 17:36:12.623584  8086 net.cpp:156] Memory required for data: 80582656
I0524 17:36:12.623589  8086 layer_factory.hpp:77] Creating layer conv1_1_D_conv1_1_D_0_split
I0524 17:36:12.623597  8086 net.cpp:91] Creating Layer conv1_1_D_conv1_1_D_0_split
I0524 17:36:12.623600  8086 net.cpp:425] conv1_1_D_conv1_1_D_0_split <- conv1_1_D
I0524 17:36:12.623605  8086 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_0
I0524 17:36:12.623610  8086 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_1
I0524 17:36:12.623656  8086 net.cpp:141] Setting up conv1_1_D_conv1_1_D_0_split
I0524 17:36:12.623661  8086 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0524 17:36:12.623664  8086 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0524 17:36:12.623667  8086 net.cpp:156] Memory required for data: 81385472
I0524 17:36:12.623669  8086 layer_factory.hpp:77] Creating layer loss
I0524 17:36:12.623685  8086 net.cpp:91] Creating Layer loss
I0524 17:36:12.623688  8086 net.cpp:425] loss <- conv1_1_D_conv1_1_D_0_split_0
I0524 17:36:12.623692  8086 net.cpp:425] loss <- label_data_1_split_0
I0524 17:36:12.623695  8086 net.cpp:399] loss -> loss
I0524 17:36:12.623703  8086 layer_factory.hpp:77] Creating layer loss
I0524 17:36:12.624467  8086 net.cpp:141] Setting up loss
I0524 17:36:12.624480  8086 net.cpp:148] Top shape: (1)
I0524 17:36:12.624483  8086 net.cpp:151]     with loss weight 1
I0524 17:36:12.624498  8086 net.cpp:156] Memory required for data: 81385476
I0524 17:36:12.624501  8086 layer_factory.hpp:77] Creating layer accuracy
I0524 17:36:12.624506  8086 net.cpp:91] Creating Layer accuracy
I0524 17:36:12.624510  8086 net.cpp:425] accuracy <- conv1_1_D_conv1_1_D_0_split_1
I0524 17:36:12.624513  8086 net.cpp:425] accuracy <- label_data_1_split_1
I0524 17:36:12.624518  8086 net.cpp:399] accuracy -> accuracy
I0524 17:36:12.624529  8086 net.cpp:141] Setting up accuracy
I0524 17:36:12.624533  8086 net.cpp:148] Top shape: (1)
I0524 17:36:12.624536  8086 net.cpp:156] Memory required for data: 81385480
I0524 17:36:12.624537  8086 net.cpp:219] accuracy does not need backward computation.
I0524 17:36:12.624541  8086 net.cpp:217] loss needs backward computation.
I0524 17:36:12.624543  8086 net.cpp:217] conv1_1_D_conv1_1_D_0_split needs backward computation.
I0524 17:36:12.624546  8086 net.cpp:217] conv1_1_D needs backward computation.
I0524 17:36:12.624548  8086 net.cpp:217] upsample1 needs backward computation.
I0524 17:36:12.624552  8086 net.cpp:217] relu2_1_D needs backward computation.
I0524 17:36:12.624553  8086 net.cpp:217] scale2_1_D needs backward computation.
I0524 17:36:12.624555  8086 net.cpp:217] bn2_1_D needs backward computation.
I0524 17:36:12.624557  8086 net.cpp:217] conv2_1_D needs backward computation.
I0524 17:36:12.624559  8086 net.cpp:217] upsample2 needs backward computation.
I0524 17:36:12.624562  8086 net.cpp:217] relu3_1_D needs backward computation.
I0524 17:36:12.624564  8086 net.cpp:217] scale3_1_D needs backward computation.
I0524 17:36:12.624567  8086 net.cpp:217] bn3_1_D needs backward computation.
I0524 17:36:12.624568  8086 net.cpp:217] conv3_1_D needs backward computation.
I0524 17:36:12.624572  8086 net.cpp:217] upsample3 needs backward computation.
I0524 17:36:12.624573  8086 net.cpp:217] relu4_1_D needs backward computation.
I0524 17:36:12.624575  8086 net.cpp:217] scale4_1_D needs backward computation.
I0524 17:36:12.624577  8086 net.cpp:217] bn4_1_D needs backward computation.
I0524 17:36:12.624579  8086 net.cpp:217] conv4_1_D needs backward computation.
I0524 17:36:12.624582  8086 net.cpp:217] upsample4 needs backward computation.
I0524 17:36:12.624595  8086 net.cpp:217] relu5_1_D needs backward computation.
I0524 17:36:12.624598  8086 net.cpp:217] scale5_1_D needs backward computation.
I0524 17:36:12.624599  8086 net.cpp:217] bn5_1_D needs backward computation.
I0524 17:36:12.624603  8086 net.cpp:217] conv5_1_D needs backward computation.
I0524 17:36:12.624605  8086 net.cpp:217] upsample5 needs backward computation.
I0524 17:36:12.624608  8086 net.cpp:217] pool5 needs backward computation.
I0524 17:36:12.624610  8086 net.cpp:217] relu5_1 needs backward computation.
I0524 17:36:12.624614  8086 net.cpp:217] scale5_1 needs backward computation.
I0524 17:36:12.624615  8086 net.cpp:217] bn5_1 needs backward computation.
I0524 17:36:12.624617  8086 net.cpp:217] conv5_1 needs backward computation.
I0524 17:36:12.624620  8086 net.cpp:217] pool4 needs backward computation.
I0524 17:36:12.624622  8086 net.cpp:217] relu4_1 needs backward computation.
I0524 17:36:12.624625  8086 net.cpp:217] scale4_1 needs backward computation.
I0524 17:36:12.624627  8086 net.cpp:217] bn4_1 needs backward computation.
I0524 17:36:12.624629  8086 net.cpp:217] conv4_1 needs backward computation.
I0524 17:36:12.624632  8086 net.cpp:217] pool3 needs backward computation.
I0524 17:36:12.624634  8086 net.cpp:217] relu3_1 needs backward computation.
I0524 17:36:12.624637  8086 net.cpp:217] scale3_1 needs backward computation.
I0524 17:36:12.624639  8086 net.cpp:217] bn3_1 needs backward computation.
I0524 17:36:12.624641  8086 net.cpp:217] conv3_1 needs backward computation.
I0524 17:36:12.624644  8086 net.cpp:217] pool2 needs backward computation.
I0524 17:36:12.624646  8086 net.cpp:217] relu2_1 needs backward computation.
I0524 17:36:12.624649  8086 net.cpp:217] scale2_1 needs backward computation.
I0524 17:36:12.624651  8086 net.cpp:217] bn2_1 needs backward computation.
I0524 17:36:12.624653  8086 net.cpp:217] conv2_1 needs backward computation.
I0524 17:36:12.624655  8086 net.cpp:217] pool1 needs backward computation.
I0524 17:36:12.624660  8086 net.cpp:217] relu1_1 needs backward computation.
I0524 17:36:12.624662  8086 net.cpp:217] scale1_1 needs backward computation.
I0524 17:36:12.624665  8086 net.cpp:217] bn1_1 needs backward computation.
I0524 17:36:12.624666  8086 net.cpp:217] conv1_1 needs backward computation.
I0524 17:36:12.624670  8086 net.cpp:219] label_data_1_split does not need backward computation.
I0524 17:36:12.624672  8086 net.cpp:219] data does not need backward computation.
I0524 17:36:12.624675  8086 net.cpp:261] This network produces output accuracy
I0524 17:36:12.624677  8086 net.cpp:261] This network produces output loss
I0524 17:36:12.624701  8086 net.cpp:274] Network initialization done.
I0524 17:36:12.625684  8086 solver.cpp:181] Creating test net (#0) specified by net file: models/segnet/train_val.prototxt
I0524 17:36:12.625744  8086 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0524 17:36:12.626015  8086 net.cpp:49] Initializing net from parameters: 
name: "segnet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "DenseImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 224
    mean_value: 100
  }
  dense_image_data_param {
    source: "data/val.txt"
    batch_size: 4
    shuffle: true
    new_height: 224
    new_width: 310
    is_color: false
    root_folder: "data/raw/train/"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_1"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 14
    upsample_w: 14
  }
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5_1_D"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1_D"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 28
    upsample_w: 28
  }
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4_1_D"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1_D"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
    upsample_h: 56
    upsample_w: 56
  }
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3_1_D"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1_D"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
    upsample_h: 112
    upsample_w: 112
  }
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2_1_D"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1_D"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
    upsample_h: 224
    upsample_w: 224
  }
}
layer {
  name: "conv1_1_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "accuracy"
}
I0524 17:36:12.626183  8086 layer_factory.hpp:77] Creating layer data
I0524 17:36:12.626196  8086 net.cpp:91] Creating Layer data
I0524 17:36:12.626200  8086 net.cpp:399] data -> data
I0524 17:36:12.626209  8086 net.cpp:399] data -> label
I0524 17:36:12.626217  8086 dense_image_data_layer.cpp:38] Opening file data/val.txt
I0524 17:36:12.626731  8086 dense_image_data_layer.cpp:48] Shuffling data
I0524 17:36:12.626813  8086 dense_image_data_layer.cpp:53] A total of 705 examples.
I0524 17:36:12.632619  8086 dense_image_data_layer.cpp:92] output data size: 1,1,224,224
I0524 17:36:12.633502  8086 net.cpp:141] Setting up data
I0524 17:36:12.633515  8086 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0524 17:36:12.633519  8086 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0524 17:36:12.633522  8086 net.cpp:156] Memory required for data: 401408
I0524 17:36:12.633525  8086 layer_factory.hpp:77] Creating layer label_data_1_split
I0524 17:36:12.633533  8086 net.cpp:91] Creating Layer label_data_1_split
I0524 17:36:12.633536  8086 net.cpp:425] label_data_1_split <- label
I0524 17:36:12.633540  8086 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0524 17:36:12.633548  8086 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0524 17:36:12.633646  8086 net.cpp:141] Setting up label_data_1_split
I0524 17:36:12.633656  8086 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0524 17:36:12.633658  8086 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0524 17:36:12.633661  8086 net.cpp:156] Memory required for data: 802816
I0524 17:36:12.633664  8086 layer_factory.hpp:77] Creating layer conv1_1
I0524 17:36:12.633672  8086 net.cpp:91] Creating Layer conv1_1
I0524 17:36:12.633676  8086 net.cpp:425] conv1_1 <- data
I0524 17:36:12.633679  8086 net.cpp:399] conv1_1 -> conv1_1
I0524 17:36:12.634907  8086 net.cpp:141] Setting up conv1_1
I0524 17:36:12.634922  8086 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0524 17:36:12.634924  8086 net.cpp:156] Memory required for data: 7225344
I0524 17:36:12.634932  8086 layer_factory.hpp:77] Creating layer bn1_1
I0524 17:36:12.634938  8086 net.cpp:91] Creating Layer bn1_1
I0524 17:36:12.634941  8086 net.cpp:425] bn1_1 <- conv1_1
I0524 17:36:12.634945  8086 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0524 17:36:12.635143  8086 net.cpp:141] Setting up bn1_1
I0524 17:36:12.635152  8086 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0524 17:36:12.635155  8086 net.cpp:156] Memory required for data: 13647872
I0524 17:36:12.635164  8086 layer_factory.hpp:77] Creating layer scale1_1
I0524 17:36:12.635171  8086 net.cpp:91] Creating Layer scale1_1
I0524 17:36:12.635174  8086 net.cpp:425] scale1_1 <- conv1_1
I0524 17:36:12.635179  8086 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0524 17:36:12.635215  8086 layer_factory.hpp:77] Creating layer scale1_1
I0524 17:36:12.635712  8086 net.cpp:141] Setting up scale1_1
I0524 17:36:12.635735  8086 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0524 17:36:12.635738  8086 net.cpp:156] Memory required for data: 20070400
I0524 17:36:12.635746  8086 layer_factory.hpp:77] Creating layer relu1_1
I0524 17:36:12.635751  8086 net.cpp:91] Creating Layer relu1_1
I0524 17:36:12.635754  8086 net.cpp:425] relu1_1 <- conv1_1
I0524 17:36:12.635758  8086 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0524 17:36:12.635918  8086 net.cpp:141] Setting up relu1_1
I0524 17:36:12.635928  8086 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0524 17:36:12.635931  8086 net.cpp:156] Memory required for data: 26492928
I0524 17:36:12.635933  8086 layer_factory.hpp:77] Creating layer pool1
I0524 17:36:12.635936  8086 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0524 17:36:12.635941  8086 net.cpp:91] Creating Layer pool1
I0524 17:36:12.635943  8086 net.cpp:425] pool1 <- conv1_1
I0524 17:36:12.635947  8086 net.cpp:399] pool1 -> pool1
I0524 17:36:12.635952  8086 net.cpp:399] pool1 -> pool1_mask
I0524 17:36:12.635992  8086 net.cpp:141] Setting up pool1
I0524 17:36:12.635998  8086 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0524 17:36:12.636001  8086 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0524 17:36:12.636003  8086 net.cpp:156] Memory required for data: 29704192
I0524 17:36:12.636006  8086 layer_factory.hpp:77] Creating layer conv2_1
I0524 17:36:12.636013  8086 net.cpp:91] Creating Layer conv2_1
I0524 17:36:12.636015  8086 net.cpp:425] conv2_1 <- pool1
I0524 17:36:12.636019  8086 net.cpp:399] conv2_1 -> conv2_1
I0524 17:36:12.637367  8086 net.cpp:141] Setting up conv2_1
I0524 17:36:12.637379  8086 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0524 17:36:12.637382  8086 net.cpp:156] Memory required for data: 32915456
I0524 17:36:12.637387  8086 layer_factory.hpp:77] Creating layer bn2_1
I0524 17:36:12.637395  8086 net.cpp:91] Creating Layer bn2_1
I0524 17:36:12.637398  8086 net.cpp:425] bn2_1 <- conv2_1
I0524 17:36:12.637403  8086 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0524 17:36:12.637574  8086 net.cpp:141] Setting up bn2_1
I0524 17:36:12.637583  8086 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0524 17:36:12.637585  8086 net.cpp:156] Memory required for data: 36126720
I0524 17:36:12.637593  8086 layer_factory.hpp:77] Creating layer scale2_1
I0524 17:36:12.637599  8086 net.cpp:91] Creating Layer scale2_1
I0524 17:36:12.637601  8086 net.cpp:425] scale2_1 <- conv2_1
I0524 17:36:12.637605  8086 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0524 17:36:12.637644  8086 layer_factory.hpp:77] Creating layer scale2_1
I0524 17:36:12.637758  8086 net.cpp:141] Setting up scale2_1
I0524 17:36:12.637764  8086 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0524 17:36:12.637768  8086 net.cpp:156] Memory required for data: 39337984
I0524 17:36:12.637771  8086 layer_factory.hpp:77] Creating layer relu2_1
I0524 17:36:12.637776  8086 net.cpp:91] Creating Layer relu2_1
I0524 17:36:12.637778  8086 net.cpp:425] relu2_1 <- conv2_1
I0524 17:36:12.637783  8086 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0524 17:36:12.637933  8086 net.cpp:141] Setting up relu2_1
I0524 17:36:12.637941  8086 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0524 17:36:12.637943  8086 net.cpp:156] Memory required for data: 42549248
I0524 17:36:12.637946  8086 layer_factory.hpp:77] Creating layer pool2
I0524 17:36:12.637949  8086 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0524 17:36:12.637953  8086 net.cpp:91] Creating Layer pool2
I0524 17:36:12.637956  8086 net.cpp:425] pool2 <- conv2_1
I0524 17:36:12.637960  8086 net.cpp:399] pool2 -> pool2
I0524 17:36:12.637966  8086 net.cpp:399] pool2 -> pool2_mask
I0524 17:36:12.638005  8086 net.cpp:141] Setting up pool2
I0524 17:36:12.638011  8086 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0524 17:36:12.638015  8086 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0524 17:36:12.638017  8086 net.cpp:156] Memory required for data: 44154880
I0524 17:36:12.638020  8086 layer_factory.hpp:77] Creating layer conv3_1
I0524 17:36:12.638037  8086 net.cpp:91] Creating Layer conv3_1
I0524 17:36:12.638041  8086 net.cpp:425] conv3_1 <- pool2
I0524 17:36:12.638046  8086 net.cpp:399] conv3_1 -> conv3_1
I0524 17:36:12.641072  8086 net.cpp:141] Setting up conv3_1
I0524 17:36:12.641084  8086 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0524 17:36:12.641088  8086 net.cpp:156] Memory required for data: 45760512
I0524 17:36:12.641093  8086 layer_factory.hpp:77] Creating layer bn3_1
I0524 17:36:12.641098  8086 net.cpp:91] Creating Layer bn3_1
I0524 17:36:12.641101  8086 net.cpp:425] bn3_1 <- conv3_1
I0524 17:36:12.641105  8086 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0524 17:36:12.641266  8086 net.cpp:141] Setting up bn3_1
I0524 17:36:12.641274  8086 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0524 17:36:12.641276  8086 net.cpp:156] Memory required for data: 47366144
I0524 17:36:12.641283  8086 layer_factory.hpp:77] Creating layer scale3_1
I0524 17:36:12.641288  8086 net.cpp:91] Creating Layer scale3_1
I0524 17:36:12.641290  8086 net.cpp:425] scale3_1 <- conv3_1
I0524 17:36:12.641294  8086 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0524 17:36:12.641329  8086 layer_factory.hpp:77] Creating layer scale3_1
I0524 17:36:12.641422  8086 net.cpp:141] Setting up scale3_1
I0524 17:36:12.641428  8086 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0524 17:36:12.641430  8086 net.cpp:156] Memory required for data: 48971776
I0524 17:36:12.641438  8086 layer_factory.hpp:77] Creating layer relu3_1
I0524 17:36:12.641443  8086 net.cpp:91] Creating Layer relu3_1
I0524 17:36:12.641445  8086 net.cpp:425] relu3_1 <- conv3_1
I0524 17:36:12.641448  8086 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0524 17:36:12.641695  8086 net.cpp:141] Setting up relu3_1
I0524 17:36:12.641707  8086 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0524 17:36:12.641710  8086 net.cpp:156] Memory required for data: 50577408
I0524 17:36:12.641712  8086 layer_factory.hpp:77] Creating layer pool3
I0524 17:36:12.641716  8086 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0524 17:36:12.641722  8086 net.cpp:91] Creating Layer pool3
I0524 17:36:12.641724  8086 net.cpp:425] pool3 <- conv3_1
I0524 17:36:12.641728  8086 net.cpp:399] pool3 -> pool3
I0524 17:36:12.641734  8086 net.cpp:399] pool3 -> pool3_mask
I0524 17:36:12.641772  8086 net.cpp:141] Setting up pool3
I0524 17:36:12.641779  8086 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0524 17:36:12.641783  8086 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0524 17:36:12.641785  8086 net.cpp:156] Memory required for data: 51380224
I0524 17:36:12.641788  8086 layer_factory.hpp:77] Creating layer conv4_1
I0524 17:36:12.641794  8086 net.cpp:91] Creating Layer conv4_1
I0524 17:36:12.641798  8086 net.cpp:425] conv4_1 <- pool3
I0524 17:36:12.641801  8086 net.cpp:399] conv4_1 -> conv4_1
I0524 17:36:12.650327  8086 net.cpp:141] Setting up conv4_1
I0524 17:36:12.650341  8086 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0524 17:36:12.650343  8086 net.cpp:156] Memory required for data: 52183040
I0524 17:36:12.650347  8086 layer_factory.hpp:77] Creating layer bn4_1
I0524 17:36:12.650353  8086 net.cpp:91] Creating Layer bn4_1
I0524 17:36:12.650357  8086 net.cpp:425] bn4_1 <- conv4_1
I0524 17:36:12.650360  8086 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0524 17:36:12.650526  8086 net.cpp:141] Setting up bn4_1
I0524 17:36:12.650533  8086 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0524 17:36:12.650535  8086 net.cpp:156] Memory required for data: 52985856
I0524 17:36:12.650540  8086 layer_factory.hpp:77] Creating layer scale4_1
I0524 17:36:12.650547  8086 net.cpp:91] Creating Layer scale4_1
I0524 17:36:12.650549  8086 net.cpp:425] scale4_1 <- conv4_1
I0524 17:36:12.650552  8086 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0524 17:36:12.650588  8086 layer_factory.hpp:77] Creating layer scale4_1
I0524 17:36:12.650681  8086 net.cpp:141] Setting up scale4_1
I0524 17:36:12.650688  8086 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0524 17:36:12.650691  8086 net.cpp:156] Memory required for data: 53788672
I0524 17:36:12.650707  8086 layer_factory.hpp:77] Creating layer relu4_1
I0524 17:36:12.650712  8086 net.cpp:91] Creating Layer relu4_1
I0524 17:36:12.650715  8086 net.cpp:425] relu4_1 <- conv4_1
I0524 17:36:12.650718  8086 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0524 17:36:12.650867  8086 net.cpp:141] Setting up relu4_1
I0524 17:36:12.650876  8086 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0524 17:36:12.650879  8086 net.cpp:156] Memory required for data: 54591488
I0524 17:36:12.650882  8086 layer_factory.hpp:77] Creating layer pool4
I0524 17:36:12.650884  8086 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0524 17:36:12.650888  8086 net.cpp:91] Creating Layer pool4
I0524 17:36:12.650892  8086 net.cpp:425] pool4 <- conv4_1
I0524 17:36:12.650897  8086 net.cpp:399] pool4 -> pool4
I0524 17:36:12.650900  8086 net.cpp:399] pool4 -> pool4_mask
I0524 17:36:12.650939  8086 net.cpp:141] Setting up pool4
I0524 17:36:12.650945  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.650949  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.650950  8086 net.cpp:156] Memory required for data: 54992896
I0524 17:36:12.650954  8086 layer_factory.hpp:77] Creating layer conv5_1
I0524 17:36:12.650959  8086 net.cpp:91] Creating Layer conv5_1
I0524 17:36:12.650962  8086 net.cpp:425] conv5_1 <- pool4
I0524 17:36:12.650966  8086 net.cpp:399] conv5_1 -> conv5_1
I0524 17:36:12.666826  8086 net.cpp:141] Setting up conv5_1
I0524 17:36:12.666847  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.666851  8086 net.cpp:156] Memory required for data: 55193600
I0524 17:36:12.666856  8086 layer_factory.hpp:77] Creating layer bn5_1
I0524 17:36:12.666863  8086 net.cpp:91] Creating Layer bn5_1
I0524 17:36:12.666867  8086 net.cpp:425] bn5_1 <- conv5_1
I0524 17:36:12.666872  8086 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0524 17:36:12.667034  8086 net.cpp:141] Setting up bn5_1
I0524 17:36:12.667042  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.667044  8086 net.cpp:156] Memory required for data: 55394304
I0524 17:36:12.667050  8086 layer_factory.hpp:77] Creating layer scale5_1
I0524 17:36:12.667057  8086 net.cpp:91] Creating Layer scale5_1
I0524 17:36:12.667059  8086 net.cpp:425] scale5_1 <- conv5_1
I0524 17:36:12.667062  8086 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0524 17:36:12.667098  8086 layer_factory.hpp:77] Creating layer scale5_1
I0524 17:36:12.667186  8086 net.cpp:141] Setting up scale5_1
I0524 17:36:12.667192  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.667194  8086 net.cpp:156] Memory required for data: 55595008
I0524 17:36:12.667198  8086 layer_factory.hpp:77] Creating layer relu5_1
I0524 17:36:12.667203  8086 net.cpp:91] Creating Layer relu5_1
I0524 17:36:12.667206  8086 net.cpp:425] relu5_1 <- conv5_1
I0524 17:36:12.667209  8086 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0524 17:36:12.667362  8086 net.cpp:141] Setting up relu5_1
I0524 17:36:12.667371  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.667374  8086 net.cpp:156] Memory required for data: 55795712
I0524 17:36:12.667376  8086 layer_factory.hpp:77] Creating layer pool5
I0524 17:36:12.667379  8086 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0524 17:36:12.667383  8086 net.cpp:91] Creating Layer pool5
I0524 17:36:12.667387  8086 net.cpp:425] pool5 <- conv5_1
I0524 17:36:12.667390  8086 net.cpp:399] pool5 -> pool5
I0524 17:36:12.667395  8086 net.cpp:399] pool5 -> pool5_mask
I0524 17:36:12.667435  8086 net.cpp:141] Setting up pool5
I0524 17:36:12.667441  8086 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0524 17:36:12.667444  8086 net.cpp:148] Top shape: 1 256 7 7 (12544)
I0524 17:36:12.667446  8086 net.cpp:156] Memory required for data: 55896064
I0524 17:36:12.667449  8086 layer_factory.hpp:77] Creating layer upsample5
I0524 17:36:12.667454  8086 net.cpp:91] Creating Layer upsample5
I0524 17:36:12.667457  8086 net.cpp:425] upsample5 <- pool5
I0524 17:36:12.667459  8086 net.cpp:425] upsample5 <- pool5_mask
I0524 17:36:12.667475  8086 net.cpp:399] upsample5 -> pool5_D
I0524 17:36:12.667501  8086 net.cpp:141] Setting up upsample5
I0524 17:36:12.667505  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.667507  8086 net.cpp:156] Memory required for data: 56096768
I0524 17:36:12.667510  8086 layer_factory.hpp:77] Creating layer conv5_1_D
I0524 17:36:12.667517  8086 net.cpp:91] Creating Layer conv5_1_D
I0524 17:36:12.667520  8086 net.cpp:425] conv5_1_D <- pool5_D
I0524 17:36:12.667523  8086 net.cpp:399] conv5_1_D -> conv5_1_D
I0524 17:36:12.683393  8086 net.cpp:141] Setting up conv5_1_D
I0524 17:36:12.683409  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.683411  8086 net.cpp:156] Memory required for data: 56297472
I0524 17:36:12.683416  8086 layer_factory.hpp:77] Creating layer bn5_1_D
I0524 17:36:12.683423  8086 net.cpp:91] Creating Layer bn5_1_D
I0524 17:36:12.683426  8086 net.cpp:425] bn5_1_D <- conv5_1_D
I0524 17:36:12.683431  8086 net.cpp:386] bn5_1_D -> conv5_1_D (in-place)
I0524 17:36:12.683594  8086 net.cpp:141] Setting up bn5_1_D
I0524 17:36:12.683603  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.683604  8086 net.cpp:156] Memory required for data: 56498176
I0524 17:36:12.683616  8086 layer_factory.hpp:77] Creating layer scale5_1_D
I0524 17:36:12.683621  8086 net.cpp:91] Creating Layer scale5_1_D
I0524 17:36:12.683624  8086 net.cpp:425] scale5_1_D <- conv5_1_D
I0524 17:36:12.683627  8086 net.cpp:386] scale5_1_D -> conv5_1_D (in-place)
I0524 17:36:12.683707  8086 layer_factory.hpp:77] Creating layer scale5_1_D
I0524 17:36:12.684159  8086 net.cpp:141] Setting up scale5_1_D
I0524 17:36:12.684166  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.684168  8086 net.cpp:156] Memory required for data: 56698880
I0524 17:36:12.684173  8086 layer_factory.hpp:77] Creating layer relu5_1_D
I0524 17:36:12.684177  8086 net.cpp:91] Creating Layer relu5_1_D
I0524 17:36:12.684180  8086 net.cpp:425] relu5_1_D <- conv5_1_D
I0524 17:36:12.684183  8086 net.cpp:386] relu5_1_D -> conv5_1_D (in-place)
I0524 17:36:12.684741  8086 net.cpp:141] Setting up relu5_1_D
I0524 17:36:12.684751  8086 net.cpp:148] Top shape: 1 256 14 14 (50176)
I0524 17:36:12.684754  8086 net.cpp:156] Memory required for data: 56899584
I0524 17:36:12.684757  8086 layer_factory.hpp:77] Creating layer upsample4
I0524 17:36:12.684767  8086 net.cpp:91] Creating Layer upsample4
I0524 17:36:12.684769  8086 net.cpp:425] upsample4 <- conv5_1_D
I0524 17:36:12.684772  8086 net.cpp:425] upsample4 <- pool4_mask
I0524 17:36:12.684777  8086 net.cpp:399] upsample4 -> pool4_D
I0524 17:36:12.684806  8086 net.cpp:141] Setting up upsample4
I0524 17:36:12.684811  8086 net.cpp:148] Top shape: 1 256 28 28 (200704)
I0524 17:36:12.684814  8086 net.cpp:156] Memory required for data: 57702400
I0524 17:36:12.684816  8086 layer_factory.hpp:77] Creating layer conv4_1_D
I0524 17:36:12.684823  8086 net.cpp:91] Creating Layer conv4_1_D
I0524 17:36:12.684825  8086 net.cpp:425] conv4_1_D <- pool4_D
I0524 17:36:12.684829  8086 net.cpp:399] conv4_1_D -> conv4_1_D
I0524 17:36:12.693239  8086 net.cpp:141] Setting up conv4_1_D
I0524 17:36:12.693253  8086 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0524 17:36:12.693255  8086 net.cpp:156] Memory required for data: 58103808
I0524 17:36:12.693261  8086 layer_factory.hpp:77] Creating layer bn4_1_D
I0524 17:36:12.693269  8086 net.cpp:91] Creating Layer bn4_1_D
I0524 17:36:12.693272  8086 net.cpp:425] bn4_1_D <- conv4_1_D
I0524 17:36:12.693276  8086 net.cpp:386] bn4_1_D -> conv4_1_D (in-place)
I0524 17:36:12.693450  8086 net.cpp:141] Setting up bn4_1_D
I0524 17:36:12.693459  8086 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0524 17:36:12.693460  8086 net.cpp:156] Memory required for data: 58505216
I0524 17:36:12.693466  8086 layer_factory.hpp:77] Creating layer scale4_1_D
I0524 17:36:12.693475  8086 net.cpp:91] Creating Layer scale4_1_D
I0524 17:36:12.693476  8086 net.cpp:425] scale4_1_D <- conv4_1_D
I0524 17:36:12.693480  8086 net.cpp:386] scale4_1_D -> conv4_1_D (in-place)
I0524 17:36:12.693517  8086 layer_factory.hpp:77] Creating layer scale4_1_D
I0524 17:36:12.693632  8086 net.cpp:141] Setting up scale4_1_D
I0524 17:36:12.693640  8086 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0524 17:36:12.693644  8086 net.cpp:156] Memory required for data: 58906624
I0524 17:36:12.693647  8086 layer_factory.hpp:77] Creating layer relu4_1_D
I0524 17:36:12.693653  8086 net.cpp:91] Creating Layer relu4_1_D
I0524 17:36:12.693656  8086 net.cpp:425] relu4_1_D <- conv4_1_D
I0524 17:36:12.693660  8086 net.cpp:386] relu4_1_D -> conv4_1_D (in-place)
I0524 17:36:12.693825  8086 net.cpp:141] Setting up relu4_1_D
I0524 17:36:12.693835  8086 net.cpp:148] Top shape: 1 128 28 28 (100352)
I0524 17:36:12.693837  8086 net.cpp:156] Memory required for data: 59308032
I0524 17:36:12.693840  8086 layer_factory.hpp:77] Creating layer upsample3
I0524 17:36:12.693845  8086 net.cpp:91] Creating Layer upsample3
I0524 17:36:12.693848  8086 net.cpp:425] upsample3 <- conv4_1_D
I0524 17:36:12.693851  8086 net.cpp:425] upsample3 <- pool3_mask
I0524 17:36:12.693856  8086 net.cpp:399] upsample3 -> pool3_D
I0524 17:36:12.693886  8086 net.cpp:141] Setting up upsample3
I0524 17:36:12.693892  8086 net.cpp:148] Top shape: 1 128 56 56 (401408)
I0524 17:36:12.693894  8086 net.cpp:156] Memory required for data: 60913664
I0524 17:36:12.693897  8086 layer_factory.hpp:77] Creating layer conv3_1_D
I0524 17:36:12.693904  8086 net.cpp:91] Creating Layer conv3_1_D
I0524 17:36:12.693907  8086 net.cpp:425] conv3_1_D <- pool3_D
I0524 17:36:12.693912  8086 net.cpp:399] conv3_1_D -> conv3_1_D
I0524 17:36:12.696655  8086 net.cpp:141] Setting up conv3_1_D
I0524 17:36:12.696667  8086 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0524 17:36:12.696671  8086 net.cpp:156] Memory required for data: 61716480
I0524 17:36:12.696676  8086 layer_factory.hpp:77] Creating layer bn3_1_D
I0524 17:36:12.696682  8086 net.cpp:91] Creating Layer bn3_1_D
I0524 17:36:12.696684  8086 net.cpp:425] bn3_1_D <- conv3_1_D
I0524 17:36:12.696689  8086 net.cpp:386] bn3_1_D -> conv3_1_D (in-place)
I0524 17:36:12.696880  8086 net.cpp:141] Setting up bn3_1_D
I0524 17:36:12.696888  8086 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0524 17:36:12.696890  8086 net.cpp:156] Memory required for data: 62519296
I0524 17:36:12.696897  8086 layer_factory.hpp:77] Creating layer scale3_1_D
I0524 17:36:12.696903  8086 net.cpp:91] Creating Layer scale3_1_D
I0524 17:36:12.696905  8086 net.cpp:425] scale3_1_D <- conv3_1_D
I0524 17:36:12.696909  8086 net.cpp:386] scale3_1_D -> conv3_1_D (in-place)
I0524 17:36:12.696951  8086 layer_factory.hpp:77] Creating layer scale3_1_D
I0524 17:36:12.697065  8086 net.cpp:141] Setting up scale3_1_D
I0524 17:36:12.697073  8086 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0524 17:36:12.697075  8086 net.cpp:156] Memory required for data: 63322112
I0524 17:36:12.697080  8086 layer_factory.hpp:77] Creating layer relu3_1_D
I0524 17:36:12.697085  8086 net.cpp:91] Creating Layer relu3_1_D
I0524 17:36:12.697088  8086 net.cpp:425] relu3_1_D <- conv3_1_D
I0524 17:36:12.697093  8086 net.cpp:386] relu3_1_D -> conv3_1_D (in-place)
I0524 17:36:12.697252  8086 net.cpp:141] Setting up relu3_1_D
I0524 17:36:12.697263  8086 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0524 17:36:12.697265  8086 net.cpp:156] Memory required for data: 64124928
I0524 17:36:12.697268  8086 layer_factory.hpp:77] Creating layer upsample2
I0524 17:36:12.697274  8086 net.cpp:91] Creating Layer upsample2
I0524 17:36:12.697278  8086 net.cpp:425] upsample2 <- conv3_1_D
I0524 17:36:12.697280  8086 net.cpp:425] upsample2 <- pool2_mask
I0524 17:36:12.697284  8086 net.cpp:399] upsample2 -> pool2_D
I0524 17:36:12.697314  8086 net.cpp:141] Setting up upsample2
I0524 17:36:12.697317  8086 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0524 17:36:12.697319  8086 net.cpp:156] Memory required for data: 67336192
I0524 17:36:12.697321  8086 layer_factory.hpp:77] Creating layer conv2_1_D
I0524 17:36:12.697329  8086 net.cpp:91] Creating Layer conv2_1_D
I0524 17:36:12.697331  8086 net.cpp:425] conv2_1_D <- pool2_D
I0524 17:36:12.697336  8086 net.cpp:399] conv2_1_D -> conv2_1_D
I0524 17:36:12.698638  8086 net.cpp:141] Setting up conv2_1_D
I0524 17:36:12.698652  8086 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0524 17:36:12.698653  8086 net.cpp:156] Memory required for data: 68941824
I0524 17:36:12.698657  8086 layer_factory.hpp:77] Creating layer bn2_1_D
I0524 17:36:12.698664  8086 net.cpp:91] Creating Layer bn2_1_D
I0524 17:36:12.698668  8086 net.cpp:425] bn2_1_D <- conv2_1_D
I0524 17:36:12.698671  8086 net.cpp:386] bn2_1_D -> conv2_1_D (in-place)
I0524 17:36:12.698863  8086 net.cpp:141] Setting up bn2_1_D
I0524 17:36:12.698871  8086 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0524 17:36:12.698873  8086 net.cpp:156] Memory required for data: 70547456
I0524 17:36:12.698879  8086 layer_factory.hpp:77] Creating layer scale2_1_D
I0524 17:36:12.698884  8086 net.cpp:91] Creating Layer scale2_1_D
I0524 17:36:12.698886  8086 net.cpp:425] scale2_1_D <- conv2_1_D
I0524 17:36:12.698891  8086 net.cpp:386] scale2_1_D -> conv2_1_D (in-place)
I0524 17:36:12.698928  8086 layer_factory.hpp:77] Creating layer scale2_1_D
I0524 17:36:12.699056  8086 net.cpp:141] Setting up scale2_1_D
I0524 17:36:12.699064  8086 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0524 17:36:12.699066  8086 net.cpp:156] Memory required for data: 72153088
I0524 17:36:12.699070  8086 layer_factory.hpp:77] Creating layer relu2_1_D
I0524 17:36:12.699075  8086 net.cpp:91] Creating Layer relu2_1_D
I0524 17:36:12.699077  8086 net.cpp:425] relu2_1_D <- conv2_1_D
I0524 17:36:12.699081  8086 net.cpp:386] relu2_1_D -> conv2_1_D (in-place)
I0524 17:36:12.699348  8086 net.cpp:141] Setting up relu2_1_D
I0524 17:36:12.699359  8086 net.cpp:148] Top shape: 1 32 112 112 (401408)
I0524 17:36:12.699362  8086 net.cpp:156] Memory required for data: 73758720
I0524 17:36:12.699364  8086 layer_factory.hpp:77] Creating layer upsample1
I0524 17:36:12.699369  8086 net.cpp:91] Creating Layer upsample1
I0524 17:36:12.699373  8086 net.cpp:425] upsample1 <- conv2_1_D
I0524 17:36:12.699375  8086 net.cpp:425] upsample1 <- pool1_mask
I0524 17:36:12.699383  8086 net.cpp:399] upsample1 -> pool1_D
I0524 17:36:12.699414  8086 net.cpp:141] Setting up upsample1
I0524 17:36:12.699420  8086 net.cpp:148] Top shape: 1 32 224 224 (1605632)
I0524 17:36:12.699422  8086 net.cpp:156] Memory required for data: 80181248
I0524 17:36:12.699424  8086 layer_factory.hpp:77] Creating layer conv1_1_D
I0524 17:36:12.699432  8086 net.cpp:91] Creating Layer conv1_1_D
I0524 17:36:12.699434  8086 net.cpp:425] conv1_1_D <- pool1_D
I0524 17:36:12.699439  8086 net.cpp:399] conv1_1_D -> conv1_1_D
I0524 17:36:12.700489  8086 net.cpp:141] Setting up conv1_1_D
I0524 17:36:12.700500  8086 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0524 17:36:12.700503  8086 net.cpp:156] Memory required for data: 80582656
I0524 17:36:12.700508  8086 layer_factory.hpp:77] Creating layer conv1_1_D_conv1_1_D_0_split
I0524 17:36:12.700515  8086 net.cpp:91] Creating Layer conv1_1_D_conv1_1_D_0_split
I0524 17:36:12.700518  8086 net.cpp:425] conv1_1_D_conv1_1_D_0_split <- conv1_1_D
I0524 17:36:12.700522  8086 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_0
I0524 17:36:12.700527  8086 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_1
I0524 17:36:12.700572  8086 net.cpp:141] Setting up conv1_1_D_conv1_1_D_0_split
I0524 17:36:12.700577  8086 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0524 17:36:12.700579  8086 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0524 17:36:12.700582  8086 net.cpp:156] Memory required for data: 81385472
I0524 17:36:12.700583  8086 layer_factory.hpp:77] Creating layer loss
I0524 17:36:12.700590  8086 net.cpp:91] Creating Layer loss
I0524 17:36:12.700593  8086 net.cpp:425] loss <- conv1_1_D_conv1_1_D_0_split_0
I0524 17:36:12.700597  8086 net.cpp:425] loss <- label_data_1_split_0
I0524 17:36:12.700599  8086 net.cpp:399] loss -> loss
I0524 17:36:12.700605  8086 layer_factory.hpp:77] Creating layer loss
I0524 17:36:12.700923  8086 net.cpp:141] Setting up loss
I0524 17:36:12.700933  8086 net.cpp:148] Top shape: (1)
I0524 17:36:12.700945  8086 net.cpp:151]     with loss weight 1
I0524 17:36:12.700954  8086 net.cpp:156] Memory required for data: 81385476
I0524 17:36:12.700956  8086 layer_factory.hpp:77] Creating layer accuracy
I0524 17:36:12.700963  8086 net.cpp:91] Creating Layer accuracy
I0524 17:36:12.700964  8086 net.cpp:425] accuracy <- conv1_1_D_conv1_1_D_0_split_1
I0524 17:36:12.700968  8086 net.cpp:425] accuracy <- label_data_1_split_1
I0524 17:36:12.700973  8086 net.cpp:399] accuracy -> accuracy
I0524 17:36:12.700983  8086 net.cpp:141] Setting up accuracy
I0524 17:36:12.700987  8086 net.cpp:148] Top shape: (1)
I0524 17:36:12.700989  8086 net.cpp:156] Memory required for data: 81385480
I0524 17:36:12.700991  8086 net.cpp:219] accuracy does not need backward computation.
I0524 17:36:12.700994  8086 net.cpp:217] loss needs backward computation.
I0524 17:36:12.700997  8086 net.cpp:217] conv1_1_D_conv1_1_D_0_split needs backward computation.
I0524 17:36:12.700999  8086 net.cpp:217] conv1_1_D needs backward computation.
I0524 17:36:12.701001  8086 net.cpp:217] upsample1 needs backward computation.
I0524 17:36:12.701004  8086 net.cpp:217] relu2_1_D needs backward computation.
I0524 17:36:12.701006  8086 net.cpp:217] scale2_1_D needs backward computation.
I0524 17:36:12.701007  8086 net.cpp:217] bn2_1_D needs backward computation.
I0524 17:36:12.701009  8086 net.cpp:217] conv2_1_D needs backward computation.
I0524 17:36:12.701012  8086 net.cpp:217] upsample2 needs backward computation.
I0524 17:36:12.701014  8086 net.cpp:217] relu3_1_D needs backward computation.
I0524 17:36:12.701016  8086 net.cpp:217] scale3_1_D needs backward computation.
I0524 17:36:12.701019  8086 net.cpp:217] bn3_1_D needs backward computation.
I0524 17:36:12.701020  8086 net.cpp:217] conv3_1_D needs backward computation.
I0524 17:36:12.701022  8086 net.cpp:217] upsample3 needs backward computation.
I0524 17:36:12.701025  8086 net.cpp:217] relu4_1_D needs backward computation.
I0524 17:36:12.701027  8086 net.cpp:217] scale4_1_D needs backward computation.
I0524 17:36:12.701030  8086 net.cpp:217] bn4_1_D needs backward computation.
I0524 17:36:12.701031  8086 net.cpp:217] conv4_1_D needs backward computation.
I0524 17:36:12.701033  8086 net.cpp:217] upsample4 needs backward computation.
I0524 17:36:12.701036  8086 net.cpp:217] relu5_1_D needs backward computation.
I0524 17:36:12.701038  8086 net.cpp:217] scale5_1_D needs backward computation.
I0524 17:36:12.701041  8086 net.cpp:217] bn5_1_D needs backward computation.
I0524 17:36:12.701043  8086 net.cpp:217] conv5_1_D needs backward computation.
I0524 17:36:12.701045  8086 net.cpp:217] upsample5 needs backward computation.
I0524 17:36:12.701048  8086 net.cpp:217] pool5 needs backward computation.
I0524 17:36:12.701051  8086 net.cpp:217] relu5_1 needs backward computation.
I0524 17:36:12.701053  8086 net.cpp:217] scale5_1 needs backward computation.
I0524 17:36:12.701056  8086 net.cpp:217] bn5_1 needs backward computation.
I0524 17:36:12.701057  8086 net.cpp:217] conv5_1 needs backward computation.
I0524 17:36:12.701061  8086 net.cpp:217] pool4 needs backward computation.
I0524 17:36:12.701062  8086 net.cpp:217] relu4_1 needs backward computation.
I0524 17:36:12.701064  8086 net.cpp:217] scale4_1 needs backward computation.
I0524 17:36:12.701067  8086 net.cpp:217] bn4_1 needs backward computation.
I0524 17:36:12.701069  8086 net.cpp:217] conv4_1 needs backward computation.
I0524 17:36:12.701071  8086 net.cpp:217] pool3 needs backward computation.
I0524 17:36:12.701073  8086 net.cpp:217] relu3_1 needs backward computation.
I0524 17:36:12.701076  8086 net.cpp:217] scale3_1 needs backward computation.
I0524 17:36:12.701078  8086 net.cpp:217] bn3_1 needs backward computation.
I0524 17:36:12.701081  8086 net.cpp:217] conv3_1 needs backward computation.
I0524 17:36:12.701082  8086 net.cpp:217] pool2 needs backward computation.
I0524 17:36:12.701084  8086 net.cpp:217] relu2_1 needs backward computation.
I0524 17:36:12.701087  8086 net.cpp:217] scale2_1 needs backward computation.
I0524 17:36:12.701089  8086 net.cpp:217] bn2_1 needs backward computation.
I0524 17:36:12.701097  8086 net.cpp:217] conv2_1 needs backward computation.
I0524 17:36:12.701100  8086 net.cpp:217] pool1 needs backward computation.
I0524 17:36:12.701102  8086 net.cpp:217] relu1_1 needs backward computation.
I0524 17:36:12.701105  8086 net.cpp:217] scale1_1 needs backward computation.
I0524 17:36:12.701107  8086 net.cpp:217] bn1_1 needs backward computation.
I0524 17:36:12.701109  8086 net.cpp:217] conv1_1 needs backward computation.
I0524 17:36:12.701112  8086 net.cpp:219] label_data_1_split does not need backward computation.
I0524 17:36:12.701115  8086 net.cpp:219] data does not need backward computation.
I0524 17:36:12.701117  8086 net.cpp:261] This network produces output accuracy
I0524 17:36:12.701119  8086 net.cpp:261] This network produces output loss
I0524 17:36:12.701143  8086 net.cpp:274] Network initialization done.
I0524 17:36:12.701282  8086 solver.cpp:60] Solver scaffolding done.
I0524 17:36:12.702973  8086 caffe.cpp:219] Starting Optimization
I0524 17:36:12.702980  8086 solver.cpp:279] Solving segnet
I0524 17:36:12.702983  8086 solver.cpp:280] Learning Rate Policy: step
I0524 17:36:12.704452  8086 solver.cpp:337] Iteration 0, Testing net (#0)
I0524 17:36:13.267525  8086 solver.cpp:404]     Test net output #0: accuracy = 0.589411
I0524 17:36:13.267554  8086 solver.cpp:404]     Test net output #1: loss = 0.682898 (* 1 = 0.682898 loss)
I0524 17:36:13.666815  8086 solver.cpp:228] Iteration 0, loss = 0.683464
I0524 17:36:13.666837  8086 solver.cpp:244]     Train net output #0: accuracy = 0.588645
I0524 17:36:13.666844  8086 solver.cpp:244]     Train net output #1: loss = 0.683464 (* 1 = 0.683464 loss)
I0524 17:36:13.666857  8086 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0524 17:36:21.271813  8086 solver.cpp:228] Iteration 20, loss = 0.126551
I0524 17:36:21.271848  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987155
I0524 17:36:21.271855  8086 solver.cpp:244]     Train net output #1: loss = 0.126551 (* 1 = 0.126551 loss)
I0524 17:36:21.271862  8086 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0524 17:36:29.090575  8086 solver.cpp:228] Iteration 40, loss = 0.0886901
I0524 17:36:29.090611  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986318
I0524 17:36:29.090618  8086 solver.cpp:244]     Train net output #1: loss = 0.0886901 (* 1 = 0.0886901 loss)
I0524 17:36:29.090623  8086 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0524 17:36:36.904642  8086 solver.cpp:228] Iteration 60, loss = 0.0770833
I0524 17:36:36.904664  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987895
I0524 17:36:36.904682  8086 solver.cpp:244]     Train net output #1: loss = 0.0770833 (* 1 = 0.0770833 loss)
I0524 17:36:36.904687  8086 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0524 17:36:44.623548  8086 solver.cpp:228] Iteration 80, loss = 0.0859794
I0524 17:36:44.623600  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985099
I0524 17:36:44.623610  8086 solver.cpp:244]     Train net output #1: loss = 0.0859794 (* 1 = 0.0859794 loss)
I0524 17:36:44.623613  8086 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0524 17:36:52.122722  8086 solver.cpp:337] Iteration 100, Testing net (#0)
I0524 17:36:52.633430  8086 solver.cpp:404]     Test net output #0: accuracy = 0.979232
I0524 17:36:52.633465  8086 solver.cpp:404]     Test net output #1: loss = 0.109346 (* 1 = 0.109346 loss)
I0524 17:36:52.860342  8086 solver.cpp:228] Iteration 100, loss = 0.100886
I0524 17:36:52.860364  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98139
I0524 17:36:52.860371  8086 solver.cpp:244]     Train net output #1: loss = 0.100886 (* 1 = 0.100886 loss)
I0524 17:36:52.860376  8086 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0524 17:37:00.600556  8086 solver.cpp:228] Iteration 120, loss = 0.112777
I0524 17:37:00.600591  8086 solver.cpp:244]     Train net output #0: accuracy = 0.9781
I0524 17:37:00.600599  8086 solver.cpp:244]     Train net output #1: loss = 0.112777 (* 1 = 0.112777 loss)
I0524 17:37:00.600602  8086 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0524 17:37:08.357125  8086 solver.cpp:228] Iteration 140, loss = 0.109484
I0524 17:37:08.357159  8086 solver.cpp:244]     Train net output #0: accuracy = 0.97876
I0524 17:37:08.357167  8086 solver.cpp:244]     Train net output #1: loss = 0.109484 (* 1 = 0.109484 loss)
I0524 17:37:08.357170  8086 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0524 17:37:16.099514  8086 solver.cpp:228] Iteration 160, loss = 0.0924685
I0524 17:37:16.099627  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982498
I0524 17:37:16.099637  8086 solver.cpp:244]     Train net output #1: loss = 0.0924685 (* 1 = 0.0924685 loss)
I0524 17:37:16.099642  8086 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0524 17:37:23.822326  8086 solver.cpp:228] Iteration 180, loss = 0.076047
I0524 17:37:23.822360  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98646
I0524 17:37:23.822367  8086 solver.cpp:244]     Train net output #1: loss = 0.076047 (* 1 = 0.076047 loss)
I0524 17:37:23.822372  8086 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0524 17:37:31.332564  8086 solver.cpp:337] Iteration 200, Testing net (#0)
I0524 17:37:31.843883  8086 solver.cpp:404]     Test net output #0: accuracy = 0.980249
I0524 17:37:31.843919  8086 solver.cpp:404]     Test net output #1: loss = 0.100261 (* 1 = 0.100261 loss)
I0524 17:37:32.072129  8086 solver.cpp:228] Iteration 200, loss = 0.0948229
I0524 17:37:32.072159  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981869
I0524 17:37:32.072165  8086 solver.cpp:244]     Train net output #1: loss = 0.0948229 (* 1 = 0.0948229 loss)
I0524 17:37:32.072170  8086 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0524 17:37:39.815973  8086 solver.cpp:228] Iteration 220, loss = 0.0866617
I0524 17:37:39.816007  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983533
I0524 17:37:39.816015  8086 solver.cpp:244]     Train net output #1: loss = 0.0866617 (* 1 = 0.0866617 loss)
I0524 17:37:39.816023  8086 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0524 17:37:47.554853  8086 solver.cpp:228] Iteration 240, loss = 0.0766274
I0524 17:37:47.554955  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98583
I0524 17:37:47.554963  8086 solver.cpp:244]     Train net output #1: loss = 0.0766274 (* 1 = 0.0766274 loss)
I0524 17:37:47.554967  8086 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0524 17:37:55.300786  8086 solver.cpp:228] Iteration 260, loss = 0.0876825
I0524 17:37:55.300811  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983154
I0524 17:37:55.300817  8086 solver.cpp:244]     Train net output #1: loss = 0.0876825 (* 1 = 0.0876825 loss)
I0524 17:37:55.300822  8086 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0524 17:38:03.037122  8086 solver.cpp:228] Iteration 280, loss = 0.085397
I0524 17:38:03.037155  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983262
I0524 17:38:03.037163  8086 solver.cpp:244]     Train net output #1: loss = 0.085397 (* 1 = 0.085397 loss)
I0524 17:38:03.037168  8086 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0524 17:38:10.608695  8086 solver.cpp:337] Iteration 300, Testing net (#0)
I0524 17:38:11.126111  8086 solver.cpp:404]     Test net output #0: accuracy = 0.983709
I0524 17:38:11.126135  8086 solver.cpp:404]     Test net output #1: loss = 0.0832971 (* 1 = 0.0832971 loss)
I0524 17:38:11.355049  8086 solver.cpp:228] Iteration 300, loss = 0.0749144
I0524 17:38:11.355082  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985578
I0524 17:38:11.355089  8086 solver.cpp:244]     Train net output #1: loss = 0.0749144 (* 1 = 0.0749144 loss)
I0524 17:38:11.355094  8086 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0524 17:38:19.178297  8086 solver.cpp:228] Iteration 320, loss = 0.0965347
I0524 17:38:19.178386  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979824
I0524 17:38:19.178395  8086 solver.cpp:244]     Train net output #1: loss = 0.0965347 (* 1 = 0.0965347 loss)
I0524 17:38:19.178400  8086 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0524 17:38:27.024812  8086 solver.cpp:228] Iteration 340, loss = 0.0657865
I0524 17:38:27.024848  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987657
I0524 17:38:27.024855  8086 solver.cpp:244]     Train net output #1: loss = 0.0657865 (* 1 = 0.0657865 loss)
I0524 17:38:27.024860  8086 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0524 17:38:34.769023  8086 solver.cpp:228] Iteration 360, loss = 0.114129
I0524 17:38:34.769048  8086 solver.cpp:244]     Train net output #0: accuracy = 0.974778
I0524 17:38:34.769055  8086 solver.cpp:244]     Train net output #1: loss = 0.114129 (* 1 = 0.114129 loss)
I0524 17:38:34.769060  8086 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0524 17:38:42.583308  8086 solver.cpp:228] Iteration 380, loss = 0.0838249
I0524 17:38:42.583335  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982884
I0524 17:38:42.583343  8086 solver.cpp:244]     Train net output #1: loss = 0.0838249 (* 1 = 0.0838249 loss)
I0524 17:38:42.583348  8086 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0524 17:38:50.334147  8086 solver.cpp:337] Iteration 400, Testing net (#0)
I0524 17:38:50.863307  8086 solver.cpp:404]     Test net output #0: accuracy = 0.986211
I0524 17:38:50.863335  8086 solver.cpp:404]     Test net output #1: loss = 0.0699557 (* 1 = 0.0699557 loss)
I0524 17:38:51.098477  8086 solver.cpp:228] Iteration 400, loss = 0.100138
I0524 17:38:51.098500  8086 solver.cpp:244]     Train net output #0: accuracy = 0.978062
I0524 17:38:51.098507  8086 solver.cpp:244]     Train net output #1: loss = 0.100138 (* 1 = 0.100138 loss)
I0524 17:38:51.098513  8086 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0524 17:38:58.981663  8086 solver.cpp:228] Iteration 420, loss = 0.0921311
I0524 17:38:58.981686  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980088
I0524 17:38:58.981693  8086 solver.cpp:244]     Train net output #1: loss = 0.0921311 (* 1 = 0.0921311 loss)
I0524 17:38:58.981698  8086 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0524 17:39:06.865509  8086 solver.cpp:228] Iteration 440, loss = 0.0704584
I0524 17:39:06.865532  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985834
I0524 17:39:06.865540  8086 solver.cpp:244]     Train net output #1: loss = 0.0704584 (* 1 = 0.0704584 loss)
I0524 17:39:06.865543  8086 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0524 17:39:14.658190  8086 solver.cpp:228] Iteration 460, loss = 0.0880665
I0524 17:39:14.658213  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980704
I0524 17:39:14.658231  8086 solver.cpp:244]     Train net output #1: loss = 0.0880665 (* 1 = 0.0880665 loss)
I0524 17:39:14.658236  8086 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0524 17:39:22.405124  8086 solver.cpp:228] Iteration 480, loss = 0.0678548
I0524 17:39:22.405211  8086 solver.cpp:244]     Train net output #0: accuracy = 0.9862
I0524 17:39:22.405220  8086 solver.cpp:244]     Train net output #1: loss = 0.0678548 (* 1 = 0.0678548 loss)
I0524 17:39:22.405225  8086 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0524 17:39:29.976491  8086 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_500.caffemodel
I0524 17:39:30.000411  8086 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_500.solverstate
I0524 17:39:30.009219  8086 solver.cpp:337] Iteration 500, Testing net (#0)
I0524 17:39:30.171550  8086 blocking_queue.cpp:50] Data layer prefetch queue empty
I0524 17:39:30.533079  8086 solver.cpp:404]     Test net output #0: accuracy = 0.985621
I0524 17:39:30.533108  8086 solver.cpp:404]     Test net output #1: loss = 0.0683931 (* 1 = 0.0683931 loss)
I0524 17:39:30.765414  8086 solver.cpp:228] Iteration 500, loss = 0.0887436
I0524 17:39:30.765447  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980323
I0524 17:39:30.765455  8086 solver.cpp:244]     Train net output #1: loss = 0.0887436 (* 1 = 0.0887436 loss)
I0524 17:39:30.765460  8086 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0524 17:39:38.545137  8086 solver.cpp:228] Iteration 520, loss = 0.0716805
I0524 17:39:38.545161  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984614
I0524 17:39:38.545167  8086 solver.cpp:244]     Train net output #1: loss = 0.0716805 (* 1 = 0.0716805 loss)
I0524 17:39:38.545172  8086 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0524 17:39:46.290300  8086 solver.cpp:228] Iteration 540, loss = 0.0758505
I0524 17:39:46.290335  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983564
I0524 17:39:46.290343  8086 solver.cpp:244]     Train net output #1: loss = 0.0758505 (* 1 = 0.0758505 loss)
I0524 17:39:46.290347  8086 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0524 17:39:54.031842  8086 solver.cpp:228] Iteration 560, loss = 0.0821834
I0524 17:39:54.031965  8086 solver.cpp:244]     Train net output #0: accuracy = 0.9813
I0524 17:39:54.031975  8086 solver.cpp:244]     Train net output #1: loss = 0.0821834 (* 1 = 0.0821834 loss)
I0524 17:39:54.031980  8086 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0524 17:40:01.774924  8086 solver.cpp:228] Iteration 580, loss = 0.0699612
I0524 17:40:01.774958  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984012
I0524 17:40:01.774966  8086 solver.cpp:244]     Train net output #1: loss = 0.0699612 (* 1 = 0.0699612 loss)
I0524 17:40:01.774971  8086 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0524 17:40:09.289399  8086 solver.cpp:337] Iteration 600, Testing net (#0)
I0524 17:40:09.801288  8086 solver.cpp:404]     Test net output #0: accuracy = 0.980566
I0524 17:40:09.801322  8086 solver.cpp:404]     Test net output #1: loss = 0.0823354 (* 1 = 0.0823354 loss)
I0524 17:40:10.029538  8086 solver.cpp:228] Iteration 600, loss = 0.0646067
I0524 17:40:10.029562  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986068
I0524 17:40:10.029569  8086 solver.cpp:244]     Train net output #1: loss = 0.0646067 (* 1 = 0.0646067 loss)
I0524 17:40:10.029574  8086 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0524 17:40:17.777550  8086 solver.cpp:228] Iteration 620, loss = 0.0588346
I0524 17:40:17.777575  8086 solver.cpp:244]     Train net output #0: accuracy = 0.988143
I0524 17:40:17.777582  8086 solver.cpp:244]     Train net output #1: loss = 0.0588346 (* 1 = 0.0588346 loss)
I0524 17:40:17.777587  8086 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0524 17:40:25.519201  8086 solver.cpp:228] Iteration 640, loss = 0.0712215
I0524 17:40:25.519302  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984326
I0524 17:40:25.519311  8086 solver.cpp:244]     Train net output #1: loss = 0.0712215 (* 1 = 0.0712215 loss)
I0524 17:40:25.519316  8086 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0524 17:40:33.265938  8086 solver.cpp:228] Iteration 660, loss = 0.0758617
I0524 17:40:33.265972  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980954
I0524 17:40:33.265980  8086 solver.cpp:244]     Train net output #1: loss = 0.0758617 (* 1 = 0.0758617 loss)
I0524 17:40:33.265985  8086 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0524 17:40:41.015277  8086 solver.cpp:228] Iteration 680, loss = 0.0627612
I0524 17:40:41.015311  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986357
I0524 17:40:41.015318  8086 solver.cpp:244]     Train net output #1: loss = 0.0627612 (* 1 = 0.0627612 loss)
I0524 17:40:41.015327  8086 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0524 17:40:48.535493  8086 solver.cpp:337] Iteration 700, Testing net (#0)
I0524 17:40:49.046630  8086 solver.cpp:404]     Test net output #0: accuracy = 0.986166
I0524 17:40:49.046664  8086 solver.cpp:404]     Test net output #1: loss = 0.0601467 (* 1 = 0.0601467 loss)
I0524 17:40:49.275152  8086 solver.cpp:228] Iteration 700, loss = 0.0640585
I0524 17:40:49.275187  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985269
I0524 17:40:49.275193  8086 solver.cpp:244]     Train net output #1: loss = 0.0640585 (* 1 = 0.0640585 loss)
I0524 17:40:49.275198  8086 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0524 17:40:57.025240  8086 solver.cpp:228] Iteration 720, loss = 0.0648869
I0524 17:40:57.025331  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984292
I0524 17:40:57.025339  8086 solver.cpp:244]     Train net output #1: loss = 0.0648869 (* 1 = 0.0648869 loss)
I0524 17:40:57.025344  8086 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0524 17:41:04.768013  8086 solver.cpp:228] Iteration 740, loss = 0.0830615
I0524 17:41:04.768049  8086 solver.cpp:244]     Train net output #0: accuracy = 0.978765
I0524 17:41:04.768055  8086 solver.cpp:244]     Train net output #1: loss = 0.0830615 (* 1 = 0.0830615 loss)
I0524 17:41:04.768060  8086 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0524 17:41:12.532845  8086 solver.cpp:228] Iteration 760, loss = 0.072828
I0524 17:41:12.532879  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98143
I0524 17:41:12.532887  8086 solver.cpp:244]     Train net output #1: loss = 0.072828 (* 1 = 0.072828 loss)
I0524 17:41:12.532891  8086 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0524 17:41:20.284848  8086 solver.cpp:228] Iteration 780, loss = 0.0540659
I0524 17:41:20.284883  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987246
I0524 17:41:20.284889  8086 solver.cpp:244]     Train net output #1: loss = 0.0540659 (* 1 = 0.0540659 loss)
I0524 17:41:20.284894  8086 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0524 17:41:27.819299  8086 solver.cpp:337] Iteration 800, Testing net (#0)
I0524 17:41:28.331818  8086 solver.cpp:404]     Test net output #0: accuracy = 0.984023
I0524 17:41:28.331841  8086 solver.cpp:404]     Test net output #1: loss = 0.0638579 (* 1 = 0.0638579 loss)
I0524 17:41:28.560979  8086 solver.cpp:228] Iteration 800, loss = 0.0789248
I0524 17:41:28.561002  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979501
I0524 17:41:28.561009  8086 solver.cpp:244]     Train net output #1: loss = 0.0789248 (* 1 = 0.0789248 loss)
I0524 17:41:28.561013  8086 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0524 17:41:36.326189  8086 solver.cpp:228] Iteration 820, loss = 0.0709911
I0524 17:41:36.326213  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981515
I0524 17:41:36.326220  8086 solver.cpp:244]     Train net output #1: loss = 0.0709911 (* 1 = 0.0709911 loss)
I0524 17:41:36.326225  8086 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0524 17:41:44.316228  8086 solver.cpp:228] Iteration 840, loss = 0.0679414
I0524 17:41:44.316262  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982929
I0524 17:41:44.316269  8086 solver.cpp:244]     Train net output #1: loss = 0.0679414 (* 1 = 0.0679414 loss)
I0524 17:41:44.316274  8086 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0524 17:41:52.154233  8086 solver.cpp:228] Iteration 860, loss = 0.0651188
I0524 17:41:52.154258  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983052
I0524 17:41:52.154264  8086 solver.cpp:244]     Train net output #1: loss = 0.0651188 (* 1 = 0.0651188 loss)
I0524 17:41:52.154269  8086 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0524 17:41:59.894831  8086 solver.cpp:228] Iteration 880, loss = 0.0693164
I0524 17:41:59.894938  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980799
I0524 17:41:59.894948  8086 solver.cpp:244]     Train net output #1: loss = 0.0693164 (* 1 = 0.0693164 loss)
I0524 17:41:59.894953  8086 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0524 17:42:07.425709  8086 solver.cpp:337] Iteration 900, Testing net (#0)
I0524 17:42:07.945633  8086 solver.cpp:404]     Test net output #0: accuracy = 0.983843
I0524 17:42:07.945667  8086 solver.cpp:404]     Test net output #1: loss = 0.0610839 (* 1 = 0.0610839 loss)
I0524 17:42:08.177577  8086 solver.cpp:228] Iteration 900, loss = 0.0485169
I0524 17:42:08.177599  8086 solver.cpp:244]     Train net output #0: accuracy = 0.988487
I0524 17:42:08.177606  8086 solver.cpp:244]     Train net output #1: loss = 0.0485169 (* 1 = 0.0485169 loss)
I0524 17:42:08.177611  8086 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0524 17:42:16.010438  8086 solver.cpp:228] Iteration 920, loss = 0.0437424
I0524 17:42:16.010474  8086 solver.cpp:244]     Train net output #0: accuracy = 0.99053
I0524 17:42:16.010481  8086 solver.cpp:244]     Train net output #1: loss = 0.0437424 (* 1 = 0.0437424 loss)
I0524 17:42:16.010486  8086 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0524 17:42:23.865744  8086 solver.cpp:228] Iteration 940, loss = 0.0753455
I0524 17:42:23.865779  8086 solver.cpp:244]     Train net output #0: accuracy = 0.97854
I0524 17:42:23.865787  8086 solver.cpp:244]     Train net output #1: loss = 0.0753455 (* 1 = 0.0753455 loss)
I0524 17:42:23.865792  8086 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0524 17:42:31.603063  8086 solver.cpp:228] Iteration 960, loss = 0.0645139
I0524 17:42:31.603169  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98342
I0524 17:42:31.603179  8086 solver.cpp:244]     Train net output #1: loss = 0.0645139 (* 1 = 0.0645139 loss)
I0524 17:42:31.603184  8086 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0524 17:42:39.342294  8086 solver.cpp:228] Iteration 980, loss = 0.0634376
I0524 17:42:39.342317  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983099
I0524 17:42:39.342325  8086 solver.cpp:244]     Train net output #1: loss = 0.0634376 (* 1 = 0.0634376 loss)
I0524 17:42:39.342330  8086 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0524 17:42:46.855232  8086 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_1000.caffemodel
I0524 17:42:46.873558  8086 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_1000.solverstate
I0524 17:42:46.882128  8086 solver.cpp:337] Iteration 1000, Testing net (#0)
I0524 17:42:47.401182  8086 solver.cpp:404]     Test net output #0: accuracy = 0.982226
I0524 17:42:47.401218  8086 solver.cpp:404]     Test net output #1: loss = 0.0682938 (* 1 = 0.0682938 loss)
I0524 17:42:47.629346  8086 solver.cpp:228] Iteration 1000, loss = 0.0532658
I0524 17:42:47.629381  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987299
I0524 17:42:47.629389  8086 solver.cpp:244]     Train net output #1: loss = 0.0532658 (* 1 = 0.0532658 loss)
I0524 17:42:47.629393  8086 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0524 17:42:55.368484  8086 solver.cpp:228] Iteration 1020, loss = 0.0502313
I0524 17:42:55.368508  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986419
I0524 17:42:55.368515  8086 solver.cpp:244]     Train net output #1: loss = 0.0502313 (* 1 = 0.0502313 loss)
I0524 17:42:55.368520  8086 sgd_solver.cpp:106] Iteration 1020, lr = 0.01
I0524 17:43:03.110108  8086 solver.cpp:228] Iteration 1040, loss = 0.0686466
I0524 17:43:03.110214  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980718
I0524 17:43:03.110224  8086 solver.cpp:244]     Train net output #1: loss = 0.0686466 (* 1 = 0.0686466 loss)
I0524 17:43:03.110229  8086 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I0524 17:43:10.842782  8086 solver.cpp:228] Iteration 1060, loss = 0.0768017
I0524 17:43:10.842806  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979175
I0524 17:43:10.842824  8086 solver.cpp:244]     Train net output #1: loss = 0.0768017 (* 1 = 0.0768017 loss)
I0524 17:43:10.842829  8086 sgd_solver.cpp:106] Iteration 1060, lr = 0.01
I0524 17:43:18.585304  8086 solver.cpp:228] Iteration 1080, loss = 0.0594549
I0524 17:43:18.585338  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984646
I0524 17:43:18.585345  8086 solver.cpp:244]     Train net output #1: loss = 0.0594549 (* 1 = 0.0594549 loss)
I0524 17:43:18.585350  8086 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I0524 17:43:26.094740  8086 solver.cpp:337] Iteration 1100, Testing net (#0)
I0524 17:43:26.605186  8086 solver.cpp:404]     Test net output #0: accuracy = 0.980962
I0524 17:43:26.605221  8086 solver.cpp:404]     Test net output #1: loss = 0.0656199 (* 1 = 0.0656199 loss)
I0524 17:43:26.833338  8086 solver.cpp:228] Iteration 1100, loss = 0.069866
I0524 17:43:26.833372  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979409
I0524 17:43:26.833379  8086 solver.cpp:244]     Train net output #1: loss = 0.069866 (* 1 = 0.069866 loss)
I0524 17:43:26.833384  8086 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0524 17:43:34.570976  8086 solver.cpp:228] Iteration 1120, loss = 0.0755924
I0524 17:43:34.571095  8086 solver.cpp:244]     Train net output #0: accuracy = 0.97628
I0524 17:43:34.571105  8086 solver.cpp:244]     Train net output #1: loss = 0.0755924 (* 1 = 0.0755924 loss)
I0524 17:43:34.571110  8086 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I0524 17:43:42.312520  8086 solver.cpp:228] Iteration 1140, loss = 0.0603368
I0524 17:43:42.312543  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982342
I0524 17:43:42.312551  8086 solver.cpp:244]     Train net output #1: loss = 0.0603368 (* 1 = 0.0603368 loss)
I0524 17:43:42.312556  8086 sgd_solver.cpp:106] Iteration 1140, lr = 0.01
I0524 17:43:50.051889  8086 solver.cpp:228] Iteration 1160, loss = 0.037281
I0524 17:43:50.051925  8086 solver.cpp:244]     Train net output #0: accuracy = 0.990722
I0524 17:43:50.051933  8086 solver.cpp:244]     Train net output #1: loss = 0.037281 (* 1 = 0.037281 loss)
I0524 17:43:50.051937  8086 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I0524 17:43:57.791594  8086 solver.cpp:228] Iteration 1180, loss = 0.0772148
I0524 17:43:57.791618  8086 solver.cpp:244]     Train net output #0: accuracy = 0.976949
I0524 17:43:57.791625  8086 solver.cpp:244]     Train net output #1: loss = 0.0772148 (* 1 = 0.0772148 loss)
I0524 17:43:57.791630  8086 sgd_solver.cpp:106] Iteration 1180, lr = 0.01
I0524 17:44:05.308213  8086 solver.cpp:337] Iteration 1200, Testing net (#0)
I0524 17:44:05.820726  8086 solver.cpp:404]     Test net output #0: accuracy = 0.981986
I0524 17:44:05.820761  8086 solver.cpp:404]     Test net output #1: loss = 0.0596912 (* 1 = 0.0596912 loss)
I0524 17:44:06.048995  8086 solver.cpp:228] Iteration 1200, loss = 0.0692201
I0524 17:44:06.049028  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979486
I0524 17:44:06.049036  8086 solver.cpp:244]     Train net output #1: loss = 0.0692201 (* 1 = 0.0692201 loss)
I0524 17:44:06.049039  8086 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0524 17:44:13.794497  8086 solver.cpp:228] Iteration 1220, loss = 0.0668404
I0524 17:44:13.794522  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98021
I0524 17:44:13.794528  8086 solver.cpp:244]     Train net output #1: loss = 0.0668404 (* 1 = 0.0668404 loss)
I0524 17:44:13.794533  8086 sgd_solver.cpp:106] Iteration 1220, lr = 0.01
I0524 17:44:21.538969  8086 solver.cpp:228] Iteration 1240, loss = 0.0644691
I0524 17:44:21.539005  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980241
I0524 17:44:21.539011  8086 solver.cpp:244]     Train net output #1: loss = 0.0644691 (* 1 = 0.0644691 loss)
I0524 17:44:21.539016  8086 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I0524 17:44:29.290817  8086 solver.cpp:228] Iteration 1260, loss = 0.0433016
I0524 17:44:29.290841  8086 solver.cpp:244]     Train net output #0: accuracy = 0.988857
I0524 17:44:29.290848  8086 solver.cpp:244]     Train net output #1: loss = 0.0433016 (* 1 = 0.0433016 loss)
I0524 17:44:29.290854  8086 sgd_solver.cpp:106] Iteration 1260, lr = 0.01
I0524 17:44:37.042779  8086 solver.cpp:228] Iteration 1280, loss = 0.0623636
I0524 17:44:37.042865  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980768
I0524 17:44:37.042873  8086 solver.cpp:244]     Train net output #1: loss = 0.0623636 (* 1 = 0.0623636 loss)
I0524 17:44:37.042877  8086 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I0524 17:44:44.567006  8086 solver.cpp:337] Iteration 1300, Testing net (#0)
I0524 17:44:45.078155  8086 solver.cpp:404]     Test net output #0: accuracy = 0.984195
I0524 17:44:45.078189  8086 solver.cpp:404]     Test net output #1: loss = 0.0555833 (* 1 = 0.0555833 loss)
I0524 17:44:45.306306  8086 solver.cpp:228] Iteration 1300, loss = 0.0664299
I0524 17:44:45.306340  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979984
I0524 17:44:45.306349  8086 solver.cpp:244]     Train net output #1: loss = 0.0664299 (* 1 = 0.0664299 loss)
I0524 17:44:45.306352  8086 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0524 17:44:53.046345  8086 solver.cpp:228] Iteration 1320, loss = 0.0602274
I0524 17:44:53.046371  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981759
I0524 17:44:53.046378  8086 solver.cpp:244]     Train net output #1: loss = 0.0602274 (* 1 = 0.0602274 loss)
I0524 17:44:53.046383  8086 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I0524 17:45:00.794389  8086 solver.cpp:228] Iteration 1340, loss = 0.0645737
I0524 17:45:00.794414  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980122
I0524 17:45:00.794420  8086 solver.cpp:244]     Train net output #1: loss = 0.0645737 (* 1 = 0.0645737 loss)
I0524 17:45:00.794425  8086 sgd_solver.cpp:106] Iteration 1340, lr = 0.01
I0524 17:45:08.538805  8086 solver.cpp:228] Iteration 1360, loss = 0.060699
I0524 17:45:08.538926  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981275
I0524 17:45:08.538936  8086 solver.cpp:244]     Train net output #1: loss = 0.060699 (* 1 = 0.060699 loss)
I0524 17:45:08.538941  8086 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I0524 17:45:16.278072  8086 solver.cpp:228] Iteration 1380, loss = 0.0488991
I0524 17:45:16.278106  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987386
I0524 17:45:16.278113  8086 solver.cpp:244]     Train net output #1: loss = 0.0488991 (* 1 = 0.0488991 loss)
I0524 17:45:16.278118  8086 sgd_solver.cpp:106] Iteration 1380, lr = 0.01
I0524 17:45:23.793437  8086 solver.cpp:337] Iteration 1400, Testing net (#0)
I0524 17:45:24.304436  8086 solver.cpp:404]     Test net output #0: accuracy = 0.984649
I0524 17:45:24.304462  8086 solver.cpp:404]     Test net output #1: loss = 0.0535497 (* 1 = 0.0535497 loss)
I0524 17:45:24.532846  8086 solver.cpp:228] Iteration 1400, loss = 0.0702933
I0524 17:45:24.532881  8086 solver.cpp:244]     Train net output #0: accuracy = 0.978262
I0524 17:45:24.532889  8086 solver.cpp:244]     Train net output #1: loss = 0.0702933 (* 1 = 0.0702933 loss)
I0524 17:45:24.532893  8086 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0524 17:45:32.270371  8086 solver.cpp:228] Iteration 1420, loss = 0.0540214
I0524 17:45:32.270407  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983001
I0524 17:45:32.270416  8086 solver.cpp:244]     Train net output #1: loss = 0.0540214 (* 1 = 0.0540214 loss)
I0524 17:45:32.270421  8086 sgd_solver.cpp:106] Iteration 1420, lr = 0.01
I0524 17:45:40.013213  8086 solver.cpp:228] Iteration 1440, loss = 0.0588227
I0524 17:45:40.013317  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98252
I0524 17:45:40.013329  8086 solver.cpp:244]     Train net output #1: loss = 0.0588227 (* 1 = 0.0588227 loss)
I0524 17:45:40.013334  8086 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I0524 17:45:47.752116  8086 solver.cpp:228] Iteration 1460, loss = 0.0642572
I0524 17:45:47.752140  8086 solver.cpp:244]     Train net output #0: accuracy = 0.978991
I0524 17:45:47.752146  8086 solver.cpp:244]     Train net output #1: loss = 0.0642572 (* 1 = 0.0642572 loss)
I0524 17:45:47.752151  8086 sgd_solver.cpp:106] Iteration 1460, lr = 0.01
I0524 17:45:55.490989  8086 solver.cpp:228] Iteration 1480, loss = 0.062911
I0524 17:45:55.491024  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981185
I0524 17:45:55.491031  8086 solver.cpp:244]     Train net output #1: loss = 0.062911 (* 1 = 0.062911 loss)
I0524 17:45:55.491037  8086 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I0524 17:46:03.005106  8086 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_1500.caffemodel
I0524 17:46:03.022115  8086 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_1500.solverstate
I0524 17:46:03.030616  8086 solver.cpp:337] Iteration 1500, Testing net (#0)
I0524 17:46:03.543437  8086 solver.cpp:404]     Test net output #0: accuracy = 0.98275
I0524 17:46:03.543462  8086 solver.cpp:404]     Test net output #1: loss = 0.0567496 (* 1 = 0.0567496 loss)
I0524 17:46:03.771842  8086 solver.cpp:228] Iteration 1500, loss = 0.0532197
I0524 17:46:03.771877  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983273
I0524 17:46:03.771883  8086 solver.cpp:244]     Train net output #1: loss = 0.0532197 (* 1 = 0.0532197 loss)
I0524 17:46:03.771888  8086 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0524 17:46:11.513401  8086 solver.cpp:228] Iteration 1520, loss = 0.0581634
I0524 17:46:11.513525  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982654
I0524 17:46:11.513535  8086 solver.cpp:244]     Train net output #1: loss = 0.0581634 (* 1 = 0.0581634 loss)
I0524 17:46:11.513540  8086 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I0524 17:46:19.249513  8086 solver.cpp:228] Iteration 1540, loss = 0.0724622
I0524 17:46:19.249537  8086 solver.cpp:244]     Train net output #0: accuracy = 0.975846
I0524 17:46:19.249544  8086 solver.cpp:244]     Train net output #1: loss = 0.0724622 (* 1 = 0.0724622 loss)
I0524 17:46:19.249548  8086 sgd_solver.cpp:106] Iteration 1540, lr = 0.01
I0524 17:46:26.981704  8086 solver.cpp:228] Iteration 1560, loss = 0.0472338
I0524 17:46:26.981739  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985533
I0524 17:46:26.981746  8086 solver.cpp:244]     Train net output #1: loss = 0.0472338 (* 1 = 0.0472338 loss)
I0524 17:46:26.981751  8086 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I0524 17:46:34.714109  8086 solver.cpp:228] Iteration 1580, loss = 0.0439553
I0524 17:46:34.714144  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987379
I0524 17:46:34.714151  8086 solver.cpp:244]     Train net output #1: loss = 0.0439553 (* 1 = 0.0439553 loss)
I0524 17:46:34.714156  8086 sgd_solver.cpp:106] Iteration 1580, lr = 0.01
I0524 17:46:42.227946  8086 solver.cpp:337] Iteration 1600, Testing net (#0)
I0524 17:46:42.739168  8086 solver.cpp:404]     Test net output #0: accuracy = 0.979973
I0524 17:46:42.739203  8086 solver.cpp:404]     Test net output #1: loss = 0.0619389 (* 1 = 0.0619389 loss)
I0524 17:46:42.967072  8086 solver.cpp:228] Iteration 1600, loss = 0.0518789
I0524 17:46:42.967106  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984366
I0524 17:46:42.967113  8086 solver.cpp:244]     Train net output #1: loss = 0.0518789 (* 1 = 0.0518789 loss)
I0524 17:46:42.967118  8086 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0524 17:46:50.706198  8086 solver.cpp:228] Iteration 1620, loss = 0.0408833
I0524 17:46:50.706231  8086 solver.cpp:244]     Train net output #0: accuracy = 0.988766
I0524 17:46:50.706238  8086 solver.cpp:244]     Train net output #1: loss = 0.0408833 (* 1 = 0.0408833 loss)
I0524 17:46:50.706243  8086 sgd_solver.cpp:106] Iteration 1620, lr = 0.01
I0524 17:46:58.443264  8086 solver.cpp:228] Iteration 1640, loss = 0.0612922
I0524 17:46:58.443297  8086 solver.cpp:244]     Train net output #0: accuracy = 0.978956
I0524 17:46:58.443305  8086 solver.cpp:244]     Train net output #1: loss = 0.0612922 (* 1 = 0.0612922 loss)
I0524 17:46:58.443310  8086 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I0524 17:47:06.178848  8086 solver.cpp:228] Iteration 1660, loss = 0.0466009
I0524 17:47:06.178871  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986109
I0524 17:47:06.178879  8086 solver.cpp:244]     Train net output #1: loss = 0.0466009 (* 1 = 0.0466009 loss)
I0524 17:47:06.178884  8086 sgd_solver.cpp:106] Iteration 1660, lr = 0.01
I0524 17:47:13.913539  8086 solver.cpp:228] Iteration 1680, loss = 0.0570039
I0524 17:47:13.913632  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982585
I0524 17:47:13.913641  8086 solver.cpp:244]     Train net output #1: loss = 0.0570039 (* 1 = 0.0570039 loss)
I0524 17:47:13.913646  8086 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I0524 17:47:21.426900  8086 solver.cpp:337] Iteration 1700, Testing net (#0)
I0524 17:47:21.938284  8086 solver.cpp:404]     Test net output #0: accuracy = 0.984594
I0524 17:47:21.938329  8086 solver.cpp:404]     Test net output #1: loss = 0.0484628 (* 1 = 0.0484628 loss)
I0524 17:47:22.166481  8086 solver.cpp:228] Iteration 1700, loss = 0.0523752
I0524 17:47:22.166515  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983323
I0524 17:47:22.166523  8086 solver.cpp:244]     Train net output #1: loss = 0.0523752 (* 1 = 0.0523752 loss)
I0524 17:47:22.166527  8086 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0524 17:47:29.961344  8086 solver.cpp:228] Iteration 1720, loss = 0.0601031
I0524 17:47:29.961369  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979122
I0524 17:47:29.961375  8086 solver.cpp:244]     Train net output #1: loss = 0.0601031 (* 1 = 0.0601031 loss)
I0524 17:47:29.961380  8086 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I0524 17:47:38.011896  8086 solver.cpp:228] Iteration 1740, loss = 0.0405928
I0524 17:47:38.011919  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987947
I0524 17:47:38.011927  8086 solver.cpp:244]     Train net output #1: loss = 0.0405928 (* 1 = 0.0405928 loss)
I0524 17:47:38.011931  8086 sgd_solver.cpp:106] Iteration 1740, lr = 0.01
I0524 17:47:45.812469  8086 solver.cpp:228] Iteration 1760, loss = 0.0495202
I0524 17:47:45.812587  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982616
I0524 17:47:45.812597  8086 solver.cpp:244]     Train net output #1: loss = 0.0495202 (* 1 = 0.0495202 loss)
I0524 17:47:45.812602  8086 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I0524 17:47:53.561291  8086 solver.cpp:228] Iteration 1780, loss = 0.0428703
I0524 17:47:53.561326  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985956
I0524 17:47:53.561333  8086 solver.cpp:244]     Train net output #1: loss = 0.0428703 (* 1 = 0.0428703 loss)
I0524 17:47:53.561338  8086 sgd_solver.cpp:106] Iteration 1780, lr = 0.01
I0524 17:48:01.081934  8086 solver.cpp:337] Iteration 1800, Testing net (#0)
I0524 17:48:01.595219  8086 solver.cpp:404]     Test net output #0: accuracy = 0.983492
I0524 17:48:01.595254  8086 solver.cpp:404]     Test net output #1: loss = 0.0501573 (* 1 = 0.0501573 loss)
I0524 17:48:01.824687  8086 solver.cpp:228] Iteration 1800, loss = 0.0668837
I0524 17:48:01.824723  8086 solver.cpp:244]     Train net output #0: accuracy = 0.978359
I0524 17:48:01.824729  8086 solver.cpp:244]     Train net output #1: loss = 0.0668837 (* 1 = 0.0668837 loss)
I0524 17:48:01.824734  8086 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0524 17:48:09.579545  8086 solver.cpp:228] Iteration 1820, loss = 0.0592703
I0524 17:48:09.579569  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979317
I0524 17:48:09.579576  8086 solver.cpp:244]     Train net output #1: loss = 0.0592703 (* 1 = 0.0592703 loss)
I0524 17:48:09.579581  8086 sgd_solver.cpp:106] Iteration 1820, lr = 0.01
I0524 17:48:17.328038  8086 solver.cpp:228] Iteration 1840, loss = 0.0567809
I0524 17:48:17.328148  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979814
I0524 17:48:17.328158  8086 solver.cpp:244]     Train net output #1: loss = 0.0567809 (* 1 = 0.0567809 loss)
I0524 17:48:17.328163  8086 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I0524 17:48:25.072913  8086 solver.cpp:228] Iteration 1860, loss = 0.0679867
I0524 17:48:25.072947  8086 solver.cpp:244]     Train net output #0: accuracy = 0.976503
I0524 17:48:25.072954  8086 solver.cpp:244]     Train net output #1: loss = 0.0679867 (* 1 = 0.0679867 loss)
I0524 17:48:25.072959  8086 sgd_solver.cpp:106] Iteration 1860, lr = 0.01
I0524 17:48:32.826318  8086 solver.cpp:228] Iteration 1880, loss = 0.0479308
I0524 17:48:32.826354  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984648
I0524 17:48:32.826360  8086 solver.cpp:244]     Train net output #1: loss = 0.0479308 (* 1 = 0.0479308 loss)
I0524 17:48:32.826365  8086 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I0524 17:48:40.343714  8086 solver.cpp:337] Iteration 1900, Testing net (#0)
I0524 17:48:40.855130  8086 solver.cpp:404]     Test net output #0: accuracy = 0.978644
I0524 17:48:40.855165  8086 solver.cpp:404]     Test net output #1: loss = 0.0623792 (* 1 = 0.0623792 loss)
I0524 17:48:41.084053  8086 solver.cpp:228] Iteration 1900, loss = 0.053126
I0524 17:48:41.084089  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982331
I0524 17:48:41.084095  8086 solver.cpp:244]     Train net output #1: loss = 0.053126 (* 1 = 0.053126 loss)
I0524 17:48:41.084100  8086 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0524 17:48:48.831257  8086 solver.cpp:228] Iteration 1920, loss = 0.0540536
I0524 17:48:48.831387  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984245
I0524 17:48:48.831398  8086 solver.cpp:244]     Train net output #1: loss = 0.0540536 (* 1 = 0.0540536 loss)
I0524 17:48:48.831403  8086 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I0524 17:48:56.576673  8086 solver.cpp:228] Iteration 1940, loss = 0.0514781
I0524 17:48:56.576695  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983388
I0524 17:48:56.576702  8086 solver.cpp:244]     Train net output #1: loss = 0.0514781 (* 1 = 0.0514781 loss)
I0524 17:48:56.576707  8086 sgd_solver.cpp:106] Iteration 1940, lr = 0.01
I0524 17:49:04.316237  8086 solver.cpp:228] Iteration 1960, loss = 0.054594
I0524 17:49:04.316272  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981369
I0524 17:49:04.316279  8086 solver.cpp:244]     Train net output #1: loss = 0.054594 (* 1 = 0.054594 loss)
I0524 17:49:04.316284  8086 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I0524 17:49:12.070299  8086 solver.cpp:228] Iteration 1980, loss = 0.0577158
I0524 17:49:12.070334  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982852
I0524 17:49:12.070341  8086 solver.cpp:244]     Train net output #1: loss = 0.0577158 (* 1 = 0.0577158 loss)
I0524 17:49:12.070346  8086 sgd_solver.cpp:106] Iteration 1980, lr = 0.01
I0524 17:49:19.592337  8086 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_2000.caffemodel
I0524 17:49:19.609464  8086 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_2000.solverstate
I0524 17:49:19.617815  8086 solver.cpp:337] Iteration 2000, Testing net (#0)
I0524 17:49:20.132707  8086 solver.cpp:404]     Test net output #0: accuracy = 0.991535
I0524 17:49:20.132743  8086 solver.cpp:404]     Test net output #1: loss = 0.0325183 (* 1 = 0.0325183 loss)
I0524 17:49:20.361263  8086 solver.cpp:228] Iteration 2000, loss = 0.0448297
I0524 17:49:20.361285  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984932
I0524 17:49:20.361292  8086 solver.cpp:244]     Train net output #1: loss = 0.0448297 (* 1 = 0.0448297 loss)
I0524 17:49:20.361296  8086 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I0524 17:49:28.111678  8086 solver.cpp:228] Iteration 2020, loss = 0.0602359
I0524 17:49:28.111711  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980029
I0524 17:49:28.111718  8086 solver.cpp:244]     Train net output #1: loss = 0.0602359 (* 1 = 0.0602359 loss)
I0524 17:49:28.111722  8086 sgd_solver.cpp:106] Iteration 2020, lr = 0.01
I0524 17:49:35.857679  8086 solver.cpp:228] Iteration 2040, loss = 0.0490442
I0524 17:49:35.857713  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985345
I0524 17:49:35.857722  8086 solver.cpp:244]     Train net output #1: loss = 0.0490442 (* 1 = 0.0490442 loss)
I0524 17:49:35.857725  8086 sgd_solver.cpp:106] Iteration 2040, lr = 0.01
I0524 17:49:43.592146  8086 solver.cpp:228] Iteration 2060, loss = 0.0528284
I0524 17:49:43.592169  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983766
I0524 17:49:43.592175  8086 solver.cpp:244]     Train net output #1: loss = 0.0528284 (* 1 = 0.0528284 loss)
I0524 17:49:43.592180  8086 sgd_solver.cpp:106] Iteration 2060, lr = 0.01
I0524 17:49:51.341228  8086 solver.cpp:228] Iteration 2080, loss = 0.0400193
I0524 17:49:51.341310  8086 solver.cpp:244]     Train net output #0: accuracy = 0.988675
I0524 17:49:51.341320  8086 solver.cpp:244]     Train net output #1: loss = 0.0400193 (* 1 = 0.0400193 loss)
I0524 17:49:51.341325  8086 sgd_solver.cpp:106] Iteration 2080, lr = 0.01
I0524 17:49:58.867485  8086 solver.cpp:337] Iteration 2100, Testing net (#0)
I0524 17:49:59.401787  8086 solver.cpp:404]     Test net output #0: accuracy = 0.982484
I0524 17:49:59.401823  8086 solver.cpp:404]     Test net output #1: loss = 0.0504047 (* 1 = 0.0504047 loss)
I0524 17:49:59.631716  8086 solver.cpp:228] Iteration 2100, loss = 0.0551714
I0524 17:49:59.631741  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982743
I0524 17:49:59.631747  8086 solver.cpp:244]     Train net output #1: loss = 0.0551714 (* 1 = 0.0551714 loss)
I0524 17:49:59.631752  8086 sgd_solver.cpp:106] Iteration 2100, lr = 0.01
I0524 17:50:07.410678  8086 solver.cpp:228] Iteration 2120, loss = 0.0665278
I0524 17:50:07.410713  8086 solver.cpp:244]     Train net output #0: accuracy = 0.976072
I0524 17:50:07.410722  8086 solver.cpp:244]     Train net output #1: loss = 0.0665278 (* 1 = 0.0665278 loss)
I0524 17:50:07.410725  8086 sgd_solver.cpp:106] Iteration 2120, lr = 0.01
I0524 17:50:15.176118  8086 solver.cpp:228] Iteration 2140, loss = 0.0371659
I0524 17:50:15.176143  8086 solver.cpp:244]     Train net output #0: accuracy = 0.988145
I0524 17:50:15.176151  8086 solver.cpp:244]     Train net output #1: loss = 0.0371659 (* 1 = 0.0371659 loss)
I0524 17:50:15.176156  8086 sgd_solver.cpp:106] Iteration 2140, lr = 0.01
I0524 17:50:22.934345  8086 solver.cpp:228] Iteration 2160, loss = 0.0602236
I0524 17:50:22.934476  8086 solver.cpp:244]     Train net output #0: accuracy = 0.976632
I0524 17:50:22.934486  8086 solver.cpp:244]     Train net output #1: loss = 0.0602236 (* 1 = 0.0602236 loss)
I0524 17:50:22.934497  8086 sgd_solver.cpp:106] Iteration 2160, lr = 0.01
I0524 17:50:30.689604  8086 solver.cpp:228] Iteration 2180, loss = 0.0700632
I0524 17:50:30.689628  8086 solver.cpp:244]     Train net output #0: accuracy = 0.975037
I0524 17:50:30.689636  8086 solver.cpp:244]     Train net output #1: loss = 0.0700632 (* 1 = 0.0700632 loss)
I0524 17:50:30.689640  8086 sgd_solver.cpp:106] Iteration 2180, lr = 0.01
I0524 17:50:38.205534  8086 solver.cpp:337] Iteration 2200, Testing net (#0)
I0524 17:50:38.717178  8086 solver.cpp:404]     Test net output #0: accuracy = 0.985721
I0524 17:50:38.717212  8086 solver.cpp:404]     Test net output #1: loss = 0.0443451 (* 1 = 0.0443451 loss)
I0524 17:50:38.946377  8086 solver.cpp:228] Iteration 2200, loss = 0.0438933
I0524 17:50:38.946411  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98653
I0524 17:50:38.946419  8086 solver.cpp:244]     Train net output #1: loss = 0.0438933 (* 1 = 0.0438933 loss)
I0524 17:50:38.946424  8086 sgd_solver.cpp:106] Iteration 2200, lr = 0.01
I0524 17:50:46.696377  8086 solver.cpp:228] Iteration 2220, loss = 0.0461916
I0524 17:50:46.696399  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983757
I0524 17:50:46.696406  8086 solver.cpp:244]     Train net output #1: loss = 0.0461916 (* 1 = 0.0461916 loss)
I0524 17:50:46.696411  8086 sgd_solver.cpp:106] Iteration 2220, lr = 0.01
I0524 17:50:54.441035  8086 solver.cpp:228] Iteration 2240, loss = 0.0399764
I0524 17:50:54.441141  8086 solver.cpp:244]     Train net output #0: accuracy = 0.989355
I0524 17:50:54.441150  8086 solver.cpp:244]     Train net output #1: loss = 0.0399764 (* 1 = 0.0399764 loss)
I0524 17:50:54.441155  8086 sgd_solver.cpp:106] Iteration 2240, lr = 0.01
I0524 17:51:02.184384  8086 solver.cpp:228] Iteration 2260, loss = 0.0432491
I0524 17:51:02.184408  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986909
I0524 17:51:02.184415  8086 solver.cpp:244]     Train net output #1: loss = 0.0432491 (* 1 = 0.0432491 loss)
I0524 17:51:02.184420  8086 sgd_solver.cpp:106] Iteration 2260, lr = 0.01
I0524 17:51:09.936612  8086 solver.cpp:228] Iteration 2280, loss = 0.0490922
I0524 17:51:09.936636  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981442
I0524 17:51:09.936643  8086 solver.cpp:244]     Train net output #1: loss = 0.0490922 (* 1 = 0.0490922 loss)
I0524 17:51:09.936648  8086 sgd_solver.cpp:106] Iteration 2280, lr = 0.01
I0524 17:51:17.462297  8086 solver.cpp:337] Iteration 2300, Testing net (#0)
I0524 17:51:17.975273  8086 solver.cpp:404]     Test net output #0: accuracy = 0.984899
I0524 17:51:17.975307  8086 solver.cpp:404]     Test net output #1: loss = 0.0451015 (* 1 = 0.0451015 loss)
I0524 17:51:18.204295  8086 solver.cpp:228] Iteration 2300, loss = 0.0531575
I0524 17:51:18.204329  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98035
I0524 17:51:18.204336  8086 solver.cpp:244]     Train net output #1: loss = 0.0531575 (* 1 = 0.0531575 loss)
I0524 17:51:18.204341  8086 sgd_solver.cpp:106] Iteration 2300, lr = 0.01
I0524 17:51:25.955997  8086 solver.cpp:228] Iteration 2320, loss = 0.0403591
I0524 17:51:25.956120  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986607
I0524 17:51:25.956130  8086 solver.cpp:244]     Train net output #1: loss = 0.0403591 (* 1 = 0.0403591 loss)
I0524 17:51:25.956135  8086 sgd_solver.cpp:106] Iteration 2320, lr = 0.01
I0524 17:51:33.706982  8086 solver.cpp:228] Iteration 2340, loss = 0.0553405
I0524 17:51:33.707016  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979225
I0524 17:51:33.707025  8086 solver.cpp:244]     Train net output #1: loss = 0.0553405 (* 1 = 0.0553405 loss)
I0524 17:51:33.707028  8086 sgd_solver.cpp:106] Iteration 2340, lr = 0.01
I0524 17:51:41.453665  8086 solver.cpp:228] Iteration 2360, loss = 0.0435052
I0524 17:51:41.453690  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984798
I0524 17:51:41.453696  8086 solver.cpp:244]     Train net output #1: loss = 0.0435052 (* 1 = 0.0435052 loss)
I0524 17:51:41.453701  8086 sgd_solver.cpp:106] Iteration 2360, lr = 0.01
I0524 17:51:49.212852  8086 solver.cpp:228] Iteration 2380, loss = 0.0493271
I0524 17:51:49.212874  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984094
I0524 17:51:49.212893  8086 solver.cpp:244]     Train net output #1: loss = 0.0493271 (* 1 = 0.0493271 loss)
I0524 17:51:49.212896  8086 sgd_solver.cpp:106] Iteration 2380, lr = 0.01
I0524 17:51:56.748105  8086 solver.cpp:337] Iteration 2400, Testing net (#0)
I0524 17:51:57.262552  8086 solver.cpp:404]     Test net output #0: accuracy = 0.982275
I0524 17:51:57.262575  8086 solver.cpp:404]     Test net output #1: loss = 0.0511437 (* 1 = 0.0511437 loss)
I0524 17:51:57.491860  8086 solver.cpp:228] Iteration 2400, loss = 0.0644815
I0524 17:51:57.491895  8086 solver.cpp:244]     Train net output #0: accuracy = 0.975833
I0524 17:51:57.491904  8086 solver.cpp:244]     Train net output #1: loss = 0.0644815 (* 1 = 0.0644815 loss)
I0524 17:51:57.491909  8086 sgd_solver.cpp:106] Iteration 2400, lr = 0.01
I0524 17:52:05.267973  8086 solver.cpp:228] Iteration 2420, loss = 0.0373831
I0524 17:52:05.268007  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987298
I0524 17:52:05.268013  8086 solver.cpp:244]     Train net output #1: loss = 0.0373831 (* 1 = 0.0373831 loss)
I0524 17:52:05.268018  8086 sgd_solver.cpp:106] Iteration 2420, lr = 0.01
I0524 17:52:13.034044  8086 solver.cpp:228] Iteration 2440, loss = 0.040863
I0524 17:52:13.034078  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985842
I0524 17:52:13.034085  8086 solver.cpp:244]     Train net output #1: loss = 0.040863 (* 1 = 0.040863 loss)
I0524 17:52:13.034090  8086 sgd_solver.cpp:106] Iteration 2440, lr = 0.01
I0524 17:52:20.785907  8086 solver.cpp:228] Iteration 2460, loss = 0.0460279
I0524 17:52:20.785943  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984397
I0524 17:52:20.785949  8086 solver.cpp:244]     Train net output #1: loss = 0.0460279 (* 1 = 0.0460279 loss)
I0524 17:52:20.785954  8086 sgd_solver.cpp:106] Iteration 2460, lr = 0.01
I0524 17:52:28.543568  8086 solver.cpp:228] Iteration 2480, loss = 0.0592801
I0524 17:52:28.543660  8086 solver.cpp:244]     Train net output #0: accuracy = 0.977423
I0524 17:52:28.543669  8086 solver.cpp:244]     Train net output #1: loss = 0.0592801 (* 1 = 0.0592801 loss)
I0524 17:52:28.543674  8086 sgd_solver.cpp:106] Iteration 2480, lr = 0.01
I0524 17:52:36.077244  8086 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_2500.caffemodel
I0524 17:52:36.115839  8086 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_2500.solverstate
I0524 17:52:36.135444  8086 solver.cpp:337] Iteration 2500, Testing net (#0)
I0524 17:52:36.702687  8086 solver.cpp:404]     Test net output #0: accuracy = 0.981436
I0524 17:52:36.702714  8086 solver.cpp:404]     Test net output #1: loss = 0.0507068 (* 1 = 0.0507068 loss)
I0524 17:52:36.938004  8086 solver.cpp:228] Iteration 2500, loss = 0.057141
I0524 17:52:36.938031  8086 solver.cpp:244]     Train net output #0: accuracy = 0.977874
I0524 17:52:36.938040  8086 solver.cpp:244]     Train net output #1: loss = 0.057141 (* 1 = 0.057141 loss)
I0524 17:52:36.938045  8086 sgd_solver.cpp:106] Iteration 2500, lr = 0.01
I0524 17:52:44.695078  8086 solver.cpp:228] Iteration 2520, loss = 0.0513557
I0524 17:52:44.695102  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982401
I0524 17:52:44.695109  8086 solver.cpp:244]     Train net output #1: loss = 0.0513557 (* 1 = 0.0513557 loss)
I0524 17:52:44.695114  8086 sgd_solver.cpp:106] Iteration 2520, lr = 0.01
I0524 17:52:52.451828  8086 solver.cpp:228] Iteration 2540, loss = 0.0447033
I0524 17:52:52.451864  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984665
I0524 17:52:52.451871  8086 solver.cpp:244]     Train net output #1: loss = 0.0447033 (* 1 = 0.0447033 loss)
I0524 17:52:52.451877  8086 sgd_solver.cpp:106] Iteration 2540, lr = 0.01
I0524 17:53:00.219629  8086 solver.cpp:228] Iteration 2560, loss = 0.0538183
I0524 17:53:00.219781  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979592
I0524 17:53:00.219792  8086 solver.cpp:244]     Train net output #1: loss = 0.0538183 (* 1 = 0.0538183 loss)
I0524 17:53:00.219797  8086 sgd_solver.cpp:106] Iteration 2560, lr = 0.01
I0524 17:53:07.979871  8086 solver.cpp:228] Iteration 2580, loss = 0.0585638
I0524 17:53:07.979907  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979645
I0524 17:53:07.979914  8086 solver.cpp:244]     Train net output #1: loss = 0.0585638 (* 1 = 0.0585638 loss)
I0524 17:53:07.979919  8086 sgd_solver.cpp:106] Iteration 2580, lr = 0.01
I0524 17:53:15.519297  8086 solver.cpp:337] Iteration 2600, Testing net (#0)
I0524 17:53:16.032613  8086 solver.cpp:404]     Test net output #0: accuracy = 0.984227
I0524 17:53:16.032637  8086 solver.cpp:404]     Test net output #1: loss = 0.0448497 (* 1 = 0.0448497 loss)
I0524 17:53:16.262717  8086 solver.cpp:228] Iteration 2600, loss = 0.0395426
I0524 17:53:16.262739  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986119
I0524 17:53:16.262747  8086 solver.cpp:244]     Train net output #1: loss = 0.0395426 (* 1 = 0.0395426 loss)
I0524 17:53:16.262751  8086 sgd_solver.cpp:106] Iteration 2600, lr = 0.01
I0524 17:53:24.028555  8086 solver.cpp:228] Iteration 2620, loss = 0.0438816
I0524 17:53:24.028591  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982137
I0524 17:53:24.028599  8086 solver.cpp:244]     Train net output #1: loss = 0.0438816 (* 1 = 0.0438816 loss)
I0524 17:53:24.028604  8086 sgd_solver.cpp:106] Iteration 2620, lr = 0.01
I0524 17:53:31.774633  8086 solver.cpp:228] Iteration 2640, loss = 0.0524164
I0524 17:53:31.774735  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980276
I0524 17:53:31.774745  8086 solver.cpp:244]     Train net output #1: loss = 0.0524164 (* 1 = 0.0524164 loss)
I0524 17:53:31.774750  8086 sgd_solver.cpp:106] Iteration 2640, lr = 0.01
I0524 17:53:39.542737  8086 solver.cpp:228] Iteration 2660, loss = 0.0433769
I0524 17:53:39.542762  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984408
I0524 17:53:39.542770  8086 solver.cpp:244]     Train net output #1: loss = 0.0433769 (* 1 = 0.0433769 loss)
I0524 17:53:39.542775  8086 sgd_solver.cpp:106] Iteration 2660, lr = 0.01
I0524 17:53:47.299015  8086 solver.cpp:228] Iteration 2680, loss = 0.0347063
I0524 17:53:47.299052  8086 solver.cpp:244]     Train net output #0: accuracy = 0.988329
I0524 17:53:47.299059  8086 solver.cpp:244]     Train net output #1: loss = 0.0347063 (* 1 = 0.0347063 loss)
I0524 17:53:47.299063  8086 sgd_solver.cpp:106] Iteration 2680, lr = 0.01
I0524 17:53:55.355046  8086 solver.cpp:337] Iteration 2700, Testing net (#0)
I0524 17:53:55.866540  8086 solver.cpp:404]     Test net output #0: accuracy = 0.98716
I0524 17:53:55.866575  8086 solver.cpp:404]     Test net output #1: loss = 0.0371891 (* 1 = 0.0371891 loss)
I0524 17:53:56.137615  8086 solver.cpp:228] Iteration 2700, loss = 0.0640937
I0524 17:53:56.137639  8086 solver.cpp:244]     Train net output #0: accuracy = 0.977123
I0524 17:53:56.137647  8086 solver.cpp:244]     Train net output #1: loss = 0.0640937 (* 1 = 0.0640937 loss)
I0524 17:53:56.137652  8086 sgd_solver.cpp:106] Iteration 2700, lr = 0.01
I0524 17:54:04.738203  8086 solver.cpp:228] Iteration 2720, loss = 0.0651546
I0524 17:54:04.738323  8086 solver.cpp:244]     Train net output #0: accuracy = 0.977821
I0524 17:54:04.738334  8086 solver.cpp:244]     Train net output #1: loss = 0.0651546 (* 1 = 0.0651546 loss)
I0524 17:54:04.738339  8086 sgd_solver.cpp:106] Iteration 2720, lr = 0.01
I0524 17:54:13.341155  8086 solver.cpp:228] Iteration 2740, loss = 0.0567162
I0524 17:54:13.341176  8086 solver.cpp:244]     Train net output #0: accuracy = 0.978339
I0524 17:54:13.341184  8086 solver.cpp:244]     Train net output #1: loss = 0.0567162 (* 1 = 0.0567162 loss)
I0524 17:54:13.341188  8086 sgd_solver.cpp:106] Iteration 2740, lr = 0.01
I0524 17:54:21.942829  8086 solver.cpp:228] Iteration 2760, loss = 0.0649063
I0524 17:54:21.942852  8086 solver.cpp:244]     Train net output #0: accuracy = 0.976226
I0524 17:54:21.942860  8086 solver.cpp:244]     Train net output #1: loss = 0.0649063 (* 1 = 0.0649063 loss)
I0524 17:54:21.942864  8086 sgd_solver.cpp:106] Iteration 2760, lr = 0.01
I0524 17:54:30.542515  8086 solver.cpp:228] Iteration 2780, loss = 0.0469373
I0524 17:54:30.542539  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985772
I0524 17:54:30.542547  8086 solver.cpp:244]     Train net output #1: loss = 0.0469373 (* 1 = 0.0469373 loss)
I0524 17:54:30.542551  8086 sgd_solver.cpp:106] Iteration 2780, lr = 0.01
I0524 17:54:38.872038  8086 solver.cpp:337] Iteration 2800, Testing net (#0)
I0524 17:54:39.383913  8086 solver.cpp:404]     Test net output #0: accuracy = 0.981634
I0524 17:54:39.383949  8086 solver.cpp:404]     Test net output #1: loss = 0.0497049 (* 1 = 0.0497049 loss)
I0524 17:54:39.655709  8086 solver.cpp:228] Iteration 2800, loss = 0.0532884
I0524 17:54:39.655735  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979482
I0524 17:54:39.655741  8086 solver.cpp:244]     Train net output #1: loss = 0.0532884 (* 1 = 0.0532884 loss)
I0524 17:54:39.655746  8086 sgd_solver.cpp:106] Iteration 2800, lr = 0.01
I0524 17:54:48.256161  8086 solver.cpp:228] Iteration 2820, loss = 0.0416018
I0524 17:54:48.256196  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986139
I0524 17:54:48.256202  8086 solver.cpp:244]     Train net output #1: loss = 0.0416018 (* 1 = 0.0416018 loss)
I0524 17:54:48.256207  8086 sgd_solver.cpp:106] Iteration 2820, lr = 0.01
I0524 17:54:56.859103  8086 solver.cpp:228] Iteration 2840, loss = 0.0328646
I0524 17:54:56.859127  8086 solver.cpp:244]     Train net output #0: accuracy = 0.991847
I0524 17:54:56.859134  8086 solver.cpp:244]     Train net output #1: loss = 0.0328646 (* 1 = 0.0328646 loss)
I0524 17:54:56.859138  8086 sgd_solver.cpp:106] Iteration 2840, lr = 0.01
I0524 17:55:05.462136  8086 solver.cpp:228] Iteration 2860, loss = 0.0431062
I0524 17:55:05.462159  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982297
I0524 17:55:05.462167  8086 solver.cpp:244]     Train net output #1: loss = 0.0431062 (* 1 = 0.0431062 loss)
I0524 17:55:05.462172  8086 sgd_solver.cpp:106] Iteration 2860, lr = 0.01
I0524 17:55:14.066017  8086 solver.cpp:228] Iteration 2880, loss = 0.0585153
I0524 17:55:14.066113  8086 solver.cpp:244]     Train net output #0: accuracy = 0.976097
I0524 17:55:14.066123  8086 solver.cpp:244]     Train net output #1: loss = 0.0585153 (* 1 = 0.0585153 loss)
I0524 17:55:14.066128  8086 sgd_solver.cpp:106] Iteration 2880, lr = 0.01
I0524 17:55:22.402807  8086 solver.cpp:337] Iteration 2900, Testing net (#0)
I0524 17:55:22.915899  8086 solver.cpp:404]     Test net output #0: accuracy = 0.983841
I0524 17:55:22.915935  8086 solver.cpp:404]     Test net output #1: loss = 0.0438679 (* 1 = 0.0438679 loss)
I0524 17:55:23.187396  8086 solver.cpp:228] Iteration 2900, loss = 0.0502162
I0524 17:55:23.187419  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980366
I0524 17:55:23.187427  8086 solver.cpp:244]     Train net output #1: loss = 0.0502162 (* 1 = 0.0502162 loss)
I0524 17:55:23.187430  8086 sgd_solver.cpp:106] Iteration 2900, lr = 0.01
I0524 17:55:31.787740  8086 solver.cpp:228] Iteration 2920, loss = 0.0481992
I0524 17:55:31.787763  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984037
I0524 17:55:31.787770  8086 solver.cpp:244]     Train net output #1: loss = 0.0481992 (* 1 = 0.0481992 loss)
I0524 17:55:31.787775  8086 sgd_solver.cpp:106] Iteration 2920, lr = 0.01
I0524 17:55:40.389912  8086 solver.cpp:228] Iteration 2940, loss = 0.041653
I0524 17:55:40.389936  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984488
I0524 17:55:40.389943  8086 solver.cpp:244]     Train net output #1: loss = 0.041653 (* 1 = 0.041653 loss)
I0524 17:55:40.389950  8086 sgd_solver.cpp:106] Iteration 2940, lr = 0.01
I0524 17:55:48.984037  8086 solver.cpp:228] Iteration 2960, loss = 0.0388085
I0524 17:55:48.984160  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986507
I0524 17:55:48.984171  8086 solver.cpp:244]     Train net output #1: loss = 0.0388085 (* 1 = 0.0388085 loss)
I0524 17:55:48.984176  8086 sgd_solver.cpp:106] Iteration 2960, lr = 0.01
I0524 17:55:57.213727  8086 solver.cpp:228] Iteration 2980, loss = 0.0389557
I0524 17:55:57.213752  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984282
I0524 17:55:57.213758  8086 solver.cpp:244]     Train net output #1: loss = 0.0389557 (* 1 = 0.0389557 loss)
I0524 17:55:57.213762  8086 sgd_solver.cpp:106] Iteration 2980, lr = 0.01
I0524 17:56:04.737790  8086 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_3000.caffemodel
I0524 17:56:04.754971  8086 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_3000.solverstate
I0524 17:56:04.763545  8086 solver.cpp:337] Iteration 3000, Testing net (#0)
I0524 17:56:05.279062  8086 solver.cpp:404]     Test net output #0: accuracy = 0.983364
I0524 17:56:05.279096  8086 solver.cpp:404]     Test net output #1: loss = 0.0476717 (* 1 = 0.0476717 loss)
I0524 17:56:05.509793  8086 solver.cpp:228] Iteration 3000, loss = 0.063928
I0524 17:56:05.509816  8086 solver.cpp:244]     Train net output #0: accuracy = 0.976146
I0524 17:56:05.509822  8086 solver.cpp:244]     Train net output #1: loss = 0.063928 (* 1 = 0.063928 loss)
I0524 17:56:05.509827  8086 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0524 17:56:13.267757  8086 solver.cpp:228] Iteration 3020, loss = 0.0396741
I0524 17:56:13.267782  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985213
I0524 17:56:13.267789  8086 solver.cpp:244]     Train net output #1: loss = 0.0396741 (* 1 = 0.0396741 loss)
I0524 17:56:13.267794  8086 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0524 17:56:21.022915  8086 solver.cpp:228] Iteration 3040, loss = 0.034058
I0524 17:56:21.023010  8086 solver.cpp:244]     Train net output #0: accuracy = 0.988133
I0524 17:56:21.023020  8086 solver.cpp:244]     Train net output #1: loss = 0.034058 (* 1 = 0.034058 loss)
I0524 17:56:21.023025  8086 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0524 17:56:28.777530  8086 solver.cpp:228] Iteration 3060, loss = 0.037807
I0524 17:56:28.777565  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984373
I0524 17:56:28.777573  8086 solver.cpp:244]     Train net output #1: loss = 0.037807 (* 1 = 0.037807 loss)
I0524 17:56:28.777577  8086 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0524 17:56:36.526206  8086 solver.cpp:228] Iteration 3080, loss = 0.0395877
I0524 17:56:36.526239  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984837
I0524 17:56:36.526247  8086 solver.cpp:244]     Train net output #1: loss = 0.0395877 (* 1 = 0.0395877 loss)
I0524 17:56:36.526252  8086 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0524 17:56:44.068068  8086 solver.cpp:337] Iteration 3100, Testing net (#0)
I0524 17:56:44.581874  8086 solver.cpp:404]     Test net output #0: accuracy = 0.981862
I0524 17:56:44.581899  8086 solver.cpp:404]     Test net output #1: loss = 0.0437271 (* 1 = 0.0437271 loss)
I0524 17:56:44.812005  8086 solver.cpp:228] Iteration 3100, loss = 0.0437715
I0524 17:56:44.812028  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984021
I0524 17:56:44.812036  8086 solver.cpp:244]     Train net output #1: loss = 0.0437715 (* 1 = 0.0437715 loss)
I0524 17:56:44.812041  8086 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0524 17:56:52.562288  8086 solver.cpp:228] Iteration 3120, loss = 0.0257525
I0524 17:56:52.562420  8086 solver.cpp:244]     Train net output #0: accuracy = 0.992952
I0524 17:56:52.562430  8086 solver.cpp:244]     Train net output #1: loss = 0.0257525 (* 1 = 0.0257525 loss)
I0524 17:56:52.562435  8086 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0524 17:57:00.307183  8086 solver.cpp:228] Iteration 3140, loss = 0.0369942
I0524 17:57:00.307206  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986074
I0524 17:57:00.307214  8086 solver.cpp:244]     Train net output #1: loss = 0.0369942 (* 1 = 0.0369942 loss)
I0524 17:57:00.307219  8086 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0524 17:57:08.049881  8086 solver.cpp:228] Iteration 3160, loss = 0.0444498
I0524 17:57:08.049916  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98611
I0524 17:57:08.049922  8086 solver.cpp:244]     Train net output #1: loss = 0.0444498 (* 1 = 0.0444498 loss)
I0524 17:57:08.049926  8086 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0524 17:57:15.793052  8086 solver.cpp:228] Iteration 3180, loss = 0.0438372
I0524 17:57:15.793076  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983026
I0524 17:57:15.793083  8086 solver.cpp:244]     Train net output #1: loss = 0.0438372 (* 1 = 0.0438372 loss)
I0524 17:57:15.793088  8086 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0524 17:57:23.317595  8086 solver.cpp:337] Iteration 3200, Testing net (#0)
I0524 17:57:23.830669  8086 solver.cpp:404]     Test net output #0: accuracy = 0.978423
I0524 17:57:23.830704  8086 solver.cpp:404]     Test net output #1: loss = 0.0594663 (* 1 = 0.0594663 loss)
I0524 17:57:24.060943  8086 solver.cpp:228] Iteration 3200, loss = 0.028815
I0524 17:57:24.060967  8086 solver.cpp:244]     Train net output #0: accuracy = 0.990781
I0524 17:57:24.060974  8086 solver.cpp:244]     Train net output #1: loss = 0.028815 (* 1 = 0.028815 loss)
I0524 17:57:24.060981  8086 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0524 17:57:31.812640  8086 solver.cpp:228] Iteration 3220, loss = 0.0448266
I0524 17:57:31.812664  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984475
I0524 17:57:31.812683  8086 solver.cpp:244]     Train net output #1: loss = 0.0448266 (* 1 = 0.0448266 loss)
I0524 17:57:31.812688  8086 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0524 17:57:39.561385  8086 solver.cpp:228] Iteration 3240, loss = 0.0468035
I0524 17:57:39.561420  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982148
I0524 17:57:39.561429  8086 solver.cpp:244]     Train net output #1: loss = 0.0468035 (* 1 = 0.0468035 loss)
I0524 17:57:39.561432  8086 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0524 17:57:47.304177  8086 solver.cpp:228] Iteration 3260, loss = 0.0511116
I0524 17:57:47.304213  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98057
I0524 17:57:47.304219  8086 solver.cpp:244]     Train net output #1: loss = 0.0511116 (* 1 = 0.0511116 loss)
I0524 17:57:47.304224  8086 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0524 17:57:55.041338  8086 solver.cpp:228] Iteration 3280, loss = 0.0458062
I0524 17:57:55.041435  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983625
I0524 17:57:55.041443  8086 solver.cpp:244]     Train net output #1: loss = 0.0458062 (* 1 = 0.0458062 loss)
I0524 17:57:55.041448  8086 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0524 17:58:02.562470  8086 solver.cpp:337] Iteration 3300, Testing net (#0)
I0524 17:58:03.075812  8086 solver.cpp:404]     Test net output #0: accuracy = 0.98579
I0524 17:58:03.075848  8086 solver.cpp:404]     Test net output #1: loss = 0.0385649 (* 1 = 0.0385649 loss)
I0524 17:58:03.304805  8086 solver.cpp:228] Iteration 3300, loss = 0.0491054
I0524 17:58:03.304837  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981075
I0524 17:58:03.304844  8086 solver.cpp:244]     Train net output #1: loss = 0.0491054 (* 1 = 0.0491054 loss)
I0524 17:58:03.304849  8086 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0524 17:58:11.053316  8086 solver.cpp:228] Iteration 3320, loss = 0.0537365
I0524 17:58:11.053350  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982393
I0524 17:58:11.053359  8086 solver.cpp:244]     Train net output #1: loss = 0.0537365 (* 1 = 0.0537365 loss)
I0524 17:58:11.053364  8086 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0524 17:58:18.811297  8086 solver.cpp:228] Iteration 3340, loss = 0.0422548
I0524 17:58:18.811336  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985951
I0524 17:58:18.811342  8086 solver.cpp:244]     Train net output #1: loss = 0.0422548 (* 1 = 0.0422548 loss)
I0524 17:58:18.811347  8086 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0524 17:58:26.577356  8086 solver.cpp:228] Iteration 3360, loss = 0.0573542
I0524 17:58:26.577474  8086 solver.cpp:244]     Train net output #0: accuracy = 0.977173
I0524 17:58:26.577484  8086 solver.cpp:244]     Train net output #1: loss = 0.0573542 (* 1 = 0.0573542 loss)
I0524 17:58:26.577489  8086 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0524 17:58:34.328941  8086 solver.cpp:228] Iteration 3380, loss = 0.045402
I0524 17:58:34.328965  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980691
I0524 17:58:34.328972  8086 solver.cpp:244]     Train net output #1: loss = 0.045402 (* 1 = 0.045402 loss)
I0524 17:58:34.328976  8086 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0524 17:58:41.849889  8086 solver.cpp:337] Iteration 3400, Testing net (#0)
I0524 17:58:42.363270  8086 solver.cpp:404]     Test net output #0: accuracy = 0.981807
I0524 17:58:42.363304  8086 solver.cpp:404]     Test net output #1: loss = 0.0537667 (* 1 = 0.0537667 loss)
I0524 17:58:42.592319  8086 solver.cpp:228] Iteration 3400, loss = 0.0509076
I0524 17:58:42.592351  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98184
I0524 17:58:42.592360  8086 solver.cpp:244]     Train net output #1: loss = 0.0509076 (* 1 = 0.0509076 loss)
I0524 17:58:42.592365  8086 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0524 17:58:50.327036  8086 solver.cpp:228] Iteration 3420, loss = 0.0508972
I0524 17:58:50.327059  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982139
I0524 17:58:50.327076  8086 solver.cpp:244]     Train net output #1: loss = 0.0508972 (* 1 = 0.0508972 loss)
I0524 17:58:50.327081  8086 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0524 17:58:58.062355  8086 solver.cpp:228] Iteration 3440, loss = 0.0362517
I0524 17:58:58.062444  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985116
I0524 17:58:58.062453  8086 solver.cpp:244]     Train net output #1: loss = 0.0362517 (* 1 = 0.0362517 loss)
I0524 17:58:58.062458  8086 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0524 17:59:05.818121  8086 solver.cpp:228] Iteration 3460, loss = 0.0405869
I0524 17:59:05.818143  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984588
I0524 17:59:05.818150  8086 solver.cpp:244]     Train net output #1: loss = 0.0405869 (* 1 = 0.0405869 loss)
I0524 17:59:05.818155  8086 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0524 17:59:13.562046  8086 solver.cpp:228] Iteration 3480, loss = 0.0361062
I0524 17:59:13.562079  8086 solver.cpp:244]     Train net output #0: accuracy = 0.988892
I0524 17:59:13.562086  8086 solver.cpp:244]     Train net output #1: loss = 0.0361062 (* 1 = 0.0361062 loss)
I0524 17:59:13.562091  8086 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0524 17:59:21.083650  8086 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_3500.caffemodel
I0524 17:59:21.102268  8086 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_3500.solverstate
I0524 17:59:21.110981  8086 solver.cpp:337] Iteration 3500, Testing net (#0)
I0524 17:59:21.625572  8086 solver.cpp:404]     Test net output #0: accuracy = 0.981091
I0524 17:59:21.625607  8086 solver.cpp:404]     Test net output #1: loss = 0.0508951 (* 1 = 0.0508951 loss)
I0524 17:59:21.854678  8086 solver.cpp:228] Iteration 3500, loss = 0.0485471
I0524 17:59:21.854701  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979709
I0524 17:59:21.854707  8086 solver.cpp:244]     Train net output #1: loss = 0.0485471 (* 1 = 0.0485471 loss)
I0524 17:59:21.854712  8086 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0524 17:59:29.602866  8086 solver.cpp:228] Iteration 3520, loss = 0.0304949
I0524 17:59:29.602977  8086 solver.cpp:244]     Train net output #0: accuracy = 0.988501
I0524 17:59:29.602988  8086 solver.cpp:244]     Train net output #1: loss = 0.0304949 (* 1 = 0.0304949 loss)
I0524 17:59:29.602993  8086 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0524 17:59:37.347956  8086 solver.cpp:228] Iteration 3540, loss = 0.0530469
I0524 17:59:37.347991  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981118
I0524 17:59:37.347998  8086 solver.cpp:244]     Train net output #1: loss = 0.0530469 (* 1 = 0.0530469 loss)
I0524 17:59:37.348003  8086 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0524 17:59:45.101162  8086 solver.cpp:228] Iteration 3560, loss = 0.055407
I0524 17:59:45.101197  8086 solver.cpp:244]     Train net output #0: accuracy = 0.976425
I0524 17:59:45.101204  8086 solver.cpp:244]     Train net output #1: loss = 0.055407 (* 1 = 0.055407 loss)
I0524 17:59:45.101208  8086 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0524 17:59:52.851649  8086 solver.cpp:228] Iteration 3580, loss = 0.0644837
I0524 17:59:52.851672  8086 solver.cpp:244]     Train net output #0: accuracy = 0.978813
I0524 17:59:52.851680  8086 solver.cpp:244]     Train net output #1: loss = 0.0644837 (* 1 = 0.0644837 loss)
I0524 17:59:52.851685  8086 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0524 18:00:00.376021  8086 solver.cpp:337] Iteration 3600, Testing net (#0)
I0524 18:00:00.889142  8086 solver.cpp:404]     Test net output #0: accuracy = 0.983468
I0524 18:00:00.889175  8086 solver.cpp:404]     Test net output #1: loss = 0.0409241 (* 1 = 0.0409241 loss)
I0524 18:00:01.120280  8086 solver.cpp:228] Iteration 3600, loss = 0.0415642
I0524 18:00:01.120313  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983326
I0524 18:00:01.120321  8086 solver.cpp:244]     Train net output #1: loss = 0.0415642 (* 1 = 0.0415642 loss)
I0524 18:00:01.120324  8086 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0524 18:00:08.872318  8086 solver.cpp:228] Iteration 3620, loss = 0.0390358
I0524 18:00:08.872342  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98642
I0524 18:00:08.872349  8086 solver.cpp:244]     Train net output #1: loss = 0.0390358 (* 1 = 0.0390358 loss)
I0524 18:00:08.872354  8086 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0524 18:00:16.625798  8086 solver.cpp:228] Iteration 3640, loss = 0.0462165
I0524 18:00:16.625823  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980657
I0524 18:00:16.625828  8086 solver.cpp:244]     Train net output #1: loss = 0.0462165 (* 1 = 0.0462165 loss)
I0524 18:00:16.625833  8086 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0524 18:00:24.385284  8086 solver.cpp:228] Iteration 3660, loss = 0.0283713
I0524 18:00:24.385308  8086 solver.cpp:244]     Train net output #0: accuracy = 0.989814
I0524 18:00:24.385316  8086 solver.cpp:244]     Train net output #1: loss = 0.0283713 (* 1 = 0.0283713 loss)
I0524 18:00:24.385320  8086 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0524 18:00:32.149415  8086 solver.cpp:228] Iteration 3680, loss = 0.0459238
I0524 18:00:32.149502  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981825
I0524 18:00:32.149512  8086 solver.cpp:244]     Train net output #1: loss = 0.0459238 (* 1 = 0.0459238 loss)
I0524 18:00:32.149515  8086 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0524 18:00:39.669461  8086 solver.cpp:337] Iteration 3700, Testing net (#0)
I0524 18:00:40.181354  8086 solver.cpp:404]     Test net output #0: accuracy = 0.980124
I0524 18:00:40.181388  8086 solver.cpp:404]     Test net output #1: loss = 0.0493956 (* 1 = 0.0493956 loss)
I0524 18:00:40.412261  8086 solver.cpp:228] Iteration 3700, loss = 0.0323628
I0524 18:00:40.412282  8086 solver.cpp:244]     Train net output #0: accuracy = 0.988035
I0524 18:00:40.412289  8086 solver.cpp:244]     Train net output #1: loss = 0.0323628 (* 1 = 0.0323628 loss)
I0524 18:00:40.412294  8086 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0524 18:00:48.176563  8086 solver.cpp:228] Iteration 3720, loss = 0.0584834
I0524 18:00:48.176597  8086 solver.cpp:244]     Train net output #0: accuracy = 0.977974
I0524 18:00:48.176604  8086 solver.cpp:244]     Train net output #1: loss = 0.0584834 (* 1 = 0.0584834 loss)
I0524 18:00:48.176609  8086 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0524 18:00:55.930771  8086 solver.cpp:228] Iteration 3740, loss = 0.0463358
I0524 18:00:55.930804  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980948
I0524 18:00:55.930811  8086 solver.cpp:244]     Train net output #1: loss = 0.0463358 (* 1 = 0.0463358 loss)
I0524 18:00:55.930816  8086 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0524 18:01:03.681795  8086 solver.cpp:228] Iteration 3760, loss = 0.0415718
I0524 18:01:03.681915  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982835
I0524 18:01:03.681926  8086 solver.cpp:244]     Train net output #1: loss = 0.0415718 (* 1 = 0.0415718 loss)
I0524 18:01:03.681931  8086 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0524 18:01:11.430964  8086 solver.cpp:228] Iteration 3780, loss = 0.0374165
I0524 18:01:11.430999  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986836
I0524 18:01:11.431005  8086 solver.cpp:244]     Train net output #1: loss = 0.0374165 (* 1 = 0.0374165 loss)
I0524 18:01:11.431010  8086 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0524 18:01:18.958834  8086 solver.cpp:337] Iteration 3800, Testing net (#0)
I0524 18:01:19.470613  8086 solver.cpp:404]     Test net output #0: accuracy = 0.987024
I0524 18:01:19.470638  8086 solver.cpp:404]     Test net output #1: loss = 0.0336176 (* 1 = 0.0336176 loss)
I0524 18:01:19.699515  8086 solver.cpp:228] Iteration 3800, loss = 0.0411803
I0524 18:01:19.699538  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983992
I0524 18:01:19.699545  8086 solver.cpp:244]     Train net output #1: loss = 0.0411803 (* 1 = 0.0411803 loss)
I0524 18:01:19.699550  8086 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0524 18:01:27.445685  8086 solver.cpp:228] Iteration 3820, loss = 0.0430071
I0524 18:01:27.445708  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982128
I0524 18:01:27.445715  8086 solver.cpp:244]     Train net output #1: loss = 0.0430071 (* 1 = 0.0430071 loss)
I0524 18:01:27.445719  8086 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0524 18:01:35.188935  8086 solver.cpp:228] Iteration 3840, loss = 0.0452423
I0524 18:01:35.189031  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982099
I0524 18:01:35.189040  8086 solver.cpp:244]     Train net output #1: loss = 0.0452423 (* 1 = 0.0452423 loss)
I0524 18:01:35.189045  8086 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0524 18:01:42.935335  8086 solver.cpp:228] Iteration 3860, loss = 0.0313189
I0524 18:01:42.935359  8086 solver.cpp:244]     Train net output #0: accuracy = 0.988497
I0524 18:01:42.935366  8086 solver.cpp:244]     Train net output #1: loss = 0.0313189 (* 1 = 0.0313189 loss)
I0524 18:01:42.935370  8086 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0524 18:01:50.678978  8086 solver.cpp:228] Iteration 3880, loss = 0.0412762
I0524 18:01:50.679003  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983532
I0524 18:01:50.679011  8086 solver.cpp:244]     Train net output #1: loss = 0.0412762 (* 1 = 0.0412762 loss)
I0524 18:01:50.679016  8086 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0524 18:01:58.194636  8086 solver.cpp:337] Iteration 3900, Testing net (#0)
I0524 18:01:58.706420  8086 solver.cpp:404]     Test net output #0: accuracy = 0.982781
I0524 18:01:58.706456  8086 solver.cpp:404]     Test net output #1: loss = 0.0493944 (* 1 = 0.0493944 loss)
I0524 18:01:58.935235  8086 solver.cpp:228] Iteration 3900, loss = 0.0467345
I0524 18:01:58.935257  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98247
I0524 18:01:58.935264  8086 solver.cpp:244]     Train net output #1: loss = 0.0467345 (* 1 = 0.0467345 loss)
I0524 18:01:58.935269  8086 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0524 18:02:06.682245  8086 solver.cpp:228] Iteration 3920, loss = 0.0420912
I0524 18:02:06.682353  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983953
I0524 18:02:06.682363  8086 solver.cpp:244]     Train net output #1: loss = 0.0420912 (* 1 = 0.0420912 loss)
I0524 18:02:06.682368  8086 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0524 18:02:14.426482  8086 solver.cpp:228] Iteration 3940, loss = 0.0396498
I0524 18:02:14.426517  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983924
I0524 18:02:14.426523  8086 solver.cpp:244]     Train net output #1: loss = 0.0396498 (* 1 = 0.0396498 loss)
I0524 18:02:14.426528  8086 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0524 18:02:22.184957  8086 solver.cpp:228] Iteration 3960, loss = 0.0382316
I0524 18:02:22.184993  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984558
I0524 18:02:22.184998  8086 solver.cpp:244]     Train net output #1: loss = 0.0382316 (* 1 = 0.0382316 loss)
I0524 18:02:22.185003  8086 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0524 18:02:29.930665  8086 solver.cpp:228] Iteration 3980, loss = 0.046251
I0524 18:02:29.930688  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979903
I0524 18:02:29.930696  8086 solver.cpp:244]     Train net output #1: loss = 0.046251 (* 1 = 0.046251 loss)
I0524 18:02:29.930701  8086 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0524 18:02:37.451437  8086 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_4000.caffemodel
I0524 18:02:37.469941  8086 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_4000.solverstate
I0524 18:02:37.504706  8086 solver.cpp:337] Iteration 4000, Testing net (#0)
I0524 18:02:38.085580  8086 solver.cpp:404]     Test net output #0: accuracy = 0.978559
I0524 18:02:38.085608  8086 solver.cpp:404]     Test net output #1: loss = 0.0554361 (* 1 = 0.0554361 loss)
I0524 18:02:38.320816  8086 solver.cpp:228] Iteration 4000, loss = 0.0395268
I0524 18:02:38.320842  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985037
I0524 18:02:38.320849  8086 solver.cpp:244]     Train net output #1: loss = 0.0395268 (* 1 = 0.0395268 loss)
I0524 18:02:38.320854  8086 sgd_solver.cpp:106] Iteration 4000, lr = 0.001
I0524 18:02:46.064944  8086 solver.cpp:228] Iteration 4020, loss = 0.0295592
I0524 18:02:46.064968  8086 solver.cpp:244]     Train net output #0: accuracy = 0.989478
I0524 18:02:46.064975  8086 solver.cpp:244]     Train net output #1: loss = 0.0295592 (* 1 = 0.0295592 loss)
I0524 18:02:46.064980  8086 sgd_solver.cpp:106] Iteration 4020, lr = 0.001
I0524 18:02:53.812294  8086 solver.cpp:228] Iteration 4040, loss = 0.0436581
I0524 18:02:53.812328  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983549
I0524 18:02:53.812335  8086 solver.cpp:244]     Train net output #1: loss = 0.0436581 (* 1 = 0.0436581 loss)
I0524 18:02:53.812340  8086 sgd_solver.cpp:106] Iteration 4040, lr = 0.001
I0524 18:03:01.562784  8086 solver.cpp:228] Iteration 4060, loss = 0.0358505
I0524 18:03:01.562819  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987072
I0524 18:03:01.562825  8086 solver.cpp:244]     Train net output #1: loss = 0.0358505 (* 1 = 0.0358505 loss)
I0524 18:03:01.562830  8086 sgd_solver.cpp:106] Iteration 4060, lr = 0.001
I0524 18:03:09.306326  8086 solver.cpp:228] Iteration 4080, loss = 0.042175
I0524 18:03:09.306421  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984511
I0524 18:03:09.306430  8086 solver.cpp:244]     Train net output #1: loss = 0.042175 (* 1 = 0.042175 loss)
I0524 18:03:09.306434  8086 sgd_solver.cpp:106] Iteration 4080, lr = 0.001
I0524 18:03:16.828865  8086 solver.cpp:337] Iteration 4100, Testing net (#0)
I0524 18:03:17.342514  8086 solver.cpp:404]     Test net output #0: accuracy = 0.983669
I0524 18:03:17.342546  8086 solver.cpp:404]     Test net output #1: loss = 0.0420242 (* 1 = 0.0420242 loss)
I0524 18:03:17.571172  8086 solver.cpp:228] Iteration 4100, loss = 0.0572181
I0524 18:03:17.571208  8086 solver.cpp:244]     Train net output #0: accuracy = 0.97591
I0524 18:03:17.571214  8086 solver.cpp:244]     Train net output #1: loss = 0.0572181 (* 1 = 0.0572181 loss)
I0524 18:03:17.571218  8086 sgd_solver.cpp:106] Iteration 4100, lr = 0.001
I0524 18:03:25.313776  8086 solver.cpp:228] Iteration 4120, loss = 0.0364126
I0524 18:03:25.313808  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986087
I0524 18:03:25.313815  8086 solver.cpp:244]     Train net output #1: loss = 0.0364126 (* 1 = 0.0364126 loss)
I0524 18:03:25.313820  8086 sgd_solver.cpp:106] Iteration 4120, lr = 0.001
I0524 18:03:33.056988  8086 solver.cpp:228] Iteration 4140, loss = 0.0371492
I0524 18:03:33.057020  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986322
I0524 18:03:33.057027  8086 solver.cpp:244]     Train net output #1: loss = 0.0371492 (* 1 = 0.0371492 loss)
I0524 18:03:33.057031  8086 sgd_solver.cpp:106] Iteration 4140, lr = 0.001
I0524 18:03:40.805105  8086 solver.cpp:228] Iteration 4160, loss = 0.0432113
I0524 18:03:40.805234  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984992
I0524 18:03:40.805245  8086 solver.cpp:244]     Train net output #1: loss = 0.0432113 (* 1 = 0.0432113 loss)
I0524 18:03:40.805249  8086 sgd_solver.cpp:106] Iteration 4160, lr = 0.001
I0524 18:03:48.546880  8086 solver.cpp:228] Iteration 4180, loss = 0.0434033
I0524 18:03:48.546913  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981656
I0524 18:03:48.546921  8086 solver.cpp:244]     Train net output #1: loss = 0.0434033 (* 1 = 0.0434033 loss)
I0524 18:03:48.546926  8086 sgd_solver.cpp:106] Iteration 4180, lr = 0.001
I0524 18:03:56.064743  8086 solver.cpp:337] Iteration 4200, Testing net (#0)
I0524 18:03:56.575211  8086 solver.cpp:404]     Test net output #0: accuracy = 0.984468
I0524 18:03:56.575244  8086 solver.cpp:404]     Test net output #1: loss = 0.0418094 (* 1 = 0.0418094 loss)
I0524 18:03:56.803782  8086 solver.cpp:228] Iteration 4200, loss = 0.0522886
I0524 18:03:56.803817  8086 solver.cpp:244]     Train net output #0: accuracy = 0.975884
I0524 18:03:56.803823  8086 solver.cpp:244]     Train net output #1: loss = 0.0522886 (* 1 = 0.0522886 loss)
I0524 18:03:56.803828  8086 sgd_solver.cpp:106] Iteration 4200, lr = 0.001
I0524 18:04:04.547742  8086 solver.cpp:228] Iteration 4220, loss = 0.0499874
I0524 18:04:04.547778  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981027
I0524 18:04:04.547785  8086 solver.cpp:244]     Train net output #1: loss = 0.0499874 (* 1 = 0.0499874 loss)
I0524 18:04:04.547790  8086 sgd_solver.cpp:106] Iteration 4220, lr = 0.001
I0524 18:04:12.295492  8086 solver.cpp:228] Iteration 4240, loss = 0.0431369
I0524 18:04:12.295578  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983168
I0524 18:04:12.295586  8086 solver.cpp:244]     Train net output #1: loss = 0.0431369 (* 1 = 0.0431369 loss)
I0524 18:04:12.295591  8086 sgd_solver.cpp:106] Iteration 4240, lr = 0.001
I0524 18:04:20.039291  8086 solver.cpp:228] Iteration 4260, loss = 0.0509517
I0524 18:04:20.039329  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979605
I0524 18:04:20.039336  8086 solver.cpp:244]     Train net output #1: loss = 0.0509517 (* 1 = 0.0509517 loss)
I0524 18:04:20.039341  8086 sgd_solver.cpp:106] Iteration 4260, lr = 0.001
I0524 18:04:27.790572  8086 solver.cpp:228] Iteration 4280, loss = 0.0510325
I0524 18:04:27.790596  8086 solver.cpp:244]     Train net output #0: accuracy = 0.978569
I0524 18:04:27.790601  8086 solver.cpp:244]     Train net output #1: loss = 0.0510325 (* 1 = 0.0510325 loss)
I0524 18:04:27.790606  8086 sgd_solver.cpp:106] Iteration 4280, lr = 0.001
I0524 18:04:35.305748  8086 solver.cpp:337] Iteration 4300, Testing net (#0)
I0524 18:04:35.817937  8086 solver.cpp:404]     Test net output #0: accuracy = 0.986684
I0524 18:04:35.817961  8086 solver.cpp:404]     Test net output #1: loss = 0.0397861 (* 1 = 0.0397861 loss)
I0524 18:04:36.046677  8086 solver.cpp:228] Iteration 4300, loss = 0.0497455
I0524 18:04:36.046700  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98198
I0524 18:04:36.046706  8086 solver.cpp:244]     Train net output #1: loss = 0.0497455 (* 1 = 0.0497455 loss)
I0524 18:04:36.046711  8086 sgd_solver.cpp:106] Iteration 4300, lr = 0.001
I0524 18:04:43.787590  8086 solver.cpp:228] Iteration 4320, loss = 0.0384215
I0524 18:04:43.787703  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985674
I0524 18:04:43.787714  8086 solver.cpp:244]     Train net output #1: loss = 0.0384215 (* 1 = 0.0384215 loss)
I0524 18:04:43.787717  8086 sgd_solver.cpp:106] Iteration 4320, lr = 0.001
I0524 18:04:51.528555  8086 solver.cpp:228] Iteration 4340, loss = 0.0423309
I0524 18:04:51.528589  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98507
I0524 18:04:51.528597  8086 solver.cpp:244]     Train net output #1: loss = 0.0423309 (* 1 = 0.0423309 loss)
I0524 18:04:51.528601  8086 sgd_solver.cpp:106] Iteration 4340, lr = 0.001
I0524 18:04:59.272522  8086 solver.cpp:228] Iteration 4360, loss = 0.053128
I0524 18:04:59.272557  8086 solver.cpp:244]     Train net output #0: accuracy = 0.977189
I0524 18:04:59.272563  8086 solver.cpp:244]     Train net output #1: loss = 0.053128 (* 1 = 0.053128 loss)
I0524 18:04:59.272568  8086 sgd_solver.cpp:106] Iteration 4360, lr = 0.001
I0524 18:05:07.022464  8086 solver.cpp:228] Iteration 4380, loss = 0.0432919
I0524 18:05:07.022486  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985456
I0524 18:05:07.022495  8086 solver.cpp:244]     Train net output #1: loss = 0.0432919 (* 1 = 0.0432919 loss)
I0524 18:05:07.022498  8086 sgd_solver.cpp:106] Iteration 4380, lr = 0.001
I0524 18:05:14.523367  8086 solver.cpp:337] Iteration 4400, Testing net (#0)
I0524 18:05:15.036029  8086 solver.cpp:404]     Test net output #0: accuracy = 0.981019
I0524 18:05:15.036065  8086 solver.cpp:404]     Test net output #1: loss = 0.0496274 (* 1 = 0.0496274 loss)
I0524 18:05:15.264425  8086 solver.cpp:228] Iteration 4400, loss = 0.0469864
I0524 18:05:15.264448  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980908
I0524 18:05:15.264456  8086 solver.cpp:244]     Train net output #1: loss = 0.0469864 (* 1 = 0.0469864 loss)
I0524 18:05:15.264459  8086 sgd_solver.cpp:106] Iteration 4400, lr = 0.001
I0524 18:05:23.004531  8086 solver.cpp:228] Iteration 4420, loss = 0.0443252
I0524 18:05:23.004554  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984084
I0524 18:05:23.004571  8086 solver.cpp:244]     Train net output #1: loss = 0.0443252 (* 1 = 0.0443252 loss)
I0524 18:05:23.004575  8086 sgd_solver.cpp:106] Iteration 4420, lr = 0.001
I0524 18:05:30.746836  8086 solver.cpp:228] Iteration 4440, loss = 0.0423155
I0524 18:05:30.746870  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983674
I0524 18:05:30.746877  8086 solver.cpp:244]     Train net output #1: loss = 0.0423155 (* 1 = 0.0423155 loss)
I0524 18:05:30.746882  8086 sgd_solver.cpp:106] Iteration 4440, lr = 0.001
I0524 18:05:38.483992  8086 solver.cpp:228] Iteration 4460, loss = 0.0393618
I0524 18:05:38.484016  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984263
I0524 18:05:38.484022  8086 solver.cpp:244]     Train net output #1: loss = 0.0393618 (* 1 = 0.0393618 loss)
I0524 18:05:38.484027  8086 sgd_solver.cpp:106] Iteration 4460, lr = 0.001
I0524 18:05:46.224840  8086 solver.cpp:228] Iteration 4480, loss = 0.0432587
I0524 18:05:46.224943  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983672
I0524 18:05:46.224952  8086 solver.cpp:244]     Train net output #1: loss = 0.0432587 (* 1 = 0.0432587 loss)
I0524 18:05:46.224956  8086 sgd_solver.cpp:106] Iteration 4480, lr = 0.001
I0524 18:05:53.741381  8086 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_4500.caffemodel
I0524 18:05:53.759886  8086 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_4500.solverstate
I0524 18:05:53.768499  8086 solver.cpp:337] Iteration 4500, Testing net (#0)
I0524 18:05:54.281911  8086 solver.cpp:404]     Test net output #0: accuracy = 0.986948
I0524 18:05:54.281946  8086 solver.cpp:404]     Test net output #1: loss = 0.035138 (* 1 = 0.035138 loss)
I0524 18:05:54.510933  8086 solver.cpp:228] Iteration 4500, loss = 0.0557114
I0524 18:05:54.510967  8086 solver.cpp:244]     Train net output #0: accuracy = 0.975648
I0524 18:05:54.510974  8086 solver.cpp:244]     Train net output #1: loss = 0.0557114 (* 1 = 0.0557114 loss)
I0524 18:05:54.510978  8086 sgd_solver.cpp:106] Iteration 4500, lr = 0.001
I0524 18:06:02.253976  8086 solver.cpp:228] Iteration 4520, loss = 0.0365406
I0524 18:06:02.254010  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986721
I0524 18:06:02.254017  8086 solver.cpp:244]     Train net output #1: loss = 0.0365406 (* 1 = 0.0365406 loss)
I0524 18:06:02.254022  8086 sgd_solver.cpp:106] Iteration 4520, lr = 0.001
I0524 18:06:10.001634  8086 solver.cpp:228] Iteration 4540, loss = 0.0368152
I0524 18:06:10.001668  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986607
I0524 18:06:10.001675  8086 solver.cpp:244]     Train net output #1: loss = 0.0368152 (* 1 = 0.0368152 loss)
I0524 18:06:10.001679  8086 sgd_solver.cpp:106] Iteration 4540, lr = 0.001
I0524 18:06:17.750584  8086 solver.cpp:228] Iteration 4560, loss = 0.0429663
I0524 18:06:17.750712  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984452
I0524 18:06:17.750722  8086 solver.cpp:244]     Train net output #1: loss = 0.0429663 (* 1 = 0.0429663 loss)
I0524 18:06:17.750726  8086 sgd_solver.cpp:106] Iteration 4560, lr = 0.001
I0524 18:06:25.497879  8086 solver.cpp:228] Iteration 4580, loss = 0.0433224
I0524 18:06:25.497912  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983298
I0524 18:06:25.497920  8086 solver.cpp:244]     Train net output #1: loss = 0.0433224 (* 1 = 0.0433224 loss)
I0524 18:06:25.497923  8086 sgd_solver.cpp:106] Iteration 4580, lr = 0.001
I0524 18:06:33.011451  8086 solver.cpp:337] Iteration 4600, Testing net (#0)
I0524 18:06:33.525143  8086 solver.cpp:404]     Test net output #0: accuracy = 0.985132
I0524 18:06:33.525177  8086 solver.cpp:404]     Test net output #1: loss = 0.039744 (* 1 = 0.039744 loss)
I0524 18:06:33.755180  8086 solver.cpp:228] Iteration 4600, loss = 0.0528506
I0524 18:06:33.755204  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981613
I0524 18:06:33.755211  8086 solver.cpp:244]     Train net output #1: loss = 0.0528506 (* 1 = 0.0528506 loss)
I0524 18:06:33.755216  8086 sgd_solver.cpp:106] Iteration 4600, lr = 0.001
I0524 18:06:41.498270  8086 solver.cpp:228] Iteration 4620, loss = 0.0491684
I0524 18:06:41.498294  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980388
I0524 18:06:41.498301  8086 solver.cpp:244]     Train net output #1: loss = 0.0491684 (* 1 = 0.0491684 loss)
I0524 18:06:41.498306  8086 sgd_solver.cpp:106] Iteration 4620, lr = 0.001
I0524 18:06:49.245887  8086 solver.cpp:228] Iteration 4640, loss = 0.0291729
I0524 18:06:49.245996  8086 solver.cpp:244]     Train net output #0: accuracy = 0.992578
I0524 18:06:49.246006  8086 solver.cpp:244]     Train net output #1: loss = 0.0291729 (* 1 = 0.0291729 loss)
I0524 18:06:49.246011  8086 sgd_solver.cpp:106] Iteration 4640, lr = 0.001
I0524 18:06:56.990911  8086 solver.cpp:228] Iteration 4660, loss = 0.0432311
I0524 18:06:56.990934  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981686
I0524 18:06:56.990952  8086 solver.cpp:244]     Train net output #1: loss = 0.0432311 (* 1 = 0.0432311 loss)
I0524 18:06:56.990957  8086 sgd_solver.cpp:106] Iteration 4660, lr = 0.001
I0524 18:07:04.740659  8086 solver.cpp:228] Iteration 4680, loss = 0.0380762
I0524 18:07:04.740684  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985322
I0524 18:07:04.740690  8086 solver.cpp:244]     Train net output #1: loss = 0.0380762 (* 1 = 0.0380762 loss)
I0524 18:07:04.740695  8086 sgd_solver.cpp:106] Iteration 4680, lr = 0.001
I0524 18:07:12.261184  8086 solver.cpp:337] Iteration 4700, Testing net (#0)
I0524 18:07:12.772723  8086 solver.cpp:404]     Test net output #0: accuracy = 0.984272
I0524 18:07:12.772747  8086 solver.cpp:404]     Test net output #1: loss = 0.0406152 (* 1 = 0.0406152 loss)
I0524 18:07:13.001860  8086 solver.cpp:228] Iteration 4700, loss = 0.0417322
I0524 18:07:13.001894  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983829
I0524 18:07:13.001901  8086 solver.cpp:244]     Train net output #1: loss = 0.0417322 (* 1 = 0.0417322 loss)
I0524 18:07:13.001906  8086 sgd_solver.cpp:106] Iteration 4700, lr = 0.001
I0524 18:07:20.745312  8086 solver.cpp:228] Iteration 4720, loss = 0.0440468
I0524 18:07:20.745436  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98261
I0524 18:07:20.745446  8086 solver.cpp:244]     Train net output #1: loss = 0.0440468 (* 1 = 0.0440468 loss)
I0524 18:07:20.745451  8086 sgd_solver.cpp:106] Iteration 4720, lr = 0.001
I0524 18:07:28.497826  8086 solver.cpp:228] Iteration 4740, loss = 0.0441797
I0524 18:07:28.497861  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982872
I0524 18:07:28.497869  8086 solver.cpp:244]     Train net output #1: loss = 0.0441797 (* 1 = 0.0441797 loss)
I0524 18:07:28.497874  8086 sgd_solver.cpp:106] Iteration 4740, lr = 0.001
I0524 18:07:36.240664  8086 solver.cpp:228] Iteration 4760, loss = 0.0403975
I0524 18:07:36.240687  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983716
I0524 18:07:36.240705  8086 solver.cpp:244]     Train net output #1: loss = 0.0403975 (* 1 = 0.0403975 loss)
I0524 18:07:36.240710  8086 sgd_solver.cpp:106] Iteration 4760, lr = 0.001
I0524 18:07:43.987582  8086 solver.cpp:228] Iteration 4780, loss = 0.0321917
I0524 18:07:43.987607  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987977
I0524 18:07:43.987613  8086 solver.cpp:244]     Train net output #1: loss = 0.0321917 (* 1 = 0.0321917 loss)
I0524 18:07:43.987618  8086 sgd_solver.cpp:106] Iteration 4780, lr = 0.001
I0524 18:07:51.509131  8086 solver.cpp:337] Iteration 4800, Testing net (#0)
I0524 18:07:52.021571  8086 solver.cpp:404]     Test net output #0: accuracy = 0.984041
I0524 18:07:52.021606  8086 solver.cpp:404]     Test net output #1: loss = 0.0451874 (* 1 = 0.0451874 loss)
I0524 18:07:52.251814  8086 solver.cpp:228] Iteration 4800, loss = 0.0421996
I0524 18:07:52.251837  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985005
I0524 18:07:52.251843  8086 solver.cpp:244]     Train net output #1: loss = 0.0421996 (* 1 = 0.0421996 loss)
I0524 18:07:52.251848  8086 sgd_solver.cpp:106] Iteration 4800, lr = 0.001
I0524 18:07:59.995465  8086 solver.cpp:228] Iteration 4820, loss = 0.0399176
I0524 18:07:59.995487  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984713
I0524 18:07:59.995494  8086 solver.cpp:244]     Train net output #1: loss = 0.0399176 (* 1 = 0.0399176 loss)
I0524 18:07:59.995499  8086 sgd_solver.cpp:106] Iteration 4820, lr = 0.001
I0524 18:08:07.750221  8086 solver.cpp:228] Iteration 4840, loss = 0.0359509
I0524 18:08:07.750255  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986522
I0524 18:08:07.750262  8086 solver.cpp:244]     Train net output #1: loss = 0.0359509 (* 1 = 0.0359509 loss)
I0524 18:08:07.750267  8086 sgd_solver.cpp:106] Iteration 4840, lr = 0.001
I0524 18:08:15.498637  8086 solver.cpp:228] Iteration 4860, loss = 0.0360409
I0524 18:08:15.498672  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987263
I0524 18:08:15.498677  8086 solver.cpp:244]     Train net output #1: loss = 0.0360409 (* 1 = 0.0360409 loss)
I0524 18:08:15.498682  8086 sgd_solver.cpp:106] Iteration 4860, lr = 0.001
I0524 18:08:23.239617  8086 solver.cpp:228] Iteration 4880, loss = 0.0393094
I0524 18:08:23.239698  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98675
I0524 18:08:23.239707  8086 solver.cpp:244]     Train net output #1: loss = 0.0393094 (* 1 = 0.0393094 loss)
I0524 18:08:23.239712  8086 sgd_solver.cpp:106] Iteration 4880, lr = 0.001
I0524 18:08:30.770052  8086 solver.cpp:337] Iteration 4900, Testing net (#0)
I0524 18:08:31.282873  8086 solver.cpp:404]     Test net output #0: accuracy = 0.982683
I0524 18:08:31.282907  8086 solver.cpp:404]     Test net output #1: loss = 0.0461113 (* 1 = 0.0461113 loss)
I0524 18:08:31.511693  8086 solver.cpp:228] Iteration 4900, loss = 0.0471871
I0524 18:08:31.511729  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981341
I0524 18:08:31.511735  8086 solver.cpp:244]     Train net output #1: loss = 0.0471871 (* 1 = 0.0471871 loss)
I0524 18:08:31.511739  8086 sgd_solver.cpp:106] Iteration 4900, lr = 0.001
I0524 18:08:39.257606  8086 solver.cpp:228] Iteration 4920, loss = 0.0346012
I0524 18:08:39.257639  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985123
I0524 18:08:39.257647  8086 solver.cpp:244]     Train net output #1: loss = 0.0346012 (* 1 = 0.0346012 loss)
I0524 18:08:39.257650  8086 sgd_solver.cpp:106] Iteration 4920, lr = 0.001
I0524 18:08:47.006100  8086 solver.cpp:228] Iteration 4940, loss = 0.0510221
I0524 18:08:47.006135  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981737
I0524 18:08:47.006142  8086 solver.cpp:244]     Train net output #1: loss = 0.0510221 (* 1 = 0.0510221 loss)
I0524 18:08:47.006147  8086 sgd_solver.cpp:106] Iteration 4940, lr = 0.001
I0524 18:08:54.748363  8086 solver.cpp:228] Iteration 4960, loss = 0.0390781
I0524 18:08:54.748489  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98559
I0524 18:08:54.748499  8086 solver.cpp:244]     Train net output #1: loss = 0.0390781 (* 1 = 0.0390781 loss)
I0524 18:08:54.748504  8086 sgd_solver.cpp:106] Iteration 4960, lr = 0.001
I0524 18:09:02.495568  8086 solver.cpp:228] Iteration 4980, loss = 0.0409214
I0524 18:09:02.495592  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984627
I0524 18:09:02.495599  8086 solver.cpp:244]     Train net output #1: loss = 0.0409214 (* 1 = 0.0409214 loss)
I0524 18:09:02.495604  8086 sgd_solver.cpp:106] Iteration 4980, lr = 0.001
I0524 18:09:10.022500  8086 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_5000.caffemodel
I0524 18:09:10.041131  8086 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_5000.solverstate
I0524 18:09:10.049693  8086 solver.cpp:337] Iteration 5000, Testing net (#0)
I0524 18:09:10.566689  8086 solver.cpp:404]     Test net output #0: accuracy = 0.980964
I0524 18:09:10.566725  8086 solver.cpp:404]     Test net output #1: loss = 0.0494438 (* 1 = 0.0494438 loss)
I0524 18:09:10.796772  8086 solver.cpp:228] Iteration 5000, loss = 0.0489362
I0524 18:09:10.796795  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981277
I0524 18:09:10.796802  8086 solver.cpp:244]     Train net output #1: loss = 0.0489362 (* 1 = 0.0489362 loss)
I0524 18:09:10.796807  8086 sgd_solver.cpp:106] Iteration 5000, lr = 0.001
I0524 18:09:18.542083  8086 solver.cpp:228] Iteration 5020, loss = 0.046301
I0524 18:09:18.542117  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980684
I0524 18:09:18.542125  8086 solver.cpp:244]     Train net output #1: loss = 0.046301 (* 1 = 0.046301 loss)
I0524 18:09:18.542129  8086 sgd_solver.cpp:106] Iteration 5020, lr = 0.001
I0524 18:09:26.289343  8086 solver.cpp:228] Iteration 5040, loss = 0.0398473
I0524 18:09:26.289441  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985595
I0524 18:09:26.289450  8086 solver.cpp:244]     Train net output #1: loss = 0.0398473 (* 1 = 0.0398473 loss)
I0524 18:09:26.289454  8086 sgd_solver.cpp:106] Iteration 5040, lr = 0.001
I0524 18:09:34.033716  8086 solver.cpp:228] Iteration 5060, loss = 0.0389541
I0524 18:09:34.033749  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985927
I0524 18:09:34.033757  8086 solver.cpp:244]     Train net output #1: loss = 0.0389541 (* 1 = 0.0389541 loss)
I0524 18:09:34.033761  8086 sgd_solver.cpp:106] Iteration 5060, lr = 0.001
I0524 18:09:41.776482  8086 solver.cpp:228] Iteration 5080, loss = 0.0402103
I0524 18:09:41.776506  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986012
I0524 18:09:41.776513  8086 solver.cpp:244]     Train net output #1: loss = 0.0402103 (* 1 = 0.0402103 loss)
I0524 18:09:41.776518  8086 sgd_solver.cpp:106] Iteration 5080, lr = 0.001
I0524 18:09:49.294569  8086 solver.cpp:337] Iteration 5100, Testing net (#0)
I0524 18:09:49.805143  8086 solver.cpp:404]     Test net output #0: accuracy = 0.987045
I0524 18:09:49.805168  8086 solver.cpp:404]     Test net output #1: loss = 0.0410933 (* 1 = 0.0410933 loss)
I0524 18:09:50.035096  8086 solver.cpp:228] Iteration 5100, loss = 0.0411569
I0524 18:09:50.035120  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98332
I0524 18:09:50.035126  8086 solver.cpp:244]     Train net output #1: loss = 0.0411569 (* 1 = 0.0411569 loss)
I0524 18:09:50.035130  8086 sgd_solver.cpp:106] Iteration 5100, lr = 0.001
I0524 18:09:57.768436  8086 solver.cpp:228] Iteration 5120, loss = 0.0413528
I0524 18:09:57.768556  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983199
I0524 18:09:57.768566  8086 solver.cpp:244]     Train net output #1: loss = 0.0413528 (* 1 = 0.0413528 loss)
I0524 18:09:57.768570  8086 sgd_solver.cpp:106] Iteration 5120, lr = 0.001
I0524 18:10:05.527262  8086 solver.cpp:228] Iteration 5140, loss = 0.042664
I0524 18:10:05.527297  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986304
I0524 18:10:05.527302  8086 solver.cpp:244]     Train net output #1: loss = 0.042664 (* 1 = 0.042664 loss)
I0524 18:10:05.527307  8086 sgd_solver.cpp:106] Iteration 5140, lr = 0.001
I0524 18:10:13.282243  8086 solver.cpp:228] Iteration 5160, loss = 0.0369062
I0524 18:10:13.282277  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984705
I0524 18:10:13.282284  8086 solver.cpp:244]     Train net output #1: loss = 0.0369062 (* 1 = 0.0369062 loss)
I0524 18:10:13.282289  8086 sgd_solver.cpp:106] Iteration 5160, lr = 0.001
I0524 18:10:21.026000  8086 solver.cpp:228] Iteration 5180, loss = 0.0442073
I0524 18:10:21.026033  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981921
I0524 18:10:21.026041  8086 solver.cpp:244]     Train net output #1: loss = 0.0442073 (* 1 = 0.0442073 loss)
I0524 18:10:21.026046  8086 sgd_solver.cpp:106] Iteration 5180, lr = 0.001
I0524 18:10:28.546025  8086 solver.cpp:337] Iteration 5200, Testing net (#0)
I0524 18:10:29.058548  8086 solver.cpp:404]     Test net output #0: accuracy = 0.982497
I0524 18:10:29.058571  8086 solver.cpp:404]     Test net output #1: loss = 0.0465437 (* 1 = 0.0465437 loss)
I0524 18:10:29.288167  8086 solver.cpp:228] Iteration 5200, loss = 0.0415668
I0524 18:10:29.288190  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987213
I0524 18:10:29.288198  8086 solver.cpp:244]     Train net output #1: loss = 0.0415668 (* 1 = 0.0415668 loss)
I0524 18:10:29.288203  8086 sgd_solver.cpp:106] Iteration 5200, lr = 0.001
I0524 18:10:37.043877  8086 solver.cpp:228] Iteration 5220, loss = 0.0302778
I0524 18:10:37.043911  8086 solver.cpp:244]     Train net output #0: accuracy = 0.989552
I0524 18:10:37.043918  8086 solver.cpp:244]     Train net output #1: loss = 0.0302778 (* 1 = 0.0302778 loss)
I0524 18:10:37.043923  8086 sgd_solver.cpp:106] Iteration 5220, lr = 0.001
I0524 18:10:44.799581  8086 solver.cpp:228] Iteration 5240, loss = 0.0521611
I0524 18:10:44.799612  8086 solver.cpp:244]     Train net output #0: accuracy = 0.978866
I0524 18:10:44.799619  8086 solver.cpp:244]     Train net output #1: loss = 0.0521611 (* 1 = 0.0521611 loss)
I0524 18:10:44.799624  8086 sgd_solver.cpp:106] Iteration 5240, lr = 0.001
I0524 18:10:52.596426  8086 solver.cpp:228] Iteration 5260, loss = 0.0467406
I0524 18:10:52.596459  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983904
I0524 18:10:52.596467  8086 solver.cpp:244]     Train net output #1: loss = 0.0467406 (* 1 = 0.0467406 loss)
I0524 18:10:52.596472  8086 sgd_solver.cpp:106] Iteration 5260, lr = 0.001
I0524 18:11:00.342448  8086 solver.cpp:228] Iteration 5280, loss = 0.0480082
I0524 18:11:00.342541  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984702
I0524 18:11:00.342551  8086 solver.cpp:244]     Train net output #1: loss = 0.0480082 (* 1 = 0.0480082 loss)
I0524 18:11:00.342556  8086 sgd_solver.cpp:106] Iteration 5280, lr = 0.001
I0524 18:11:07.861482  8086 solver.cpp:337] Iteration 5300, Testing net (#0)
I0524 18:11:08.372444  8086 solver.cpp:404]     Test net output #0: accuracy = 0.980141
I0524 18:11:08.372478  8086 solver.cpp:404]     Test net output #1: loss = 0.050534 (* 1 = 0.050534 loss)
I0524 18:11:08.602047  8086 solver.cpp:228] Iteration 5300, loss = 0.0463071
I0524 18:11:08.602069  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983177
I0524 18:11:08.602077  8086 solver.cpp:244]     Train net output #1: loss = 0.0463071 (* 1 = 0.0463071 loss)
I0524 18:11:08.602080  8086 sgd_solver.cpp:106] Iteration 5300, lr = 0.001
I0524 18:11:16.346153  8086 solver.cpp:228] Iteration 5320, loss = 0.0447197
I0524 18:11:16.346177  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981135
I0524 18:11:16.346184  8086 solver.cpp:244]     Train net output #1: loss = 0.0447197 (* 1 = 0.0447197 loss)
I0524 18:11:16.346189  8086 sgd_solver.cpp:106] Iteration 5320, lr = 0.001
I0524 18:11:24.091837  8086 solver.cpp:228] Iteration 5340, loss = 0.0498478
I0524 18:11:24.091871  8086 solver.cpp:244]     Train net output #0: accuracy = 0.978002
I0524 18:11:24.091878  8086 solver.cpp:244]     Train net output #1: loss = 0.0498478 (* 1 = 0.0498478 loss)
I0524 18:11:24.091883  8086 sgd_solver.cpp:106] Iteration 5340, lr = 0.001
I0524 18:11:31.836423  8086 solver.cpp:228] Iteration 5360, loss = 0.038773
I0524 18:11:31.836547  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984587
I0524 18:11:31.836560  8086 solver.cpp:244]     Train net output #1: loss = 0.038773 (* 1 = 0.038773 loss)
I0524 18:11:31.836565  8086 sgd_solver.cpp:106] Iteration 5360, lr = 0.001
I0524 18:11:39.581652  8086 solver.cpp:228] Iteration 5380, loss = 0.0513189
I0524 18:11:39.581688  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979808
I0524 18:11:39.581696  8086 solver.cpp:244]     Train net output #1: loss = 0.0513189 (* 1 = 0.0513189 loss)
I0524 18:11:39.581701  8086 sgd_solver.cpp:106] Iteration 5380, lr = 0.001
I0524 18:11:47.100306  8086 solver.cpp:337] Iteration 5400, Testing net (#0)
I0524 18:11:47.611407  8086 solver.cpp:404]     Test net output #0: accuracy = 0.983278
I0524 18:11:47.611433  8086 solver.cpp:404]     Test net output #1: loss = 0.0410366 (* 1 = 0.0410366 loss)
I0524 18:11:47.841311  8086 solver.cpp:228] Iteration 5400, loss = 0.0495022
I0524 18:11:47.841346  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981362
I0524 18:11:47.841352  8086 solver.cpp:244]     Train net output #1: loss = 0.0495022 (* 1 = 0.0495022 loss)
I0524 18:11:47.841356  8086 sgd_solver.cpp:106] Iteration 5400, lr = 0.001
I0524 18:11:55.589704  8086 solver.cpp:228] Iteration 5420, loss = 0.0365691
I0524 18:11:55.589737  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986904
I0524 18:11:55.589745  8086 solver.cpp:244]     Train net output #1: loss = 0.0365691 (* 1 = 0.0365691 loss)
I0524 18:11:55.589750  8086 sgd_solver.cpp:106] Iteration 5420, lr = 0.001
I0524 18:12:03.327802  8086 solver.cpp:228] Iteration 5440, loss = 0.0604063
I0524 18:12:03.327904  8086 solver.cpp:244]     Train net output #0: accuracy = 0.977997
I0524 18:12:03.327913  8086 solver.cpp:244]     Train net output #1: loss = 0.0604063 (* 1 = 0.0604063 loss)
I0524 18:12:03.327919  8086 sgd_solver.cpp:106] Iteration 5440, lr = 0.001
I0524 18:12:11.075494  8086 solver.cpp:228] Iteration 5460, loss = 0.0400383
I0524 18:12:11.075517  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984385
I0524 18:12:11.075525  8086 solver.cpp:244]     Train net output #1: loss = 0.0400383 (* 1 = 0.0400383 loss)
I0524 18:12:11.075528  8086 sgd_solver.cpp:106] Iteration 5460, lr = 0.001
I0524 18:12:18.816004  8086 solver.cpp:228] Iteration 5480, loss = 0.0395189
I0524 18:12:18.816040  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984574
I0524 18:12:18.816046  8086 solver.cpp:244]     Train net output #1: loss = 0.0395189 (* 1 = 0.0395189 loss)
I0524 18:12:18.816051  8086 sgd_solver.cpp:106] Iteration 5480, lr = 0.001
I0524 18:12:26.327338  8086 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_5500.caffemodel
I0524 18:12:26.345937  8086 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_5500.solverstate
I0524 18:12:26.354473  8086 solver.cpp:337] Iteration 5500, Testing net (#0)
I0524 18:12:26.868942  8086 solver.cpp:404]     Test net output #0: accuracy = 0.9816
I0524 18:12:26.868976  8086 solver.cpp:404]     Test net output #1: loss = 0.0490801 (* 1 = 0.0490801 loss)
I0524 18:12:27.096242  8086 solver.cpp:228] Iteration 5500, loss = 0.0477045
I0524 18:12:27.096264  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979956
I0524 18:12:27.096271  8086 solver.cpp:244]     Train net output #1: loss = 0.0477045 (* 1 = 0.0477045 loss)
I0524 18:12:27.096276  8086 sgd_solver.cpp:106] Iteration 5500, lr = 0.001
I0524 18:12:34.832603  8086 solver.cpp:228] Iteration 5520, loss = 0.0296791
I0524 18:12:34.832731  8086 solver.cpp:244]     Train net output #0: accuracy = 0.99142
I0524 18:12:34.832741  8086 solver.cpp:244]     Train net output #1: loss = 0.0296791 (* 1 = 0.0296791 loss)
I0524 18:12:34.832744  8086 sgd_solver.cpp:106] Iteration 5520, lr = 0.001
I0524 18:12:42.567688  8086 solver.cpp:228] Iteration 5540, loss = 0.0466473
I0524 18:12:42.567710  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979351
I0524 18:12:42.567718  8086 solver.cpp:244]     Train net output #1: loss = 0.0466473 (* 1 = 0.0466473 loss)
I0524 18:12:42.567721  8086 sgd_solver.cpp:106] Iteration 5540, lr = 0.001
I0524 18:12:50.301440  8086 solver.cpp:228] Iteration 5560, loss = 0.038924
I0524 18:12:50.301462  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986583
I0524 18:12:50.301470  8086 solver.cpp:244]     Train net output #1: loss = 0.038924 (* 1 = 0.038924 loss)
I0524 18:12:50.301475  8086 sgd_solver.cpp:106] Iteration 5560, lr = 0.001
I0524 18:12:58.038636  8086 solver.cpp:228] Iteration 5580, loss = 0.0378805
I0524 18:12:58.038661  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984704
I0524 18:12:58.038667  8086 solver.cpp:244]     Train net output #1: loss = 0.0378805 (* 1 = 0.0378805 loss)
I0524 18:12:58.038672  8086 sgd_solver.cpp:106] Iteration 5580, lr = 0.001
I0524 18:13:05.544791  8086 solver.cpp:337] Iteration 5600, Testing net (#0)
I0524 18:13:06.059927  8086 solver.cpp:404]     Test net output #0: accuracy = 0.98524
I0524 18:13:06.059952  8086 solver.cpp:404]     Test net output #1: loss = 0.0404444 (* 1 = 0.0404444 loss)
I0524 18:13:06.288148  8086 solver.cpp:228] Iteration 5600, loss = 0.0413099
I0524 18:13:06.288182  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982626
I0524 18:13:06.288189  8086 solver.cpp:244]     Train net output #1: loss = 0.0413099 (* 1 = 0.0413099 loss)
I0524 18:13:06.288194  8086 sgd_solver.cpp:106] Iteration 5600, lr = 0.001
I0524 18:13:14.020593  8086 solver.cpp:228] Iteration 5620, loss = 0.0206581
I0524 18:13:14.020617  8086 solver.cpp:244]     Train net output #0: accuracy = 0.994605
I0524 18:13:14.020623  8086 solver.cpp:244]     Train net output #1: loss = 0.0206581 (* 1 = 0.0206581 loss)
I0524 18:13:14.020628  8086 sgd_solver.cpp:106] Iteration 5620, lr = 0.001
I0524 18:13:21.753317  8086 solver.cpp:228] Iteration 5640, loss = 0.0477762
I0524 18:13:21.753342  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98464
I0524 18:13:21.753348  8086 solver.cpp:244]     Train net output #1: loss = 0.0477762 (* 1 = 0.0477762 loss)
I0524 18:13:21.753353  8086 sgd_solver.cpp:106] Iteration 5640, lr = 0.001
I0524 18:13:29.478166  8086 solver.cpp:228] Iteration 5660, loss = 0.0402124
I0524 18:13:29.478189  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983496
I0524 18:13:29.478196  8086 solver.cpp:244]     Train net output #1: loss = 0.0402124 (* 1 = 0.0402124 loss)
I0524 18:13:29.478200  8086 sgd_solver.cpp:106] Iteration 5660, lr = 0.001
I0524 18:13:37.205001  8086 solver.cpp:228] Iteration 5680, loss = 0.0458386
I0524 18:13:37.205121  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982781
I0524 18:13:37.205132  8086 solver.cpp:244]     Train net output #1: loss = 0.0458386 (* 1 = 0.0458386 loss)
I0524 18:13:37.205137  8086 sgd_solver.cpp:106] Iteration 5680, lr = 0.001
I0524 18:13:44.762359  8086 solver.cpp:337] Iteration 5700, Testing net (#0)
I0524 18:13:45.273587  8086 solver.cpp:404]     Test net output #0: accuracy = 0.983974
I0524 18:13:45.273622  8086 solver.cpp:404]     Test net output #1: loss = 0.0440135 (* 1 = 0.0440135 loss)
I0524 18:13:45.501443  8086 solver.cpp:228] Iteration 5700, loss = 0.0306079
I0524 18:13:45.501466  8086 solver.cpp:244]     Train net output #0: accuracy = 0.989968
I0524 18:13:45.501474  8086 solver.cpp:244]     Train net output #1: loss = 0.0306079 (* 1 = 0.0306079 loss)
I0524 18:13:45.501478  8086 sgd_solver.cpp:106] Iteration 5700, lr = 0.001
I0524 18:13:53.230866  8086 solver.cpp:228] Iteration 5720, loss = 0.0344398
I0524 18:13:53.230901  8086 solver.cpp:244]     Train net output #0: accuracy = 0.989424
I0524 18:13:53.230908  8086 solver.cpp:244]     Train net output #1: loss = 0.0344398 (* 1 = 0.0344398 loss)
I0524 18:13:53.230912  8086 sgd_solver.cpp:106] Iteration 5720, lr = 0.001
I0524 18:14:00.968364  8086 solver.cpp:228] Iteration 5740, loss = 0.0582022
I0524 18:14:00.968400  8086 solver.cpp:244]     Train net output #0: accuracy = 0.976894
I0524 18:14:00.968406  8086 solver.cpp:244]     Train net output #1: loss = 0.0582022 (* 1 = 0.0582022 loss)
I0524 18:14:00.968411  8086 sgd_solver.cpp:106] Iteration 5740, lr = 0.001
I0524 18:14:08.697139  8086 solver.cpp:228] Iteration 5760, loss = 0.0438369
I0524 18:14:08.697252  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983645
I0524 18:14:08.697262  8086 solver.cpp:244]     Train net output #1: loss = 0.0438369 (* 1 = 0.0438369 loss)
I0524 18:14:08.697266  8086 sgd_solver.cpp:106] Iteration 5760, lr = 0.001
I0524 18:14:16.427494  8086 solver.cpp:228] Iteration 5780, loss = 0.0353068
I0524 18:14:16.427517  8086 solver.cpp:244]     Train net output #0: accuracy = 0.988008
I0524 18:14:16.427523  8086 solver.cpp:244]     Train net output #1: loss = 0.0353068 (* 1 = 0.0353068 loss)
I0524 18:14:16.427528  8086 sgd_solver.cpp:106] Iteration 5780, lr = 0.001
I0524 18:14:23.938807  8086 solver.cpp:337] Iteration 5800, Testing net (#0)
I0524 18:14:24.450978  8086 solver.cpp:404]     Test net output #0: accuracy = 0.983105
I0524 18:14:24.451012  8086 solver.cpp:404]     Test net output #1: loss = 0.0438494 (* 1 = 0.0438494 loss)
I0524 18:14:24.679865  8086 solver.cpp:228] Iteration 5800, loss = 0.0508846
I0524 18:14:24.679889  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984049
I0524 18:14:24.679896  8086 solver.cpp:244]     Train net output #1: loss = 0.0508846 (* 1 = 0.0508846 loss)
I0524 18:14:24.679900  8086 sgd_solver.cpp:106] Iteration 5800, lr = 0.001
I0524 18:14:32.418573  8086 solver.cpp:228] Iteration 5820, loss = 0.04827
I0524 18:14:32.418599  8086 solver.cpp:244]     Train net output #0: accuracy = 0.977055
I0524 18:14:32.418606  8086 solver.cpp:244]     Train net output #1: loss = 0.04827 (* 1 = 0.04827 loss)
I0524 18:14:32.418612  8086 sgd_solver.cpp:106] Iteration 5820, lr = 0.001
I0524 18:14:40.169834  8086 solver.cpp:228] Iteration 5840, loss = 0.0605377
I0524 18:14:40.169940  8086 solver.cpp:244]     Train net output #0: accuracy = 0.975276
I0524 18:14:40.169950  8086 solver.cpp:244]     Train net output #1: loss = 0.0605377 (* 1 = 0.0605377 loss)
I0524 18:14:40.169955  8086 sgd_solver.cpp:106] Iteration 5840, lr = 0.001
I0524 18:14:47.918828  8086 solver.cpp:228] Iteration 5860, loss = 0.0393572
I0524 18:14:47.918853  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985329
I0524 18:14:47.918861  8086 solver.cpp:244]     Train net output #1: loss = 0.0393572 (* 1 = 0.0393572 loss)
I0524 18:14:47.918866  8086 sgd_solver.cpp:106] Iteration 5860, lr = 0.001
I0524 18:14:55.664868  8086 solver.cpp:228] Iteration 5880, loss = 0.0404062
I0524 18:14:55.664891  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98331
I0524 18:14:55.664898  8086 solver.cpp:244]     Train net output #1: loss = 0.0404062 (* 1 = 0.0404062 loss)
I0524 18:14:55.664902  8086 sgd_solver.cpp:106] Iteration 5880, lr = 0.001
I0524 18:15:03.191458  8086 solver.cpp:337] Iteration 5900, Testing net (#0)
I0524 18:15:03.702460  8086 solver.cpp:404]     Test net output #0: accuracy = 0.981772
I0524 18:15:03.702496  8086 solver.cpp:404]     Test net output #1: loss = 0.0468599 (* 1 = 0.0468599 loss)
I0524 18:15:03.931457  8086 solver.cpp:228] Iteration 5900, loss = 0.0368479
I0524 18:15:03.931483  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986366
I0524 18:15:03.931490  8086 solver.cpp:244]     Train net output #1: loss = 0.0368479 (* 1 = 0.0368479 loss)
I0524 18:15:03.931495  8086 sgd_solver.cpp:106] Iteration 5900, lr = 0.001
I0524 18:15:11.678863  8086 solver.cpp:228] Iteration 5920, loss = 0.0475835
I0524 18:15:11.678979  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98056
I0524 18:15:11.678989  8086 solver.cpp:244]     Train net output #1: loss = 0.0475835 (* 1 = 0.0475835 loss)
I0524 18:15:11.678994  8086 sgd_solver.cpp:106] Iteration 5920, lr = 0.001
I0524 18:15:19.430824  8086 solver.cpp:228] Iteration 5940, loss = 0.0375857
I0524 18:15:19.430860  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986276
I0524 18:15:19.430867  8086 solver.cpp:244]     Train net output #1: loss = 0.0375857 (* 1 = 0.0375857 loss)
I0524 18:15:19.430871  8086 sgd_solver.cpp:106] Iteration 5940, lr = 0.001
I0524 18:15:27.180685  8086 solver.cpp:228] Iteration 5960, loss = 0.0419647
I0524 18:15:27.180721  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98201
I0524 18:15:27.180728  8086 solver.cpp:244]     Train net output #1: loss = 0.0419647 (* 1 = 0.0419647 loss)
I0524 18:15:27.180733  8086 sgd_solver.cpp:106] Iteration 5960, lr = 0.001
I0524 18:15:34.925153  8086 solver.cpp:228] Iteration 5980, loss = 0.0540025
I0524 18:15:34.925179  8086 solver.cpp:244]     Train net output #0: accuracy = 0.978148
I0524 18:15:34.925185  8086 solver.cpp:244]     Train net output #1: loss = 0.0540025 (* 1 = 0.0540025 loss)
I0524 18:15:34.925189  8086 sgd_solver.cpp:106] Iteration 5980, lr = 0.001
I0524 18:15:42.444169  8086 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_6000.caffemodel
I0524 18:15:42.486230  8086 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_6000.solverstate
I0524 18:15:42.505878  8086 solver.cpp:337] Iteration 6000, Testing net (#0)
I0524 18:15:43.071408  8086 solver.cpp:404]     Test net output #0: accuracy = 0.987781
I0524 18:15:43.071434  8086 solver.cpp:404]     Test net output #1: loss = 0.0390406 (* 1 = 0.0390406 loss)
I0524 18:15:43.306051  8086 solver.cpp:228] Iteration 6000, loss = 0.0430565
I0524 18:15:43.306074  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981686
I0524 18:15:43.306082  8086 solver.cpp:244]     Train net output #1: loss = 0.0430565 (* 1 = 0.0430565 loss)
I0524 18:15:43.306087  8086 sgd_solver.cpp:106] Iteration 6000, lr = 0.0001
I0524 18:15:51.053611  8086 solver.cpp:228] Iteration 6020, loss = 0.0483161
I0524 18:15:51.053647  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982258
I0524 18:15:51.053654  8086 solver.cpp:244]     Train net output #1: loss = 0.0483161 (* 1 = 0.0483161 loss)
I0524 18:15:51.053658  8086 sgd_solver.cpp:106] Iteration 6020, lr = 0.0001
I0524 18:15:58.809080  8086 solver.cpp:228] Iteration 6040, loss = 0.0493045
I0524 18:15:58.809103  8086 solver.cpp:244]     Train net output #0: accuracy = 0.978938
I0524 18:15:58.809110  8086 solver.cpp:244]     Train net output #1: loss = 0.0493045 (* 1 = 0.0493045 loss)
I0524 18:15:58.809114  8086 sgd_solver.cpp:106] Iteration 6040, lr = 0.0001
I0524 18:16:06.548069  8086 solver.cpp:228] Iteration 6060, loss = 0.0335543
I0524 18:16:06.548090  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985565
I0524 18:16:06.548097  8086 solver.cpp:244]     Train net output #1: loss = 0.0335543 (* 1 = 0.0335543 loss)
I0524 18:16:06.548102  8086 sgd_solver.cpp:106] Iteration 6060, lr = 0.0001
I0524 18:16:14.290393  8086 solver.cpp:228] Iteration 6080, loss = 0.0382192
I0524 18:16:14.290510  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984859
I0524 18:16:14.290520  8086 solver.cpp:244]     Train net output #1: loss = 0.0382192 (* 1 = 0.0382192 loss)
I0524 18:16:14.290525  8086 sgd_solver.cpp:106] Iteration 6080, lr = 0.0001
I0524 18:16:21.809263  8086 solver.cpp:337] Iteration 6100, Testing net (#0)
I0524 18:16:22.321651  8086 solver.cpp:404]     Test net output #0: accuracy = 0.97942
I0524 18:16:22.321686  8086 solver.cpp:404]     Test net output #1: loss = 0.0533574 (* 1 = 0.0533574 loss)
I0524 18:16:22.550547  8086 solver.cpp:228] Iteration 6100, loss = 0.0478753
I0524 18:16:22.550570  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982976
I0524 18:16:22.550575  8086 solver.cpp:244]     Train net output #1: loss = 0.0478753 (* 1 = 0.0478753 loss)
I0524 18:16:22.550580  8086 sgd_solver.cpp:106] Iteration 6100, lr = 0.0001
I0524 18:16:30.296264  8086 solver.cpp:228] Iteration 6120, loss = 0.0450233
I0524 18:16:30.296300  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979984
I0524 18:16:30.296308  8086 solver.cpp:244]     Train net output #1: loss = 0.0450233 (* 1 = 0.0450233 loss)
I0524 18:16:30.296313  8086 sgd_solver.cpp:106] Iteration 6120, lr = 0.0001
I0524 18:16:38.042264  8086 solver.cpp:228] Iteration 6140, loss = 0.0435567
I0524 18:16:38.042289  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981943
I0524 18:16:38.042296  8086 solver.cpp:244]     Train net output #1: loss = 0.0435567 (* 1 = 0.0435567 loss)
I0524 18:16:38.042300  8086 sgd_solver.cpp:106] Iteration 6140, lr = 0.0001
I0524 18:16:45.786486  8086 solver.cpp:228] Iteration 6160, loss = 0.0433942
I0524 18:16:45.786582  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986477
I0524 18:16:45.786592  8086 solver.cpp:244]     Train net output #1: loss = 0.0433942 (* 1 = 0.0433942 loss)
I0524 18:16:45.786597  8086 sgd_solver.cpp:106] Iteration 6160, lr = 0.0001
I0524 18:16:53.531312  8086 solver.cpp:228] Iteration 6180, loss = 0.0452206
I0524 18:16:53.531352  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980378
I0524 18:16:53.531359  8086 solver.cpp:244]     Train net output #1: loss = 0.0452206 (* 1 = 0.0452206 loss)
I0524 18:16:53.531363  8086 sgd_solver.cpp:106] Iteration 6180, lr = 0.0001
I0524 18:17:01.053920  8086 solver.cpp:337] Iteration 6200, Testing net (#0)
I0524 18:17:01.565189  8086 solver.cpp:404]     Test net output #0: accuracy = 0.983961
I0524 18:17:01.565224  8086 solver.cpp:404]     Test net output #1: loss = 0.0391618 (* 1 = 0.0391618 loss)
I0524 18:17:01.794210  8086 solver.cpp:228] Iteration 6200, loss = 0.0381951
I0524 18:17:01.794245  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985608
I0524 18:17:01.794252  8086 solver.cpp:244]     Train net output #1: loss = 0.0381951 (* 1 = 0.0381951 loss)
I0524 18:17:01.794256  8086 sgd_solver.cpp:106] Iteration 6200, lr = 0.0001
I0524 18:17:09.542578  8086 solver.cpp:228] Iteration 6220, loss = 0.0511721
I0524 18:17:09.542613  8086 solver.cpp:244]     Train net output #0: accuracy = 0.978938
I0524 18:17:09.542619  8086 solver.cpp:244]     Train net output #1: loss = 0.0511721 (* 1 = 0.0511721 loss)
I0524 18:17:09.542624  8086 sgd_solver.cpp:106] Iteration 6220, lr = 0.0001
I0524 18:17:17.291883  8086 solver.cpp:228] Iteration 6240, loss = 0.04647
I0524 18:17:17.291980  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983189
I0524 18:17:17.291990  8086 solver.cpp:244]     Train net output #1: loss = 0.04647 (* 1 = 0.04647 loss)
I0524 18:17:17.291993  8086 sgd_solver.cpp:106] Iteration 6240, lr = 0.0001
I0524 18:17:25.036659  8086 solver.cpp:228] Iteration 6260, loss = 0.0410903
I0524 18:17:25.036684  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985294
I0524 18:17:25.036692  8086 solver.cpp:244]     Train net output #1: loss = 0.0410903 (* 1 = 0.0410903 loss)
I0524 18:17:25.036696  8086 sgd_solver.cpp:106] Iteration 6260, lr = 0.0001
I0524 18:17:32.785666  8086 solver.cpp:228] Iteration 6280, loss = 0.0220647
I0524 18:17:32.785701  8086 solver.cpp:244]     Train net output #0: accuracy = 0.993983
I0524 18:17:32.785708  8086 solver.cpp:244]     Train net output #1: loss = 0.0220647 (* 1 = 0.0220647 loss)
I0524 18:17:32.785713  8086 sgd_solver.cpp:106] Iteration 6280, lr = 0.0001
I0524 18:17:40.301453  8086 solver.cpp:337] Iteration 6300, Testing net (#0)
I0524 18:17:40.815840  8086 solver.cpp:404]     Test net output #0: accuracy = 0.982769
I0524 18:17:40.815865  8086 solver.cpp:404]     Test net output #1: loss = 0.0444097 (* 1 = 0.0444097 loss)
I0524 18:17:41.045949  8086 solver.cpp:228] Iteration 6300, loss = 0.0473182
I0524 18:17:41.045971  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980142
I0524 18:17:41.045979  8086 solver.cpp:244]     Train net output #1: loss = 0.0473182 (* 1 = 0.0473182 loss)
I0524 18:17:41.045984  8086 sgd_solver.cpp:106] Iteration 6300, lr = 0.0001
I0524 18:17:48.794523  8086 solver.cpp:228] Iteration 6320, loss = 0.0429235
I0524 18:17:48.794631  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983144
I0524 18:17:48.794641  8086 solver.cpp:244]     Train net output #1: loss = 0.0429236 (* 1 = 0.0429236 loss)
I0524 18:17:48.794646  8086 sgd_solver.cpp:106] Iteration 6320, lr = 0.0001
I0524 18:17:56.537762  8086 solver.cpp:228] Iteration 6340, loss = 0.0416039
I0524 18:17:56.537784  8086 solver.cpp:244]     Train net output #0: accuracy = 0.9853
I0524 18:17:56.537791  8086 solver.cpp:244]     Train net output #1: loss = 0.0416039 (* 1 = 0.0416039 loss)
I0524 18:17:56.537796  8086 sgd_solver.cpp:106] Iteration 6340, lr = 0.0001
I0524 18:18:04.290889  8086 solver.cpp:228] Iteration 6360, loss = 0.0522675
I0524 18:18:04.290925  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980019
I0524 18:18:04.290933  8086 solver.cpp:244]     Train net output #1: loss = 0.0522675 (* 1 = 0.0522675 loss)
I0524 18:18:04.290938  8086 sgd_solver.cpp:106] Iteration 6360, lr = 0.0001
I0524 18:18:12.038043  8086 solver.cpp:228] Iteration 6380, loss = 0.0485678
I0524 18:18:12.038069  8086 solver.cpp:244]     Train net output #0: accuracy = 0.978785
I0524 18:18:12.038076  8086 solver.cpp:244]     Train net output #1: loss = 0.0485678 (* 1 = 0.0485678 loss)
I0524 18:18:12.038081  8086 sgd_solver.cpp:106] Iteration 6380, lr = 0.0001
I0524 18:18:19.555296  8086 solver.cpp:337] Iteration 6400, Testing net (#0)
I0524 18:18:20.069227  8086 solver.cpp:404]     Test net output #0: accuracy = 0.983719
I0524 18:18:20.069264  8086 solver.cpp:404]     Test net output #1: loss = 0.0422324 (* 1 = 0.0422324 loss)
I0524 18:18:20.298818  8086 solver.cpp:228] Iteration 6400, loss = 0.0383772
I0524 18:18:20.298853  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985631
I0524 18:18:20.298861  8086 solver.cpp:244]     Train net output #1: loss = 0.0383772 (* 1 = 0.0383772 loss)
I0524 18:18:20.298866  8086 sgd_solver.cpp:106] Iteration 6400, lr = 0.0001
I0524 18:18:28.042027  8086 solver.cpp:228] Iteration 6420, loss = 0.0476561
I0524 18:18:28.042062  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98053
I0524 18:18:28.042070  8086 solver.cpp:244]     Train net output #1: loss = 0.0476561 (* 1 = 0.0476561 loss)
I0524 18:18:28.042074  8086 sgd_solver.cpp:106] Iteration 6420, lr = 0.0001
I0524 18:18:35.785094  8086 solver.cpp:228] Iteration 6440, loss = 0.0430716
I0524 18:18:35.785130  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983274
I0524 18:18:35.785136  8086 solver.cpp:244]     Train net output #1: loss = 0.0430716 (* 1 = 0.0430716 loss)
I0524 18:18:35.785141  8086 sgd_solver.cpp:106] Iteration 6440, lr = 0.0001
I0524 18:18:43.535747  8086 solver.cpp:228] Iteration 6460, loss = 0.0275658
I0524 18:18:43.535783  8086 solver.cpp:244]     Train net output #0: accuracy = 0.990299
I0524 18:18:43.535789  8086 solver.cpp:244]     Train net output #1: loss = 0.0275658 (* 1 = 0.0275658 loss)
I0524 18:18:43.535794  8086 sgd_solver.cpp:106] Iteration 6460, lr = 0.0001
I0524 18:18:51.279358  8086 solver.cpp:228] Iteration 6480, loss = 0.0532141
I0524 18:18:51.279474  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979632
I0524 18:18:51.279484  8086 solver.cpp:244]     Train net output #1: loss = 0.0532141 (* 1 = 0.0532141 loss)
I0524 18:18:51.279489  8086 sgd_solver.cpp:106] Iteration 6480, lr = 0.0001
I0524 18:18:58.799574  8086 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_6500.caffemodel
I0524 18:18:58.817970  8086 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_6500.solverstate
I0524 18:18:58.826457  8086 solver.cpp:337] Iteration 6500, Testing net (#0)
I0524 18:18:59.341238  8086 solver.cpp:404]     Test net output #0: accuracy = 0.982643
I0524 18:18:59.341272  8086 solver.cpp:404]     Test net output #1: loss = 0.0437756 (* 1 = 0.0437756 loss)
I0524 18:18:59.572294  8086 solver.cpp:228] Iteration 6500, loss = 0.0384386
I0524 18:18:59.572329  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984815
I0524 18:18:59.572335  8086 solver.cpp:244]     Train net output #1: loss = 0.0384386 (* 1 = 0.0384386 loss)
I0524 18:18:59.572340  8086 sgd_solver.cpp:106] Iteration 6500, lr = 0.0001
I0524 18:19:07.311090  8086 solver.cpp:228] Iteration 6520, loss = 0.0437218
I0524 18:19:07.311125  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980074
I0524 18:19:07.311132  8086 solver.cpp:244]     Train net output #1: loss = 0.0437218 (* 1 = 0.0437218 loss)
I0524 18:19:07.311136  8086 sgd_solver.cpp:106] Iteration 6520, lr = 0.0001
I0524 18:19:15.053462  8086 solver.cpp:228] Iteration 6540, loss = 0.0433397
I0524 18:19:15.053489  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983158
I0524 18:19:15.053496  8086 solver.cpp:244]     Train net output #1: loss = 0.0433397 (* 1 = 0.0433397 loss)
I0524 18:19:15.053501  8086 sgd_solver.cpp:106] Iteration 6540, lr = 0.0001
I0524 18:19:22.803529  8086 solver.cpp:228] Iteration 6560, loss = 0.0410031
I0524 18:19:22.803617  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983392
I0524 18:19:22.803627  8086 solver.cpp:244]     Train net output #1: loss = 0.0410031 (* 1 = 0.0410031 loss)
I0524 18:19:22.803632  8086 sgd_solver.cpp:106] Iteration 6560, lr = 0.0001
I0524 18:19:30.550276  8086 solver.cpp:228] Iteration 6580, loss = 0.0326587
I0524 18:19:30.550310  8086 solver.cpp:244]     Train net output #0: accuracy = 0.988913
I0524 18:19:30.550318  8086 solver.cpp:244]     Train net output #1: loss = 0.0326587 (* 1 = 0.0326587 loss)
I0524 18:19:30.550321  8086 sgd_solver.cpp:106] Iteration 6580, lr = 0.0001
I0524 18:19:38.066685  8086 solver.cpp:337] Iteration 6600, Testing net (#0)
I0524 18:19:38.578541  8086 solver.cpp:404]     Test net output #0: accuracy = 0.981785
I0524 18:19:38.578575  8086 solver.cpp:404]     Test net output #1: loss = 0.0452384 (* 1 = 0.0452384 loss)
I0524 18:19:38.807375  8086 solver.cpp:228] Iteration 6600, loss = 0.0349543
I0524 18:19:38.807397  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986521
I0524 18:19:38.807404  8086 solver.cpp:244]     Train net output #1: loss = 0.0349543 (* 1 = 0.0349543 loss)
I0524 18:19:38.807409  8086 sgd_solver.cpp:106] Iteration 6600, lr = 0.0001
I0524 18:19:46.553129  8086 solver.cpp:228] Iteration 6620, loss = 0.034945
I0524 18:19:46.553164  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986143
I0524 18:19:46.553171  8086 solver.cpp:244]     Train net output #1: loss = 0.034945 (* 1 = 0.034945 loss)
I0524 18:19:46.553175  8086 sgd_solver.cpp:106] Iteration 6620, lr = 0.0001
I0524 18:19:54.297142  8086 solver.cpp:228] Iteration 6640, loss = 0.0349638
I0524 18:19:54.297242  8086 solver.cpp:244]     Train net output #0: accuracy = 0.988024
I0524 18:19:54.297251  8086 solver.cpp:244]     Train net output #1: loss = 0.0349638 (* 1 = 0.0349638 loss)
I0524 18:19:54.297256  8086 sgd_solver.cpp:106] Iteration 6640, lr = 0.0001
I0524 18:20:02.046077  8086 solver.cpp:228] Iteration 6660, loss = 0.0588182
I0524 18:20:02.046100  8086 solver.cpp:244]     Train net output #0: accuracy = 0.973206
I0524 18:20:02.046108  8086 solver.cpp:244]     Train net output #1: loss = 0.0588182 (* 1 = 0.0588182 loss)
I0524 18:20:02.046111  8086 sgd_solver.cpp:106] Iteration 6660, lr = 0.0001
I0524 18:20:09.796793  8086 solver.cpp:228] Iteration 6680, loss = 0.0442596
I0524 18:20:09.796828  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984054
I0524 18:20:09.796835  8086 solver.cpp:244]     Train net output #1: loss = 0.0442596 (* 1 = 0.0442596 loss)
I0524 18:20:09.796840  8086 sgd_solver.cpp:106] Iteration 6680, lr = 0.0001
I0524 18:20:17.316309  8086 solver.cpp:337] Iteration 6700, Testing net (#0)
I0524 18:20:17.828414  8086 solver.cpp:404]     Test net output #0: accuracy = 0.982372
I0524 18:20:17.828449  8086 solver.cpp:404]     Test net output #1: loss = 0.0491887 (* 1 = 0.0491887 loss)
I0524 18:20:18.057477  8086 solver.cpp:228] Iteration 6700, loss = 0.0371894
I0524 18:20:18.057510  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985269
I0524 18:20:18.057518  8086 solver.cpp:244]     Train net output #1: loss = 0.0371894 (* 1 = 0.0371894 loss)
I0524 18:20:18.057523  8086 sgd_solver.cpp:106] Iteration 6700, lr = 0.0001
I0524 18:20:25.805127  8086 solver.cpp:228] Iteration 6720, loss = 0.0432026
I0524 18:20:25.805239  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982873
I0524 18:20:25.805249  8086 solver.cpp:244]     Train net output #1: loss = 0.0432026 (* 1 = 0.0432026 loss)
I0524 18:20:25.805254  8086 sgd_solver.cpp:106] Iteration 6720, lr = 0.0001
I0524 18:20:33.549288  8086 solver.cpp:228] Iteration 6740, loss = 0.0426025
I0524 18:20:33.549322  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983827
I0524 18:20:33.549329  8086 solver.cpp:244]     Train net output #1: loss = 0.0426025 (* 1 = 0.0426025 loss)
I0524 18:20:33.549335  8086 sgd_solver.cpp:106] Iteration 6740, lr = 0.0001
I0524 18:20:41.292058  8086 solver.cpp:228] Iteration 6760, loss = 0.0531111
I0524 18:20:41.292093  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980668
I0524 18:20:41.292099  8086 solver.cpp:244]     Train net output #1: loss = 0.0531112 (* 1 = 0.0531112 loss)
I0524 18:20:41.292104  8086 sgd_solver.cpp:106] Iteration 6760, lr = 0.0001
I0524 18:20:49.036162  8086 solver.cpp:228] Iteration 6780, loss = 0.0429881
I0524 18:20:49.036198  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983745
I0524 18:20:49.036206  8086 solver.cpp:244]     Train net output #1: loss = 0.0429881 (* 1 = 0.0429881 loss)
I0524 18:20:49.036211  8086 sgd_solver.cpp:106] Iteration 6780, lr = 0.0001
I0524 18:20:56.557032  8086 solver.cpp:337] Iteration 6800, Testing net (#0)
I0524 18:20:57.069414  8086 solver.cpp:404]     Test net output #0: accuracy = 0.976244
I0524 18:20:57.069449  8086 solver.cpp:404]     Test net output #1: loss = 0.0574644 (* 1 = 0.0574644 loss)
I0524 18:20:57.298954  8086 solver.cpp:228] Iteration 6800, loss = 0.0457556
I0524 18:20:57.298979  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981361
I0524 18:20:57.298985  8086 solver.cpp:244]     Train net output #1: loss = 0.0457556 (* 1 = 0.0457556 loss)
I0524 18:20:57.298990  8086 sgd_solver.cpp:106] Iteration 6800, lr = 0.0001
I0524 18:21:05.059053  8086 solver.cpp:228] Iteration 6820, loss = 0.0580307
I0524 18:21:05.059087  8086 solver.cpp:244]     Train net output #0: accuracy = 0.974959
I0524 18:21:05.059094  8086 solver.cpp:244]     Train net output #1: loss = 0.0580307 (* 1 = 0.0580307 loss)
I0524 18:21:05.059099  8086 sgd_solver.cpp:106] Iteration 6820, lr = 0.0001
I0524 18:21:12.810422  8086 solver.cpp:228] Iteration 6840, loss = 0.0439496
I0524 18:21:12.810446  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984431
I0524 18:21:12.810452  8086 solver.cpp:244]     Train net output #1: loss = 0.0439496 (* 1 = 0.0439496 loss)
I0524 18:21:12.810457  8086 sgd_solver.cpp:106] Iteration 6840, lr = 0.0001
I0524 18:21:20.553738  8086 solver.cpp:228] Iteration 6860, loss = 0.0322223
I0524 18:21:20.553762  8086 solver.cpp:244]     Train net output #0: accuracy = 0.988847
I0524 18:21:20.553769  8086 solver.cpp:244]     Train net output #1: loss = 0.0322223 (* 1 = 0.0322223 loss)
I0524 18:21:20.553773  8086 sgd_solver.cpp:106] Iteration 6860, lr = 0.0001
I0524 18:21:28.322319  8086 solver.cpp:228] Iteration 6880, loss = 0.0518739
I0524 18:21:28.322444  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979993
I0524 18:21:28.322454  8086 solver.cpp:244]     Train net output #1: loss = 0.0518739 (* 1 = 0.0518739 loss)
I0524 18:21:28.322458  8086 sgd_solver.cpp:106] Iteration 6880, lr = 0.0001
I0524 18:21:35.840059  8086 solver.cpp:337] Iteration 6900, Testing net (#0)
I0524 18:21:36.352264  8086 solver.cpp:404]     Test net output #0: accuracy = 0.985267
I0524 18:21:36.352288  8086 solver.cpp:404]     Test net output #1: loss = 0.0396863 (* 1 = 0.0396863 loss)
I0524 18:21:36.582422  8086 solver.cpp:228] Iteration 6900, loss = 0.0401898
I0524 18:21:36.582445  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983471
I0524 18:21:36.582453  8086 solver.cpp:244]     Train net output #1: loss = 0.0401898 (* 1 = 0.0401898 loss)
I0524 18:21:36.582456  8086 sgd_solver.cpp:106] Iteration 6900, lr = 0.0001
I0524 18:21:44.328989  8086 solver.cpp:228] Iteration 6920, loss = 0.0313264
I0524 18:21:44.329023  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987998
I0524 18:21:44.329030  8086 solver.cpp:244]     Train net output #1: loss = 0.0313264 (* 1 = 0.0313264 loss)
I0524 18:21:44.329035  8086 sgd_solver.cpp:106] Iteration 6920, lr = 0.0001
I0524 18:21:52.079823  8086 solver.cpp:228] Iteration 6940, loss = 0.038626
I0524 18:21:52.079846  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985225
I0524 18:21:52.079854  8086 solver.cpp:244]     Train net output #1: loss = 0.038626 (* 1 = 0.038626 loss)
I0524 18:21:52.079859  8086 sgd_solver.cpp:106] Iteration 6940, lr = 0.0001
I0524 18:21:59.822374  8086 solver.cpp:228] Iteration 6960, loss = 0.0453598
I0524 18:21:59.822474  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982678
I0524 18:21:59.822484  8086 solver.cpp:244]     Train net output #1: loss = 0.0453598 (* 1 = 0.0453598 loss)
I0524 18:21:59.822489  8086 sgd_solver.cpp:106] Iteration 6960, lr = 0.0001
I0524 18:22:07.577569  8086 solver.cpp:228] Iteration 6980, loss = 0.0392087
I0524 18:22:07.577592  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987521
I0524 18:22:07.577610  8086 solver.cpp:244]     Train net output #1: loss = 0.0392087 (* 1 = 0.0392087 loss)
I0524 18:22:07.577615  8086 sgd_solver.cpp:106] Iteration 6980, lr = 0.0001
I0524 18:22:15.090474  8086 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_7000.caffemodel
I0524 18:22:15.108922  8086 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_7000.solverstate
I0524 18:22:15.117318  8086 solver.cpp:337] Iteration 7000, Testing net (#0)
I0524 18:22:15.635146  8086 solver.cpp:404]     Test net output #0: accuracy = 0.984159
I0524 18:22:15.635171  8086 solver.cpp:404]     Test net output #1: loss = 0.0456731 (* 1 = 0.0456731 loss)
I0524 18:22:15.864627  8086 solver.cpp:228] Iteration 7000, loss = 0.0363488
I0524 18:22:15.864662  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986115
I0524 18:22:15.864670  8086 solver.cpp:244]     Train net output #1: loss = 0.0363488 (* 1 = 0.0363488 loss)
I0524 18:22:15.864673  8086 sgd_solver.cpp:106] Iteration 7000, lr = 0.0001
I0524 18:22:23.609906  8086 solver.cpp:228] Iteration 7020, loss = 0.0438805
I0524 18:22:23.609941  8086 solver.cpp:244]     Train net output #0: accuracy = 0.9829
I0524 18:22:23.609949  8086 solver.cpp:244]     Train net output #1: loss = 0.0438805 (* 1 = 0.0438805 loss)
I0524 18:22:23.609953  8086 sgd_solver.cpp:106] Iteration 7020, lr = 0.0001
I0524 18:22:31.355764  8086 solver.cpp:228] Iteration 7040, loss = 0.0380628
I0524 18:22:31.355866  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984108
I0524 18:22:31.355875  8086 solver.cpp:244]     Train net output #1: loss = 0.0380628 (* 1 = 0.0380628 loss)
I0524 18:22:31.355880  8086 sgd_solver.cpp:106] Iteration 7040, lr = 0.0001
I0524 18:22:39.100661  8086 solver.cpp:228] Iteration 7060, loss = 0.0450446
I0524 18:22:39.100685  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982999
I0524 18:22:39.100692  8086 solver.cpp:244]     Train net output #1: loss = 0.0450446 (* 1 = 0.0450446 loss)
I0524 18:22:39.100697  8086 sgd_solver.cpp:106] Iteration 7060, lr = 0.0001
I0524 18:22:46.850983  8086 solver.cpp:228] Iteration 7080, loss = 0.0432382
I0524 18:22:46.851017  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983967
I0524 18:22:46.851024  8086 solver.cpp:244]     Train net output #1: loss = 0.0432382 (* 1 = 0.0432382 loss)
I0524 18:22:46.851028  8086 sgd_solver.cpp:106] Iteration 7080, lr = 0.0001
I0524 18:22:54.364996  8086 solver.cpp:337] Iteration 7100, Testing net (#0)
I0524 18:22:54.875711  8086 solver.cpp:404]     Test net output #0: accuracy = 0.986386
I0524 18:22:54.875744  8086 solver.cpp:404]     Test net output #1: loss = 0.0415823 (* 1 = 0.0415823 loss)
I0524 18:22:55.104389  8086 solver.cpp:228] Iteration 7100, loss = 0.0640368
I0524 18:22:55.104423  8086 solver.cpp:244]     Train net output #0: accuracy = 0.977063
I0524 18:22:55.104430  8086 solver.cpp:244]     Train net output #1: loss = 0.0640368 (* 1 = 0.0640368 loss)
I0524 18:22:55.104435  8086 sgd_solver.cpp:106] Iteration 7100, lr = 0.0001
I0524 18:23:02.853929  8086 solver.cpp:228] Iteration 7120, loss = 0.0375449
I0524 18:23:02.854056  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985404
I0524 18:23:02.854066  8086 solver.cpp:244]     Train net output #1: loss = 0.0375449 (* 1 = 0.0375449 loss)
I0524 18:23:02.854071  8086 sgd_solver.cpp:106] Iteration 7120, lr = 0.0001
I0524 18:23:10.600100  8086 solver.cpp:228] Iteration 7140, loss = 0.0319349
I0524 18:23:10.600126  8086 solver.cpp:244]     Train net output #0: accuracy = 0.99082
I0524 18:23:10.600132  8086 solver.cpp:244]     Train net output #1: loss = 0.0319349 (* 1 = 0.0319349 loss)
I0524 18:23:10.600137  8086 sgd_solver.cpp:106] Iteration 7140, lr = 0.0001
I0524 18:23:18.346020  8086 solver.cpp:228] Iteration 7160, loss = 0.0457723
I0524 18:23:18.346045  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983453
I0524 18:23:18.346051  8086 solver.cpp:244]     Train net output #1: loss = 0.0457723 (* 1 = 0.0457723 loss)
I0524 18:23:18.346056  8086 sgd_solver.cpp:106] Iteration 7160, lr = 0.0001
I0524 18:23:26.094475  8086 solver.cpp:228] Iteration 7180, loss = 0.04385
I0524 18:23:26.094501  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980981
I0524 18:23:26.094507  8086 solver.cpp:244]     Train net output #1: loss = 0.04385 (* 1 = 0.04385 loss)
I0524 18:23:26.094511  8086 sgd_solver.cpp:106] Iteration 7180, lr = 0.0001
I0524 18:23:33.613612  8086 solver.cpp:337] Iteration 7200, Testing net (#0)
I0524 18:23:34.125707  8086 solver.cpp:404]     Test net output #0: accuracy = 0.985215
I0524 18:23:34.125741  8086 solver.cpp:404]     Test net output #1: loss = 0.0384651 (* 1 = 0.0384651 loss)
I0524 18:23:34.355533  8086 solver.cpp:228] Iteration 7200, loss = 0.0452702
I0524 18:23:34.355567  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981446
I0524 18:23:34.355574  8086 solver.cpp:244]     Train net output #1: loss = 0.0452703 (* 1 = 0.0452703 loss)
I0524 18:23:34.355578  8086 sgd_solver.cpp:106] Iteration 7200, lr = 0.0001
I0524 18:23:42.101888  8086 solver.cpp:228] Iteration 7220, loss = 0.0413767
I0524 18:23:42.101922  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982824
I0524 18:23:42.101929  8086 solver.cpp:244]     Train net output #1: loss = 0.0413767 (* 1 = 0.0413767 loss)
I0524 18:23:42.101935  8086 sgd_solver.cpp:106] Iteration 7220, lr = 0.0001
I0524 18:23:49.851857  8086 solver.cpp:228] Iteration 7240, loss = 0.0486385
I0524 18:23:49.851892  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980713
I0524 18:23:49.851899  8086 solver.cpp:244]     Train net output #1: loss = 0.0486385 (* 1 = 0.0486385 loss)
I0524 18:23:49.851904  8086 sgd_solver.cpp:106] Iteration 7240, lr = 0.0001
I0524 18:23:57.594099  8086 solver.cpp:228] Iteration 7260, loss = 0.0412415
I0524 18:23:57.594133  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981553
I0524 18:23:57.594141  8086 solver.cpp:244]     Train net output #1: loss = 0.0412415 (* 1 = 0.0412415 loss)
I0524 18:23:57.594146  8086 sgd_solver.cpp:106] Iteration 7260, lr = 0.0001
I0524 18:24:05.337364  8086 solver.cpp:228] Iteration 7280, loss = 0.0270647
I0524 18:24:05.337468  8086 solver.cpp:244]     Train net output #0: accuracy = 0.992011
I0524 18:24:05.337478  8086 solver.cpp:244]     Train net output #1: loss = 0.0270647 (* 1 = 0.0270647 loss)
I0524 18:24:05.337482  8086 sgd_solver.cpp:106] Iteration 7280, lr = 0.0001
I0524 18:24:12.865236  8086 solver.cpp:337] Iteration 7300, Testing net (#0)
I0524 18:24:13.376998  8086 solver.cpp:404]     Test net output #0: accuracy = 0.984012
I0524 18:24:13.377032  8086 solver.cpp:404]     Test net output #1: loss = 0.0398787 (* 1 = 0.0398787 loss)
I0524 18:24:13.607008  8086 solver.cpp:228] Iteration 7300, loss = 0.0486908
I0524 18:24:13.607031  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981722
I0524 18:24:13.607039  8086 solver.cpp:244]     Train net output #1: loss = 0.0486909 (* 1 = 0.0486909 loss)
I0524 18:24:13.607043  8086 sgd_solver.cpp:106] Iteration 7300, lr = 0.0001
I0524 18:24:21.350602  8086 solver.cpp:228] Iteration 7320, loss = 0.0493371
I0524 18:24:21.350636  8086 solver.cpp:244]     Train net output #0: accuracy = 0.978275
I0524 18:24:21.350643  8086 solver.cpp:244]     Train net output #1: loss = 0.0493371 (* 1 = 0.0493371 loss)
I0524 18:24:21.350647  8086 sgd_solver.cpp:106] Iteration 7320, lr = 0.0001
I0524 18:24:29.097990  8086 solver.cpp:228] Iteration 7340, loss = 0.0361772
I0524 18:24:29.098023  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985537
I0524 18:24:29.098031  8086 solver.cpp:244]     Train net output #1: loss = 0.0361772 (* 1 = 0.0361772 loss)
I0524 18:24:29.098037  8086 sgd_solver.cpp:106] Iteration 7340, lr = 0.0001
I0524 18:24:36.837967  8086 solver.cpp:228] Iteration 7360, loss = 0.0379301
I0524 18:24:36.838075  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985779
I0524 18:24:36.838084  8086 solver.cpp:244]     Train net output #1: loss = 0.0379301 (* 1 = 0.0379301 loss)
I0524 18:24:36.838089  8086 sgd_solver.cpp:106] Iteration 7360, lr = 0.0001
I0524 18:24:44.577416  8086 solver.cpp:228] Iteration 7380, loss = 0.0396239
I0524 18:24:44.577450  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987377
I0524 18:24:44.577457  8086 solver.cpp:244]     Train net output #1: loss = 0.0396239 (* 1 = 0.0396239 loss)
I0524 18:24:44.577461  8086 sgd_solver.cpp:106] Iteration 7380, lr = 0.0001
I0524 18:24:52.093063  8086 solver.cpp:337] Iteration 7400, Testing net (#0)
I0524 18:24:52.604671  8086 solver.cpp:404]     Test net output #0: accuracy = 0.984586
I0524 18:24:52.604704  8086 solver.cpp:404]     Test net output #1: loss = 0.0406929 (* 1 = 0.0406929 loss)
I0524 18:24:52.833276  8086 solver.cpp:228] Iteration 7400, loss = 0.0380135
I0524 18:24:52.833308  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986877
I0524 18:24:52.833315  8086 solver.cpp:244]     Train net output #1: loss = 0.0380135 (* 1 = 0.0380135 loss)
I0524 18:24:52.833320  8086 sgd_solver.cpp:106] Iteration 7400, lr = 0.0001
I0524 18:25:00.573385  8086 solver.cpp:228] Iteration 7420, loss = 0.0337972
I0524 18:25:00.573418  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986938
I0524 18:25:00.573426  8086 solver.cpp:244]     Train net output #1: loss = 0.0337972 (* 1 = 0.0337972 loss)
I0524 18:25:00.573431  8086 sgd_solver.cpp:106] Iteration 7420, lr = 0.0001
I0524 18:25:08.320165  8086 solver.cpp:228] Iteration 7440, loss = 0.0423375
I0524 18:25:08.320271  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984828
I0524 18:25:08.320281  8086 solver.cpp:244]     Train net output #1: loss = 0.0423375 (* 1 = 0.0423375 loss)
I0524 18:25:08.320286  8086 sgd_solver.cpp:106] Iteration 7440, lr = 0.0001
I0524 18:25:16.065116  8086 solver.cpp:228] Iteration 7460, loss = 0.0339528
I0524 18:25:16.065151  8086 solver.cpp:244]     Train net output #0: accuracy = 0.988599
I0524 18:25:16.065158  8086 solver.cpp:244]     Train net output #1: loss = 0.0339528 (* 1 = 0.0339528 loss)
I0524 18:25:16.065162  8086 sgd_solver.cpp:106] Iteration 7460, lr = 0.0001
I0524 18:25:23.811535  8086 solver.cpp:228] Iteration 7480, loss = 0.0394578
I0524 18:25:23.811558  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983589
I0524 18:25:23.811565  8086 solver.cpp:244]     Train net output #1: loss = 0.0394578 (* 1 = 0.0394578 loss)
I0524 18:25:23.811569  8086 sgd_solver.cpp:106] Iteration 7480, lr = 0.0001
I0524 18:25:31.329838  8086 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_7500.caffemodel
I0524 18:25:31.348270  8086 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_7500.solverstate
I0524 18:25:31.369622  8086 solver.cpp:337] Iteration 7500, Testing net (#0)
I0524 18:25:31.881553  8086 solver.cpp:404]     Test net output #0: accuracy = 0.98578
I0524 18:25:31.881589  8086 solver.cpp:404]     Test net output #1: loss = 0.0374611 (* 1 = 0.0374611 loss)
I0524 18:25:32.108642  8086 solver.cpp:228] Iteration 7500, loss = 0.0351778
I0524 18:25:32.108667  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986739
I0524 18:25:32.108675  8086 solver.cpp:244]     Train net output #1: loss = 0.0351778 (* 1 = 0.0351778 loss)
I0524 18:25:32.108678  8086 sgd_solver.cpp:106] Iteration 7500, lr = 0.0001
I0524 18:25:39.850455  8086 solver.cpp:228] Iteration 7520, loss = 0.0391347
I0524 18:25:39.850584  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982637
I0524 18:25:39.850594  8086 solver.cpp:244]     Train net output #1: loss = 0.0391347 (* 1 = 0.0391347 loss)
I0524 18:25:39.850599  8086 sgd_solver.cpp:106] Iteration 7520, lr = 0.0001
I0524 18:25:47.593900  8086 solver.cpp:228] Iteration 7540, loss = 0.0469488
I0524 18:25:47.593935  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980311
I0524 18:25:47.593942  8086 solver.cpp:244]     Train net output #1: loss = 0.0469488 (* 1 = 0.0469488 loss)
I0524 18:25:47.593946  8086 sgd_solver.cpp:106] Iteration 7540, lr = 0.0001
I0524 18:25:55.334522  8086 solver.cpp:228] Iteration 7560, loss = 0.0410946
I0524 18:25:55.334556  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982288
I0524 18:25:55.334563  8086 solver.cpp:244]     Train net output #1: loss = 0.0410946 (* 1 = 0.0410946 loss)
I0524 18:25:55.334568  8086 sgd_solver.cpp:106] Iteration 7560, lr = 0.0001
I0524 18:26:03.081734  8086 solver.cpp:228] Iteration 7580, loss = 0.0430418
I0524 18:26:03.081768  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983443
I0524 18:26:03.081775  8086 solver.cpp:244]     Train net output #1: loss = 0.0430418 (* 1 = 0.0430418 loss)
I0524 18:26:03.081781  8086 sgd_solver.cpp:106] Iteration 7580, lr = 0.0001
I0524 18:26:10.601949  8086 solver.cpp:337] Iteration 7600, Testing net (#0)
I0524 18:26:11.112699  8086 solver.cpp:404]     Test net output #0: accuracy = 0.978534
I0524 18:26:11.112735  8086 solver.cpp:404]     Test net output #1: loss = 0.0543101 (* 1 = 0.0543101 loss)
I0524 18:26:11.340796  8086 solver.cpp:228] Iteration 7600, loss = 0.0410587
I0524 18:26:11.340818  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982579
I0524 18:26:11.340836  8086 solver.cpp:244]     Train net output #1: loss = 0.0410587 (* 1 = 0.0410587 loss)
I0524 18:26:11.340840  8086 sgd_solver.cpp:106] Iteration 7600, lr = 0.0001
I0524 18:26:19.081749  8086 solver.cpp:228] Iteration 7620, loss = 0.0434974
I0524 18:26:19.081773  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984471
I0524 18:26:19.081791  8086 solver.cpp:244]     Train net output #1: loss = 0.0434974 (* 1 = 0.0434974 loss)
I0524 18:26:19.081795  8086 sgd_solver.cpp:106] Iteration 7620, lr = 0.0001
I0524 18:26:26.823721  8086 solver.cpp:228] Iteration 7640, loss = 0.0356991
I0524 18:26:26.823745  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985894
I0524 18:26:26.823752  8086 solver.cpp:244]     Train net output #1: loss = 0.0356991 (* 1 = 0.0356991 loss)
I0524 18:26:26.823756  8086 sgd_solver.cpp:106] Iteration 7640, lr = 0.0001
I0524 18:26:34.570684  8086 solver.cpp:228] Iteration 7660, loss = 0.0432534
I0524 18:26:34.570720  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98424
I0524 18:26:34.570727  8086 solver.cpp:244]     Train net output #1: loss = 0.0432534 (* 1 = 0.0432534 loss)
I0524 18:26:34.570731  8086 sgd_solver.cpp:106] Iteration 7660, lr = 0.0001
I0524 18:26:42.308442  8086 solver.cpp:228] Iteration 7680, loss = 0.0419942
I0524 18:26:42.308564  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983049
I0524 18:26:42.308573  8086 solver.cpp:244]     Train net output #1: loss = 0.0419942 (* 1 = 0.0419942 loss)
I0524 18:26:42.308578  8086 sgd_solver.cpp:106] Iteration 7680, lr = 0.0001
I0524 18:26:49.826189  8086 solver.cpp:337] Iteration 7700, Testing net (#0)
I0524 18:26:50.338490  8086 solver.cpp:404]     Test net output #0: accuracy = 0.985623
I0524 18:26:50.338524  8086 solver.cpp:404]     Test net output #1: loss = 0.0434152 (* 1 = 0.0434152 loss)
I0524 18:26:50.567198  8086 solver.cpp:228] Iteration 7700, loss = 0.0422152
I0524 18:26:50.567230  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982682
I0524 18:26:50.567237  8086 solver.cpp:244]     Train net output #1: loss = 0.0422152 (* 1 = 0.0422152 loss)
I0524 18:26:50.567242  8086 sgd_solver.cpp:106] Iteration 7700, lr = 0.0001
I0524 18:26:58.317064  8086 solver.cpp:228] Iteration 7720, loss = 0.0284291
I0524 18:26:58.317096  8086 solver.cpp:244]     Train net output #0: accuracy = 0.991806
I0524 18:26:58.317103  8086 solver.cpp:244]     Train net output #1: loss = 0.0284291 (* 1 = 0.0284291 loss)
I0524 18:26:58.317108  8086 sgd_solver.cpp:106] Iteration 7720, lr = 0.0001
I0524 18:27:06.062443  8086 solver.cpp:228] Iteration 7740, loss = 0.0402541
I0524 18:27:06.062479  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982763
I0524 18:27:06.062485  8086 solver.cpp:244]     Train net output #1: loss = 0.0402542 (* 1 = 0.0402542 loss)
I0524 18:27:06.062490  8086 sgd_solver.cpp:106] Iteration 7740, lr = 0.0001
I0524 18:27:13.808673  8086 solver.cpp:228] Iteration 7760, loss = 0.0468199
I0524 18:27:13.808801  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983876
I0524 18:27:13.808810  8086 solver.cpp:244]     Train net output #1: loss = 0.0468199 (* 1 = 0.0468199 loss)
I0524 18:27:13.808815  8086 sgd_solver.cpp:106] Iteration 7760, lr = 0.0001
I0524 18:27:21.554507  8086 solver.cpp:228] Iteration 7780, loss = 0.0398488
I0524 18:27:21.554543  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984576
I0524 18:27:21.554548  8086 solver.cpp:244]     Train net output #1: loss = 0.0398488 (* 1 = 0.0398488 loss)
I0524 18:27:21.554553  8086 sgd_solver.cpp:106] Iteration 7780, lr = 0.0001
I0524 18:27:29.067145  8086 solver.cpp:337] Iteration 7800, Testing net (#0)
I0524 18:27:29.579195  8086 solver.cpp:404]     Test net output #0: accuracy = 0.987701
I0524 18:27:29.579219  8086 solver.cpp:404]     Test net output #1: loss = 0.036638 (* 1 = 0.036638 loss)
I0524 18:27:29.809250  8086 solver.cpp:228] Iteration 7800, loss = 0.04252
I0524 18:27:29.809273  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984126
I0524 18:27:29.809280  8086 solver.cpp:244]     Train net output #1: loss = 0.04252 (* 1 = 0.04252 loss)
I0524 18:27:29.809285  8086 sgd_solver.cpp:106] Iteration 7800, lr = 0.0001
I0524 18:27:37.554322  8086 solver.cpp:228] Iteration 7820, loss = 0.0387429
I0524 18:27:37.554357  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984561
I0524 18:27:37.554364  8086 solver.cpp:244]     Train net output #1: loss = 0.0387429 (* 1 = 0.0387429 loss)
I0524 18:27:37.554368  8086 sgd_solver.cpp:106] Iteration 7820, lr = 0.0001
I0524 18:27:45.295766  8086 solver.cpp:228] Iteration 7840, loss = 0.0324785
I0524 18:27:45.295871  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987596
I0524 18:27:45.295878  8086 solver.cpp:244]     Train net output #1: loss = 0.0324785 (* 1 = 0.0324785 loss)
I0524 18:27:45.295883  8086 sgd_solver.cpp:106] Iteration 7840, lr = 0.0001
I0524 18:27:53.040820  8086 solver.cpp:228] Iteration 7860, loss = 0.0269867
I0524 18:27:53.040843  8086 solver.cpp:244]     Train net output #0: accuracy = 0.992268
I0524 18:27:53.040850  8086 solver.cpp:244]     Train net output #1: loss = 0.0269867 (* 1 = 0.0269867 loss)
I0524 18:27:53.040854  8086 sgd_solver.cpp:106] Iteration 7860, lr = 0.0001
I0524 18:28:00.789320  8086 solver.cpp:228] Iteration 7880, loss = 0.0467044
I0524 18:28:00.789355  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981977
I0524 18:28:00.789361  8086 solver.cpp:244]     Train net output #1: loss = 0.0467044 (* 1 = 0.0467044 loss)
I0524 18:28:00.789366  8086 sgd_solver.cpp:106] Iteration 7880, lr = 0.0001
I0524 18:28:08.308951  8086 solver.cpp:337] Iteration 7900, Testing net (#0)
I0524 18:28:08.822080  8086 solver.cpp:404]     Test net output #0: accuracy = 0.980033
I0524 18:28:08.822115  8086 solver.cpp:404]     Test net output #1: loss = 0.0494989 (* 1 = 0.0494989 loss)
I0524 18:28:09.052175  8086 solver.cpp:228] Iteration 7900, loss = 0.0447589
I0524 18:28:09.052198  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983448
I0524 18:28:09.052206  8086 solver.cpp:244]     Train net output #1: loss = 0.0447589 (* 1 = 0.0447589 loss)
I0524 18:28:09.052209  8086 sgd_solver.cpp:106] Iteration 7900, lr = 0.0001
I0524 18:28:16.802878  8086 solver.cpp:228] Iteration 7920, loss = 0.0456123
I0524 18:28:16.803009  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983717
I0524 18:28:16.803019  8086 solver.cpp:244]     Train net output #1: loss = 0.0456123 (* 1 = 0.0456123 loss)
I0524 18:28:16.803023  8086 sgd_solver.cpp:106] Iteration 7920, lr = 0.0001
I0524 18:28:24.547158  8086 solver.cpp:228] Iteration 7940, loss = 0.0376687
I0524 18:28:24.547194  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986152
I0524 18:28:24.547200  8086 solver.cpp:244]     Train net output #1: loss = 0.0376687 (* 1 = 0.0376687 loss)
I0524 18:28:24.547204  8086 sgd_solver.cpp:106] Iteration 7940, lr = 0.0001
I0524 18:28:32.291956  8086 solver.cpp:228] Iteration 7960, loss = 0.0472068
I0524 18:28:32.291990  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98151
I0524 18:28:32.291998  8086 solver.cpp:244]     Train net output #1: loss = 0.0472068 (* 1 = 0.0472068 loss)
I0524 18:28:32.292003  8086 sgd_solver.cpp:106] Iteration 7960, lr = 0.0001
I0524 18:28:40.038828  8086 solver.cpp:228] Iteration 7980, loss = 0.0509334
I0524 18:28:40.038851  8086 solver.cpp:244]     Train net output #0: accuracy = 0.978528
I0524 18:28:40.038858  8086 solver.cpp:244]     Train net output #1: loss = 0.0509334 (* 1 = 0.0509334 loss)
I0524 18:28:40.038863  8086 sgd_solver.cpp:106] Iteration 7980, lr = 0.0001
I0524 18:28:47.553650  8086 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_8000.caffemodel
I0524 18:28:47.572456  8086 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_8000.solverstate
I0524 18:28:47.584108  8086 solver.cpp:337] Iteration 8000, Testing net (#0)
I0524 18:28:48.098211  8086 solver.cpp:404]     Test net output #0: accuracy = 0.981902
I0524 18:28:48.098245  8086 solver.cpp:404]     Test net output #1: loss = 0.0448495 (* 1 = 0.0448495 loss)
I0524 18:28:48.327009  8086 solver.cpp:228] Iteration 8000, loss = 0.0439688
I0524 18:28:48.327033  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981323
I0524 18:28:48.327040  8086 solver.cpp:244]     Train net output #1: loss = 0.0439688 (* 1 = 0.0439688 loss)
I0524 18:28:48.327045  8086 sgd_solver.cpp:106] Iteration 8000, lr = 0.0001
I0524 18:28:56.074236  8086 solver.cpp:228] Iteration 8020, loss = 0.0357569
I0524 18:28:56.074259  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986324
I0524 18:28:56.074276  8086 solver.cpp:244]     Train net output #1: loss = 0.0357569 (* 1 = 0.0357569 loss)
I0524 18:28:56.074281  8086 sgd_solver.cpp:106] Iteration 8020, lr = 0.0001
I0524 18:29:03.813410  8086 solver.cpp:228] Iteration 8040, loss = 0.0454664
I0524 18:29:03.813442  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981957
I0524 18:29:03.813448  8086 solver.cpp:244]     Train net output #1: loss = 0.0454664 (* 1 = 0.0454664 loss)
I0524 18:29:03.813453  8086 sgd_solver.cpp:106] Iteration 8040, lr = 0.0001
I0524 18:29:11.554473  8086 solver.cpp:228] Iteration 8060, loss = 0.0322989
I0524 18:29:11.554507  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987107
I0524 18:29:11.554514  8086 solver.cpp:244]     Train net output #1: loss = 0.0322989 (* 1 = 0.0322989 loss)
I0524 18:29:11.554518  8086 sgd_solver.cpp:106] Iteration 8060, lr = 0.0001
I0524 18:29:19.302950  8086 solver.cpp:228] Iteration 8080, loss = 0.0399444
I0524 18:29:19.303071  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985339
I0524 18:29:19.303079  8086 solver.cpp:244]     Train net output #1: loss = 0.0399444 (* 1 = 0.0399444 loss)
I0524 18:29:19.303086  8086 sgd_solver.cpp:106] Iteration 8080, lr = 0.0001
I0524 18:29:26.821096  8086 solver.cpp:337] Iteration 8100, Testing net (#0)
I0524 18:29:27.332309  8086 solver.cpp:404]     Test net output #0: accuracy = 0.983051
I0524 18:29:27.332332  8086 solver.cpp:404]     Test net output #1: loss = 0.0418004 (* 1 = 0.0418004 loss)
I0524 18:29:27.560817  8086 solver.cpp:228] Iteration 8100, loss = 0.0416267
I0524 18:29:27.560840  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982735
I0524 18:29:27.560847  8086 solver.cpp:244]     Train net output #1: loss = 0.0416267 (* 1 = 0.0416267 loss)
I0524 18:29:27.560852  8086 sgd_solver.cpp:106] Iteration 8100, lr = 0.0001
I0524 18:29:35.305377  8086 solver.cpp:228] Iteration 8120, loss = 0.0311787
I0524 18:29:35.305411  8086 solver.cpp:244]     Train net output #0: accuracy = 0.990638
I0524 18:29:35.305418  8086 solver.cpp:244]     Train net output #1: loss = 0.0311787 (* 1 = 0.0311787 loss)
I0524 18:29:35.305423  8086 sgd_solver.cpp:106] Iteration 8120, lr = 0.0001
I0524 18:29:43.054193  8086 solver.cpp:228] Iteration 8140, loss = 0.0410791
I0524 18:29:43.054217  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981889
I0524 18:29:43.054224  8086 solver.cpp:244]     Train net output #1: loss = 0.0410791 (* 1 = 0.0410791 loss)
I0524 18:29:43.054229  8086 sgd_solver.cpp:106] Iteration 8140, lr = 0.0001
I0524 18:29:50.804394  8086 solver.cpp:228] Iteration 8160, loss = 0.0439727
I0524 18:29:50.804491  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983776
I0524 18:29:50.804498  8086 solver.cpp:244]     Train net output #1: loss = 0.0439727 (* 1 = 0.0439727 loss)
I0524 18:29:50.804503  8086 sgd_solver.cpp:106] Iteration 8160, lr = 0.0001
I0524 18:29:58.554833  8086 solver.cpp:228] Iteration 8180, loss = 0.0364709
I0524 18:29:58.554857  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984219
I0524 18:29:58.554863  8086 solver.cpp:244]     Train net output #1: loss = 0.0364709 (* 1 = 0.0364709 loss)
I0524 18:29:58.554868  8086 sgd_solver.cpp:106] Iteration 8180, lr = 0.0001
I0524 18:30:06.079854  8086 solver.cpp:337] Iteration 8200, Testing net (#0)
I0524 18:30:06.590693  8086 solver.cpp:404]     Test net output #0: accuracy = 0.988941
I0524 18:30:06.590718  8086 solver.cpp:404]     Test net output #1: loss = 0.0317353 (* 1 = 0.0317353 loss)
I0524 18:30:06.820652  8086 solver.cpp:228] Iteration 8200, loss = 0.0288051
I0524 18:30:06.820674  8086 solver.cpp:244]     Train net output #0: accuracy = 0.989483
I0524 18:30:06.820682  8086 solver.cpp:244]     Train net output #1: loss = 0.0288052 (* 1 = 0.0288052 loss)
I0524 18:30:06.820685  8086 sgd_solver.cpp:106] Iteration 8200, lr = 0.0001
I0524 18:30:14.569090  8086 solver.cpp:228] Iteration 8220, loss = 0.0366707
I0524 18:30:14.569123  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985772
I0524 18:30:14.569130  8086 solver.cpp:244]     Train net output #1: loss = 0.0366707 (* 1 = 0.0366707 loss)
I0524 18:30:14.569135  8086 sgd_solver.cpp:106] Iteration 8220, lr = 0.0001
I0524 18:30:22.310302  8086 solver.cpp:228] Iteration 8240, loss = 0.0330913
I0524 18:30:22.310421  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987416
I0524 18:30:22.310431  8086 solver.cpp:244]     Train net output #1: loss = 0.0330913 (* 1 = 0.0330913 loss)
I0524 18:30:22.310436  8086 sgd_solver.cpp:106] Iteration 8240, lr = 0.0001
I0524 18:30:30.049857  8086 solver.cpp:228] Iteration 8260, loss = 0.0336928
I0524 18:30:30.049892  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987754
I0524 18:30:30.049899  8086 solver.cpp:244]     Train net output #1: loss = 0.0336928 (* 1 = 0.0336928 loss)
I0524 18:30:30.049903  8086 sgd_solver.cpp:106] Iteration 8260, lr = 0.0001
I0524 18:30:37.792695  8086 solver.cpp:228] Iteration 8280, loss = 0.0471259
I0524 18:30:37.792728  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981594
I0524 18:30:37.792735  8086 solver.cpp:244]     Train net output #1: loss = 0.0471259 (* 1 = 0.0471259 loss)
I0524 18:30:37.792740  8086 sgd_solver.cpp:106] Iteration 8280, lr = 0.0001
I0524 18:30:45.312273  8086 solver.cpp:337] Iteration 8300, Testing net (#0)
I0524 18:30:45.823583  8086 solver.cpp:404]     Test net output #0: accuracy = 0.977735
I0524 18:30:45.823608  8086 solver.cpp:404]     Test net output #1: loss = 0.058765 (* 1 = 0.058765 loss)
I0524 18:30:46.052184  8086 solver.cpp:228] Iteration 8300, loss = 0.0445246
I0524 18:30:46.052218  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980786
I0524 18:30:46.052227  8086 solver.cpp:244]     Train net output #1: loss = 0.0445246 (* 1 = 0.0445246 loss)
I0524 18:30:46.052232  8086 sgd_solver.cpp:106] Iteration 8300, lr = 0.0001
I0524 18:30:53.798702  8086 solver.cpp:228] Iteration 8320, loss = 0.0548501
I0524 18:30:53.798806  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979791
I0524 18:30:53.798815  8086 solver.cpp:244]     Train net output #1: loss = 0.0548501 (* 1 = 0.0548501 loss)
I0524 18:30:53.798820  8086 sgd_solver.cpp:106] Iteration 8320, lr = 0.0001
I0524 18:31:01.551892  8086 solver.cpp:228] Iteration 8340, loss = 0.0389843
I0524 18:31:01.551928  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984411
I0524 18:31:01.551935  8086 solver.cpp:244]     Train net output #1: loss = 0.0389843 (* 1 = 0.0389843 loss)
I0524 18:31:01.551940  8086 sgd_solver.cpp:106] Iteration 8340, lr = 0.0001
I0524 18:31:09.297323  8086 solver.cpp:228] Iteration 8360, loss = 0.0460447
I0524 18:31:09.297358  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980114
I0524 18:31:09.297365  8086 solver.cpp:244]     Train net output #1: loss = 0.0460447 (* 1 = 0.0460447 loss)
I0524 18:31:09.297370  8086 sgd_solver.cpp:106] Iteration 8360, lr = 0.0001
I0524 18:31:17.043797  8086 solver.cpp:228] Iteration 8380, loss = 0.042357
I0524 18:31:17.043830  8086 solver.cpp:244]     Train net output #0: accuracy = 0.9828
I0524 18:31:17.043838  8086 solver.cpp:244]     Train net output #1: loss = 0.042357 (* 1 = 0.042357 loss)
I0524 18:31:17.043843  8086 sgd_solver.cpp:106] Iteration 8380, lr = 0.0001
I0524 18:31:24.571380  8086 solver.cpp:337] Iteration 8400, Testing net (#0)
I0524 18:31:25.084131  8086 solver.cpp:404]     Test net output #0: accuracy = 0.983253
I0524 18:31:25.084154  8086 solver.cpp:404]     Test net output #1: loss = 0.046451 (* 1 = 0.046451 loss)
I0524 18:31:25.312928  8086 solver.cpp:228] Iteration 8400, loss = 0.0400738
I0524 18:31:25.312952  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985329
I0524 18:31:25.312969  8086 solver.cpp:244]     Train net output #1: loss = 0.0400739 (* 1 = 0.0400739 loss)
I0524 18:31:25.312974  8086 sgd_solver.cpp:106] Iteration 8400, lr = 0.0001
I0524 18:31:33.055716  8086 solver.cpp:228] Iteration 8420, loss = 0.0426211
I0524 18:31:33.055750  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982464
I0524 18:31:33.055757  8086 solver.cpp:244]     Train net output #1: loss = 0.0426211 (* 1 = 0.0426211 loss)
I0524 18:31:33.055763  8086 sgd_solver.cpp:106] Iteration 8420, lr = 0.0001
I0524 18:31:40.806058  8086 solver.cpp:228] Iteration 8440, loss = 0.0359699
I0524 18:31:40.806082  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986149
I0524 18:31:40.806087  8086 solver.cpp:244]     Train net output #1: loss = 0.0359699 (* 1 = 0.0359699 loss)
I0524 18:31:40.806092  8086 sgd_solver.cpp:106] Iteration 8440, lr = 0.0001
I0524 18:31:48.545460  8086 solver.cpp:228] Iteration 8460, loss = 0.0276654
I0524 18:31:48.545495  8086 solver.cpp:244]     Train net output #0: accuracy = 0.990571
I0524 18:31:48.545501  8086 solver.cpp:244]     Train net output #1: loss = 0.0276654 (* 1 = 0.0276654 loss)
I0524 18:31:48.545506  8086 sgd_solver.cpp:106] Iteration 8460, lr = 0.0001
I0524 18:31:56.283905  8086 solver.cpp:228] Iteration 8480, loss = 0.0424903
I0524 18:31:56.284029  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98109
I0524 18:31:56.284039  8086 solver.cpp:244]     Train net output #1: loss = 0.0424903 (* 1 = 0.0424903 loss)
I0524 18:31:56.284044  8086 sgd_solver.cpp:106] Iteration 8480, lr = 0.0001
I0524 18:32:03.811100  8086 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_8500.caffemodel
I0524 18:32:03.829725  8086 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_8500.solverstate
I0524 18:32:03.849759  8086 solver.cpp:337] Iteration 8500, Testing net (#0)
I0524 18:32:04.361248  8086 solver.cpp:404]     Test net output #0: accuracy = 0.986838
I0524 18:32:04.361271  8086 solver.cpp:404]     Test net output #1: loss = 0.034656 (* 1 = 0.034656 loss)
I0524 18:32:04.589803  8086 solver.cpp:228] Iteration 8500, loss = 0.0480169
I0524 18:32:04.589838  8086 solver.cpp:244]     Train net output #0: accuracy = 0.97982
I0524 18:32:04.589846  8086 solver.cpp:244]     Train net output #1: loss = 0.0480169 (* 1 = 0.0480169 loss)
I0524 18:32:04.589851  8086 sgd_solver.cpp:106] Iteration 8500, lr = 0.0001
I0524 18:32:12.337083  8086 solver.cpp:228] Iteration 8520, loss = 0.0410712
I0524 18:32:12.337107  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983774
I0524 18:32:12.337115  8086 solver.cpp:244]     Train net output #1: loss = 0.0410712 (* 1 = 0.0410712 loss)
I0524 18:32:12.337118  8086 sgd_solver.cpp:106] Iteration 8520, lr = 0.0001
I0524 18:32:20.104913  8086 solver.cpp:228] Iteration 8540, loss = 0.0524183
I0524 18:32:20.104936  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982476
I0524 18:32:20.104943  8086 solver.cpp:244]     Train net output #1: loss = 0.0524183 (* 1 = 0.0524183 loss)
I0524 18:32:20.104948  8086 sgd_solver.cpp:106] Iteration 8540, lr = 0.0001
I0524 18:32:27.854226  8086 solver.cpp:228] Iteration 8560, loss = 0.0348116
I0524 18:32:27.854311  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987724
I0524 18:32:27.854321  8086 solver.cpp:244]     Train net output #1: loss = 0.0348116 (* 1 = 0.0348116 loss)
I0524 18:32:27.854326  8086 sgd_solver.cpp:106] Iteration 8560, lr = 0.0001
I0524 18:32:35.614207  8086 solver.cpp:228] Iteration 8580, loss = 0.0464413
I0524 18:32:35.614243  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981252
I0524 18:32:35.614249  8086 solver.cpp:244]     Train net output #1: loss = 0.0464413 (* 1 = 0.0464413 loss)
I0524 18:32:35.614253  8086 sgd_solver.cpp:106] Iteration 8580, lr = 0.0001
I0524 18:32:43.155199  8086 solver.cpp:337] Iteration 8600, Testing net (#0)
I0524 18:32:43.669582  8086 solver.cpp:404]     Test net output #0: accuracy = 0.980914
I0524 18:32:43.669606  8086 solver.cpp:404]     Test net output #1: loss = 0.0499731 (* 1 = 0.0499731 loss)
I0524 18:32:43.899509  8086 solver.cpp:228] Iteration 8600, loss = 0.0484039
I0524 18:32:43.899533  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981623
I0524 18:32:43.899538  8086 solver.cpp:244]     Train net output #1: loss = 0.0484039 (* 1 = 0.0484039 loss)
I0524 18:32:43.899544  8086 sgd_solver.cpp:106] Iteration 8600, lr = 0.0001
I0524 18:32:51.651249  8086 solver.cpp:228] Iteration 8620, loss = 0.0485664
I0524 18:32:51.651284  8086 solver.cpp:244]     Train net output #0: accuracy = 0.977794
I0524 18:32:51.651291  8086 solver.cpp:244]     Train net output #1: loss = 0.0485664 (* 1 = 0.0485664 loss)
I0524 18:32:51.651295  8086 sgd_solver.cpp:106] Iteration 8620, lr = 0.0001
I0524 18:32:59.407302  8086 solver.cpp:228] Iteration 8640, loss = 0.039465
I0524 18:32:59.407433  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987739
I0524 18:32:59.407443  8086 solver.cpp:244]     Train net output #1: loss = 0.039465 (* 1 = 0.039465 loss)
I0524 18:32:59.407447  8086 sgd_solver.cpp:106] Iteration 8640, lr = 0.0001
I0524 18:33:07.156163  8086 solver.cpp:228] Iteration 8660, loss = 0.0482249
I0524 18:33:07.156198  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981939
I0524 18:33:07.156203  8086 solver.cpp:244]     Train net output #1: loss = 0.0482249 (* 1 = 0.0482249 loss)
I0524 18:33:07.156208  8086 sgd_solver.cpp:106] Iteration 8660, lr = 0.0001
I0524 18:33:14.900807  8086 solver.cpp:228] Iteration 8680, loss = 0.0388312
I0524 18:33:14.900831  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985521
I0524 18:33:14.900838  8086 solver.cpp:244]     Train net output #1: loss = 0.0388312 (* 1 = 0.0388312 loss)
I0524 18:33:14.900842  8086 sgd_solver.cpp:106] Iteration 8680, lr = 0.0001
I0524 18:33:22.426007  8086 solver.cpp:337] Iteration 8700, Testing net (#0)
I0524 18:33:22.936851  8086 solver.cpp:404]     Test net output #0: accuracy = 0.980431
I0524 18:33:22.936883  8086 solver.cpp:404]     Test net output #1: loss = 0.0472171 (* 1 = 0.0472171 loss)
I0524 18:33:23.167045  8086 solver.cpp:228] Iteration 8700, loss = 0.0461714
I0524 18:33:23.167068  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98158
I0524 18:33:23.167075  8086 solver.cpp:244]     Train net output #1: loss = 0.0461714 (* 1 = 0.0461714 loss)
I0524 18:33:23.167080  8086 sgd_solver.cpp:106] Iteration 8700, lr = 0.0001
I0524 18:33:30.911722  8086 solver.cpp:228] Iteration 8720, loss = 0.0540655
I0524 18:33:30.911818  8086 solver.cpp:244]     Train net output #0: accuracy = 0.97824
I0524 18:33:30.911826  8086 solver.cpp:244]     Train net output #1: loss = 0.0540655 (* 1 = 0.0540655 loss)
I0524 18:33:30.911831  8086 sgd_solver.cpp:106] Iteration 8720, lr = 0.0001
I0524 18:33:38.661427  8086 solver.cpp:228] Iteration 8740, loss = 0.0413409
I0524 18:33:38.661461  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983871
I0524 18:33:38.661468  8086 solver.cpp:244]     Train net output #1: loss = 0.0413409 (* 1 = 0.0413409 loss)
I0524 18:33:38.661473  8086 sgd_solver.cpp:106] Iteration 8740, lr = 0.0001
I0524 18:33:46.407165  8086 solver.cpp:228] Iteration 8760, loss = 0.0404586
I0524 18:33:46.407198  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984154
I0524 18:33:46.407205  8086 solver.cpp:244]     Train net output #1: loss = 0.0404586 (* 1 = 0.0404586 loss)
I0524 18:33:46.407210  8086 sgd_solver.cpp:106] Iteration 8760, lr = 0.0001
I0524 18:33:54.149691  8086 solver.cpp:228] Iteration 8780, loss = 0.0380917
I0524 18:33:54.149715  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984377
I0524 18:33:54.149722  8086 solver.cpp:244]     Train net output #1: loss = 0.0380917 (* 1 = 0.0380917 loss)
I0524 18:33:54.149727  8086 sgd_solver.cpp:106] Iteration 8780, lr = 0.0001
I0524 18:34:01.670802  8086 solver.cpp:337] Iteration 8800, Testing net (#0)
I0524 18:34:02.181160  8086 solver.cpp:404]     Test net output #0: accuracy = 0.978467
I0524 18:34:02.181195  8086 solver.cpp:404]     Test net output #1: loss = 0.0551615 (* 1 = 0.0551615 loss)
I0524 18:34:02.410159  8086 solver.cpp:228] Iteration 8800, loss = 0.0477211
I0524 18:34:02.410182  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980223
I0524 18:34:02.410189  8086 solver.cpp:244]     Train net output #1: loss = 0.0477211 (* 1 = 0.0477211 loss)
I0524 18:34:02.410193  8086 sgd_solver.cpp:106] Iteration 8800, lr = 0.0001
I0524 18:34:10.140318  8086 solver.cpp:228] Iteration 8820, loss = 0.0394497
I0524 18:34:10.140342  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982997
I0524 18:34:10.140349  8086 solver.cpp:244]     Train net output #1: loss = 0.0394497 (* 1 = 0.0394497 loss)
I0524 18:34:10.140354  8086 sgd_solver.cpp:106] Iteration 8820, lr = 0.0001
I0524 18:34:17.881350  8086 solver.cpp:228] Iteration 8840, loss = 0.0479599
I0524 18:34:17.881383  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979198
I0524 18:34:17.881391  8086 solver.cpp:244]     Train net output #1: loss = 0.0479599 (* 1 = 0.0479599 loss)
I0524 18:34:17.881395  8086 sgd_solver.cpp:106] Iteration 8840, lr = 0.0001
I0524 18:34:25.632417  8086 solver.cpp:228] Iteration 8860, loss = 0.0725136
I0524 18:34:25.632452  8086 solver.cpp:244]     Train net output #0: accuracy = 0.973394
I0524 18:34:25.632458  8086 solver.cpp:244]     Train net output #1: loss = 0.0725136 (* 1 = 0.0725136 loss)
I0524 18:34:25.632462  8086 sgd_solver.cpp:106] Iteration 8860, lr = 0.0001
I0524 18:34:33.376597  8086 solver.cpp:228] Iteration 8880, loss = 0.0456355
I0524 18:34:33.376723  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984234
I0524 18:34:33.376732  8086 solver.cpp:244]     Train net output #1: loss = 0.0456355 (* 1 = 0.0456355 loss)
I0524 18:34:33.376737  8086 sgd_solver.cpp:106] Iteration 8880, lr = 0.0001
I0524 18:34:40.897266  8086 solver.cpp:337] Iteration 8900, Testing net (#0)
I0524 18:34:41.411842  8086 solver.cpp:404]     Test net output #0: accuracy = 0.983811
I0524 18:34:41.411866  8086 solver.cpp:404]     Test net output #1: loss = 0.0450773 (* 1 = 0.0450773 loss)
I0524 18:34:41.642321  8086 solver.cpp:228] Iteration 8900, loss = 0.0448595
I0524 18:34:41.642344  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982479
I0524 18:34:41.642351  8086 solver.cpp:244]     Train net output #1: loss = 0.0448595 (* 1 = 0.0448595 loss)
I0524 18:34:41.642355  8086 sgd_solver.cpp:106] Iteration 8900, lr = 0.0001
I0524 18:34:49.385211  8086 solver.cpp:228] Iteration 8920, loss = 0.0408316
I0524 18:34:49.385246  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984451
I0524 18:34:49.385252  8086 solver.cpp:244]     Train net output #1: loss = 0.0408316 (* 1 = 0.0408316 loss)
I0524 18:34:49.385257  8086 sgd_solver.cpp:106] Iteration 8920, lr = 0.0001
I0524 18:34:57.128294  8086 solver.cpp:228] Iteration 8940, loss = 0.0470365
I0524 18:34:57.128329  8086 solver.cpp:244]     Train net output #0: accuracy = 0.97931
I0524 18:34:57.128336  8086 solver.cpp:244]     Train net output #1: loss = 0.0470365 (* 1 = 0.0470365 loss)
I0524 18:34:57.128341  8086 sgd_solver.cpp:106] Iteration 8940, lr = 0.0001
I0524 18:35:04.877702  8086 solver.cpp:228] Iteration 8960, loss = 0.0512982
I0524 18:35:04.877804  8086 solver.cpp:244]     Train net output #0: accuracy = 0.978448
I0524 18:35:04.877812  8086 solver.cpp:244]     Train net output #1: loss = 0.0512982 (* 1 = 0.0512982 loss)
I0524 18:35:04.877817  8086 sgd_solver.cpp:106] Iteration 8960, lr = 0.0001
I0524 18:35:12.627028  8086 solver.cpp:228] Iteration 8980, loss = 0.0580825
I0524 18:35:12.627063  8086 solver.cpp:244]     Train net output #0: accuracy = 0.977581
I0524 18:35:12.627069  8086 solver.cpp:244]     Train net output #1: loss = 0.0580825 (* 1 = 0.0580825 loss)
I0524 18:35:12.627074  8086 sgd_solver.cpp:106] Iteration 8980, lr = 0.0001
I0524 18:35:20.144881  8086 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_9000.caffemodel
I0524 18:35:20.163352  8086 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_9000.solverstate
I0524 18:35:20.171778  8086 solver.cpp:337] Iteration 9000, Testing net (#0)
I0524 18:35:20.684847  8086 solver.cpp:404]     Test net output #0: accuracy = 0.985162
I0524 18:35:20.684881  8086 solver.cpp:404]     Test net output #1: loss = 0.0416868 (* 1 = 0.0416868 loss)
I0524 18:35:20.914585  8086 solver.cpp:228] Iteration 9000, loss = 0.0344591
I0524 18:35:20.914608  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986644
I0524 18:35:20.914625  8086 solver.cpp:244]     Train net output #1: loss = 0.0344592 (* 1 = 0.0344592 loss)
I0524 18:35:20.914630  8086 sgd_solver.cpp:106] Iteration 9000, lr = 1e-05
I0524 18:35:28.659384  8086 solver.cpp:228] Iteration 9020, loss = 0.0336712
I0524 18:35:28.659407  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987279
I0524 18:35:28.659415  8086 solver.cpp:244]     Train net output #1: loss = 0.0336712 (* 1 = 0.0336712 loss)
I0524 18:35:28.659420  8086 sgd_solver.cpp:106] Iteration 9020, lr = 1e-05
I0524 18:35:36.399297  8086 solver.cpp:228] Iteration 9040, loss = 0.0434552
I0524 18:35:36.399428  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981893
I0524 18:35:36.399440  8086 solver.cpp:244]     Train net output #1: loss = 0.0434552 (* 1 = 0.0434552 loss)
I0524 18:35:36.399444  8086 sgd_solver.cpp:106] Iteration 9040, lr = 1e-05
I0524 18:35:44.150502  8086 solver.cpp:228] Iteration 9060, loss = 0.0457513
I0524 18:35:44.150526  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982803
I0524 18:35:44.150532  8086 solver.cpp:244]     Train net output #1: loss = 0.0457513 (* 1 = 0.0457513 loss)
I0524 18:35:44.150537  8086 sgd_solver.cpp:106] Iteration 9060, lr = 1e-05
I0524 18:35:51.894192  8086 solver.cpp:228] Iteration 9080, loss = 0.0410679
I0524 18:35:51.894227  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984406
I0524 18:35:51.894234  8086 solver.cpp:244]     Train net output #1: loss = 0.0410679 (* 1 = 0.0410679 loss)
I0524 18:35:51.894239  8086 sgd_solver.cpp:106] Iteration 9080, lr = 1e-05
I0524 18:35:59.414659  8086 solver.cpp:337] Iteration 9100, Testing net (#0)
I0524 18:35:59.949864  8086 solver.cpp:404]     Test net output #0: accuracy = 0.98435
I0524 18:35:59.949901  8086 solver.cpp:404]     Test net output #1: loss = 0.0433187 (* 1 = 0.0433187 loss)
I0524 18:36:00.178822  8086 solver.cpp:228] Iteration 9100, loss = 0.0305121
I0524 18:36:00.178856  8086 solver.cpp:244]     Train net output #0: accuracy = 0.989117
I0524 18:36:00.178864  8086 solver.cpp:244]     Train net output #1: loss = 0.0305121 (* 1 = 0.0305121 loss)
I0524 18:36:00.178870  8086 sgd_solver.cpp:106] Iteration 9100, lr = 1e-05
I0524 18:36:07.927023  8086 solver.cpp:228] Iteration 9120, loss = 0.0541982
I0524 18:36:07.927129  8086 solver.cpp:244]     Train net output #0: accuracy = 0.976049
I0524 18:36:07.927139  8086 solver.cpp:244]     Train net output #1: loss = 0.0541982 (* 1 = 0.0541982 loss)
I0524 18:36:07.927145  8086 sgd_solver.cpp:106] Iteration 9120, lr = 1e-05
I0524 18:36:15.963842  8086 solver.cpp:228] Iteration 9140, loss = 0.0480987
I0524 18:36:15.963866  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983496
I0524 18:36:15.963873  8086 solver.cpp:244]     Train net output #1: loss = 0.0480987 (* 1 = 0.0480987 loss)
I0524 18:36:15.963889  8086 sgd_solver.cpp:106] Iteration 9140, lr = 1e-05
I0524 18:36:24.561682  8086 solver.cpp:228] Iteration 9160, loss = 0.0572076
I0524 18:36:24.561705  8086 solver.cpp:244]     Train net output #0: accuracy = 0.979151
I0524 18:36:24.561712  8086 solver.cpp:244]     Train net output #1: loss = 0.0572076 (* 1 = 0.0572076 loss)
I0524 18:36:24.561718  8086 sgd_solver.cpp:106] Iteration 9160, lr = 1e-05
I0524 18:36:33.149129  8086 solver.cpp:228] Iteration 9180, loss = 0.0478598
I0524 18:36:33.149153  8086 solver.cpp:244]     Train net output #0: accuracy = 0.978962
I0524 18:36:33.149159  8086 solver.cpp:244]     Train net output #1: loss = 0.0478598 (* 1 = 0.0478598 loss)
I0524 18:36:33.149165  8086 sgd_solver.cpp:106] Iteration 9180, lr = 1e-05
I0524 18:36:41.475953  8086 solver.cpp:337] Iteration 9200, Testing net (#0)
I0524 18:36:41.989195  8086 solver.cpp:404]     Test net output #0: accuracy = 0.984907
I0524 18:36:41.989230  8086 solver.cpp:404]     Test net output #1: loss = 0.0425575 (* 1 = 0.0425575 loss)
I0524 18:36:42.259841  8086 solver.cpp:228] Iteration 9200, loss = 0.0474432
I0524 18:36:42.259865  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982688
I0524 18:36:42.259871  8086 solver.cpp:244]     Train net output #1: loss = 0.0474432 (* 1 = 0.0474432 loss)
I0524 18:36:42.259876  8086 sgd_solver.cpp:106] Iteration 9200, lr = 1e-05
I0524 18:36:50.852293  8086 solver.cpp:228] Iteration 9220, loss = 0.0511392
I0524 18:36:50.852316  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981021
I0524 18:36:50.852324  8086 solver.cpp:244]     Train net output #1: loss = 0.0511392 (* 1 = 0.0511392 loss)
I0524 18:36:50.852329  8086 sgd_solver.cpp:106] Iteration 9220, lr = 1e-05
I0524 18:36:59.441824  8086 solver.cpp:228] Iteration 9240, loss = 0.0452178
I0524 18:36:59.441848  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980822
I0524 18:36:59.441854  8086 solver.cpp:244]     Train net output #1: loss = 0.0452178 (* 1 = 0.0452178 loss)
I0524 18:36:59.441859  8086 sgd_solver.cpp:106] Iteration 9240, lr = 1e-05
I0524 18:37:07.897115  8086 solver.cpp:228] Iteration 9260, loss = 0.0390024
I0524 18:37:07.897140  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984234
I0524 18:37:07.897146  8086 solver.cpp:244]     Train net output #1: loss = 0.0390024 (* 1 = 0.0390024 loss)
I0524 18:37:07.897151  8086 sgd_solver.cpp:106] Iteration 9260, lr = 1e-05
I0524 18:37:15.640184  8086 solver.cpp:228] Iteration 9280, loss = 0.0630956
I0524 18:37:15.640307  8086 solver.cpp:244]     Train net output #0: accuracy = 0.973355
I0524 18:37:15.640317  8086 solver.cpp:244]     Train net output #1: loss = 0.0630956 (* 1 = 0.0630956 loss)
I0524 18:37:15.640322  8086 sgd_solver.cpp:106] Iteration 9280, lr = 1e-05
I0524 18:37:23.159988  8086 solver.cpp:337] Iteration 9300, Testing net (#0)
I0524 18:37:23.671499  8086 solver.cpp:404]     Test net output #0: accuracy = 0.979401
I0524 18:37:23.671522  8086 solver.cpp:404]     Test net output #1: loss = 0.0506655 (* 1 = 0.0506655 loss)
I0524 18:37:23.900755  8086 solver.cpp:228] Iteration 9300, loss = 0.0335666
I0524 18:37:23.900789  8086 solver.cpp:244]     Train net output #0: accuracy = 0.988043
I0524 18:37:23.900796  8086 solver.cpp:244]     Train net output #1: loss = 0.0335666 (* 1 = 0.0335666 loss)
I0524 18:37:23.900801  8086 sgd_solver.cpp:106] Iteration 9300, lr = 1e-05
I0524 18:37:31.646426  8086 solver.cpp:228] Iteration 9320, loss = 0.0381013
I0524 18:37:31.646462  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987445
I0524 18:37:31.646469  8086 solver.cpp:244]     Train net output #1: loss = 0.0381013 (* 1 = 0.0381013 loss)
I0524 18:37:31.646476  8086 sgd_solver.cpp:106] Iteration 9320, lr = 1e-05
I0524 18:37:39.391721  8086 solver.cpp:228] Iteration 9340, loss = 0.0468557
I0524 18:37:39.391757  8086 solver.cpp:244]     Train net output #0: accuracy = 0.978023
I0524 18:37:39.391763  8086 solver.cpp:244]     Train net output #1: loss = 0.0468557 (* 1 = 0.0468557 loss)
I0524 18:37:39.391768  8086 sgd_solver.cpp:106] Iteration 9340, lr = 1e-05
I0524 18:37:47.138541  8086 solver.cpp:228] Iteration 9360, loss = 0.0342421
I0524 18:37:47.138649  8086 solver.cpp:244]     Train net output #0: accuracy = 0.988066
I0524 18:37:47.138659  8086 solver.cpp:244]     Train net output #1: loss = 0.0342421 (* 1 = 0.0342421 loss)
I0524 18:37:47.138664  8086 sgd_solver.cpp:106] Iteration 9360, lr = 1e-05
I0524 18:37:54.884080  8086 solver.cpp:228] Iteration 9380, loss = 0.0398675
I0524 18:37:54.884104  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985129
I0524 18:37:54.884110  8086 solver.cpp:244]     Train net output #1: loss = 0.0398675 (* 1 = 0.0398675 loss)
I0524 18:37:54.884116  8086 sgd_solver.cpp:106] Iteration 9380, lr = 1e-05
I0524 18:38:02.403126  8086 solver.cpp:337] Iteration 9400, Testing net (#0)
I0524 18:38:02.914288  8086 solver.cpp:404]     Test net output #0: accuracy = 0.984394
I0524 18:38:02.914324  8086 solver.cpp:404]     Test net output #1: loss = 0.041252 (* 1 = 0.041252 loss)
I0524 18:38:03.142740  8086 solver.cpp:228] Iteration 9400, loss = 0.0324885
I0524 18:38:03.142762  8086 solver.cpp:244]     Train net output #0: accuracy = 0.987955
I0524 18:38:03.142770  8086 solver.cpp:244]     Train net output #1: loss = 0.0324885 (* 1 = 0.0324885 loss)
I0524 18:38:03.142774  8086 sgd_solver.cpp:106] Iteration 9400, lr = 1e-05
I0524 18:38:10.885536  8086 solver.cpp:228] Iteration 9420, loss = 0.0352868
I0524 18:38:10.885571  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985471
I0524 18:38:10.885577  8086 solver.cpp:244]     Train net output #1: loss = 0.0352868 (* 1 = 0.0352868 loss)
I0524 18:38:10.885582  8086 sgd_solver.cpp:106] Iteration 9420, lr = 1e-05
I0524 18:38:18.624868  8086 solver.cpp:228] Iteration 9440, loss = 0.043812
I0524 18:38:18.625002  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982858
I0524 18:38:18.625012  8086 solver.cpp:244]     Train net output #1: loss = 0.043812 (* 1 = 0.043812 loss)
I0524 18:38:18.625018  8086 sgd_solver.cpp:106] Iteration 9440, lr = 1e-05
I0524 18:38:26.367122  8086 solver.cpp:228] Iteration 9460, loss = 0.042736
I0524 18:38:26.367147  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986631
I0524 18:38:26.367154  8086 solver.cpp:244]     Train net output #1: loss = 0.0427361 (* 1 = 0.0427361 loss)
I0524 18:38:26.367161  8086 sgd_solver.cpp:106] Iteration 9460, lr = 1e-05
I0524 18:38:34.114441  8086 solver.cpp:228] Iteration 9480, loss = 0.0455143
I0524 18:38:34.114466  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982109
I0524 18:38:34.114473  8086 solver.cpp:244]     Train net output #1: loss = 0.0455143 (* 1 = 0.0455143 loss)
I0524 18:38:34.114478  8086 sgd_solver.cpp:106] Iteration 9480, lr = 1e-05
I0524 18:38:41.629784  8086 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_9500.caffemodel
I0524 18:38:41.648490  8086 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_9500.solverstate
I0524 18:38:41.657032  8086 solver.cpp:337] Iteration 9500, Testing net (#0)
I0524 18:38:42.170944  8086 solver.cpp:404]     Test net output #0: accuracy = 0.981865
I0524 18:38:42.170979  8086 solver.cpp:404]     Test net output #1: loss = 0.0430318 (* 1 = 0.0430318 loss)
I0524 18:38:42.399600  8086 solver.cpp:228] Iteration 9500, loss = 0.038014
I0524 18:38:42.399623  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984922
I0524 18:38:42.399631  8086 solver.cpp:244]     Train net output #1: loss = 0.038014 (* 1 = 0.038014 loss)
I0524 18:38:42.399636  8086 sgd_solver.cpp:106] Iteration 9500, lr = 1e-05
I0524 18:38:50.145143  8086 solver.cpp:228] Iteration 9520, loss = 0.02962
I0524 18:38:50.145242  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98961
I0524 18:38:50.145252  8086 solver.cpp:244]     Train net output #1: loss = 0.02962 (* 1 = 0.02962 loss)
I0524 18:38:50.145257  8086 sgd_solver.cpp:106] Iteration 9520, lr = 1e-05
I0524 18:38:57.883213  8086 solver.cpp:228] Iteration 9540, loss = 0.0410383
I0524 18:38:57.883236  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982804
I0524 18:38:57.883244  8086 solver.cpp:244]     Train net output #1: loss = 0.0410383 (* 1 = 0.0410383 loss)
I0524 18:38:57.883249  8086 sgd_solver.cpp:106] Iteration 9540, lr = 1e-05
I0524 18:39:05.622993  8086 solver.cpp:228] Iteration 9560, loss = 0.0411116
I0524 18:39:05.623018  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984572
I0524 18:39:05.623026  8086 solver.cpp:244]     Train net output #1: loss = 0.0411116 (* 1 = 0.0411116 loss)
I0524 18:39:05.623030  8086 sgd_solver.cpp:106] Iteration 9560, lr = 1e-05
I0524 18:39:13.376854  8086 solver.cpp:228] Iteration 9580, loss = 0.0521796
I0524 18:39:13.376888  8086 solver.cpp:244]     Train net output #0: accuracy = 0.97774
I0524 18:39:13.376894  8086 solver.cpp:244]     Train net output #1: loss = 0.0521796 (* 1 = 0.0521796 loss)
I0524 18:39:13.376899  8086 sgd_solver.cpp:106] Iteration 9580, lr = 1e-05
I0524 18:39:20.904449  8086 solver.cpp:337] Iteration 9600, Testing net (#0)
I0524 18:39:21.416419  8086 solver.cpp:404]     Test net output #0: accuracy = 0.986823
I0524 18:39:21.416452  8086 solver.cpp:404]     Test net output #1: loss = 0.039458 (* 1 = 0.039458 loss)
I0524 18:39:21.645716  8086 solver.cpp:228] Iteration 9600, loss = 0.0454834
I0524 18:39:21.645740  8086 solver.cpp:244]     Train net output #0: accuracy = 0.984036
I0524 18:39:21.645747  8086 solver.cpp:244]     Train net output #1: loss = 0.0454834 (* 1 = 0.0454834 loss)
I0524 18:39:21.645752  8086 sgd_solver.cpp:106] Iteration 9600, lr = 1e-05
I0524 18:39:29.390736  8086 solver.cpp:228] Iteration 9620, loss = 0.0371386
I0524 18:39:29.390759  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985243
I0524 18:39:29.390766  8086 solver.cpp:244]     Train net output #1: loss = 0.0371386 (* 1 = 0.0371386 loss)
I0524 18:39:29.390771  8086 sgd_solver.cpp:106] Iteration 9620, lr = 1e-05
I0524 18:39:37.133577  8086 solver.cpp:228] Iteration 9640, loss = 0.0376045
I0524 18:39:37.133612  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986646
I0524 18:39:37.133620  8086 solver.cpp:244]     Train net output #1: loss = 0.0376045 (* 1 = 0.0376045 loss)
I0524 18:39:37.133625  8086 sgd_solver.cpp:106] Iteration 9640, lr = 1e-05
I0524 18:39:44.876915  8086 solver.cpp:228] Iteration 9660, loss = 0.0527918
I0524 18:39:44.876950  8086 solver.cpp:244]     Train net output #0: accuracy = 0.976156
I0524 18:39:44.876957  8086 solver.cpp:244]     Train net output #1: loss = 0.0527918 (* 1 = 0.0527918 loss)
I0524 18:39:44.876962  8086 sgd_solver.cpp:106] Iteration 9660, lr = 1e-05
I0524 18:39:52.622707  8086 solver.cpp:228] Iteration 9680, loss = 0.0532277
I0524 18:39:52.622833  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982305
I0524 18:39:52.622843  8086 solver.cpp:244]     Train net output #1: loss = 0.0532277 (* 1 = 0.0532277 loss)
I0524 18:39:52.622849  8086 sgd_solver.cpp:106] Iteration 9680, lr = 1e-05
I0524 18:40:00.145388  8086 solver.cpp:337] Iteration 9700, Testing net (#0)
I0524 18:40:00.677073  8086 solver.cpp:404]     Test net output #0: accuracy = 0.984286
I0524 18:40:00.677109  8086 solver.cpp:404]     Test net output #1: loss = 0.0402423 (* 1 = 0.0402423 loss)
I0524 18:40:00.906255  8086 solver.cpp:228] Iteration 9700, loss = 0.0443725
I0524 18:40:00.906289  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98202
I0524 18:40:00.906297  8086 solver.cpp:244]     Train net output #1: loss = 0.0443725 (* 1 = 0.0443725 loss)
I0524 18:40:00.906302  8086 sgd_solver.cpp:106] Iteration 9700, lr = 1e-05
I0524 18:40:08.657582  8086 solver.cpp:228] Iteration 9720, loss = 0.0501234
I0524 18:40:08.657606  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981475
I0524 18:40:08.657613  8086 solver.cpp:244]     Train net output #1: loss = 0.0501234 (* 1 = 0.0501234 loss)
I0524 18:40:08.657618  8086 sgd_solver.cpp:106] Iteration 9720, lr = 1e-05
I0524 18:40:16.403210  8086 solver.cpp:228] Iteration 9740, loss = 0.0455888
I0524 18:40:16.403234  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980626
I0524 18:40:16.403241  8086 solver.cpp:244]     Train net output #1: loss = 0.0455888 (* 1 = 0.0455888 loss)
I0524 18:40:16.403247  8086 sgd_solver.cpp:106] Iteration 9740, lr = 1e-05
I0524 18:40:24.144575  8086 solver.cpp:228] Iteration 9760, loss = 0.0360497
I0524 18:40:24.144680  8086 solver.cpp:244]     Train net output #0: accuracy = 0.983826
I0524 18:40:24.144688  8086 solver.cpp:244]     Train net output #1: loss = 0.0360497 (* 1 = 0.0360497 loss)
I0524 18:40:24.144695  8086 sgd_solver.cpp:106] Iteration 9760, lr = 1e-05
I0524 18:40:31.887516  8086 solver.cpp:228] Iteration 9780, loss = 0.0442567
I0524 18:40:31.887540  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980175
I0524 18:40:31.887548  8086 solver.cpp:244]     Train net output #1: loss = 0.0442567 (* 1 = 0.0442567 loss)
I0524 18:40:31.887553  8086 sgd_solver.cpp:106] Iteration 9780, lr = 1e-05
I0524 18:40:39.403280  8086 solver.cpp:337] Iteration 9800, Testing net (#0)
I0524 18:40:39.915742  8086 solver.cpp:404]     Test net output #0: accuracy = 0.982185
I0524 18:40:39.915776  8086 solver.cpp:404]     Test net output #1: loss = 0.044572 (* 1 = 0.044572 loss)
I0524 18:40:40.144649  8086 solver.cpp:228] Iteration 9800, loss = 0.0406825
I0524 18:40:40.144672  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982583
I0524 18:40:40.144680  8086 solver.cpp:244]     Train net output #1: loss = 0.0406825 (* 1 = 0.0406825 loss)
I0524 18:40:40.144685  8086 sgd_solver.cpp:106] Iteration 9800, lr = 1e-05
I0524 18:40:47.883975  8086 solver.cpp:228] Iteration 9820, loss = 0.0482928
I0524 18:40:47.884011  8086 solver.cpp:244]     Train net output #0: accuracy = 0.980271
I0524 18:40:47.884017  8086 solver.cpp:244]     Train net output #1: loss = 0.0482928 (* 1 = 0.0482928 loss)
I0524 18:40:47.884022  8086 sgd_solver.cpp:106] Iteration 9820, lr = 1e-05
I0524 18:40:55.631464  8086 solver.cpp:228] Iteration 9840, loss = 0.0466678
I0524 18:40:55.631579  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98246
I0524 18:40:55.631589  8086 solver.cpp:244]     Train net output #1: loss = 0.0466678 (* 1 = 0.0466678 loss)
I0524 18:40:55.631594  8086 sgd_solver.cpp:106] Iteration 9840, lr = 1e-05
I0524 18:41:03.370157  8086 solver.cpp:228] Iteration 9860, loss = 0.0377981
I0524 18:41:03.370192  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985784
I0524 18:41:03.370199  8086 solver.cpp:244]     Train net output #1: loss = 0.0377981 (* 1 = 0.0377981 loss)
I0524 18:41:03.370204  8086 sgd_solver.cpp:106] Iteration 9860, lr = 1e-05
I0524 18:41:11.114965  8086 solver.cpp:228] Iteration 9880, loss = 0.0542451
I0524 18:41:11.115001  8086 solver.cpp:244]     Train net output #0: accuracy = 0.978113
I0524 18:41:11.115008  8086 solver.cpp:244]     Train net output #1: loss = 0.0542451 (* 1 = 0.0542451 loss)
I0524 18:41:11.115013  8086 sgd_solver.cpp:106] Iteration 9880, lr = 1e-05
I0524 18:41:18.639480  8086 solver.cpp:337] Iteration 9900, Testing net (#0)
I0524 18:41:19.151118  8086 solver.cpp:404]     Test net output #0: accuracy = 0.980763
I0524 18:41:19.151154  8086 solver.cpp:404]     Test net output #1: loss = 0.0490766 (* 1 = 0.0490766 loss)
I0524 18:41:19.379886  8086 solver.cpp:228] Iteration 9900, loss = 0.0436494
I0524 18:41:19.379921  8086 solver.cpp:244]     Train net output #0: accuracy = 0.985135
I0524 18:41:19.379928  8086 solver.cpp:244]     Train net output #1: loss = 0.0436494 (* 1 = 0.0436494 loss)
I0524 18:41:19.379933  8086 sgd_solver.cpp:106] Iteration 9900, lr = 1e-05
I0524 18:41:27.124368  8086 solver.cpp:228] Iteration 9920, loss = 0.0585127
I0524 18:41:27.124474  8086 solver.cpp:244]     Train net output #0: accuracy = 0.98022
I0524 18:41:27.124482  8086 solver.cpp:244]     Train net output #1: loss = 0.0585127 (* 1 = 0.0585127 loss)
I0524 18:41:27.124487  8086 sgd_solver.cpp:106] Iteration 9920, lr = 1e-05
I0524 18:41:34.869096  8086 solver.cpp:228] Iteration 9940, loss = 0.0398718
I0524 18:41:34.869129  8086 solver.cpp:244]     Train net output #0: accuracy = 0.982119
I0524 18:41:34.869137  8086 solver.cpp:244]     Train net output #1: loss = 0.0398718 (* 1 = 0.0398718 loss)
I0524 18:41:34.869143  8086 sgd_solver.cpp:106] Iteration 9940, lr = 1e-05
I0524 18:41:42.611270  8086 solver.cpp:228] Iteration 9960, loss = 0.044385
I0524 18:41:42.611305  8086 solver.cpp:244]     Train net output #0: accuracy = 0.986015
I0524 18:41:42.611312  8086 solver.cpp:244]     Train net output #1: loss = 0.044385 (* 1 = 0.044385 loss)
I0524 18:41:42.611318  8086 sgd_solver.cpp:106] Iteration 9960, lr = 1e-05
I0524 18:41:50.354579  8086 solver.cpp:228] Iteration 9980, loss = 0.0430048
I0524 18:41:50.354614  8086 solver.cpp:244]     Train net output #0: accuracy = 0.981211
I0524 18:41:50.354620  8086 solver.cpp:244]     Train net output #1: loss = 0.0430048 (* 1 = 0.0430048 loss)
I0524 18:41:50.354625  8086 sgd_solver.cpp:106] Iteration 9980, lr = 1e-05
I0524 18:41:57.868993  8086 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_10000.caffemodel
I0524 18:41:57.887707  8086 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_10000.solverstate
I0524 18:41:58.121527  8086 solver.cpp:317] Iteration 10000, loss = 0.0398346
I0524 18:41:58.121562  8086 solver.cpp:337] Iteration 10000, Testing net (#0)
I0524 18:41:58.633283  8086 solver.cpp:404]     Test net output #0: accuracy = 0.986643
I0524 18:41:58.633307  8086 solver.cpp:404]     Test net output #1: loss = 0.0388763 (* 1 = 0.0388763 loss)
I0524 18:41:58.633311  8086 solver.cpp:322] Optimization Done.
I0524 18:41:58.633313  8086 caffe.cpp:222] Optimization Done.
