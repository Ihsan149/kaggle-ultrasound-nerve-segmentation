I0622 16:36:26.858348  3302 caffe.cpp:185] Using GPUs 1
I0622 16:36:26.866196  3302 caffe.cpp:190] GPU 1: GeForce GTX TITAN X
I0622 16:36:27.159574  3302 solver.cpp:48] Initializing solver from parameters: 
test_iter: 16
test_interval: 100
base_lr: 0.01
display: 20
max_iter: 6000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 500
snapshot_prefix: "data/models/segnet"
solver_mode: GPU
device_id: 1
net: "models/segnet/train_val.prototxt"
test_initialization: true
I0622 16:36:27.160783  3302 solver.cpp:91] Creating training net from net file: models/segnet/train_val.prototxt
I0622 16:36:27.161880  3302 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0622 16:36:27.162102  3302 net.cpp:49] Initializing net from parameters: 
name: "segnet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "DenseImageData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    crop_size: 224
    mean_value: 100
  }
  dense_image_data_param {
    source: "data/train.txt"
    batch_size: 64
    shuffle: true
    new_height: 224
    new_width: 310
    is_color: false
    root_folder: "data/raw/train/"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_1"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 14
    upsample_w: 14
  }
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5_1_D"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1_D"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 28
    upsample_w: 28
  }
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4_1_D"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1_D"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
    upsample_h: 56
    upsample_w: 56
  }
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3_1_D"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1_D"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
    upsample_h: 112
    upsample_w: 112
  }
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2_1_D"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1_D"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
    upsample_h: 224
    upsample_w: 224
  }
}
layer {
  name: "conv1_1_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "accuracy"
}
I0622 16:36:27.162276  3302 layer_factory.hpp:77] Creating layer data
I0622 16:36:27.163065  3302 net.cpp:91] Creating Layer data
I0622 16:36:27.163076  3302 net.cpp:399] data -> data
I0622 16:36:27.163096  3302 net.cpp:399] data -> label
I0622 16:36:27.163385  3302 dense_image_data_layer.cpp:38] Opening file data/train.txt
I0622 16:36:27.167296  3302 dense_image_data_layer.cpp:48] Shuffling data
I0622 16:36:27.168555  3302 dense_image_data_layer.cpp:53] A total of 4930 examples.
I0622 16:36:27.364405  3302 dense_image_data_layer.cpp:92] output data size: 1,1,224,224
I0622 16:36:27.366374  3302 net.cpp:141] Setting up data
I0622 16:36:27.366395  3302 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0622 16:36:27.366400  3302 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0622 16:36:27.366401  3302 net.cpp:156] Memory required for data: 401408
I0622 16:36:27.366407  3302 layer_factory.hpp:77] Creating layer label_data_1_split
I0622 16:36:27.366792  3302 net.cpp:91] Creating Layer label_data_1_split
I0622 16:36:27.366801  3302 net.cpp:425] label_data_1_split <- label
I0622 16:36:27.366827  3302 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0622 16:36:27.366835  3302 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0622 16:36:27.367141  3302 net.cpp:141] Setting up label_data_1_split
I0622 16:36:27.367149  3302 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0622 16:36:27.367152  3302 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0622 16:36:27.367154  3302 net.cpp:156] Memory required for data: 802816
I0622 16:36:27.367157  3302 layer_factory.hpp:77] Creating layer conv1_1
I0622 16:36:27.367171  3302 net.cpp:91] Creating Layer conv1_1
I0622 16:36:27.367173  3302 net.cpp:425] conv1_1 <- data
I0622 16:36:27.367177  3302 net.cpp:399] conv1_1 -> conv1_1
I0622 16:36:27.738808  3302 net.cpp:141] Setting up conv1_1
I0622 16:36:27.738831  3302 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0622 16:36:27.738833  3302 net.cpp:156] Memory required for data: 13647872
I0622 16:36:27.738844  3302 layer_factory.hpp:77] Creating layer bn1_1
I0622 16:36:27.738858  3302 net.cpp:91] Creating Layer bn1_1
I0622 16:36:27.738862  3302 net.cpp:425] bn1_1 <- conv1_1
I0622 16:36:27.738865  3302 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0622 16:36:27.739042  3302 net.cpp:141] Setting up bn1_1
I0622 16:36:27.739048  3302 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0622 16:36:27.739050  3302 net.cpp:156] Memory required for data: 26492928
I0622 16:36:27.739059  3302 layer_factory.hpp:77] Creating layer scale1_1
I0622 16:36:27.739069  3302 net.cpp:91] Creating Layer scale1_1
I0622 16:36:27.739073  3302 net.cpp:425] scale1_1 <- conv1_1
I0622 16:36:27.739078  3302 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0622 16:36:27.739112  3302 layer_factory.hpp:77] Creating layer scale1_1
I0622 16:36:27.739259  3302 net.cpp:141] Setting up scale1_1
I0622 16:36:27.739264  3302 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0622 16:36:27.739266  3302 net.cpp:156] Memory required for data: 39337984
I0622 16:36:27.739272  3302 layer_factory.hpp:77] Creating layer relu1_1
I0622 16:36:27.739276  3302 net.cpp:91] Creating Layer relu1_1
I0622 16:36:27.739279  3302 net.cpp:425] relu1_1 <- conv1_1
I0622 16:36:27.739282  3302 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0622 16:36:27.739533  3302 net.cpp:141] Setting up relu1_1
I0622 16:36:27.739543  3302 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0622 16:36:27.739545  3302 net.cpp:156] Memory required for data: 52183040
I0622 16:36:27.739548  3302 layer_factory.hpp:77] Creating layer pool1
I0622 16:36:27.739552  3302 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0622 16:36:27.739557  3302 net.cpp:91] Creating Layer pool1
I0622 16:36:27.739558  3302 net.cpp:425] pool1 <- conv1_1
I0622 16:36:27.739562  3302 net.cpp:399] pool1 -> pool1
I0622 16:36:27.739568  3302 net.cpp:399] pool1 -> pool1_mask
I0622 16:36:27.739603  3302 net.cpp:141] Setting up pool1
I0622 16:36:27.739609  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.739611  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.739614  3302 net.cpp:156] Memory required for data: 58605568
I0622 16:36:27.739616  3302 layer_factory.hpp:77] Creating layer conv2_1
I0622 16:36:27.739624  3302 net.cpp:91] Creating Layer conv2_1
I0622 16:36:27.739625  3302 net.cpp:425] conv2_1 <- pool1
I0622 16:36:27.739629  3302 net.cpp:399] conv2_1 -> conv2_1
I0622 16:36:27.741600  3302 net.cpp:141] Setting up conv2_1
I0622 16:36:27.741611  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.741613  3302 net.cpp:156] Memory required for data: 61816832
I0622 16:36:27.741617  3302 layer_factory.hpp:77] Creating layer bn2_1
I0622 16:36:27.741624  3302 net.cpp:91] Creating Layer bn2_1
I0622 16:36:27.741626  3302 net.cpp:425] bn2_1 <- conv2_1
I0622 16:36:27.741631  3302 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0622 16:36:27.742285  3302 net.cpp:141] Setting up bn2_1
I0622 16:36:27.742295  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.742296  3302 net.cpp:156] Memory required for data: 65028096
I0622 16:36:27.742316  3302 layer_factory.hpp:77] Creating layer scale2_1
I0622 16:36:27.742322  3302 net.cpp:91] Creating Layer scale2_1
I0622 16:36:27.742326  3302 net.cpp:425] scale2_1 <- conv2_1
I0622 16:36:27.742328  3302 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0622 16:36:27.742359  3302 layer_factory.hpp:77] Creating layer scale2_1
I0622 16:36:27.742447  3302 net.cpp:141] Setting up scale2_1
I0622 16:36:27.742455  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.742456  3302 net.cpp:156] Memory required for data: 68239360
I0622 16:36:27.742460  3302 layer_factory.hpp:77] Creating layer relu2_1
I0622 16:36:27.742465  3302 net.cpp:91] Creating Layer relu2_1
I0622 16:36:27.742466  3302 net.cpp:425] relu2_1 <- conv2_1
I0622 16:36:27.742470  3302 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0622 16:36:27.742597  3302 net.cpp:141] Setting up relu2_1
I0622 16:36:27.742604  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.742607  3302 net.cpp:156] Memory required for data: 71450624
I0622 16:36:27.742609  3302 layer_factory.hpp:77] Creating layer pool2
I0622 16:36:27.742612  3302 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0622 16:36:27.742616  3302 net.cpp:91] Creating Layer pool2
I0622 16:36:27.742619  3302 net.cpp:425] pool2 <- conv2_1
I0622 16:36:27.742622  3302 net.cpp:399] pool2 -> pool2
I0622 16:36:27.742627  3302 net.cpp:399] pool2 -> pool2_mask
I0622 16:36:27.742656  3302 net.cpp:141] Setting up pool2
I0622 16:36:27.742661  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.742665  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.742666  3302 net.cpp:156] Memory required for data: 73056256
I0622 16:36:27.742668  3302 layer_factory.hpp:77] Creating layer conv3_1
I0622 16:36:27.742674  3302 net.cpp:91] Creating Layer conv3_1
I0622 16:36:27.742676  3302 net.cpp:425] conv3_1 <- pool2
I0622 16:36:27.742681  3302 net.cpp:399] conv3_1 -> conv3_1
I0622 16:36:27.744365  3302 net.cpp:141] Setting up conv3_1
I0622 16:36:27.744375  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.744379  3302 net.cpp:156] Memory required for data: 73859072
I0622 16:36:27.744382  3302 layer_factory.hpp:77] Creating layer bn3_1
I0622 16:36:27.744387  3302 net.cpp:91] Creating Layer bn3_1
I0622 16:36:27.744391  3302 net.cpp:425] bn3_1 <- conv3_1
I0622 16:36:27.744395  3302 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0622 16:36:27.745035  3302 net.cpp:141] Setting up bn3_1
I0622 16:36:27.745044  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.745046  3302 net.cpp:156] Memory required for data: 74661888
I0622 16:36:27.745052  3302 layer_factory.hpp:77] Creating layer scale3_1
I0622 16:36:27.745057  3302 net.cpp:91] Creating Layer scale3_1
I0622 16:36:27.745060  3302 net.cpp:425] scale3_1 <- conv3_1
I0622 16:36:27.745064  3302 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0622 16:36:27.745093  3302 layer_factory.hpp:77] Creating layer scale3_1
I0622 16:36:27.745175  3302 net.cpp:141] Setting up scale3_1
I0622 16:36:27.745180  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.745182  3302 net.cpp:156] Memory required for data: 75464704
I0622 16:36:27.745189  3302 layer_factory.hpp:77] Creating layer relu3_1
I0622 16:36:27.745193  3302 net.cpp:91] Creating Layer relu3_1
I0622 16:36:27.745195  3302 net.cpp:425] relu3_1 <- conv3_1
I0622 16:36:27.745198  3302 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0622 16:36:27.745434  3302 net.cpp:141] Setting up relu3_1
I0622 16:36:27.745443  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.745445  3302 net.cpp:156] Memory required for data: 76267520
I0622 16:36:27.745448  3302 layer_factory.hpp:77] Creating layer pool3
I0622 16:36:27.745451  3302 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0622 16:36:27.745456  3302 net.cpp:91] Creating Layer pool3
I0622 16:36:27.745458  3302 net.cpp:425] pool3 <- conv3_1
I0622 16:36:27.745462  3302 net.cpp:399] pool3 -> pool3
I0622 16:36:27.745477  3302 net.cpp:399] pool3 -> pool3_mask
I0622 16:36:27.745520  3302 net.cpp:141] Setting up pool3
I0622 16:36:27.745527  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.745529  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.745532  3302 net.cpp:156] Memory required for data: 76668928
I0622 16:36:27.745534  3302 layer_factory.hpp:77] Creating layer conv4_1
I0622 16:36:27.745540  3302 net.cpp:91] Creating Layer conv4_1
I0622 16:36:27.745543  3302 net.cpp:425] conv4_1 <- pool3
I0622 16:36:27.745548  3302 net.cpp:399] conv4_1 -> conv4_1
I0622 16:36:27.747136  3302 net.cpp:141] Setting up conv4_1
I0622 16:36:27.747148  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.747149  3302 net.cpp:156] Memory required for data: 76869632
I0622 16:36:27.747153  3302 layer_factory.hpp:77] Creating layer bn4_1
I0622 16:36:27.747159  3302 net.cpp:91] Creating Layer bn4_1
I0622 16:36:27.747161  3302 net.cpp:425] bn4_1 <- conv4_1
I0622 16:36:27.747165  3302 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0622 16:36:27.747304  3302 net.cpp:141] Setting up bn4_1
I0622 16:36:27.747311  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.747313  3302 net.cpp:156] Memory required for data: 77070336
I0622 16:36:27.747318  3302 layer_factory.hpp:77] Creating layer scale4_1
I0622 16:36:27.747323  3302 net.cpp:91] Creating Layer scale4_1
I0622 16:36:27.747325  3302 net.cpp:425] scale4_1 <- conv4_1
I0622 16:36:27.747329  3302 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0622 16:36:27.747357  3302 layer_factory.hpp:77] Creating layer scale4_1
I0622 16:36:27.747442  3302 net.cpp:141] Setting up scale4_1
I0622 16:36:27.747447  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.747448  3302 net.cpp:156] Memory required for data: 77271040
I0622 16:36:27.747453  3302 layer_factory.hpp:77] Creating layer relu4_1
I0622 16:36:27.747468  3302 net.cpp:91] Creating Layer relu4_1
I0622 16:36:27.747473  3302 net.cpp:425] relu4_1 <- conv4_1
I0622 16:36:27.747478  3302 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0622 16:36:27.747730  3302 net.cpp:141] Setting up relu4_1
I0622 16:36:27.747740  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.747743  3302 net.cpp:156] Memory required for data: 77471744
I0622 16:36:27.747748  3302 layer_factory.hpp:77] Creating layer pool4
I0622 16:36:27.747752  3302 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0622 16:36:27.747759  3302 net.cpp:91] Creating Layer pool4
I0622 16:36:27.747763  3302 net.cpp:425] pool4 <- conv4_1
I0622 16:36:27.747767  3302 net.cpp:399] pool4 -> pool4
I0622 16:36:27.747772  3302 net.cpp:399] pool4 -> pool4_mask
I0622 16:36:27.747805  3302 net.cpp:141] Setting up pool4
I0622 16:36:27.747810  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.747813  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.747815  3302 net.cpp:156] Memory required for data: 77572096
I0622 16:36:27.747817  3302 layer_factory.hpp:77] Creating layer conv5_1
I0622 16:36:27.747824  3302 net.cpp:91] Creating Layer conv5_1
I0622 16:36:27.747826  3302 net.cpp:425] conv5_1 <- pool4
I0622 16:36:27.747830  3302 net.cpp:399] conv5_1 -> conv5_1
I0622 16:36:27.750031  3302 net.cpp:141] Setting up conv5_1
I0622 16:36:27.750043  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.750046  3302 net.cpp:156] Memory required for data: 77622272
I0622 16:36:27.750049  3302 layer_factory.hpp:77] Creating layer bn5_1
I0622 16:36:27.750056  3302 net.cpp:91] Creating Layer bn5_1
I0622 16:36:27.750057  3302 net.cpp:425] bn5_1 <- conv5_1
I0622 16:36:27.750061  3302 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0622 16:36:27.750205  3302 net.cpp:141] Setting up bn5_1
I0622 16:36:27.750211  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.750213  3302 net.cpp:156] Memory required for data: 77672448
I0622 16:36:27.750219  3302 layer_factory.hpp:77] Creating layer scale5_1
I0622 16:36:27.750224  3302 net.cpp:91] Creating Layer scale5_1
I0622 16:36:27.750227  3302 net.cpp:425] scale5_1 <- conv5_1
I0622 16:36:27.750241  3302 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0622 16:36:27.750272  3302 layer_factory.hpp:77] Creating layer scale5_1
I0622 16:36:27.750355  3302 net.cpp:141] Setting up scale5_1
I0622 16:36:27.750360  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.750362  3302 net.cpp:156] Memory required for data: 77722624
I0622 16:36:27.750366  3302 layer_factory.hpp:77] Creating layer relu5_1
I0622 16:36:27.750370  3302 net.cpp:91] Creating Layer relu5_1
I0622 16:36:27.750372  3302 net.cpp:425] relu5_1 <- conv5_1
I0622 16:36:27.750375  3302 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0622 16:36:27.750502  3302 net.cpp:141] Setting up relu5_1
I0622 16:36:27.750509  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.750511  3302 net.cpp:156] Memory required for data: 77772800
I0622 16:36:27.750514  3302 layer_factory.hpp:77] Creating layer pool5
I0622 16:36:27.750517  3302 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0622 16:36:27.750521  3302 net.cpp:91] Creating Layer pool5
I0622 16:36:27.750524  3302 net.cpp:425] pool5 <- conv5_1
I0622 16:36:27.750527  3302 net.cpp:399] pool5 -> pool5
I0622 16:36:27.750532  3302 net.cpp:399] pool5 -> pool5_mask
I0622 16:36:27.750562  3302 net.cpp:141] Setting up pool5
I0622 16:36:27.750568  3302 net.cpp:148] Top shape: 1 64 7 7 (3136)
I0622 16:36:27.750571  3302 net.cpp:148] Top shape: 1 64 7 7 (3136)
I0622 16:36:27.750573  3302 net.cpp:156] Memory required for data: 77797888
I0622 16:36:27.750576  3302 layer_factory.hpp:77] Creating layer upsample5
I0622 16:36:27.750581  3302 net.cpp:91] Creating Layer upsample5
I0622 16:36:27.750582  3302 net.cpp:425] upsample5 <- pool5
I0622 16:36:27.750586  3302 net.cpp:425] upsample5 <- pool5_mask
I0622 16:36:27.750588  3302 net.cpp:399] upsample5 -> pool5_D
I0622 16:36:27.750608  3302 net.cpp:141] Setting up upsample5
I0622 16:36:27.750612  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.750613  3302 net.cpp:156] Memory required for data: 77848064
I0622 16:36:27.750615  3302 layer_factory.hpp:77] Creating layer conv5_1_D
I0622 16:36:27.750622  3302 net.cpp:91] Creating Layer conv5_1_D
I0622 16:36:27.750624  3302 net.cpp:425] conv5_1_D <- pool5_D
I0622 16:36:27.750628  3302 net.cpp:399] conv5_1_D -> conv5_1_D
I0622 16:36:27.752305  3302 net.cpp:141] Setting up conv5_1_D
I0622 16:36:27.752315  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.752329  3302 net.cpp:156] Memory required for data: 77898240
I0622 16:36:27.752333  3302 layer_factory.hpp:77] Creating layer bn5_1_D
I0622 16:36:27.752338  3302 net.cpp:91] Creating Layer bn5_1_D
I0622 16:36:27.752341  3302 net.cpp:425] bn5_1_D <- conv5_1_D
I0622 16:36:27.752346  3302 net.cpp:386] bn5_1_D -> conv5_1_D (in-place)
I0622 16:36:27.752493  3302 net.cpp:141] Setting up bn5_1_D
I0622 16:36:27.752498  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.752501  3302 net.cpp:156] Memory required for data: 77948416
I0622 16:36:27.752511  3302 layer_factory.hpp:77] Creating layer scale5_1_D
I0622 16:36:27.752516  3302 net.cpp:91] Creating Layer scale5_1_D
I0622 16:36:27.752518  3302 net.cpp:425] scale5_1_D <- conv5_1_D
I0622 16:36:27.752521  3302 net.cpp:386] scale5_1_D -> conv5_1_D (in-place)
I0622 16:36:27.752550  3302 layer_factory.hpp:77] Creating layer scale5_1_D
I0622 16:36:27.752631  3302 net.cpp:141] Setting up scale5_1_D
I0622 16:36:27.752636  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.752638  3302 net.cpp:156] Memory required for data: 77998592
I0622 16:36:27.752642  3302 layer_factory.hpp:77] Creating layer relu5_1_D
I0622 16:36:27.752646  3302 net.cpp:91] Creating Layer relu5_1_D
I0622 16:36:27.752648  3302 net.cpp:425] relu5_1_D <- conv5_1_D
I0622 16:36:27.752651  3302 net.cpp:386] relu5_1_D -> conv5_1_D (in-place)
I0622 16:36:27.752897  3302 net.cpp:141] Setting up relu5_1_D
I0622 16:36:27.752905  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.752907  3302 net.cpp:156] Memory required for data: 78048768
I0622 16:36:27.752910  3302 layer_factory.hpp:77] Creating layer upsample4
I0622 16:36:27.752926  3302 net.cpp:91] Creating Layer upsample4
I0622 16:36:27.752930  3302 net.cpp:425] upsample4 <- conv5_1_D
I0622 16:36:27.752933  3302 net.cpp:425] upsample4 <- pool4_mask
I0622 16:36:27.752938  3302 net.cpp:399] upsample4 -> pool4_D
I0622 16:36:27.752961  3302 net.cpp:141] Setting up upsample4
I0622 16:36:27.752966  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.752969  3302 net.cpp:156] Memory required for data: 78249472
I0622 16:36:27.752970  3302 layer_factory.hpp:77] Creating layer conv4_1_D
I0622 16:36:27.752976  3302 net.cpp:91] Creating Layer conv4_1_D
I0622 16:36:27.752979  3302 net.cpp:425] conv4_1_D <- pool4_D
I0622 16:36:27.752984  3302 net.cpp:399] conv4_1_D -> conv4_1_D
I0622 16:36:27.754614  3302 net.cpp:141] Setting up conv4_1_D
I0622 16:36:27.754624  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.754627  3302 net.cpp:156] Memory required for data: 78450176
I0622 16:36:27.754631  3302 layer_factory.hpp:77] Creating layer bn4_1_D
I0622 16:36:27.754637  3302 net.cpp:91] Creating Layer bn4_1_D
I0622 16:36:27.754640  3302 net.cpp:425] bn4_1_D <- conv4_1_D
I0622 16:36:27.754644  3302 net.cpp:386] bn4_1_D -> conv4_1_D (in-place)
I0622 16:36:27.754801  3302 net.cpp:141] Setting up bn4_1_D
I0622 16:36:27.754806  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.754807  3302 net.cpp:156] Memory required for data: 78650880
I0622 16:36:27.754813  3302 layer_factory.hpp:77] Creating layer scale4_1_D
I0622 16:36:27.754818  3302 net.cpp:91] Creating Layer scale4_1_D
I0622 16:36:27.754822  3302 net.cpp:425] scale4_1_D <- conv4_1_D
I0622 16:36:27.754827  3302 net.cpp:386] scale4_1_D -> conv4_1_D (in-place)
I0622 16:36:27.754858  3302 layer_factory.hpp:77] Creating layer scale4_1_D
I0622 16:36:27.754956  3302 net.cpp:141] Setting up scale4_1_D
I0622 16:36:27.754961  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.754962  3302 net.cpp:156] Memory required for data: 78851584
I0622 16:36:27.754966  3302 layer_factory.hpp:77] Creating layer relu4_1_D
I0622 16:36:27.754971  3302 net.cpp:91] Creating Layer relu4_1_D
I0622 16:36:27.754973  3302 net.cpp:425] relu4_1_D <- conv4_1_D
I0622 16:36:27.754978  3302 net.cpp:386] relu4_1_D -> conv4_1_D (in-place)
I0622 16:36:27.755223  3302 net.cpp:141] Setting up relu4_1_D
I0622 16:36:27.755231  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.755234  3302 net.cpp:156] Memory required for data: 79052288
I0622 16:36:27.755236  3302 layer_factory.hpp:77] Creating layer upsample3
I0622 16:36:27.755240  3302 net.cpp:91] Creating Layer upsample3
I0622 16:36:27.755244  3302 net.cpp:425] upsample3 <- conv4_1_D
I0622 16:36:27.755246  3302 net.cpp:425] upsample3 <- pool3_mask
I0622 16:36:27.755250  3302 net.cpp:399] upsample3 -> pool3_D
I0622 16:36:27.755275  3302 net.cpp:141] Setting up upsample3
I0622 16:36:27.755280  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.755281  3302 net.cpp:156] Memory required for data: 79855104
I0622 16:36:27.755283  3302 layer_factory.hpp:77] Creating layer conv3_1_D
I0622 16:36:27.755290  3302 net.cpp:91] Creating Layer conv3_1_D
I0622 16:36:27.755293  3302 net.cpp:425] conv3_1_D <- pool3_D
I0622 16:36:27.755297  3302 net.cpp:399] conv3_1_D -> conv3_1_D
I0622 16:36:27.757153  3302 net.cpp:141] Setting up conv3_1_D
I0622 16:36:27.757163  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.757164  3302 net.cpp:156] Memory required for data: 80657920
I0622 16:36:27.757169  3302 layer_factory.hpp:77] Creating layer bn3_1_D
I0622 16:36:27.757175  3302 net.cpp:91] Creating Layer bn3_1_D
I0622 16:36:27.757177  3302 net.cpp:425] bn3_1_D <- conv3_1_D
I0622 16:36:27.757181  3302 net.cpp:386] bn3_1_D -> conv3_1_D (in-place)
I0622 16:36:27.757344  3302 net.cpp:141] Setting up bn3_1_D
I0622 16:36:27.757350  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.757354  3302 net.cpp:156] Memory required for data: 81460736
I0622 16:36:27.757359  3302 layer_factory.hpp:77] Creating layer scale3_1_D
I0622 16:36:27.757374  3302 net.cpp:91] Creating Layer scale3_1_D
I0622 16:36:27.757377  3302 net.cpp:425] scale3_1_D <- conv3_1_D
I0622 16:36:27.757380  3302 net.cpp:386] scale3_1_D -> conv3_1_D (in-place)
I0622 16:36:27.757414  3302 layer_factory.hpp:77] Creating layer scale3_1_D
I0622 16:36:27.757522  3302 net.cpp:141] Setting up scale3_1_D
I0622 16:36:27.757529  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.757531  3302 net.cpp:156] Memory required for data: 82263552
I0622 16:36:27.757535  3302 layer_factory.hpp:77] Creating layer relu3_1_D
I0622 16:36:27.757539  3302 net.cpp:91] Creating Layer relu3_1_D
I0622 16:36:27.757541  3302 net.cpp:425] relu3_1_D <- conv3_1_D
I0622 16:36:27.757546  3302 net.cpp:386] relu3_1_D -> conv3_1_D (in-place)
I0622 16:36:27.757681  3302 net.cpp:141] Setting up relu3_1_D
I0622 16:36:27.757688  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.757691  3302 net.cpp:156] Memory required for data: 83066368
I0622 16:36:27.757695  3302 layer_factory.hpp:77] Creating layer upsample2
I0622 16:36:27.757699  3302 net.cpp:91] Creating Layer upsample2
I0622 16:36:27.757702  3302 net.cpp:425] upsample2 <- conv3_1_D
I0622 16:36:27.757705  3302 net.cpp:425] upsample2 <- pool2_mask
I0622 16:36:27.757709  3302 net.cpp:399] upsample2 -> pool2_D
I0622 16:36:27.757735  3302 net.cpp:141] Setting up upsample2
I0622 16:36:27.757740  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.757741  3302 net.cpp:156] Memory required for data: 86277632
I0622 16:36:27.757745  3302 layer_factory.hpp:77] Creating layer conv2_1_D
I0622 16:36:27.757750  3302 net.cpp:91] Creating Layer conv2_1_D
I0622 16:36:27.757753  3302 net.cpp:425] conv2_1_D <- pool2_D
I0622 16:36:27.757756  3302 net.cpp:399] conv2_1_D -> conv2_1_D
I0622 16:36:27.759511  3302 net.cpp:141] Setting up conv2_1_D
I0622 16:36:27.759522  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.759526  3302 net.cpp:156] Memory required for data: 89488896
I0622 16:36:27.759529  3302 layer_factory.hpp:77] Creating layer bn2_1_D
I0622 16:36:27.759536  3302 net.cpp:91] Creating Layer bn2_1_D
I0622 16:36:27.759538  3302 net.cpp:425] bn2_1_D <- conv2_1_D
I0622 16:36:27.759541  3302 net.cpp:386] bn2_1_D -> conv2_1_D (in-place)
I0622 16:36:27.759704  3302 net.cpp:141] Setting up bn2_1_D
I0622 16:36:27.759711  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.759712  3302 net.cpp:156] Memory required for data: 92700160
I0622 16:36:27.759718  3302 layer_factory.hpp:77] Creating layer scale2_1_D
I0622 16:36:27.759723  3302 net.cpp:91] Creating Layer scale2_1_D
I0622 16:36:27.759727  3302 net.cpp:425] scale2_1_D <- conv2_1_D
I0622 16:36:27.759730  3302 net.cpp:386] scale2_1_D -> conv2_1_D (in-place)
I0622 16:36:27.759763  3302 layer_factory.hpp:77] Creating layer scale2_1_D
I0622 16:36:27.759865  3302 net.cpp:141] Setting up scale2_1_D
I0622 16:36:27.759870  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.759871  3302 net.cpp:156] Memory required for data: 95911424
I0622 16:36:27.759876  3302 layer_factory.hpp:77] Creating layer relu2_1_D
I0622 16:36:27.759879  3302 net.cpp:91] Creating Layer relu2_1_D
I0622 16:36:27.759882  3302 net.cpp:425] relu2_1_D <- conv2_1_D
I0622 16:36:27.759886  3302 net.cpp:386] relu2_1_D -> conv2_1_D (in-place)
I0622 16:36:27.760135  3302 net.cpp:141] Setting up relu2_1_D
I0622 16:36:27.760143  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.760146  3302 net.cpp:156] Memory required for data: 99122688
I0622 16:36:27.760149  3302 layer_factory.hpp:77] Creating layer upsample1
I0622 16:36:27.760155  3302 net.cpp:91] Creating Layer upsample1
I0622 16:36:27.760159  3302 net.cpp:425] upsample1 <- conv2_1_D
I0622 16:36:27.760161  3302 net.cpp:425] upsample1 <- pool1_mask
I0622 16:36:27.760165  3302 net.cpp:399] upsample1 -> pool1_D
I0622 16:36:27.760190  3302 net.cpp:141] Setting up upsample1
I0622 16:36:27.760195  3302 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0622 16:36:27.760196  3302 net.cpp:156] Memory required for data: 111967744
I0622 16:36:27.760207  3302 layer_factory.hpp:77] Creating layer conv1_1_D
I0622 16:36:27.760216  3302 net.cpp:91] Creating Layer conv1_1_D
I0622 16:36:27.760220  3302 net.cpp:425] conv1_1_D <- pool1_D
I0622 16:36:27.760223  3302 net.cpp:399] conv1_1_D -> conv1_1_D
I0622 16:36:27.761109  3302 net.cpp:141] Setting up conv1_1_D
I0622 16:36:27.761121  3302 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0622 16:36:27.761122  3302 net.cpp:156] Memory required for data: 112369152
I0622 16:36:27.761128  3302 layer_factory.hpp:77] Creating layer conv1_1_D_conv1_1_D_0_split
I0622 16:36:27.761133  3302 net.cpp:91] Creating Layer conv1_1_D_conv1_1_D_0_split
I0622 16:36:27.761137  3302 net.cpp:425] conv1_1_D_conv1_1_D_0_split <- conv1_1_D
I0622 16:36:27.761142  3302 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_0
I0622 16:36:27.761147  3302 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_1
I0622 16:36:27.761183  3302 net.cpp:141] Setting up conv1_1_D_conv1_1_D_0_split
I0622 16:36:27.761188  3302 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0622 16:36:27.761191  3302 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0622 16:36:27.761193  3302 net.cpp:156] Memory required for data: 113171968
I0622 16:36:27.761195  3302 layer_factory.hpp:77] Creating layer loss
I0622 16:36:27.761199  3302 net.cpp:91] Creating Layer loss
I0622 16:36:27.761201  3302 net.cpp:425] loss <- conv1_1_D_conv1_1_D_0_split_0
I0622 16:36:27.761205  3302 net.cpp:425] loss <- label_data_1_split_0
I0622 16:36:27.761209  3302 net.cpp:399] loss -> loss
I0622 16:36:27.761214  3302 layer_factory.hpp:77] Creating layer loss
I0622 16:36:27.762418  3302 net.cpp:141] Setting up loss
I0622 16:36:27.762428  3302 net.cpp:148] Top shape: (1)
I0622 16:36:27.762431  3302 net.cpp:151]     with loss weight 1
I0622 16:36:27.762445  3302 net.cpp:156] Memory required for data: 113171972
I0622 16:36:27.762449  3302 layer_factory.hpp:77] Creating layer accuracy
I0622 16:36:27.762454  3302 net.cpp:91] Creating Layer accuracy
I0622 16:36:27.762457  3302 net.cpp:425] accuracy <- conv1_1_D_conv1_1_D_0_split_1
I0622 16:36:27.762460  3302 net.cpp:425] accuracy <- label_data_1_split_1
I0622 16:36:27.762464  3302 net.cpp:399] accuracy -> accuracy
I0622 16:36:27.762472  3302 net.cpp:141] Setting up accuracy
I0622 16:36:27.762477  3302 net.cpp:148] Top shape: (1)
I0622 16:36:27.762480  3302 net.cpp:156] Memory required for data: 113171976
I0622 16:36:27.762481  3302 net.cpp:219] accuracy does not need backward computation.
I0622 16:36:27.762483  3302 net.cpp:217] loss needs backward computation.
I0622 16:36:27.762486  3302 net.cpp:217] conv1_1_D_conv1_1_D_0_split needs backward computation.
I0622 16:36:27.762488  3302 net.cpp:217] conv1_1_D needs backward computation.
I0622 16:36:27.762490  3302 net.cpp:217] upsample1 needs backward computation.
I0622 16:36:27.762493  3302 net.cpp:217] relu2_1_D needs backward computation.
I0622 16:36:27.762495  3302 net.cpp:217] scale2_1_D needs backward computation.
I0622 16:36:27.762496  3302 net.cpp:217] bn2_1_D needs backward computation.
I0622 16:36:27.762498  3302 net.cpp:217] conv2_1_D needs backward computation.
I0622 16:36:27.762501  3302 net.cpp:217] upsample2 needs backward computation.
I0622 16:36:27.762503  3302 net.cpp:217] relu3_1_D needs backward computation.
I0622 16:36:27.762506  3302 net.cpp:217] scale3_1_D needs backward computation.
I0622 16:36:27.762506  3302 net.cpp:217] bn3_1_D needs backward computation.
I0622 16:36:27.762508  3302 net.cpp:217] conv3_1_D needs backward computation.
I0622 16:36:27.762511  3302 net.cpp:217] upsample3 needs backward computation.
I0622 16:36:27.762513  3302 net.cpp:217] relu4_1_D needs backward computation.
I0622 16:36:27.762516  3302 net.cpp:217] scale4_1_D needs backward computation.
I0622 16:36:27.762516  3302 net.cpp:217] bn4_1_D needs backward computation.
I0622 16:36:27.762518  3302 net.cpp:217] conv4_1_D needs backward computation.
I0622 16:36:27.762521  3302 net.cpp:217] upsample4 needs backward computation.
I0622 16:36:27.762522  3302 net.cpp:217] relu5_1_D needs backward computation.
I0622 16:36:27.762532  3302 net.cpp:217] scale5_1_D needs backward computation.
I0622 16:36:27.762534  3302 net.cpp:217] bn5_1_D needs backward computation.
I0622 16:36:27.762537  3302 net.cpp:217] conv5_1_D needs backward computation.
I0622 16:36:27.762538  3302 net.cpp:217] upsample5 needs backward computation.
I0622 16:36:27.762540  3302 net.cpp:217] pool5 needs backward computation.
I0622 16:36:27.762542  3302 net.cpp:217] relu5_1 needs backward computation.
I0622 16:36:27.762544  3302 net.cpp:217] scale5_1 needs backward computation.
I0622 16:36:27.762547  3302 net.cpp:217] bn5_1 needs backward computation.
I0622 16:36:27.762548  3302 net.cpp:217] conv5_1 needs backward computation.
I0622 16:36:27.762550  3302 net.cpp:217] pool4 needs backward computation.
I0622 16:36:27.762552  3302 net.cpp:217] relu4_1 needs backward computation.
I0622 16:36:27.762555  3302 net.cpp:217] scale4_1 needs backward computation.
I0622 16:36:27.762557  3302 net.cpp:217] bn4_1 needs backward computation.
I0622 16:36:27.762558  3302 net.cpp:217] conv4_1 needs backward computation.
I0622 16:36:27.762560  3302 net.cpp:217] pool3 needs backward computation.
I0622 16:36:27.762563  3302 net.cpp:217] relu3_1 needs backward computation.
I0622 16:36:27.762565  3302 net.cpp:217] scale3_1 needs backward computation.
I0622 16:36:27.762567  3302 net.cpp:217] bn3_1 needs backward computation.
I0622 16:36:27.762569  3302 net.cpp:217] conv3_1 needs backward computation.
I0622 16:36:27.762572  3302 net.cpp:217] pool2 needs backward computation.
I0622 16:36:27.762573  3302 net.cpp:217] relu2_1 needs backward computation.
I0622 16:36:27.762575  3302 net.cpp:217] scale2_1 needs backward computation.
I0622 16:36:27.762578  3302 net.cpp:217] bn2_1 needs backward computation.
I0622 16:36:27.762579  3302 net.cpp:217] conv2_1 needs backward computation.
I0622 16:36:27.762581  3302 net.cpp:217] pool1 needs backward computation.
I0622 16:36:27.762583  3302 net.cpp:217] relu1_1 needs backward computation.
I0622 16:36:27.762585  3302 net.cpp:217] scale1_1 needs backward computation.
I0622 16:36:27.762588  3302 net.cpp:217] bn1_1 needs backward computation.
I0622 16:36:27.762589  3302 net.cpp:217] conv1_1 needs backward computation.
I0622 16:36:27.762593  3302 net.cpp:219] label_data_1_split does not need backward computation.
I0622 16:36:27.762595  3302 net.cpp:219] data does not need backward computation.
I0622 16:36:27.762596  3302 net.cpp:261] This network produces output accuracy
I0622 16:36:27.762599  3302 net.cpp:261] This network produces output loss
I0622 16:36:27.762620  3302 net.cpp:274] Network initialization done.
I0622 16:36:27.763476  3302 solver.cpp:181] Creating test net (#0) specified by net file: models/segnet/train_val.prototxt
I0622 16:36:27.763527  3302 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0622 16:36:27.763737  3302 net.cpp:49] Initializing net from parameters: 
name: "segnet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "DenseImageData"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 224
    mean_value: 100
  }
  dense_image_data_param {
    source: "data/val.txt"
    batch_size: 4
    shuffle: true
    new_height: 224
    new_width: 310
    is_color: false
    root_folder: "data/raw/train/"
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_1"
  top: "pool1"
  top: "pool1_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_1"
  top: "pool2"
  top: "pool2_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_1"
  top: "pool3"
  top: "pool3_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_1"
  top: "pool4"
  top: "pool4_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_1"
  top: "pool5"
  top: "pool5_mask"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "upsample5"
  type: "Upsample"
  bottom: "pool5"
  bottom: "pool5_mask"
  top: "pool5_D"
  upsample_param {
    scale: 2
    upsample_h: 14
    upsample_w: 14
  }
}
layer {
  name: "conv5_1_D"
  type: "Convolution"
  bottom: "pool5_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn5_1_D"
  type: "BatchNorm"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1_D"
  type: "Scale"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1_D"
  type: "ReLU"
  bottom: "conv5_1_D"
  top: "conv5_1_D"
}
layer {
  name: "upsample4"
  type: "Upsample"
  bottom: "conv5_1_D"
  bottom: "pool4_mask"
  top: "pool4_D"
  upsample_param {
    scale: 2
    upsample_h: 28
    upsample_w: 28
  }
}
layer {
  name: "conv4_1_D"
  type: "Convolution"
  bottom: "pool4_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn4_1_D"
  type: "BatchNorm"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1_D"
  type: "Scale"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1_D"
  type: "ReLU"
  bottom: "conv4_1_D"
  top: "conv4_1_D"
}
layer {
  name: "upsample3"
  type: "Upsample"
  bottom: "conv4_1_D"
  bottom: "pool3_mask"
  top: "pool3_D"
  upsample_param {
    scale: 2
    upsample_h: 56
    upsample_w: 56
  }
}
layer {
  name: "conv3_1_D"
  type: "Convolution"
  bottom: "pool3_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn3_1_D"
  type: "BatchNorm"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1_D"
  type: "Scale"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1_D"
  type: "ReLU"
  bottom: "conv3_1_D"
  top: "conv3_1_D"
}
layer {
  name: "upsample2"
  type: "Upsample"
  bottom: "conv3_1_D"
  bottom: "pool2_mask"
  top: "pool2_D"
  upsample_param {
    scale: 2
    upsample_h: 112
    upsample_w: 112
  }
}
layer {
  name: "conv2_1_D"
  type: "Convolution"
  bottom: "pool2_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "bn2_1_D"
  type: "BatchNorm"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1_D"
  type: "Scale"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1_D"
  type: "ReLU"
  bottom: "conv2_1_D"
  top: "conv2_1_D"
}
layer {
  name: "upsample1"
  type: "Upsample"
  bottom: "conv2_1_D"
  bottom: "pool1_mask"
  top: "pool1_D"
  upsample_param {
    scale: 2
    upsample_h: 224
    upsample_w: 224
  }
}
layer {
  name: "conv1_1_D"
  type: "Convolution"
  bottom: "pool1_D"
  top: "conv1_1_D"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 2
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "msra"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "conv1_1_D"
  bottom: "label"
  top: "accuracy"
}
I0622 16:36:27.763876  3302 layer_factory.hpp:77] Creating layer data
I0622 16:36:27.763887  3302 net.cpp:91] Creating Layer data
I0622 16:36:27.763890  3302 net.cpp:399] data -> data
I0622 16:36:27.763896  3302 net.cpp:399] data -> label
I0622 16:36:27.763905  3302 dense_image_data_layer.cpp:38] Opening file data/val.txt
I0622 16:36:27.764367  3302 dense_image_data_layer.cpp:48] Shuffling data
I0622 16:36:27.764441  3302 dense_image_data_layer.cpp:53] A total of 705 examples.
I0622 16:36:27.769733  3302 dense_image_data_layer.cpp:92] output data size: 1,1,224,224
I0622 16:36:27.771138  3302 net.cpp:141] Setting up data
I0622 16:36:27.771149  3302 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0622 16:36:27.771153  3302 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0622 16:36:27.771155  3302 net.cpp:156] Memory required for data: 401408
I0622 16:36:27.771160  3302 layer_factory.hpp:77] Creating layer label_data_1_split
I0622 16:36:27.771168  3302 net.cpp:91] Creating Layer label_data_1_split
I0622 16:36:27.771173  3302 net.cpp:425] label_data_1_split <- label
I0622 16:36:27.771178  3302 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0622 16:36:27.771184  3302 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0622 16:36:27.771270  3302 net.cpp:141] Setting up label_data_1_split
I0622 16:36:27.771276  3302 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0622 16:36:27.771280  3302 net.cpp:148] Top shape: 1 1 224 224 (50176)
I0622 16:36:27.771282  3302 net.cpp:156] Memory required for data: 802816
I0622 16:36:27.771286  3302 layer_factory.hpp:77] Creating layer conv1_1
I0622 16:36:27.771294  3302 net.cpp:91] Creating Layer conv1_1
I0622 16:36:27.771298  3302 net.cpp:425] conv1_1 <- data
I0622 16:36:27.771301  3302 net.cpp:399] conv1_1 -> conv1_1
I0622 16:36:27.772307  3302 net.cpp:141] Setting up conv1_1
I0622 16:36:27.772320  3302 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0622 16:36:27.772321  3302 net.cpp:156] Memory required for data: 13647872
I0622 16:36:27.772327  3302 layer_factory.hpp:77] Creating layer bn1_1
I0622 16:36:27.772337  3302 net.cpp:91] Creating Layer bn1_1
I0622 16:36:27.772341  3302 net.cpp:425] bn1_1 <- conv1_1
I0622 16:36:27.772347  3302 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0622 16:36:27.772533  3302 net.cpp:141] Setting up bn1_1
I0622 16:36:27.772542  3302 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0622 16:36:27.772547  3302 net.cpp:156] Memory required for data: 26492928
I0622 16:36:27.772558  3302 layer_factory.hpp:77] Creating layer scale1_1
I0622 16:36:27.772569  3302 net.cpp:91] Creating Layer scale1_1
I0622 16:36:27.772575  3302 net.cpp:425] scale1_1 <- conv1_1
I0622 16:36:27.772581  3302 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0622 16:36:27.772624  3302 layer_factory.hpp:77] Creating layer scale1_1
I0622 16:36:27.772766  3302 net.cpp:141] Setting up scale1_1
I0622 16:36:27.772775  3302 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0622 16:36:27.772792  3302 net.cpp:156] Memory required for data: 39337984
I0622 16:36:27.772799  3302 layer_factory.hpp:77] Creating layer relu1_1
I0622 16:36:27.772807  3302 net.cpp:91] Creating Layer relu1_1
I0622 16:36:27.772811  3302 net.cpp:425] relu1_1 <- conv1_1
I0622 16:36:27.772832  3302 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0622 16:36:27.772997  3302 net.cpp:141] Setting up relu1_1
I0622 16:36:27.773011  3302 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0622 16:36:27.773015  3302 net.cpp:156] Memory required for data: 52183040
I0622 16:36:27.773020  3302 layer_factory.hpp:77] Creating layer pool1
I0622 16:36:27.773025  3302 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0622 16:36:27.773032  3302 net.cpp:91] Creating Layer pool1
I0622 16:36:27.773037  3302 net.cpp:425] pool1 <- conv1_1
I0622 16:36:27.773046  3302 net.cpp:399] pool1 -> pool1
I0622 16:36:27.773053  3302 net.cpp:399] pool1 -> pool1_mask
I0622 16:36:27.773105  3302 net.cpp:141] Setting up pool1
I0622 16:36:27.773111  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.773113  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.773115  3302 net.cpp:156] Memory required for data: 58605568
I0622 16:36:27.773118  3302 layer_factory.hpp:77] Creating layer conv2_1
I0622 16:36:27.773124  3302 net.cpp:91] Creating Layer conv2_1
I0622 16:36:27.773128  3302 net.cpp:425] conv2_1 <- pool1
I0622 16:36:27.773130  3302 net.cpp:399] conv2_1 -> conv2_1
I0622 16:36:27.774888  3302 net.cpp:141] Setting up conv2_1
I0622 16:36:27.774900  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.774902  3302 net.cpp:156] Memory required for data: 61816832
I0622 16:36:27.774906  3302 layer_factory.hpp:77] Creating layer bn2_1
I0622 16:36:27.774914  3302 net.cpp:91] Creating Layer bn2_1
I0622 16:36:27.774916  3302 net.cpp:425] bn2_1 <- conv2_1
I0622 16:36:27.774920  3302 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0622 16:36:27.775085  3302 net.cpp:141] Setting up bn2_1
I0622 16:36:27.775091  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.775094  3302 net.cpp:156] Memory required for data: 65028096
I0622 16:36:27.775100  3302 layer_factory.hpp:77] Creating layer scale2_1
I0622 16:36:27.775107  3302 net.cpp:91] Creating Layer scale2_1
I0622 16:36:27.775110  3302 net.cpp:425] scale2_1 <- conv2_1
I0622 16:36:27.775115  3302 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0622 16:36:27.775146  3302 layer_factory.hpp:77] Creating layer scale2_1
I0622 16:36:27.775249  3302 net.cpp:141] Setting up scale2_1
I0622 16:36:27.775254  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.775256  3302 net.cpp:156] Memory required for data: 68239360
I0622 16:36:27.775260  3302 layer_factory.hpp:77] Creating layer relu2_1
I0622 16:36:27.775264  3302 net.cpp:91] Creating Layer relu2_1
I0622 16:36:27.775267  3302 net.cpp:425] relu2_1 <- conv2_1
I0622 16:36:27.775270  3302 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0622 16:36:27.775528  3302 net.cpp:141] Setting up relu2_1
I0622 16:36:27.775538  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.775540  3302 net.cpp:156] Memory required for data: 71450624
I0622 16:36:27.775542  3302 layer_factory.hpp:77] Creating layer pool2
I0622 16:36:27.775545  3302 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0622 16:36:27.775549  3302 net.cpp:91] Creating Layer pool2
I0622 16:36:27.775552  3302 net.cpp:425] pool2 <- conv2_1
I0622 16:36:27.775557  3302 net.cpp:399] pool2 -> pool2
I0622 16:36:27.775563  3302 net.cpp:399] pool2 -> pool2_mask
I0622 16:36:27.775599  3302 net.cpp:141] Setting up pool2
I0622 16:36:27.775604  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.775606  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.775609  3302 net.cpp:156] Memory required for data: 73056256
I0622 16:36:27.775610  3302 layer_factory.hpp:77] Creating layer conv3_1
I0622 16:36:27.775616  3302 net.cpp:91] Creating Layer conv3_1
I0622 16:36:27.775629  3302 net.cpp:425] conv3_1 <- pool2
I0622 16:36:27.775635  3302 net.cpp:399] conv3_1 -> conv3_1
I0622 16:36:27.778422  3302 net.cpp:141] Setting up conv3_1
I0622 16:36:27.778439  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.778441  3302 net.cpp:156] Memory required for data: 73859072
I0622 16:36:27.778447  3302 layer_factory.hpp:77] Creating layer bn3_1
I0622 16:36:27.778456  3302 net.cpp:91] Creating Layer bn3_1
I0622 16:36:27.778460  3302 net.cpp:425] bn3_1 <- conv3_1
I0622 16:36:27.778465  3302 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0622 16:36:27.778635  3302 net.cpp:141] Setting up bn3_1
I0622 16:36:27.778643  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.778646  3302 net.cpp:156] Memory required for data: 74661888
I0622 16:36:27.778656  3302 layer_factory.hpp:77] Creating layer scale3_1
I0622 16:36:27.778666  3302 net.cpp:91] Creating Layer scale3_1
I0622 16:36:27.778686  3302 net.cpp:425] scale3_1 <- conv3_1
I0622 16:36:27.778693  3302 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0622 16:36:27.778741  3302 layer_factory.hpp:77] Creating layer scale3_1
I0622 16:36:27.778858  3302 net.cpp:141] Setting up scale3_1
I0622 16:36:27.778867  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.778870  3302 net.cpp:156] Memory required for data: 75464704
I0622 16:36:27.778882  3302 layer_factory.hpp:77] Creating layer relu3_1
I0622 16:36:27.778889  3302 net.cpp:91] Creating Layer relu3_1
I0622 16:36:27.778906  3302 net.cpp:425] relu3_1 <- conv3_1
I0622 16:36:27.778913  3302 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0622 16:36:27.779177  3302 net.cpp:141] Setting up relu3_1
I0622 16:36:27.779188  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.779192  3302 net.cpp:156] Memory required for data: 76267520
I0622 16:36:27.779196  3302 layer_factory.hpp:77] Creating layer pool3
I0622 16:36:27.779203  3302 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0622 16:36:27.779211  3302 net.cpp:91] Creating Layer pool3
I0622 16:36:27.779213  3302 net.cpp:425] pool3 <- conv3_1
I0622 16:36:27.779218  3302 net.cpp:399] pool3 -> pool3
I0622 16:36:27.779223  3302 net.cpp:399] pool3 -> pool3_mask
I0622 16:36:27.779263  3302 net.cpp:141] Setting up pool3
I0622 16:36:27.779269  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.779273  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.779274  3302 net.cpp:156] Memory required for data: 76668928
I0622 16:36:27.779276  3302 layer_factory.hpp:77] Creating layer conv4_1
I0622 16:36:27.779284  3302 net.cpp:91] Creating Layer conv4_1
I0622 16:36:27.779286  3302 net.cpp:425] conv4_1 <- pool3
I0622 16:36:27.779289  3302 net.cpp:399] conv4_1 -> conv4_1
I0622 16:36:27.781112  3302 net.cpp:141] Setting up conv4_1
I0622 16:36:27.781131  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.781133  3302 net.cpp:156] Memory required for data: 76869632
I0622 16:36:27.781141  3302 layer_factory.hpp:77] Creating layer bn4_1
I0622 16:36:27.781150  3302 net.cpp:91] Creating Layer bn4_1
I0622 16:36:27.781172  3302 net.cpp:425] bn4_1 <- conv4_1
I0622 16:36:27.781180  3302 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0622 16:36:27.781376  3302 net.cpp:141] Setting up bn4_1
I0622 16:36:27.781385  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.781388  3302 net.cpp:156] Memory required for data: 77070336
I0622 16:36:27.781397  3302 layer_factory.hpp:77] Creating layer scale4_1
I0622 16:36:27.781407  3302 net.cpp:91] Creating Layer scale4_1
I0622 16:36:27.781412  3302 net.cpp:425] scale4_1 <- conv4_1
I0622 16:36:27.781419  3302 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0622 16:36:27.781464  3302 layer_factory.hpp:77] Creating layer scale4_1
I0622 16:36:27.781577  3302 net.cpp:141] Setting up scale4_1
I0622 16:36:27.781585  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.781589  3302 net.cpp:156] Memory required for data: 77271040
I0622 16:36:27.781595  3302 layer_factory.hpp:77] Creating layer relu4_1
I0622 16:36:27.781615  3302 net.cpp:91] Creating Layer relu4_1
I0622 16:36:27.781621  3302 net.cpp:425] relu4_1 <- conv4_1
I0622 16:36:27.781627  3302 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0622 16:36:27.781777  3302 net.cpp:141] Setting up relu4_1
I0622 16:36:27.781787  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.781790  3302 net.cpp:156] Memory required for data: 77471744
I0622 16:36:27.781795  3302 layer_factory.hpp:77] Creating layer pool4
I0622 16:36:27.781798  3302 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0622 16:36:27.781817  3302 net.cpp:91] Creating Layer pool4
I0622 16:36:27.781822  3302 net.cpp:425] pool4 <- conv4_1
I0622 16:36:27.781829  3302 net.cpp:399] pool4 -> pool4
I0622 16:36:27.781847  3302 net.cpp:399] pool4 -> pool4_mask
I0622 16:36:27.781895  3302 net.cpp:141] Setting up pool4
I0622 16:36:27.781903  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.781908  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.781922  3302 net.cpp:156] Memory required for data: 77572096
I0622 16:36:27.781927  3302 layer_factory.hpp:77] Creating layer conv5_1
I0622 16:36:27.781939  3302 net.cpp:91] Creating Layer conv5_1
I0622 16:36:27.781944  3302 net.cpp:425] conv5_1 <- pool4
I0622 16:36:27.781950  3302 net.cpp:399] conv5_1 -> conv5_1
I0622 16:36:27.783813  3302 net.cpp:141] Setting up conv5_1
I0622 16:36:27.783830  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.783834  3302 net.cpp:156] Memory required for data: 77622272
I0622 16:36:27.783840  3302 layer_factory.hpp:77] Creating layer bn5_1
I0622 16:36:27.783852  3302 net.cpp:91] Creating Layer bn5_1
I0622 16:36:27.783856  3302 net.cpp:425] bn5_1 <- conv5_1
I0622 16:36:27.783860  3302 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0622 16:36:27.784044  3302 net.cpp:141] Setting up bn5_1
I0622 16:36:27.784049  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.784052  3302 net.cpp:156] Memory required for data: 77672448
I0622 16:36:27.784057  3302 layer_factory.hpp:77] Creating layer scale5_1
I0622 16:36:27.784065  3302 net.cpp:91] Creating Layer scale5_1
I0622 16:36:27.784067  3302 net.cpp:425] scale5_1 <- conv5_1
I0622 16:36:27.784070  3302 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0622 16:36:27.784104  3302 layer_factory.hpp:77] Creating layer scale5_1
I0622 16:36:27.784199  3302 net.cpp:141] Setting up scale5_1
I0622 16:36:27.784204  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.784206  3302 net.cpp:156] Memory required for data: 77722624
I0622 16:36:27.784210  3302 layer_factory.hpp:77] Creating layer relu5_1
I0622 16:36:27.784214  3302 net.cpp:91] Creating Layer relu5_1
I0622 16:36:27.784216  3302 net.cpp:425] relu5_1 <- conv5_1
I0622 16:36:27.784219  3302 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0622 16:36:27.784477  3302 net.cpp:141] Setting up relu5_1
I0622 16:36:27.784487  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.784489  3302 net.cpp:156] Memory required for data: 77772800
I0622 16:36:27.784492  3302 layer_factory.hpp:77] Creating layer pool5
I0622 16:36:27.784494  3302 layer_factory.cpp:90] cuDNN does not support multiple tops. Using Caffe's own pooling layer.
I0622 16:36:27.784498  3302 net.cpp:91] Creating Layer pool5
I0622 16:36:27.784502  3302 net.cpp:425] pool5 <- conv5_1
I0622 16:36:27.784505  3302 net.cpp:399] pool5 -> pool5
I0622 16:36:27.784510  3302 net.cpp:399] pool5 -> pool5_mask
I0622 16:36:27.784549  3302 net.cpp:141] Setting up pool5
I0622 16:36:27.784554  3302 net.cpp:148] Top shape: 1 64 7 7 (3136)
I0622 16:36:27.784557  3302 net.cpp:148] Top shape: 1 64 7 7 (3136)
I0622 16:36:27.784559  3302 net.cpp:156] Memory required for data: 77797888
I0622 16:36:27.784561  3302 layer_factory.hpp:77] Creating layer upsample5
I0622 16:36:27.784565  3302 net.cpp:91] Creating Layer upsample5
I0622 16:36:27.784567  3302 net.cpp:425] upsample5 <- pool5
I0622 16:36:27.784570  3302 net.cpp:425] upsample5 <- pool5_mask
I0622 16:36:27.784574  3302 net.cpp:399] upsample5 -> pool5_D
I0622 16:36:27.784607  3302 net.cpp:141] Setting up upsample5
I0622 16:36:27.784612  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.784615  3302 net.cpp:156] Memory required for data: 77848064
I0622 16:36:27.784616  3302 layer_factory.hpp:77] Creating layer conv5_1_D
I0622 16:36:27.784622  3302 net.cpp:91] Creating Layer conv5_1_D
I0622 16:36:27.784626  3302 net.cpp:425] conv5_1_D <- pool5_D
I0622 16:36:27.784629  3302 net.cpp:399] conv5_1_D -> conv5_1_D
I0622 16:36:27.786398  3302 net.cpp:141] Setting up conv5_1_D
I0622 16:36:27.786408  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.786411  3302 net.cpp:156] Memory required for data: 77898240
I0622 16:36:27.786414  3302 layer_factory.hpp:77] Creating layer bn5_1_D
I0622 16:36:27.786420  3302 net.cpp:91] Creating Layer bn5_1_D
I0622 16:36:27.786422  3302 net.cpp:425] bn5_1_D <- conv5_1_D
I0622 16:36:27.786427  3302 net.cpp:386] bn5_1_D -> conv5_1_D (in-place)
I0622 16:36:27.786592  3302 net.cpp:141] Setting up bn5_1_D
I0622 16:36:27.786597  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.786599  3302 net.cpp:156] Memory required for data: 77948416
I0622 16:36:27.786608  3302 layer_factory.hpp:77] Creating layer scale5_1_D
I0622 16:36:27.786615  3302 net.cpp:91] Creating Layer scale5_1_D
I0622 16:36:27.786618  3302 net.cpp:425] scale5_1_D <- conv5_1_D
I0622 16:36:27.786623  3302 net.cpp:386] scale5_1_D -> conv5_1_D (in-place)
I0622 16:36:27.786655  3302 layer_factory.hpp:77] Creating layer scale5_1_D
I0622 16:36:27.786751  3302 net.cpp:141] Setting up scale5_1_D
I0622 16:36:27.786756  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.786757  3302 net.cpp:156] Memory required for data: 77998592
I0622 16:36:27.786761  3302 layer_factory.hpp:77] Creating layer relu5_1_D
I0622 16:36:27.786766  3302 net.cpp:91] Creating Layer relu5_1_D
I0622 16:36:27.786767  3302 net.cpp:425] relu5_1_D <- conv5_1_D
I0622 16:36:27.786772  3302 net.cpp:386] relu5_1_D -> conv5_1_D (in-place)
I0622 16:36:27.787019  3302 net.cpp:141] Setting up relu5_1_D
I0622 16:36:27.787029  3302 net.cpp:148] Top shape: 1 64 14 14 (12544)
I0622 16:36:27.787030  3302 net.cpp:156] Memory required for data: 78048768
I0622 16:36:27.787034  3302 layer_factory.hpp:77] Creating layer upsample4
I0622 16:36:27.787040  3302 net.cpp:91] Creating Layer upsample4
I0622 16:36:27.787044  3302 net.cpp:425] upsample4 <- conv5_1_D
I0622 16:36:27.787046  3302 net.cpp:425] upsample4 <- pool4_mask
I0622 16:36:27.787050  3302 net.cpp:399] upsample4 -> pool4_D
I0622 16:36:27.787076  3302 net.cpp:141] Setting up upsample4
I0622 16:36:27.787081  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.787083  3302 net.cpp:156] Memory required for data: 78249472
I0622 16:36:27.787086  3302 layer_factory.hpp:77] Creating layer conv4_1_D
I0622 16:36:27.787091  3302 net.cpp:91] Creating Layer conv4_1_D
I0622 16:36:27.787093  3302 net.cpp:425] conv4_1_D <- pool4_D
I0622 16:36:27.787097  3302 net.cpp:399] conv4_1_D -> conv4_1_D
I0622 16:36:27.788874  3302 net.cpp:141] Setting up conv4_1_D
I0622 16:36:27.788897  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.788898  3302 net.cpp:156] Memory required for data: 78450176
I0622 16:36:27.788913  3302 layer_factory.hpp:77] Creating layer bn4_1_D
I0622 16:36:27.788920  3302 net.cpp:91] Creating Layer bn4_1_D
I0622 16:36:27.788923  3302 net.cpp:425] bn4_1_D <- conv4_1_D
I0622 16:36:27.788928  3302 net.cpp:386] bn4_1_D -> conv4_1_D (in-place)
I0622 16:36:27.789113  3302 net.cpp:141] Setting up bn4_1_D
I0622 16:36:27.789118  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.789119  3302 net.cpp:156] Memory required for data: 78650880
I0622 16:36:27.789124  3302 layer_factory.hpp:77] Creating layer scale4_1_D
I0622 16:36:27.789129  3302 net.cpp:91] Creating Layer scale4_1_D
I0622 16:36:27.789131  3302 net.cpp:425] scale4_1_D <- conv4_1_D
I0622 16:36:27.789135  3302 net.cpp:386] scale4_1_D -> conv4_1_D (in-place)
I0622 16:36:27.789167  3302 layer_factory.hpp:77] Creating layer scale4_1_D
I0622 16:36:27.789268  3302 net.cpp:141] Setting up scale4_1_D
I0622 16:36:27.789283  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.789284  3302 net.cpp:156] Memory required for data: 78851584
I0622 16:36:27.789289  3302 layer_factory.hpp:77] Creating layer relu4_1_D
I0622 16:36:27.789294  3302 net.cpp:91] Creating Layer relu4_1_D
I0622 16:36:27.789295  3302 net.cpp:425] relu4_1_D <- conv4_1_D
I0622 16:36:27.789299  3302 net.cpp:386] relu4_1_D -> conv4_1_D (in-place)
I0622 16:36:27.789443  3302 net.cpp:141] Setting up relu4_1_D
I0622 16:36:27.789451  3302 net.cpp:148] Top shape: 1 64 28 28 (50176)
I0622 16:36:27.789453  3302 net.cpp:156] Memory required for data: 79052288
I0622 16:36:27.789456  3302 layer_factory.hpp:77] Creating layer upsample3
I0622 16:36:27.789461  3302 net.cpp:91] Creating Layer upsample3
I0622 16:36:27.789463  3302 net.cpp:425] upsample3 <- conv4_1_D
I0622 16:36:27.789468  3302 net.cpp:425] upsample3 <- pool3_mask
I0622 16:36:27.789470  3302 net.cpp:399] upsample3 -> pool3_D
I0622 16:36:27.789496  3302 net.cpp:141] Setting up upsample3
I0622 16:36:27.789501  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.789504  3302 net.cpp:156] Memory required for data: 79855104
I0622 16:36:27.789506  3302 layer_factory.hpp:77] Creating layer conv3_1_D
I0622 16:36:27.789512  3302 net.cpp:91] Creating Layer conv3_1_D
I0622 16:36:27.789516  3302 net.cpp:425] conv3_1_D <- pool3_D
I0622 16:36:27.789520  3302 net.cpp:399] conv3_1_D -> conv3_1_D
I0622 16:36:27.791311  3302 net.cpp:141] Setting up conv3_1_D
I0622 16:36:27.791321  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.791323  3302 net.cpp:156] Memory required for data: 80657920
I0622 16:36:27.791329  3302 layer_factory.hpp:77] Creating layer bn3_1_D
I0622 16:36:27.791335  3302 net.cpp:91] Creating Layer bn3_1_D
I0622 16:36:27.791337  3302 net.cpp:425] bn3_1_D <- conv3_1_D
I0622 16:36:27.791342  3302 net.cpp:386] bn3_1_D -> conv3_1_D (in-place)
I0622 16:36:27.791527  3302 net.cpp:141] Setting up bn3_1_D
I0622 16:36:27.791534  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.791537  3302 net.cpp:156] Memory required for data: 81460736
I0622 16:36:27.791546  3302 layer_factory.hpp:77] Creating layer scale3_1_D
I0622 16:36:27.791554  3302 net.cpp:91] Creating Layer scale3_1_D
I0622 16:36:27.791558  3302 net.cpp:425] scale3_1_D <- conv3_1_D
I0622 16:36:27.791563  3302 net.cpp:386] scale3_1_D -> conv3_1_D (in-place)
I0622 16:36:27.791620  3302 layer_factory.hpp:77] Creating layer scale3_1_D
I0622 16:36:27.791760  3302 net.cpp:141] Setting up scale3_1_D
I0622 16:36:27.791769  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.791771  3302 net.cpp:156] Memory required for data: 82263552
I0622 16:36:27.791776  3302 layer_factory.hpp:77] Creating layer relu3_1_D
I0622 16:36:27.791780  3302 net.cpp:91] Creating Layer relu3_1_D
I0622 16:36:27.791782  3302 net.cpp:425] relu3_1_D <- conv3_1_D
I0622 16:36:27.791786  3302 net.cpp:386] relu3_1_D -> conv3_1_D (in-place)
I0622 16:36:27.792048  3302 net.cpp:141] Setting up relu3_1_D
I0622 16:36:27.792057  3302 net.cpp:148] Top shape: 1 64 56 56 (200704)
I0622 16:36:27.792062  3302 net.cpp:156] Memory required for data: 83066368
I0622 16:36:27.792063  3302 layer_factory.hpp:77] Creating layer upsample2
I0622 16:36:27.792068  3302 net.cpp:91] Creating Layer upsample2
I0622 16:36:27.792071  3302 net.cpp:425] upsample2 <- conv3_1_D
I0622 16:36:27.792074  3302 net.cpp:425] upsample2 <- pool2_mask
I0622 16:36:27.792078  3302 net.cpp:399] upsample2 -> pool2_D
I0622 16:36:27.792105  3302 net.cpp:141] Setting up upsample2
I0622 16:36:27.792110  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.792112  3302 net.cpp:156] Memory required for data: 86277632
I0622 16:36:27.792114  3302 layer_factory.hpp:77] Creating layer conv2_1_D
I0622 16:36:27.792121  3302 net.cpp:91] Creating Layer conv2_1_D
I0622 16:36:27.792124  3302 net.cpp:425] conv2_1_D <- pool2_D
I0622 16:36:27.792129  3302 net.cpp:399] conv2_1_D -> conv2_1_D
I0622 16:36:27.793830  3302 net.cpp:141] Setting up conv2_1_D
I0622 16:36:27.793849  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.793853  3302 net.cpp:156] Memory required for data: 89488896
I0622 16:36:27.793856  3302 layer_factory.hpp:77] Creating layer bn2_1_D
I0622 16:36:27.793864  3302 net.cpp:91] Creating Layer bn2_1_D
I0622 16:36:27.793865  3302 net.cpp:425] bn2_1_D <- conv2_1_D
I0622 16:36:27.793870  3302 net.cpp:386] bn2_1_D -> conv2_1_D (in-place)
I0622 16:36:27.794055  3302 net.cpp:141] Setting up bn2_1_D
I0622 16:36:27.794061  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.794064  3302 net.cpp:156] Memory required for data: 92700160
I0622 16:36:27.794070  3302 layer_factory.hpp:77] Creating layer scale2_1_D
I0622 16:36:27.794075  3302 net.cpp:91] Creating Layer scale2_1_D
I0622 16:36:27.794078  3302 net.cpp:425] scale2_1_D <- conv2_1_D
I0622 16:36:27.794085  3302 net.cpp:386] scale2_1_D -> conv2_1_D (in-place)
I0622 16:36:27.794132  3302 layer_factory.hpp:77] Creating layer scale2_1_D
I0622 16:36:27.794260  3302 net.cpp:141] Setting up scale2_1_D
I0622 16:36:27.794270  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.794275  3302 net.cpp:156] Memory required for data: 95911424
I0622 16:36:27.794281  3302 layer_factory.hpp:77] Creating layer relu2_1_D
I0622 16:36:27.794289  3302 net.cpp:91] Creating Layer relu2_1_D
I0622 16:36:27.794292  3302 net.cpp:425] relu2_1_D <- conv2_1_D
I0622 16:36:27.794296  3302 net.cpp:386] relu2_1_D -> conv2_1_D (in-place)
I0622 16:36:27.794558  3302 net.cpp:141] Setting up relu2_1_D
I0622 16:36:27.794566  3302 net.cpp:148] Top shape: 1 64 112 112 (802816)
I0622 16:36:27.794570  3302 net.cpp:156] Memory required for data: 99122688
I0622 16:36:27.794572  3302 layer_factory.hpp:77] Creating layer upsample1
I0622 16:36:27.794579  3302 net.cpp:91] Creating Layer upsample1
I0622 16:36:27.794582  3302 net.cpp:425] upsample1 <- conv2_1_D
I0622 16:36:27.794585  3302 net.cpp:425] upsample1 <- pool1_mask
I0622 16:36:27.794589  3302 net.cpp:399] upsample1 -> pool1_D
I0622 16:36:27.794618  3302 net.cpp:141] Setting up upsample1
I0622 16:36:27.794623  3302 net.cpp:148] Top shape: 1 64 224 224 (3211264)
I0622 16:36:27.794625  3302 net.cpp:156] Memory required for data: 111967744
I0622 16:36:27.794627  3302 layer_factory.hpp:77] Creating layer conv1_1_D
I0622 16:36:27.794636  3302 net.cpp:91] Creating Layer conv1_1_D
I0622 16:36:27.794639  3302 net.cpp:425] conv1_1_D <- pool1_D
I0622 16:36:27.794644  3302 net.cpp:399] conv1_1_D -> conv1_1_D
I0622 16:36:27.795594  3302 net.cpp:141] Setting up conv1_1_D
I0622 16:36:27.795606  3302 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0622 16:36:27.795609  3302 net.cpp:156] Memory required for data: 112369152
I0622 16:36:27.795614  3302 layer_factory.hpp:77] Creating layer conv1_1_D_conv1_1_D_0_split
I0622 16:36:27.795619  3302 net.cpp:91] Creating Layer conv1_1_D_conv1_1_D_0_split
I0622 16:36:27.795624  3302 net.cpp:425] conv1_1_D_conv1_1_D_0_split <- conv1_1_D
I0622 16:36:27.795627  3302 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_0
I0622 16:36:27.795634  3302 net.cpp:399] conv1_1_D_conv1_1_D_0_split -> conv1_1_D_conv1_1_D_0_split_1
I0622 16:36:27.795673  3302 net.cpp:141] Setting up conv1_1_D_conv1_1_D_0_split
I0622 16:36:27.795678  3302 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0622 16:36:27.795681  3302 net.cpp:148] Top shape: 1 2 224 224 (100352)
I0622 16:36:27.795684  3302 net.cpp:156] Memory required for data: 113171968
I0622 16:36:27.795686  3302 layer_factory.hpp:77] Creating layer loss
I0622 16:36:27.795691  3302 net.cpp:91] Creating Layer loss
I0622 16:36:27.795693  3302 net.cpp:425] loss <- conv1_1_D_conv1_1_D_0_split_0
I0622 16:36:27.795697  3302 net.cpp:425] loss <- label_data_1_split_0
I0622 16:36:27.795701  3302 net.cpp:399] loss -> loss
I0622 16:36:27.795708  3302 layer_factory.hpp:77] Creating layer loss
I0622 16:36:27.796005  3302 net.cpp:141] Setting up loss
I0622 16:36:27.796011  3302 net.cpp:148] Top shape: (1)
I0622 16:36:27.796015  3302 net.cpp:151]     with loss weight 1
I0622 16:36:27.796025  3302 net.cpp:156] Memory required for data: 113171972
I0622 16:36:27.796036  3302 layer_factory.hpp:77] Creating layer accuracy
I0622 16:36:27.796041  3302 net.cpp:91] Creating Layer accuracy
I0622 16:36:27.796046  3302 net.cpp:425] accuracy <- conv1_1_D_conv1_1_D_0_split_1
I0622 16:36:27.796048  3302 net.cpp:425] accuracy <- label_data_1_split_1
I0622 16:36:27.796052  3302 net.cpp:399] accuracy -> accuracy
I0622 16:36:27.796061  3302 net.cpp:141] Setting up accuracy
I0622 16:36:27.796068  3302 net.cpp:148] Top shape: (1)
I0622 16:36:27.796072  3302 net.cpp:156] Memory required for data: 113171976
I0622 16:36:27.796073  3302 net.cpp:219] accuracy does not need backward computation.
I0622 16:36:27.796077  3302 net.cpp:217] loss needs backward computation.
I0622 16:36:27.796080  3302 net.cpp:217] conv1_1_D_conv1_1_D_0_split needs backward computation.
I0622 16:36:27.796082  3302 net.cpp:217] conv1_1_D needs backward computation.
I0622 16:36:27.796084  3302 net.cpp:217] upsample1 needs backward computation.
I0622 16:36:27.796088  3302 net.cpp:217] relu2_1_D needs backward computation.
I0622 16:36:27.796090  3302 net.cpp:217] scale2_1_D needs backward computation.
I0622 16:36:27.796092  3302 net.cpp:217] bn2_1_D needs backward computation.
I0622 16:36:27.796093  3302 net.cpp:217] conv2_1_D needs backward computation.
I0622 16:36:27.796097  3302 net.cpp:217] upsample2 needs backward computation.
I0622 16:36:27.796098  3302 net.cpp:217] relu3_1_D needs backward computation.
I0622 16:36:27.796100  3302 net.cpp:217] scale3_1_D needs backward computation.
I0622 16:36:27.796103  3302 net.cpp:217] bn3_1_D needs backward computation.
I0622 16:36:27.796104  3302 net.cpp:217] conv3_1_D needs backward computation.
I0622 16:36:27.796106  3302 net.cpp:217] upsample3 needs backward computation.
I0622 16:36:27.796108  3302 net.cpp:217] relu4_1_D needs backward computation.
I0622 16:36:27.796110  3302 net.cpp:217] scale4_1_D needs backward computation.
I0622 16:36:27.796113  3302 net.cpp:217] bn4_1_D needs backward computation.
I0622 16:36:27.796114  3302 net.cpp:217] conv4_1_D needs backward computation.
I0622 16:36:27.796116  3302 net.cpp:217] upsample4 needs backward computation.
I0622 16:36:27.796118  3302 net.cpp:217] relu5_1_D needs backward computation.
I0622 16:36:27.796120  3302 net.cpp:217] scale5_1_D needs backward computation.
I0622 16:36:27.796123  3302 net.cpp:217] bn5_1_D needs backward computation.
I0622 16:36:27.796124  3302 net.cpp:217] conv5_1_D needs backward computation.
I0622 16:36:27.796126  3302 net.cpp:217] upsample5 needs backward computation.
I0622 16:36:27.796129  3302 net.cpp:217] pool5 needs backward computation.
I0622 16:36:27.796131  3302 net.cpp:217] relu5_1 needs backward computation.
I0622 16:36:27.796134  3302 net.cpp:217] scale5_1 needs backward computation.
I0622 16:36:27.796136  3302 net.cpp:217] bn5_1 needs backward computation.
I0622 16:36:27.796139  3302 net.cpp:217] conv5_1 needs backward computation.
I0622 16:36:27.796141  3302 net.cpp:217] pool4 needs backward computation.
I0622 16:36:27.796144  3302 net.cpp:217] relu4_1 needs backward computation.
I0622 16:36:27.796145  3302 net.cpp:217] scale4_1 needs backward computation.
I0622 16:36:27.796147  3302 net.cpp:217] bn4_1 needs backward computation.
I0622 16:36:27.796149  3302 net.cpp:217] conv4_1 needs backward computation.
I0622 16:36:27.796152  3302 net.cpp:217] pool3 needs backward computation.
I0622 16:36:27.796154  3302 net.cpp:217] relu3_1 needs backward computation.
I0622 16:36:27.796156  3302 net.cpp:217] scale3_1 needs backward computation.
I0622 16:36:27.796159  3302 net.cpp:217] bn3_1 needs backward computation.
I0622 16:36:27.796160  3302 net.cpp:217] conv3_1 needs backward computation.
I0622 16:36:27.796162  3302 net.cpp:217] pool2 needs backward computation.
I0622 16:36:27.796164  3302 net.cpp:217] relu2_1 needs backward computation.
I0622 16:36:27.796167  3302 net.cpp:217] scale2_1 needs backward computation.
I0622 16:36:27.796169  3302 net.cpp:217] bn2_1 needs backward computation.
I0622 16:36:27.796171  3302 net.cpp:217] conv2_1 needs backward computation.
I0622 16:36:27.796180  3302 net.cpp:217] pool1 needs backward computation.
I0622 16:36:27.796182  3302 net.cpp:217] relu1_1 needs backward computation.
I0622 16:36:27.796185  3302 net.cpp:217] scale1_1 needs backward computation.
I0622 16:36:27.796186  3302 net.cpp:217] bn1_1 needs backward computation.
I0622 16:36:27.796188  3302 net.cpp:217] conv1_1 needs backward computation.
I0622 16:36:27.796191  3302 net.cpp:219] label_data_1_split does not need backward computation.
I0622 16:36:27.796195  3302 net.cpp:219] data does not need backward computation.
I0622 16:36:27.796196  3302 net.cpp:261] This network produces output accuracy
I0622 16:36:27.796198  3302 net.cpp:261] This network produces output loss
I0622 16:36:27.796221  3302 net.cpp:274] Network initialization done.
I0622 16:36:27.796346  3302 solver.cpp:60] Solver scaffolding done.
I0622 16:36:27.798014  3302 caffe.cpp:219] Starting Optimization
I0622 16:36:27.798022  3302 solver.cpp:279] Solving segnet
I0622 16:36:27.798024  3302 solver.cpp:280] Learning Rate Policy: step
I0622 16:36:27.799347  3302 solver.cpp:337] Iteration 0, Testing net (#0)
I0622 16:36:27.800428  3302 blocking_queue.cpp:50] Data layer prefetch queue empty
I0622 16:36:28.401466  3302 solver.cpp:404]     Test net output #0: accuracy = 0.525989
I0622 16:36:28.401494  3302 solver.cpp:404]     Test net output #1: loss = 0.725923 (* 1 = 0.725923 loss)
I0622 16:36:29.279299  3302 solver.cpp:228] Iteration 0, loss = 0.726224
I0622 16:36:29.279326  3302 solver.cpp:244]     Train net output #0: accuracy = 0.52606
I0622 16:36:29.279335  3302 solver.cpp:244]     Train net output #1: loss = 0.726224 (* 1 = 0.726224 loss)
I0622 16:36:29.279351  3302 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0622 16:36:46.285217  3302 solver.cpp:228] Iteration 20, loss = 0.12779
I0622 16:36:46.285241  3302 solver.cpp:244]     Train net output #0: accuracy = 0.979695
I0622 16:36:46.285261  3302 solver.cpp:244]     Train net output #1: loss = 0.12779 (* 1 = 0.12779 loss)
I0622 16:36:46.285266  3302 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I0622 16:37:03.476109  3302 solver.cpp:228] Iteration 40, loss = 0.085986
I0622 16:37:03.476161  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986107
I0622 16:37:03.476171  3302 solver.cpp:244]     Train net output #1: loss = 0.085986 (* 1 = 0.085986 loss)
I0622 16:37:03.476174  3302 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I0622 16:37:20.658637  3302 solver.cpp:228] Iteration 60, loss = 0.119612
I0622 16:37:20.658663  3302 solver.cpp:244]     Train net output #0: accuracy = 0.97804
I0622 16:37:20.658671  3302 solver.cpp:244]     Train net output #1: loss = 0.119612 (* 1 = 0.119612 loss)
I0622 16:37:20.658676  3302 sgd_solver.cpp:106] Iteration 60, lr = 0.01
I0622 16:37:37.986176  3302 solver.cpp:228] Iteration 80, loss = 0.0971323
I0622 16:37:37.986263  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982421
I0622 16:37:37.986273  3302 solver.cpp:244]     Train net output #1: loss = 0.0971323 (* 1 = 0.0971323 loss)
I0622 16:37:37.986277  3302 sgd_solver.cpp:106] Iteration 80, lr = 0.01
I0622 16:37:54.741313  3302 solver.cpp:337] Iteration 100, Testing net (#0)
I0622 16:37:55.280722  3302 solver.cpp:404]     Test net output #0: accuracy = 0.982261
I0622 16:37:55.280758  3302 solver.cpp:404]     Test net output #1: loss = 0.0929509 (* 1 = 0.0929509 loss)
I0622 16:37:55.762866  3302 solver.cpp:228] Iteration 100, loss = 0.0877431
I0622 16:37:55.762890  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983846
I0622 16:37:55.762897  3302 solver.cpp:244]     Train net output #1: loss = 0.0877431 (* 1 = 0.0877431 loss)
I0622 16:37:55.762902  3302 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0622 16:38:13.033829  3302 solver.cpp:228] Iteration 120, loss = 0.0746937
I0622 16:38:13.033936  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986809
I0622 16:38:13.033944  3302 solver.cpp:244]     Train net output #1: loss = 0.0746937 (* 1 = 0.0746937 loss)
I0622 16:38:13.033951  3302 sgd_solver.cpp:106] Iteration 120, lr = 0.01
I0622 16:38:30.291723  3302 solver.cpp:228] Iteration 140, loss = 0.093416
I0622 16:38:30.291749  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981718
I0622 16:38:30.291769  3302 solver.cpp:244]     Train net output #1: loss = 0.093416 (* 1 = 0.093416 loss)
I0622 16:38:30.291772  3302 sgd_solver.cpp:106] Iteration 140, lr = 0.01
I0622 16:38:47.546499  3302 solver.cpp:228] Iteration 160, loss = 0.0868137
I0622 16:38:47.546622  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982917
I0622 16:38:47.546633  3302 solver.cpp:244]     Train net output #1: loss = 0.0868137 (* 1 = 0.0868137 loss)
I0622 16:38:47.546638  3302 sgd_solver.cpp:106] Iteration 160, lr = 0.01
I0622 16:39:04.840104  3302 solver.cpp:228] Iteration 180, loss = 0.101351
I0622 16:39:04.840131  3302 solver.cpp:244]     Train net output #0: accuracy = 0.978783
I0622 16:39:04.840150  3302 solver.cpp:244]     Train net output #1: loss = 0.101351 (* 1 = 0.101351 loss)
I0622 16:39:04.840154  3302 sgd_solver.cpp:106] Iteration 180, lr = 0.01
I0622 16:39:21.593806  3302 solver.cpp:337] Iteration 200, Testing net (#0)
I0622 16:39:22.137039  3302 solver.cpp:404]     Test net output #0: accuracy = 0.982849
I0622 16:39:22.137064  3302 solver.cpp:404]     Test net output #1: loss = 0.0845558 (* 1 = 0.0845558 loss)
I0622 16:39:22.619556  3302 solver.cpp:228] Iteration 200, loss = 0.0750875
I0622 16:39:22.619578  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985423
I0622 16:39:22.619585  3302 solver.cpp:244]     Train net output #1: loss = 0.0750875 (* 1 = 0.0750875 loss)
I0622 16:39:22.619590  3302 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0622 16:39:39.840023  3302 solver.cpp:228] Iteration 220, loss = 0.0853769
I0622 16:39:39.840049  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982058
I0622 16:39:39.840056  3302 solver.cpp:244]     Train net output #1: loss = 0.0853769 (* 1 = 0.0853769 loss)
I0622 16:39:39.840061  3302 sgd_solver.cpp:106] Iteration 220, lr = 0.01
I0622 16:39:57.034437  3302 solver.cpp:228] Iteration 240, loss = 0.0815264
I0622 16:39:57.034611  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983351
I0622 16:39:57.034621  3302 solver.cpp:244]     Train net output #1: loss = 0.0815264 (* 1 = 0.0815264 loss)
I0622 16:39:57.034626  3302 sgd_solver.cpp:106] Iteration 240, lr = 0.01
I0622 16:40:14.252985  3302 solver.cpp:228] Iteration 260, loss = 0.0893396
I0622 16:40:14.253010  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980732
I0622 16:40:14.253017  3302 solver.cpp:244]     Train net output #1: loss = 0.0893396 (* 1 = 0.0893396 loss)
I0622 16:40:14.253022  3302 sgd_solver.cpp:106] Iteration 260, lr = 0.01
I0622 16:40:31.514469  3302 solver.cpp:228] Iteration 280, loss = 0.0839247
I0622 16:40:31.514580  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982238
I0622 16:40:31.514588  3302 solver.cpp:244]     Train net output #1: loss = 0.0839247 (* 1 = 0.0839247 loss)
I0622 16:40:31.514593  3302 sgd_solver.cpp:106] Iteration 280, lr = 0.01
I0622 16:40:48.278090  3302 solver.cpp:337] Iteration 300, Testing net (#0)
I0622 16:40:48.821077  3302 solver.cpp:404]     Test net output #0: accuracy = 0.985276
I0622 16:40:48.821106  3302 solver.cpp:404]     Test net output #1: loss = 0.0705297 (* 1 = 0.0705297 loss)
I0622 16:40:49.303290  3302 solver.cpp:228] Iteration 300, loss = 0.0794104
I0622 16:40:49.303325  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982706
I0622 16:40:49.303333  3302 solver.cpp:244]     Train net output #1: loss = 0.0794104 (* 1 = 0.0794104 loss)
I0622 16:40:49.303338  3302 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0622 16:41:06.577666  3302 solver.cpp:228] Iteration 320, loss = 0.0882345
I0622 16:41:06.577769  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980091
I0622 16:41:06.577778  3302 solver.cpp:244]     Train net output #1: loss = 0.0882345 (* 1 = 0.0882345 loss)
I0622 16:41:06.577782  3302 sgd_solver.cpp:106] Iteration 320, lr = 0.01
I0622 16:41:23.798228  3302 solver.cpp:228] Iteration 340, loss = 0.0677919
I0622 16:41:23.798254  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985432
I0622 16:41:23.798260  3302 solver.cpp:244]     Train net output #1: loss = 0.0677919 (* 1 = 0.0677919 loss)
I0622 16:41:23.798264  3302 sgd_solver.cpp:106] Iteration 340, lr = 0.01
I0622 16:41:41.081496  3302 solver.cpp:228] Iteration 360, loss = 0.05845
I0622 16:41:41.081626  3302 solver.cpp:244]     Train net output #0: accuracy = 0.988041
I0622 16:41:41.081636  3302 solver.cpp:244]     Train net output #1: loss = 0.05845 (* 1 = 0.05845 loss)
I0622 16:41:41.081641  3302 sgd_solver.cpp:106] Iteration 360, lr = 0.01
I0622 16:41:58.332576  3302 solver.cpp:228] Iteration 380, loss = 0.0714449
I0622 16:41:58.332599  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983471
I0622 16:41:58.332607  3302 solver.cpp:244]     Train net output #1: loss = 0.0714449 (* 1 = 0.0714449 loss)
I0622 16:41:58.332610  3302 sgd_solver.cpp:106] Iteration 380, lr = 0.01
I0622 16:42:15.166769  3302 solver.cpp:337] Iteration 400, Testing net (#0)
I0622 16:42:15.711158  3302 solver.cpp:404]     Test net output #0: accuracy = 0.984403
I0622 16:42:15.711186  3302 solver.cpp:404]     Test net output #1: loss = 0.0666026 (* 1 = 0.0666026 loss)
I0622 16:42:16.193625  3302 solver.cpp:228] Iteration 400, loss = 0.077118
I0622 16:42:16.193648  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98127
I0622 16:42:16.193655  3302 solver.cpp:244]     Train net output #1: loss = 0.077118 (* 1 = 0.077118 loss)
I0622 16:42:16.193660  3302 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0622 16:42:33.457209  3302 solver.cpp:228] Iteration 420, loss = 0.0793681
I0622 16:42:33.457247  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980147
I0622 16:42:33.457255  3302 solver.cpp:244]     Train net output #1: loss = 0.0793681 (* 1 = 0.0793681 loss)
I0622 16:42:33.457260  3302 sgd_solver.cpp:106] Iteration 420, lr = 0.01
I0622 16:42:50.728168  3302 solver.cpp:228] Iteration 440, loss = 0.0692602
I0622 16:42:50.728260  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983293
I0622 16:42:50.728269  3302 solver.cpp:244]     Train net output #1: loss = 0.0692602 (* 1 = 0.0692602 loss)
I0622 16:42:50.728274  3302 sgd_solver.cpp:106] Iteration 440, lr = 0.01
I0622 16:43:07.943876  3302 solver.cpp:228] Iteration 460, loss = 0.0650263
I0622 16:43:07.943898  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984958
I0622 16:43:07.943907  3302 solver.cpp:244]     Train net output #1: loss = 0.0650263 (* 1 = 0.0650263 loss)
I0622 16:43:07.943910  3302 sgd_solver.cpp:106] Iteration 460, lr = 0.01
I0622 16:43:25.205765  3302 solver.cpp:228] Iteration 480, loss = 0.0637866
I0622 16:43:25.205867  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984445
I0622 16:43:25.205875  3302 solver.cpp:244]     Train net output #1: loss = 0.0637866 (* 1 = 0.0637866 loss)
I0622 16:43:25.205879  3302 sgd_solver.cpp:106] Iteration 480, lr = 0.01
I0622 16:43:41.967157  3302 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_500.caffemodel
I0622 16:43:41.979153  3302 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_500.solverstate
I0622 16:43:41.983393  3302 solver.cpp:337] Iteration 500, Testing net (#0)
I0622 16:43:42.595160  3302 solver.cpp:404]     Test net output #0: accuracy = 0.978811
I0622 16:43:42.595191  3302 solver.cpp:404]     Test net output #1: loss = 0.0788718 (* 1 = 0.0788718 loss)
I0622 16:43:43.087245  3302 solver.cpp:228] Iteration 500, loss = 0.0715181
I0622 16:43:43.087270  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980835
I0622 16:43:43.087278  3302 solver.cpp:244]     Train net output #1: loss = 0.0715181 (* 1 = 0.0715181 loss)
I0622 16:43:43.087283  3302 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0622 16:44:00.357620  3302 solver.cpp:228] Iteration 520, loss = 0.0689178
I0622 16:44:00.357744  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982666
I0622 16:44:00.357756  3302 solver.cpp:244]     Train net output #1: loss = 0.0689178 (* 1 = 0.0689178 loss)
I0622 16:44:00.357760  3302 sgd_solver.cpp:106] Iteration 520, lr = 0.01
I0622 16:44:17.605747  3302 solver.cpp:228] Iteration 540, loss = 0.060268
I0622 16:44:17.605770  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984903
I0622 16:44:17.605778  3302 solver.cpp:244]     Train net output #1: loss = 0.060268 (* 1 = 0.060268 loss)
I0622 16:44:17.605783  3302 sgd_solver.cpp:106] Iteration 540, lr = 0.01
I0622 16:44:34.874881  3302 solver.cpp:228] Iteration 560, loss = 0.062331
I0622 16:44:34.874984  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984586
I0622 16:44:34.874994  3302 solver.cpp:244]     Train net output #1: loss = 0.062331 (* 1 = 0.062331 loss)
I0622 16:44:34.874999  3302 sgd_solver.cpp:106] Iteration 560, lr = 0.01
I0622 16:44:52.113970  3302 solver.cpp:228] Iteration 580, loss = 0.066565
I0622 16:44:52.113996  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982019
I0622 16:44:52.114013  3302 solver.cpp:244]     Train net output #1: loss = 0.066565 (* 1 = 0.066565 loss)
I0622 16:44:52.114018  3302 sgd_solver.cpp:106] Iteration 580, lr = 0.01
I0622 16:45:08.849167  3302 solver.cpp:337] Iteration 600, Testing net (#0)
I0622 16:45:09.398370  3302 solver.cpp:404]     Test net output #0: accuracy = 0.981687
I0622 16:45:09.398406  3302 solver.cpp:404]     Test net output #1: loss = 0.0659989 (* 1 = 0.0659989 loss)
I0622 16:45:09.886128  3302 solver.cpp:228] Iteration 600, loss = 0.0585227
I0622 16:45:09.886152  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985389
I0622 16:45:09.886159  3302 solver.cpp:244]     Train net output #1: loss = 0.0585227 (* 1 = 0.0585227 loss)
I0622 16:45:09.886163  3302 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0622 16:45:27.125005  3302 solver.cpp:228] Iteration 620, loss = 0.059891
I0622 16:45:27.125041  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984251
I0622 16:45:27.125048  3302 solver.cpp:244]     Train net output #1: loss = 0.059891 (* 1 = 0.059891 loss)
I0622 16:45:27.125053  3302 sgd_solver.cpp:106] Iteration 620, lr = 0.01
I0622 16:45:44.343296  3302 solver.cpp:228] Iteration 640, loss = 0.0862113
I0622 16:45:44.343389  3302 solver.cpp:244]     Train net output #0: accuracy = 0.975139
I0622 16:45:44.343400  3302 solver.cpp:244]     Train net output #1: loss = 0.0862113 (* 1 = 0.0862113 loss)
I0622 16:45:44.343405  3302 sgd_solver.cpp:106] Iteration 640, lr = 0.01
I0622 16:46:01.614579  3302 solver.cpp:228] Iteration 660, loss = 0.048853
I0622 16:46:01.614606  3302 solver.cpp:244]     Train net output #0: accuracy = 0.987326
I0622 16:46:01.614614  3302 solver.cpp:244]     Train net output #1: loss = 0.048853 (* 1 = 0.048853 loss)
I0622 16:46:01.614619  3302 sgd_solver.cpp:106] Iteration 660, lr = 0.01
I0622 16:46:18.844527  3302 solver.cpp:228] Iteration 680, loss = 0.0621496
I0622 16:46:18.844626  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983022
I0622 16:46:18.844635  3302 solver.cpp:244]     Train net output #1: loss = 0.0621496 (* 1 = 0.0621496 loss)
I0622 16:46:18.844640  3302 sgd_solver.cpp:106] Iteration 680, lr = 0.01
I0622 16:46:35.613571  3302 solver.cpp:337] Iteration 700, Testing net (#0)
I0622 16:46:36.154263  3302 solver.cpp:404]     Test net output #0: accuracy = 0.982823
I0622 16:46:36.154299  3302 solver.cpp:404]     Test net output #1: loss = 0.0623628 (* 1 = 0.0623628 loss)
I0622 16:46:36.633993  3302 solver.cpp:228] Iteration 700, loss = 0.0655323
I0622 16:46:36.634016  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982678
I0622 16:46:36.634023  3302 solver.cpp:244]     Train net output #1: loss = 0.0655323 (* 1 = 0.0655323 loss)
I0622 16:46:36.634029  3302 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0622 16:46:53.844568  3302 solver.cpp:228] Iteration 720, loss = 0.058462
I0622 16:46:53.844658  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983274
I0622 16:46:53.844667  3302 solver.cpp:244]     Train net output #1: loss = 0.058462 (* 1 = 0.058462 loss)
I0622 16:46:53.844672  3302 sgd_solver.cpp:106] Iteration 720, lr = 0.01
I0622 16:47:11.092988  3302 solver.cpp:228] Iteration 740, loss = 0.0637879
I0622 16:47:11.093013  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980799
I0622 16:47:11.093020  3302 solver.cpp:244]     Train net output #1: loss = 0.0637879 (* 1 = 0.0637879 loss)
I0622 16:47:11.093025  3302 sgd_solver.cpp:106] Iteration 740, lr = 0.01
I0622 16:47:28.304725  3302 solver.cpp:228] Iteration 760, loss = 0.0567866
I0622 16:47:28.304848  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985877
I0622 16:47:28.304857  3302 solver.cpp:244]     Train net output #1: loss = 0.0567866 (* 1 = 0.0567866 loss)
I0622 16:47:28.304862  3302 sgd_solver.cpp:106] Iteration 760, lr = 0.01
I0622 16:47:45.509105  3302 solver.cpp:228] Iteration 780, loss = 0.0683673
I0622 16:47:45.509130  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980514
I0622 16:47:45.509138  3302 solver.cpp:244]     Train net output #1: loss = 0.0683673 (* 1 = 0.0683673 loss)
I0622 16:47:45.509142  3302 sgd_solver.cpp:106] Iteration 780, lr = 0.01
I0622 16:48:02.300716  3302 solver.cpp:337] Iteration 800, Testing net (#0)
I0622 16:48:02.843096  3302 solver.cpp:404]     Test net output #0: accuracy = 0.982255
I0622 16:48:02.843132  3302 solver.cpp:404]     Test net output #1: loss = 0.0606593 (* 1 = 0.0606593 loss)
I0622 16:48:03.324378  3302 solver.cpp:228] Iteration 800, loss = 0.0483762
I0622 16:48:03.324401  3302 solver.cpp:244]     Train net output #0: accuracy = 0.987405
I0622 16:48:03.324409  3302 solver.cpp:244]     Train net output #1: loss = 0.0483762 (* 1 = 0.0483762 loss)
I0622 16:48:03.324414  3302 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0622 16:48:20.561921  3302 solver.cpp:228] Iteration 820, loss = 0.0627608
I0622 16:48:20.561945  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980704
I0622 16:48:20.561952  3302 solver.cpp:244]     Train net output #1: loss = 0.0627608 (* 1 = 0.0627608 loss)
I0622 16:48:20.561956  3302 sgd_solver.cpp:106] Iteration 820, lr = 0.01
I0622 16:48:37.765154  3302 solver.cpp:228] Iteration 840, loss = 0.065604
I0622 16:48:37.765270  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981041
I0622 16:48:37.765280  3302 solver.cpp:244]     Train net output #1: loss = 0.065604 (* 1 = 0.065604 loss)
I0622 16:48:37.765285  3302 sgd_solver.cpp:106] Iteration 840, lr = 0.01
I0622 16:48:54.971585  3302 solver.cpp:228] Iteration 860, loss = 0.0660226
I0622 16:48:54.971608  3302 solver.cpp:244]     Train net output #0: accuracy = 0.979525
I0622 16:48:54.971617  3302 solver.cpp:244]     Train net output #1: loss = 0.0660226 (* 1 = 0.0660226 loss)
I0622 16:48:54.971622  3302 sgd_solver.cpp:106] Iteration 860, lr = 0.01
I0622 16:49:12.239614  3302 solver.cpp:228] Iteration 880, loss = 0.0584695
I0622 16:49:12.239717  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981632
I0622 16:49:12.239725  3302 solver.cpp:244]     Train net output #1: loss = 0.0584695 (* 1 = 0.0584695 loss)
I0622 16:49:12.239729  3302 sgd_solver.cpp:106] Iteration 880, lr = 0.01
I0622 16:49:28.979748  3302 solver.cpp:337] Iteration 900, Testing net (#0)
I0622 16:49:29.519655  3302 solver.cpp:404]     Test net output #0: accuracy = 0.984317
I0622 16:49:29.519680  3302 solver.cpp:404]     Test net output #1: loss = 0.0525408 (* 1 = 0.0525408 loss)
I0622 16:49:29.999166  3302 solver.cpp:228] Iteration 900, loss = 0.0549543
I0622 16:49:29.999191  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983093
I0622 16:49:29.999197  3302 solver.cpp:244]     Train net output #1: loss = 0.0549543 (* 1 = 0.0549543 loss)
I0622 16:49:29.999202  3302 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0622 16:49:47.207072  3302 solver.cpp:228] Iteration 920, loss = 0.0510632
I0622 16:49:47.207172  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985492
I0622 16:49:47.207181  3302 solver.cpp:244]     Train net output #1: loss = 0.0510632 (* 1 = 0.0510632 loss)
I0622 16:49:47.207186  3302 sgd_solver.cpp:106] Iteration 920, lr = 0.01
I0622 16:50:04.433748  3302 solver.cpp:228] Iteration 940, loss = 0.0561732
I0622 16:50:04.433771  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982556
I0622 16:50:04.433779  3302 solver.cpp:244]     Train net output #1: loss = 0.0561732 (* 1 = 0.0561732 loss)
I0622 16:50:04.433784  3302 sgd_solver.cpp:106] Iteration 940, lr = 0.01
I0622 16:50:21.666492  3302 solver.cpp:228] Iteration 960, loss = 0.0493661
I0622 16:50:21.666613  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985766
I0622 16:50:21.666623  3302 solver.cpp:244]     Train net output #1: loss = 0.0493661 (* 1 = 0.0493661 loss)
I0622 16:50:21.666628  3302 sgd_solver.cpp:106] Iteration 960, lr = 0.01
I0622 16:50:38.892994  3302 solver.cpp:228] Iteration 980, loss = 0.0551142
I0622 16:50:38.893019  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983326
I0622 16:50:38.893026  3302 solver.cpp:244]     Train net output #1: loss = 0.0551142 (* 1 = 0.0551142 loss)
I0622 16:50:38.893031  3302 sgd_solver.cpp:106] Iteration 980, lr = 0.01
I0622 16:50:55.651079  3302 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_1000.caffemodel
I0622 16:50:55.659914  3302 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_1000.solverstate
I0622 16:50:55.664230  3302 solver.cpp:337] Iteration 1000, Testing net (#0)
I0622 16:50:56.279652  3302 solver.cpp:404]     Test net output #0: accuracy = 0.985551
I0622 16:50:56.279678  3302 solver.cpp:404]     Test net output #1: loss = 0.0475508 (* 1 = 0.0475508 loss)
I0622 16:50:56.815289  3302 solver.cpp:228] Iteration 1000, loss = 0.0431493
I0622 16:50:56.815317  3302 solver.cpp:244]     Train net output #0: accuracy = 0.987666
I0622 16:50:56.815326  3302 solver.cpp:244]     Train net output #1: loss = 0.0431493 (* 1 = 0.0431493 loss)
I0622 16:50:56.815332  3302 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0622 16:51:14.036245  3302 solver.cpp:228] Iteration 1020, loss = 0.0466146
I0622 16:51:14.036270  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986795
I0622 16:51:14.036278  3302 solver.cpp:244]     Train net output #1: loss = 0.0466146 (* 1 = 0.0466146 loss)
I0622 16:51:14.036283  3302 sgd_solver.cpp:106] Iteration 1020, lr = 0.01
I0622 16:51:31.258679  3302 solver.cpp:228] Iteration 1040, loss = 0.0416217
I0622 16:51:31.258782  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98873
I0622 16:51:31.258791  3302 solver.cpp:244]     Train net output #1: loss = 0.0416217 (* 1 = 0.0416217 loss)
I0622 16:51:31.258796  3302 sgd_solver.cpp:106] Iteration 1040, lr = 0.01
I0622 16:51:48.476198  3302 solver.cpp:228] Iteration 1060, loss = 0.0587553
I0622 16:51:48.476222  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98061
I0622 16:51:48.476228  3302 solver.cpp:244]     Train net output #1: loss = 0.0587553 (* 1 = 0.0587553 loss)
I0622 16:51:48.476233  3302 sgd_solver.cpp:106] Iteration 1060, lr = 0.01
I0622 16:52:05.780731  3302 solver.cpp:228] Iteration 1080, loss = 0.0548239
I0622 16:52:05.780820  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983915
I0622 16:52:05.780830  3302 solver.cpp:244]     Train net output #1: loss = 0.0548239 (* 1 = 0.0548239 loss)
I0622 16:52:05.780835  3302 sgd_solver.cpp:106] Iteration 1080, lr = 0.01
I0622 16:52:22.549685  3302 solver.cpp:337] Iteration 1100, Testing net (#0)
I0622 16:52:23.091362  3302 solver.cpp:404]     Test net output #0: accuracy = 0.98034
I0622 16:52:23.091398  3302 solver.cpp:404]     Test net output #1: loss = 0.0598416 (* 1 = 0.0598416 loss)
I0622 16:52:23.570893  3302 solver.cpp:228] Iteration 1100, loss = 0.0530123
I0622 16:52:23.570927  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985083
I0622 16:52:23.570935  3302 solver.cpp:244]     Train net output #1: loss = 0.0530123 (* 1 = 0.0530123 loss)
I0622 16:52:23.570940  3302 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0622 16:52:40.802587  3302 solver.cpp:228] Iteration 1120, loss = 0.0596433
I0622 16:52:40.802707  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981474
I0622 16:52:40.802718  3302 solver.cpp:244]     Train net output #1: loss = 0.0596433 (* 1 = 0.0596433 loss)
I0622 16:52:40.802723  3302 sgd_solver.cpp:106] Iteration 1120, lr = 0.01
I0622 16:52:58.028884  3302 solver.cpp:228] Iteration 1140, loss = 0.0561658
I0622 16:52:58.028910  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98177
I0622 16:52:58.028918  3302 solver.cpp:244]     Train net output #1: loss = 0.0561658 (* 1 = 0.0561658 loss)
I0622 16:52:58.028923  3302 sgd_solver.cpp:106] Iteration 1140, lr = 0.01
I0622 16:53:15.386279  3302 solver.cpp:228] Iteration 1160, loss = 0.0504355
I0622 16:53:15.386382  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984154
I0622 16:53:15.386392  3302 solver.cpp:244]     Train net output #1: loss = 0.0504355 (* 1 = 0.0504355 loss)
I0622 16:53:15.386397  3302 sgd_solver.cpp:106] Iteration 1160, lr = 0.01
I0622 16:53:32.689581  3302 solver.cpp:228] Iteration 1180, loss = 0.0527278
I0622 16:53:32.689607  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983694
I0622 16:53:32.689615  3302 solver.cpp:244]     Train net output #1: loss = 0.0527278 (* 1 = 0.0527278 loss)
I0622 16:53:32.689620  3302 sgd_solver.cpp:106] Iteration 1180, lr = 0.01
I0622 16:53:49.623162  3302 solver.cpp:337] Iteration 1200, Testing net (#0)
I0622 16:53:50.165679  3302 solver.cpp:404]     Test net output #0: accuracy = 0.987043
I0622 16:53:50.165714  3302 solver.cpp:404]     Test net output #1: loss = 0.0421472 (* 1 = 0.0421472 loss)
I0622 16:53:50.647032  3302 solver.cpp:228] Iteration 1200, loss = 0.0475198
I0622 16:53:50.647053  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984901
I0622 16:53:50.647060  3302 solver.cpp:244]     Train net output #1: loss = 0.0475198 (* 1 = 0.0475198 loss)
I0622 16:53:50.647065  3302 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0622 16:54:07.965268  3302 solver.cpp:228] Iteration 1220, loss = 0.0465108
I0622 16:54:07.965296  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985017
I0622 16:54:07.965302  3302 solver.cpp:244]     Train net output #1: loss = 0.0465108 (* 1 = 0.0465108 loss)
I0622 16:54:07.965308  3302 sgd_solver.cpp:106] Iteration 1220, lr = 0.01
I0622 16:54:25.263088  3302 solver.cpp:228] Iteration 1240, loss = 0.0526239
I0622 16:54:25.263176  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983362
I0622 16:54:25.263186  3302 solver.cpp:244]     Train net output #1: loss = 0.0526239 (* 1 = 0.0526239 loss)
I0622 16:54:25.263191  3302 sgd_solver.cpp:106] Iteration 1240, lr = 0.01
I0622 16:54:42.504257  3302 solver.cpp:228] Iteration 1260, loss = 0.0557511
I0622 16:54:42.504281  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980597
I0622 16:54:42.504289  3302 solver.cpp:244]     Train net output #1: loss = 0.0557511 (* 1 = 0.0557511 loss)
I0622 16:54:42.504293  3302 sgd_solver.cpp:106] Iteration 1260, lr = 0.01
I0622 16:54:59.744963  3302 solver.cpp:228] Iteration 1280, loss = 0.0655461
I0622 16:54:59.745074  3302 solver.cpp:244]     Train net output #0: accuracy = 0.979052
I0622 16:54:59.745082  3302 solver.cpp:244]     Train net output #1: loss = 0.0655461 (* 1 = 0.0655461 loss)
I0622 16:54:59.745087  3302 sgd_solver.cpp:106] Iteration 1280, lr = 0.01
I0622 16:55:16.498914  3302 solver.cpp:337] Iteration 1300, Testing net (#0)
I0622 16:55:17.041389  3302 solver.cpp:404]     Test net output #0: accuracy = 0.983315
I0622 16:55:17.041424  3302 solver.cpp:404]     Test net output #1: loss = 0.0511221 (* 1 = 0.0511221 loss)
I0622 16:55:17.522909  3302 solver.cpp:228] Iteration 1300, loss = 0.036483
I0622 16:55:17.522933  3302 solver.cpp:244]     Train net output #0: accuracy = 0.990199
I0622 16:55:17.522941  3302 solver.cpp:244]     Train net output #1: loss = 0.036483 (* 1 = 0.036483 loss)
I0622 16:55:17.522945  3302 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0622 16:55:34.769284  3302 solver.cpp:228] Iteration 1320, loss = 0.053556
I0622 16:55:34.769394  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982257
I0622 16:55:34.769404  3302 solver.cpp:244]     Train net output #1: loss = 0.053556 (* 1 = 0.053556 loss)
I0622 16:55:34.769409  3302 sgd_solver.cpp:106] Iteration 1320, lr = 0.01
I0622 16:55:52.005695  3302 solver.cpp:228] Iteration 1340, loss = 0.0412383
I0622 16:55:52.005722  3302 solver.cpp:244]     Train net output #0: accuracy = 0.987649
I0622 16:55:52.005729  3302 solver.cpp:244]     Train net output #1: loss = 0.0412383 (* 1 = 0.0412383 loss)
I0622 16:55:52.005733  3302 sgd_solver.cpp:106] Iteration 1340, lr = 0.01
I0622 16:56:09.305989  3302 solver.cpp:228] Iteration 1360, loss = 0.0482937
I0622 16:56:09.306114  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984755
I0622 16:56:09.306125  3302 solver.cpp:244]     Train net output #1: loss = 0.0482937 (* 1 = 0.0482937 loss)
I0622 16:56:09.306130  3302 sgd_solver.cpp:106] Iteration 1360, lr = 0.01
I0622 16:56:26.585691  3302 solver.cpp:228] Iteration 1380, loss = 0.0464855
I0622 16:56:26.585726  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985575
I0622 16:56:26.585734  3302 solver.cpp:244]     Train net output #1: loss = 0.0464855 (* 1 = 0.0464855 loss)
I0622 16:56:26.585738  3302 sgd_solver.cpp:106] Iteration 1380, lr = 0.01
I0622 16:56:43.335713  3302 solver.cpp:337] Iteration 1400, Testing net (#0)
I0622 16:56:43.878144  3302 solver.cpp:404]     Test net output #0: accuracy = 0.980281
I0622 16:56:43.878178  3302 solver.cpp:404]     Test net output #1: loss = 0.0577589 (* 1 = 0.0577589 loss)
I0622 16:56:44.357803  3302 solver.cpp:228] Iteration 1400, loss = 0.0513207
I0622 16:56:44.357828  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98261
I0622 16:56:44.357836  3302 solver.cpp:244]     Train net output #1: loss = 0.0513207 (* 1 = 0.0513207 loss)
I0622 16:56:44.357841  3302 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0622 16:57:01.619129  3302 solver.cpp:228] Iteration 1420, loss = 0.0534872
I0622 16:57:01.619153  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982744
I0622 16:57:01.619161  3302 solver.cpp:244]     Train net output #1: loss = 0.0534872 (* 1 = 0.0534872 loss)
I0622 16:57:01.619166  3302 sgd_solver.cpp:106] Iteration 1420, lr = 0.01
I0622 16:57:18.898412  3302 solver.cpp:228] Iteration 1440, loss = 0.0594161
I0622 16:57:18.898514  3302 solver.cpp:244]     Train net output #0: accuracy = 0.979316
I0622 16:57:18.898522  3302 solver.cpp:244]     Train net output #1: loss = 0.0594161 (* 1 = 0.0594161 loss)
I0622 16:57:18.898526  3302 sgd_solver.cpp:106] Iteration 1440, lr = 0.01
I0622 16:57:36.191077  3302 solver.cpp:228] Iteration 1460, loss = 0.0527614
I0622 16:57:36.191115  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981502
I0622 16:57:36.191123  3302 solver.cpp:244]     Train net output #1: loss = 0.0527614 (* 1 = 0.0527614 loss)
I0622 16:57:36.191128  3302 sgd_solver.cpp:106] Iteration 1460, lr = 0.01
I0622 16:57:53.487896  3302 solver.cpp:228] Iteration 1480, loss = 0.057203
I0622 16:57:53.487999  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981061
I0622 16:57:53.488010  3302 solver.cpp:244]     Train net output #1: loss = 0.057203 (* 1 = 0.057203 loss)
I0622 16:57:53.488015  3302 sgd_solver.cpp:106] Iteration 1480, lr = 0.01
I0622 16:58:10.632410  3302 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_1500.caffemodel
I0622 16:58:10.638805  3302 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_1500.solverstate
I0622 16:58:10.642858  3302 solver.cpp:337] Iteration 1500, Testing net (#0)
I0622 16:58:11.201398  3302 solver.cpp:404]     Test net output #0: accuracy = 0.983665
I0622 16:58:11.201423  3302 solver.cpp:404]     Test net output #1: loss = 0.0486252 (* 1 = 0.0486252 loss)
I0622 16:58:11.684088  3302 solver.cpp:228] Iteration 1500, loss = 0.0500259
I0622 16:58:11.684123  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982579
I0622 16:58:11.684131  3302 solver.cpp:244]     Train net output #1: loss = 0.0500259 (* 1 = 0.0500259 loss)
I0622 16:58:11.684136  3302 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0622 16:58:28.996778  3302 solver.cpp:228] Iteration 1520, loss = 0.0520959
I0622 16:58:28.996904  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984844
I0622 16:58:28.996914  3302 solver.cpp:244]     Train net output #1: loss = 0.0520959 (* 1 = 0.0520959 loss)
I0622 16:58:28.996919  3302 sgd_solver.cpp:106] Iteration 1520, lr = 0.01
I0622 16:58:46.377820  3302 solver.cpp:228] Iteration 1540, loss = 0.0478146
I0622 16:58:46.377845  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983735
I0622 16:58:46.377851  3302 solver.cpp:244]     Train net output #1: loss = 0.0478146 (* 1 = 0.0478146 loss)
I0622 16:58:46.377856  3302 sgd_solver.cpp:106] Iteration 1540, lr = 0.01
I0622 16:59:03.745146  3302 solver.cpp:228] Iteration 1560, loss = 0.0514284
I0622 16:59:03.745250  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982294
I0622 16:59:03.745260  3302 solver.cpp:244]     Train net output #1: loss = 0.0514284 (* 1 = 0.0514284 loss)
I0622 16:59:03.745265  3302 sgd_solver.cpp:106] Iteration 1560, lr = 0.01
I0622 16:59:21.152271  3302 solver.cpp:228] Iteration 1580, loss = 0.0534477
I0622 16:59:21.152297  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981824
I0622 16:59:21.152305  3302 solver.cpp:244]     Train net output #1: loss = 0.0534477 (* 1 = 0.0534477 loss)
I0622 16:59:21.152309  3302 sgd_solver.cpp:106] Iteration 1580, lr = 0.01
I0622 16:59:37.957836  3302 solver.cpp:337] Iteration 1600, Testing net (#0)
I0622 16:59:38.503105  3302 solver.cpp:404]     Test net output #0: accuracy = 0.984287
I0622 16:59:38.503141  3302 solver.cpp:404]     Test net output #1: loss = 0.049205 (* 1 = 0.049205 loss)
I0622 16:59:38.985939  3302 solver.cpp:228] Iteration 1600, loss = 0.0434495
I0622 16:59:38.985965  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986354
I0622 16:59:38.985971  3302 solver.cpp:244]     Train net output #1: loss = 0.0434495 (* 1 = 0.0434495 loss)
I0622 16:59:38.985976  3302 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0622 16:59:56.483253  3302 solver.cpp:228] Iteration 1620, loss = 0.0483651
I0622 16:59:56.483278  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983113
I0622 16:59:56.483285  3302 solver.cpp:244]     Train net output #1: loss = 0.0483651 (* 1 = 0.0483651 loss)
I0622 16:59:56.483289  3302 sgd_solver.cpp:106] Iteration 1620, lr = 0.01
I0622 17:00:13.870971  3302 solver.cpp:228] Iteration 1640, loss = 0.0501069
I0622 17:00:13.871073  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98225
I0622 17:00:13.871083  3302 solver.cpp:244]     Train net output #1: loss = 0.0501069 (* 1 = 0.0501069 loss)
I0622 17:00:13.871088  3302 sgd_solver.cpp:106] Iteration 1640, lr = 0.01
I0622 17:00:31.471637  3302 solver.cpp:228] Iteration 1660, loss = 0.0386313
I0622 17:00:31.471662  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986984
I0622 17:00:31.471669  3302 solver.cpp:244]     Train net output #1: loss = 0.0386313 (* 1 = 0.0386313 loss)
I0622 17:00:31.471673  3302 sgd_solver.cpp:106] Iteration 1660, lr = 0.01
I0622 17:00:48.773542  3302 solver.cpp:228] Iteration 1680, loss = 0.0486117
I0622 17:00:48.773627  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98401
I0622 17:00:48.773636  3302 solver.cpp:244]     Train net output #1: loss = 0.0486117 (* 1 = 0.0486117 loss)
I0622 17:00:48.773641  3302 sgd_solver.cpp:106] Iteration 1680, lr = 0.01
I0622 17:01:05.583129  3302 solver.cpp:337] Iteration 1700, Testing net (#0)
I0622 17:01:06.127876  3302 solver.cpp:404]     Test net output #0: accuracy = 0.983765
I0622 17:01:06.127899  3302 solver.cpp:404]     Test net output #1: loss = 0.0455856 (* 1 = 0.0455856 loss)
I0622 17:01:06.610939  3302 solver.cpp:228] Iteration 1700, loss = 0.0384369
I0622 17:01:06.610963  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986798
I0622 17:01:06.610970  3302 solver.cpp:244]     Train net output #1: loss = 0.0384369 (* 1 = 0.0384369 loss)
I0622 17:01:06.610975  3302 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0622 17:01:24.194874  3302 solver.cpp:228] Iteration 1720, loss = 0.0426115
I0622 17:01:24.195024  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986005
I0622 17:01:24.195045  3302 solver.cpp:244]     Train net output #1: loss = 0.0426115 (* 1 = 0.0426115 loss)
I0622 17:01:24.195055  3302 sgd_solver.cpp:106] Iteration 1720, lr = 0.01
I0622 17:01:41.493425  3302 solver.cpp:228] Iteration 1740, loss = 0.0483488
I0622 17:01:41.493463  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984466
I0622 17:01:41.493471  3302 solver.cpp:244]     Train net output #1: loss = 0.0483488 (* 1 = 0.0483488 loss)
I0622 17:01:41.493476  3302 sgd_solver.cpp:106] Iteration 1740, lr = 0.01
I0622 17:01:58.914183  3302 solver.cpp:228] Iteration 1760, loss = 0.0418256
I0622 17:01:58.914288  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986871
I0622 17:01:58.914299  3302 solver.cpp:244]     Train net output #1: loss = 0.0418256 (* 1 = 0.0418256 loss)
I0622 17:01:58.914304  3302 sgd_solver.cpp:106] Iteration 1760, lr = 0.01
I0622 17:02:16.256207  3302 solver.cpp:228] Iteration 1780, loss = 0.0503985
I0622 17:02:16.256232  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981024
I0622 17:02:16.256240  3302 solver.cpp:244]     Train net output #1: loss = 0.0503985 (* 1 = 0.0503985 loss)
I0622 17:02:16.256244  3302 sgd_solver.cpp:106] Iteration 1780, lr = 0.01
I0622 17:02:33.403370  3302 solver.cpp:337] Iteration 1800, Testing net (#0)
I0622 17:02:33.948035  3302 solver.cpp:404]     Test net output #0: accuracy = 0.981249
I0622 17:02:33.948060  3302 solver.cpp:404]     Test net output #1: loss = 0.049412 (* 1 = 0.049412 loss)
I0622 17:02:34.432799  3302 solver.cpp:228] Iteration 1800, loss = 0.0519833
I0622 17:02:34.432837  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982433
I0622 17:02:34.432855  3302 solver.cpp:244]     Train net output #1: loss = 0.0519833 (* 1 = 0.0519833 loss)
I0622 17:02:34.432860  3302 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0622 17:02:51.737541  3302 solver.cpp:228] Iteration 1820, loss = 0.0431651
I0622 17:02:51.737577  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984062
I0622 17:02:51.737586  3302 solver.cpp:244]     Train net output #1: loss = 0.0431651 (* 1 = 0.0431651 loss)
I0622 17:02:51.737591  3302 sgd_solver.cpp:106] Iteration 1820, lr = 0.01
I0622 17:03:09.044884  3302 solver.cpp:228] Iteration 1840, loss = 0.0489663
I0622 17:03:09.044980  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98327
I0622 17:03:09.044989  3302 solver.cpp:244]     Train net output #1: loss = 0.0489663 (* 1 = 0.0489663 loss)
I0622 17:03:09.044993  3302 sgd_solver.cpp:106] Iteration 1840, lr = 0.01
I0622 17:03:26.365043  3302 solver.cpp:228] Iteration 1860, loss = 0.0535163
I0622 17:03:26.365068  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980829
I0622 17:03:26.365075  3302 solver.cpp:244]     Train net output #1: loss = 0.0535163 (* 1 = 0.0535163 loss)
I0622 17:03:26.365080  3302 sgd_solver.cpp:106] Iteration 1860, lr = 0.01
I0622 17:03:43.826282  3302 solver.cpp:228] Iteration 1880, loss = 0.0415214
I0622 17:03:43.826395  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984294
I0622 17:03:43.826406  3302 solver.cpp:244]     Train net output #1: loss = 0.0415214 (* 1 = 0.0415214 loss)
I0622 17:03:43.826411  3302 sgd_solver.cpp:106] Iteration 1880, lr = 0.01
I0622 17:04:00.665177  3302 solver.cpp:337] Iteration 1900, Testing net (#0)
I0622 17:04:01.210114  3302 solver.cpp:404]     Test net output #0: accuracy = 0.981904
I0622 17:04:01.210139  3302 solver.cpp:404]     Test net output #1: loss = 0.0498514 (* 1 = 0.0498514 loss)
I0622 17:04:01.694034  3302 solver.cpp:228] Iteration 1900, loss = 0.0452097
I0622 17:04:01.694059  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983198
I0622 17:04:01.694067  3302 solver.cpp:244]     Train net output #1: loss = 0.0452097 (* 1 = 0.0452097 loss)
I0622 17:04:01.694072  3302 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0622 17:04:18.990474  3302 solver.cpp:228] Iteration 1920, loss = 0.0499787
I0622 17:04:18.990581  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982199
I0622 17:04:18.990591  3302 solver.cpp:244]     Train net output #1: loss = 0.0499787 (* 1 = 0.0499787 loss)
I0622 17:04:18.990594  3302 sgd_solver.cpp:106] Iteration 1920, lr = 0.01
I0622 17:04:36.305474  3302 solver.cpp:228] Iteration 1940, loss = 0.0497429
I0622 17:04:36.305500  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981857
I0622 17:04:36.305506  3302 solver.cpp:244]     Train net output #1: loss = 0.0497429 (* 1 = 0.0497429 loss)
I0622 17:04:36.305511  3302 sgd_solver.cpp:106] Iteration 1940, lr = 0.01
I0622 17:04:53.603147  3302 solver.cpp:228] Iteration 1960, loss = 0.0505687
I0622 17:04:53.603283  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981367
I0622 17:04:53.603294  3302 solver.cpp:244]     Train net output #1: loss = 0.0505687 (* 1 = 0.0505687 loss)
I0622 17:04:53.603299  3302 sgd_solver.cpp:106] Iteration 1960, lr = 0.01
I0622 17:05:10.893688  3302 solver.cpp:228] Iteration 1980, loss = 0.0461243
I0622 17:05:10.893713  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982661
I0622 17:05:10.893721  3302 solver.cpp:244]     Train net output #1: loss = 0.0461243 (* 1 = 0.0461243 loss)
I0622 17:05:10.893726  3302 sgd_solver.cpp:106] Iteration 1980, lr = 0.01
I0622 17:05:27.704505  3302 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_2000.caffemodel
I0622 17:05:27.713726  3302 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_2000.solverstate
I0622 17:05:27.718747  3302 solver.cpp:337] Iteration 2000, Testing net (#0)
I0622 17:05:28.334069  3302 solver.cpp:404]     Test net output #0: accuracy = 0.984775
I0622 17:05:28.334102  3302 solver.cpp:404]     Test net output #1: loss = 0.046855 (* 1 = 0.046855 loss)
I0622 17:05:28.827927  3302 solver.cpp:228] Iteration 2000, loss = 0.0580672
I0622 17:05:28.827955  3302 solver.cpp:244]     Train net output #0: accuracy = 0.979341
I0622 17:05:28.827963  3302 solver.cpp:244]     Train net output #1: loss = 0.0580672 (* 1 = 0.0580672 loss)
I0622 17:05:28.827968  3302 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0622 17:05:46.141288  3302 solver.cpp:228] Iteration 2020, loss = 0.0406722
I0622 17:05:46.141325  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986811
I0622 17:05:46.141333  3302 solver.cpp:244]     Train net output #1: loss = 0.0406722 (* 1 = 0.0406722 loss)
I0622 17:05:46.141337  3302 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0622 17:06:03.476394  3302 solver.cpp:228] Iteration 2040, loss = 0.0544842
I0622 17:06:03.476501  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980916
I0622 17:06:03.476511  3302 solver.cpp:244]     Train net output #1: loss = 0.0544842 (* 1 = 0.0544842 loss)
I0622 17:06:03.476516  3302 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0622 17:06:20.792577  3302 solver.cpp:228] Iteration 2060, loss = 0.0430556
I0622 17:06:20.792603  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985429
I0622 17:06:20.792611  3302 solver.cpp:244]     Train net output #1: loss = 0.0430556 (* 1 = 0.0430556 loss)
I0622 17:06:20.792616  3302 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0622 17:06:38.134903  3302 solver.cpp:228] Iteration 2080, loss = 0.0569244
I0622 17:06:38.134979  3302 solver.cpp:244]     Train net output #0: accuracy = 0.977988
I0622 17:06:38.134990  3302 solver.cpp:244]     Train net output #1: loss = 0.0569244 (* 1 = 0.0569244 loss)
I0622 17:06:38.134994  3302 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0622 17:06:54.994745  3302 solver.cpp:337] Iteration 2100, Testing net (#0)
I0622 17:06:55.540376  3302 solver.cpp:404]     Test net output #0: accuracy = 0.984779
I0622 17:06:55.540402  3302 solver.cpp:404]     Test net output #1: loss = 0.0419567 (* 1 = 0.0419567 loss)
I0622 17:06:56.024631  3302 solver.cpp:228] Iteration 2100, loss = 0.0544875
I0622 17:06:56.024657  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980427
I0622 17:06:56.024664  3302 solver.cpp:244]     Train net output #1: loss = 0.0544875 (* 1 = 0.0544875 loss)
I0622 17:06:56.024670  3302 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0622 17:07:13.325927  3302 solver.cpp:228] Iteration 2120, loss = 0.0446414
I0622 17:07:13.326036  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983884
I0622 17:07:13.326056  3302 solver.cpp:244]     Train net output #1: loss = 0.0446414 (* 1 = 0.0446414 loss)
I0622 17:07:13.326061  3302 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0622 17:07:30.626788  3302 solver.cpp:228] Iteration 2140, loss = 0.0389889
I0622 17:07:30.626813  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986313
I0622 17:07:30.626821  3302 solver.cpp:244]     Train net output #1: loss = 0.0389889 (* 1 = 0.0389889 loss)
I0622 17:07:30.626827  3302 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0622 17:07:47.921164  3302 solver.cpp:228] Iteration 2160, loss = 0.0376643
I0622 17:07:47.921270  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986165
I0622 17:07:47.921279  3302 solver.cpp:244]     Train net output #1: loss = 0.0376643 (* 1 = 0.0376643 loss)
I0622 17:07:47.921283  3302 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0622 17:08:05.243846  3302 solver.cpp:228] Iteration 2180, loss = 0.0449369
I0622 17:08:05.243872  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983853
I0622 17:08:05.243891  3302 solver.cpp:244]     Train net output #1: loss = 0.0449369 (* 1 = 0.0449369 loss)
I0622 17:08:05.243896  3302 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0622 17:08:22.049857  3302 solver.cpp:337] Iteration 2200, Testing net (#0)
I0622 17:08:22.595469  3302 solver.cpp:404]     Test net output #0: accuracy = 0.985998
I0622 17:08:22.595494  3302 solver.cpp:404]     Test net output #1: loss = 0.0428593 (* 1 = 0.0428593 loss)
I0622 17:08:23.079412  3302 solver.cpp:228] Iteration 2200, loss = 0.0538137
I0622 17:08:23.079437  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982635
I0622 17:08:23.079444  3302 solver.cpp:244]     Train net output #1: loss = 0.0538137 (* 1 = 0.0538137 loss)
I0622 17:08:23.079449  3302 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0622 17:08:40.664808  3302 solver.cpp:228] Iteration 2220, loss = 0.0477936
I0622 17:08:40.664832  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983012
I0622 17:08:40.664840  3302 solver.cpp:244]     Train net output #1: loss = 0.0477936 (* 1 = 0.0477936 loss)
I0622 17:08:40.664844  3302 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0622 17:08:57.983304  3302 solver.cpp:228] Iteration 2240, loss = 0.0421468
I0622 17:08:57.987190  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985111
I0622 17:08:57.987198  3302 solver.cpp:244]     Train net output #1: loss = 0.0421468 (* 1 = 0.0421468 loss)
I0622 17:08:57.987203  3302 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0622 17:09:15.300920  3302 solver.cpp:228] Iteration 2260, loss = 0.0421214
I0622 17:09:15.300945  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983766
I0622 17:09:15.300953  3302 solver.cpp:244]     Train net output #1: loss = 0.0421214 (* 1 = 0.0421214 loss)
I0622 17:09:15.300957  3302 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0622 17:09:32.957422  3302 solver.cpp:228] Iteration 2280, loss = 0.03792
I0622 17:09:32.957651  3302 solver.cpp:244]     Train net output #0: accuracy = 0.987571
I0622 17:09:32.957660  3302 solver.cpp:244]     Train net output #1: loss = 0.03792 (* 1 = 0.03792 loss)
I0622 17:09:32.957665  3302 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0622 17:09:49.960748  3302 solver.cpp:337] Iteration 2300, Testing net (#0)
I0622 17:09:50.506336  3302 solver.cpp:404]     Test net output #0: accuracy = 0.981775
I0622 17:09:50.506362  3302 solver.cpp:404]     Test net output #1: loss = 0.0471847 (* 1 = 0.0471847 loss)
I0622 17:09:50.988932  3302 solver.cpp:228] Iteration 2300, loss = 0.0404866
I0622 17:09:50.988957  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98604
I0622 17:09:50.988966  3302 solver.cpp:244]     Train net output #1: loss = 0.0404866 (* 1 = 0.0404866 loss)
I0622 17:09:50.988970  3302 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0622 17:10:08.724551  3302 solver.cpp:228] Iteration 2320, loss = 0.0488035
I0622 17:10:08.724694  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981036
I0622 17:10:08.724705  3302 solver.cpp:244]     Train net output #1: loss = 0.0488035 (* 1 = 0.0488035 loss)
I0622 17:10:08.724710  3302 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0622 17:10:26.014807  3302 solver.cpp:228] Iteration 2340, loss = 0.0463508
I0622 17:10:26.014832  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98331
I0622 17:10:26.014840  3302 solver.cpp:244]     Train net output #1: loss = 0.0463508 (* 1 = 0.0463508 loss)
I0622 17:10:26.014844  3302 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0622 17:10:43.299695  3302 solver.cpp:228] Iteration 2360, loss = 0.0440954
I0622 17:10:43.299798  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98332
I0622 17:10:43.299808  3302 solver.cpp:244]     Train net output #1: loss = 0.0440954 (* 1 = 0.0440954 loss)
I0622 17:10:43.299813  3302 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0622 17:11:00.587970  3302 solver.cpp:228] Iteration 2380, loss = 0.051639
I0622 17:11:00.587996  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980098
I0622 17:11:00.588004  3302 solver.cpp:244]     Train net output #1: loss = 0.051639 (* 1 = 0.051639 loss)
I0622 17:11:00.588009  3302 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0622 17:11:17.390566  3302 solver.cpp:337] Iteration 2400, Testing net (#0)
I0622 17:11:17.935432  3302 solver.cpp:404]     Test net output #0: accuracy = 0.979011
I0622 17:11:17.935459  3302 solver.cpp:404]     Test net output #1: loss = 0.0526567 (* 1 = 0.0526567 loss)
I0622 17:11:18.417567  3302 solver.cpp:228] Iteration 2400, loss = 0.0503405
I0622 17:11:18.417590  3302 solver.cpp:244]     Train net output #0: accuracy = 0.979807
I0622 17:11:18.417598  3302 solver.cpp:244]     Train net output #1: loss = 0.0503405 (* 1 = 0.0503405 loss)
I0622 17:11:18.417601  3302 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0622 17:11:35.694345  3302 solver.cpp:228] Iteration 2420, loss = 0.0469424
I0622 17:11:35.694370  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982407
I0622 17:11:35.694378  3302 solver.cpp:244]     Train net output #1: loss = 0.0469424 (* 1 = 0.0469424 loss)
I0622 17:11:35.694383  3302 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0622 17:11:52.976323  3302 solver.cpp:228] Iteration 2440, loss = 0.0340976
I0622 17:11:52.976462  3302 solver.cpp:244]     Train net output #0: accuracy = 0.988453
I0622 17:11:52.976471  3302 solver.cpp:244]     Train net output #1: loss = 0.0340976 (* 1 = 0.0340976 loss)
I0622 17:11:52.976476  3302 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0622 17:12:10.274498  3302 solver.cpp:228] Iteration 2460, loss = 0.0467973
I0622 17:12:10.274524  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981972
I0622 17:12:10.274531  3302 solver.cpp:244]     Train net output #1: loss = 0.0467973 (* 1 = 0.0467973 loss)
I0622 17:12:10.274536  3302 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0622 17:12:27.554101  3302 solver.cpp:228] Iteration 2480, loss = 0.0367001
I0622 17:12:27.554172  3302 solver.cpp:244]     Train net output #0: accuracy = 0.987668
I0622 17:12:27.554180  3302 solver.cpp:244]     Train net output #1: loss = 0.0367001 (* 1 = 0.0367001 loss)
I0622 17:12:27.554185  3302 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0622 17:12:44.454457  3302 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_2500.caffemodel
I0622 17:12:44.457906  3302 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_2500.solverstate
I0622 17:12:44.465020  3302 solver.cpp:337] Iteration 2500, Testing net (#0)
I0622 17:12:45.080220  3302 solver.cpp:404]     Test net output #0: accuracy = 0.979856
I0622 17:12:45.080246  3302 solver.cpp:404]     Test net output #1: loss = 0.0556596 (* 1 = 0.0556596 loss)
I0622 17:12:45.574544  3302 solver.cpp:228] Iteration 2500, loss = 0.0434394
I0622 17:12:45.574571  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983969
I0622 17:12:45.574580  3302 solver.cpp:244]     Train net output #1: loss = 0.0434394 (* 1 = 0.0434394 loss)
I0622 17:12:45.574585  3302 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0622 17:13:02.955874  3302 solver.cpp:228] Iteration 2520, loss = 0.0412599
I0622 17:13:02.955996  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984775
I0622 17:13:02.956007  3302 solver.cpp:244]     Train net output #1: loss = 0.0412599 (* 1 = 0.0412599 loss)
I0622 17:13:02.956012  3302 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0622 17:13:20.237567  3302 solver.cpp:228] Iteration 2540, loss = 0.0448477
I0622 17:13:20.237592  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986439
I0622 17:13:20.237599  3302 solver.cpp:244]     Train net output #1: loss = 0.0448477 (* 1 = 0.0448477 loss)
I0622 17:13:20.237604  3302 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0622 17:13:37.520429  3302 solver.cpp:228] Iteration 2560, loss = 0.0510127
I0622 17:13:37.520542  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981336
I0622 17:13:37.520552  3302 solver.cpp:244]     Train net output #1: loss = 0.0510127 (* 1 = 0.0510127 loss)
I0622 17:13:37.520557  3302 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0622 17:13:54.928287  3302 solver.cpp:228] Iteration 2580, loss = 0.0497596
I0622 17:13:54.928311  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983708
I0622 17:13:54.928318  3302 solver.cpp:244]     Train net output #1: loss = 0.0497596 (* 1 = 0.0497596 loss)
I0622 17:13:54.928323  3302 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0622 17:14:11.763121  3302 solver.cpp:337] Iteration 2600, Testing net (#0)
I0622 17:14:12.305613  3302 solver.cpp:404]     Test net output #0: accuracy = 0.982156
I0622 17:14:12.305636  3302 solver.cpp:404]     Test net output #1: loss = 0.0442814 (* 1 = 0.0442814 loss)
I0622 17:14:12.786857  3302 solver.cpp:228] Iteration 2600, loss = 0.0551145
I0622 17:14:12.786882  3302 solver.cpp:244]     Train net output #0: accuracy = 0.978939
I0622 17:14:12.786890  3302 solver.cpp:244]     Train net output #1: loss = 0.0551145 (* 1 = 0.0551145 loss)
I0622 17:14:12.786895  3302 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0622 17:14:30.206249  3302 solver.cpp:228] Iteration 2620, loss = 0.0506114
I0622 17:14:30.206274  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98199
I0622 17:14:30.206282  3302 solver.cpp:244]     Train net output #1: loss = 0.0506114 (* 1 = 0.0506114 loss)
I0622 17:14:30.206287  3302 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0622 17:14:47.521940  3302 solver.cpp:228] Iteration 2640, loss = 0.0399321
I0622 17:14:47.522047  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985525
I0622 17:14:47.522056  3302 solver.cpp:244]     Train net output #1: loss = 0.0399321 (* 1 = 0.0399321 loss)
I0622 17:14:47.522063  3302 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0622 17:15:04.832751  3302 solver.cpp:228] Iteration 2660, loss = 0.0415744
I0622 17:15:04.832777  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984816
I0622 17:15:04.832784  3302 solver.cpp:244]     Train net output #1: loss = 0.0415744 (* 1 = 0.0415744 loss)
I0622 17:15:04.832789  3302 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0622 17:15:22.150485  3302 solver.cpp:228] Iteration 2680, loss = 0.0500237
I0622 17:15:22.150585  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981989
I0622 17:15:22.150595  3302 solver.cpp:244]     Train net output #1: loss = 0.0500237 (* 1 = 0.0500237 loss)
I0622 17:15:22.150601  3302 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0622 17:15:38.963933  3302 solver.cpp:337] Iteration 2700, Testing net (#0)
I0622 17:15:39.508532  3302 solver.cpp:404]     Test net output #0: accuracy = 0.988087
I0622 17:15:39.508556  3302 solver.cpp:404]     Test net output #1: loss = 0.0389476 (* 1 = 0.0389476 loss)
I0622 17:15:39.991211  3302 solver.cpp:228] Iteration 2700, loss = 0.0434976
I0622 17:15:39.991236  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983569
I0622 17:15:39.991245  3302 solver.cpp:244]     Train net output #1: loss = 0.0434976 (* 1 = 0.0434976 loss)
I0622 17:15:39.991248  3302 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0622 17:15:57.291833  3302 solver.cpp:228] Iteration 2720, loss = 0.0516976
I0622 17:15:57.291946  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981103
I0622 17:15:57.291956  3302 solver.cpp:244]     Train net output #1: loss = 0.0516976 (* 1 = 0.0516976 loss)
I0622 17:15:57.291960  3302 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0622 17:16:14.615314  3302 solver.cpp:228] Iteration 2740, loss = 0.0480128
I0622 17:16:14.615339  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981872
I0622 17:16:14.615345  3302 solver.cpp:244]     Train net output #1: loss = 0.0480128 (* 1 = 0.0480128 loss)
I0622 17:16:14.615350  3302 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0622 17:16:31.903241  3302 solver.cpp:228] Iteration 2760, loss = 0.0523916
I0622 17:16:31.903347  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981134
I0622 17:16:31.903357  3302 solver.cpp:244]     Train net output #1: loss = 0.0523916 (* 1 = 0.0523916 loss)
I0622 17:16:31.903362  3302 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0622 17:16:49.183430  3302 solver.cpp:228] Iteration 2780, loss = 0.0352376
I0622 17:16:49.183459  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986865
I0622 17:16:49.183466  3302 solver.cpp:244]     Train net output #1: loss = 0.0352376 (* 1 = 0.0352376 loss)
I0622 17:16:49.183471  3302 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0622 17:17:06.292894  3302 solver.cpp:337] Iteration 2800, Testing net (#0)
I0622 17:17:06.838099  3302 solver.cpp:404]     Test net output #0: accuracy = 0.984964
I0622 17:17:06.838124  3302 solver.cpp:404]     Test net output #1: loss = 0.0424834 (* 1 = 0.0424834 loss)
I0622 17:17:07.320382  3302 solver.cpp:228] Iteration 2800, loss = 0.0423882
I0622 17:17:07.320407  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983956
I0622 17:17:07.320415  3302 solver.cpp:244]     Train net output #1: loss = 0.0423882 (* 1 = 0.0423882 loss)
I0622 17:17:07.320420  3302 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0622 17:17:24.598495  3302 solver.cpp:228] Iteration 2820, loss = 0.047662
I0622 17:17:24.598520  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984606
I0622 17:17:24.598527  3302 solver.cpp:244]     Train net output #1: loss = 0.047662 (* 1 = 0.047662 loss)
I0622 17:17:24.598531  3302 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0622 17:17:41.907491  3302 solver.cpp:228] Iteration 2840, loss = 0.0408043
I0622 17:17:41.907624  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985506
I0622 17:17:41.907635  3302 solver.cpp:244]     Train net output #1: loss = 0.0408043 (* 1 = 0.0408043 loss)
I0622 17:17:41.907641  3302 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0622 17:17:59.214916  3302 solver.cpp:228] Iteration 2860, loss = 0.0508078
I0622 17:17:59.214942  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98062
I0622 17:17:59.214949  3302 solver.cpp:244]     Train net output #1: loss = 0.0508078 (* 1 = 0.0508078 loss)
I0622 17:17:59.214964  3302 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0622 17:18:16.634160  3302 solver.cpp:228] Iteration 2880, loss = 0.0425973
I0622 17:18:16.634259  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983401
I0622 17:18:16.634269  3302 solver.cpp:244]     Train net output #1: loss = 0.0425973 (* 1 = 0.0425973 loss)
I0622 17:18:16.634274  3302 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0622 17:18:33.443258  3302 solver.cpp:337] Iteration 2900, Testing net (#0)
I0622 17:18:33.988932  3302 solver.cpp:404]     Test net output #0: accuracy = 0.98623
I0622 17:18:33.988957  3302 solver.cpp:404]     Test net output #1: loss = 0.0423407 (* 1 = 0.0423407 loss)
I0622 17:18:34.472409  3302 solver.cpp:228] Iteration 2900, loss = 0.0396957
I0622 17:18:34.472434  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98639
I0622 17:18:34.472440  3302 solver.cpp:244]     Train net output #1: loss = 0.0396957 (* 1 = 0.0396957 loss)
I0622 17:18:34.472445  3302 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0622 17:18:51.759042  3302 solver.cpp:228] Iteration 2920, loss = 0.0558833
I0622 17:18:51.759166  3302 solver.cpp:244]     Train net output #0: accuracy = 0.97925
I0622 17:18:51.759176  3302 solver.cpp:244]     Train net output #1: loss = 0.0558833 (* 1 = 0.0558833 loss)
I0622 17:18:51.759181  3302 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0622 17:19:09.045974  3302 solver.cpp:228] Iteration 2940, loss = 0.0396112
I0622 17:19:09.046010  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985227
I0622 17:19:09.046017  3302 solver.cpp:244]     Train net output #1: loss = 0.0396112 (* 1 = 0.0396112 loss)
I0622 17:19:09.046022  3302 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0622 17:19:26.427438  3302 solver.cpp:228] Iteration 2960, loss = 0.0386478
I0622 17:19:26.427548  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986181
I0622 17:19:26.427558  3302 solver.cpp:244]     Train net output #1: loss = 0.0386478 (* 1 = 0.0386478 loss)
I0622 17:19:26.427562  3302 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0622 17:19:43.746788  3302 solver.cpp:228] Iteration 2980, loss = 0.0385507
I0622 17:19:43.746822  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986669
I0622 17:19:43.746829  3302 solver.cpp:244]     Train net output #1: loss = 0.0385507 (* 1 = 0.0385507 loss)
I0622 17:19:43.746834  3302 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0622 17:20:00.598281  3302 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_3000.caffemodel
I0622 17:20:00.602126  3302 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_3000.solverstate
I0622 17:20:00.605443  3302 solver.cpp:337] Iteration 3000, Testing net (#0)
I0622 17:20:01.157038  3302 solver.cpp:404]     Test net output #0: accuracy = 0.983919
I0622 17:20:01.157063  3302 solver.cpp:404]     Test net output #1: loss = 0.0486937 (* 1 = 0.0486937 loss)
I0622 17:20:01.640903  3302 solver.cpp:228] Iteration 3000, loss = 0.0408342
I0622 17:20:01.640928  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984287
I0622 17:20:01.640945  3302 solver.cpp:244]     Train net output #1: loss = 0.0408342 (* 1 = 0.0408342 loss)
I0622 17:20:01.640960  3302 sgd_solver.cpp:106] Iteration 3000, lr = 0.001
I0622 17:20:19.321516  3302 solver.cpp:228] Iteration 3020, loss = 0.0505124
I0622 17:20:19.321542  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982059
I0622 17:20:19.321549  3302 solver.cpp:244]     Train net output #1: loss = 0.0505124 (* 1 = 0.0505124 loss)
I0622 17:20:19.321553  3302 sgd_solver.cpp:106] Iteration 3020, lr = 0.001
I0622 17:20:36.625123  3302 solver.cpp:228] Iteration 3040, loss = 0.0506269
I0622 17:20:36.625226  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980155
I0622 17:20:36.625234  3302 solver.cpp:244]     Train net output #1: loss = 0.0506269 (* 1 = 0.0506269 loss)
I0622 17:20:36.625238  3302 sgd_solver.cpp:106] Iteration 3040, lr = 0.001
I0622 17:20:53.909711  3302 solver.cpp:228] Iteration 3060, loss = 0.0459216
I0622 17:20:53.909749  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982439
I0622 17:20:53.909756  3302 solver.cpp:244]     Train net output #1: loss = 0.0459216 (* 1 = 0.0459216 loss)
I0622 17:20:53.909760  3302 sgd_solver.cpp:106] Iteration 3060, lr = 0.001
I0622 17:21:11.189106  3302 solver.cpp:228] Iteration 3080, loss = 0.0513546
I0622 17:21:11.189219  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981235
I0622 17:21:11.189229  3302 solver.cpp:244]     Train net output #1: loss = 0.0513546 (* 1 = 0.0513546 loss)
I0622 17:21:11.189234  3302 sgd_solver.cpp:106] Iteration 3080, lr = 0.001
I0622 17:21:28.137316  3302 solver.cpp:337] Iteration 3100, Testing net (#0)
I0622 17:21:28.698223  3302 solver.cpp:404]     Test net output #0: accuracy = 0.980571
I0622 17:21:28.698259  3302 solver.cpp:404]     Test net output #1: loss = 0.0495778 (* 1 = 0.0495778 loss)
I0622 17:21:29.181496  3302 solver.cpp:228] Iteration 3100, loss = 0.0425197
I0622 17:21:29.181521  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982258
I0622 17:21:29.181529  3302 solver.cpp:244]     Train net output #1: loss = 0.0425197 (* 1 = 0.0425197 loss)
I0622 17:21:29.181534  3302 sgd_solver.cpp:106] Iteration 3100, lr = 0.001
I0622 17:21:46.476315  3302 solver.cpp:228] Iteration 3120, loss = 0.0458417
I0622 17:21:46.476421  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982841
I0622 17:21:46.476431  3302 solver.cpp:244]     Train net output #1: loss = 0.0458417 (* 1 = 0.0458417 loss)
I0622 17:21:46.476435  3302 sgd_solver.cpp:106] Iteration 3120, lr = 0.001
I0622 17:22:03.820312  3302 solver.cpp:228] Iteration 3140, loss = 0.0420382
I0622 17:22:03.820353  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984635
I0622 17:22:03.820360  3302 solver.cpp:244]     Train net output #1: loss = 0.0420382 (* 1 = 0.0420382 loss)
I0622 17:22:03.820365  3302 sgd_solver.cpp:106] Iteration 3140, lr = 0.001
I0622 17:22:21.144080  3302 solver.cpp:228] Iteration 3160, loss = 0.0470029
I0622 17:22:21.144198  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984218
I0622 17:22:21.144209  3302 solver.cpp:244]     Train net output #1: loss = 0.0470029 (* 1 = 0.0470029 loss)
I0622 17:22:21.144214  3302 sgd_solver.cpp:106] Iteration 3160, lr = 0.001
I0622 17:22:38.486070  3302 solver.cpp:228] Iteration 3180, loss = 0.0483003
I0622 17:22:38.486096  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980828
I0622 17:22:38.486104  3302 solver.cpp:244]     Train net output #1: loss = 0.0483003 (* 1 = 0.0483003 loss)
I0622 17:22:38.486109  3302 sgd_solver.cpp:106] Iteration 3180, lr = 0.001
I0622 17:22:55.301177  3302 solver.cpp:337] Iteration 3200, Testing net (#0)
I0622 17:22:55.848392  3302 solver.cpp:404]     Test net output #0: accuracy = 0.982891
I0622 17:22:55.848417  3302 solver.cpp:404]     Test net output #1: loss = 0.0469911 (* 1 = 0.0469911 loss)
I0622 17:22:56.330955  3302 solver.cpp:228] Iteration 3200, loss = 0.0484234
I0622 17:22:56.330979  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982144
I0622 17:22:56.330986  3302 solver.cpp:244]     Train net output #1: loss = 0.0484234 (* 1 = 0.0484234 loss)
I0622 17:22:56.330991  3302 sgd_solver.cpp:106] Iteration 3200, lr = 0.001
I0622 17:23:13.616350  3302 solver.cpp:228] Iteration 3220, loss = 0.0438303
I0622 17:23:13.616387  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983972
I0622 17:23:13.616394  3302 solver.cpp:244]     Train net output #1: loss = 0.0438303 (* 1 = 0.0438303 loss)
I0622 17:23:13.616400  3302 sgd_solver.cpp:106] Iteration 3220, lr = 0.001
I0622 17:23:30.902048  3302 solver.cpp:228] Iteration 3240, loss = 0.0450353
I0622 17:23:30.902204  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983949
I0622 17:23:30.902215  3302 solver.cpp:244]     Train net output #1: loss = 0.0450353 (* 1 = 0.0450353 loss)
I0622 17:23:30.902218  3302 sgd_solver.cpp:106] Iteration 3240, lr = 0.001
I0622 17:23:48.195626  3302 solver.cpp:228] Iteration 3260, loss = 0.0464158
I0622 17:23:48.195652  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982773
I0622 17:23:48.195659  3302 solver.cpp:244]     Train net output #1: loss = 0.0464158 (* 1 = 0.0464158 loss)
I0622 17:23:48.195663  3302 sgd_solver.cpp:106] Iteration 3260, lr = 0.001
I0622 17:24:05.582310  3302 solver.cpp:228] Iteration 3280, loss = 0.0460786
I0622 17:24:05.582384  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982406
I0622 17:24:05.582393  3302 solver.cpp:244]     Train net output #1: loss = 0.0460786 (* 1 = 0.0460786 loss)
I0622 17:24:05.582398  3302 sgd_solver.cpp:106] Iteration 3280, lr = 0.001
I0622 17:24:22.404175  3302 solver.cpp:337] Iteration 3300, Testing net (#0)
I0622 17:24:22.951536  3302 solver.cpp:404]     Test net output #0: accuracy = 0.984168
I0622 17:24:22.951561  3302 solver.cpp:404]     Test net output #1: loss = 0.0425014 (* 1 = 0.0425014 loss)
I0622 17:24:23.434655  3302 solver.cpp:228] Iteration 3300, loss = 0.0398156
I0622 17:24:23.434679  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98851
I0622 17:24:23.434687  3302 solver.cpp:244]     Train net output #1: loss = 0.0398156 (* 1 = 0.0398156 loss)
I0622 17:24:23.434691  3302 sgd_solver.cpp:106] Iteration 3300, lr = 0.001
I0622 17:24:40.727079  3302 solver.cpp:228] Iteration 3320, loss = 0.0428386
I0622 17:24:40.728106  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985746
I0622 17:24:40.728116  3302 solver.cpp:244]     Train net output #1: loss = 0.0428386 (* 1 = 0.0428386 loss)
I0622 17:24:40.728121  3302 sgd_solver.cpp:106] Iteration 3320, lr = 0.001
I0622 17:24:58.015434  3302 solver.cpp:228] Iteration 3340, loss = 0.0441542
I0622 17:24:58.015473  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983937
I0622 17:24:58.015481  3302 solver.cpp:244]     Train net output #1: loss = 0.0441542 (* 1 = 0.0441542 loss)
I0622 17:24:58.015486  3302 sgd_solver.cpp:106] Iteration 3340, lr = 0.001
I0622 17:25:15.513233  3302 solver.cpp:228] Iteration 3360, loss = 0.0539103
I0622 17:25:15.513340  3302 solver.cpp:244]     Train net output #0: accuracy = 0.978534
I0622 17:25:15.513350  3302 solver.cpp:244]     Train net output #1: loss = 0.0539103 (* 1 = 0.0539103 loss)
I0622 17:25:15.513355  3302 sgd_solver.cpp:106] Iteration 3360, lr = 0.001
I0622 17:25:32.799504  3302 solver.cpp:228] Iteration 3380, loss = 0.0400141
I0622 17:25:32.799530  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985653
I0622 17:25:32.799536  3302 solver.cpp:244]     Train net output #1: loss = 0.0400141 (* 1 = 0.0400141 loss)
I0622 17:25:32.799541  3302 sgd_solver.cpp:106] Iteration 3380, lr = 0.001
I0622 17:25:49.600137  3302 solver.cpp:337] Iteration 3400, Testing net (#0)
I0622 17:25:50.244463  3302 solver.cpp:404]     Test net output #0: accuracy = 0.986112
I0622 17:25:50.244489  3302 solver.cpp:404]     Test net output #1: loss = 0.0407823 (* 1 = 0.0407823 loss)
I0622 17:25:50.738512  3302 solver.cpp:228] Iteration 3400, loss = 0.0531371
I0622 17:25:50.738543  3302 solver.cpp:244]     Train net output #0: accuracy = 0.979954
I0622 17:25:50.738549  3302 solver.cpp:244]     Train net output #1: loss = 0.0531371 (* 1 = 0.0531371 loss)
I0622 17:25:50.738554  3302 sgd_solver.cpp:106] Iteration 3400, lr = 0.001
I0622 17:26:08.080760  3302 solver.cpp:228] Iteration 3420, loss = 0.0503026
I0622 17:26:08.080785  3302 solver.cpp:244]     Train net output #0: accuracy = 0.979268
I0622 17:26:08.080802  3302 solver.cpp:244]     Train net output #1: loss = 0.0503026 (* 1 = 0.0503026 loss)
I0622 17:26:08.080807  3302 sgd_solver.cpp:106] Iteration 3420, lr = 0.001
I0622 17:26:25.387912  3302 solver.cpp:228] Iteration 3440, loss = 0.0351816
I0622 17:26:25.387995  3302 solver.cpp:244]     Train net output #0: accuracy = 0.987878
I0622 17:26:25.388005  3302 solver.cpp:244]     Train net output #1: loss = 0.0351816 (* 1 = 0.0351816 loss)
I0622 17:26:25.388011  3302 sgd_solver.cpp:106] Iteration 3440, lr = 0.001
I0622 17:26:42.671013  3302 solver.cpp:228] Iteration 3460, loss = 0.049724
I0622 17:26:42.671051  3302 solver.cpp:244]     Train net output #0: accuracy = 0.979689
I0622 17:26:42.671058  3302 solver.cpp:244]     Train net output #1: loss = 0.049724 (* 1 = 0.049724 loss)
I0622 17:26:42.671063  3302 sgd_solver.cpp:106] Iteration 3460, lr = 0.001
I0622 17:26:59.947877  3302 solver.cpp:228] Iteration 3480, loss = 0.0437399
I0622 17:26:59.947983  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985304
I0622 17:26:59.947993  3302 solver.cpp:244]     Train net output #1: loss = 0.0437399 (* 1 = 0.0437399 loss)
I0622 17:26:59.947998  3302 sgd_solver.cpp:106] Iteration 3480, lr = 0.001
I0622 17:27:16.748615  3302 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_3500.caffemodel
I0622 17:27:16.757123  3302 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_3500.solverstate
I0622 17:27:16.761068  3302 solver.cpp:337] Iteration 3500, Testing net (#0)
I0622 17:27:17.372361  3302 solver.cpp:404]     Test net output #0: accuracy = 0.985338
I0622 17:27:17.372390  3302 solver.cpp:404]     Test net output #1: loss = 0.0417133 (* 1 = 0.0417133 loss)
I0622 17:27:17.866041  3302 solver.cpp:228] Iteration 3500, loss = 0.0406248
I0622 17:27:17.866070  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985337
I0622 17:27:17.866077  3302 solver.cpp:244]     Train net output #1: loss = 0.0406248 (* 1 = 0.0406248 loss)
I0622 17:27:17.866082  3302 sgd_solver.cpp:106] Iteration 3500, lr = 0.001
I0622 17:27:35.246389  3302 solver.cpp:228] Iteration 3520, loss = 0.0483983
I0622 17:27:35.246523  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982586
I0622 17:27:35.246533  3302 solver.cpp:244]     Train net output #1: loss = 0.0483983 (* 1 = 0.0483983 loss)
I0622 17:27:35.246537  3302 sgd_solver.cpp:106] Iteration 3520, lr = 0.001
I0622 17:27:52.548858  3302 solver.cpp:228] Iteration 3540, loss = 0.0512786
I0622 17:27:52.548894  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980787
I0622 17:27:52.548902  3302 solver.cpp:244]     Train net output #1: loss = 0.0512786 (* 1 = 0.0512786 loss)
I0622 17:27:52.548907  3302 sgd_solver.cpp:106] Iteration 3540, lr = 0.001
I0622 17:28:10.072345  3302 solver.cpp:228] Iteration 3560, loss = 0.0354428
I0622 17:28:10.072446  3302 solver.cpp:244]     Train net output #0: accuracy = 0.988934
I0622 17:28:10.072456  3302 solver.cpp:244]     Train net output #1: loss = 0.0354428 (* 1 = 0.0354428 loss)
I0622 17:28:10.072461  3302 sgd_solver.cpp:106] Iteration 3560, lr = 0.001
I0622 17:28:27.362367  3302 solver.cpp:228] Iteration 3580, loss = 0.0370389
I0622 17:28:27.362392  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985814
I0622 17:28:27.362401  3302 solver.cpp:244]     Train net output #1: loss = 0.0370389 (* 1 = 0.0370389 loss)
I0622 17:28:27.362406  3302 sgd_solver.cpp:106] Iteration 3580, lr = 0.001
I0622 17:28:44.158843  3302 solver.cpp:337] Iteration 3600, Testing net (#0)
I0622 17:28:44.703397  3302 solver.cpp:404]     Test net output #0: accuracy = 0.983014
I0622 17:28:44.703421  3302 solver.cpp:404]     Test net output #1: loss = 0.0462079 (* 1 = 0.0462079 loss)
I0622 17:28:45.185968  3302 solver.cpp:228] Iteration 3600, loss = 0.0461143
I0622 17:28:45.185991  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981894
I0622 17:28:45.185998  3302 solver.cpp:244]     Train net output #1: loss = 0.0461143 (* 1 = 0.0461143 loss)
I0622 17:28:45.186002  3302 sgd_solver.cpp:106] Iteration 3600, lr = 0.001
I0622 17:29:02.465884  3302 solver.cpp:228] Iteration 3620, loss = 0.0420323
I0622 17:29:02.465909  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985482
I0622 17:29:02.465916  3302 solver.cpp:244]     Train net output #1: loss = 0.0420323 (* 1 = 0.0420323 loss)
I0622 17:29:02.465920  3302 sgd_solver.cpp:106] Iteration 3620, lr = 0.001
I0622 17:29:19.744602  3302 solver.cpp:228] Iteration 3640, loss = 0.0480975
I0622 17:29:19.744693  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982602
I0622 17:29:19.744702  3302 solver.cpp:244]     Train net output #1: loss = 0.0480975 (* 1 = 0.0480975 loss)
I0622 17:29:19.744706  3302 sgd_solver.cpp:106] Iteration 3640, lr = 0.001
I0622 17:29:37.020900  3302 solver.cpp:228] Iteration 3660, loss = 0.0365026
I0622 17:29:37.020926  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986836
I0622 17:29:37.020934  3302 solver.cpp:244]     Train net output #1: loss = 0.0365026 (* 1 = 0.0365026 loss)
I0622 17:29:37.020939  3302 sgd_solver.cpp:106] Iteration 3660, lr = 0.001
I0622 17:29:54.302445  3302 solver.cpp:228] Iteration 3680, loss = 0.0523984
I0622 17:29:54.302551  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980115
I0622 17:29:54.302559  3302 solver.cpp:244]     Train net output #1: loss = 0.0523984 (* 1 = 0.0523984 loss)
I0622 17:29:54.302563  3302 sgd_solver.cpp:106] Iteration 3680, lr = 0.001
I0622 17:30:11.108747  3302 solver.cpp:337] Iteration 3700, Testing net (#0)
I0622 17:30:11.653384  3302 solver.cpp:404]     Test net output #0: accuracy = 0.985087
I0622 17:30:11.653420  3302 solver.cpp:404]     Test net output #1: loss = 0.0414321 (* 1 = 0.0414321 loss)
I0622 17:30:12.136684  3302 solver.cpp:228] Iteration 3700, loss = 0.0454704
I0622 17:30:12.136708  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981878
I0622 17:30:12.136716  3302 solver.cpp:244]     Train net output #1: loss = 0.0454704 (* 1 = 0.0454704 loss)
I0622 17:30:12.136720  3302 sgd_solver.cpp:106] Iteration 3700, lr = 0.001
I0622 17:30:29.520654  3302 solver.cpp:228] Iteration 3720, loss = 0.0377049
I0622 17:30:29.520781  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985876
I0622 17:30:29.520792  3302 solver.cpp:244]     Train net output #1: loss = 0.0377049 (* 1 = 0.0377049 loss)
I0622 17:30:29.520797  3302 sgd_solver.cpp:106] Iteration 3720, lr = 0.001
I0622 17:30:46.811058  3302 solver.cpp:228] Iteration 3740, loss = 0.0412128
I0622 17:30:46.811084  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985055
I0622 17:30:46.811092  3302 solver.cpp:244]     Train net output #1: loss = 0.0412128 (* 1 = 0.0412128 loss)
I0622 17:30:46.811097  3302 sgd_solver.cpp:106] Iteration 3740, lr = 0.001
I0622 17:31:04.104789  3302 solver.cpp:228] Iteration 3760, loss = 0.0480219
I0622 17:31:04.104866  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981821
I0622 17:31:04.104874  3302 solver.cpp:244]     Train net output #1: loss = 0.0480219 (* 1 = 0.0480219 loss)
I0622 17:31:04.104879  3302 sgd_solver.cpp:106] Iteration 3760, lr = 0.001
I0622 17:31:21.492697  3302 solver.cpp:228] Iteration 3780, loss = 0.0476172
I0622 17:31:21.492723  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982271
I0622 17:31:21.492730  3302 solver.cpp:244]     Train net output #1: loss = 0.0476172 (* 1 = 0.0476172 loss)
I0622 17:31:21.492734  3302 sgd_solver.cpp:106] Iteration 3780, lr = 0.001
I0622 17:31:38.387596  3302 solver.cpp:337] Iteration 3800, Testing net (#0)
I0622 17:31:38.931658  3302 solver.cpp:404]     Test net output #0: accuracy = 0.98604
I0622 17:31:38.931681  3302 solver.cpp:404]     Test net output #1: loss = 0.0429756 (* 1 = 0.0429756 loss)
I0622 17:31:39.415617  3302 solver.cpp:228] Iteration 3800, loss = 0.0452098
I0622 17:31:39.415643  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983952
I0622 17:31:39.415652  3302 solver.cpp:244]     Train net output #1: loss = 0.0452098 (* 1 = 0.0452098 loss)
I0622 17:31:39.415657  3302 sgd_solver.cpp:106] Iteration 3800, lr = 0.001
I0622 17:31:56.803210  3302 solver.cpp:228] Iteration 3820, loss = 0.0489223
I0622 17:31:56.803236  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981845
I0622 17:31:56.803243  3302 solver.cpp:244]     Train net output #1: loss = 0.0489223 (* 1 = 0.0489223 loss)
I0622 17:31:56.803248  3302 sgd_solver.cpp:106] Iteration 3820, lr = 0.001
I0622 17:32:14.371323  3302 solver.cpp:228] Iteration 3840, loss = 0.0440466
I0622 17:32:14.371408  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983344
I0622 17:32:14.371417  3302 solver.cpp:244]     Train net output #1: loss = 0.0440466 (* 1 = 0.0440466 loss)
I0622 17:32:14.371423  3302 sgd_solver.cpp:106] Iteration 3840, lr = 0.001
I0622 17:32:31.834059  3302 solver.cpp:228] Iteration 3860, loss = 0.0427445
I0622 17:32:31.834084  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984937
I0622 17:32:31.834091  3302 solver.cpp:244]     Train net output #1: loss = 0.0427445 (* 1 = 0.0427445 loss)
I0622 17:32:31.834095  3302 sgd_solver.cpp:106] Iteration 3860, lr = 0.001
I0622 17:32:49.114562  3302 solver.cpp:228] Iteration 3880, loss = 0.048739
I0622 17:32:49.114667  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981491
I0622 17:32:49.114675  3302 solver.cpp:244]     Train net output #1: loss = 0.048739 (* 1 = 0.048739 loss)
I0622 17:32:49.114681  3302 sgd_solver.cpp:106] Iteration 3880, lr = 0.001
I0622 17:33:05.905663  3302 solver.cpp:337] Iteration 3900, Testing net (#0)
I0622 17:33:06.450713  3302 solver.cpp:404]     Test net output #0: accuracy = 0.979765
I0622 17:33:06.450747  3302 solver.cpp:404]     Test net output #1: loss = 0.0521632 (* 1 = 0.0521632 loss)
I0622 17:33:06.932273  3302 solver.cpp:228] Iteration 3900, loss = 0.0433191
I0622 17:33:06.932298  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983537
I0622 17:33:06.932307  3302 solver.cpp:244]     Train net output #1: loss = 0.0433191 (* 1 = 0.0433191 loss)
I0622 17:33:06.932310  3302 sgd_solver.cpp:106] Iteration 3900, lr = 0.001
I0622 17:33:24.221106  3302 solver.cpp:228] Iteration 3920, loss = 0.0410624
I0622 17:33:24.221232  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985797
I0622 17:33:24.221242  3302 solver.cpp:244]     Train net output #1: loss = 0.0410624 (* 1 = 0.0410624 loss)
I0622 17:33:24.221247  3302 sgd_solver.cpp:106] Iteration 3920, lr = 0.001
I0622 17:33:41.530650  3302 solver.cpp:228] Iteration 3940, loss = 0.0507907
I0622 17:33:41.530675  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981192
I0622 17:33:41.530683  3302 solver.cpp:244]     Train net output #1: loss = 0.0507907 (* 1 = 0.0507907 loss)
I0622 17:33:41.530689  3302 sgd_solver.cpp:106] Iteration 3940, lr = 0.001
I0622 17:33:58.820547  3302 solver.cpp:228] Iteration 3960, loss = 0.0411212
I0622 17:33:58.820649  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985167
I0622 17:33:58.820658  3302 solver.cpp:244]     Train net output #1: loss = 0.0411212 (* 1 = 0.0411212 loss)
I0622 17:33:58.820663  3302 sgd_solver.cpp:106] Iteration 3960, lr = 0.001
I0622 17:34:16.143656  3302 solver.cpp:228] Iteration 3980, loss = 0.0473105
I0622 17:34:16.143681  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981827
I0622 17:34:16.143688  3302 solver.cpp:244]     Train net output #1: loss = 0.0473105 (* 1 = 0.0473105 loss)
I0622 17:34:16.143692  3302 sgd_solver.cpp:106] Iteration 3980, lr = 0.001
I0622 17:34:33.030436  3302 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_4000.caffemodel
I0622 17:34:33.038358  3302 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_4000.solverstate
I0622 17:34:33.043530  3302 solver.cpp:337] Iteration 4000, Testing net (#0)
I0622 17:34:33.664829  3302 solver.cpp:404]     Test net output #0: accuracy = 0.982237
I0622 17:34:33.664857  3302 solver.cpp:404]     Test net output #1: loss = 0.0506537 (* 1 = 0.0506537 loss)
I0622 17:34:34.158865  3302 solver.cpp:228] Iteration 4000, loss = 0.0436787
I0622 17:34:34.158891  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982581
I0622 17:34:34.158898  3302 solver.cpp:244]     Train net output #1: loss = 0.0436787 (* 1 = 0.0436787 loss)
I0622 17:34:34.158903  3302 sgd_solver.cpp:106] Iteration 4000, lr = 0.0001
I0622 17:34:51.447564  3302 solver.cpp:228] Iteration 4020, loss = 0.0529238
I0622 17:34:51.447595  3302 solver.cpp:244]     Train net output #0: accuracy = 0.978252
I0622 17:34:51.447602  3302 solver.cpp:244]     Train net output #1: loss = 0.0529238 (* 1 = 0.0529238 loss)
I0622 17:34:51.447608  3302 sgd_solver.cpp:106] Iteration 4020, lr = 0.0001
I0622 17:35:08.744153  3302 solver.cpp:228] Iteration 4040, loss = 0.0477484
I0622 17:35:08.744253  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980614
I0622 17:35:08.744262  3302 solver.cpp:244]     Train net output #1: loss = 0.0477484 (* 1 = 0.0477484 loss)
I0622 17:35:08.744267  3302 sgd_solver.cpp:106] Iteration 4040, lr = 0.0001
I0622 17:35:26.057803  3302 solver.cpp:228] Iteration 4060, loss = 0.0409112
I0622 17:35:26.057840  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984033
I0622 17:35:26.057855  3302 solver.cpp:244]     Train net output #1: loss = 0.0409112 (* 1 = 0.0409112 loss)
I0622 17:35:26.057860  3302 sgd_solver.cpp:106] Iteration 4060, lr = 0.0001
I0622 17:35:43.365088  3302 solver.cpp:228] Iteration 4080, loss = 0.0510533
I0622 17:35:43.365205  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981964
I0622 17:35:43.365216  3302 solver.cpp:244]     Train net output #1: loss = 0.0510533 (* 1 = 0.0510533 loss)
I0622 17:35:43.365221  3302 sgd_solver.cpp:106] Iteration 4080, lr = 0.0001
I0622 17:36:00.244324  3302 solver.cpp:337] Iteration 4100, Testing net (#0)
I0622 17:36:00.794632  3302 solver.cpp:404]     Test net output #0: accuracy = 0.981713
I0622 17:36:00.794656  3302 solver.cpp:404]     Test net output #1: loss = 0.0476674 (* 1 = 0.0476674 loss)
I0622 17:36:01.281064  3302 solver.cpp:228] Iteration 4100, loss = 0.0484686
I0622 17:36:01.281100  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980019
I0622 17:36:01.281108  3302 solver.cpp:244]     Train net output #1: loss = 0.0484686 (* 1 = 0.0484686 loss)
I0622 17:36:01.281112  3302 sgd_solver.cpp:106] Iteration 4100, lr = 0.0001
I0622 17:36:18.566504  3302 solver.cpp:228] Iteration 4120, loss = 0.0455436
I0622 17:36:18.566635  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983317
I0622 17:36:18.566645  3302 solver.cpp:244]     Train net output #1: loss = 0.0455436 (* 1 = 0.0455436 loss)
I0622 17:36:18.566649  3302 sgd_solver.cpp:106] Iteration 4120, lr = 0.0001
I0622 17:36:35.852504  3302 solver.cpp:228] Iteration 4140, loss = 0.0496844
I0622 17:36:35.852533  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98149
I0622 17:36:35.852547  3302 solver.cpp:244]     Train net output #1: loss = 0.0496844 (* 1 = 0.0496844 loss)
I0622 17:36:35.852552  3302 sgd_solver.cpp:106] Iteration 4140, lr = 0.0001
I0622 17:36:53.141175  3302 solver.cpp:228] Iteration 4160, loss = 0.0438127
I0622 17:36:53.141280  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983789
I0622 17:36:53.141290  3302 solver.cpp:244]     Train net output #1: loss = 0.0438127 (* 1 = 0.0438127 loss)
I0622 17:36:53.141294  3302 sgd_solver.cpp:106] Iteration 4160, lr = 0.0001
I0622 17:37:10.421957  3302 solver.cpp:228] Iteration 4180, loss = 0.0376564
I0622 17:37:10.421995  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985701
I0622 17:37:10.422003  3302 solver.cpp:244]     Train net output #1: loss = 0.0376564 (* 1 = 0.0376564 loss)
I0622 17:37:10.422008  3302 sgd_solver.cpp:106] Iteration 4180, lr = 0.0001
I0622 17:37:27.219013  3302 solver.cpp:337] Iteration 4200, Testing net (#0)
I0622 17:37:27.764060  3302 solver.cpp:404]     Test net output #0: accuracy = 0.981571
I0622 17:37:27.764084  3302 solver.cpp:404]     Test net output #1: loss = 0.0504523 (* 1 = 0.0504523 loss)
I0622 17:37:28.246578  3302 solver.cpp:228] Iteration 4200, loss = 0.0519769
I0622 17:37:28.246603  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980906
I0622 17:37:28.246610  3302 solver.cpp:244]     Train net output #1: loss = 0.0519769 (* 1 = 0.0519769 loss)
I0622 17:37:28.246615  3302 sgd_solver.cpp:106] Iteration 4200, lr = 0.0001
I0622 17:37:45.533433  3302 solver.cpp:228] Iteration 4220, loss = 0.0471548
I0622 17:37:45.533470  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983631
I0622 17:37:45.533488  3302 solver.cpp:244]     Train net output #1: loss = 0.0471548 (* 1 = 0.0471548 loss)
I0622 17:37:45.533494  3302 sgd_solver.cpp:106] Iteration 4220, lr = 0.0001
I0622 17:38:02.826905  3302 solver.cpp:228] Iteration 4240, loss = 0.0396152
I0622 17:38:02.827003  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985923
I0622 17:38:02.827011  3302 solver.cpp:244]     Train net output #1: loss = 0.0396152 (* 1 = 0.0396152 loss)
I0622 17:38:02.827015  3302 sgd_solver.cpp:106] Iteration 4240, lr = 0.0001
I0622 17:38:20.120571  3302 solver.cpp:228] Iteration 4260, loss = 0.0474935
I0622 17:38:20.120599  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983662
I0622 17:38:20.120605  3302 solver.cpp:244]     Train net output #1: loss = 0.0474935 (* 1 = 0.0474935 loss)
I0622 17:38:20.120610  3302 sgd_solver.cpp:106] Iteration 4260, lr = 0.0001
I0622 17:38:37.416107  3302 solver.cpp:228] Iteration 4280, loss = 0.0515294
I0622 17:38:37.416203  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98185
I0622 17:38:37.416214  3302 solver.cpp:244]     Train net output #1: loss = 0.0515294 (* 1 = 0.0515294 loss)
I0622 17:38:37.416218  3302 sgd_solver.cpp:106] Iteration 4280, lr = 0.0001
I0622 17:38:54.214886  3302 solver.cpp:337] Iteration 4300, Testing net (#0)
I0622 17:38:54.759022  3302 solver.cpp:404]     Test net output #0: accuracy = 0.980464
I0622 17:38:54.759047  3302 solver.cpp:404]     Test net output #1: loss = 0.0502243 (* 1 = 0.0502243 loss)
I0622 17:38:55.242257  3302 solver.cpp:228] Iteration 4300, loss = 0.042997
I0622 17:38:55.242281  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983338
I0622 17:38:55.242300  3302 solver.cpp:244]     Train net output #1: loss = 0.042997 (* 1 = 0.042997 loss)
I0622 17:38:55.242305  3302 sgd_solver.cpp:106] Iteration 4300, lr = 0.0001
I0622 17:39:12.528628  3302 solver.cpp:228] Iteration 4320, loss = 0.0430831
I0622 17:39:12.528762  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983779
I0622 17:39:12.528772  3302 solver.cpp:244]     Train net output #1: loss = 0.0430831 (* 1 = 0.0430831 loss)
I0622 17:39:12.528777  3302 sgd_solver.cpp:106] Iteration 4320, lr = 0.0001
I0622 17:39:29.807157  3302 solver.cpp:228] Iteration 4340, loss = 0.0439918
I0622 17:39:29.807183  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984866
I0622 17:39:29.807190  3302 solver.cpp:244]     Train net output #1: loss = 0.0439918 (* 1 = 0.0439918 loss)
I0622 17:39:29.807195  3302 sgd_solver.cpp:106] Iteration 4340, lr = 0.0001
I0622 17:39:47.088444  3302 solver.cpp:228] Iteration 4360, loss = 0.0431844
I0622 17:39:47.088511  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986081
I0622 17:39:47.088521  3302 solver.cpp:244]     Train net output #1: loss = 0.0431844 (* 1 = 0.0431844 loss)
I0622 17:39:47.088526  3302 sgd_solver.cpp:106] Iteration 4360, lr = 0.0001
I0622 17:40:04.376829  3302 solver.cpp:228] Iteration 4380, loss = 0.0565454
I0622 17:40:04.376857  3302 solver.cpp:244]     Train net output #0: accuracy = 0.977188
I0622 17:40:04.376863  3302 solver.cpp:244]     Train net output #1: loss = 0.0565454 (* 1 = 0.0565454 loss)
I0622 17:40:04.376868  3302 sgd_solver.cpp:106] Iteration 4380, lr = 0.0001
I0622 17:40:21.188531  3302 solver.cpp:337] Iteration 4400, Testing net (#0)
I0622 17:40:21.733599  3302 solver.cpp:404]     Test net output #0: accuracy = 0.985394
I0622 17:40:21.733634  3302 solver.cpp:404]     Test net output #1: loss = 0.0426257 (* 1 = 0.0426257 loss)
I0622 17:40:22.216502  3302 solver.cpp:228] Iteration 4400, loss = 0.0470732
I0622 17:40:22.216527  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983948
I0622 17:40:22.216534  3302 solver.cpp:244]     Train net output #1: loss = 0.0470732 (* 1 = 0.0470732 loss)
I0622 17:40:22.216539  3302 sgd_solver.cpp:106] Iteration 4400, lr = 0.0001
I0622 17:40:39.498934  3302 solver.cpp:228] Iteration 4420, loss = 0.0441556
I0622 17:40:39.498960  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984837
I0622 17:40:39.498967  3302 solver.cpp:244]     Train net output #1: loss = 0.0441556 (* 1 = 0.0441556 loss)
I0622 17:40:39.498971  3302 sgd_solver.cpp:106] Iteration 4420, lr = 0.0001
I0622 17:40:56.783161  3302 solver.cpp:228] Iteration 4440, loss = 0.0444554
I0622 17:40:56.783262  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983053
I0622 17:40:56.783270  3302 solver.cpp:244]     Train net output #1: loss = 0.0444554 (* 1 = 0.0444554 loss)
I0622 17:40:56.783274  3302 sgd_solver.cpp:106] Iteration 4440, lr = 0.0001
I0622 17:41:14.064546  3302 solver.cpp:228] Iteration 4460, loss = 0.0480493
I0622 17:41:14.064581  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982267
I0622 17:41:14.064599  3302 solver.cpp:244]     Train net output #1: loss = 0.0480493 (* 1 = 0.0480493 loss)
I0622 17:41:14.064604  3302 sgd_solver.cpp:106] Iteration 4460, lr = 0.0001
I0622 17:41:31.353296  3302 solver.cpp:228] Iteration 4480, loss = 0.0478403
I0622 17:41:31.353384  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981862
I0622 17:41:31.353392  3302 solver.cpp:244]     Train net output #1: loss = 0.0478403 (* 1 = 0.0478403 loss)
I0622 17:41:31.353396  3302 sgd_solver.cpp:106] Iteration 4480, lr = 0.0001
I0622 17:41:48.224522  3302 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_4500.caffemodel
I0622 17:41:48.232993  3302 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_4500.solverstate
I0622 17:41:48.236979  3302 solver.cpp:337] Iteration 4500, Testing net (#0)
I0622 17:41:48.847923  3302 solver.cpp:404]     Test net output #0: accuracy = 0.980775
I0622 17:41:48.847951  3302 solver.cpp:404]     Test net output #1: loss = 0.0510689 (* 1 = 0.0510689 loss)
I0622 17:41:49.343704  3302 solver.cpp:228] Iteration 4500, loss = 0.0405175
I0622 17:41:49.343734  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985237
I0622 17:41:49.343741  3302 solver.cpp:244]     Train net output #1: loss = 0.0405175 (* 1 = 0.0405175 loss)
I0622 17:41:49.343746  3302 sgd_solver.cpp:106] Iteration 4500, lr = 0.0001
I0622 17:42:06.680796  3302 solver.cpp:228] Iteration 4520, loss = 0.0339468
I0622 17:42:06.680902  3302 solver.cpp:244]     Train net output #0: accuracy = 0.990022
I0622 17:42:06.680913  3302 solver.cpp:244]     Train net output #1: loss = 0.0339468 (* 1 = 0.0339468 loss)
I0622 17:42:06.680918  3302 sgd_solver.cpp:106] Iteration 4520, lr = 0.0001
I0622 17:42:24.010220  3302 solver.cpp:228] Iteration 4540, loss = 0.0405114
I0622 17:42:24.010246  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98506
I0622 17:42:24.010253  3302 solver.cpp:244]     Train net output #1: loss = 0.0405114 (* 1 = 0.0405114 loss)
I0622 17:42:24.010258  3302 sgd_solver.cpp:106] Iteration 4540, lr = 0.0001
I0622 17:42:41.520910  3302 solver.cpp:228] Iteration 4560, loss = 0.0496053
I0622 17:42:41.521010  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983678
I0622 17:42:41.521020  3302 solver.cpp:244]     Train net output #1: loss = 0.0496053 (* 1 = 0.0496053 loss)
I0622 17:42:41.521024  3302 sgd_solver.cpp:106] Iteration 4560, lr = 0.0001
I0622 17:42:58.824887  3302 solver.cpp:228] Iteration 4580, loss = 0.0511391
I0622 17:42:58.824913  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982091
I0622 17:42:58.824920  3302 solver.cpp:244]     Train net output #1: loss = 0.0511391 (* 1 = 0.0511391 loss)
I0622 17:42:58.824925  3302 sgd_solver.cpp:106] Iteration 4580, lr = 0.0001
I0622 17:43:15.885263  3302 solver.cpp:337] Iteration 4600, Testing net (#0)
I0622 17:43:16.430881  3302 solver.cpp:404]     Test net output #0: accuracy = 0.98373
I0622 17:43:16.430905  3302 solver.cpp:404]     Test net output #1: loss = 0.0422571 (* 1 = 0.0422571 loss)
I0622 17:43:16.913885  3302 solver.cpp:228] Iteration 4600, loss = 0.0513994
I0622 17:43:16.913910  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980875
I0622 17:43:16.913918  3302 solver.cpp:244]     Train net output #1: loss = 0.0513994 (* 1 = 0.0513994 loss)
I0622 17:43:16.913923  3302 sgd_solver.cpp:106] Iteration 4600, lr = 0.0001
I0622 17:43:34.213729  3302 solver.cpp:228] Iteration 4620, loss = 0.0456235
I0622 17:43:34.213757  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98318
I0622 17:43:34.213763  3302 solver.cpp:244]     Train net output #1: loss = 0.0456235 (* 1 = 0.0456235 loss)
I0622 17:43:34.213768  3302 sgd_solver.cpp:106] Iteration 4620, lr = 0.0001
I0622 17:43:51.510185  3302 solver.cpp:228] Iteration 4640, loss = 0.0550526
I0622 17:43:51.510288  3302 solver.cpp:244]     Train net output #0: accuracy = 0.976758
I0622 17:43:51.510298  3302 solver.cpp:244]     Train net output #1: loss = 0.0550526 (* 1 = 0.0550526 loss)
I0622 17:43:51.510301  3302 sgd_solver.cpp:106] Iteration 4640, lr = 0.0001
I0622 17:44:09.070978  3302 solver.cpp:228] Iteration 4660, loss = 0.047768
I0622 17:44:09.071007  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981625
I0622 17:44:09.071013  3302 solver.cpp:244]     Train net output #1: loss = 0.047768 (* 1 = 0.047768 loss)
I0622 17:44:09.071018  3302 sgd_solver.cpp:106] Iteration 4660, lr = 0.0001
I0622 17:44:26.625174  3302 solver.cpp:228] Iteration 4680, loss = 0.0403243
I0622 17:44:26.625277  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986183
I0622 17:44:26.625286  3302 solver.cpp:244]     Train net output #1: loss = 0.0403243 (* 1 = 0.0403243 loss)
I0622 17:44:26.625290  3302 sgd_solver.cpp:106] Iteration 4680, lr = 0.0001
I0622 17:44:43.442410  3302 solver.cpp:337] Iteration 4700, Testing net (#0)
I0622 17:44:43.986907  3302 solver.cpp:404]     Test net output #0: accuracy = 0.983694
I0622 17:44:43.986943  3302 solver.cpp:404]     Test net output #1: loss = 0.0435665 (* 1 = 0.0435665 loss)
I0622 17:44:44.469949  3302 solver.cpp:228] Iteration 4700, loss = 0.0433112
I0622 17:44:44.469974  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984203
I0622 17:44:44.469980  3302 solver.cpp:244]     Train net output #1: loss = 0.0433112 (* 1 = 0.0433112 loss)
I0622 17:44:44.469985  3302 sgd_solver.cpp:106] Iteration 4700, lr = 0.0001
I0622 17:45:01.754796  3302 solver.cpp:228] Iteration 4720, loss = 0.0431777
I0622 17:45:01.754914  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985388
I0622 17:45:01.754925  3302 solver.cpp:244]     Train net output #1: loss = 0.0431777 (* 1 = 0.0431777 loss)
I0622 17:45:01.754930  3302 sgd_solver.cpp:106] Iteration 4720, lr = 0.0001
I0622 17:45:19.026139  3302 solver.cpp:228] Iteration 4740, loss = 0.0465668
I0622 17:45:19.026175  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984442
I0622 17:45:19.026181  3302 solver.cpp:244]     Train net output #1: loss = 0.0465668 (* 1 = 0.0465668 loss)
I0622 17:45:19.026186  3302 sgd_solver.cpp:106] Iteration 4740, lr = 0.0001
I0622 17:45:36.306155  3302 solver.cpp:228] Iteration 4760, loss = 0.0454487
I0622 17:45:36.306264  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983855
I0622 17:45:36.306273  3302 solver.cpp:244]     Train net output #1: loss = 0.0454487 (* 1 = 0.0454487 loss)
I0622 17:45:36.306278  3302 sgd_solver.cpp:106] Iteration 4760, lr = 0.0001
I0622 17:45:53.796020  3302 solver.cpp:228] Iteration 4780, loss = 0.0451643
I0622 17:45:53.796056  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982495
I0622 17:45:53.796064  3302 solver.cpp:244]     Train net output #1: loss = 0.0451643 (* 1 = 0.0451643 loss)
I0622 17:45:53.796068  3302 sgd_solver.cpp:106] Iteration 4780, lr = 0.0001
I0622 17:46:10.741819  3302 solver.cpp:337] Iteration 4800, Testing net (#0)
I0622 17:46:11.302882  3302 solver.cpp:404]     Test net output #0: accuracy = 0.981837
I0622 17:46:11.302908  3302 solver.cpp:404]     Test net output #1: loss = 0.0494458 (* 1 = 0.0494458 loss)
I0622 17:46:11.787639  3302 solver.cpp:228] Iteration 4800, loss = 0.0456627
I0622 17:46:11.787667  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981864
I0622 17:46:11.787673  3302 solver.cpp:244]     Train net output #1: loss = 0.0456627 (* 1 = 0.0456627 loss)
I0622 17:46:11.787678  3302 sgd_solver.cpp:106] Iteration 4800, lr = 0.0001
I0622 17:46:29.105254  3302 solver.cpp:228] Iteration 4820, loss = 0.0407642
I0622 17:46:29.105280  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985879
I0622 17:46:29.105288  3302 solver.cpp:244]     Train net output #1: loss = 0.0407642 (* 1 = 0.0407642 loss)
I0622 17:46:29.105293  3302 sgd_solver.cpp:106] Iteration 4820, lr = 0.0001
I0622 17:46:46.383368  3302 solver.cpp:228] Iteration 4840, loss = 0.0545572
I0622 17:46:46.383491  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980646
I0622 17:46:46.383500  3302 solver.cpp:244]     Train net output #1: loss = 0.0545572 (* 1 = 0.0545572 loss)
I0622 17:46:46.383505  3302 sgd_solver.cpp:106] Iteration 4840, lr = 0.0001
I0622 17:47:03.665442  3302 solver.cpp:228] Iteration 4860, loss = 0.0464239
I0622 17:47:03.665467  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983442
I0622 17:47:03.665474  3302 solver.cpp:244]     Train net output #1: loss = 0.0464239 (* 1 = 0.0464239 loss)
I0622 17:47:03.665478  3302 sgd_solver.cpp:106] Iteration 4860, lr = 0.0001
I0622 17:47:20.942769  3302 solver.cpp:228] Iteration 4880, loss = 0.0443667
I0622 17:47:20.942867  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982384
I0622 17:47:20.942876  3302 solver.cpp:244]     Train net output #1: loss = 0.0443667 (* 1 = 0.0443667 loss)
I0622 17:47:20.942881  3302 sgd_solver.cpp:106] Iteration 4880, lr = 0.0001
I0622 17:47:37.743612  3302 solver.cpp:337] Iteration 4900, Testing net (#0)
I0622 17:47:38.307427  3302 solver.cpp:404]     Test net output #0: accuracy = 0.978577
I0622 17:47:38.307453  3302 solver.cpp:404]     Test net output #1: loss = 0.0584752 (* 1 = 0.0584752 loss)
I0622 17:47:38.934272  3302 solver.cpp:228] Iteration 4900, loss = 0.0361632
I0622 17:47:38.934298  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98778
I0622 17:47:38.934306  3302 solver.cpp:244]     Train net output #1: loss = 0.0361632 (* 1 = 0.0361632 loss)
I0622 17:47:38.934311  3302 sgd_solver.cpp:106] Iteration 4900, lr = 0.0001
I0622 17:47:56.221954  3302 solver.cpp:228] Iteration 4920, loss = 0.0395855
I0622 17:47:56.222090  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986498
I0622 17:47:56.222100  3302 solver.cpp:244]     Train net output #1: loss = 0.0395855 (* 1 = 0.0395855 loss)
I0622 17:47:56.222105  3302 sgd_solver.cpp:106] Iteration 4920, lr = 0.0001
I0622 17:48:13.596083  3302 solver.cpp:228] Iteration 4940, loss = 0.0419013
I0622 17:48:13.596109  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985758
I0622 17:48:13.596117  3302 solver.cpp:244]     Train net output #1: loss = 0.0419013 (* 1 = 0.0419013 loss)
I0622 17:48:13.596122  3302 sgd_solver.cpp:106] Iteration 4940, lr = 0.0001
I0622 17:48:30.878674  3302 solver.cpp:228] Iteration 4960, loss = 0.0470551
I0622 17:48:30.878780  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984035
I0622 17:48:30.878789  3302 solver.cpp:244]     Train net output #1: loss = 0.0470551 (* 1 = 0.0470551 loss)
I0622 17:48:30.878794  3302 sgd_solver.cpp:106] Iteration 4960, lr = 0.0001
I0622 17:48:48.173434  3302 solver.cpp:228] Iteration 4980, loss = 0.0454607
I0622 17:48:48.173460  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981097
I0622 17:48:48.173467  3302 solver.cpp:244]     Train net output #1: loss = 0.0454607 (* 1 = 0.0454607 loss)
I0622 17:48:48.173471  3302 sgd_solver.cpp:106] Iteration 4980, lr = 0.0001
I0622 17:49:04.977056  3302 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_5000.caffemodel
I0622 17:49:04.985713  3302 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_5000.solverstate
I0622 17:49:04.990213  3302 solver.cpp:337] Iteration 5000, Testing net (#0)
I0622 17:49:05.600620  3302 solver.cpp:404]     Test net output #0: accuracy = 0.981186
I0622 17:49:05.600648  3302 solver.cpp:404]     Test net output #1: loss = 0.0527827 (* 1 = 0.0527827 loss)
I0622 17:49:06.094357  3302 solver.cpp:228] Iteration 5000, loss = 0.0507727
I0622 17:49:06.094395  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98045
I0622 17:49:06.094403  3302 solver.cpp:244]     Train net output #1: loss = 0.0507727 (* 1 = 0.0507727 loss)
I0622 17:49:06.094409  3302 sgd_solver.cpp:106] Iteration 5000, lr = 0.0001
I0622 17:49:23.436269  3302 solver.cpp:228] Iteration 5020, loss = 0.0457387
I0622 17:49:23.436305  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981076
I0622 17:49:23.436318  3302 solver.cpp:244]     Train net output #1: loss = 0.0457387 (* 1 = 0.0457387 loss)
I0622 17:49:23.436326  3302 sgd_solver.cpp:106] Iteration 5020, lr = 0.0001
I0622 17:49:40.727012  3302 solver.cpp:228] Iteration 5040, loss = 0.0419174
I0622 17:49:40.727105  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983934
I0622 17:49:40.727116  3302 solver.cpp:244]     Train net output #1: loss = 0.0419174 (* 1 = 0.0419174 loss)
I0622 17:49:40.727121  3302 sgd_solver.cpp:106] Iteration 5040, lr = 0.0001
I0622 17:49:58.002838  3302 solver.cpp:228] Iteration 5060, loss = 0.0450483
I0622 17:49:58.002864  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984254
I0622 17:49:58.002871  3302 solver.cpp:244]     Train net output #1: loss = 0.0450483 (* 1 = 0.0450483 loss)
I0622 17:49:58.002876  3302 sgd_solver.cpp:106] Iteration 5060, lr = 0.0001
I0622 17:50:15.293722  3302 solver.cpp:228] Iteration 5080, loss = 0.0491767
I0622 17:50:15.293854  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980553
I0622 17:50:15.293864  3302 solver.cpp:244]     Train net output #1: loss = 0.0491767 (* 1 = 0.0491767 loss)
I0622 17:50:15.293870  3302 sgd_solver.cpp:106] Iteration 5080, lr = 0.0001
I0622 17:50:32.100466  3302 solver.cpp:337] Iteration 5100, Testing net (#0)
I0622 17:50:32.643039  3302 solver.cpp:404]     Test net output #0: accuracy = 0.98533
I0622 17:50:32.643064  3302 solver.cpp:404]     Test net output #1: loss = 0.0398469 (* 1 = 0.0398469 loss)
I0622 17:50:33.124450  3302 solver.cpp:228] Iteration 5100, loss = 0.0477308
I0622 17:50:33.124485  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982221
I0622 17:50:33.124493  3302 solver.cpp:244]     Train net output #1: loss = 0.0477308 (* 1 = 0.0477308 loss)
I0622 17:50:33.124497  3302 sgd_solver.cpp:106] Iteration 5100, lr = 0.0001
I0622 17:50:50.418463  3302 solver.cpp:228] Iteration 5120, loss = 0.0411236
I0622 17:50:50.418562  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984657
I0622 17:50:50.418571  3302 solver.cpp:244]     Train net output #1: loss = 0.0411236 (* 1 = 0.0411236 loss)
I0622 17:50:50.418576  3302 sgd_solver.cpp:106] Iteration 5120, lr = 0.0001
I0622 17:51:07.720824  3302 solver.cpp:228] Iteration 5140, loss = 0.0432065
I0622 17:51:07.720850  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985089
I0622 17:51:07.720859  3302 solver.cpp:244]     Train net output #1: loss = 0.0432065 (* 1 = 0.0432065 loss)
I0622 17:51:07.720862  3302 sgd_solver.cpp:106] Iteration 5140, lr = 0.0001
I0622 17:51:25.304630  3302 solver.cpp:228] Iteration 5160, loss = 0.0430639
I0622 17:51:25.304729  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984405
I0622 17:51:25.304738  3302 solver.cpp:244]     Train net output #1: loss = 0.0430639 (* 1 = 0.0430639 loss)
I0622 17:51:25.304744  3302 sgd_solver.cpp:106] Iteration 5160, lr = 0.0001
I0622 17:51:42.597324  3302 solver.cpp:228] Iteration 5180, loss = 0.0498896
I0622 17:51:42.597359  3302 solver.cpp:244]     Train net output #0: accuracy = 0.978713
I0622 17:51:42.597368  3302 solver.cpp:244]     Train net output #1: loss = 0.0498896 (* 1 = 0.0498896 loss)
I0622 17:51:42.597373  3302 sgd_solver.cpp:106] Iteration 5180, lr = 0.0001
I0622 17:51:59.404290  3302 solver.cpp:337] Iteration 5200, Testing net (#0)
I0622 17:51:59.960616  3302 solver.cpp:404]     Test net output #0: accuracy = 0.9871
I0622 17:51:59.960640  3302 solver.cpp:404]     Test net output #1: loss = 0.037829 (* 1 = 0.037829 loss)
I0622 17:52:00.443819  3302 solver.cpp:228] Iteration 5200, loss = 0.0441778
I0622 17:52:00.443845  3302 solver.cpp:244]     Train net output #0: accuracy = 0.98376
I0622 17:52:00.443852  3302 solver.cpp:244]     Train net output #1: loss = 0.0441778 (* 1 = 0.0441778 loss)
I0622 17:52:00.443856  3302 sgd_solver.cpp:106] Iteration 5200, lr = 0.0001
I0622 17:52:17.739928  3302 solver.cpp:228] Iteration 5220, loss = 0.0469169
I0622 17:52:17.739954  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984241
I0622 17:52:17.739960  3302 solver.cpp:244]     Train net output #1: loss = 0.0469169 (* 1 = 0.0469169 loss)
I0622 17:52:17.739965  3302 sgd_solver.cpp:106] Iteration 5220, lr = 0.0001
I0622 17:52:35.026973  3302 solver.cpp:228] Iteration 5240, loss = 0.0441703
I0622 17:52:35.027227  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984705
I0622 17:52:35.027237  3302 solver.cpp:244]     Train net output #1: loss = 0.0441703 (* 1 = 0.0441703 loss)
I0622 17:52:35.027242  3302 sgd_solver.cpp:106] Iteration 5240, lr = 0.0001
I0622 17:52:52.312925  3302 solver.cpp:228] Iteration 5260, loss = 0.0430565
I0622 17:52:52.312950  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983619
I0622 17:52:52.312958  3302 solver.cpp:244]     Train net output #1: loss = 0.0430565 (* 1 = 0.0430565 loss)
I0622 17:52:52.312963  3302 sgd_solver.cpp:106] Iteration 5260, lr = 0.0001
I0622 17:53:09.608016  3302 solver.cpp:228] Iteration 5280, loss = 0.0481308
I0622 17:53:09.608117  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981162
I0622 17:53:09.608127  3302 solver.cpp:244]     Train net output #1: loss = 0.0481308 (* 1 = 0.0481308 loss)
I0622 17:53:09.608132  3302 sgd_solver.cpp:106] Iteration 5280, lr = 0.0001
I0622 17:53:26.417170  3302 solver.cpp:337] Iteration 5300, Testing net (#0)
I0622 17:53:26.963449  3302 solver.cpp:404]     Test net output #0: accuracy = 0.983815
I0622 17:53:26.963477  3302 solver.cpp:404]     Test net output #1: loss = 0.0437566 (* 1 = 0.0437566 loss)
I0622 17:53:27.446264  3302 solver.cpp:228] Iteration 5300, loss = 0.0405415
I0622 17:53:27.446287  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982966
I0622 17:53:27.446295  3302 solver.cpp:244]     Train net output #1: loss = 0.0405415 (* 1 = 0.0405415 loss)
I0622 17:53:27.446300  3302 sgd_solver.cpp:106] Iteration 5300, lr = 0.0001
I0622 17:53:45.041528  3302 solver.cpp:228] Iteration 5320, loss = 0.0488686
I0622 17:53:45.041659  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981064
I0622 17:53:45.041669  3302 solver.cpp:244]     Train net output #1: loss = 0.0488686 (* 1 = 0.0488686 loss)
I0622 17:53:45.041674  3302 sgd_solver.cpp:106] Iteration 5320, lr = 0.0001
I0622 17:54:02.363127  3302 solver.cpp:228] Iteration 5340, loss = 0.0488272
I0622 17:54:02.363155  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981852
I0622 17:54:02.363165  3302 solver.cpp:244]     Train net output #1: loss = 0.0488272 (* 1 = 0.0488272 loss)
I0622 17:54:02.363170  3302 sgd_solver.cpp:106] Iteration 5340, lr = 0.0001
I0622 17:54:19.673156  3302 solver.cpp:228] Iteration 5360, loss = 0.047833
I0622 17:54:19.673255  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982989
I0622 17:54:19.673264  3302 solver.cpp:244]     Train net output #1: loss = 0.047833 (* 1 = 0.047833 loss)
I0622 17:54:19.673269  3302 sgd_solver.cpp:106] Iteration 5360, lr = 0.0001
I0622 17:54:36.961432  3302 solver.cpp:228] Iteration 5380, loss = 0.0407362
I0622 17:54:36.961459  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984174
I0622 17:54:36.961467  3302 solver.cpp:244]     Train net output #1: loss = 0.0407362 (* 1 = 0.0407362 loss)
I0622 17:54:36.961472  3302 sgd_solver.cpp:106] Iteration 5380, lr = 0.0001
I0622 17:54:53.761339  3302 solver.cpp:337] Iteration 5400, Testing net (#0)
I0622 17:54:54.306814  3302 solver.cpp:404]     Test net output #0: accuracy = 0.984559
I0622 17:54:54.306838  3302 solver.cpp:404]     Test net output #1: loss = 0.0425864 (* 1 = 0.0425864 loss)
I0622 17:54:54.789129  3302 solver.cpp:228] Iteration 5400, loss = 0.0405091
I0622 17:54:54.789155  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986833
I0622 17:54:54.789162  3302 solver.cpp:244]     Train net output #1: loss = 0.0405091 (* 1 = 0.0405091 loss)
I0622 17:54:54.789166  3302 sgd_solver.cpp:106] Iteration 5400, lr = 0.0001
I0622 17:55:12.071686  3302 solver.cpp:228] Iteration 5420, loss = 0.0356705
I0622 17:55:12.071712  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986907
I0622 17:55:12.071718  3302 solver.cpp:244]     Train net output #1: loss = 0.0356705 (* 1 = 0.0356705 loss)
I0622 17:55:12.071723  3302 sgd_solver.cpp:106] Iteration 5420, lr = 0.0001
I0622 17:55:29.356940  3302 solver.cpp:228] Iteration 5440, loss = 0.0486452
I0622 17:55:29.357048  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982526
I0622 17:55:29.357058  3302 solver.cpp:244]     Train net output #1: loss = 0.0486452 (* 1 = 0.0486452 loss)
I0622 17:55:29.357062  3302 sgd_solver.cpp:106] Iteration 5440, lr = 0.0001
I0622 17:55:46.663939  3302 solver.cpp:228] Iteration 5460, loss = 0.0405294
I0622 17:55:46.663964  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985324
I0622 17:55:46.663971  3302 solver.cpp:244]     Train net output #1: loss = 0.0405294 (* 1 = 0.0405294 loss)
I0622 17:55:46.663975  3302 sgd_solver.cpp:106] Iteration 5460, lr = 0.0001
I0622 17:56:03.970369  3302 solver.cpp:228] Iteration 5480, loss = 0.0479574
I0622 17:56:03.970463  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982339
I0622 17:56:03.970473  3302 solver.cpp:244]     Train net output #1: loss = 0.0479574 (* 1 = 0.0479574 loss)
I0622 17:56:03.970477  3302 sgd_solver.cpp:106] Iteration 5480, lr = 0.0001
I0622 17:56:20.773289  3302 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_5500.caffemodel
I0622 17:56:20.781836  3302 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_5500.solverstate
I0622 17:56:20.787061  3302 solver.cpp:337] Iteration 5500, Testing net (#0)
I0622 17:56:21.332579  3302 solver.cpp:404]     Test net output #0: accuracy = 0.98239
I0622 17:56:21.332614  3302 solver.cpp:404]     Test net output #1: loss = 0.0456219 (* 1 = 0.0456219 loss)
I0622 17:56:21.815104  3302 solver.cpp:228] Iteration 5500, loss = 0.0424486
I0622 17:56:21.815129  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984052
I0622 17:56:21.815136  3302 solver.cpp:244]     Train net output #1: loss = 0.0424486 (* 1 = 0.0424486 loss)
I0622 17:56:21.815141  3302 sgd_solver.cpp:106] Iteration 5500, lr = 0.0001
I0622 17:56:39.113054  3302 solver.cpp:228] Iteration 5520, loss = 0.0449713
I0622 17:56:39.113175  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985761
I0622 17:56:39.113185  3302 solver.cpp:244]     Train net output #1: loss = 0.0449713 (* 1 = 0.0449713 loss)
I0622 17:56:39.113189  3302 sgd_solver.cpp:106] Iteration 5520, lr = 0.0001
I0622 17:56:56.401847  3302 solver.cpp:228] Iteration 5540, loss = 0.0537402
I0622 17:56:56.401871  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980355
I0622 17:56:56.401878  3302 solver.cpp:244]     Train net output #1: loss = 0.0537402 (* 1 = 0.0537402 loss)
I0622 17:56:56.401883  3302 sgd_solver.cpp:106] Iteration 5540, lr = 0.0001
I0622 17:57:13.681874  3302 solver.cpp:228] Iteration 5560, loss = 0.0475275
I0622 17:57:13.681978  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982526
I0622 17:57:13.681988  3302 solver.cpp:244]     Train net output #1: loss = 0.0475275 (* 1 = 0.0475275 loss)
I0622 17:57:13.681993  3302 sgd_solver.cpp:106] Iteration 5560, lr = 0.0001
I0622 17:57:30.979220  3302 solver.cpp:228] Iteration 5580, loss = 0.0436348
I0622 17:57:30.979248  3302 solver.cpp:244]     Train net output #0: accuracy = 0.986777
I0622 17:57:30.979254  3302 solver.cpp:244]     Train net output #1: loss = 0.0436348 (* 1 = 0.0436348 loss)
I0622 17:57:30.979259  3302 sgd_solver.cpp:106] Iteration 5580, lr = 0.0001
I0622 17:57:47.793871  3302 solver.cpp:337] Iteration 5600, Testing net (#0)
I0622 17:57:48.339170  3302 solver.cpp:404]     Test net output #0: accuracy = 0.983898
I0622 17:57:48.339195  3302 solver.cpp:404]     Test net output #1: loss = 0.0479887 (* 1 = 0.0479887 loss)
I0622 17:57:48.822641  3302 solver.cpp:228] Iteration 5600, loss = 0.0412911
I0622 17:57:48.822666  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985869
I0622 17:57:48.822674  3302 solver.cpp:244]     Train net output #1: loss = 0.0412911 (* 1 = 0.0412911 loss)
I0622 17:57:48.822679  3302 sgd_solver.cpp:106] Iteration 5600, lr = 0.0001
I0622 17:58:06.128340  3302 solver.cpp:228] Iteration 5620, loss = 0.050894
I0622 17:58:06.128365  3302 solver.cpp:244]     Train net output #0: accuracy = 0.980409
I0622 17:58:06.128371  3302 solver.cpp:244]     Train net output #1: loss = 0.050894 (* 1 = 0.050894 loss)
I0622 17:58:06.128376  3302 sgd_solver.cpp:106] Iteration 5620, lr = 0.0001
I0622 17:58:23.457007  3302 solver.cpp:228] Iteration 5640, loss = 0.045383
I0622 17:58:23.457108  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983979
I0622 17:58:23.457118  3302 solver.cpp:244]     Train net output #1: loss = 0.045383 (* 1 = 0.045383 loss)
I0622 17:58:23.457123  3302 sgd_solver.cpp:106] Iteration 5640, lr = 0.0001
I0622 17:58:40.746053  3302 solver.cpp:228] Iteration 5660, loss = 0.0423317
I0622 17:58:40.746078  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985321
I0622 17:58:40.746085  3302 solver.cpp:244]     Train net output #1: loss = 0.0423317 (* 1 = 0.0423317 loss)
I0622 17:58:40.746089  3302 sgd_solver.cpp:106] Iteration 5660, lr = 0.0001
I0622 17:58:58.033022  3302 solver.cpp:228] Iteration 5680, loss = 0.0459699
I0622 17:58:58.033145  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981584
I0622 17:58:58.033155  3302 solver.cpp:244]     Train net output #1: loss = 0.0459699 (* 1 = 0.0459699 loss)
I0622 17:58:58.033160  3302 sgd_solver.cpp:106] Iteration 5680, lr = 0.0001
I0622 17:59:14.849794  3302 solver.cpp:337] Iteration 5700, Testing net (#0)
I0622 17:59:15.410758  3302 solver.cpp:404]     Test net output #0: accuracy = 0.983438
I0622 17:59:15.410783  3302 solver.cpp:404]     Test net output #1: loss = 0.0426882 (* 1 = 0.0426882 loss)
I0622 17:59:15.894825  3302 solver.cpp:228] Iteration 5700, loss = 0.0523038
I0622 17:59:15.894850  3302 solver.cpp:244]     Train net output #0: accuracy = 0.979464
I0622 17:59:15.894857  3302 solver.cpp:244]     Train net output #1: loss = 0.0523038 (* 1 = 0.0523038 loss)
I0622 17:59:15.894862  3302 sgd_solver.cpp:106] Iteration 5700, lr = 0.0001
I0622 17:59:33.174276  3302 solver.cpp:228] Iteration 5720, loss = 0.0402715
I0622 17:59:33.174372  3302 solver.cpp:244]     Train net output #0: accuracy = 0.985636
I0622 17:59:33.174382  3302 solver.cpp:244]     Train net output #1: loss = 0.0402715 (* 1 = 0.0402715 loss)
I0622 17:59:33.174386  3302 sgd_solver.cpp:106] Iteration 5720, lr = 0.0001
I0622 17:59:50.460088  3302 solver.cpp:228] Iteration 5740, loss = 0.0443271
I0622 17:59:50.460114  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983101
I0622 17:59:50.460120  3302 solver.cpp:244]     Train net output #1: loss = 0.0443271 (* 1 = 0.0443271 loss)
I0622 17:59:50.460125  3302 sgd_solver.cpp:106] Iteration 5740, lr = 0.0001
I0622 18:00:07.766185  3302 solver.cpp:228] Iteration 5760, loss = 0.0417932
I0622 18:00:07.766294  3302 solver.cpp:244]     Train net output #0: accuracy = 0.984649
I0622 18:00:07.766304  3302 solver.cpp:244]     Train net output #1: loss = 0.0417932 (* 1 = 0.0417932 loss)
I0622 18:00:07.766309  3302 sgd_solver.cpp:106] Iteration 5760, lr = 0.0001
I0622 18:00:25.061228  3302 solver.cpp:228] Iteration 5780, loss = 0.0501698
I0622 18:00:25.061254  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981953
I0622 18:00:25.061262  3302 solver.cpp:244]     Train net output #1: loss = 0.0501698 (* 1 = 0.0501698 loss)
I0622 18:00:25.061267  3302 sgd_solver.cpp:106] Iteration 5780, lr = 0.0001
I0622 18:00:41.875628  3302 solver.cpp:337] Iteration 5800, Testing net (#0)
I0622 18:00:42.420766  3302 solver.cpp:404]     Test net output #0: accuracy = 0.977416
I0622 18:00:42.420790  3302 solver.cpp:404]     Test net output #1: loss = 0.0576016 (* 1 = 0.0576016 loss)
I0622 18:00:42.905460  3302 solver.cpp:228] Iteration 5800, loss = 0.0438628
I0622 18:00:42.905484  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982726
I0622 18:00:42.905491  3302 solver.cpp:244]     Train net output #1: loss = 0.0438628 (* 1 = 0.0438628 loss)
I0622 18:00:42.905496  3302 sgd_solver.cpp:106] Iteration 5800, lr = 0.0001
I0622 18:01:00.198122  3302 solver.cpp:228] Iteration 5820, loss = 0.0437287
I0622 18:01:00.198148  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983024
I0622 18:01:00.198156  3302 solver.cpp:244]     Train net output #1: loss = 0.0437287 (* 1 = 0.0437287 loss)
I0622 18:01:00.198160  3302 sgd_solver.cpp:106] Iteration 5820, lr = 0.0001
I0622 18:01:17.499312  3302 solver.cpp:228] Iteration 5840, loss = 0.0513067
I0622 18:01:17.499424  3302 solver.cpp:244]     Train net output #0: accuracy = 0.979971
I0622 18:01:17.499434  3302 solver.cpp:244]     Train net output #1: loss = 0.0513067 (* 1 = 0.0513067 loss)
I0622 18:01:17.499439  3302 sgd_solver.cpp:106] Iteration 5840, lr = 0.0001
I0622 18:01:34.769973  3302 solver.cpp:228] Iteration 5860, loss = 0.0453936
I0622 18:01:34.769999  3302 solver.cpp:244]     Train net output #0: accuracy = 0.983199
I0622 18:01:34.770005  3302 solver.cpp:244]     Train net output #1: loss = 0.0453936 (* 1 = 0.0453936 loss)
I0622 18:01:34.770010  3302 sgd_solver.cpp:106] Iteration 5860, lr = 0.0001
I0622 18:01:52.055685  3302 solver.cpp:228] Iteration 5880, loss = 0.0584158
I0622 18:01:52.055807  3302 solver.cpp:244]     Train net output #0: accuracy = 0.977489
I0622 18:01:52.055817  3302 solver.cpp:244]     Train net output #1: loss = 0.0584158 (* 1 = 0.0584158 loss)
I0622 18:01:52.055822  3302 sgd_solver.cpp:106] Iteration 5880, lr = 0.0001
I0622 18:02:08.981559  3302 solver.cpp:337] Iteration 5900, Testing net (#0)
I0622 18:02:09.526401  3302 solver.cpp:404]     Test net output #0: accuracy = 0.986434
I0622 18:02:09.526427  3302 solver.cpp:404]     Test net output #1: loss = 0.0420337 (* 1 = 0.0420337 loss)
I0622 18:02:10.008966  3302 solver.cpp:228] Iteration 5900, loss = 0.0587801
I0622 18:02:10.009001  3302 solver.cpp:244]     Train net output #0: accuracy = 0.97535
I0622 18:02:10.009008  3302 solver.cpp:244]     Train net output #1: loss = 0.0587801 (* 1 = 0.0587801 loss)
I0622 18:02:10.009013  3302 sgd_solver.cpp:106] Iteration 5900, lr = 0.0001
I0622 18:02:27.290526  3302 solver.cpp:228] Iteration 5920, loss = 0.0465323
I0622 18:02:27.290640  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982414
I0622 18:02:27.290649  3302 solver.cpp:244]     Train net output #1: loss = 0.0465323 (* 1 = 0.0465323 loss)
I0622 18:02:27.290654  3302 sgd_solver.cpp:106] Iteration 5920, lr = 0.0001
I0622 18:02:44.576115  3302 solver.cpp:228] Iteration 5940, loss = 0.0475244
I0622 18:02:44.576140  3302 solver.cpp:244]     Train net output #0: accuracy = 0.982627
I0622 18:02:44.576148  3302 solver.cpp:244]     Train net output #1: loss = 0.0475244 (* 1 = 0.0475244 loss)
I0622 18:02:44.576151  3302 sgd_solver.cpp:106] Iteration 5940, lr = 0.0001
I0622 18:03:01.831732  3302 solver.cpp:228] Iteration 5960, loss = 0.0448211
I0622 18:03:01.831822  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981994
I0622 18:03:01.831831  3302 solver.cpp:244]     Train net output #1: loss = 0.0448211 (* 1 = 0.0448211 loss)
I0622 18:03:01.831835  3302 sgd_solver.cpp:106] Iteration 5960, lr = 0.0001
I0622 18:03:19.087419  3302 solver.cpp:228] Iteration 5980, loss = 0.0512713
I0622 18:03:19.087445  3302 solver.cpp:244]     Train net output #0: accuracy = 0.981047
I0622 18:03:19.087451  3302 solver.cpp:244]     Train net output #1: loss = 0.0512713 (* 1 = 0.0512713 loss)
I0622 18:03:19.087460  3302 sgd_solver.cpp:106] Iteration 5980, lr = 0.0001
I0622 18:03:35.889538  3302 solver.cpp:454] Snapshotting to binary proto file data/models/segnet_iter_6000.caffemodel
I0622 18:03:35.898295  3302 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/segnet_iter_6000.solverstate
I0622 18:03:36.407976  3302 solver.cpp:317] Iteration 6000, loss = 0.0399479
I0622 18:03:36.408004  3302 solver.cpp:337] Iteration 6000, Testing net (#0)
I0622 18:03:36.961848  3302 solver.cpp:404]     Test net output #0: accuracy = 0.983819
I0622 18:03:36.961875  3302 solver.cpp:404]     Test net output #1: loss = 0.0436331 (* 1 = 0.0436331 loss)
I0622 18:03:36.961879  3302 solver.cpp:322] Optimization Done.
I0622 18:03:36.961882  3302 caffe.cpp:222] Optimization Done.
