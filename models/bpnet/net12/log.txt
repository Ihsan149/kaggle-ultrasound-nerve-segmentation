I0625 20:07:08.862296 18573 caffe.cpp:185] Using GPUs 0
I0625 20:07:08.878674 18573 caffe.cpp:190] GPU 0: Graphics Device
I0625 20:07:09.338755 18573 solver.cpp:48] Initializing solver from parameters: 
test_iter: 64
test_interval: 100
base_lr: 0.001
display: 20
max_iter: 3000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 3000
snapshot: 500
snapshot_prefix: "data/models/bpnet"
solver_mode: GPU
device_id: 0
net: "models/bpnet/train_val.prototxt"
test_initialization: true
iter_size: 1
I0625 20:07:09.338867 18573 solver.cpp:91] Creating training net from net file: models/bpnet/train_val.prototxt
I0625 20:07:09.339669 18573 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0625 20:07:09.339891 18573 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 100
    crop_h: 196
    crop_w: 256
    rotation_range: 10
    scale_jitter_range: 0.1
    contrast_jitter_range: 0.3
  }
  data_param {
    source: "data/train_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  pooling_param {
    pool: AVE
    stride: 1
    kernel_h: 6
    kernel_w: 8
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0625 20:07:09.340055 18573 layer_factory.hpp:77] Creating layer data
I0625 20:07:09.340523 18573 net.cpp:91] Creating Layer data
I0625 20:07:09.340534 18573 net.cpp:399] data -> data
I0625 20:07:09.340556 18573 net.cpp:399] data -> label
I0625 20:07:09.341866 18577 db_lmdb.cpp:35] Opened lmdb data/train_lmdb
I0625 20:07:09.365813 18573 data_layer.cpp:42] output data size: 32,3,196,256
I0625 20:07:09.406193 18573 net.cpp:141] Setting up data
I0625 20:07:09.406227 18573 net.cpp:148] Top shape: 32 3 196 256 (4816896)
I0625 20:07:09.406234 18573 net.cpp:148] Top shape: 32 (32)
I0625 20:07:09.406237 18573 net.cpp:156] Memory required for data: 19267712
I0625 20:07:09.406249 18573 layer_factory.hpp:77] Creating layer label_data_1_split
I0625 20:07:09.406270 18573 net.cpp:91] Creating Layer label_data_1_split
I0625 20:07:09.406280 18573 net.cpp:425] label_data_1_split <- label
I0625 20:07:09.406296 18573 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0625 20:07:09.406311 18573 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0625 20:07:09.406378 18573 net.cpp:141] Setting up label_data_1_split
I0625 20:07:09.406388 18573 net.cpp:148] Top shape: 32 (32)
I0625 20:07:09.406393 18573 net.cpp:148] Top shape: 32 (32)
I0625 20:07:09.406396 18573 net.cpp:156] Memory required for data: 19267968
I0625 20:07:09.406400 18573 layer_factory.hpp:77] Creating layer conv1_1
I0625 20:07:09.406422 18573 net.cpp:91] Creating Layer conv1_1
I0625 20:07:09.406445 18573 net.cpp:425] conv1_1 <- data
I0625 20:07:09.406455 18573 net.cpp:399] conv1_1 -> conv1_1
I0625 20:07:09.690104 18573 net.cpp:141] Setting up conv1_1
I0625 20:07:09.690130 18573 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:07:09.690135 18573 net.cpp:156] Memory required for data: 70648192
I0625 20:07:09.690150 18573 layer_factory.hpp:77] Creating layer bn1_1
I0625 20:07:09.690171 18573 net.cpp:91] Creating Layer bn1_1
I0625 20:07:09.690181 18573 net.cpp:425] bn1_1 <- conv1_1
I0625 20:07:09.690186 18573 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0625 20:07:09.690343 18573 net.cpp:141] Setting up bn1_1
I0625 20:07:09.690352 18573 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:07:09.690354 18573 net.cpp:156] Memory required for data: 122028416
I0625 20:07:09.690363 18573 layer_factory.hpp:77] Creating layer scale1_1
I0625 20:07:09.690372 18573 net.cpp:91] Creating Layer scale1_1
I0625 20:07:09.690376 18573 net.cpp:425] scale1_1 <- conv1_1
I0625 20:07:09.690379 18573 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0625 20:07:09.690413 18573 layer_factory.hpp:77] Creating layer scale1_1
I0625 20:07:09.690511 18573 net.cpp:141] Setting up scale1_1
I0625 20:07:09.690518 18573 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:07:09.690521 18573 net.cpp:156] Memory required for data: 173408640
I0625 20:07:09.690527 18573 layer_factory.hpp:77] Creating layer relu1_1
I0625 20:07:09.690532 18573 net.cpp:91] Creating Layer relu1_1
I0625 20:07:09.690536 18573 net.cpp:425] relu1_1 <- conv1_1
I0625 20:07:09.690538 18573 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0625 20:07:09.690678 18573 net.cpp:141] Setting up relu1_1
I0625 20:07:09.690687 18573 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:07:09.690690 18573 net.cpp:156] Memory required for data: 224788864
I0625 20:07:09.690692 18573 layer_factory.hpp:77] Creating layer conv1_2
I0625 20:07:09.690701 18573 net.cpp:91] Creating Layer conv1_2
I0625 20:07:09.690704 18573 net.cpp:425] conv1_2 <- conv1_1
I0625 20:07:09.690709 18573 net.cpp:399] conv1_2 -> conv1_2
I0625 20:07:09.691578 18573 net.cpp:141] Setting up conv1_2
I0625 20:07:09.691591 18573 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:07:09.691593 18573 net.cpp:156] Memory required for data: 276169088
I0625 20:07:09.691597 18573 layer_factory.hpp:77] Creating layer bn1_2
I0625 20:07:09.691604 18573 net.cpp:91] Creating Layer bn1_2
I0625 20:07:09.691607 18573 net.cpp:425] bn1_2 <- conv1_2
I0625 20:07:09.691612 18573 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0625 20:07:09.691768 18573 net.cpp:141] Setting up bn1_2
I0625 20:07:09.691776 18573 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:07:09.691778 18573 net.cpp:156] Memory required for data: 327549312
I0625 20:07:09.691787 18573 layer_factory.hpp:77] Creating layer scale1_2
I0625 20:07:09.691794 18573 net.cpp:91] Creating Layer scale1_2
I0625 20:07:09.691797 18573 net.cpp:425] scale1_2 <- conv1_2
I0625 20:07:09.691802 18573 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0625 20:07:09.691833 18573 layer_factory.hpp:77] Creating layer scale1_2
I0625 20:07:09.691936 18573 net.cpp:141] Setting up scale1_2
I0625 20:07:09.691943 18573 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:07:09.691946 18573 net.cpp:156] Memory required for data: 378929536
I0625 20:07:09.691951 18573 layer_factory.hpp:77] Creating layer relu1_2
I0625 20:07:09.691954 18573 net.cpp:91] Creating Layer relu1_2
I0625 20:07:09.691957 18573 net.cpp:425] relu1_2 <- conv1_2
I0625 20:07:09.691962 18573 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0625 20:07:09.692097 18573 net.cpp:141] Setting up relu1_2
I0625 20:07:09.692106 18573 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 20:07:09.692108 18573 net.cpp:156] Memory required for data: 430309760
I0625 20:07:09.692111 18573 layer_factory.hpp:77] Creating layer pool1
I0625 20:07:09.692116 18573 net.cpp:91] Creating Layer pool1
I0625 20:07:09.692118 18573 net.cpp:425] pool1 <- conv1_2
I0625 20:07:09.692123 18573 net.cpp:399] pool1 -> pool1
I0625 20:07:09.692168 18573 net.cpp:141] Setting up pool1
I0625 20:07:09.692188 18573 net.cpp:148] Top shape: 32 32 49 64 (3211264)
I0625 20:07:09.692189 18573 net.cpp:156] Memory required for data: 443154816
I0625 20:07:09.692193 18573 layer_factory.hpp:77] Creating layer conv2_1
I0625 20:07:09.692201 18573 net.cpp:91] Creating Layer conv2_1
I0625 20:07:09.692204 18573 net.cpp:425] conv2_1 <- pool1
I0625 20:07:09.692209 18573 net.cpp:399] conv2_1 -> conv2_1
I0625 20:07:09.696121 18573 net.cpp:141] Setting up conv2_1
I0625 20:07:09.696135 18573 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:07:09.696138 18573 net.cpp:156] Memory required for data: 468844928
I0625 20:07:09.696142 18573 layer_factory.hpp:77] Creating layer bn2_1
I0625 20:07:09.696151 18573 net.cpp:91] Creating Layer bn2_1
I0625 20:07:09.696153 18573 net.cpp:425] bn2_1 <- conv2_1
I0625 20:07:09.696158 18573 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0625 20:07:09.697355 18573 net.cpp:141] Setting up bn2_1
I0625 20:07:09.697365 18573 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:07:09.697367 18573 net.cpp:156] Memory required for data: 494535040
I0625 20:07:09.697374 18573 layer_factory.hpp:77] Creating layer scale2_1
I0625 20:07:09.697381 18573 net.cpp:91] Creating Layer scale2_1
I0625 20:07:09.697383 18573 net.cpp:425] scale2_1 <- conv2_1
I0625 20:07:09.697388 18573 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0625 20:07:09.697422 18573 layer_factory.hpp:77] Creating layer scale2_1
I0625 20:07:09.697512 18573 net.cpp:141] Setting up scale2_1
I0625 20:07:09.697518 18573 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:07:09.697521 18573 net.cpp:156] Memory required for data: 520225152
I0625 20:07:09.697528 18573 layer_factory.hpp:77] Creating layer relu2_1
I0625 20:07:09.697535 18573 net.cpp:91] Creating Layer relu2_1
I0625 20:07:09.697536 18573 net.cpp:425] relu2_1 <- conv2_1
I0625 20:07:09.697546 18573 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0625 20:07:09.697934 18573 net.cpp:141] Setting up relu2_1
I0625 20:07:09.697945 18573 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:07:09.697948 18573 net.cpp:156] Memory required for data: 545915264
I0625 20:07:09.697950 18573 layer_factory.hpp:77] Creating layer conv2_2
I0625 20:07:09.697959 18573 net.cpp:91] Creating Layer conv2_2
I0625 20:07:09.697962 18573 net.cpp:425] conv2_2 <- conv2_1
I0625 20:07:09.697967 18573 net.cpp:399] conv2_2 -> conv2_2
I0625 20:07:09.698700 18573 net.cpp:141] Setting up conv2_2
I0625 20:07:09.698710 18573 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:07:09.698712 18573 net.cpp:156] Memory required for data: 571605376
I0625 20:07:09.698716 18573 layer_factory.hpp:77] Creating layer bn2_2
I0625 20:07:09.698726 18573 net.cpp:91] Creating Layer bn2_2
I0625 20:07:09.698729 18573 net.cpp:425] bn2_2 <- conv2_2
I0625 20:07:09.698734 18573 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0625 20:07:09.698870 18573 net.cpp:141] Setting up bn2_2
I0625 20:07:09.698878 18573 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:07:09.698879 18573 net.cpp:156] Memory required for data: 597295488
I0625 20:07:09.698885 18573 layer_factory.hpp:77] Creating layer scale2_2
I0625 20:07:09.698891 18573 net.cpp:91] Creating Layer scale2_2
I0625 20:07:09.698894 18573 net.cpp:425] scale2_2 <- conv2_2
I0625 20:07:09.698899 18573 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0625 20:07:09.698927 18573 layer_factory.hpp:77] Creating layer scale2_2
I0625 20:07:09.699010 18573 net.cpp:141] Setting up scale2_2
I0625 20:07:09.699017 18573 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:07:09.699018 18573 net.cpp:156] Memory required for data: 622985600
I0625 20:07:09.699023 18573 layer_factory.hpp:77] Creating layer relu2_2
I0625 20:07:09.699026 18573 net.cpp:91] Creating Layer relu2_2
I0625 20:07:09.699029 18573 net.cpp:425] relu2_2 <- conv2_2
I0625 20:07:09.699034 18573 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0625 20:07:09.699419 18573 net.cpp:141] Setting up relu2_2
I0625 20:07:09.699430 18573 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 20:07:09.699434 18573 net.cpp:156] Memory required for data: 648675712
I0625 20:07:09.699446 18573 layer_factory.hpp:77] Creating layer pool2
I0625 20:07:09.699453 18573 net.cpp:91] Creating Layer pool2
I0625 20:07:09.699456 18573 net.cpp:425] pool2 <- conv2_2
I0625 20:07:09.699460 18573 net.cpp:399] pool2 -> pool2
I0625 20:07:09.699496 18573 net.cpp:141] Setting up pool2
I0625 20:07:09.699501 18573 net.cpp:148] Top shape: 32 64 25 32 (1638400)
I0625 20:07:09.699503 18573 net.cpp:156] Memory required for data: 655229312
I0625 20:07:09.699506 18573 layer_factory.hpp:77] Creating layer conv3_1
I0625 20:07:09.699512 18573 net.cpp:91] Creating Layer conv3_1
I0625 20:07:09.699514 18573 net.cpp:425] conv3_1 <- pool2
I0625 20:07:09.699518 18573 net.cpp:399] conv3_1 -> conv3_1
I0625 20:07:09.701742 18573 net.cpp:141] Setting up conv3_1
I0625 20:07:09.701755 18573 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:07:09.701757 18573 net.cpp:156] Memory required for data: 668336512
I0625 20:07:09.701761 18573 layer_factory.hpp:77] Creating layer bn3_1
I0625 20:07:09.701767 18573 net.cpp:91] Creating Layer bn3_1
I0625 20:07:09.701771 18573 net.cpp:425] bn3_1 <- conv3_1
I0625 20:07:09.701774 18573 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0625 20:07:09.702940 18573 net.cpp:141] Setting up bn3_1
I0625 20:07:09.702951 18573 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:07:09.702955 18573 net.cpp:156] Memory required for data: 681443712
I0625 20:07:09.702960 18573 layer_factory.hpp:77] Creating layer scale3_1
I0625 20:07:09.702967 18573 net.cpp:91] Creating Layer scale3_1
I0625 20:07:09.702970 18573 net.cpp:425] scale3_1 <- conv3_1
I0625 20:07:09.702977 18573 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0625 20:07:09.703011 18573 layer_factory.hpp:77] Creating layer scale3_1
I0625 20:07:09.703090 18573 net.cpp:141] Setting up scale3_1
I0625 20:07:09.703096 18573 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:07:09.703099 18573 net.cpp:156] Memory required for data: 694550912
I0625 20:07:09.703104 18573 layer_factory.hpp:77] Creating layer relu3_1
I0625 20:07:09.703107 18573 net.cpp:91] Creating Layer relu3_1
I0625 20:07:09.703110 18573 net.cpp:425] relu3_1 <- conv3_1
I0625 20:07:09.703115 18573 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0625 20:07:09.703256 18573 net.cpp:141] Setting up relu3_1
I0625 20:07:09.703266 18573 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:07:09.703269 18573 net.cpp:156] Memory required for data: 707658112
I0625 20:07:09.703271 18573 layer_factory.hpp:77] Creating layer conv3_2
I0625 20:07:09.703279 18573 net.cpp:91] Creating Layer conv3_2
I0625 20:07:09.703282 18573 net.cpp:425] conv3_2 <- conv3_1
I0625 20:07:09.703287 18573 net.cpp:399] conv3_2 -> conv3_2
I0625 20:07:09.705276 18573 net.cpp:141] Setting up conv3_2
I0625 20:07:09.705287 18573 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:07:09.705291 18573 net.cpp:156] Memory required for data: 720765312
I0625 20:07:09.705294 18573 layer_factory.hpp:77] Creating layer bn3_2
I0625 20:07:09.705302 18573 net.cpp:91] Creating Layer bn3_2
I0625 20:07:09.705305 18573 net.cpp:425] bn3_2 <- conv3_2
I0625 20:07:09.705309 18573 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0625 20:07:09.705451 18573 net.cpp:141] Setting up bn3_2
I0625 20:07:09.705458 18573 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:07:09.705461 18573 net.cpp:156] Memory required for data: 733872512
I0625 20:07:09.705472 18573 layer_factory.hpp:77] Creating layer scale3_2
I0625 20:07:09.705478 18573 net.cpp:91] Creating Layer scale3_2
I0625 20:07:09.705481 18573 net.cpp:425] scale3_2 <- conv3_2
I0625 20:07:09.705483 18573 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0625 20:07:09.705514 18573 layer_factory.hpp:77] Creating layer scale3_2
I0625 20:07:09.705593 18573 net.cpp:141] Setting up scale3_2
I0625 20:07:09.705598 18573 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:07:09.705600 18573 net.cpp:156] Memory required for data: 746979712
I0625 20:07:09.705605 18573 layer_factory.hpp:77] Creating layer relu3_2
I0625 20:07:09.705608 18573 net.cpp:91] Creating Layer relu3_2
I0625 20:07:09.705611 18573 net.cpp:425] relu3_2 <- conv3_2
I0625 20:07:09.705627 18573 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0625 20:07:09.705768 18573 net.cpp:141] Setting up relu3_2
I0625 20:07:09.705778 18573 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 20:07:09.705781 18573 net.cpp:156] Memory required for data: 760086912
I0625 20:07:09.705785 18573 layer_factory.hpp:77] Creating layer pool3
I0625 20:07:09.705790 18573 net.cpp:91] Creating Layer pool3
I0625 20:07:09.705791 18573 net.cpp:425] pool3 <- conv3_2
I0625 20:07:09.705796 18573 net.cpp:399] pool3 -> pool3
I0625 20:07:09.705832 18573 net.cpp:141] Setting up pool3
I0625 20:07:09.705837 18573 net.cpp:148] Top shape: 32 128 13 16 (851968)
I0625 20:07:09.705839 18573 net.cpp:156] Memory required for data: 763494784
I0625 20:07:09.705842 18573 layer_factory.hpp:77] Creating layer conv4_1
I0625 20:07:09.705849 18573 net.cpp:91] Creating Layer conv4_1
I0625 20:07:09.705852 18573 net.cpp:425] conv4_1 <- pool3
I0625 20:07:09.705855 18573 net.cpp:399] conv4_1 -> conv4_1
I0625 20:07:09.708654 18573 net.cpp:141] Setting up conv4_1
I0625 20:07:09.708667 18573 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:07:09.708673 18573 net.cpp:156] Memory required for data: 770310528
I0625 20:07:09.708676 18573 layer_factory.hpp:77] Creating layer bn4_1
I0625 20:07:09.708684 18573 net.cpp:91] Creating Layer bn4_1
I0625 20:07:09.708688 18573 net.cpp:425] bn4_1 <- conv4_1
I0625 20:07:09.708691 18573 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0625 20:07:09.708837 18573 net.cpp:141] Setting up bn4_1
I0625 20:07:09.708844 18573 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:07:09.708847 18573 net.cpp:156] Memory required for data: 777126272
I0625 20:07:09.708853 18573 layer_factory.hpp:77] Creating layer scale4_1
I0625 20:07:09.708858 18573 net.cpp:91] Creating Layer scale4_1
I0625 20:07:09.708860 18573 net.cpp:425] scale4_1 <- conv4_1
I0625 20:07:09.708864 18573 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0625 20:07:09.708895 18573 layer_factory.hpp:77] Creating layer scale4_1
I0625 20:07:09.708973 18573 net.cpp:141] Setting up scale4_1
I0625 20:07:09.708979 18573 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:07:09.708982 18573 net.cpp:156] Memory required for data: 783942016
I0625 20:07:09.708986 18573 layer_factory.hpp:77] Creating layer relu4_1
I0625 20:07:09.708994 18573 net.cpp:91] Creating Layer relu4_1
I0625 20:07:09.708997 18573 net.cpp:425] relu4_1 <- conv4_1
I0625 20:07:09.709000 18573 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0625 20:07:09.709137 18573 net.cpp:141] Setting up relu4_1
I0625 20:07:09.709146 18573 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:07:09.709148 18573 net.cpp:156] Memory required for data: 790757760
I0625 20:07:09.709151 18573 layer_factory.hpp:77] Creating layer conv4_2
I0625 20:07:09.709159 18573 net.cpp:91] Creating Layer conv4_2
I0625 20:07:09.709162 18573 net.cpp:425] conv4_2 <- conv4_1
I0625 20:07:09.709167 18573 net.cpp:399] conv4_2 -> conv4_2
I0625 20:07:09.714732 18573 net.cpp:141] Setting up conv4_2
I0625 20:07:09.714747 18573 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:07:09.714751 18573 net.cpp:156] Memory required for data: 797573504
I0625 20:07:09.714756 18573 layer_factory.hpp:77] Creating layer bn4_2
I0625 20:07:09.714763 18573 net.cpp:91] Creating Layer bn4_2
I0625 20:07:09.714767 18573 net.cpp:425] bn4_2 <- conv4_2
I0625 20:07:09.714772 18573 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0625 20:07:09.714920 18573 net.cpp:141] Setting up bn4_2
I0625 20:07:09.714926 18573 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:07:09.714928 18573 net.cpp:156] Memory required for data: 804389248
I0625 20:07:09.714934 18573 layer_factory.hpp:77] Creating layer scale4_2
I0625 20:07:09.714941 18573 net.cpp:91] Creating Layer scale4_2
I0625 20:07:09.714942 18573 net.cpp:425] scale4_2 <- conv4_2
I0625 20:07:09.714951 18573 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0625 20:07:09.714984 18573 layer_factory.hpp:77] Creating layer scale4_2
I0625 20:07:09.715064 18573 net.cpp:141] Setting up scale4_2
I0625 20:07:09.715082 18573 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:07:09.715085 18573 net.cpp:156] Memory required for data: 811204992
I0625 20:07:09.715090 18573 layer_factory.hpp:77] Creating layer relu4_2
I0625 20:07:09.715095 18573 net.cpp:91] Creating Layer relu4_2
I0625 20:07:09.715096 18573 net.cpp:425] relu4_2 <- conv4_2
I0625 20:07:09.715101 18573 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0625 20:07:09.715245 18573 net.cpp:141] Setting up relu4_2
I0625 20:07:09.715253 18573 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 20:07:09.715256 18573 net.cpp:156] Memory required for data: 818020736
I0625 20:07:09.715258 18573 layer_factory.hpp:77] Creating layer pool4
I0625 20:07:09.715265 18573 net.cpp:91] Creating Layer pool4
I0625 20:07:09.715267 18573 net.cpp:425] pool4 <- conv4_2
I0625 20:07:09.715271 18573 net.cpp:399] pool4 -> pool4
I0625 20:07:09.715306 18573 net.cpp:141] Setting up pool4
I0625 20:07:09.715312 18573 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:07:09.715313 18573 net.cpp:156] Memory required for data: 819855744
I0625 20:07:09.715315 18573 layer_factory.hpp:77] Creating layer conv5_1
I0625 20:07:09.715323 18573 net.cpp:91] Creating Layer conv5_1
I0625 20:07:09.715327 18573 net.cpp:425] conv5_1 <- pool4
I0625 20:07:09.715330 18573 net.cpp:399] conv5_1 -> conv5_1
I0625 20:07:09.720898 18573 net.cpp:141] Setting up conv5_1
I0625 20:07:09.720914 18573 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:07:09.720917 18573 net.cpp:156] Memory required for data: 821690752
I0625 20:07:09.720921 18573 layer_factory.hpp:77] Creating layer bn5_1
I0625 20:07:09.720929 18573 net.cpp:91] Creating Layer bn5_1
I0625 20:07:09.720933 18573 net.cpp:425] bn5_1 <- conv5_1
I0625 20:07:09.720938 18573 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0625 20:07:09.721091 18573 net.cpp:141] Setting up bn5_1
I0625 20:07:09.721098 18573 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:07:09.721101 18573 net.cpp:156] Memory required for data: 823525760
I0625 20:07:09.721107 18573 layer_factory.hpp:77] Creating layer scale5_1
I0625 20:07:09.721112 18573 net.cpp:91] Creating Layer scale5_1
I0625 20:07:09.721115 18573 net.cpp:425] scale5_1 <- conv5_1
I0625 20:07:09.721119 18573 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0625 20:07:09.721154 18573 layer_factory.hpp:77] Creating layer scale5_1
I0625 20:07:09.721235 18573 net.cpp:141] Setting up scale5_1
I0625 20:07:09.721240 18573 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:07:09.721242 18573 net.cpp:156] Memory required for data: 825360768
I0625 20:07:09.721247 18573 layer_factory.hpp:77] Creating layer relu5_1
I0625 20:07:09.721252 18573 net.cpp:91] Creating Layer relu5_1
I0625 20:07:09.721254 18573 net.cpp:425] relu5_1 <- conv5_1
I0625 20:07:09.721258 18573 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0625 20:07:09.721673 18573 net.cpp:141] Setting up relu5_1
I0625 20:07:09.721685 18573 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:07:09.721688 18573 net.cpp:156] Memory required for data: 827195776
I0625 20:07:09.721690 18573 layer_factory.hpp:77] Creating layer conv5_2
I0625 20:07:09.721700 18573 net.cpp:91] Creating Layer conv5_2
I0625 20:07:09.721704 18573 net.cpp:425] conv5_2 <- conv5_1
I0625 20:07:09.721709 18573 net.cpp:399] conv5_2 -> conv5_2
I0625 20:07:09.727171 18573 net.cpp:141] Setting up conv5_2
I0625 20:07:09.727187 18573 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:07:09.727190 18573 net.cpp:156] Memory required for data: 829030784
I0625 20:07:09.727195 18573 layer_factory.hpp:77] Creating layer bn5_2
I0625 20:07:09.727205 18573 net.cpp:91] Creating Layer bn5_2
I0625 20:07:09.727208 18573 net.cpp:425] bn5_2 <- conv5_2
I0625 20:07:09.727212 18573 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0625 20:07:09.727370 18573 net.cpp:141] Setting up bn5_2
I0625 20:07:09.727376 18573 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:07:09.727378 18573 net.cpp:156] Memory required for data: 830865792
I0625 20:07:09.727385 18573 layer_factory.hpp:77] Creating layer scale5_2
I0625 20:07:09.727391 18573 net.cpp:91] Creating Layer scale5_2
I0625 20:07:09.727407 18573 net.cpp:425] scale5_2 <- conv5_2
I0625 20:07:09.727411 18573 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0625 20:07:09.727449 18573 layer_factory.hpp:77] Creating layer scale5_2
I0625 20:07:09.727531 18573 net.cpp:141] Setting up scale5_2
I0625 20:07:09.727537 18573 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:07:09.727540 18573 net.cpp:156] Memory required for data: 832700800
I0625 20:07:09.727545 18573 layer_factory.hpp:77] Creating layer relu5_2
I0625 20:07:09.727548 18573 net.cpp:91] Creating Layer relu5_2
I0625 20:07:09.727551 18573 net.cpp:425] relu5_2 <- conv5_2
I0625 20:07:09.727555 18573 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0625 20:07:09.730386 18573 net.cpp:141] Setting up relu5_2
I0625 20:07:09.730398 18573 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 20:07:09.730401 18573 net.cpp:156] Memory required for data: 834535808
I0625 20:07:09.730404 18573 layer_factory.hpp:77] Creating layer pool5
I0625 20:07:09.730412 18573 net.cpp:91] Creating Layer pool5
I0625 20:07:09.730414 18573 net.cpp:425] pool5 <- conv5_2
I0625 20:07:09.730418 18573 net.cpp:399] pool5 -> pool5
I0625 20:07:09.730583 18573 net.cpp:141] Setting up pool5
I0625 20:07:09.730593 18573 net.cpp:148] Top shape: 32 256 2 1 (16384)
I0625 20:07:09.730595 18573 net.cpp:156] Memory required for data: 834601344
I0625 20:07:09.730598 18573 layer_factory.hpp:77] Creating layer fc2
I0625 20:07:09.730603 18573 net.cpp:91] Creating Layer fc2
I0625 20:07:09.730607 18573 net.cpp:425] fc2 <- pool5
I0625 20:07:09.730612 18573 net.cpp:399] fc2 -> fc2
I0625 20:07:09.730711 18573 net.cpp:141] Setting up fc2
I0625 20:07:09.730718 18573 net.cpp:148] Top shape: 32 2 (64)
I0625 20:07:09.730720 18573 net.cpp:156] Memory required for data: 834601600
I0625 20:07:09.730726 18573 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0625 20:07:09.730731 18573 net.cpp:91] Creating Layer fc2_fc2_0_split
I0625 20:07:09.730734 18573 net.cpp:425] fc2_fc2_0_split <- fc2
I0625 20:07:09.730738 18573 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0625 20:07:09.730743 18573 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0625 20:07:09.730772 18573 net.cpp:141] Setting up fc2_fc2_0_split
I0625 20:07:09.730775 18573 net.cpp:148] Top shape: 32 2 (64)
I0625 20:07:09.730778 18573 net.cpp:148] Top shape: 32 2 (64)
I0625 20:07:09.730780 18573 net.cpp:156] Memory required for data: 834602112
I0625 20:07:09.730782 18573 layer_factory.hpp:77] Creating layer loss
I0625 20:07:09.730787 18573 net.cpp:91] Creating Layer loss
I0625 20:07:09.730789 18573 net.cpp:425] loss <- fc2_fc2_0_split_0
I0625 20:07:09.730792 18573 net.cpp:425] loss <- label_data_1_split_0
I0625 20:07:09.730797 18573 net.cpp:399] loss -> loss
I0625 20:07:09.730803 18573 layer_factory.hpp:77] Creating layer loss
I0625 20:07:09.731014 18573 net.cpp:141] Setting up loss
I0625 20:07:09.731021 18573 net.cpp:148] Top shape: (1)
I0625 20:07:09.731024 18573 net.cpp:151]     with loss weight 1
I0625 20:07:09.731040 18573 net.cpp:156] Memory required for data: 834602116
I0625 20:07:09.731042 18573 layer_factory.hpp:77] Creating layer accuracy
I0625 20:07:09.731047 18573 net.cpp:91] Creating Layer accuracy
I0625 20:07:09.731050 18573 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0625 20:07:09.731053 18573 net.cpp:425] accuracy <- label_data_1_split_1
I0625 20:07:09.731057 18573 net.cpp:399] accuracy -> accuracy
I0625 20:07:09.731065 18573 net.cpp:141] Setting up accuracy
I0625 20:07:09.731067 18573 net.cpp:148] Top shape: (1)
I0625 20:07:09.731070 18573 net.cpp:156] Memory required for data: 834602120
I0625 20:07:09.731072 18573 net.cpp:219] accuracy does not need backward computation.
I0625 20:07:09.731076 18573 net.cpp:217] loss needs backward computation.
I0625 20:07:09.731077 18573 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0625 20:07:09.731079 18573 net.cpp:217] fc2 needs backward computation.
I0625 20:07:09.731082 18573 net.cpp:217] pool5 needs backward computation.
I0625 20:07:09.731084 18573 net.cpp:217] relu5_2 needs backward computation.
I0625 20:07:09.731086 18573 net.cpp:217] scale5_2 needs backward computation.
I0625 20:07:09.731098 18573 net.cpp:217] bn5_2 needs backward computation.
I0625 20:07:09.731101 18573 net.cpp:217] conv5_2 needs backward computation.
I0625 20:07:09.731103 18573 net.cpp:217] relu5_1 needs backward computation.
I0625 20:07:09.731106 18573 net.cpp:217] scale5_1 needs backward computation.
I0625 20:07:09.731107 18573 net.cpp:217] bn5_1 needs backward computation.
I0625 20:07:09.731111 18573 net.cpp:217] conv5_1 needs backward computation.
I0625 20:07:09.731112 18573 net.cpp:217] pool4 needs backward computation.
I0625 20:07:09.731115 18573 net.cpp:217] relu4_2 needs backward computation.
I0625 20:07:09.731117 18573 net.cpp:217] scale4_2 needs backward computation.
I0625 20:07:09.731120 18573 net.cpp:217] bn4_2 needs backward computation.
I0625 20:07:09.731122 18573 net.cpp:217] conv4_2 needs backward computation.
I0625 20:07:09.731125 18573 net.cpp:217] relu4_1 needs backward computation.
I0625 20:07:09.731127 18573 net.cpp:217] scale4_1 needs backward computation.
I0625 20:07:09.731129 18573 net.cpp:217] bn4_1 needs backward computation.
I0625 20:07:09.731132 18573 net.cpp:217] conv4_1 needs backward computation.
I0625 20:07:09.731134 18573 net.cpp:217] pool3 needs backward computation.
I0625 20:07:09.731137 18573 net.cpp:217] relu3_2 needs backward computation.
I0625 20:07:09.731139 18573 net.cpp:217] scale3_2 needs backward computation.
I0625 20:07:09.731142 18573 net.cpp:217] bn3_2 needs backward computation.
I0625 20:07:09.731143 18573 net.cpp:217] conv3_2 needs backward computation.
I0625 20:07:09.731145 18573 net.cpp:217] relu3_1 needs backward computation.
I0625 20:07:09.731153 18573 net.cpp:217] scale3_1 needs backward computation.
I0625 20:07:09.731156 18573 net.cpp:217] bn3_1 needs backward computation.
I0625 20:07:09.731158 18573 net.cpp:217] conv3_1 needs backward computation.
I0625 20:07:09.731161 18573 net.cpp:217] pool2 needs backward computation.
I0625 20:07:09.731164 18573 net.cpp:217] relu2_2 needs backward computation.
I0625 20:07:09.731166 18573 net.cpp:217] scale2_2 needs backward computation.
I0625 20:07:09.731168 18573 net.cpp:217] bn2_2 needs backward computation.
I0625 20:07:09.731170 18573 net.cpp:217] conv2_2 needs backward computation.
I0625 20:07:09.731173 18573 net.cpp:217] relu2_1 needs backward computation.
I0625 20:07:09.731175 18573 net.cpp:217] scale2_1 needs backward computation.
I0625 20:07:09.731178 18573 net.cpp:217] bn2_1 needs backward computation.
I0625 20:07:09.731179 18573 net.cpp:217] conv2_1 needs backward computation.
I0625 20:07:09.731183 18573 net.cpp:217] pool1 needs backward computation.
I0625 20:07:09.731184 18573 net.cpp:217] relu1_2 needs backward computation.
I0625 20:07:09.731186 18573 net.cpp:217] scale1_2 needs backward computation.
I0625 20:07:09.731189 18573 net.cpp:217] bn1_2 needs backward computation.
I0625 20:07:09.731190 18573 net.cpp:217] conv1_2 needs backward computation.
I0625 20:07:09.731192 18573 net.cpp:217] relu1_1 needs backward computation.
I0625 20:07:09.731194 18573 net.cpp:217] scale1_1 needs backward computation.
I0625 20:07:09.731196 18573 net.cpp:217] bn1_1 needs backward computation.
I0625 20:07:09.731199 18573 net.cpp:217] conv1_1 needs backward computation.
I0625 20:07:09.731201 18573 net.cpp:219] label_data_1_split does not need backward computation.
I0625 20:07:09.731204 18573 net.cpp:219] data does not need backward computation.
I0625 20:07:09.731206 18573 net.cpp:261] This network produces output accuracy
I0625 20:07:09.731209 18573 net.cpp:261] This network produces output loss
I0625 20:07:09.731230 18573 net.cpp:274] Network initialization done.
I0625 20:07:09.732067 18573 solver.cpp:181] Creating test net (#0) specified by net file: models/bpnet/train_val.prototxt
I0625 20:07:09.732120 18573 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0625 20:07:09.732333 18573 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 100
    crop_h: 196
    crop_w: 256
  }
  data_param {
    source: "data/val_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  pooling_param {
    pool: AVE
    stride: 1
    kernel_h: 6
    kernel_w: 8
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0625 20:07:09.732478 18573 layer_factory.hpp:77] Creating layer data
I0625 20:07:09.732558 18573 net.cpp:91] Creating Layer data
I0625 20:07:09.732564 18573 net.cpp:399] data -> data
I0625 20:07:09.732571 18573 net.cpp:399] data -> label
I0625 20:07:09.733847 18586 db_lmdb.cpp:35] Opened lmdb data/val_lmdb
I0625 20:07:09.734252 18573 data_layer.cpp:42] output data size: 64,3,196,256
I0625 20:07:09.813941 18573 net.cpp:141] Setting up data
I0625 20:07:09.813966 18573 net.cpp:148] Top shape: 64 3 196 256 (9633792)
I0625 20:07:09.813971 18573 net.cpp:148] Top shape: 64 (64)
I0625 20:07:09.813972 18573 net.cpp:156] Memory required for data: 38535424
I0625 20:07:09.813979 18573 layer_factory.hpp:77] Creating layer label_data_1_split
I0625 20:07:09.813992 18573 net.cpp:91] Creating Layer label_data_1_split
I0625 20:07:09.813994 18573 net.cpp:425] label_data_1_split <- label
I0625 20:07:09.813999 18573 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0625 20:07:09.814007 18573 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0625 20:07:09.814117 18573 net.cpp:141] Setting up label_data_1_split
I0625 20:07:09.814126 18573 net.cpp:148] Top shape: 64 (64)
I0625 20:07:09.814129 18573 net.cpp:148] Top shape: 64 (64)
I0625 20:07:09.814131 18573 net.cpp:156] Memory required for data: 38535936
I0625 20:07:09.814133 18573 layer_factory.hpp:77] Creating layer conv1_1
I0625 20:07:09.814146 18573 net.cpp:91] Creating Layer conv1_1
I0625 20:07:09.814149 18573 net.cpp:425] conv1_1 <- data
I0625 20:07:09.814152 18573 net.cpp:399] conv1_1 -> conv1_1
I0625 20:07:09.818157 18573 net.cpp:141] Setting up conv1_1
I0625 20:07:09.818171 18573 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:07:09.818173 18573 net.cpp:156] Memory required for data: 141296384
I0625 20:07:09.818181 18573 layer_factory.hpp:77] Creating layer bn1_1
I0625 20:07:09.818187 18573 net.cpp:91] Creating Layer bn1_1
I0625 20:07:09.818191 18573 net.cpp:425] bn1_1 <- conv1_1
I0625 20:07:09.818195 18573 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0625 20:07:09.818372 18573 net.cpp:141] Setting up bn1_1
I0625 20:07:09.818379 18573 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:07:09.818382 18573 net.cpp:156] Memory required for data: 244056832
I0625 20:07:09.818389 18573 layer_factory.hpp:77] Creating layer scale1_1
I0625 20:07:09.818398 18573 net.cpp:91] Creating Layer scale1_1
I0625 20:07:09.818402 18573 net.cpp:425] scale1_1 <- conv1_1
I0625 20:07:09.818418 18573 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0625 20:07:09.818455 18573 layer_factory.hpp:77] Creating layer scale1_1
I0625 20:07:09.818569 18573 net.cpp:141] Setting up scale1_1
I0625 20:07:09.818577 18573 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:07:09.818578 18573 net.cpp:156] Memory required for data: 346817280
I0625 20:07:09.818584 18573 layer_factory.hpp:77] Creating layer relu1_1
I0625 20:07:09.818591 18573 net.cpp:91] Creating Layer relu1_1
I0625 20:07:09.818594 18573 net.cpp:425] relu1_1 <- conv1_1
I0625 20:07:09.818598 18573 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0625 20:07:09.818735 18573 net.cpp:141] Setting up relu1_1
I0625 20:07:09.818744 18573 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:07:09.818747 18573 net.cpp:156] Memory required for data: 449577728
I0625 20:07:09.818750 18573 layer_factory.hpp:77] Creating layer conv1_2
I0625 20:07:09.818758 18573 net.cpp:91] Creating Layer conv1_2
I0625 20:07:09.818759 18573 net.cpp:425] conv1_2 <- conv1_1
I0625 20:07:09.818764 18573 net.cpp:399] conv1_2 -> conv1_2
I0625 20:07:09.819681 18573 net.cpp:141] Setting up conv1_2
I0625 20:07:09.819694 18573 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:07:09.819696 18573 net.cpp:156] Memory required for data: 552338176
I0625 20:07:09.819700 18573 layer_factory.hpp:77] Creating layer bn1_2
I0625 20:07:09.819707 18573 net.cpp:91] Creating Layer bn1_2
I0625 20:07:09.819710 18573 net.cpp:425] bn1_2 <- conv1_2
I0625 20:07:09.819715 18573 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0625 20:07:09.819924 18573 net.cpp:141] Setting up bn1_2
I0625 20:07:09.819932 18573 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:07:09.819936 18573 net.cpp:156] Memory required for data: 655098624
I0625 20:07:09.819943 18573 layer_factory.hpp:77] Creating layer scale1_2
I0625 20:07:09.819952 18573 net.cpp:91] Creating Layer scale1_2
I0625 20:07:09.819953 18573 net.cpp:425] scale1_2 <- conv1_2
I0625 20:07:09.819957 18573 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0625 20:07:09.819990 18573 layer_factory.hpp:77] Creating layer scale1_2
I0625 20:07:09.820102 18573 net.cpp:141] Setting up scale1_2
I0625 20:07:09.820109 18573 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:07:09.820111 18573 net.cpp:156] Memory required for data: 757859072
I0625 20:07:09.820116 18573 layer_factory.hpp:77] Creating layer relu1_2
I0625 20:07:09.820121 18573 net.cpp:91] Creating Layer relu1_2
I0625 20:07:09.820122 18573 net.cpp:425] relu1_2 <- conv1_2
I0625 20:07:09.820127 18573 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0625 20:07:09.820546 18573 net.cpp:141] Setting up relu1_2
I0625 20:07:09.820557 18573 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 20:07:09.820560 18573 net.cpp:156] Memory required for data: 860619520
I0625 20:07:09.820564 18573 layer_factory.hpp:77] Creating layer pool1
I0625 20:07:09.820570 18573 net.cpp:91] Creating Layer pool1
I0625 20:07:09.820572 18573 net.cpp:425] pool1 <- conv1_2
I0625 20:07:09.820577 18573 net.cpp:399] pool1 -> pool1
I0625 20:07:09.820617 18573 net.cpp:141] Setting up pool1
I0625 20:07:09.820623 18573 net.cpp:148] Top shape: 64 32 49 64 (6422528)
I0625 20:07:09.820626 18573 net.cpp:156] Memory required for data: 886309632
I0625 20:07:09.820628 18573 layer_factory.hpp:77] Creating layer conv2_1
I0625 20:07:09.820636 18573 net.cpp:91] Creating Layer conv2_1
I0625 20:07:09.820638 18573 net.cpp:425] conv2_1 <- pool1
I0625 20:07:09.820643 18573 net.cpp:399] conv2_1 -> conv2_1
I0625 20:07:09.821590 18573 net.cpp:141] Setting up conv2_1
I0625 20:07:09.821604 18573 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:07:09.821605 18573 net.cpp:156] Memory required for data: 937689856
I0625 20:07:09.821610 18573 layer_factory.hpp:77] Creating layer bn2_1
I0625 20:07:09.821615 18573 net.cpp:91] Creating Layer bn2_1
I0625 20:07:09.821619 18573 net.cpp:425] bn2_1 <- conv2_1
I0625 20:07:09.821624 18573 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0625 20:07:09.821784 18573 net.cpp:141] Setting up bn2_1
I0625 20:07:09.821802 18573 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:07:09.821805 18573 net.cpp:156] Memory required for data: 989070080
I0625 20:07:09.821810 18573 layer_factory.hpp:77] Creating layer scale2_1
I0625 20:07:09.821816 18573 net.cpp:91] Creating Layer scale2_1
I0625 20:07:09.821820 18573 net.cpp:425] scale2_1 <- conv2_1
I0625 20:07:09.821825 18573 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0625 20:07:09.821862 18573 layer_factory.hpp:77] Creating layer scale2_1
I0625 20:07:09.821960 18573 net.cpp:141] Setting up scale2_1
I0625 20:07:09.821966 18573 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:07:09.821969 18573 net.cpp:156] Memory required for data: 1040450304
I0625 20:07:09.821976 18573 layer_factory.hpp:77] Creating layer relu2_1
I0625 20:07:09.821980 18573 net.cpp:91] Creating Layer relu2_1
I0625 20:07:09.821982 18573 net.cpp:425] relu2_1 <- conv2_1
I0625 20:07:09.821987 18573 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0625 20:07:09.822124 18573 net.cpp:141] Setting up relu2_1
I0625 20:07:09.822134 18573 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:07:09.822135 18573 net.cpp:156] Memory required for data: 1091830528
I0625 20:07:09.822139 18573 layer_factory.hpp:77] Creating layer conv2_2
I0625 20:07:09.822145 18573 net.cpp:91] Creating Layer conv2_2
I0625 20:07:09.822149 18573 net.cpp:425] conv2_2 <- conv2_1
I0625 20:07:09.822154 18573 net.cpp:399] conv2_2 -> conv2_2
I0625 20:07:09.823212 18573 net.cpp:141] Setting up conv2_2
I0625 20:07:09.823225 18573 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:07:09.823227 18573 net.cpp:156] Memory required for data: 1143210752
I0625 20:07:09.823231 18573 layer_factory.hpp:77] Creating layer bn2_2
I0625 20:07:09.823240 18573 net.cpp:91] Creating Layer bn2_2
I0625 20:07:09.823242 18573 net.cpp:425] bn2_2 <- conv2_2
I0625 20:07:09.823247 18573 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0625 20:07:09.823411 18573 net.cpp:141] Setting up bn2_2
I0625 20:07:09.823418 18573 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:07:09.823421 18573 net.cpp:156] Memory required for data: 1194590976
I0625 20:07:09.823426 18573 layer_factory.hpp:77] Creating layer scale2_2
I0625 20:07:09.823433 18573 net.cpp:91] Creating Layer scale2_2
I0625 20:07:09.823436 18573 net.cpp:425] scale2_2 <- conv2_2
I0625 20:07:09.823439 18573 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0625 20:07:09.823470 18573 layer_factory.hpp:77] Creating layer scale2_2
I0625 20:07:09.823565 18573 net.cpp:141] Setting up scale2_2
I0625 20:07:09.823571 18573 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:07:09.823575 18573 net.cpp:156] Memory required for data: 1245971200
I0625 20:07:09.823578 18573 layer_factory.hpp:77] Creating layer relu2_2
I0625 20:07:09.823582 18573 net.cpp:91] Creating Layer relu2_2
I0625 20:07:09.823585 18573 net.cpp:425] relu2_2 <- conv2_2
I0625 20:07:09.823590 18573 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0625 20:07:09.823739 18573 net.cpp:141] Setting up relu2_2
I0625 20:07:09.823747 18573 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 20:07:09.823750 18573 net.cpp:156] Memory required for data: 1297351424
I0625 20:07:09.823752 18573 layer_factory.hpp:77] Creating layer pool2
I0625 20:07:09.823757 18573 net.cpp:91] Creating Layer pool2
I0625 20:07:09.823760 18573 net.cpp:425] pool2 <- conv2_2
I0625 20:07:09.823763 18573 net.cpp:399] pool2 -> pool2
I0625 20:07:09.823801 18573 net.cpp:141] Setting up pool2
I0625 20:07:09.823807 18573 net.cpp:148] Top shape: 64 64 25 32 (3276800)
I0625 20:07:09.823808 18573 net.cpp:156] Memory required for data: 1310458624
I0625 20:07:09.823812 18573 layer_factory.hpp:77] Creating layer conv3_1
I0625 20:07:09.823817 18573 net.cpp:91] Creating Layer conv3_1
I0625 20:07:09.823820 18573 net.cpp:425] conv3_1 <- pool2
I0625 20:07:09.823824 18573 net.cpp:399] conv3_1 -> conv3_1
I0625 20:07:09.826369 18573 net.cpp:141] Setting up conv3_1
I0625 20:07:09.826381 18573 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:07:09.826385 18573 net.cpp:156] Memory required for data: 1336673024
I0625 20:07:09.826400 18573 layer_factory.hpp:77] Creating layer bn3_1
I0625 20:07:09.826406 18573 net.cpp:91] Creating Layer bn3_1
I0625 20:07:09.826408 18573 net.cpp:425] bn3_1 <- conv3_1
I0625 20:07:09.826413 18573 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0625 20:07:09.826570 18573 net.cpp:141] Setting up bn3_1
I0625 20:07:09.826577 18573 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:07:09.826580 18573 net.cpp:156] Memory required for data: 1362887424
I0625 20:07:09.826586 18573 layer_factory.hpp:77] Creating layer scale3_1
I0625 20:07:09.826591 18573 net.cpp:91] Creating Layer scale3_1
I0625 20:07:09.826593 18573 net.cpp:425] scale3_1 <- conv3_1
I0625 20:07:09.826596 18573 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0625 20:07:09.826629 18573 layer_factory.hpp:77] Creating layer scale3_1
I0625 20:07:09.826719 18573 net.cpp:141] Setting up scale3_1
I0625 20:07:09.826725 18573 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:07:09.826726 18573 net.cpp:156] Memory required for data: 1389101824
I0625 20:07:09.826730 18573 layer_factory.hpp:77] Creating layer relu3_1
I0625 20:07:09.826741 18573 net.cpp:91] Creating Layer relu3_1
I0625 20:07:09.826743 18573 net.cpp:425] relu3_1 <- conv3_1
I0625 20:07:09.826747 18573 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0625 20:07:09.826890 18573 net.cpp:141] Setting up relu3_1
I0625 20:07:09.826899 18573 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:07:09.826901 18573 net.cpp:156] Memory required for data: 1415316224
I0625 20:07:09.826903 18573 layer_factory.hpp:77] Creating layer conv3_2
I0625 20:07:09.826911 18573 net.cpp:91] Creating Layer conv3_2
I0625 20:07:09.826915 18573 net.cpp:425] conv3_2 <- conv3_1
I0625 20:07:09.826920 18573 net.cpp:399] conv3_2 -> conv3_2
I0625 20:07:09.828835 18573 net.cpp:141] Setting up conv3_2
I0625 20:07:09.828847 18573 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:07:09.828850 18573 net.cpp:156] Memory required for data: 1441530624
I0625 20:07:09.828855 18573 layer_factory.hpp:77] Creating layer bn3_2
I0625 20:07:09.828860 18573 net.cpp:91] Creating Layer bn3_2
I0625 20:07:09.828863 18573 net.cpp:425] bn3_2 <- conv3_2
I0625 20:07:09.828867 18573 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0625 20:07:09.829028 18573 net.cpp:141] Setting up bn3_2
I0625 20:07:09.829035 18573 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:07:09.829037 18573 net.cpp:156] Memory required for data: 1467745024
I0625 20:07:09.829048 18573 layer_factory.hpp:77] Creating layer scale3_2
I0625 20:07:09.829056 18573 net.cpp:91] Creating Layer scale3_2
I0625 20:07:09.829057 18573 net.cpp:425] scale3_2 <- conv3_2
I0625 20:07:09.829061 18573 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0625 20:07:09.829093 18573 layer_factory.hpp:77] Creating layer scale3_2
I0625 20:07:09.829181 18573 net.cpp:141] Setting up scale3_2
I0625 20:07:09.829188 18573 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:07:09.829190 18573 net.cpp:156] Memory required for data: 1493959424
I0625 20:07:09.829195 18573 layer_factory.hpp:77] Creating layer relu3_2
I0625 20:07:09.829200 18573 net.cpp:91] Creating Layer relu3_2
I0625 20:07:09.829202 18573 net.cpp:425] relu3_2 <- conv3_2
I0625 20:07:09.829206 18573 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0625 20:07:09.829347 18573 net.cpp:141] Setting up relu3_2
I0625 20:07:09.829355 18573 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 20:07:09.829358 18573 net.cpp:156] Memory required for data: 1520173824
I0625 20:07:09.829361 18573 layer_factory.hpp:77] Creating layer pool3
I0625 20:07:09.829365 18573 net.cpp:91] Creating Layer pool3
I0625 20:07:09.829368 18573 net.cpp:425] pool3 <- conv3_2
I0625 20:07:09.829372 18573 net.cpp:399] pool3 -> pool3
I0625 20:07:09.829411 18573 net.cpp:141] Setting up pool3
I0625 20:07:09.829414 18573 net.cpp:148] Top shape: 64 128 13 16 (1703936)
I0625 20:07:09.829417 18573 net.cpp:156] Memory required for data: 1526989568
I0625 20:07:09.829419 18573 layer_factory.hpp:77] Creating layer conv4_1
I0625 20:07:09.829427 18573 net.cpp:91] Creating Layer conv4_1
I0625 20:07:09.829439 18573 net.cpp:425] conv4_1 <- pool3
I0625 20:07:09.829445 18573 net.cpp:399] conv4_1 -> conv4_1
I0625 20:07:09.832190 18573 net.cpp:141] Setting up conv4_1
I0625 20:07:09.832202 18573 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:07:09.832206 18573 net.cpp:156] Memory required for data: 1540621056
I0625 20:07:09.832209 18573 layer_factory.hpp:77] Creating layer bn4_1
I0625 20:07:09.832216 18573 net.cpp:91] Creating Layer bn4_1
I0625 20:07:09.832219 18573 net.cpp:425] bn4_1 <- conv4_1
I0625 20:07:09.832223 18573 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0625 20:07:09.832389 18573 net.cpp:141] Setting up bn4_1
I0625 20:07:09.832396 18573 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:07:09.832399 18573 net.cpp:156] Memory required for data: 1554252544
I0625 20:07:09.832404 18573 layer_factory.hpp:77] Creating layer scale4_1
I0625 20:07:09.832409 18573 net.cpp:91] Creating Layer scale4_1
I0625 20:07:09.832412 18573 net.cpp:425] scale4_1 <- conv4_1
I0625 20:07:09.832417 18573 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0625 20:07:09.832449 18573 layer_factory.hpp:77] Creating layer scale4_1
I0625 20:07:09.832536 18573 net.cpp:141] Setting up scale4_1
I0625 20:07:09.832542 18573 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:07:09.832545 18573 net.cpp:156] Memory required for data: 1567884032
I0625 20:07:09.832548 18573 layer_factory.hpp:77] Creating layer relu4_1
I0625 20:07:09.832557 18573 net.cpp:91] Creating Layer relu4_1
I0625 20:07:09.832559 18573 net.cpp:425] relu4_1 <- conv4_1
I0625 20:07:09.832563 18573 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0625 20:07:09.832703 18573 net.cpp:141] Setting up relu4_1
I0625 20:07:09.832712 18573 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:07:09.832715 18573 net.cpp:156] Memory required for data: 1581515520
I0625 20:07:09.832717 18573 layer_factory.hpp:77] Creating layer conv4_2
I0625 20:07:09.832726 18573 net.cpp:91] Creating Layer conv4_2
I0625 20:07:09.832728 18573 net.cpp:425] conv4_2 <- conv4_1
I0625 20:07:09.832732 18573 net.cpp:399] conv4_2 -> conv4_2
I0625 20:07:09.838297 18573 net.cpp:141] Setting up conv4_2
I0625 20:07:09.838313 18573 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:07:09.838316 18573 net.cpp:156] Memory required for data: 1595147008
I0625 20:07:09.838320 18573 layer_factory.hpp:77] Creating layer bn4_2
I0625 20:07:09.838328 18573 net.cpp:91] Creating Layer bn4_2
I0625 20:07:09.838332 18573 net.cpp:425] bn4_2 <- conv4_2
I0625 20:07:09.838336 18573 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0625 20:07:09.838502 18573 net.cpp:141] Setting up bn4_2
I0625 20:07:09.838510 18573 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:07:09.838512 18573 net.cpp:156] Memory required for data: 1608778496
I0625 20:07:09.838518 18573 layer_factory.hpp:77] Creating layer scale4_2
I0625 20:07:09.838524 18573 net.cpp:91] Creating Layer scale4_2
I0625 20:07:09.838526 18573 net.cpp:425] scale4_2 <- conv4_2
I0625 20:07:09.838529 18573 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0625 20:07:09.838562 18573 layer_factory.hpp:77] Creating layer scale4_2
I0625 20:07:09.838652 18573 net.cpp:141] Setting up scale4_2
I0625 20:07:09.838660 18573 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:07:09.838662 18573 net.cpp:156] Memory required for data: 1622409984
I0625 20:07:09.838666 18573 layer_factory.hpp:77] Creating layer relu4_2
I0625 20:07:09.838670 18573 net.cpp:91] Creating Layer relu4_2
I0625 20:07:09.838673 18573 net.cpp:425] relu4_2 <- conv4_2
I0625 20:07:09.838677 18573 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0625 20:07:09.839123 18573 net.cpp:141] Setting up relu4_2
I0625 20:07:09.839134 18573 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 20:07:09.839138 18573 net.cpp:156] Memory required for data: 1636041472
I0625 20:07:09.839140 18573 layer_factory.hpp:77] Creating layer pool4
I0625 20:07:09.839159 18573 net.cpp:91] Creating Layer pool4
I0625 20:07:09.839162 18573 net.cpp:425] pool4 <- conv4_2
I0625 20:07:09.839167 18573 net.cpp:399] pool4 -> pool4
I0625 20:07:09.839210 18573 net.cpp:141] Setting up pool4
I0625 20:07:09.839228 18573 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:07:09.839231 18573 net.cpp:156] Memory required for data: 1639711488
I0625 20:07:09.839232 18573 layer_factory.hpp:77] Creating layer conv5_1
I0625 20:07:09.839241 18573 net.cpp:91] Creating Layer conv5_1
I0625 20:07:09.839244 18573 net.cpp:425] conv5_1 <- pool4
I0625 20:07:09.839248 18573 net.cpp:399] conv5_1 -> conv5_1
I0625 20:07:09.844817 18573 net.cpp:141] Setting up conv5_1
I0625 20:07:09.844835 18573 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:07:09.844837 18573 net.cpp:156] Memory required for data: 1643381504
I0625 20:07:09.844842 18573 layer_factory.hpp:77] Creating layer bn5_1
I0625 20:07:09.844851 18573 net.cpp:91] Creating Layer bn5_1
I0625 20:07:09.844854 18573 net.cpp:425] bn5_1 <- conv5_1
I0625 20:07:09.844858 18573 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0625 20:07:09.845031 18573 net.cpp:141] Setting up bn5_1
I0625 20:07:09.845038 18573 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:07:09.845041 18573 net.cpp:156] Memory required for data: 1647051520
I0625 20:07:09.845046 18573 layer_factory.hpp:77] Creating layer scale5_1
I0625 20:07:09.845052 18573 net.cpp:91] Creating Layer scale5_1
I0625 20:07:09.845054 18573 net.cpp:425] scale5_1 <- conv5_1
I0625 20:07:09.845059 18573 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0625 20:07:09.845093 18573 layer_factory.hpp:77] Creating layer scale5_1
I0625 20:07:09.845183 18573 net.cpp:141] Setting up scale5_1
I0625 20:07:09.845196 18573 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:07:09.845198 18573 net.cpp:156] Memory required for data: 1650721536
I0625 20:07:09.845202 18573 layer_factory.hpp:77] Creating layer relu5_1
I0625 20:07:09.845207 18573 net.cpp:91] Creating Layer relu5_1
I0625 20:07:09.845209 18573 net.cpp:425] relu5_1 <- conv5_1
I0625 20:07:09.845213 18573 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0625 20:07:09.845360 18573 net.cpp:141] Setting up relu5_1
I0625 20:07:09.845368 18573 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:07:09.845371 18573 net.cpp:156] Memory required for data: 1654391552
I0625 20:07:09.845374 18573 layer_factory.hpp:77] Creating layer conv5_2
I0625 20:07:09.845382 18573 net.cpp:91] Creating Layer conv5_2
I0625 20:07:09.845384 18573 net.cpp:425] conv5_2 <- conv5_1
I0625 20:07:09.845389 18573 net.cpp:399] conv5_2 -> conv5_2
I0625 20:07:09.851173 18573 net.cpp:141] Setting up conv5_2
I0625 20:07:09.851191 18573 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:07:09.851194 18573 net.cpp:156] Memory required for data: 1658061568
I0625 20:07:09.851200 18573 layer_factory.hpp:77] Creating layer bn5_2
I0625 20:07:09.851210 18573 net.cpp:91] Creating Layer bn5_2
I0625 20:07:09.851213 18573 net.cpp:425] bn5_2 <- conv5_2
I0625 20:07:09.851223 18573 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0625 20:07:09.851393 18573 net.cpp:141] Setting up bn5_2
I0625 20:07:09.851402 18573 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:07:09.851403 18573 net.cpp:156] Memory required for data: 1661731584
I0625 20:07:09.851409 18573 layer_factory.hpp:77] Creating layer scale5_2
I0625 20:07:09.851415 18573 net.cpp:91] Creating Layer scale5_2
I0625 20:07:09.851418 18573 net.cpp:425] scale5_2 <- conv5_2
I0625 20:07:09.851423 18573 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0625 20:07:09.851456 18573 layer_factory.hpp:77] Creating layer scale5_2
I0625 20:07:09.851550 18573 net.cpp:141] Setting up scale5_2
I0625 20:07:09.851557 18573 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:07:09.851559 18573 net.cpp:156] Memory required for data: 1665401600
I0625 20:07:09.851563 18573 layer_factory.hpp:77] Creating layer relu5_2
I0625 20:07:09.851568 18573 net.cpp:91] Creating Layer relu5_2
I0625 20:07:09.851572 18573 net.cpp:425] relu5_2 <- conv5_2
I0625 20:07:09.851574 18573 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0625 20:07:09.851727 18573 net.cpp:141] Setting up relu5_2
I0625 20:07:09.851734 18573 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 20:07:09.851737 18573 net.cpp:156] Memory required for data: 1669071616
I0625 20:07:09.851752 18573 layer_factory.hpp:77] Creating layer pool5
I0625 20:07:09.851758 18573 net.cpp:91] Creating Layer pool5
I0625 20:07:09.851761 18573 net.cpp:425] pool5 <- conv5_2
I0625 20:07:09.851768 18573 net.cpp:399] pool5 -> pool5
I0625 20:07:09.851927 18573 net.cpp:141] Setting up pool5
I0625 20:07:09.851936 18573 net.cpp:148] Top shape: 64 256 2 1 (32768)
I0625 20:07:09.851938 18573 net.cpp:156] Memory required for data: 1669202688
I0625 20:07:09.851941 18573 layer_factory.hpp:77] Creating layer fc2
I0625 20:07:09.851948 18573 net.cpp:91] Creating Layer fc2
I0625 20:07:09.851950 18573 net.cpp:425] fc2 <- pool5
I0625 20:07:09.851953 18573 net.cpp:399] fc2 -> fc2
I0625 20:07:09.852061 18573 net.cpp:141] Setting up fc2
I0625 20:07:09.852068 18573 net.cpp:148] Top shape: 64 2 (128)
I0625 20:07:09.852072 18573 net.cpp:156] Memory required for data: 1669203200
I0625 20:07:09.852075 18573 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0625 20:07:09.852082 18573 net.cpp:91] Creating Layer fc2_fc2_0_split
I0625 20:07:09.852084 18573 net.cpp:425] fc2_fc2_0_split <- fc2
I0625 20:07:09.852088 18573 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0625 20:07:09.852092 18573 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0625 20:07:09.852124 18573 net.cpp:141] Setting up fc2_fc2_0_split
I0625 20:07:09.852128 18573 net.cpp:148] Top shape: 64 2 (128)
I0625 20:07:09.852131 18573 net.cpp:148] Top shape: 64 2 (128)
I0625 20:07:09.852133 18573 net.cpp:156] Memory required for data: 1669204224
I0625 20:07:09.852135 18573 layer_factory.hpp:77] Creating layer loss
I0625 20:07:09.852139 18573 net.cpp:91] Creating Layer loss
I0625 20:07:09.852144 18573 net.cpp:425] loss <- fc2_fc2_0_split_0
I0625 20:07:09.852146 18573 net.cpp:425] loss <- label_data_1_split_0
I0625 20:07:09.852149 18573 net.cpp:399] loss -> loss
I0625 20:07:09.852155 18573 layer_factory.hpp:77] Creating layer loss
I0625 20:07:09.852658 18573 net.cpp:141] Setting up loss
I0625 20:07:09.852669 18573 net.cpp:148] Top shape: (1)
I0625 20:07:09.852672 18573 net.cpp:151]     with loss weight 1
I0625 20:07:09.852682 18573 net.cpp:156] Memory required for data: 1669204228
I0625 20:07:09.852685 18573 layer_factory.hpp:77] Creating layer accuracy
I0625 20:07:09.852691 18573 net.cpp:91] Creating Layer accuracy
I0625 20:07:09.852694 18573 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0625 20:07:09.852697 18573 net.cpp:425] accuracy <- label_data_1_split_1
I0625 20:07:09.852701 18573 net.cpp:399] accuracy -> accuracy
I0625 20:07:09.852707 18573 net.cpp:141] Setting up accuracy
I0625 20:07:09.852711 18573 net.cpp:148] Top shape: (1)
I0625 20:07:09.852713 18573 net.cpp:156] Memory required for data: 1669204232
I0625 20:07:09.852715 18573 net.cpp:219] accuracy does not need backward computation.
I0625 20:07:09.852718 18573 net.cpp:217] loss needs backward computation.
I0625 20:07:09.852720 18573 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0625 20:07:09.852722 18573 net.cpp:217] fc2 needs backward computation.
I0625 20:07:09.852725 18573 net.cpp:217] pool5 needs backward computation.
I0625 20:07:09.852727 18573 net.cpp:217] relu5_2 needs backward computation.
I0625 20:07:09.852730 18573 net.cpp:217] scale5_2 needs backward computation.
I0625 20:07:09.852731 18573 net.cpp:217] bn5_2 needs backward computation.
I0625 20:07:09.852733 18573 net.cpp:217] conv5_2 needs backward computation.
I0625 20:07:09.852735 18573 net.cpp:217] relu5_1 needs backward computation.
I0625 20:07:09.852738 18573 net.cpp:217] scale5_1 needs backward computation.
I0625 20:07:09.852741 18573 net.cpp:217] bn5_1 needs backward computation.
I0625 20:07:09.852742 18573 net.cpp:217] conv5_1 needs backward computation.
I0625 20:07:09.852746 18573 net.cpp:217] pool4 needs backward computation.
I0625 20:07:09.852747 18573 net.cpp:217] relu4_2 needs backward computation.
I0625 20:07:09.852749 18573 net.cpp:217] scale4_2 needs backward computation.
I0625 20:07:09.852752 18573 net.cpp:217] bn4_2 needs backward computation.
I0625 20:07:09.852754 18573 net.cpp:217] conv4_2 needs backward computation.
I0625 20:07:09.852767 18573 net.cpp:217] relu4_1 needs backward computation.
I0625 20:07:09.852769 18573 net.cpp:217] scale4_1 needs backward computation.
I0625 20:07:09.852771 18573 net.cpp:217] bn4_1 needs backward computation.
I0625 20:07:09.852774 18573 net.cpp:217] conv4_1 needs backward computation.
I0625 20:07:09.852777 18573 net.cpp:217] pool3 needs backward computation.
I0625 20:07:09.852778 18573 net.cpp:217] relu3_2 needs backward computation.
I0625 20:07:09.852782 18573 net.cpp:217] scale3_2 needs backward computation.
I0625 20:07:09.852783 18573 net.cpp:217] bn3_2 needs backward computation.
I0625 20:07:09.852785 18573 net.cpp:217] conv3_2 needs backward computation.
I0625 20:07:09.852788 18573 net.cpp:217] relu3_1 needs backward computation.
I0625 20:07:09.852790 18573 net.cpp:217] scale3_1 needs backward computation.
I0625 20:07:09.852792 18573 net.cpp:217] bn3_1 needs backward computation.
I0625 20:07:09.852794 18573 net.cpp:217] conv3_1 needs backward computation.
I0625 20:07:09.852797 18573 net.cpp:217] pool2 needs backward computation.
I0625 20:07:09.852799 18573 net.cpp:217] relu2_2 needs backward computation.
I0625 20:07:09.852802 18573 net.cpp:217] scale2_2 needs backward computation.
I0625 20:07:09.852804 18573 net.cpp:217] bn2_2 needs backward computation.
I0625 20:07:09.852807 18573 net.cpp:217] conv2_2 needs backward computation.
I0625 20:07:09.852808 18573 net.cpp:217] relu2_1 needs backward computation.
I0625 20:07:09.852812 18573 net.cpp:217] scale2_1 needs backward computation.
I0625 20:07:09.852813 18573 net.cpp:217] bn2_1 needs backward computation.
I0625 20:07:09.852815 18573 net.cpp:217] conv2_1 needs backward computation.
I0625 20:07:09.852818 18573 net.cpp:217] pool1 needs backward computation.
I0625 20:07:09.852820 18573 net.cpp:217] relu1_2 needs backward computation.
I0625 20:07:09.852823 18573 net.cpp:217] scale1_2 needs backward computation.
I0625 20:07:09.852824 18573 net.cpp:217] bn1_2 needs backward computation.
I0625 20:07:09.852828 18573 net.cpp:217] conv1_2 needs backward computation.
I0625 20:07:09.852829 18573 net.cpp:217] relu1_1 needs backward computation.
I0625 20:07:09.852831 18573 net.cpp:217] scale1_1 needs backward computation.
I0625 20:07:09.852833 18573 net.cpp:217] bn1_1 needs backward computation.
I0625 20:07:09.852835 18573 net.cpp:217] conv1_1 needs backward computation.
I0625 20:07:09.852838 18573 net.cpp:219] label_data_1_split does not need backward computation.
I0625 20:07:09.852841 18573 net.cpp:219] data does not need backward computation.
I0625 20:07:09.852843 18573 net.cpp:261] This network produces output accuracy
I0625 20:07:09.852845 18573 net.cpp:261] This network produces output loss
I0625 20:07:09.852869 18573 net.cpp:274] Network initialization done.
I0625 20:07:09.853009 18573 solver.cpp:60] Solver scaffolding done.
I0625 20:07:09.854776 18573 caffe.cpp:219] Starting Optimization
I0625 20:07:09.854784 18573 solver.cpp:279] Solving BPnet
I0625 20:07:09.854786 18573 solver.cpp:280] Learning Rate Policy: step
I0625 20:07:09.856806 18573 solver.cpp:337] Iteration 0, Testing net (#0)
I0625 20:07:09.858786 18573 blocking_queue.cpp:50] Data layer prefetch queue empty
I0625 20:07:12.845633 18573 solver.cpp:404]     Test net output #0: accuracy = 0.424805
I0625 20:07:12.845671 18573 solver.cpp:404]     Test net output #1: loss = 0.693147 (* 1 = 0.693147 loss)
I0625 20:07:12.929275 18573 solver.cpp:228] Iteration 0, loss = 0.693147
I0625 20:07:12.929319 18573 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0625 20:07:12.929327 18573 solver.cpp:244]     Train net output #1: loss = 0.693147 (* 1 = 0.693147 loss)
I0625 20:07:12.929342 18573 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0625 20:07:14.471048 18573 solver.cpp:228] Iteration 20, loss = 0.659104
I0625 20:07:14.471083 18573 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0625 20:07:14.471089 18573 solver.cpp:244]     Train net output #1: loss = 0.659104 (* 1 = 0.659104 loss)
I0625 20:07:14.471093 18573 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0625 20:07:16.059201 18573 solver.cpp:228] Iteration 40, loss = 0.652461
I0625 20:07:16.059249 18573 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0625 20:07:16.059257 18573 solver.cpp:244]     Train net output #1: loss = 0.652461 (* 1 = 0.652461 loss)
I0625 20:07:16.059262 18573 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0625 20:07:17.650354 18573 solver.cpp:228] Iteration 60, loss = 0.664831
I0625 20:07:17.650390 18573 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0625 20:07:17.650398 18573 solver.cpp:244]     Train net output #1: loss = 0.664831 (* 1 = 0.664831 loss)
I0625 20:07:17.650401 18573 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0625 20:07:19.237373 18573 solver.cpp:228] Iteration 80, loss = 0.636041
I0625 20:07:19.237398 18573 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0625 20:07:19.237406 18573 solver.cpp:244]     Train net output #1: loss = 0.636041 (* 1 = 0.636041 loss)
I0625 20:07:19.237409 18573 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0625 20:07:20.800825 18573 solver.cpp:337] Iteration 100, Testing net (#0)
I0625 20:07:23.782737 18573 solver.cpp:404]     Test net output #0: accuracy = 0.625244
I0625 20:07:23.782763 18573 solver.cpp:404]     Test net output #1: loss = 0.639197 (* 1 = 0.639197 loss)
I0625 20:07:23.810273 18573 solver.cpp:228] Iteration 100, loss = 0.629153
I0625 20:07:23.810302 18573 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0625 20:07:23.810308 18573 solver.cpp:244]     Train net output #1: loss = 0.629153 (* 1 = 0.629153 loss)
I0625 20:07:23.810314 18573 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0625 20:07:25.404439 18573 solver.cpp:228] Iteration 120, loss = 0.617916
I0625 20:07:25.404465 18573 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:07:25.404472 18573 solver.cpp:244]     Train net output #1: loss = 0.617916 (* 1 = 0.617916 loss)
I0625 20:07:25.404476 18573 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0625 20:07:26.994982 18573 solver.cpp:228] Iteration 140, loss = 0.602971
I0625 20:07:26.995018 18573 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 20:07:26.995024 18573 solver.cpp:244]     Train net output #1: loss = 0.602971 (* 1 = 0.602971 loss)
I0625 20:07:26.995028 18573 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0625 20:07:28.586431 18573 solver.cpp:228] Iteration 160, loss = 0.679192
I0625 20:07:28.586457 18573 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0625 20:07:28.586463 18573 solver.cpp:244]     Train net output #1: loss = 0.679192 (* 1 = 0.679192 loss)
I0625 20:07:28.586468 18573 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0625 20:07:30.178320 18573 solver.cpp:228] Iteration 180, loss = 0.733641
I0625 20:07:30.178355 18573 solver.cpp:244]     Train net output #0: accuracy = 0.53125
I0625 20:07:30.178361 18573 solver.cpp:244]     Train net output #1: loss = 0.733641 (* 1 = 0.733641 loss)
I0625 20:07:30.178366 18573 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0625 20:07:31.801417 18573 solver.cpp:337] Iteration 200, Testing net (#0)
I0625 20:07:34.706285 18573 solver.cpp:404]     Test net output #0: accuracy = 0.665527
I0625 20:07:34.706313 18573 solver.cpp:404]     Test net output #1: loss = 0.616415 (* 1 = 0.616415 loss)
I0625 20:07:34.733794 18573 solver.cpp:228] Iteration 200, loss = 0.530915
I0625 20:07:34.733821 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:07:34.733829 18573 solver.cpp:244]     Train net output #1: loss = 0.530915 (* 1 = 0.530915 loss)
I0625 20:07:34.733834 18573 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0625 20:07:36.381032 18573 solver.cpp:228] Iteration 220, loss = 0.706866
I0625 20:07:36.381058 18573 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0625 20:07:36.381065 18573 solver.cpp:244]     Train net output #1: loss = 0.706866 (* 1 = 0.706866 loss)
I0625 20:07:36.381070 18573 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0625 20:07:37.978469 18573 solver.cpp:228] Iteration 240, loss = 0.615909
I0625 20:07:37.978497 18573 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:07:37.978521 18573 solver.cpp:244]     Train net output #1: loss = 0.615909 (* 1 = 0.615909 loss)
I0625 20:07:37.978528 18573 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0625 20:07:39.569161 18573 solver.cpp:228] Iteration 260, loss = 0.553009
I0625 20:07:39.569294 18573 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:07:39.569304 18573 solver.cpp:244]     Train net output #1: loss = 0.553009 (* 1 = 0.553009 loss)
I0625 20:07:39.569309 18573 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0625 20:07:41.169469 18573 solver.cpp:228] Iteration 280, loss = 0.651178
I0625 20:07:41.169493 18573 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:07:41.169500 18573 solver.cpp:244]     Train net output #1: loss = 0.651178 (* 1 = 0.651178 loss)
I0625 20:07:41.169505 18573 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0625 20:07:42.786844 18573 solver.cpp:337] Iteration 300, Testing net (#0)
I0625 20:07:45.842782 18573 solver.cpp:404]     Test net output #0: accuracy = 0.678467
I0625 20:07:45.842821 18573 solver.cpp:404]     Test net output #1: loss = 0.597287 (* 1 = 0.597287 loss)
I0625 20:07:45.870474 18573 solver.cpp:228] Iteration 300, loss = 0.609672
I0625 20:07:45.870504 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:07:45.870512 18573 solver.cpp:244]     Train net output #1: loss = 0.609672 (* 1 = 0.609672 loss)
I0625 20:07:45.870517 18573 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0625 20:07:47.574172 18573 solver.cpp:228] Iteration 320, loss = 0.596658
I0625 20:07:47.574196 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:07:47.574203 18573 solver.cpp:244]     Train net output #1: loss = 0.596658 (* 1 = 0.596658 loss)
I0625 20:07:47.574208 18573 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0625 20:07:49.239615 18573 solver.cpp:228] Iteration 340, loss = 0.463634
I0625 20:07:49.239642 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:07:49.239650 18573 solver.cpp:244]     Train net output #1: loss = 0.463634 (* 1 = 0.463634 loss)
I0625 20:07:49.239655 18573 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0625 20:07:50.839443 18573 solver.cpp:228] Iteration 360, loss = 0.62135
I0625 20:07:50.839468 18573 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 20:07:50.839473 18573 solver.cpp:244]     Train net output #1: loss = 0.62135 (* 1 = 0.62135 loss)
I0625 20:07:50.839478 18573 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0625 20:07:52.446712 18573 solver.cpp:228] Iteration 380, loss = 0.660856
I0625 20:07:52.446738 18573 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:07:52.446748 18573 solver.cpp:244]     Train net output #1: loss = 0.660856 (* 1 = 0.660856 loss)
I0625 20:07:52.446753 18573 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0625 20:07:54.031219 18573 solver.cpp:337] Iteration 400, Testing net (#0)
I0625 20:07:57.047673 18573 solver.cpp:404]     Test net output #0: accuracy = 0.6875
I0625 20:07:57.047701 18573 solver.cpp:404]     Test net output #1: loss = 0.589486 (* 1 = 0.589486 loss)
I0625 20:07:57.075451 18573 solver.cpp:228] Iteration 400, loss = 0.596626
I0625 20:07:57.075477 18573 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:07:57.075485 18573 solver.cpp:244]     Train net output #1: loss = 0.596626 (* 1 = 0.596626 loss)
I0625 20:07:57.075490 18573 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0625 20:07:58.691714 18573 solver.cpp:228] Iteration 420, loss = 0.65611
I0625 20:07:58.691748 18573 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0625 20:07:58.691756 18573 solver.cpp:244]     Train net output #1: loss = 0.65611 (* 1 = 0.65611 loss)
I0625 20:07:58.691761 18573 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0625 20:08:00.300545 18573 solver.cpp:228] Iteration 440, loss = 0.580895
I0625 20:08:00.300570 18573 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0625 20:08:00.300588 18573 solver.cpp:244]     Train net output #1: loss = 0.580895 (* 1 = 0.580895 loss)
I0625 20:08:00.300592 18573 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0625 20:08:02.000082 18573 solver.cpp:228] Iteration 460, loss = 0.510526
I0625 20:08:02.000107 18573 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:08:02.000113 18573 solver.cpp:244]     Train net output #1: loss = 0.510526 (* 1 = 0.510526 loss)
I0625 20:08:02.000140 18573 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0625 20:08:03.670570 18573 solver.cpp:228] Iteration 480, loss = 0.53797
I0625 20:08:03.670593 18573 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 20:08:03.670610 18573 solver.cpp:244]     Train net output #1: loss = 0.53797 (* 1 = 0.53797 loss)
I0625 20:08:03.670614 18573 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0625 20:08:05.252012 18573 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_500.caffemodel
I0625 20:08:05.281556 18573 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_500.solverstate
I0625 20:08:05.292686 18573 solver.cpp:337] Iteration 500, Testing net (#0)
I0625 20:08:08.373734 18573 solver.cpp:404]     Test net output #0: accuracy = 0.7146
I0625 20:08:08.373764 18573 solver.cpp:404]     Test net output #1: loss = 0.564623 (* 1 = 0.564623 loss)
I0625 20:08:08.401772 18573 solver.cpp:228] Iteration 500, loss = 0.509522
I0625 20:08:08.401798 18573 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:08:08.401803 18573 solver.cpp:244]     Train net output #1: loss = 0.509522 (* 1 = 0.509522 loss)
I0625 20:08:08.401809 18573 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0625 20:08:10.015631 18573 solver.cpp:228] Iteration 520, loss = 0.636064
I0625 20:08:10.015779 18573 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0625 20:08:10.015791 18573 solver.cpp:244]     Train net output #1: loss = 0.636064 (* 1 = 0.636064 loss)
I0625 20:08:10.015795 18573 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0625 20:08:11.626027 18573 solver.cpp:228] Iteration 540, loss = 0.433461
I0625 20:08:11.626055 18573 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 20:08:11.626072 18573 solver.cpp:244]     Train net output #1: loss = 0.433461 (* 1 = 0.433461 loss)
I0625 20:08:11.626077 18573 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0625 20:08:13.236783 18573 solver.cpp:228] Iteration 560, loss = 0.613015
I0625 20:08:13.236811 18573 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 20:08:13.236819 18573 solver.cpp:244]     Train net output #1: loss = 0.613015 (* 1 = 0.613015 loss)
I0625 20:08:13.236824 18573 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0625 20:08:14.843533 18573 solver.cpp:228] Iteration 580, loss = 0.615826
I0625 20:08:14.843557 18573 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 20:08:14.843575 18573 solver.cpp:244]     Train net output #1: loss = 0.615826 (* 1 = 0.615826 loss)
I0625 20:08:14.843580 18573 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0625 20:08:16.430730 18573 solver.cpp:337] Iteration 600, Testing net (#0)
I0625 20:08:19.501725 18573 solver.cpp:404]     Test net output #0: accuracy = 0.704834
I0625 20:08:19.501752 18573 solver.cpp:404]     Test net output #1: loss = 0.575116 (* 1 = 0.575116 loss)
I0625 20:08:19.529278 18573 solver.cpp:228] Iteration 600, loss = 0.560144
I0625 20:08:19.529307 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:08:19.529314 18573 solver.cpp:244]     Train net output #1: loss = 0.560144 (* 1 = 0.560144 loss)
I0625 20:08:19.529320 18573 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0625 20:08:21.151690 18573 solver.cpp:228] Iteration 620, loss = 0.608476
I0625 20:08:21.151716 18573 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:08:21.151726 18573 solver.cpp:244]     Train net output #1: loss = 0.608476 (* 1 = 0.608476 loss)
I0625 20:08:21.151733 18573 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0625 20:08:22.768331 18573 solver.cpp:228] Iteration 640, loss = 0.478938
I0625 20:08:22.768358 18573 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:08:22.768368 18573 solver.cpp:244]     Train net output #1: loss = 0.478938 (* 1 = 0.478938 loss)
I0625 20:08:22.768374 18573 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0625 20:08:24.381695 18573 solver.cpp:228] Iteration 660, loss = 0.521767
I0625 20:08:24.381719 18573 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:08:24.381729 18573 solver.cpp:244]     Train net output #1: loss = 0.521767 (* 1 = 0.521767 loss)
I0625 20:08:24.381736 18573 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0625 20:08:25.997686 18573 solver.cpp:228] Iteration 680, loss = 0.571843
I0625 20:08:25.997712 18573 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 20:08:25.997722 18573 solver.cpp:244]     Train net output #1: loss = 0.571843 (* 1 = 0.571843 loss)
I0625 20:08:25.997730 18573 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0625 20:08:27.585729 18573 solver.cpp:337] Iteration 700, Testing net (#0)
I0625 20:08:30.581109 18573 solver.cpp:404]     Test net output #0: accuracy = 0.700684
I0625 20:08:30.581142 18573 solver.cpp:404]     Test net output #1: loss = 0.576554 (* 1 = 0.576554 loss)
I0625 20:08:30.608755 18573 solver.cpp:228] Iteration 700, loss = 0.702929
I0625 20:08:30.608783 18573 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 20:08:30.608793 18573 solver.cpp:244]     Train net output #1: loss = 0.702929 (* 1 = 0.702929 loss)
I0625 20:08:30.608800 18573 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0625 20:08:32.237500 18573 solver.cpp:228] Iteration 720, loss = 0.498557
I0625 20:08:32.237527 18573 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:08:32.237536 18573 solver.cpp:244]     Train net output #1: loss = 0.498557 (* 1 = 0.498557 loss)
I0625 20:08:32.237582 18573 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0625 20:08:33.863080 18573 solver.cpp:228] Iteration 740, loss = 0.573161
I0625 20:08:33.863108 18573 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:08:33.863118 18573 solver.cpp:244]     Train net output #1: loss = 0.573161 (* 1 = 0.573161 loss)
I0625 20:08:33.863126 18573 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0625 20:08:35.478425 18573 solver.cpp:228] Iteration 760, loss = 0.576617
I0625 20:08:35.478452 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:08:35.478463 18573 solver.cpp:244]     Train net output #1: loss = 0.576617 (* 1 = 0.576617 loss)
I0625 20:08:35.478471 18573 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0625 20:08:37.092995 18573 solver.cpp:228] Iteration 780, loss = 0.497811
I0625 20:08:37.093019 18573 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:08:37.093029 18573 solver.cpp:244]     Train net output #1: loss = 0.497811 (* 1 = 0.497811 loss)
I0625 20:08:37.093036 18573 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0625 20:08:38.684267 18573 solver.cpp:337] Iteration 800, Testing net (#0)
I0625 20:08:41.796804 18573 solver.cpp:404]     Test net output #0: accuracy = 0.748779
I0625 20:08:41.796947 18573 solver.cpp:404]     Test net output #1: loss = 0.528869 (* 1 = 0.528869 loss)
I0625 20:08:41.824626 18573 solver.cpp:228] Iteration 800, loss = 0.619262
I0625 20:08:41.824656 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:08:41.824666 18573 solver.cpp:244]     Train net output #1: loss = 0.619262 (* 1 = 0.619262 loss)
I0625 20:08:41.824673 18573 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0625 20:08:43.449098 18573 solver.cpp:228] Iteration 820, loss = 0.492034
I0625 20:08:43.449125 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:08:43.449133 18573 solver.cpp:244]     Train net output #1: loss = 0.492034 (* 1 = 0.492034 loss)
I0625 20:08:43.449141 18573 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0625 20:08:45.066229 18573 solver.cpp:228] Iteration 840, loss = 0.501214
I0625 20:08:45.066256 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:08:45.066264 18573 solver.cpp:244]     Train net output #1: loss = 0.501214 (* 1 = 0.501214 loss)
I0625 20:08:45.066272 18573 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0625 20:08:46.689074 18573 solver.cpp:228] Iteration 860, loss = 0.415297
I0625 20:08:46.689100 18573 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:08:46.689110 18573 solver.cpp:244]     Train net output #1: loss = 0.415297 (* 1 = 0.415297 loss)
I0625 20:08:46.689116 18573 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0625 20:08:48.304419 18573 solver.cpp:228] Iteration 880, loss = 0.495049
I0625 20:08:48.304443 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:08:48.304455 18573 solver.cpp:244]     Train net output #1: loss = 0.495049 (* 1 = 0.495049 loss)
I0625 20:08:48.304461 18573 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0625 20:08:49.936745 18573 solver.cpp:337] Iteration 900, Testing net (#0)
I0625 20:08:52.994417 18573 solver.cpp:404]     Test net output #0: accuracy = 0.732666
I0625 20:08:52.994456 18573 solver.cpp:404]     Test net output #1: loss = 0.533364 (* 1 = 0.533364 loss)
I0625 20:08:53.023450 18573 solver.cpp:228] Iteration 900, loss = 0.54168
I0625 20:08:53.023485 18573 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:08:53.023495 18573 solver.cpp:244]     Train net output #1: loss = 0.54168 (* 1 = 0.54168 loss)
I0625 20:08:53.023502 18573 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0625 20:08:54.684885 18573 solver.cpp:228] Iteration 920, loss = 0.5033
I0625 20:08:54.684911 18573 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:08:54.684921 18573 solver.cpp:244]     Train net output #1: loss = 0.5033 (* 1 = 0.5033 loss)
I0625 20:08:54.684927 18573 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0625 20:08:56.308405 18573 solver.cpp:228] Iteration 940, loss = 0.620267
I0625 20:08:56.308430 18573 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0625 20:08:56.308440 18573 solver.cpp:244]     Train net output #1: loss = 0.620267 (* 1 = 0.620267 loss)
I0625 20:08:56.308446 18573 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0625 20:08:57.983942 18573 solver.cpp:228] Iteration 960, loss = 0.540822
I0625 20:08:57.983968 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:08:57.983978 18573 solver.cpp:244]     Train net output #1: loss = 0.540822 (* 1 = 0.540822 loss)
I0625 20:08:57.983985 18573 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0625 20:08:59.718504 18573 solver.cpp:228] Iteration 980, loss = 0.550898
I0625 20:08:59.718529 18573 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:08:59.718540 18573 solver.cpp:244]     Train net output #1: loss = 0.550898 (* 1 = 0.550898 loss)
I0625 20:08:59.718547 18573 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0625 20:09:01.424726 18573 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_1000.caffemodel
I0625 20:09:01.444857 18573 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_1000.solverstate
I0625 20:09:01.454483 18573 solver.cpp:337] Iteration 1000, Testing net (#0)
I0625 20:09:04.592861 18573 solver.cpp:404]     Test net output #0: accuracy = 0.746338
I0625 20:09:04.592891 18573 solver.cpp:404]     Test net output #1: loss = 0.529534 (* 1 = 0.529534 loss)
I0625 20:09:04.620769 18573 solver.cpp:228] Iteration 1000, loss = 0.603076
I0625 20:09:04.620797 18573 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:09:04.620807 18573 solver.cpp:244]     Train net output #1: loss = 0.603076 (* 1 = 0.603076 loss)
I0625 20:09:04.620815 18573 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0625 20:09:06.279068 18573 solver.cpp:228] Iteration 1020, loss = 0.59044
I0625 20:09:06.279093 18573 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0625 20:09:06.279103 18573 solver.cpp:244]     Train net output #1: loss = 0.59044 (* 1 = 0.59044 loss)
I0625 20:09:06.279110 18573 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0625 20:09:07.877692 18573 solver.cpp:228] Iteration 1040, loss = 0.51262
I0625 20:09:07.877718 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:09:07.877729 18573 solver.cpp:244]     Train net output #1: loss = 0.51262 (* 1 = 0.51262 loss)
I0625 20:09:07.877735 18573 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0625 20:09:09.474994 18573 solver.cpp:228] Iteration 1060, loss = 0.497073
I0625 20:09:09.475020 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:09:09.475030 18573 solver.cpp:244]     Train net output #1: loss = 0.497073 (* 1 = 0.497073 loss)
I0625 20:09:09.475036 18573 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0625 20:09:11.073392 18573 solver.cpp:228] Iteration 1080, loss = 0.572294
I0625 20:09:11.073417 18573 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0625 20:09:11.073427 18573 solver.cpp:244]     Train net output #1: loss = 0.572294 (* 1 = 0.572294 loss)
I0625 20:09:11.073433 18573 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0625 20:09:12.648054 18573 solver.cpp:337] Iteration 1100, Testing net (#0)
I0625 20:09:15.680829 18573 solver.cpp:404]     Test net output #0: accuracy = 0.763672
I0625 20:09:15.680858 18573 solver.cpp:404]     Test net output #1: loss = 0.48983 (* 1 = 0.48983 loss)
I0625 20:09:15.708823 18573 solver.cpp:228] Iteration 1100, loss = 0.431982
I0625 20:09:15.708852 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:09:15.708861 18573 solver.cpp:244]     Train net output #1: loss = 0.431982 (* 1 = 0.431982 loss)
I0625 20:09:15.708869 18573 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0625 20:09:17.315580 18573 solver.cpp:228] Iteration 1120, loss = 0.542842
I0625 20:09:17.315605 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:09:17.315614 18573 solver.cpp:244]     Train net output #1: loss = 0.542842 (* 1 = 0.542842 loss)
I0625 20:09:17.315621 18573 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0625 20:09:18.918663 18573 solver.cpp:228] Iteration 1140, loss = 0.546377
I0625 20:09:18.918691 18573 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:09:18.918699 18573 solver.cpp:244]     Train net output #1: loss = 0.546377 (* 1 = 0.546377 loss)
I0625 20:09:18.918704 18573 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0625 20:09:20.517201 18573 solver.cpp:228] Iteration 1160, loss = 0.569506
I0625 20:09:20.517227 18573 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 20:09:20.517235 18573 solver.cpp:244]     Train net output #1: loss = 0.569506 (* 1 = 0.569506 loss)
I0625 20:09:20.517240 18573 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0625 20:09:22.116773 18573 solver.cpp:228] Iteration 1180, loss = 0.575714
I0625 20:09:22.116797 18573 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 20:09:22.116816 18573 solver.cpp:244]     Train net output #1: loss = 0.575714 (* 1 = 0.575714 loss)
I0625 20:09:22.116819 18573 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0625 20:09:23.691015 18573 solver.cpp:337] Iteration 1200, Testing net (#0)
I0625 20:09:26.729393 18573 solver.cpp:404]     Test net output #0: accuracy = 0.772461
I0625 20:09:26.729437 18573 solver.cpp:404]     Test net output #1: loss = 0.488682 (* 1 = 0.488682 loss)
I0625 20:09:26.759269 18573 solver.cpp:228] Iteration 1200, loss = 0.666378
I0625 20:09:26.759326 18573 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0625 20:09:26.759344 18573 solver.cpp:244]     Train net output #1: loss = 0.666378 (* 1 = 0.666378 loss)
I0625 20:09:26.759356 18573 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0625 20:09:28.365617 18573 solver.cpp:228] Iteration 1220, loss = 0.390731
I0625 20:09:28.365653 18573 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:09:28.365660 18573 solver.cpp:244]     Train net output #1: loss = 0.390731 (* 1 = 0.390731 loss)
I0625 20:09:28.365665 18573 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0625 20:09:29.963534 18573 solver.cpp:228] Iteration 1240, loss = 0.508898
I0625 20:09:29.963557 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:09:29.963574 18573 solver.cpp:244]     Train net output #1: loss = 0.508898 (* 1 = 0.508898 loss)
I0625 20:09:29.963579 18573 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0625 20:09:31.562667 18573 solver.cpp:228] Iteration 1260, loss = 0.474752
I0625 20:09:31.562693 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:09:31.562712 18573 solver.cpp:244]     Train net output #1: loss = 0.474752 (* 1 = 0.474752 loss)
I0625 20:09:31.562716 18573 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0625 20:09:33.160948 18573 solver.cpp:228] Iteration 1280, loss = 0.378295
I0625 20:09:33.160981 18573 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:09:33.160987 18573 solver.cpp:244]     Train net output #1: loss = 0.378295 (* 1 = 0.378295 loss)
I0625 20:09:33.160992 18573 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0625 20:09:34.735971 18573 solver.cpp:337] Iteration 1300, Testing net (#0)
I0625 20:09:37.732239 18573 solver.cpp:404]     Test net output #0: accuracy = 0.763428
I0625 20:09:37.732267 18573 solver.cpp:404]     Test net output #1: loss = 0.498019 (* 1 = 0.498019 loss)
I0625 20:09:37.761662 18573 solver.cpp:228] Iteration 1300, loss = 0.457682
I0625 20:09:37.761698 18573 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:09:37.761710 18573 solver.cpp:244]     Train net output #1: loss = 0.457682 (* 1 = 0.457682 loss)
I0625 20:09:37.761718 18573 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0625 20:09:39.365131 18573 solver.cpp:228] Iteration 1320, loss = 0.500269
I0625 20:09:39.365156 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:09:39.365164 18573 solver.cpp:244]     Train net output #1: loss = 0.500269 (* 1 = 0.500269 loss)
I0625 20:09:39.365169 18573 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0625 20:09:40.962393 18573 solver.cpp:228] Iteration 1340, loss = 0.642261
I0625 20:09:40.962416 18573 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0625 20:09:40.962435 18573 solver.cpp:244]     Train net output #1: loss = 0.642261 (* 1 = 0.642261 loss)
I0625 20:09:40.962440 18573 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0625 20:09:42.560555 18573 solver.cpp:228] Iteration 1360, loss = 0.655442
I0625 20:09:42.560580 18573 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0625 20:09:42.560586 18573 solver.cpp:244]     Train net output #1: loss = 0.655442 (* 1 = 0.655442 loss)
I0625 20:09:42.560590 18573 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0625 20:09:44.158048 18573 solver.cpp:228] Iteration 1380, loss = 0.480357
I0625 20:09:44.158187 18573 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:09:44.158197 18573 solver.cpp:244]     Train net output #1: loss = 0.480357 (* 1 = 0.480357 loss)
I0625 20:09:44.158202 18573 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0625 20:09:45.730464 18573 solver.cpp:337] Iteration 1400, Testing net (#0)
I0625 20:09:48.723881 18573 solver.cpp:404]     Test net output #0: accuracy = 0.772217
I0625 20:09:48.723922 18573 solver.cpp:404]     Test net output #1: loss = 0.479545 (* 1 = 0.479545 loss)
I0625 20:09:48.751476 18573 solver.cpp:228] Iteration 1400, loss = 0.403345
I0625 20:09:48.751502 18573 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:09:48.751509 18573 solver.cpp:244]     Train net output #1: loss = 0.403345 (* 1 = 0.403345 loss)
I0625 20:09:48.751514 18573 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0625 20:09:50.358057 18573 solver.cpp:228] Iteration 1420, loss = 0.510622
I0625 20:09:50.358081 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:09:50.358088 18573 solver.cpp:244]     Train net output #1: loss = 0.510622 (* 1 = 0.510622 loss)
I0625 20:09:50.358093 18573 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0625 20:09:51.956710 18573 solver.cpp:228] Iteration 1440, loss = 0.515905
I0625 20:09:51.956734 18573 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:09:51.956740 18573 solver.cpp:244]     Train net output #1: loss = 0.515905 (* 1 = 0.515905 loss)
I0625 20:09:51.956745 18573 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0625 20:09:53.554898 18573 solver.cpp:228] Iteration 1460, loss = 0.459809
I0625 20:09:53.554922 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:09:53.554929 18573 solver.cpp:244]     Train net output #1: loss = 0.459809 (* 1 = 0.459809 loss)
I0625 20:09:53.554934 18573 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0625 20:09:55.153779 18573 solver.cpp:228] Iteration 1480, loss = 0.440621
I0625 20:09:55.153803 18573 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:09:55.153810 18573 solver.cpp:244]     Train net output #1: loss = 0.440621 (* 1 = 0.440621 loss)
I0625 20:09:55.153815 18573 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0625 20:09:56.727824 18573 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_1500.caffemodel
I0625 20:09:56.749337 18573 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_1500.solverstate
I0625 20:09:56.760610 18573 solver.cpp:337] Iteration 1500, Testing net (#0)
I0625 20:09:59.762336 18573 solver.cpp:404]     Test net output #0: accuracy = 0.779297
I0625 20:09:59.762378 18573 solver.cpp:404]     Test net output #1: loss = 0.480324 (* 1 = 0.480324 loss)
I0625 20:09:59.790304 18573 solver.cpp:228] Iteration 1500, loss = 0.495316
I0625 20:09:59.790333 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:09:59.790344 18573 solver.cpp:244]     Train net output #1: loss = 0.495316 (* 1 = 0.495316 loss)
I0625 20:09:59.790350 18573 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0625 20:10:01.401216 18573 solver.cpp:228] Iteration 1520, loss = 0.564146
I0625 20:10:01.401239 18573 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:10:01.401247 18573 solver.cpp:244]     Train net output #1: loss = 0.564146 (* 1 = 0.564146 loss)
I0625 20:10:01.401250 18573 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0625 20:10:03.003646 18573 solver.cpp:228] Iteration 1540, loss = 0.417265
I0625 20:10:03.003669 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:10:03.003687 18573 solver.cpp:244]     Train net output #1: loss = 0.417265 (* 1 = 0.417265 loss)
I0625 20:10:03.003691 18573 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0625 20:10:04.629745 18573 solver.cpp:228] Iteration 1560, loss = 0.484063
I0625 20:10:04.629779 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:10:04.629786 18573 solver.cpp:244]     Train net output #1: loss = 0.484063 (* 1 = 0.484063 loss)
I0625 20:10:04.629791 18573 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0625 20:10:06.237246 18573 solver.cpp:228] Iteration 1580, loss = 0.397237
I0625 20:10:06.237270 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:10:06.237277 18573 solver.cpp:244]     Train net output #1: loss = 0.397237 (* 1 = 0.397237 loss)
I0625 20:10:06.237282 18573 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0625 20:10:07.826066 18573 solver.cpp:337] Iteration 1600, Testing net (#0)
I0625 20:10:10.761559 18573 solver.cpp:404]     Test net output #0: accuracy = 0.775635
I0625 20:10:10.761600 18573 solver.cpp:404]     Test net output #1: loss = 0.48346 (* 1 = 0.48346 loss)
I0625 20:10:10.789638 18573 solver.cpp:228] Iteration 1600, loss = 0.41352
I0625 20:10:10.789666 18573 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:10:10.789674 18573 solver.cpp:244]     Train net output #1: loss = 0.41352 (* 1 = 0.41352 loss)
I0625 20:10:10.789679 18573 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0625 20:10:12.399565 18573 solver.cpp:228] Iteration 1620, loss = 0.533187
I0625 20:10:12.399610 18573 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:10:12.399616 18573 solver.cpp:244]     Train net output #1: loss = 0.533187 (* 1 = 0.533187 loss)
I0625 20:10:12.399621 18573 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0625 20:10:14.002586 18573 solver.cpp:228] Iteration 1640, loss = 0.31803
I0625 20:10:14.002610 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:10:14.002617 18573 solver.cpp:244]     Train net output #1: loss = 0.31803 (* 1 = 0.31803 loss)
I0625 20:10:14.002622 18573 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0625 20:10:15.603662 18573 solver.cpp:228] Iteration 1660, loss = 0.433659
I0625 20:10:15.603811 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:10:15.603821 18573 solver.cpp:244]     Train net output #1: loss = 0.433659 (* 1 = 0.433659 loss)
I0625 20:10:15.603826 18573 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0625 20:10:17.206140 18573 solver.cpp:228] Iteration 1680, loss = 0.370916
I0625 20:10:17.206166 18573 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:10:17.206172 18573 solver.cpp:244]     Train net output #1: loss = 0.370916 (* 1 = 0.370916 loss)
I0625 20:10:17.206176 18573 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0625 20:10:18.788070 18573 solver.cpp:337] Iteration 1700, Testing net (#0)
I0625 20:10:21.789710 18573 solver.cpp:404]     Test net output #0: accuracy = 0.761719
I0625 20:10:21.789738 18573 solver.cpp:404]     Test net output #1: loss = 0.484556 (* 1 = 0.484556 loss)
I0625 20:10:21.817445 18573 solver.cpp:228] Iteration 1700, loss = 0.515135
I0625 20:10:21.817476 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:10:21.817484 18573 solver.cpp:244]     Train net output #1: loss = 0.515135 (* 1 = 0.515135 loss)
I0625 20:10:21.817488 18573 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0625 20:10:23.426496 18573 solver.cpp:228] Iteration 1720, loss = 0.612508
I0625 20:10:23.426520 18573 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:10:23.426528 18573 solver.cpp:244]     Train net output #1: loss = 0.612508 (* 1 = 0.612508 loss)
I0625 20:10:23.426532 18573 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0625 20:10:25.028148 18573 solver.cpp:228] Iteration 1740, loss = 0.615922
I0625 20:10:25.028172 18573 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 20:10:25.028179 18573 solver.cpp:244]     Train net output #1: loss = 0.615922 (* 1 = 0.615922 loss)
I0625 20:10:25.028183 18573 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0625 20:10:26.630256 18573 solver.cpp:228] Iteration 1760, loss = 0.487979
I0625 20:10:26.630291 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:10:26.630300 18573 solver.cpp:244]     Train net output #1: loss = 0.487979 (* 1 = 0.487979 loss)
I0625 20:10:26.630303 18573 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0625 20:10:28.232554 18573 solver.cpp:228] Iteration 1780, loss = 0.47895
I0625 20:10:28.232589 18573 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:10:28.232595 18573 solver.cpp:244]     Train net output #1: loss = 0.47895 (* 1 = 0.47895 loss)
I0625 20:10:28.232600 18573 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0625 20:10:29.810880 18573 solver.cpp:337] Iteration 1800, Testing net (#0)
I0625 20:10:31.201256 18573 blocking_queue.cpp:50] Data layer prefetch queue empty
I0625 20:10:32.820112 18573 solver.cpp:404]     Test net output #0: accuracy = 0.774902
I0625 20:10:32.820143 18573 solver.cpp:404]     Test net output #1: loss = 0.481692 (* 1 = 0.481692 loss)
I0625 20:10:32.847707 18573 solver.cpp:228] Iteration 1800, loss = 0.41942
I0625 20:10:32.847733 18573 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:10:32.847739 18573 solver.cpp:244]     Train net output #1: loss = 0.41942 (* 1 = 0.41942 loss)
I0625 20:10:32.847745 18573 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0625 20:10:34.460654 18573 solver.cpp:228] Iteration 1820, loss = 0.605543
I0625 20:10:34.460680 18573 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:10:34.460686 18573 solver.cpp:244]     Train net output #1: loss = 0.605543 (* 1 = 0.605543 loss)
I0625 20:10:34.460691 18573 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0625 20:10:36.059602 18573 solver.cpp:228] Iteration 1840, loss = 0.429082
I0625 20:10:36.059638 18573 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:10:36.059645 18573 solver.cpp:244]     Train net output #1: loss = 0.429082 (* 1 = 0.429082 loss)
I0625 20:10:36.059649 18573 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0625 20:10:37.661350 18573 solver.cpp:228] Iteration 1860, loss = 0.511702
I0625 20:10:37.661375 18573 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:10:37.661417 18573 solver.cpp:244]     Train net output #1: loss = 0.511702 (* 1 = 0.511702 loss)
I0625 20:10:37.661422 18573 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0625 20:10:39.261626 18573 solver.cpp:228] Iteration 1880, loss = 0.410114
I0625 20:10:39.261662 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:10:39.261668 18573 solver.cpp:244]     Train net output #1: loss = 0.410114 (* 1 = 0.410114 loss)
I0625 20:10:39.261672 18573 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0625 20:10:40.839205 18573 solver.cpp:337] Iteration 1900, Testing net (#0)
I0625 20:10:43.962522 18573 solver.cpp:404]     Test net output #0: accuracy = 0.783203
I0625 20:10:43.962549 18573 solver.cpp:404]     Test net output #1: loss = 0.494341 (* 1 = 0.494341 loss)
I0625 20:10:43.990284 18573 solver.cpp:228] Iteration 1900, loss = 0.444293
I0625 20:10:43.990314 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:10:43.990322 18573 solver.cpp:244]     Train net output #1: loss = 0.444293 (* 1 = 0.444293 loss)
I0625 20:10:43.990329 18573 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0625 20:10:45.641773 18573 solver.cpp:228] Iteration 1920, loss = 0.541681
I0625 20:10:45.641878 18573 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:10:45.641888 18573 solver.cpp:244]     Train net output #1: loss = 0.541681 (* 1 = 0.541681 loss)
I0625 20:10:45.641893 18573 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0625 20:10:47.295606 18573 solver.cpp:228] Iteration 1940, loss = 0.525115
I0625 20:10:47.295631 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:10:47.295639 18573 solver.cpp:244]     Train net output #1: loss = 0.525115 (* 1 = 0.525115 loss)
I0625 20:10:47.295644 18573 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0625 20:10:48.925629 18573 solver.cpp:228] Iteration 1960, loss = 0.472163
I0625 20:10:48.925664 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:10:48.925671 18573 solver.cpp:244]     Train net output #1: loss = 0.472163 (* 1 = 0.472163 loss)
I0625 20:10:48.925675 18573 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0625 20:10:50.538264 18573 solver.cpp:228] Iteration 1980, loss = 0.354013
I0625 20:10:50.538288 18573 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:10:50.538295 18573 solver.cpp:244]     Train net output #1: loss = 0.354013 (* 1 = 0.354013 loss)
I0625 20:10:50.538300 18573 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0625 20:10:52.127769 18573 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_2000.caffemodel
I0625 20:10:52.147295 18573 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_2000.solverstate
I0625 20:10:52.156677 18573 solver.cpp:337] Iteration 2000, Testing net (#0)
I0625 20:10:55.209215 18573 solver.cpp:404]     Test net output #0: accuracy = 0.771973
I0625 20:10:55.209244 18573 solver.cpp:404]     Test net output #1: loss = 0.480786 (* 1 = 0.480786 loss)
I0625 20:10:55.237010 18573 solver.cpp:228] Iteration 2000, loss = 0.448748
I0625 20:10:55.237038 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:10:55.237046 18573 solver.cpp:244]     Train net output #1: loss = 0.448748 (* 1 = 0.448748 loss)
I0625 20:10:55.237051 18573 sgd_solver.cpp:106] Iteration 2000, lr = 0.001
I0625 20:10:56.853018 18573 solver.cpp:228] Iteration 2020, loss = 0.387084
I0625 20:10:56.853041 18573 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 20:10:56.853049 18573 solver.cpp:244]     Train net output #1: loss = 0.387084 (* 1 = 0.387084 loss)
I0625 20:10:56.853052 18573 sgd_solver.cpp:106] Iteration 2020, lr = 0.001
I0625 20:10:58.494892 18573 solver.cpp:228] Iteration 2040, loss = 0.270907
I0625 20:10:58.494917 18573 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 20:10:58.494923 18573 solver.cpp:244]     Train net output #1: loss = 0.270907 (* 1 = 0.270907 loss)
I0625 20:10:58.494927 18573 sgd_solver.cpp:106] Iteration 2040, lr = 0.001
I0625 20:11:00.136219 18573 solver.cpp:228] Iteration 2060, loss = 0.388169
I0625 20:11:00.136252 18573 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:11:00.136260 18573 solver.cpp:244]     Train net output #1: loss = 0.388169 (* 1 = 0.388169 loss)
I0625 20:11:00.136265 18573 sgd_solver.cpp:106] Iteration 2060, lr = 0.001
I0625 20:11:01.750924 18573 solver.cpp:228] Iteration 2080, loss = 0.336228
I0625 20:11:01.750948 18573 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:11:01.750955 18573 solver.cpp:244]     Train net output #1: loss = 0.336228 (* 1 = 0.336228 loss)
I0625 20:11:01.750960 18573 sgd_solver.cpp:106] Iteration 2080, lr = 0.001
I0625 20:11:03.343061 18573 solver.cpp:337] Iteration 2100, Testing net (#0)
I0625 20:11:06.370836 18573 solver.cpp:404]     Test net output #0: accuracy = 0.785889
I0625 20:11:06.370875 18573 solver.cpp:404]     Test net output #1: loss = 0.474546 (* 1 = 0.474546 loss)
I0625 20:11:06.398576 18573 solver.cpp:228] Iteration 2100, loss = 0.690233
I0625 20:11:06.398602 18573 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:11:06.398610 18573 solver.cpp:244]     Train net output #1: loss = 0.690233 (* 1 = 0.690233 loss)
I0625 20:11:06.398615 18573 sgd_solver.cpp:106] Iteration 2100, lr = 0.001
I0625 20:11:08.025878 18573 solver.cpp:228] Iteration 2120, loss = 0.442854
I0625 20:11:08.025903 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:11:08.025910 18573 solver.cpp:244]     Train net output #1: loss = 0.442854 (* 1 = 0.442854 loss)
I0625 20:11:08.025914 18573 sgd_solver.cpp:106] Iteration 2120, lr = 0.001
I0625 20:11:09.644893 18573 solver.cpp:228] Iteration 2140, loss = 0.407891
I0625 20:11:09.644917 18573 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:11:09.644924 18573 solver.cpp:244]     Train net output #1: loss = 0.407891 (* 1 = 0.407891 loss)
I0625 20:11:09.644928 18573 sgd_solver.cpp:106] Iteration 2140, lr = 0.001
I0625 20:11:11.259444 18573 solver.cpp:228] Iteration 2160, loss = 0.443195
I0625 20:11:11.259469 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:11:11.259476 18573 solver.cpp:244]     Train net output #1: loss = 0.443195 (* 1 = 0.443195 loss)
I0625 20:11:11.259480 18573 sgd_solver.cpp:106] Iteration 2160, lr = 0.001
I0625 20:11:12.878880 18573 solver.cpp:228] Iteration 2180, loss = 0.394788
I0625 20:11:12.878903 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:11:12.878921 18573 solver.cpp:244]     Train net output #1: loss = 0.394788 (* 1 = 0.394788 loss)
I0625 20:11:12.878926 18573 sgd_solver.cpp:106] Iteration 2180, lr = 0.001
I0625 20:11:14.474380 18573 solver.cpp:337] Iteration 2200, Testing net (#0)
I0625 20:11:17.478190 18573 solver.cpp:404]     Test net output #0: accuracy = 0.786377
I0625 20:11:17.478301 18573 solver.cpp:404]     Test net output #1: loss = 0.473793 (* 1 = 0.473793 loss)
I0625 20:11:17.506091 18573 solver.cpp:228] Iteration 2200, loss = 0.437825
I0625 20:11:17.506116 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:11:17.506122 18573 solver.cpp:244]     Train net output #1: loss = 0.437825 (* 1 = 0.437825 loss)
I0625 20:11:17.506129 18573 sgd_solver.cpp:106] Iteration 2200, lr = 0.001
I0625 20:11:19.131541 18573 solver.cpp:228] Iteration 2220, loss = 0.62159
I0625 20:11:19.131567 18573 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:11:19.131573 18573 solver.cpp:244]     Train net output #1: loss = 0.62159 (* 1 = 0.62159 loss)
I0625 20:11:19.131577 18573 sgd_solver.cpp:106] Iteration 2220, lr = 0.001
I0625 20:11:20.746296 18573 solver.cpp:228] Iteration 2240, loss = 0.501268
I0625 20:11:20.746320 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:11:20.746327 18573 solver.cpp:244]     Train net output #1: loss = 0.501268 (* 1 = 0.501268 loss)
I0625 20:11:20.746331 18573 sgd_solver.cpp:106] Iteration 2240, lr = 0.001
I0625 20:11:22.364384 18573 solver.cpp:228] Iteration 2260, loss = 0.437042
I0625 20:11:22.364408 18573 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:11:22.364415 18573 solver.cpp:244]     Train net output #1: loss = 0.437042 (* 1 = 0.437042 loss)
I0625 20:11:22.364420 18573 sgd_solver.cpp:106] Iteration 2260, lr = 0.001
I0625 20:11:23.982214 18573 solver.cpp:228] Iteration 2280, loss = 0.574203
I0625 20:11:23.982240 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:11:23.982247 18573 solver.cpp:244]     Train net output #1: loss = 0.574203 (* 1 = 0.574203 loss)
I0625 20:11:23.982251 18573 sgd_solver.cpp:106] Iteration 2280, lr = 0.001
I0625 20:11:25.571996 18573 solver.cpp:337] Iteration 2300, Testing net (#0)
I0625 20:11:28.487473 18573 solver.cpp:404]     Test net output #0: accuracy = 0.761719
I0625 20:11:28.487504 18573 solver.cpp:404]     Test net output #1: loss = 0.493435 (* 1 = 0.493435 loss)
I0625 20:11:28.515226 18573 solver.cpp:228] Iteration 2300, loss = 0.50838
I0625 20:11:28.515251 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:11:28.515269 18573 solver.cpp:244]     Train net output #1: loss = 0.50838 (* 1 = 0.50838 loss)
I0625 20:11:28.515274 18573 sgd_solver.cpp:106] Iteration 2300, lr = 0.001
I0625 20:11:30.134090 18573 solver.cpp:228] Iteration 2320, loss = 0.485446
I0625 20:11:30.134114 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:11:30.134121 18573 solver.cpp:244]     Train net output #1: loss = 0.485446 (* 1 = 0.485446 loss)
I0625 20:11:30.134125 18573 sgd_solver.cpp:106] Iteration 2320, lr = 0.001
I0625 20:11:31.748931 18573 solver.cpp:228] Iteration 2340, loss = 0.388879
I0625 20:11:31.748957 18573 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:11:31.748965 18573 solver.cpp:244]     Train net output #1: loss = 0.388879 (* 1 = 0.388879 loss)
I0625 20:11:31.748970 18573 sgd_solver.cpp:106] Iteration 2340, lr = 0.001
I0625 20:11:33.368815 18573 solver.cpp:228] Iteration 2360, loss = 0.30618
I0625 20:11:33.368841 18573 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:11:33.368849 18573 solver.cpp:244]     Train net output #1: loss = 0.30618 (* 1 = 0.30618 loss)
I0625 20:11:33.368854 18573 sgd_solver.cpp:106] Iteration 2360, lr = 0.001
I0625 20:11:34.986305 18573 solver.cpp:228] Iteration 2380, loss = 0.4702
I0625 20:11:34.986331 18573 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:11:34.986348 18573 solver.cpp:244]     Train net output #1: loss = 0.4702 (* 1 = 0.4702 loss)
I0625 20:11:34.986353 18573 sgd_solver.cpp:106] Iteration 2380, lr = 0.001
I0625 20:11:36.575413 18573 solver.cpp:337] Iteration 2400, Testing net (#0)
I0625 20:11:39.611325 18573 solver.cpp:404]     Test net output #0: accuracy = 0.769043
I0625 20:11:39.611352 18573 solver.cpp:404]     Test net output #1: loss = 0.482683 (* 1 = 0.482683 loss)
I0625 20:11:39.639173 18573 solver.cpp:228] Iteration 2400, loss = 0.414679
I0625 20:11:39.639227 18573 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:11:39.639235 18573 solver.cpp:244]     Train net output #1: loss = 0.414679 (* 1 = 0.414679 loss)
I0625 20:11:39.639240 18573 sgd_solver.cpp:106] Iteration 2400, lr = 0.001
I0625 20:11:41.260777 18573 solver.cpp:228] Iteration 2420, loss = 0.641846
I0625 20:11:41.260802 18573 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0625 20:11:41.260809 18573 solver.cpp:244]     Train net output #1: loss = 0.641846 (* 1 = 0.641846 loss)
I0625 20:11:41.260813 18573 sgd_solver.cpp:106] Iteration 2420, lr = 0.001
I0625 20:11:42.879851 18573 solver.cpp:228] Iteration 2440, loss = 0.713752
I0625 20:11:42.879876 18573 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0625 20:11:42.879884 18573 solver.cpp:244]     Train net output #1: loss = 0.713752 (* 1 = 0.713752 loss)
I0625 20:11:42.879889 18573 sgd_solver.cpp:106] Iteration 2440, lr = 0.001
I0625 20:11:44.497277 18573 solver.cpp:228] Iteration 2460, loss = 0.543748
I0625 20:11:44.497303 18573 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:11:44.497309 18573 solver.cpp:244]     Train net output #1: loss = 0.543748 (* 1 = 0.543748 loss)
I0625 20:11:44.497314 18573 sgd_solver.cpp:106] Iteration 2460, lr = 0.001
I0625 20:11:46.110514 18573 solver.cpp:228] Iteration 2480, loss = 0.42602
I0625 20:11:46.110539 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:11:46.110548 18573 solver.cpp:244]     Train net output #1: loss = 0.42602 (* 1 = 0.42602 loss)
I0625 20:11:46.110553 18573 sgd_solver.cpp:106] Iteration 2480, lr = 0.001
I0625 20:11:47.703809 18573 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_2500.caffemodel
I0625 20:11:47.723498 18573 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_2500.solverstate
I0625 20:11:47.733043 18573 solver.cpp:337] Iteration 2500, Testing net (#0)
I0625 20:11:50.733108 18573 solver.cpp:404]     Test net output #0: accuracy = 0.785889
I0625 20:11:50.733147 18573 solver.cpp:404]     Test net output #1: loss = 0.468769 (* 1 = 0.468769 loss)
I0625 20:11:50.761070 18573 solver.cpp:228] Iteration 2500, loss = 0.39044
I0625 20:11:50.761099 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:11:50.761107 18573 solver.cpp:244]     Train net output #1: loss = 0.39044 (* 1 = 0.39044 loss)
I0625 20:11:50.761112 18573 sgd_solver.cpp:106] Iteration 2500, lr = 0.001
I0625 20:11:52.386679 18573 solver.cpp:228] Iteration 2520, loss = 0.473101
I0625 20:11:52.386705 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:11:52.386711 18573 solver.cpp:244]     Train net output #1: loss = 0.473101 (* 1 = 0.473101 loss)
I0625 20:11:52.386715 18573 sgd_solver.cpp:106] Iteration 2520, lr = 0.001
I0625 20:11:54.006549 18573 solver.cpp:228] Iteration 2540, loss = 0.568412
I0625 20:11:54.006575 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:11:54.006582 18573 solver.cpp:244]     Train net output #1: loss = 0.568412 (* 1 = 0.568412 loss)
I0625 20:11:54.006587 18573 sgd_solver.cpp:106] Iteration 2540, lr = 0.001
I0625 20:11:55.618286 18573 solver.cpp:228] Iteration 2560, loss = 0.375532
I0625 20:11:55.618312 18573 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:11:55.618319 18573 solver.cpp:244]     Train net output #1: loss = 0.375532 (* 1 = 0.375532 loss)
I0625 20:11:55.618324 18573 sgd_solver.cpp:106] Iteration 2560, lr = 0.001
I0625 20:11:57.234776 18573 solver.cpp:228] Iteration 2580, loss = 0.448557
I0625 20:11:57.234812 18573 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:11:57.234818 18573 solver.cpp:244]     Train net output #1: loss = 0.448557 (* 1 = 0.448557 loss)
I0625 20:11:57.234822 18573 sgd_solver.cpp:106] Iteration 2580, lr = 0.001
I0625 20:11:58.828052 18573 solver.cpp:337] Iteration 2600, Testing net (#0)
I0625 20:12:01.935709 18573 solver.cpp:404]     Test net output #0: accuracy = 0.773682
I0625 20:12:01.935746 18573 solver.cpp:404]     Test net output #1: loss = 0.467811 (* 1 = 0.467811 loss)
I0625 20:12:01.963925 18573 solver.cpp:228] Iteration 2600, loss = 0.580628
I0625 20:12:01.963951 18573 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 20:12:01.963958 18573 solver.cpp:244]     Train net output #1: loss = 0.580628 (* 1 = 0.580628 loss)
I0625 20:12:01.963963 18573 sgd_solver.cpp:106] Iteration 2600, lr = 0.001
I0625 20:12:03.590049 18573 solver.cpp:228] Iteration 2620, loss = 0.364943
I0625 20:12:03.590073 18573 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:12:03.590080 18573 solver.cpp:244]     Train net output #1: loss = 0.364943 (* 1 = 0.364943 loss)
I0625 20:12:03.590085 18573 sgd_solver.cpp:106] Iteration 2620, lr = 0.001
I0625 20:12:05.205302 18573 solver.cpp:228] Iteration 2640, loss = 0.386846
I0625 20:12:05.205338 18573 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:12:05.205344 18573 solver.cpp:244]     Train net output #1: loss = 0.386846 (* 1 = 0.386846 loss)
I0625 20:12:05.205349 18573 sgd_solver.cpp:106] Iteration 2640, lr = 0.001
I0625 20:12:06.824053 18573 solver.cpp:228] Iteration 2660, loss = 0.424973
I0625 20:12:06.824089 18573 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:12:06.824095 18573 solver.cpp:244]     Train net output #1: loss = 0.424973 (* 1 = 0.424973 loss)
I0625 20:12:06.824100 18573 sgd_solver.cpp:106] Iteration 2660, lr = 0.001
I0625 20:12:08.443390 18573 solver.cpp:228] Iteration 2680, loss = 0.50581
I0625 20:12:08.443425 18573 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:12:08.443433 18573 solver.cpp:244]     Train net output #1: loss = 0.50581 (* 1 = 0.50581 loss)
I0625 20:12:08.443436 18573 sgd_solver.cpp:106] Iteration 2680, lr = 0.001
I0625 20:12:10.033578 18573 solver.cpp:337] Iteration 2700, Testing net (#0)
I0625 20:12:13.026520 18573 solver.cpp:404]     Test net output #0: accuracy = 0.769775
I0625 20:12:13.026551 18573 solver.cpp:404]     Test net output #1: loss = 0.493938 (* 1 = 0.493938 loss)
I0625 20:12:13.054293 18573 solver.cpp:228] Iteration 2700, loss = 0.537574
I0625 20:12:13.054319 18573 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:12:13.054327 18573 solver.cpp:244]     Train net output #1: loss = 0.537574 (* 1 = 0.537574 loss)
I0625 20:12:13.054332 18573 sgd_solver.cpp:106] Iteration 2700, lr = 0.001
I0625 20:12:14.680253 18573 solver.cpp:228] Iteration 2720, loss = 0.647747
I0625 20:12:14.680279 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:12:14.680295 18573 solver.cpp:244]     Train net output #1: loss = 0.647747 (* 1 = 0.647747 loss)
I0625 20:12:14.680300 18573 sgd_solver.cpp:106] Iteration 2720, lr = 0.001
I0625 20:12:16.299022 18573 solver.cpp:228] Iteration 2740, loss = 0.474936
I0625 20:12:16.299052 18573 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 20:12:16.299059 18573 solver.cpp:244]     Train net output #1: loss = 0.474936 (* 1 = 0.474936 loss)
I0625 20:12:16.299064 18573 sgd_solver.cpp:106] Iteration 2740, lr = 0.001
I0625 20:12:17.921088 18573 solver.cpp:228] Iteration 2760, loss = 0.583754
I0625 20:12:17.921216 18573 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:12:17.921226 18573 solver.cpp:244]     Train net output #1: loss = 0.583754 (* 1 = 0.583754 loss)
I0625 20:12:17.921231 18573 sgd_solver.cpp:106] Iteration 2760, lr = 0.001
I0625 20:12:19.538038 18573 solver.cpp:228] Iteration 2780, loss = 0.400701
I0625 20:12:19.538074 18573 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 20:12:19.538080 18573 solver.cpp:244]     Train net output #1: loss = 0.400701 (* 1 = 0.400701 loss)
I0625 20:12:19.538084 18573 sgd_solver.cpp:106] Iteration 2780, lr = 0.001
I0625 20:12:21.133610 18573 solver.cpp:337] Iteration 2800, Testing net (#0)
I0625 20:12:24.166071 18573 solver.cpp:404]     Test net output #0: accuracy = 0.776855
I0625 20:12:24.166097 18573 solver.cpp:404]     Test net output #1: loss = 0.474189 (* 1 = 0.474189 loss)
I0625 20:12:24.193871 18573 solver.cpp:228] Iteration 2800, loss = 0.414737
I0625 20:12:24.193898 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:12:24.193905 18573 solver.cpp:244]     Train net output #1: loss = 0.414737 (* 1 = 0.414737 loss)
I0625 20:12:24.193912 18573 sgd_solver.cpp:106] Iteration 2800, lr = 0.001
I0625 20:12:25.816927 18573 solver.cpp:228] Iteration 2820, loss = 0.304789
I0625 20:12:25.816963 18573 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:12:25.816970 18573 solver.cpp:244]     Train net output #1: loss = 0.304789 (* 1 = 0.304789 loss)
I0625 20:12:25.816975 18573 sgd_solver.cpp:106] Iteration 2820, lr = 0.001
I0625 20:12:27.434767 18573 solver.cpp:228] Iteration 2840, loss = 0.331207
I0625 20:12:27.434792 18573 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 20:12:27.434798 18573 solver.cpp:244]     Train net output #1: loss = 0.331207 (* 1 = 0.331207 loss)
I0625 20:12:27.434803 18573 sgd_solver.cpp:106] Iteration 2840, lr = 0.001
I0625 20:12:29.052829 18573 solver.cpp:228] Iteration 2860, loss = 0.414574
I0625 20:12:29.052855 18573 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:12:29.052861 18573 solver.cpp:244]     Train net output #1: loss = 0.414574 (* 1 = 0.414574 loss)
I0625 20:12:29.052865 18573 sgd_solver.cpp:106] Iteration 2860, lr = 0.001
I0625 20:12:30.701033 18573 solver.cpp:228] Iteration 2880, loss = 0.476624
I0625 20:12:30.701071 18573 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 20:12:30.701078 18573 solver.cpp:244]     Train net output #1: loss = 0.476624 (* 1 = 0.476624 loss)
I0625 20:12:30.701082 18573 sgd_solver.cpp:106] Iteration 2880, lr = 0.001
I0625 20:12:32.318819 18573 solver.cpp:337] Iteration 2900, Testing net (#0)
I0625 20:12:35.375377 18573 solver.cpp:404]     Test net output #0: accuracy = 0.779541
I0625 20:12:35.375409 18573 solver.cpp:404]     Test net output #1: loss = 0.477436 (* 1 = 0.477436 loss)
I0625 20:12:35.404271 18573 solver.cpp:228] Iteration 2900, loss = 0.516927
I0625 20:12:35.404299 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:12:35.404306 18573 solver.cpp:244]     Train net output #1: loss = 0.516927 (* 1 = 0.516927 loss)
I0625 20:12:35.404311 18573 sgd_solver.cpp:106] Iteration 2900, lr = 0.001
I0625 20:12:37.065130 18573 solver.cpp:228] Iteration 2920, loss = 0.595944
I0625 20:12:37.065155 18573 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 20:12:37.065173 18573 solver.cpp:244]     Train net output #1: loss = 0.595944 (* 1 = 0.595944 loss)
I0625 20:12:37.065178 18573 sgd_solver.cpp:106] Iteration 2920, lr = 0.001
I0625 20:12:38.721102 18573 solver.cpp:228] Iteration 2940, loss = 0.390632
I0625 20:12:38.721132 18573 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 20:12:38.721143 18573 solver.cpp:244]     Train net output #1: loss = 0.390632 (* 1 = 0.390632 loss)
I0625 20:12:38.721149 18573 sgd_solver.cpp:106] Iteration 2940, lr = 0.001
I0625 20:12:40.343971 18573 solver.cpp:228] Iteration 2960, loss = 0.421337
I0625 20:12:40.343996 18573 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 20:12:40.344005 18573 solver.cpp:244]     Train net output #1: loss = 0.421337 (* 1 = 0.421337 loss)
I0625 20:12:40.344045 18573 sgd_solver.cpp:106] Iteration 2960, lr = 0.001
I0625 20:12:41.951025 18573 solver.cpp:228] Iteration 2980, loss = 0.378699
I0625 20:12:41.951051 18573 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 20:12:41.951059 18573 solver.cpp:244]     Train net output #1: loss = 0.378699 (* 1 = 0.378699 loss)
I0625 20:12:41.951064 18573 sgd_solver.cpp:106] Iteration 2980, lr = 0.001
I0625 20:12:43.539296 18573 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_3000.caffemodel
I0625 20:12:43.559954 18573 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_3000.solverstate
I0625 20:12:43.593170 18573 solver.cpp:317] Iteration 3000, loss = 0.691853
I0625 20:12:43.593192 18573 solver.cpp:337] Iteration 3000, Testing net (#0)
I0625 20:12:46.597307 18573 solver.cpp:404]     Test net output #0: accuracy = 0.768799
I0625 20:12:46.597347 18573 solver.cpp:404]     Test net output #1: loss = 0.484468 (* 1 = 0.484468 loss)
I0625 20:12:46.597350 18573 solver.cpp:322] Optimization Done.
I0625 20:12:46.597353 18573 caffe.cpp:222] Optimization Done.
