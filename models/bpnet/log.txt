I0625 21:35:21.021553 20335 caffe.cpp:185] Using GPUs 0
I0625 21:35:21.037960 20335 caffe.cpp:190] GPU 0: Graphics Device
I0625 21:35:21.545302 20335 solver.cpp:48] Initializing solver from parameters: 
test_iter: 64
test_interval: 100
base_lr: 0.001
display: 20
max_iter: 6000
lr_policy: "step"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
stepsize: 2000
snapshot: 500
snapshot_prefix: "data/models/bpnet"
solver_mode: GPU
device_id: 0
net: "models/bpnet/train_val.prototxt"
test_initialization: true
iter_size: 1
I0625 21:35:21.545418 20335 solver.cpp:91] Creating training net from net file: models/bpnet/train_val.prototxt
I0625 21:35:21.546254 20335 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0625 21:35:21.546489 20335 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 100
    crop_h: 196
    crop_w: 256
    rotation_range: 10
    scale_jitter_range: 0.1
    contrast_jitter_range: 0.3
  }
  data_param {
    source: "data/train_lmdb"
    batch_size: 32
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  pooling_param {
    pool: AVE
    stride: 1
    kernel_h: 6
    kernel_w: 8
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0625 21:35:21.546660 20335 layer_factory.hpp:77] Creating layer data
I0625 21:35:21.547070 20335 net.cpp:91] Creating Layer data
I0625 21:35:21.547081 20335 net.cpp:399] data -> data
I0625 21:35:21.547103 20335 net.cpp:399] data -> label
I0625 21:35:21.548432 20339 db_lmdb.cpp:35] Opened lmdb data/train_lmdb
I0625 21:35:21.573807 20335 data_layer.cpp:42] output data size: 32,3,196,256
I0625 21:35:21.614179 20335 net.cpp:141] Setting up data
I0625 21:35:21.614209 20335 net.cpp:148] Top shape: 32 3 196 256 (4816896)
I0625 21:35:21.614214 20335 net.cpp:148] Top shape: 32 (32)
I0625 21:35:21.614217 20335 net.cpp:156] Memory required for data: 19267712
I0625 21:35:21.614224 20335 layer_factory.hpp:77] Creating layer label_data_1_split
I0625 21:35:21.614240 20335 net.cpp:91] Creating Layer label_data_1_split
I0625 21:35:21.614245 20335 net.cpp:425] label_data_1_split <- label
I0625 21:35:21.614254 20335 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0625 21:35:21.614264 20335 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0625 21:35:21.614325 20335 net.cpp:141] Setting up label_data_1_split
I0625 21:35:21.614331 20335 net.cpp:148] Top shape: 32 (32)
I0625 21:35:21.614334 20335 net.cpp:148] Top shape: 32 (32)
I0625 21:35:21.614337 20335 net.cpp:156] Memory required for data: 19267968
I0625 21:35:21.614341 20335 layer_factory.hpp:77] Creating layer conv1_1
I0625 21:35:21.614356 20335 net.cpp:91] Creating Layer conv1_1
I0625 21:35:21.614374 20335 net.cpp:425] conv1_1 <- data
I0625 21:35:21.614380 20335 net.cpp:399] conv1_1 -> conv1_1
I0625 21:35:21.961046 20335 net.cpp:141] Setting up conv1_1
I0625 21:35:21.961072 20335 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 21:35:21.961076 20335 net.cpp:156] Memory required for data: 70648192
I0625 21:35:21.961087 20335 layer_factory.hpp:77] Creating layer bn1_1
I0625 21:35:21.961102 20335 net.cpp:91] Creating Layer bn1_1
I0625 21:35:21.961105 20335 net.cpp:425] bn1_1 <- conv1_1
I0625 21:35:21.961110 20335 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0625 21:35:21.961262 20335 net.cpp:141] Setting up bn1_1
I0625 21:35:21.961269 20335 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 21:35:21.961272 20335 net.cpp:156] Memory required for data: 122028416
I0625 21:35:21.961280 20335 layer_factory.hpp:77] Creating layer scale1_1
I0625 21:35:21.961293 20335 net.cpp:91] Creating Layer scale1_1
I0625 21:35:21.961295 20335 net.cpp:425] scale1_1 <- conv1_1
I0625 21:35:21.961299 20335 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0625 21:35:21.961334 20335 layer_factory.hpp:77] Creating layer scale1_1
I0625 21:35:21.961427 20335 net.cpp:141] Setting up scale1_1
I0625 21:35:21.961434 20335 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 21:35:21.961437 20335 net.cpp:156] Memory required for data: 173408640
I0625 21:35:21.961443 20335 layer_factory.hpp:77] Creating layer relu1_1
I0625 21:35:21.961448 20335 net.cpp:91] Creating Layer relu1_1
I0625 21:35:21.961452 20335 net.cpp:425] relu1_1 <- conv1_1
I0625 21:35:21.961454 20335 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0625 21:35:21.961587 20335 net.cpp:141] Setting up relu1_1
I0625 21:35:21.961596 20335 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 21:35:21.961598 20335 net.cpp:156] Memory required for data: 224788864
I0625 21:35:21.961601 20335 layer_factory.hpp:77] Creating layer conv1_2
I0625 21:35:21.961609 20335 net.cpp:91] Creating Layer conv1_2
I0625 21:35:21.961611 20335 net.cpp:425] conv1_2 <- conv1_1
I0625 21:35:21.961616 20335 net.cpp:399] conv1_2 -> conv1_2
I0625 21:35:21.962416 20335 net.cpp:141] Setting up conv1_2
I0625 21:35:21.962429 20335 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 21:35:21.962431 20335 net.cpp:156] Memory required for data: 276169088
I0625 21:35:21.962435 20335 layer_factory.hpp:77] Creating layer bn1_2
I0625 21:35:21.962463 20335 net.cpp:91] Creating Layer bn1_2
I0625 21:35:21.962466 20335 net.cpp:425] bn1_2 <- conv1_2
I0625 21:35:21.962471 20335 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0625 21:35:21.962606 20335 net.cpp:141] Setting up bn1_2
I0625 21:35:21.962613 20335 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 21:35:21.962616 20335 net.cpp:156] Memory required for data: 327549312
I0625 21:35:21.962623 20335 layer_factory.hpp:77] Creating layer scale1_2
I0625 21:35:21.962630 20335 net.cpp:91] Creating Layer scale1_2
I0625 21:35:21.962632 20335 net.cpp:425] scale1_2 <- conv1_2
I0625 21:35:21.962636 20335 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0625 21:35:21.962664 20335 layer_factory.hpp:77] Creating layer scale1_2
I0625 21:35:21.962764 20335 net.cpp:141] Setting up scale1_2
I0625 21:35:21.962772 20335 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 21:35:21.962774 20335 net.cpp:156] Memory required for data: 378929536
I0625 21:35:21.962779 20335 layer_factory.hpp:77] Creating layer relu1_2
I0625 21:35:21.962782 20335 net.cpp:91] Creating Layer relu1_2
I0625 21:35:21.962785 20335 net.cpp:425] relu1_2 <- conv1_2
I0625 21:35:21.962790 20335 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0625 21:35:21.962924 20335 net.cpp:141] Setting up relu1_2
I0625 21:35:21.962932 20335 net.cpp:148] Top shape: 32 32 98 128 (12845056)
I0625 21:35:21.962934 20335 net.cpp:156] Memory required for data: 430309760
I0625 21:35:21.962937 20335 layer_factory.hpp:77] Creating layer pool1
I0625 21:35:21.962944 20335 net.cpp:91] Creating Layer pool1
I0625 21:35:21.962946 20335 net.cpp:425] pool1 <- conv1_2
I0625 21:35:21.962949 20335 net.cpp:399] pool1 -> pool1
I0625 21:35:21.962996 20335 net.cpp:141] Setting up pool1
I0625 21:35:21.963021 20335 net.cpp:148] Top shape: 32 32 49 64 (3211264)
I0625 21:35:21.963023 20335 net.cpp:156] Memory required for data: 443154816
I0625 21:35:21.963027 20335 layer_factory.hpp:77] Creating layer conv2_1
I0625 21:35:21.963034 20335 net.cpp:91] Creating Layer conv2_1
I0625 21:35:21.963037 20335 net.cpp:425] conv2_1 <- pool1
I0625 21:35:21.963042 20335 net.cpp:399] conv2_1 -> conv2_1
I0625 21:35:21.965049 20335 net.cpp:141] Setting up conv2_1
I0625 21:35:21.965062 20335 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 21:35:21.965065 20335 net.cpp:156] Memory required for data: 468844928
I0625 21:35:21.965070 20335 layer_factory.hpp:77] Creating layer bn2_1
I0625 21:35:21.965077 20335 net.cpp:91] Creating Layer bn2_1
I0625 21:35:21.965080 20335 net.cpp:425] bn2_1 <- conv2_1
I0625 21:35:21.965085 20335 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0625 21:35:21.966322 20335 net.cpp:141] Setting up bn2_1
I0625 21:35:21.966333 20335 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 21:35:21.966336 20335 net.cpp:156] Memory required for data: 494535040
I0625 21:35:21.966342 20335 layer_factory.hpp:77] Creating layer scale2_1
I0625 21:35:21.966349 20335 net.cpp:91] Creating Layer scale2_1
I0625 21:35:21.966351 20335 net.cpp:425] scale2_1 <- conv2_1
I0625 21:35:21.966356 20335 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0625 21:35:21.966389 20335 layer_factory.hpp:77] Creating layer scale2_1
I0625 21:35:21.966480 20335 net.cpp:141] Setting up scale2_1
I0625 21:35:21.966487 20335 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 21:35:21.966490 20335 net.cpp:156] Memory required for data: 520225152
I0625 21:35:21.966500 20335 layer_factory.hpp:77] Creating layer relu2_1
I0625 21:35:21.966503 20335 net.cpp:91] Creating Layer relu2_1
I0625 21:35:21.966506 20335 net.cpp:425] relu2_1 <- conv2_1
I0625 21:35:21.966511 20335 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0625 21:35:21.966928 20335 net.cpp:141] Setting up relu2_1
I0625 21:35:21.966939 20335 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 21:35:21.966943 20335 net.cpp:156] Memory required for data: 545915264
I0625 21:35:21.966944 20335 layer_factory.hpp:77] Creating layer conv2_2
I0625 21:35:21.966953 20335 net.cpp:91] Creating Layer conv2_2
I0625 21:35:21.966956 20335 net.cpp:425] conv2_2 <- conv2_1
I0625 21:35:21.966960 20335 net.cpp:399] conv2_2 -> conv2_2
I0625 21:35:21.967728 20335 net.cpp:141] Setting up conv2_2
I0625 21:35:21.967741 20335 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 21:35:21.967742 20335 net.cpp:156] Memory required for data: 571605376
I0625 21:35:21.967746 20335 layer_factory.hpp:77] Creating layer bn2_2
I0625 21:35:21.967756 20335 net.cpp:91] Creating Layer bn2_2
I0625 21:35:21.967758 20335 net.cpp:425] bn2_2 <- conv2_2
I0625 21:35:21.967767 20335 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0625 21:35:21.967907 20335 net.cpp:141] Setting up bn2_2
I0625 21:35:21.967914 20335 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 21:35:21.967916 20335 net.cpp:156] Memory required for data: 597295488
I0625 21:35:21.967922 20335 layer_factory.hpp:77] Creating layer scale2_2
I0625 21:35:21.967928 20335 net.cpp:91] Creating Layer scale2_2
I0625 21:35:21.967931 20335 net.cpp:425] scale2_2 <- conv2_2
I0625 21:35:21.967936 20335 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0625 21:35:21.967964 20335 layer_factory.hpp:77] Creating layer scale2_2
I0625 21:35:21.968051 20335 net.cpp:141] Setting up scale2_2
I0625 21:35:21.968057 20335 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 21:35:21.968060 20335 net.cpp:156] Memory required for data: 622985600
I0625 21:35:21.968065 20335 layer_factory.hpp:77] Creating layer relu2_2
I0625 21:35:21.968070 20335 net.cpp:91] Creating Layer relu2_2
I0625 21:35:21.968072 20335 net.cpp:425] relu2_2 <- conv2_2
I0625 21:35:21.968078 20335 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0625 21:35:21.968471 20335 net.cpp:141] Setting up relu2_2
I0625 21:35:21.968482 20335 net.cpp:148] Top shape: 32 64 49 64 (6422528)
I0625 21:35:21.968485 20335 net.cpp:156] Memory required for data: 648675712
I0625 21:35:21.968499 20335 layer_factory.hpp:77] Creating layer pool2
I0625 21:35:21.968507 20335 net.cpp:91] Creating Layer pool2
I0625 21:35:21.968509 20335 net.cpp:425] pool2 <- conv2_2
I0625 21:35:21.968513 20335 net.cpp:399] pool2 -> pool2
I0625 21:35:21.968554 20335 net.cpp:141] Setting up pool2
I0625 21:35:21.968560 20335 net.cpp:148] Top shape: 32 64 25 32 (1638400)
I0625 21:35:21.968562 20335 net.cpp:156] Memory required for data: 655229312
I0625 21:35:21.968564 20335 layer_factory.hpp:77] Creating layer conv3_1
I0625 21:35:21.968572 20335 net.cpp:91] Creating Layer conv3_1
I0625 21:35:21.968575 20335 net.cpp:425] conv3_1 <- pool2
I0625 21:35:21.968580 20335 net.cpp:399] conv3_1 -> conv3_1
I0625 21:35:21.970953 20335 net.cpp:141] Setting up conv3_1
I0625 21:35:21.970966 20335 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 21:35:21.970969 20335 net.cpp:156] Memory required for data: 668336512
I0625 21:35:21.970973 20335 layer_factory.hpp:77] Creating layer bn3_1
I0625 21:35:21.970983 20335 net.cpp:91] Creating Layer bn3_1
I0625 21:35:21.970985 20335 net.cpp:425] bn3_1 <- conv3_1
I0625 21:35:21.970990 20335 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0625 21:35:21.972244 20335 net.cpp:141] Setting up bn3_1
I0625 21:35:21.972255 20335 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 21:35:21.972259 20335 net.cpp:156] Memory required for data: 681443712
I0625 21:35:21.972265 20335 layer_factory.hpp:77] Creating layer scale3_1
I0625 21:35:21.972272 20335 net.cpp:91] Creating Layer scale3_1
I0625 21:35:21.972275 20335 net.cpp:425] scale3_1 <- conv3_1
I0625 21:35:21.972278 20335 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0625 21:35:21.972313 20335 layer_factory.hpp:77] Creating layer scale3_1
I0625 21:35:21.972395 20335 net.cpp:141] Setting up scale3_1
I0625 21:35:21.972403 20335 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 21:35:21.972404 20335 net.cpp:156] Memory required for data: 694550912
I0625 21:35:21.972409 20335 layer_factory.hpp:77] Creating layer relu3_1
I0625 21:35:21.972414 20335 net.cpp:91] Creating Layer relu3_1
I0625 21:35:21.972415 20335 net.cpp:425] relu3_1 <- conv3_1
I0625 21:35:21.972420 20335 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0625 21:35:21.972560 20335 net.cpp:141] Setting up relu3_1
I0625 21:35:21.972569 20335 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 21:35:21.972573 20335 net.cpp:156] Memory required for data: 707658112
I0625 21:35:21.972574 20335 layer_factory.hpp:77] Creating layer conv3_2
I0625 21:35:21.972582 20335 net.cpp:91] Creating Layer conv3_2
I0625 21:35:21.972585 20335 net.cpp:425] conv3_2 <- conv3_1
I0625 21:35:21.972590 20335 net.cpp:399] conv3_2 -> conv3_2
I0625 21:35:21.975618 20335 net.cpp:141] Setting up conv3_2
I0625 21:35:21.975631 20335 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 21:35:21.975635 20335 net.cpp:156] Memory required for data: 720765312
I0625 21:35:21.975639 20335 layer_factory.hpp:77] Creating layer bn3_2
I0625 21:35:21.975646 20335 net.cpp:91] Creating Layer bn3_2
I0625 21:35:21.975649 20335 net.cpp:425] bn3_2 <- conv3_2
I0625 21:35:21.975657 20335 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0625 21:35:21.975836 20335 net.cpp:141] Setting up bn3_2
I0625 21:35:21.975848 20335 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 21:35:21.975852 20335 net.cpp:156] Memory required for data: 733872512
I0625 21:35:21.975867 20335 layer_factory.hpp:77] Creating layer scale3_2
I0625 21:35:21.975875 20335 net.cpp:91] Creating Layer scale3_2
I0625 21:35:21.975878 20335 net.cpp:425] scale3_2 <- conv3_2
I0625 21:35:21.975881 20335 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0625 21:35:21.975917 20335 layer_factory.hpp:77] Creating layer scale3_2
I0625 21:35:21.976002 20335 net.cpp:141] Setting up scale3_2
I0625 21:35:21.976009 20335 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 21:35:21.976011 20335 net.cpp:156] Memory required for data: 746979712
I0625 21:35:21.976016 20335 layer_factory.hpp:77] Creating layer relu3_2
I0625 21:35:21.976021 20335 net.cpp:91] Creating Layer relu3_2
I0625 21:35:21.976022 20335 net.cpp:425] relu3_2 <- conv3_2
I0625 21:35:21.976039 20335 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0625 21:35:21.976181 20335 net.cpp:141] Setting up relu3_2
I0625 21:35:21.976189 20335 net.cpp:148] Top shape: 32 128 25 32 (3276800)
I0625 21:35:21.976191 20335 net.cpp:156] Memory required for data: 760086912
I0625 21:35:21.976194 20335 layer_factory.hpp:77] Creating layer pool3
I0625 21:35:21.976200 20335 net.cpp:91] Creating Layer pool3
I0625 21:35:21.976202 20335 net.cpp:425] pool3 <- conv3_2
I0625 21:35:21.976207 20335 net.cpp:399] pool3 -> pool3
I0625 21:35:21.976243 20335 net.cpp:141] Setting up pool3
I0625 21:35:21.976248 20335 net.cpp:148] Top shape: 32 128 13 16 (851968)
I0625 21:35:21.976250 20335 net.cpp:156] Memory required for data: 763494784
I0625 21:35:21.976253 20335 layer_factory.hpp:77] Creating layer conv4_1
I0625 21:35:21.976259 20335 net.cpp:91] Creating Layer conv4_1
I0625 21:35:21.976263 20335 net.cpp:425] conv4_1 <- pool3
I0625 21:35:21.976266 20335 net.cpp:399] conv4_1 -> conv4_1
I0625 21:35:21.979094 20335 net.cpp:141] Setting up conv4_1
I0625 21:35:21.979107 20335 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 21:35:21.979110 20335 net.cpp:156] Memory required for data: 770310528
I0625 21:35:21.979115 20335 layer_factory.hpp:77] Creating layer bn4_1
I0625 21:35:21.979121 20335 net.cpp:91] Creating Layer bn4_1
I0625 21:35:21.979125 20335 net.cpp:425] bn4_1 <- conv4_1
I0625 21:35:21.979130 20335 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0625 21:35:21.979287 20335 net.cpp:141] Setting up bn4_1
I0625 21:35:21.979295 20335 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 21:35:21.979297 20335 net.cpp:156] Memory required for data: 777126272
I0625 21:35:21.979302 20335 layer_factory.hpp:77] Creating layer scale4_1
I0625 21:35:21.979308 20335 net.cpp:91] Creating Layer scale4_1
I0625 21:35:21.979311 20335 net.cpp:425] scale4_1 <- conv4_1
I0625 21:35:21.979316 20335 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0625 21:35:21.979347 20335 layer_factory.hpp:77] Creating layer scale4_1
I0625 21:35:21.979429 20335 net.cpp:141] Setting up scale4_1
I0625 21:35:21.979435 20335 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 21:35:21.979439 20335 net.cpp:156] Memory required for data: 783942016
I0625 21:35:21.979442 20335 layer_factory.hpp:77] Creating layer relu4_1
I0625 21:35:21.979450 20335 net.cpp:91] Creating Layer relu4_1
I0625 21:35:21.979454 20335 net.cpp:425] relu4_1 <- conv4_1
I0625 21:35:21.979457 20335 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0625 21:35:21.979599 20335 net.cpp:141] Setting up relu4_1
I0625 21:35:21.979607 20335 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 21:35:21.979610 20335 net.cpp:156] Memory required for data: 790757760
I0625 21:35:21.979614 20335 layer_factory.hpp:77] Creating layer conv4_2
I0625 21:35:21.979624 20335 net.cpp:91] Creating Layer conv4_2
I0625 21:35:21.979627 20335 net.cpp:425] conv4_2 <- conv4_1
I0625 21:35:21.979631 20335 net.cpp:399] conv4_2 -> conv4_2
I0625 21:35:21.985222 20335 net.cpp:141] Setting up conv4_2
I0625 21:35:21.985235 20335 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 21:35:21.985239 20335 net.cpp:156] Memory required for data: 797573504
I0625 21:35:21.985242 20335 layer_factory.hpp:77] Creating layer bn4_2
I0625 21:35:21.985249 20335 net.cpp:91] Creating Layer bn4_2
I0625 21:35:21.985256 20335 net.cpp:425] bn4_2 <- conv4_2
I0625 21:35:21.985262 20335 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0625 21:35:21.985409 20335 net.cpp:141] Setting up bn4_2
I0625 21:35:21.985415 20335 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 21:35:21.985419 20335 net.cpp:156] Memory required for data: 804389248
I0625 21:35:21.985424 20335 layer_factory.hpp:77] Creating layer scale4_2
I0625 21:35:21.985430 20335 net.cpp:91] Creating Layer scale4_2
I0625 21:35:21.985431 20335 net.cpp:425] scale4_2 <- conv4_2
I0625 21:35:21.985436 20335 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0625 21:35:21.985469 20335 layer_factory.hpp:77] Creating layer scale4_2
I0625 21:35:21.985553 20335 net.cpp:141] Setting up scale4_2
I0625 21:35:21.985568 20335 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 21:35:21.985570 20335 net.cpp:156] Memory required for data: 811204992
I0625 21:35:21.985574 20335 layer_factory.hpp:77] Creating layer relu4_2
I0625 21:35:21.985579 20335 net.cpp:91] Creating Layer relu4_2
I0625 21:35:21.985581 20335 net.cpp:425] relu4_2 <- conv4_2
I0625 21:35:21.985586 20335 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0625 21:35:21.985726 20335 net.cpp:141] Setting up relu4_2
I0625 21:35:21.985735 20335 net.cpp:148] Top shape: 32 256 13 16 (1703936)
I0625 21:35:21.985738 20335 net.cpp:156] Memory required for data: 818020736
I0625 21:35:21.985740 20335 layer_factory.hpp:77] Creating layer pool4
I0625 21:35:21.985746 20335 net.cpp:91] Creating Layer pool4
I0625 21:35:21.985749 20335 net.cpp:425] pool4 <- conv4_2
I0625 21:35:21.985754 20335 net.cpp:399] pool4 -> pool4
I0625 21:35:21.985791 20335 net.cpp:141] Setting up pool4
I0625 21:35:21.985797 20335 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 21:35:21.985800 20335 net.cpp:156] Memory required for data: 819855744
I0625 21:35:21.985802 20335 layer_factory.hpp:77] Creating layer conv5_1
I0625 21:35:21.985810 20335 net.cpp:91] Creating Layer conv5_1
I0625 21:35:21.985812 20335 net.cpp:425] conv5_1 <- pool4
I0625 21:35:21.985817 20335 net.cpp:399] conv5_1 -> conv5_1
I0625 21:35:21.991533 20335 net.cpp:141] Setting up conv5_1
I0625 21:35:21.991550 20335 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 21:35:21.991555 20335 net.cpp:156] Memory required for data: 821690752
I0625 21:35:21.991561 20335 layer_factory.hpp:77] Creating layer bn5_1
I0625 21:35:21.991571 20335 net.cpp:91] Creating Layer bn5_1
I0625 21:35:21.991575 20335 net.cpp:425] bn5_1 <- conv5_1
I0625 21:35:21.991581 20335 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0625 21:35:21.991753 20335 net.cpp:141] Setting up bn5_1
I0625 21:35:21.991761 20335 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 21:35:21.991763 20335 net.cpp:156] Memory required for data: 823525760
I0625 21:35:21.991770 20335 layer_factory.hpp:77] Creating layer scale5_1
I0625 21:35:21.991776 20335 net.cpp:91] Creating Layer scale5_1
I0625 21:35:21.991778 20335 net.cpp:425] scale5_1 <- conv5_1
I0625 21:35:21.991786 20335 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0625 21:35:21.991823 20335 layer_factory.hpp:77] Creating layer scale5_1
I0625 21:35:21.991909 20335 net.cpp:141] Setting up scale5_1
I0625 21:35:21.991914 20335 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 21:35:21.991917 20335 net.cpp:156] Memory required for data: 825360768
I0625 21:35:21.991921 20335 layer_factory.hpp:77] Creating layer relu5_1
I0625 21:35:21.991925 20335 net.cpp:91] Creating Layer relu5_1
I0625 21:35:21.991928 20335 net.cpp:425] relu5_1 <- conv5_1
I0625 21:35:21.991932 20335 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0625 21:35:21.992349 20335 net.cpp:141] Setting up relu5_1
I0625 21:35:21.992362 20335 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 21:35:21.992363 20335 net.cpp:156] Memory required for data: 827195776
I0625 21:35:21.992367 20335 layer_factory.hpp:77] Creating layer conv5_2
I0625 21:35:21.992374 20335 net.cpp:91] Creating Layer conv5_2
I0625 21:35:21.992378 20335 net.cpp:425] conv5_2 <- conv5_1
I0625 21:35:21.992383 20335 net.cpp:399] conv5_2 -> conv5_2
I0625 21:35:21.997768 20335 net.cpp:141] Setting up conv5_2
I0625 21:35:21.997781 20335 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 21:35:21.997784 20335 net.cpp:156] Memory required for data: 829030784
I0625 21:35:21.997788 20335 layer_factory.hpp:77] Creating layer bn5_2
I0625 21:35:21.997795 20335 net.cpp:91] Creating Layer bn5_2
I0625 21:35:21.997798 20335 net.cpp:425] bn5_2 <- conv5_2
I0625 21:35:21.997802 20335 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0625 21:35:21.997956 20335 net.cpp:141] Setting up bn5_2
I0625 21:35:21.997963 20335 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 21:35:21.997966 20335 net.cpp:156] Memory required for data: 830865792
I0625 21:35:21.997972 20335 layer_factory.hpp:77] Creating layer scale5_2
I0625 21:35:21.997977 20335 net.cpp:91] Creating Layer scale5_2
I0625 21:35:21.997989 20335 net.cpp:425] scale5_2 <- conv5_2
I0625 21:35:21.997995 20335 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0625 21:35:21.998028 20335 layer_factory.hpp:77] Creating layer scale5_2
I0625 21:35:21.998116 20335 net.cpp:141] Setting up scale5_2
I0625 21:35:21.998123 20335 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 21:35:21.998126 20335 net.cpp:156] Memory required for data: 832700800
I0625 21:35:21.998129 20335 layer_factory.hpp:77] Creating layer relu5_2
I0625 21:35:21.998133 20335 net.cpp:91] Creating Layer relu5_2
I0625 21:35:21.998136 20335 net.cpp:425] relu5_2 <- conv5_2
I0625 21:35:21.998141 20335 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0625 21:35:21.998546 20335 net.cpp:141] Setting up relu5_2
I0625 21:35:21.998558 20335 net.cpp:148] Top shape: 32 256 7 8 (458752)
I0625 21:35:21.998561 20335 net.cpp:156] Memory required for data: 834535808
I0625 21:35:21.998564 20335 layer_factory.hpp:77] Creating layer pool5
I0625 21:35:21.998569 20335 net.cpp:91] Creating Layer pool5
I0625 21:35:21.998572 20335 net.cpp:425] pool5 <- conv5_2
I0625 21:35:21.998579 20335 net.cpp:399] pool5 -> pool5
I0625 21:35:21.998744 20335 net.cpp:141] Setting up pool5
I0625 21:35:21.998754 20335 net.cpp:148] Top shape: 32 256 2 1 (16384)
I0625 21:35:21.998755 20335 net.cpp:156] Memory required for data: 834601344
I0625 21:35:21.998759 20335 layer_factory.hpp:77] Creating layer fc2
I0625 21:35:21.998770 20335 net.cpp:91] Creating Layer fc2
I0625 21:35:21.998775 20335 net.cpp:425] fc2 <- pool5
I0625 21:35:21.998778 20335 net.cpp:399] fc2 -> fc2
I0625 21:35:21.998872 20335 net.cpp:141] Setting up fc2
I0625 21:35:21.998878 20335 net.cpp:148] Top shape: 32 2 (64)
I0625 21:35:21.998880 20335 net.cpp:156] Memory required for data: 834601600
I0625 21:35:21.998885 20335 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0625 21:35:21.998891 20335 net.cpp:91] Creating Layer fc2_fc2_0_split
I0625 21:35:21.998893 20335 net.cpp:425] fc2_fc2_0_split <- fc2
I0625 21:35:21.998898 20335 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0625 21:35:21.998901 20335 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0625 21:35:21.998930 20335 net.cpp:141] Setting up fc2_fc2_0_split
I0625 21:35:21.998935 20335 net.cpp:148] Top shape: 32 2 (64)
I0625 21:35:21.998939 20335 net.cpp:148] Top shape: 32 2 (64)
I0625 21:35:21.998940 20335 net.cpp:156] Memory required for data: 834602112
I0625 21:35:21.998942 20335 layer_factory.hpp:77] Creating layer loss
I0625 21:35:21.998947 20335 net.cpp:91] Creating Layer loss
I0625 21:35:21.998950 20335 net.cpp:425] loss <- fc2_fc2_0_split_0
I0625 21:35:21.998952 20335 net.cpp:425] loss <- label_data_1_split_0
I0625 21:35:21.998956 20335 net.cpp:399] loss -> loss
I0625 21:35:21.998963 20335 layer_factory.hpp:77] Creating layer loss
I0625 21:35:21.999183 20335 net.cpp:141] Setting up loss
I0625 21:35:21.999192 20335 net.cpp:148] Top shape: (1)
I0625 21:35:21.999194 20335 net.cpp:151]     with loss weight 1
I0625 21:35:21.999208 20335 net.cpp:156] Memory required for data: 834602116
I0625 21:35:21.999212 20335 layer_factory.hpp:77] Creating layer accuracy
I0625 21:35:21.999217 20335 net.cpp:91] Creating Layer accuracy
I0625 21:35:21.999219 20335 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0625 21:35:21.999223 20335 net.cpp:425] accuracy <- label_data_1_split_1
I0625 21:35:21.999227 20335 net.cpp:399] accuracy -> accuracy
I0625 21:35:21.999233 20335 net.cpp:141] Setting up accuracy
I0625 21:35:21.999235 20335 net.cpp:148] Top shape: (1)
I0625 21:35:21.999238 20335 net.cpp:156] Memory required for data: 834602120
I0625 21:35:21.999240 20335 net.cpp:219] accuracy does not need backward computation.
I0625 21:35:21.999243 20335 net.cpp:217] loss needs backward computation.
I0625 21:35:21.999245 20335 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0625 21:35:21.999248 20335 net.cpp:217] fc2 needs backward computation.
I0625 21:35:21.999250 20335 net.cpp:217] pool5 needs backward computation.
I0625 21:35:21.999253 20335 net.cpp:217] relu5_2 needs backward computation.
I0625 21:35:21.999254 20335 net.cpp:217] scale5_2 needs backward computation.
I0625 21:35:21.999265 20335 net.cpp:217] bn5_2 needs backward computation.
I0625 21:35:21.999269 20335 net.cpp:217] conv5_2 needs backward computation.
I0625 21:35:21.999270 20335 net.cpp:217] relu5_1 needs backward computation.
I0625 21:35:21.999272 20335 net.cpp:217] scale5_1 needs backward computation.
I0625 21:35:21.999274 20335 net.cpp:217] bn5_1 needs backward computation.
I0625 21:35:21.999276 20335 net.cpp:217] conv5_1 needs backward computation.
I0625 21:35:21.999279 20335 net.cpp:217] pool4 needs backward computation.
I0625 21:35:21.999281 20335 net.cpp:217] relu4_2 needs backward computation.
I0625 21:35:21.999284 20335 net.cpp:217] scale4_2 needs backward computation.
I0625 21:35:21.999285 20335 net.cpp:217] bn4_2 needs backward computation.
I0625 21:35:21.999287 20335 net.cpp:217] conv4_2 needs backward computation.
I0625 21:35:21.999289 20335 net.cpp:217] relu4_1 needs backward computation.
I0625 21:35:21.999291 20335 net.cpp:217] scale4_1 needs backward computation.
I0625 21:35:21.999294 20335 net.cpp:217] bn4_1 needs backward computation.
I0625 21:35:21.999295 20335 net.cpp:217] conv4_1 needs backward computation.
I0625 21:35:21.999299 20335 net.cpp:217] pool3 needs backward computation.
I0625 21:35:21.999300 20335 net.cpp:217] relu3_2 needs backward computation.
I0625 21:35:21.999302 20335 net.cpp:217] scale3_2 needs backward computation.
I0625 21:35:21.999305 20335 net.cpp:217] bn3_2 needs backward computation.
I0625 21:35:21.999306 20335 net.cpp:217] conv3_2 needs backward computation.
I0625 21:35:21.999310 20335 net.cpp:217] relu3_1 needs backward computation.
I0625 21:35:21.999311 20335 net.cpp:217] scale3_1 needs backward computation.
I0625 21:35:21.999313 20335 net.cpp:217] bn3_1 needs backward computation.
I0625 21:35:21.999315 20335 net.cpp:217] conv3_1 needs backward computation.
I0625 21:35:21.999318 20335 net.cpp:217] pool2 needs backward computation.
I0625 21:35:21.999320 20335 net.cpp:217] relu2_2 needs backward computation.
I0625 21:35:21.999322 20335 net.cpp:217] scale2_2 needs backward computation.
I0625 21:35:21.999325 20335 net.cpp:217] bn2_2 needs backward computation.
I0625 21:35:21.999326 20335 net.cpp:217] conv2_2 needs backward computation.
I0625 21:35:21.999330 20335 net.cpp:217] relu2_1 needs backward computation.
I0625 21:35:21.999331 20335 net.cpp:217] scale2_1 needs backward computation.
I0625 21:35:21.999333 20335 net.cpp:217] bn2_1 needs backward computation.
I0625 21:35:21.999336 20335 net.cpp:217] conv2_1 needs backward computation.
I0625 21:35:21.999338 20335 net.cpp:217] pool1 needs backward computation.
I0625 21:35:21.999341 20335 net.cpp:217] relu1_2 needs backward computation.
I0625 21:35:21.999342 20335 net.cpp:217] scale1_2 needs backward computation.
I0625 21:35:21.999344 20335 net.cpp:217] bn1_2 needs backward computation.
I0625 21:35:21.999346 20335 net.cpp:217] conv1_2 needs backward computation.
I0625 21:35:21.999348 20335 net.cpp:217] relu1_1 needs backward computation.
I0625 21:35:21.999351 20335 net.cpp:217] scale1_1 needs backward computation.
I0625 21:35:21.999353 20335 net.cpp:217] bn1_1 needs backward computation.
I0625 21:35:21.999356 20335 net.cpp:217] conv1_1 needs backward computation.
I0625 21:35:21.999359 20335 net.cpp:219] label_data_1_split does not need backward computation.
I0625 21:35:21.999362 20335 net.cpp:219] data does not need backward computation.
I0625 21:35:21.999364 20335 net.cpp:261] This network produces output accuracy
I0625 21:35:21.999366 20335 net.cpp:261] This network produces output loss
I0625 21:35:21.999387 20335 net.cpp:274] Network initialization done.
I0625 21:35:22.000211 20335 solver.cpp:181] Creating test net (#0) specified by net file: models/bpnet/train_val.prototxt
I0625 21:35:22.000262 20335 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0625 21:35:22.000479 20335 net.cpp:49] Initializing net from parameters: 
name: "BPnet"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    mean_value: 100
    crop_h: 196
    crop_w: 256
  }
  data_param {
    source: "data/val_lmdb"
    batch_size: 64
    backend: LMDB
  }
}
layer {
  name: "conv1_1"
  type: "Convolution"
  bottom: "data"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 3
    kernel_size: 7
    stride: 2
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_1"
  type: "BatchNorm"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_1"
  type: "Scale"
  bottom: "conv1_1"
  top: "conv1_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_1"
  type: "ReLU"
  bottom: "conv1_1"
  top: "conv1_1"
}
layer {
  name: "conv1_2"
  type: "Convolution"
  bottom: "conv1_1"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_2"
  type: "BatchNorm"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale1_2"
  type: "Scale"
  bottom: "conv1_2"
  top: "conv1_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1_2"
  type: "ReLU"
  bottom: "conv1_2"
  top: "conv1_2"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1_2"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "conv2_1"
  top: "conv2_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "conv2_1"
  top: "conv2_1"
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "conv2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "conv2_2"
  top: "conv2_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "conv2_2"
  top: "conv2_2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2_2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_1"
  type: "BatchNorm"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_1"
  type: "Scale"
  bottom: "conv3_1"
  top: "conv3_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_1"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3_2"
  type: "BatchNorm"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale3_2"
  type: "Scale"
  bottom: "conv3_2"
  top: "conv3_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu3_2"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_2"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "conv4_1"
  top: "conv4_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "conv4_2"
  top: "conv4_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_2"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_1"
  type: "BatchNorm"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_1"
  type: "Scale"
  bottom: "conv5_1"
  top: "conv5_1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_1"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn5_2"
  type: "BatchNorm"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  param {
    lr_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "scale5_2"
  type: "Scale"
  bottom: "conv5_2"
  top: "conv5_2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 1
    decay_mult: 1
  }
  scale_param {
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu5_2"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_2"
  top: "pool5"
  pooling_param {
    pool: AVE
    stride: 1
    kernel_h: 6
    kernel_w: 8
  }
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "pool5"
  top: "fc2"
  inner_product_param {
    num_output: 2
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "fc2"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "fc2"
  bottom: "label"
  top: "accuracy"
}
I0625 21:35:22.000623 20335 layer_factory.hpp:77] Creating layer data
I0625 21:35:22.000696 20335 net.cpp:91] Creating Layer data
I0625 21:35:22.000704 20335 net.cpp:399] data -> data
I0625 21:35:22.000710 20335 net.cpp:399] data -> label
I0625 21:35:22.002063 20349 db_lmdb.cpp:35] Opened lmdb data/val_lmdb
I0625 21:35:22.002465 20335 data_layer.cpp:42] output data size: 64,3,196,256
I0625 21:35:22.082603 20335 net.cpp:141] Setting up data
I0625 21:35:22.082628 20335 net.cpp:148] Top shape: 64 3 196 256 (9633792)
I0625 21:35:22.082631 20335 net.cpp:148] Top shape: 64 (64)
I0625 21:35:22.082634 20335 net.cpp:156] Memory required for data: 38535424
I0625 21:35:22.082639 20335 layer_factory.hpp:77] Creating layer label_data_1_split
I0625 21:35:22.082650 20335 net.cpp:91] Creating Layer label_data_1_split
I0625 21:35:22.082653 20335 net.cpp:425] label_data_1_split <- label
I0625 21:35:22.082659 20335 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0625 21:35:22.082667 20335 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0625 21:35:22.082772 20335 net.cpp:141] Setting up label_data_1_split
I0625 21:35:22.082779 20335 net.cpp:148] Top shape: 64 (64)
I0625 21:35:22.082782 20335 net.cpp:148] Top shape: 64 (64)
I0625 21:35:22.082784 20335 net.cpp:156] Memory required for data: 38535936
I0625 21:35:22.082787 20335 layer_factory.hpp:77] Creating layer conv1_1
I0625 21:35:22.082800 20335 net.cpp:91] Creating Layer conv1_1
I0625 21:35:22.082805 20335 net.cpp:425] conv1_1 <- data
I0625 21:35:22.082810 20335 net.cpp:399] conv1_1 -> conv1_1
I0625 21:35:22.083937 20335 net.cpp:141] Setting up conv1_1
I0625 21:35:22.083950 20335 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 21:35:22.083953 20335 net.cpp:156] Memory required for data: 141296384
I0625 21:35:22.083961 20335 layer_factory.hpp:77] Creating layer bn1_1
I0625 21:35:22.083969 20335 net.cpp:91] Creating Layer bn1_1
I0625 21:35:22.083971 20335 net.cpp:425] bn1_1 <- conv1_1
I0625 21:35:22.083976 20335 net.cpp:386] bn1_1 -> conv1_1 (in-place)
I0625 21:35:22.084213 20335 net.cpp:141] Setting up bn1_1
I0625 21:35:22.084220 20335 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 21:35:22.084223 20335 net.cpp:156] Memory required for data: 244056832
I0625 21:35:22.084231 20335 layer_factory.hpp:77] Creating layer scale1_1
I0625 21:35:22.084239 20335 net.cpp:91] Creating Layer scale1_1
I0625 21:35:22.084241 20335 net.cpp:425] scale1_1 <- conv1_1
I0625 21:35:22.084261 20335 net.cpp:386] scale1_1 -> conv1_1 (in-place)
I0625 21:35:22.087245 20335 layer_factory.hpp:77] Creating layer scale1_1
I0625 21:35:22.087375 20335 net.cpp:141] Setting up scale1_1
I0625 21:35:22.087383 20335 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 21:35:22.087386 20335 net.cpp:156] Memory required for data: 346817280
I0625 21:35:22.087393 20335 layer_factory.hpp:77] Creating layer relu1_1
I0625 21:35:22.087400 20335 net.cpp:91] Creating Layer relu1_1
I0625 21:35:22.087404 20335 net.cpp:425] relu1_1 <- conv1_1
I0625 21:35:22.087407 20335 net.cpp:386] relu1_1 -> conv1_1 (in-place)
I0625 21:35:22.087563 20335 net.cpp:141] Setting up relu1_1
I0625 21:35:22.087571 20335 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 21:35:22.087574 20335 net.cpp:156] Memory required for data: 449577728
I0625 21:35:22.087576 20335 layer_factory.hpp:77] Creating layer conv1_2
I0625 21:35:22.087585 20335 net.cpp:91] Creating Layer conv1_2
I0625 21:35:22.087591 20335 net.cpp:425] conv1_2 <- conv1_1
I0625 21:35:22.087599 20335 net.cpp:399] conv1_2 -> conv1_2
I0625 21:35:22.088531 20335 net.cpp:141] Setting up conv1_2
I0625 21:35:22.088546 20335 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 21:35:22.088551 20335 net.cpp:156] Memory required for data: 552338176
I0625 21:35:22.088557 20335 layer_factory.hpp:77] Creating layer bn1_2
I0625 21:35:22.088568 20335 net.cpp:91] Creating Layer bn1_2
I0625 21:35:22.088577 20335 net.cpp:425] bn1_2 <- conv1_2
I0625 21:35:22.088582 20335 net.cpp:386] bn1_2 -> conv1_2 (in-place)
I0625 21:35:22.088750 20335 net.cpp:141] Setting up bn1_2
I0625 21:35:22.088757 20335 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 21:35:22.088759 20335 net.cpp:156] Memory required for data: 655098624
I0625 21:35:22.088768 20335 layer_factory.hpp:77] Creating layer scale1_2
I0625 21:35:22.088774 20335 net.cpp:91] Creating Layer scale1_2
I0625 21:35:22.088776 20335 net.cpp:425] scale1_2 <- conv1_2
I0625 21:35:22.088780 20335 net.cpp:386] scale1_2 -> conv1_2 (in-place)
I0625 21:35:22.088814 20335 layer_factory.hpp:77] Creating layer scale1_2
I0625 21:35:22.088923 20335 net.cpp:141] Setting up scale1_2
I0625 21:35:22.088932 20335 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 21:35:22.088934 20335 net.cpp:156] Memory required for data: 757859072
I0625 21:35:22.089000 20335 layer_factory.hpp:77] Creating layer relu1_2
I0625 21:35:22.089007 20335 net.cpp:91] Creating Layer relu1_2
I0625 21:35:22.089010 20335 net.cpp:425] relu1_2 <- conv1_2
I0625 21:35:22.089013 20335 net.cpp:386] relu1_2 -> conv1_2 (in-place)
I0625 21:35:22.089432 20335 net.cpp:141] Setting up relu1_2
I0625 21:35:22.089444 20335 net.cpp:148] Top shape: 64 32 98 128 (25690112)
I0625 21:35:22.089447 20335 net.cpp:156] Memory required for data: 860619520
I0625 21:35:22.089450 20335 layer_factory.hpp:77] Creating layer pool1
I0625 21:35:22.089457 20335 net.cpp:91] Creating Layer pool1
I0625 21:35:22.089459 20335 net.cpp:425] pool1 <- conv1_2
I0625 21:35:22.089464 20335 net.cpp:399] pool1 -> pool1
I0625 21:35:22.089504 20335 net.cpp:141] Setting up pool1
I0625 21:35:22.089509 20335 net.cpp:148] Top shape: 64 32 49 64 (6422528)
I0625 21:35:22.089510 20335 net.cpp:156] Memory required for data: 886309632
I0625 21:35:22.089514 20335 layer_factory.hpp:77] Creating layer conv2_1
I0625 21:35:22.089521 20335 net.cpp:91] Creating Layer conv2_1
I0625 21:35:22.089524 20335 net.cpp:425] conv2_1 <- pool1
I0625 21:35:22.089529 20335 net.cpp:399] conv2_1 -> conv2_1
I0625 21:35:22.090595 20335 net.cpp:141] Setting up conv2_1
I0625 21:35:22.090607 20335 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 21:35:22.090610 20335 net.cpp:156] Memory required for data: 937689856
I0625 21:35:22.090615 20335 layer_factory.hpp:77] Creating layer bn2_1
I0625 21:35:22.090623 20335 net.cpp:91] Creating Layer bn2_1
I0625 21:35:22.090626 20335 net.cpp:425] bn2_1 <- conv2_1
I0625 21:35:22.090631 20335 net.cpp:386] bn2_1 -> conv2_1 (in-place)
I0625 21:35:22.090795 20335 net.cpp:141] Setting up bn2_1
I0625 21:35:22.090811 20335 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 21:35:22.090813 20335 net.cpp:156] Memory required for data: 989070080
I0625 21:35:22.090819 20335 layer_factory.hpp:77] Creating layer scale2_1
I0625 21:35:22.090826 20335 net.cpp:91] Creating Layer scale2_1
I0625 21:35:22.090829 20335 net.cpp:425] scale2_1 <- conv2_1
I0625 21:35:22.090832 20335 net.cpp:386] scale2_1 -> conv2_1 (in-place)
I0625 21:35:22.090868 20335 layer_factory.hpp:77] Creating layer scale2_1
I0625 21:35:22.090965 20335 net.cpp:141] Setting up scale2_1
I0625 21:35:22.090975 20335 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 21:35:22.090977 20335 net.cpp:156] Memory required for data: 1040450304
I0625 21:35:22.090984 20335 layer_factory.hpp:77] Creating layer relu2_1
I0625 21:35:22.090988 20335 net.cpp:91] Creating Layer relu2_1
I0625 21:35:22.090991 20335 net.cpp:425] relu2_1 <- conv2_1
I0625 21:35:22.090994 20335 net.cpp:386] relu2_1 -> conv2_1 (in-place)
I0625 21:35:22.091137 20335 net.cpp:141] Setting up relu2_1
I0625 21:35:22.091145 20335 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 21:35:22.091153 20335 net.cpp:156] Memory required for data: 1091830528
I0625 21:35:22.091156 20335 layer_factory.hpp:77] Creating layer conv2_2
I0625 21:35:22.091164 20335 net.cpp:91] Creating Layer conv2_2
I0625 21:35:22.091167 20335 net.cpp:425] conv2_2 <- conv2_1
I0625 21:35:22.091172 20335 net.cpp:399] conv2_2 -> conv2_2
I0625 21:35:22.092243 20335 net.cpp:141] Setting up conv2_2
I0625 21:35:22.092257 20335 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 21:35:22.092258 20335 net.cpp:156] Memory required for data: 1143210752
I0625 21:35:22.092262 20335 layer_factory.hpp:77] Creating layer bn2_2
I0625 21:35:22.092270 20335 net.cpp:91] Creating Layer bn2_2
I0625 21:35:22.092273 20335 net.cpp:425] bn2_2 <- conv2_2
I0625 21:35:22.092278 20335 net.cpp:386] bn2_2 -> conv2_2 (in-place)
I0625 21:35:22.092438 20335 net.cpp:141] Setting up bn2_2
I0625 21:35:22.092445 20335 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 21:35:22.092447 20335 net.cpp:156] Memory required for data: 1194590976
I0625 21:35:22.092453 20335 layer_factory.hpp:77] Creating layer scale2_2
I0625 21:35:22.092458 20335 net.cpp:91] Creating Layer scale2_2
I0625 21:35:22.092460 20335 net.cpp:425] scale2_2 <- conv2_2
I0625 21:35:22.092465 20335 net.cpp:386] scale2_2 -> conv2_2 (in-place)
I0625 21:35:22.092499 20335 layer_factory.hpp:77] Creating layer scale2_2
I0625 21:35:22.092597 20335 net.cpp:141] Setting up scale2_2
I0625 21:35:22.092604 20335 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 21:35:22.092607 20335 net.cpp:156] Memory required for data: 1245971200
I0625 21:35:22.092610 20335 layer_factory.hpp:77] Creating layer relu2_2
I0625 21:35:22.092614 20335 net.cpp:91] Creating Layer relu2_2
I0625 21:35:22.092617 20335 net.cpp:425] relu2_2 <- conv2_2
I0625 21:35:22.092622 20335 net.cpp:386] relu2_2 -> conv2_2 (in-place)
I0625 21:35:22.092777 20335 net.cpp:141] Setting up relu2_2
I0625 21:35:22.092784 20335 net.cpp:148] Top shape: 64 64 49 64 (12845056)
I0625 21:35:22.092787 20335 net.cpp:156] Memory required for data: 1297351424
I0625 21:35:22.092789 20335 layer_factory.hpp:77] Creating layer pool2
I0625 21:35:22.092794 20335 net.cpp:91] Creating Layer pool2
I0625 21:35:22.092797 20335 net.cpp:425] pool2 <- conv2_2
I0625 21:35:22.092802 20335 net.cpp:399] pool2 -> pool2
I0625 21:35:22.092839 20335 net.cpp:141] Setting up pool2
I0625 21:35:22.092844 20335 net.cpp:148] Top shape: 64 64 25 32 (3276800)
I0625 21:35:22.092845 20335 net.cpp:156] Memory required for data: 1310458624
I0625 21:35:22.092847 20335 layer_factory.hpp:77] Creating layer conv3_1
I0625 21:35:22.092854 20335 net.cpp:91] Creating Layer conv3_1
I0625 21:35:22.092857 20335 net.cpp:425] conv3_1 <- pool2
I0625 21:35:22.092862 20335 net.cpp:399] conv3_1 -> conv3_1
I0625 21:35:22.095505 20335 net.cpp:141] Setting up conv3_1
I0625 21:35:22.095525 20335 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 21:35:22.095528 20335 net.cpp:156] Memory required for data: 1336673024
I0625 21:35:22.095544 20335 layer_factory.hpp:77] Creating layer bn3_1
I0625 21:35:22.095553 20335 net.cpp:91] Creating Layer bn3_1
I0625 21:35:22.095556 20335 net.cpp:425] bn3_1 <- conv3_1
I0625 21:35:22.095561 20335 net.cpp:386] bn3_1 -> conv3_1 (in-place)
I0625 21:35:22.095716 20335 net.cpp:141] Setting up bn3_1
I0625 21:35:22.095724 20335 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 21:35:22.095726 20335 net.cpp:156] Memory required for data: 1362887424
I0625 21:35:22.095731 20335 layer_factory.hpp:77] Creating layer scale3_1
I0625 21:35:22.095738 20335 net.cpp:91] Creating Layer scale3_1
I0625 21:35:22.095741 20335 net.cpp:425] scale3_1 <- conv3_1
I0625 21:35:22.095744 20335 net.cpp:386] scale3_1 -> conv3_1 (in-place)
I0625 21:35:22.095777 20335 layer_factory.hpp:77] Creating layer scale3_1
I0625 21:35:22.095868 20335 net.cpp:141] Setting up scale3_1
I0625 21:35:22.095875 20335 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 21:35:22.095877 20335 net.cpp:156] Memory required for data: 1389101824
I0625 21:35:22.095881 20335 layer_factory.hpp:77] Creating layer relu3_1
I0625 21:35:22.095885 20335 net.cpp:91] Creating Layer relu3_1
I0625 21:35:22.095888 20335 net.cpp:425] relu3_1 <- conv3_1
I0625 21:35:22.095892 20335 net.cpp:386] relu3_1 -> conv3_1 (in-place)
I0625 21:35:22.096055 20335 net.cpp:141] Setting up relu3_1
I0625 21:35:22.096063 20335 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 21:35:22.096067 20335 net.cpp:156] Memory required for data: 1415316224
I0625 21:35:22.096070 20335 layer_factory.hpp:77] Creating layer conv3_2
I0625 21:35:22.096077 20335 net.cpp:91] Creating Layer conv3_2
I0625 21:35:22.096079 20335 net.cpp:425] conv3_2 <- conv3_1
I0625 21:35:22.096084 20335 net.cpp:399] conv3_2 -> conv3_2
I0625 21:35:22.098016 20335 net.cpp:141] Setting up conv3_2
I0625 21:35:22.098027 20335 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 21:35:22.098031 20335 net.cpp:156] Memory required for data: 1441530624
I0625 21:35:22.098036 20335 layer_factory.hpp:77] Creating layer bn3_2
I0625 21:35:22.098040 20335 net.cpp:91] Creating Layer bn3_2
I0625 21:35:22.098043 20335 net.cpp:425] bn3_2 <- conv3_2
I0625 21:35:22.098047 20335 net.cpp:386] bn3_2 -> conv3_2 (in-place)
I0625 21:35:22.098209 20335 net.cpp:141] Setting up bn3_2
I0625 21:35:22.098217 20335 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 21:35:22.098218 20335 net.cpp:156] Memory required for data: 1467745024
I0625 21:35:22.098229 20335 layer_factory.hpp:77] Creating layer scale3_2
I0625 21:35:22.098235 20335 net.cpp:91] Creating Layer scale3_2
I0625 21:35:22.098238 20335 net.cpp:425] scale3_2 <- conv3_2
I0625 21:35:22.098242 20335 net.cpp:386] scale3_2 -> conv3_2 (in-place)
I0625 21:35:22.098278 20335 layer_factory.hpp:77] Creating layer scale3_2
I0625 21:35:22.098369 20335 net.cpp:141] Setting up scale3_2
I0625 21:35:22.098377 20335 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 21:35:22.098379 20335 net.cpp:156] Memory required for data: 1493959424
I0625 21:35:22.098384 20335 layer_factory.hpp:77] Creating layer relu3_2
I0625 21:35:22.098388 20335 net.cpp:91] Creating Layer relu3_2
I0625 21:35:22.098390 20335 net.cpp:425] relu3_2 <- conv3_2
I0625 21:35:22.098394 20335 net.cpp:386] relu3_2 -> conv3_2 (in-place)
I0625 21:35:22.098536 20335 net.cpp:141] Setting up relu3_2
I0625 21:35:22.098546 20335 net.cpp:148] Top shape: 64 128 25 32 (6553600)
I0625 21:35:22.098547 20335 net.cpp:156] Memory required for data: 1520173824
I0625 21:35:22.098551 20335 layer_factory.hpp:77] Creating layer pool3
I0625 21:35:22.098556 20335 net.cpp:91] Creating Layer pool3
I0625 21:35:22.098558 20335 net.cpp:425] pool3 <- conv3_2
I0625 21:35:22.098563 20335 net.cpp:399] pool3 -> pool3
I0625 21:35:22.098600 20335 net.cpp:141] Setting up pool3
I0625 21:35:22.098604 20335 net.cpp:148] Top shape: 64 128 13 16 (1703936)
I0625 21:35:22.098606 20335 net.cpp:156] Memory required for data: 1526989568
I0625 21:35:22.098608 20335 layer_factory.hpp:77] Creating layer conv4_1
I0625 21:35:22.098616 20335 net.cpp:91] Creating Layer conv4_1
I0625 21:35:22.098628 20335 net.cpp:425] conv4_1 <- pool3
I0625 21:35:22.098634 20335 net.cpp:399] conv4_1 -> conv4_1
I0625 21:35:22.101389 20335 net.cpp:141] Setting up conv4_1
I0625 21:35:22.101402 20335 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 21:35:22.101405 20335 net.cpp:156] Memory required for data: 1540621056
I0625 21:35:22.101409 20335 layer_factory.hpp:77] Creating layer bn4_1
I0625 21:35:22.101416 20335 net.cpp:91] Creating Layer bn4_1
I0625 21:35:22.101420 20335 net.cpp:425] bn4_1 <- conv4_1
I0625 21:35:22.101424 20335 net.cpp:386] bn4_1 -> conv4_1 (in-place)
I0625 21:35:22.101593 20335 net.cpp:141] Setting up bn4_1
I0625 21:35:22.101600 20335 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 21:35:22.101603 20335 net.cpp:156] Memory required for data: 1554252544
I0625 21:35:22.101608 20335 layer_factory.hpp:77] Creating layer scale4_1
I0625 21:35:22.101615 20335 net.cpp:91] Creating Layer scale4_1
I0625 21:35:22.101618 20335 net.cpp:425] scale4_1 <- conv4_1
I0625 21:35:22.101621 20335 net.cpp:386] scale4_1 -> conv4_1 (in-place)
I0625 21:35:22.101657 20335 layer_factory.hpp:77] Creating layer scale4_1
I0625 21:35:22.101749 20335 net.cpp:141] Setting up scale4_1
I0625 21:35:22.101757 20335 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 21:35:22.101758 20335 net.cpp:156] Memory required for data: 1567884032
I0625 21:35:22.101763 20335 layer_factory.hpp:77] Creating layer relu4_1
I0625 21:35:22.101771 20335 net.cpp:91] Creating Layer relu4_1
I0625 21:35:22.101773 20335 net.cpp:425] relu4_1 <- conv4_1
I0625 21:35:22.101778 20335 net.cpp:386] relu4_1 -> conv4_1 (in-place)
I0625 21:35:22.101922 20335 net.cpp:141] Setting up relu4_1
I0625 21:35:22.101929 20335 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 21:35:22.101933 20335 net.cpp:156] Memory required for data: 1581515520
I0625 21:35:22.101934 20335 layer_factory.hpp:77] Creating layer conv4_2
I0625 21:35:22.101943 20335 net.cpp:91] Creating Layer conv4_2
I0625 21:35:22.101945 20335 net.cpp:425] conv4_2 <- conv4_1
I0625 21:35:22.101949 20335 net.cpp:399] conv4_2 -> conv4_2
I0625 21:35:22.107537 20335 net.cpp:141] Setting up conv4_2
I0625 21:35:22.107552 20335 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 21:35:22.107554 20335 net.cpp:156] Memory required for data: 1595147008
I0625 21:35:22.107559 20335 layer_factory.hpp:77] Creating layer bn4_2
I0625 21:35:22.107568 20335 net.cpp:91] Creating Layer bn4_2
I0625 21:35:22.107570 20335 net.cpp:425] bn4_2 <- conv4_2
I0625 21:35:22.107578 20335 net.cpp:386] bn4_2 -> conv4_2 (in-place)
I0625 21:35:22.107744 20335 net.cpp:141] Setting up bn4_2
I0625 21:35:22.107751 20335 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 21:35:22.107754 20335 net.cpp:156] Memory required for data: 1608778496
I0625 21:35:22.107759 20335 layer_factory.hpp:77] Creating layer scale4_2
I0625 21:35:22.107767 20335 net.cpp:91] Creating Layer scale4_2
I0625 21:35:22.107770 20335 net.cpp:425] scale4_2 <- conv4_2
I0625 21:35:22.107774 20335 net.cpp:386] scale4_2 -> conv4_2 (in-place)
I0625 21:35:22.107808 20335 layer_factory.hpp:77] Creating layer scale4_2
I0625 21:35:22.107898 20335 net.cpp:141] Setting up scale4_2
I0625 21:35:22.107905 20335 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 21:35:22.107908 20335 net.cpp:156] Memory required for data: 1622409984
I0625 21:35:22.107911 20335 layer_factory.hpp:77] Creating layer relu4_2
I0625 21:35:22.107916 20335 net.cpp:91] Creating Layer relu4_2
I0625 21:35:22.107918 20335 net.cpp:425] relu4_2 <- conv4_2
I0625 21:35:22.107923 20335 net.cpp:386] relu4_2 -> conv4_2 (in-place)
I0625 21:35:22.108351 20335 net.cpp:141] Setting up relu4_2
I0625 21:35:22.108362 20335 net.cpp:148] Top shape: 64 256 13 16 (3407872)
I0625 21:35:22.108366 20335 net.cpp:156] Memory required for data: 1636041472
I0625 21:35:22.108368 20335 layer_factory.hpp:77] Creating layer pool4
I0625 21:35:22.108376 20335 net.cpp:91] Creating Layer pool4
I0625 21:35:22.108378 20335 net.cpp:425] pool4 <- conv4_2
I0625 21:35:22.108382 20335 net.cpp:399] pool4 -> pool4
I0625 21:35:22.108425 20335 net.cpp:141] Setting up pool4
I0625 21:35:22.108443 20335 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 21:35:22.108444 20335 net.cpp:156] Memory required for data: 1639711488
I0625 21:35:22.108448 20335 layer_factory.hpp:77] Creating layer conv5_1
I0625 21:35:22.108455 20335 net.cpp:91] Creating Layer conv5_1
I0625 21:35:22.108458 20335 net.cpp:425] conv5_1 <- pool4
I0625 21:35:22.108464 20335 net.cpp:399] conv5_1 -> conv5_1
I0625 21:35:22.114151 20335 net.cpp:141] Setting up conv5_1
I0625 21:35:22.114167 20335 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 21:35:22.114171 20335 net.cpp:156] Memory required for data: 1643381504
I0625 21:35:22.114176 20335 layer_factory.hpp:77] Creating layer bn5_1
I0625 21:35:22.114182 20335 net.cpp:91] Creating Layer bn5_1
I0625 21:35:22.114186 20335 net.cpp:425] bn5_1 <- conv5_1
I0625 21:35:22.114192 20335 net.cpp:386] bn5_1 -> conv5_1 (in-place)
I0625 21:35:22.114372 20335 net.cpp:141] Setting up bn5_1
I0625 21:35:22.114378 20335 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 21:35:22.114382 20335 net.cpp:156] Memory required for data: 1647051520
I0625 21:35:22.114387 20335 layer_factory.hpp:77] Creating layer scale5_1
I0625 21:35:22.114393 20335 net.cpp:91] Creating Layer scale5_1
I0625 21:35:22.114397 20335 net.cpp:425] scale5_1 <- conv5_1
I0625 21:35:22.114400 20335 net.cpp:386] scale5_1 -> conv5_1 (in-place)
I0625 21:35:22.114435 20335 layer_factory.hpp:77] Creating layer scale5_1
I0625 21:35:22.114528 20335 net.cpp:141] Setting up scale5_1
I0625 21:35:22.114534 20335 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 21:35:22.114537 20335 net.cpp:156] Memory required for data: 1650721536
I0625 21:35:22.114542 20335 layer_factory.hpp:77] Creating layer relu5_1
I0625 21:35:22.114545 20335 net.cpp:91] Creating Layer relu5_1
I0625 21:35:22.114548 20335 net.cpp:425] relu5_1 <- conv5_1
I0625 21:35:22.114552 20335 net.cpp:386] relu5_1 -> conv5_1 (in-place)
I0625 21:35:22.114702 20335 net.cpp:141] Setting up relu5_1
I0625 21:35:22.114711 20335 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 21:35:22.114713 20335 net.cpp:156] Memory required for data: 1654391552
I0625 21:35:22.114717 20335 layer_factory.hpp:77] Creating layer conv5_2
I0625 21:35:22.114725 20335 net.cpp:91] Creating Layer conv5_2
I0625 21:35:22.114728 20335 net.cpp:425] conv5_2 <- conv5_1
I0625 21:35:22.114733 20335 net.cpp:399] conv5_2 -> conv5_2
I0625 21:35:22.120518 20335 net.cpp:141] Setting up conv5_2
I0625 21:35:22.120535 20335 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 21:35:22.120538 20335 net.cpp:156] Memory required for data: 1658061568
I0625 21:35:22.120543 20335 layer_factory.hpp:77] Creating layer bn5_2
I0625 21:35:22.120553 20335 net.cpp:91] Creating Layer bn5_2
I0625 21:35:22.120555 20335 net.cpp:425] bn5_2 <- conv5_2
I0625 21:35:22.120560 20335 net.cpp:386] bn5_2 -> conv5_2 (in-place)
I0625 21:35:22.120736 20335 net.cpp:141] Setting up bn5_2
I0625 21:35:22.120744 20335 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 21:35:22.120746 20335 net.cpp:156] Memory required for data: 1661731584
I0625 21:35:22.120753 20335 layer_factory.hpp:77] Creating layer scale5_2
I0625 21:35:22.120760 20335 net.cpp:91] Creating Layer scale5_2
I0625 21:35:22.120762 20335 net.cpp:425] scale5_2 <- conv5_2
I0625 21:35:22.120766 20335 net.cpp:386] scale5_2 -> conv5_2 (in-place)
I0625 21:35:22.120802 20335 layer_factory.hpp:77] Creating layer scale5_2
I0625 21:35:22.120898 20335 net.cpp:141] Setting up scale5_2
I0625 21:35:22.120905 20335 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 21:35:22.120908 20335 net.cpp:156] Memory required for data: 1665401600
I0625 21:35:22.120913 20335 layer_factory.hpp:77] Creating layer relu5_2
I0625 21:35:22.120918 20335 net.cpp:91] Creating Layer relu5_2
I0625 21:35:22.120921 20335 net.cpp:425] relu5_2 <- conv5_2
I0625 21:35:22.120924 20335 net.cpp:386] relu5_2 -> conv5_2 (in-place)
I0625 21:35:22.121075 20335 net.cpp:141] Setting up relu5_2
I0625 21:35:22.121084 20335 net.cpp:148] Top shape: 64 256 7 8 (917504)
I0625 21:35:22.121086 20335 net.cpp:156] Memory required for data: 1669071616
I0625 21:35:22.121101 20335 layer_factory.hpp:77] Creating layer pool5
I0625 21:35:22.121107 20335 net.cpp:91] Creating Layer pool5
I0625 21:35:22.121110 20335 net.cpp:425] pool5 <- conv5_2
I0625 21:35:22.121115 20335 net.cpp:399] pool5 -> pool5
I0625 21:35:22.121347 20335 net.cpp:141] Setting up pool5
I0625 21:35:22.121357 20335 net.cpp:148] Top shape: 64 256 2 1 (32768)
I0625 21:35:22.121361 20335 net.cpp:156] Memory required for data: 1669202688
I0625 21:35:22.121363 20335 layer_factory.hpp:77] Creating layer fc2
I0625 21:35:22.121371 20335 net.cpp:91] Creating Layer fc2
I0625 21:35:22.121373 20335 net.cpp:425] fc2 <- pool5
I0625 21:35:22.121377 20335 net.cpp:399] fc2 -> fc2
I0625 21:35:22.121486 20335 net.cpp:141] Setting up fc2
I0625 21:35:22.121493 20335 net.cpp:148] Top shape: 64 2 (128)
I0625 21:35:22.121496 20335 net.cpp:156] Memory required for data: 1669203200
I0625 21:35:22.121500 20335 layer_factory.hpp:77] Creating layer fc2_fc2_0_split
I0625 21:35:22.121505 20335 net.cpp:91] Creating Layer fc2_fc2_0_split
I0625 21:35:22.121507 20335 net.cpp:425] fc2_fc2_0_split <- fc2
I0625 21:35:22.121511 20335 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_0
I0625 21:35:22.121515 20335 net.cpp:399] fc2_fc2_0_split -> fc2_fc2_0_split_1
I0625 21:35:22.121546 20335 net.cpp:141] Setting up fc2_fc2_0_split
I0625 21:35:22.121551 20335 net.cpp:148] Top shape: 64 2 (128)
I0625 21:35:22.121553 20335 net.cpp:148] Top shape: 64 2 (128)
I0625 21:35:22.121556 20335 net.cpp:156] Memory required for data: 1669204224
I0625 21:35:22.121557 20335 layer_factory.hpp:77] Creating layer loss
I0625 21:35:22.121562 20335 net.cpp:91] Creating Layer loss
I0625 21:35:22.121564 20335 net.cpp:425] loss <- fc2_fc2_0_split_0
I0625 21:35:22.121567 20335 net.cpp:425] loss <- label_data_1_split_0
I0625 21:35:22.121572 20335 net.cpp:399] loss -> loss
I0625 21:35:22.121577 20335 layer_factory.hpp:77] Creating layer loss
I0625 21:35:22.122090 20335 net.cpp:141] Setting up loss
I0625 21:35:22.122102 20335 net.cpp:148] Top shape: (1)
I0625 21:35:22.122105 20335 net.cpp:151]     with loss weight 1
I0625 21:35:22.122113 20335 net.cpp:156] Memory required for data: 1669204228
I0625 21:35:22.122117 20335 layer_factory.hpp:77] Creating layer accuracy
I0625 21:35:22.122122 20335 net.cpp:91] Creating Layer accuracy
I0625 21:35:22.122124 20335 net.cpp:425] accuracy <- fc2_fc2_0_split_1
I0625 21:35:22.122129 20335 net.cpp:425] accuracy <- label_data_1_split_1
I0625 21:35:22.122133 20335 net.cpp:399] accuracy -> accuracy
I0625 21:35:22.122139 20335 net.cpp:141] Setting up accuracy
I0625 21:35:22.122143 20335 net.cpp:148] Top shape: (1)
I0625 21:35:22.122144 20335 net.cpp:156] Memory required for data: 1669204232
I0625 21:35:22.122146 20335 net.cpp:219] accuracy does not need backward computation.
I0625 21:35:22.122149 20335 net.cpp:217] loss needs backward computation.
I0625 21:35:22.122153 20335 net.cpp:217] fc2_fc2_0_split needs backward computation.
I0625 21:35:22.122154 20335 net.cpp:217] fc2 needs backward computation.
I0625 21:35:22.122156 20335 net.cpp:217] pool5 needs backward computation.
I0625 21:35:22.122159 20335 net.cpp:217] relu5_2 needs backward computation.
I0625 21:35:22.122161 20335 net.cpp:217] scale5_2 needs backward computation.
I0625 21:35:22.122162 20335 net.cpp:217] bn5_2 needs backward computation.
I0625 21:35:22.122164 20335 net.cpp:217] conv5_2 needs backward computation.
I0625 21:35:22.122167 20335 net.cpp:217] relu5_1 needs backward computation.
I0625 21:35:22.122169 20335 net.cpp:217] scale5_1 needs backward computation.
I0625 21:35:22.122172 20335 net.cpp:217] bn5_1 needs backward computation.
I0625 21:35:22.122174 20335 net.cpp:217] conv5_1 needs backward computation.
I0625 21:35:22.122176 20335 net.cpp:217] pool4 needs backward computation.
I0625 21:35:22.122179 20335 net.cpp:217] relu4_2 needs backward computation.
I0625 21:35:22.122181 20335 net.cpp:217] scale4_2 needs backward computation.
I0625 21:35:22.122184 20335 net.cpp:217] bn4_2 needs backward computation.
I0625 21:35:22.122185 20335 net.cpp:217] conv4_2 needs backward computation.
I0625 21:35:22.122197 20335 net.cpp:217] relu4_1 needs backward computation.
I0625 21:35:22.122200 20335 net.cpp:217] scale4_1 needs backward computation.
I0625 21:35:22.122202 20335 net.cpp:217] bn4_1 needs backward computation.
I0625 21:35:22.122205 20335 net.cpp:217] conv4_1 needs backward computation.
I0625 21:35:22.122206 20335 net.cpp:217] pool3 needs backward computation.
I0625 21:35:22.122210 20335 net.cpp:217] relu3_2 needs backward computation.
I0625 21:35:22.122211 20335 net.cpp:217] scale3_2 needs backward computation.
I0625 21:35:22.122213 20335 net.cpp:217] bn3_2 needs backward computation.
I0625 21:35:22.122216 20335 net.cpp:217] conv3_2 needs backward computation.
I0625 21:35:22.122218 20335 net.cpp:217] relu3_1 needs backward computation.
I0625 21:35:22.122220 20335 net.cpp:217] scale3_1 needs backward computation.
I0625 21:35:22.122222 20335 net.cpp:217] bn3_1 needs backward computation.
I0625 21:35:22.122225 20335 net.cpp:217] conv3_1 needs backward computation.
I0625 21:35:22.122227 20335 net.cpp:217] pool2 needs backward computation.
I0625 21:35:22.122229 20335 net.cpp:217] relu2_2 needs backward computation.
I0625 21:35:22.122231 20335 net.cpp:217] scale2_2 needs backward computation.
I0625 21:35:22.122234 20335 net.cpp:217] bn2_2 needs backward computation.
I0625 21:35:22.122236 20335 net.cpp:217] conv2_2 needs backward computation.
I0625 21:35:22.122238 20335 net.cpp:217] relu2_1 needs backward computation.
I0625 21:35:22.122241 20335 net.cpp:217] scale2_1 needs backward computation.
I0625 21:35:22.122243 20335 net.cpp:217] bn2_1 needs backward computation.
I0625 21:35:22.122246 20335 net.cpp:217] conv2_1 needs backward computation.
I0625 21:35:22.122247 20335 net.cpp:217] pool1 needs backward computation.
I0625 21:35:22.122251 20335 net.cpp:217] relu1_2 needs backward computation.
I0625 21:35:22.122252 20335 net.cpp:217] scale1_2 needs backward computation.
I0625 21:35:22.122254 20335 net.cpp:217] bn1_2 needs backward computation.
I0625 21:35:22.122256 20335 net.cpp:217] conv1_2 needs backward computation.
I0625 21:35:22.122258 20335 net.cpp:217] relu1_1 needs backward computation.
I0625 21:35:22.122262 20335 net.cpp:217] scale1_1 needs backward computation.
I0625 21:35:22.122263 20335 net.cpp:217] bn1_1 needs backward computation.
I0625 21:35:22.122265 20335 net.cpp:217] conv1_1 needs backward computation.
I0625 21:35:22.122268 20335 net.cpp:219] label_data_1_split does not need backward computation.
I0625 21:35:22.122272 20335 net.cpp:219] data does not need backward computation.
I0625 21:35:22.122274 20335 net.cpp:261] This network produces output accuracy
I0625 21:35:22.122277 20335 net.cpp:261] This network produces output loss
I0625 21:35:22.122295 20335 net.cpp:274] Network initialization done.
I0625 21:35:22.122434 20335 solver.cpp:60] Solver scaffolding done.
I0625 21:35:22.124227 20335 caffe.cpp:219] Starting Optimization
I0625 21:35:22.124233 20335 solver.cpp:279] Solving BPnet
I0625 21:35:22.124236 20335 solver.cpp:280] Learning Rate Policy: step
I0625 21:35:22.126330 20335 solver.cpp:337] Iteration 0, Testing net (#0)
I0625 21:35:22.128424 20335 blocking_queue.cpp:50] Data layer prefetch queue empty
I0625 21:35:25.182785 20335 solver.cpp:404]     Test net output #0: accuracy = 0.472412
I0625 21:35:25.182813 20335 solver.cpp:404]     Test net output #1: loss = 0.693147 (* 1 = 0.693147 loss)
I0625 21:35:25.271005 20335 solver.cpp:228] Iteration 0, loss = 0.693147
I0625 21:35:25.271029 20335 solver.cpp:244]     Train net output #0: accuracy = 0.4375
I0625 21:35:25.271036 20335 solver.cpp:244]     Train net output #1: loss = 0.693147 (* 1 = 0.693147 loss)
I0625 21:35:25.271054 20335 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I0625 21:35:26.805616 20335 solver.cpp:228] Iteration 20, loss = 0.680086
I0625 21:35:26.805651 20335 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0625 21:35:26.805658 20335 solver.cpp:244]     Train net output #1: loss = 0.680086 (* 1 = 0.680086 loss)
I0625 21:35:26.805662 20335 sgd_solver.cpp:106] Iteration 20, lr = 0.001
I0625 21:35:28.390554 20335 solver.cpp:228] Iteration 40, loss = 0.633582
I0625 21:35:28.390609 20335 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 21:35:28.390617 20335 solver.cpp:244]     Train net output #1: loss = 0.633582 (* 1 = 0.633582 loss)
I0625 21:35:28.390622 20335 sgd_solver.cpp:106] Iteration 40, lr = 0.001
I0625 21:35:29.973247 20335 solver.cpp:228] Iteration 60, loss = 0.665738
I0625 21:35:29.973280 20335 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 21:35:29.973289 20335 solver.cpp:244]     Train net output #1: loss = 0.665738 (* 1 = 0.665738 loss)
I0625 21:35:29.973292 20335 sgd_solver.cpp:106] Iteration 60, lr = 0.001
I0625 21:35:31.550611 20335 solver.cpp:228] Iteration 80, loss = 0.685316
I0625 21:35:31.550645 20335 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0625 21:35:31.550653 20335 solver.cpp:244]     Train net output #1: loss = 0.685316 (* 1 = 0.685316 loss)
I0625 21:35:31.550657 20335 sgd_solver.cpp:106] Iteration 80, lr = 0.001
I0625 21:35:33.127517 20335 solver.cpp:337] Iteration 100, Testing net (#0)
I0625 21:35:36.207612 20335 solver.cpp:404]     Test net output #0: accuracy = 0.503418
I0625 21:35:36.207654 20335 solver.cpp:404]     Test net output #1: loss = 0.67545 (* 1 = 0.67545 loss)
I0625 21:35:36.234833 20335 solver.cpp:228] Iteration 100, loss = 0.627064
I0625 21:35:36.234861 20335 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 21:35:36.234869 20335 solver.cpp:244]     Train net output #1: loss = 0.627064 (* 1 = 0.627064 loss)
I0625 21:35:36.234874 20335 sgd_solver.cpp:106] Iteration 100, lr = 0.001
I0625 21:35:37.818698 20335 solver.cpp:228] Iteration 120, loss = 0.632681
I0625 21:35:37.818733 20335 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0625 21:35:37.818740 20335 solver.cpp:244]     Train net output #1: loss = 0.632681 (* 1 = 0.632681 loss)
I0625 21:35:37.818744 20335 sgd_solver.cpp:106] Iteration 120, lr = 0.001
I0625 21:35:39.395979 20335 solver.cpp:228] Iteration 140, loss = 0.639734
I0625 21:35:39.396014 20335 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0625 21:35:39.396021 20335 solver.cpp:244]     Train net output #1: loss = 0.639734 (* 1 = 0.639734 loss)
I0625 21:35:39.396026 20335 sgd_solver.cpp:106] Iteration 140, lr = 0.001
I0625 21:35:40.973570 20335 solver.cpp:228] Iteration 160, loss = 0.614081
I0625 21:35:40.973608 20335 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0625 21:35:40.973615 20335 solver.cpp:244]     Train net output #1: loss = 0.614081 (* 1 = 0.614081 loss)
I0625 21:35:40.973620 20335 sgd_solver.cpp:106] Iteration 160, lr = 0.001
I0625 21:35:42.551295 20335 solver.cpp:228] Iteration 180, loss = 0.604316
I0625 21:35:42.551324 20335 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 21:35:42.551331 20335 solver.cpp:244]     Train net output #1: loss = 0.604316 (* 1 = 0.604316 loss)
I0625 21:35:42.551337 20335 sgd_solver.cpp:106] Iteration 180, lr = 0.001
I0625 21:35:44.106395 20335 solver.cpp:337] Iteration 200, Testing net (#0)
I0625 21:35:47.042641 20335 solver.cpp:404]     Test net output #0: accuracy = 0.510254
I0625 21:35:47.042685 20335 solver.cpp:404]     Test net output #1: loss = 0.708387 (* 1 = 0.708387 loss)
I0625 21:35:47.070237 20335 solver.cpp:228] Iteration 200, loss = 0.702856
I0625 21:35:47.070266 20335 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0625 21:35:47.070274 20335 solver.cpp:244]     Train net output #1: loss = 0.702856 (* 1 = 0.702856 loss)
I0625 21:35:47.070279 20335 sgd_solver.cpp:106] Iteration 200, lr = 0.001
I0625 21:35:48.656538 20335 solver.cpp:228] Iteration 220, loss = 0.684367
I0625 21:35:48.656563 20335 solver.cpp:244]     Train net output #0: accuracy = 0.5
I0625 21:35:48.656570 20335 solver.cpp:244]     Train net output #1: loss = 0.684367 (* 1 = 0.684367 loss)
I0625 21:35:48.656575 20335 sgd_solver.cpp:106] Iteration 220, lr = 0.001
I0625 21:35:50.235817 20335 solver.cpp:228] Iteration 240, loss = 0.654688
I0625 21:35:50.235843 20335 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0625 21:35:50.235872 20335 solver.cpp:244]     Train net output #1: loss = 0.654688 (* 1 = 0.654688 loss)
I0625 21:35:50.235877 20335 sgd_solver.cpp:106] Iteration 240, lr = 0.001
I0625 21:35:51.814788 20335 solver.cpp:228] Iteration 260, loss = 0.54137
I0625 21:35:51.814944 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:35:51.814954 20335 solver.cpp:244]     Train net output #1: loss = 0.54137 (* 1 = 0.54137 loss)
I0625 21:35:51.814959 20335 sgd_solver.cpp:106] Iteration 260, lr = 0.001
I0625 21:35:53.396975 20335 solver.cpp:228] Iteration 280, loss = 0.544077
I0625 21:35:53.397008 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:35:53.397016 20335 solver.cpp:244]     Train net output #1: loss = 0.544077 (* 1 = 0.544077 loss)
I0625 21:35:53.397020 20335 sgd_solver.cpp:106] Iteration 280, lr = 0.001
I0625 21:35:54.959679 20335 solver.cpp:337] Iteration 300, Testing net (#0)
I0625 21:35:57.996021 20335 solver.cpp:404]     Test net output #0: accuracy = 0.526855
I0625 21:35:57.996054 20335 solver.cpp:404]     Test net output #1: loss = 0.714126 (* 1 = 0.714126 loss)
I0625 21:35:58.023607 20335 solver.cpp:228] Iteration 300, loss = 0.551522
I0625 21:35:58.023638 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:35:58.023644 20335 solver.cpp:244]     Train net output #1: loss = 0.551522 (* 1 = 0.551522 loss)
I0625 21:35:58.023650 20335 sgd_solver.cpp:106] Iteration 300, lr = 0.001
I0625 21:35:59.704833 20335 solver.cpp:228] Iteration 320, loss = 0.590015
I0625 21:35:59.704857 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:35:59.704864 20335 solver.cpp:244]     Train net output #1: loss = 0.590015 (* 1 = 0.590015 loss)
I0625 21:35:59.704869 20335 sgd_solver.cpp:106] Iteration 320, lr = 0.001
I0625 21:36:01.376271 20335 solver.cpp:228] Iteration 340, loss = 0.620788
I0625 21:36:01.376296 20335 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0625 21:36:01.376303 20335 solver.cpp:244]     Train net output #1: loss = 0.620788 (* 1 = 0.620788 loss)
I0625 21:36:01.376308 20335 sgd_solver.cpp:106] Iteration 340, lr = 0.001
I0625 21:36:03.028686 20335 solver.cpp:228] Iteration 360, loss = 0.58641
I0625 21:36:03.028712 20335 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 21:36:03.028719 20335 solver.cpp:244]     Train net output #1: loss = 0.58641 (* 1 = 0.58641 loss)
I0625 21:36:03.028723 20335 sgd_solver.cpp:106] Iteration 360, lr = 0.001
I0625 21:36:04.615456 20335 solver.cpp:228] Iteration 380, loss = 0.534022
I0625 21:36:04.615491 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:36:04.615499 20335 solver.cpp:244]     Train net output #1: loss = 0.534022 (* 1 = 0.534022 loss)
I0625 21:36:04.615504 20335 sgd_solver.cpp:106] Iteration 380, lr = 0.001
I0625 21:36:06.177652 20335 solver.cpp:337] Iteration 400, Testing net (#0)
I0625 21:36:09.116397 20335 solver.cpp:404]     Test net output #0: accuracy = 0.516357
I0625 21:36:09.116428 20335 solver.cpp:404]     Test net output #1: loss = 0.762351 (* 1 = 0.762351 loss)
I0625 21:36:09.143965 20335 solver.cpp:228] Iteration 400, loss = 0.571721
I0625 21:36:09.143996 20335 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 21:36:09.144004 20335 solver.cpp:244]     Train net output #1: loss = 0.571721 (* 1 = 0.571721 loss)
I0625 21:36:09.144011 20335 sgd_solver.cpp:106] Iteration 400, lr = 0.001
I0625 21:36:10.737864 20335 solver.cpp:228] Iteration 420, loss = 0.484495
I0625 21:36:10.737887 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:36:10.737895 20335 solver.cpp:244]     Train net output #1: loss = 0.484495 (* 1 = 0.484495 loss)
I0625 21:36:10.737900 20335 sgd_solver.cpp:106] Iteration 420, lr = 0.001
I0625 21:36:12.325165 20335 solver.cpp:228] Iteration 440, loss = 0.643672
I0625 21:36:12.325201 20335 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0625 21:36:12.325207 20335 solver.cpp:244]     Train net output #1: loss = 0.643672 (* 1 = 0.643672 loss)
I0625 21:36:12.325212 20335 sgd_solver.cpp:106] Iteration 440, lr = 0.001
I0625 21:36:13.912008 20335 solver.cpp:228] Iteration 460, loss = 0.604039
I0625 21:36:13.912032 20335 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0625 21:36:13.912040 20335 solver.cpp:244]     Train net output #1: loss = 0.604039 (* 1 = 0.604039 loss)
I0625 21:36:13.912066 20335 sgd_solver.cpp:106] Iteration 460, lr = 0.001
I0625 21:36:15.504712 20335 solver.cpp:228] Iteration 480, loss = 0.513422
I0625 21:36:15.504748 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:36:15.504755 20335 solver.cpp:244]     Train net output #1: loss = 0.513422 (* 1 = 0.513422 loss)
I0625 21:36:15.504760 20335 sgd_solver.cpp:106] Iteration 480, lr = 0.001
I0625 21:36:17.111865 20335 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_500.caffemodel
I0625 21:36:17.140725 20335 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_500.solverstate
I0625 21:36:17.151865 20335 solver.cpp:337] Iteration 500, Testing net (#0)
I0625 21:36:20.096820 20335 solver.cpp:404]     Test net output #0: accuracy = 0.580322
I0625 21:36:20.096863 20335 solver.cpp:404]     Test net output #1: loss = 0.69741 (* 1 = 0.69741 loss)
I0625 21:36:20.124516 20335 solver.cpp:228] Iteration 500, loss = 0.662153
I0625 21:36:20.124543 20335 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0625 21:36:20.124552 20335 solver.cpp:244]     Train net output #1: loss = 0.662153 (* 1 = 0.662153 loss)
I0625 21:36:20.124555 20335 sgd_solver.cpp:106] Iteration 500, lr = 0.001
I0625 21:36:21.765723 20335 solver.cpp:228] Iteration 520, loss = 0.509967
I0625 21:36:21.765758 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:36:21.765765 20335 solver.cpp:244]     Train net output #1: loss = 0.509967 (* 1 = 0.509967 loss)
I0625 21:36:21.765769 20335 sgd_solver.cpp:106] Iteration 520, lr = 0.001
I0625 21:36:23.364238 20335 solver.cpp:228] Iteration 540, loss = 0.559581
I0625 21:36:23.364359 20335 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 21:36:23.364369 20335 solver.cpp:244]     Train net output #1: loss = 0.559581 (* 1 = 0.559581 loss)
I0625 21:36:23.364375 20335 sgd_solver.cpp:106] Iteration 540, lr = 0.001
I0625 21:36:24.966328 20335 solver.cpp:228] Iteration 560, loss = 0.537043
I0625 21:36:24.966363 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:36:24.966370 20335 solver.cpp:244]     Train net output #1: loss = 0.537043 (* 1 = 0.537043 loss)
I0625 21:36:24.966375 20335 sgd_solver.cpp:106] Iteration 560, lr = 0.001
I0625 21:36:26.560925 20335 solver.cpp:228] Iteration 580, loss = 0.539169
I0625 21:36:26.560950 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:36:26.560958 20335 solver.cpp:244]     Train net output #1: loss = 0.539169 (* 1 = 0.539169 loss)
I0625 21:36:26.560962 20335 sgd_solver.cpp:106] Iteration 580, lr = 0.001
I0625 21:36:28.124697 20335 solver.cpp:337] Iteration 600, Testing net (#0)
I0625 21:36:31.111733 20335 solver.cpp:404]     Test net output #0: accuracy = 0.609863
I0625 21:36:31.111763 20335 solver.cpp:404]     Test net output #1: loss = 0.673852 (* 1 = 0.673852 loss)
I0625 21:36:31.139382 20335 solver.cpp:228] Iteration 600, loss = 0.460783
I0625 21:36:31.139407 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:36:31.139415 20335 solver.cpp:244]     Train net output #1: loss = 0.460783 (* 1 = 0.460783 loss)
I0625 21:36:31.139420 20335 sgd_solver.cpp:106] Iteration 600, lr = 0.001
I0625 21:36:32.756276 20335 solver.cpp:228] Iteration 620, loss = 0.667045
I0625 21:36:32.756302 20335 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0625 21:36:32.756309 20335 solver.cpp:244]     Train net output #1: loss = 0.667045 (* 1 = 0.667045 loss)
I0625 21:36:32.756314 20335 sgd_solver.cpp:106] Iteration 620, lr = 0.001
I0625 21:36:34.366224 20335 solver.cpp:228] Iteration 640, loss = 0.578691
I0625 21:36:34.366255 20335 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 21:36:34.366264 20335 solver.cpp:244]     Train net output #1: loss = 0.578691 (* 1 = 0.578691 loss)
I0625 21:36:34.366269 20335 sgd_solver.cpp:106] Iteration 640, lr = 0.001
I0625 21:36:35.967602 20335 solver.cpp:228] Iteration 660, loss = 0.454433
I0625 21:36:35.967639 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:36:35.967648 20335 solver.cpp:244]     Train net output #1: loss = 0.454433 (* 1 = 0.454433 loss)
I0625 21:36:35.967653 20335 sgd_solver.cpp:106] Iteration 660, lr = 0.001
I0625 21:36:37.573185 20335 solver.cpp:228] Iteration 680, loss = 0.494503
I0625 21:36:37.573210 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:36:37.573217 20335 solver.cpp:244]     Train net output #1: loss = 0.494503 (* 1 = 0.494503 loss)
I0625 21:36:37.573221 20335 sgd_solver.cpp:106] Iteration 680, lr = 0.001
I0625 21:36:39.176080 20335 solver.cpp:337] Iteration 700, Testing net (#0)
I0625 21:36:42.110183 20335 solver.cpp:404]     Test net output #0: accuracy = 0.594971
I0625 21:36:42.110216 20335 solver.cpp:404]     Test net output #1: loss = 0.711373 (* 1 = 0.711373 loss)
I0625 21:36:42.137814 20335 solver.cpp:228] Iteration 700, loss = 0.58068
I0625 21:36:42.137846 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:36:42.137853 20335 solver.cpp:244]     Train net output #1: loss = 0.58068 (* 1 = 0.58068 loss)
I0625 21:36:42.137859 20335 sgd_solver.cpp:106] Iteration 700, lr = 0.001
I0625 21:36:43.780161 20335 solver.cpp:228] Iteration 720, loss = 0.415157
I0625 21:36:43.780199 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:36:43.780205 20335 solver.cpp:244]     Train net output #1: loss = 0.415157 (* 1 = 0.415157 loss)
I0625 21:36:43.780210 20335 sgd_solver.cpp:106] Iteration 720, lr = 0.001
I0625 21:36:45.408347 20335 solver.cpp:228] Iteration 740, loss = 0.631468
I0625 21:36:45.408371 20335 solver.cpp:244]     Train net output #0: accuracy = 0.59375
I0625 21:36:45.408390 20335 solver.cpp:244]     Train net output #1: loss = 0.631468 (* 1 = 0.631468 loss)
I0625 21:36:45.408421 20335 sgd_solver.cpp:106] Iteration 740, lr = 0.001
I0625 21:36:47.027467 20335 solver.cpp:228] Iteration 760, loss = 0.562177
I0625 21:36:47.027500 20335 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0625 21:36:47.027508 20335 solver.cpp:244]     Train net output #1: loss = 0.562177 (* 1 = 0.562177 loss)
I0625 21:36:47.027513 20335 sgd_solver.cpp:106] Iteration 760, lr = 0.001
I0625 21:36:48.644781 20335 solver.cpp:228] Iteration 780, loss = 0.496058
I0625 21:36:48.644806 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:36:48.644814 20335 solver.cpp:244]     Train net output #1: loss = 0.496058 (* 1 = 0.496058 loss)
I0625 21:36:48.644819 20335 sgd_solver.cpp:106] Iteration 780, lr = 0.001
I0625 21:36:50.218845 20335 solver.cpp:337] Iteration 800, Testing net (#0)
I0625 21:36:53.227926 20335 solver.cpp:404]     Test net output #0: accuracy = 0.608643
I0625 21:36:53.227955 20335 solver.cpp:404]     Test net output #1: loss = 0.7071 (* 1 = 0.7071 loss)
I0625 21:36:53.255599 20335 solver.cpp:228] Iteration 800, loss = 0.630808
I0625 21:36:53.255625 20335 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 21:36:53.255633 20335 solver.cpp:244]     Train net output #1: loss = 0.630808 (* 1 = 0.630808 loss)
I0625 21:36:53.255640 20335 sgd_solver.cpp:106] Iteration 800, lr = 0.001
I0625 21:36:54.855726 20335 solver.cpp:228] Iteration 820, loss = 0.514984
I0625 21:36:54.855839 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:36:54.855850 20335 solver.cpp:244]     Train net output #1: loss = 0.514984 (* 1 = 0.514984 loss)
I0625 21:36:54.855856 20335 sgd_solver.cpp:106] Iteration 820, lr = 0.001
I0625 21:36:56.456661 20335 solver.cpp:228] Iteration 840, loss = 0.748498
I0625 21:36:56.456697 20335 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0625 21:36:56.456706 20335 solver.cpp:244]     Train net output #1: loss = 0.748498 (* 1 = 0.748498 loss)
I0625 21:36:56.456709 20335 sgd_solver.cpp:106] Iteration 840, lr = 0.001
I0625 21:36:58.073896 20335 solver.cpp:228] Iteration 860, loss = 0.546445
I0625 21:36:58.073922 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:36:58.073930 20335 solver.cpp:244]     Train net output #1: loss = 0.546445 (* 1 = 0.546445 loss)
I0625 21:36:58.073933 20335 sgd_solver.cpp:106] Iteration 860, lr = 0.001
I0625 21:36:59.693903 20335 solver.cpp:228] Iteration 880, loss = 0.502681
I0625 21:36:59.693928 20335 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 21:36:59.693935 20335 solver.cpp:244]     Train net output #1: loss = 0.502681 (* 1 = 0.502681 loss)
I0625 21:36:59.693940 20335 sgd_solver.cpp:106] Iteration 880, lr = 0.001
I0625 21:37:01.265419 20335 solver.cpp:337] Iteration 900, Testing net (#0)
I0625 21:37:04.258039 20335 solver.cpp:404]     Test net output #0: accuracy = 0.624756
I0625 21:37:04.258071 20335 solver.cpp:404]     Test net output #1: loss = 0.649136 (* 1 = 0.649136 loss)
I0625 21:37:04.288678 20335 solver.cpp:228] Iteration 900, loss = 0.413834
I0625 21:37:04.288709 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:37:04.288717 20335 solver.cpp:244]     Train net output #1: loss = 0.413834 (* 1 = 0.413834 loss)
I0625 21:37:04.288722 20335 sgd_solver.cpp:106] Iteration 900, lr = 0.001
I0625 21:37:05.904368 20335 solver.cpp:228] Iteration 920, loss = 0.639461
I0625 21:37:05.904405 20335 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0625 21:37:05.904412 20335 solver.cpp:244]     Train net output #1: loss = 0.639461 (* 1 = 0.639461 loss)
I0625 21:37:05.904417 20335 sgd_solver.cpp:106] Iteration 920, lr = 0.001
I0625 21:37:07.499240 20335 solver.cpp:228] Iteration 940, loss = 0.450408
I0625 21:37:07.499279 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:37:07.499286 20335 solver.cpp:244]     Train net output #1: loss = 0.450408 (* 1 = 0.450408 loss)
I0625 21:37:07.499290 20335 sgd_solver.cpp:106] Iteration 940, lr = 0.001
I0625 21:37:09.089864 20335 solver.cpp:228] Iteration 960, loss = 0.472244
I0625 21:37:09.089887 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:37:09.089895 20335 solver.cpp:244]     Train net output #1: loss = 0.472244 (* 1 = 0.472244 loss)
I0625 21:37:09.089900 20335 sgd_solver.cpp:106] Iteration 960, lr = 0.001
I0625 21:37:10.701581 20335 solver.cpp:228] Iteration 980, loss = 0.513843
I0625 21:37:10.701603 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:37:10.701611 20335 solver.cpp:244]     Train net output #1: loss = 0.513843 (* 1 = 0.513843 loss)
I0625 21:37:10.701617 20335 sgd_solver.cpp:106] Iteration 980, lr = 0.001
I0625 21:37:12.281572 20335 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_1000.caffemodel
I0625 21:37:12.303105 20335 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_1000.solverstate
I0625 21:37:12.314312 20335 solver.cpp:337] Iteration 1000, Testing net (#0)
I0625 21:37:15.441313 20335 solver.cpp:404]     Test net output #0: accuracy = 0.556396
I0625 21:37:15.441342 20335 solver.cpp:404]     Test net output #1: loss = 0.781889 (* 1 = 0.781889 loss)
I0625 21:37:15.469252 20335 solver.cpp:228] Iteration 1000, loss = 0.593274
I0625 21:37:15.469280 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:37:15.469287 20335 solver.cpp:244]     Train net output #1: loss = 0.593274 (* 1 = 0.593274 loss)
I0625 21:37:15.469293 20335 sgd_solver.cpp:106] Iteration 1000, lr = 0.001
I0625 21:37:17.171129 20335 solver.cpp:228] Iteration 1020, loss = 0.327529
I0625 21:37:17.171169 20335 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 21:37:17.171176 20335 solver.cpp:244]     Train net output #1: loss = 0.327529 (* 1 = 0.327529 loss)
I0625 21:37:17.171180 20335 sgd_solver.cpp:106] Iteration 1020, lr = 0.001
I0625 21:37:18.848659 20335 solver.cpp:228] Iteration 1040, loss = 0.50947
I0625 21:37:18.848686 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:37:18.848693 20335 solver.cpp:244]     Train net output #1: loss = 0.50947 (* 1 = 0.50947 loss)
I0625 21:37:18.848698 20335 sgd_solver.cpp:106] Iteration 1040, lr = 0.001
I0625 21:37:20.576467 20335 solver.cpp:228] Iteration 1060, loss = 0.445437
I0625 21:37:20.576490 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:37:20.576498 20335 solver.cpp:244]     Train net output #1: loss = 0.445437 (* 1 = 0.445437 loss)
I0625 21:37:20.576501 20335 sgd_solver.cpp:106] Iteration 1060, lr = 0.001
I0625 21:37:22.265687 20335 solver.cpp:228] Iteration 1080, loss = 0.499136
I0625 21:37:22.265714 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:37:22.265720 20335 solver.cpp:244]     Train net output #1: loss = 0.499136 (* 1 = 0.499136 loss)
I0625 21:37:22.265725 20335 sgd_solver.cpp:106] Iteration 1080, lr = 0.001
I0625 21:37:23.932135 20335 solver.cpp:337] Iteration 1100, Testing net (#0)
I0625 21:37:27.183856 20335 solver.cpp:404]     Test net output #0: accuracy = 0.638428
I0625 21:37:27.183974 20335 solver.cpp:404]     Test net output #1: loss = 0.704532 (* 1 = 0.704532 loss)
I0625 21:37:27.212432 20335 solver.cpp:228] Iteration 1100, loss = 0.487987
I0625 21:37:27.212460 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:37:27.212468 20335 solver.cpp:244]     Train net output #1: loss = 0.487987 (* 1 = 0.487987 loss)
I0625 21:37:27.212473 20335 sgd_solver.cpp:106] Iteration 1100, lr = 0.001
I0625 21:37:28.925545 20335 solver.cpp:228] Iteration 1120, loss = 0.564801
I0625 21:37:28.925570 20335 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 21:37:28.925577 20335 solver.cpp:244]     Train net output #1: loss = 0.564801 (* 1 = 0.564801 loss)
I0625 21:37:28.925582 20335 sgd_solver.cpp:106] Iteration 1120, lr = 0.001
I0625 21:37:30.594419 20335 solver.cpp:228] Iteration 1140, loss = 0.67954
I0625 21:37:30.594444 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:37:30.594449 20335 solver.cpp:244]     Train net output #1: loss = 0.67954 (* 1 = 0.67954 loss)
I0625 21:37:30.594455 20335 sgd_solver.cpp:106] Iteration 1140, lr = 0.001
I0625 21:37:32.202740 20335 solver.cpp:228] Iteration 1160, loss = 0.454228
I0625 21:37:32.202769 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:37:32.202776 20335 solver.cpp:244]     Train net output #1: loss = 0.454228 (* 1 = 0.454228 loss)
I0625 21:37:32.202780 20335 sgd_solver.cpp:106] Iteration 1160, lr = 0.001
I0625 21:37:33.797386 20335 solver.cpp:228] Iteration 1180, loss = 0.472871
I0625 21:37:33.797411 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:37:33.797420 20335 solver.cpp:244]     Train net output #1: loss = 0.472871 (* 1 = 0.472871 loss)
I0625 21:37:33.797423 20335 sgd_solver.cpp:106] Iteration 1180, lr = 0.001
I0625 21:37:35.385470 20335 solver.cpp:337] Iteration 1200, Testing net (#0)
I0625 21:37:38.486163 20335 solver.cpp:404]     Test net output #0: accuracy = 0.675537
I0625 21:37:38.486198 20335 solver.cpp:404]     Test net output #1: loss = 0.648628 (* 1 = 0.648628 loss)
I0625 21:37:38.514679 20335 solver.cpp:228] Iteration 1200, loss = 0.417989
I0625 21:37:38.514708 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:37:38.514716 20335 solver.cpp:244]     Train net output #1: loss = 0.417989 (* 1 = 0.417989 loss)
I0625 21:37:38.514722 20335 sgd_solver.cpp:106] Iteration 1200, lr = 0.001
I0625 21:37:40.122015 20335 solver.cpp:228] Iteration 1220, loss = 0.615693
I0625 21:37:40.122051 20335 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0625 21:37:40.122058 20335 solver.cpp:244]     Train net output #1: loss = 0.615693 (* 1 = 0.615693 loss)
I0625 21:37:40.122063 20335 sgd_solver.cpp:106] Iteration 1220, lr = 0.001
I0625 21:37:41.717128 20335 solver.cpp:228] Iteration 1240, loss = 0.473427
I0625 21:37:41.717154 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:37:41.717160 20335 solver.cpp:244]     Train net output #1: loss = 0.473427 (* 1 = 0.473427 loss)
I0625 21:37:41.717165 20335 sgd_solver.cpp:106] Iteration 1240, lr = 0.001
I0625 21:37:43.342705 20335 solver.cpp:228] Iteration 1260, loss = 0.396803
I0625 21:37:43.342730 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:37:43.342737 20335 solver.cpp:244]     Train net output #1: loss = 0.396803 (* 1 = 0.396803 loss)
I0625 21:37:43.342741 20335 sgd_solver.cpp:106] Iteration 1260, lr = 0.001
I0625 21:37:45.027871 20335 solver.cpp:228] Iteration 1280, loss = 0.590677
I0625 21:37:45.027897 20335 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 21:37:45.027905 20335 solver.cpp:244]     Train net output #1: loss = 0.590677 (* 1 = 0.590677 loss)
I0625 21:37:45.027910 20335 sgd_solver.cpp:106] Iteration 1280, lr = 0.001
I0625 21:37:46.614318 20335 solver.cpp:337] Iteration 1300, Testing net (#0)
I0625 21:37:49.644270 20335 solver.cpp:404]     Test net output #0: accuracy = 0.635254
I0625 21:37:49.644301 20335 solver.cpp:404]     Test net output #1: loss = 0.731083 (* 1 = 0.731083 loss)
I0625 21:37:49.673730 20335 solver.cpp:228] Iteration 1300, loss = 0.579461
I0625 21:37:49.673760 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:37:49.673770 20335 solver.cpp:244]     Train net output #1: loss = 0.579461 (* 1 = 0.579461 loss)
I0625 21:37:49.673779 20335 sgd_solver.cpp:106] Iteration 1300, lr = 0.001
I0625 21:37:51.381726 20335 solver.cpp:228] Iteration 1320, loss = 0.303386
I0625 21:37:51.381754 20335 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 21:37:51.381765 20335 solver.cpp:244]     Train net output #1: loss = 0.303386 (* 1 = 0.303386 loss)
I0625 21:37:51.381772 20335 sgd_solver.cpp:106] Iteration 1320, lr = 0.001
I0625 21:37:53.078114 20335 solver.cpp:228] Iteration 1340, loss = 0.484424
I0625 21:37:53.078142 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:37:53.078152 20335 solver.cpp:244]     Train net output #1: loss = 0.484424 (* 1 = 0.484424 loss)
I0625 21:37:53.078161 20335 sgd_solver.cpp:106] Iteration 1340, lr = 0.001
I0625 21:37:54.706249 20335 solver.cpp:228] Iteration 1360, loss = 0.38343
I0625 21:37:54.706276 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:37:54.706286 20335 solver.cpp:244]     Train net output #1: loss = 0.38343 (* 1 = 0.38343 loss)
I0625 21:37:54.706293 20335 sgd_solver.cpp:106] Iteration 1360, lr = 0.001
I0625 21:37:56.332859 20335 solver.cpp:228] Iteration 1380, loss = 0.476476
I0625 21:37:56.332885 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:37:56.332896 20335 solver.cpp:244]     Train net output #1: loss = 0.476476 (* 1 = 0.476476 loss)
I0625 21:37:56.332902 20335 sgd_solver.cpp:106] Iteration 1380, lr = 0.001
I0625 21:37:57.928231 20335 solver.cpp:337] Iteration 1400, Testing net (#0)
I0625 21:38:00.980878 20335 solver.cpp:404]     Test net output #0: accuracy = 0.678955
I0625 21:38:00.980909 20335 solver.cpp:404]     Test net output #1: loss = 0.671612 (* 1 = 0.671612 loss)
I0625 21:38:01.009569 20335 solver.cpp:228] Iteration 1400, loss = 0.553569
I0625 21:38:01.009596 20335 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 21:38:01.009606 20335 solver.cpp:244]     Train net output #1: loss = 0.553569 (* 1 = 0.553569 loss)
I0625 21:38:01.009614 20335 sgd_solver.cpp:106] Iteration 1400, lr = 0.001
I0625 21:38:02.672173 20335 solver.cpp:228] Iteration 1420, loss = 0.530159
I0625 21:38:02.672199 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:38:02.672209 20335 solver.cpp:244]     Train net output #1: loss = 0.530159 (* 1 = 0.530159 loss)
I0625 21:38:02.672216 20335 sgd_solver.cpp:106] Iteration 1420, lr = 0.001
I0625 21:38:04.325119 20335 solver.cpp:228] Iteration 1440, loss = 0.741254
I0625 21:38:04.325144 20335 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0625 21:38:04.325153 20335 solver.cpp:244]     Train net output #1: loss = 0.741254 (* 1 = 0.741254 loss)
I0625 21:38:04.325160 20335 sgd_solver.cpp:106] Iteration 1440, lr = 0.001
I0625 21:38:05.988219 20335 solver.cpp:228] Iteration 1460, loss = 0.373965
I0625 21:38:05.988245 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:38:05.988255 20335 solver.cpp:244]     Train net output #1: loss = 0.373965 (* 1 = 0.373965 loss)
I0625 21:38:05.988262 20335 sgd_solver.cpp:106] Iteration 1460, lr = 0.001
I0625 21:38:07.656589 20335 solver.cpp:228] Iteration 1480, loss = 0.50147
I0625 21:38:07.656615 20335 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 21:38:07.656625 20335 solver.cpp:244]     Train net output #1: loss = 0.50147 (* 1 = 0.50147 loss)
I0625 21:38:07.656633 20335 sgd_solver.cpp:106] Iteration 1480, lr = 0.001
I0625 21:38:09.287963 20335 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_1500.caffemodel
I0625 21:38:09.309675 20335 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_1500.solverstate
I0625 21:38:09.321415 20335 solver.cpp:337] Iteration 1500, Testing net (#0)
I0625 21:38:12.322481 20335 solver.cpp:404]     Test net output #0: accuracy = 0.69165
I0625 21:38:12.322511 20335 solver.cpp:404]     Test net output #1: loss = 0.624849 (* 1 = 0.624849 loss)
I0625 21:38:12.350617 20335 solver.cpp:228] Iteration 1500, loss = 0.393848
I0625 21:38:12.350646 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:38:12.350657 20335 solver.cpp:244]     Train net output #1: loss = 0.393848 (* 1 = 0.393848 loss)
I0625 21:38:12.350666 20335 sgd_solver.cpp:106] Iteration 1500, lr = 0.001
I0625 21:38:14.012506 20335 solver.cpp:228] Iteration 1520, loss = 0.458604
I0625 21:38:14.012532 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:38:14.012542 20335 solver.cpp:244]     Train net output #1: loss = 0.458604 (* 1 = 0.458604 loss)
I0625 21:38:14.012549 20335 sgd_solver.cpp:106] Iteration 1520, lr = 0.001
I0625 21:38:15.667212 20335 solver.cpp:228] Iteration 1540, loss = 0.506554
I0625 21:38:15.667240 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:38:15.667251 20335 solver.cpp:244]     Train net output #1: loss = 0.506554 (* 1 = 0.506554 loss)
I0625 21:38:15.667258 20335 sgd_solver.cpp:106] Iteration 1540, lr = 0.001
I0625 21:38:17.321084 20335 solver.cpp:228] Iteration 1560, loss = 0.409057
I0625 21:38:17.321108 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:38:17.321118 20335 solver.cpp:244]     Train net output #1: loss = 0.409057 (* 1 = 0.409057 loss)
I0625 21:38:17.321125 20335 sgd_solver.cpp:106] Iteration 1560, lr = 0.001
I0625 21:38:18.975226 20335 solver.cpp:228] Iteration 1580, loss = 0.511968
I0625 21:38:18.975251 20335 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 21:38:18.975261 20335 solver.cpp:244]     Train net output #1: loss = 0.511968 (* 1 = 0.511968 loss)
I0625 21:38:18.975268 20335 sgd_solver.cpp:106] Iteration 1580, lr = 0.001
I0625 21:38:20.605204 20335 solver.cpp:337] Iteration 1600, Testing net (#0)
I0625 21:38:23.709282 20335 solver.cpp:404]     Test net output #0: accuracy = 0.622803
I0625 21:38:23.709311 20335 solver.cpp:404]     Test net output #1: loss = 0.791419 (* 1 = 0.791419 loss)
I0625 21:38:23.738052 20335 solver.cpp:228] Iteration 1600, loss = 0.529218
I0625 21:38:23.738077 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:38:23.738085 20335 solver.cpp:244]     Train net output #1: loss = 0.529218 (* 1 = 0.529218 loss)
I0625 21:38:23.738090 20335 sgd_solver.cpp:106] Iteration 1600, lr = 0.001
I0625 21:38:25.402189 20335 solver.cpp:228] Iteration 1620, loss = 0.476719
I0625 21:38:25.402217 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:38:25.402225 20335 solver.cpp:244]     Train net output #1: loss = 0.476719 (* 1 = 0.476719 loss)
I0625 21:38:25.402230 20335 sgd_solver.cpp:106] Iteration 1620, lr = 0.001
I0625 21:38:27.057968 20335 solver.cpp:228] Iteration 1640, loss = 0.445263
I0625 21:38:27.057993 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:38:27.058001 20335 solver.cpp:244]     Train net output #1: loss = 0.445263 (* 1 = 0.445263 loss)
I0625 21:38:27.058006 20335 sgd_solver.cpp:106] Iteration 1640, lr = 0.001
I0625 21:38:28.712819 20335 solver.cpp:228] Iteration 1660, loss = 0.350351
I0625 21:38:28.712942 20335 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 21:38:28.712954 20335 solver.cpp:244]     Train net output #1: loss = 0.350351 (* 1 = 0.350351 loss)
I0625 21:38:28.712957 20335 sgd_solver.cpp:106] Iteration 1660, lr = 0.001
I0625 21:38:30.383249 20335 solver.cpp:228] Iteration 1680, loss = 0.4274
I0625 21:38:30.383273 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:38:30.383280 20335 solver.cpp:244]     Train net output #1: loss = 0.4274 (* 1 = 0.4274 loss)
I0625 21:38:30.383285 20335 sgd_solver.cpp:106] Iteration 1680, lr = 0.001
I0625 21:38:32.028937 20335 solver.cpp:337] Iteration 1700, Testing net (#0)
I0625 21:38:35.129099 20335 solver.cpp:404]     Test net output #0: accuracy = 0.682373
I0625 21:38:35.129139 20335 solver.cpp:404]     Test net output #1: loss = 0.702742 (* 1 = 0.702742 loss)
I0625 21:38:35.157549 20335 solver.cpp:228] Iteration 1700, loss = 0.507162
I0625 21:38:35.157574 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:38:35.157580 20335 solver.cpp:244]     Train net output #1: loss = 0.507162 (* 1 = 0.507162 loss)
I0625 21:38:35.157587 20335 sgd_solver.cpp:106] Iteration 1700, lr = 0.001
I0625 21:38:36.826290 20335 solver.cpp:228] Iteration 1720, loss = 0.504204
I0625 21:38:36.826326 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:38:36.826334 20335 solver.cpp:244]     Train net output #1: loss = 0.504204 (* 1 = 0.504204 loss)
I0625 21:38:36.826339 20335 sgd_solver.cpp:106] Iteration 1720, lr = 0.001
I0625 21:38:38.489672 20335 solver.cpp:228] Iteration 1740, loss = 0.669202
I0625 21:38:38.489697 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:38:38.489706 20335 solver.cpp:244]     Train net output #1: loss = 0.669202 (* 1 = 0.669202 loss)
I0625 21:38:38.489711 20335 sgd_solver.cpp:106] Iteration 1740, lr = 0.001
I0625 21:38:40.148092 20335 solver.cpp:228] Iteration 1760, loss = 0.409154
I0625 21:38:40.148118 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:38:40.148124 20335 solver.cpp:244]     Train net output #1: loss = 0.409154 (* 1 = 0.409154 loss)
I0625 21:38:40.148129 20335 sgd_solver.cpp:106] Iteration 1760, lr = 0.001
I0625 21:38:41.810817 20335 solver.cpp:228] Iteration 1780, loss = 0.498232
I0625 21:38:41.810842 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:38:41.810849 20335 solver.cpp:244]     Train net output #1: loss = 0.498232 (* 1 = 0.498232 loss)
I0625 21:38:41.810854 20335 sgd_solver.cpp:106] Iteration 1780, lr = 0.001
I0625 21:38:43.444300 20335 solver.cpp:337] Iteration 1800, Testing net (#0)
I0625 21:38:46.316828 20335 blocking_queue.cpp:50] Data layer prefetch queue empty
I0625 21:38:46.559640 20335 solver.cpp:404]     Test net output #0: accuracy = 0.710938
I0625 21:38:46.559669 20335 solver.cpp:404]     Test net output #1: loss = 0.632363 (* 1 = 0.632363 loss)
I0625 21:38:46.588371 20335 solver.cpp:228] Iteration 1800, loss = 0.410018
I0625 21:38:46.588395 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:38:46.588402 20335 solver.cpp:244]     Train net output #1: loss = 0.410018 (* 1 = 0.410018 loss)
I0625 21:38:46.588407 20335 sgd_solver.cpp:106] Iteration 1800, lr = 0.001
I0625 21:38:48.258500 20335 solver.cpp:228] Iteration 1820, loss = 0.48902
I0625 21:38:48.258525 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:38:48.258533 20335 solver.cpp:244]     Train net output #1: loss = 0.48902 (* 1 = 0.48902 loss)
I0625 21:38:48.258538 20335 sgd_solver.cpp:106] Iteration 1820, lr = 0.001
I0625 21:38:49.921161 20335 solver.cpp:228] Iteration 1840, loss = 0.452699
I0625 21:38:49.921186 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:38:49.921193 20335 solver.cpp:244]     Train net output #1: loss = 0.452699 (* 1 = 0.452699 loss)
I0625 21:38:49.921197 20335 sgd_solver.cpp:106] Iteration 1840, lr = 0.001
I0625 21:38:51.581867 20335 solver.cpp:228] Iteration 1860, loss = 0.6152
I0625 21:38:51.581902 20335 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 21:38:51.581930 20335 solver.cpp:244]     Train net output #1: loss = 0.6152 (* 1 = 0.6152 loss)
I0625 21:38:51.581936 20335 sgd_solver.cpp:106] Iteration 1860, lr = 0.001
I0625 21:38:53.244644 20335 solver.cpp:228] Iteration 1880, loss = 0.451466
I0625 21:38:53.244683 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:38:53.244689 20335 solver.cpp:244]     Train net output #1: loss = 0.451466 (* 1 = 0.451466 loss)
I0625 21:38:53.244693 20335 sgd_solver.cpp:106] Iteration 1880, lr = 0.001
I0625 21:38:54.879840 20335 solver.cpp:337] Iteration 1900, Testing net (#0)
I0625 21:38:57.989593 20335 solver.cpp:404]     Test net output #0: accuracy = 0.656738
I0625 21:38:57.989621 20335 solver.cpp:404]     Test net output #1: loss = 0.736563 (* 1 = 0.736563 loss)
I0625 21:38:58.018493 20335 solver.cpp:228] Iteration 1900, loss = 0.494976
I0625 21:38:58.018522 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:38:58.018529 20335 solver.cpp:244]     Train net output #1: loss = 0.494976 (* 1 = 0.494976 loss)
I0625 21:38:58.018534 20335 sgd_solver.cpp:106] Iteration 1900, lr = 0.001
I0625 21:38:59.687527 20335 solver.cpp:228] Iteration 1920, loss = 0.431266
I0625 21:38:59.687669 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:38:59.687680 20335 solver.cpp:244]     Train net output #1: loss = 0.431266 (* 1 = 0.431266 loss)
I0625 21:38:59.687685 20335 sgd_solver.cpp:106] Iteration 1920, lr = 0.001
I0625 21:39:01.350149 20335 solver.cpp:228] Iteration 1940, loss = 0.497889
I0625 21:39:01.350175 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:39:01.350183 20335 solver.cpp:244]     Train net output #1: loss = 0.497889 (* 1 = 0.497889 loss)
I0625 21:39:01.350186 20335 sgd_solver.cpp:106] Iteration 1940, lr = 0.001
I0625 21:39:03.013810 20335 solver.cpp:228] Iteration 1960, loss = 0.272666
I0625 21:39:03.013834 20335 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0625 21:39:03.013841 20335 solver.cpp:244]     Train net output #1: loss = 0.272666 (* 1 = 0.272666 loss)
I0625 21:39:03.013846 20335 sgd_solver.cpp:106] Iteration 1960, lr = 0.001
I0625 21:39:04.675963 20335 solver.cpp:228] Iteration 1980, loss = 0.342765
I0625 21:39:04.675998 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:39:04.676007 20335 solver.cpp:244]     Train net output #1: loss = 0.342765 (* 1 = 0.342765 loss)
I0625 21:39:04.676012 20335 sgd_solver.cpp:106] Iteration 1980, lr = 0.001
I0625 21:39:06.345155 20335 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_2000.caffemodel
I0625 21:39:06.366608 20335 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_2000.solverstate
I0625 21:39:06.378070 20335 solver.cpp:337] Iteration 2000, Testing net (#0)
I0625 21:39:09.505491 20335 solver.cpp:404]     Test net output #0: accuracy = 0.665283
I0625 21:39:09.505520 20335 solver.cpp:404]     Test net output #1: loss = 0.690666 (* 1 = 0.690666 loss)
I0625 21:39:09.534126 20335 solver.cpp:228] Iteration 2000, loss = 0.452851
I0625 21:39:09.534154 20335 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 21:39:09.534162 20335 solver.cpp:244]     Train net output #1: loss = 0.452851 (* 1 = 0.452851 loss)
I0625 21:39:09.534167 20335 sgd_solver.cpp:106] Iteration 2000, lr = 0.0001
I0625 21:39:11.202608 20335 solver.cpp:228] Iteration 2020, loss = 0.367578
I0625 21:39:11.202633 20335 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 21:39:11.202641 20335 solver.cpp:244]     Train net output #1: loss = 0.367578 (* 1 = 0.367578 loss)
I0625 21:39:11.202646 20335 sgd_solver.cpp:106] Iteration 2020, lr = 0.0001
I0625 21:39:12.863322 20335 solver.cpp:228] Iteration 2040, loss = 0.536162
I0625 21:39:12.863345 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:39:12.863353 20335 solver.cpp:244]     Train net output #1: loss = 0.536162 (* 1 = 0.536162 loss)
I0625 21:39:12.863358 20335 sgd_solver.cpp:106] Iteration 2040, lr = 0.0001
I0625 21:39:14.528383 20335 solver.cpp:228] Iteration 2060, loss = 0.58785
I0625 21:39:14.528409 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:39:14.528415 20335 solver.cpp:244]     Train net output #1: loss = 0.58785 (* 1 = 0.58785 loss)
I0625 21:39:14.528420 20335 sgd_solver.cpp:106] Iteration 2060, lr = 0.0001
I0625 21:39:16.191941 20335 solver.cpp:228] Iteration 2080, loss = 0.466001
I0625 21:39:16.191967 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:39:16.191984 20335 solver.cpp:244]     Train net output #1: loss = 0.466001 (* 1 = 0.466001 loss)
I0625 21:39:16.191988 20335 sgd_solver.cpp:106] Iteration 2080, lr = 0.0001
I0625 21:39:17.828596 20335 solver.cpp:337] Iteration 2100, Testing net (#0)
I0625 21:39:20.906208 20335 solver.cpp:404]     Test net output #0: accuracy = 0.68042
I0625 21:39:20.906236 20335 solver.cpp:404]     Test net output #1: loss = 0.660664 (* 1 = 0.660664 loss)
I0625 21:39:20.934521 20335 solver.cpp:228] Iteration 2100, loss = 0.416661
I0625 21:39:20.934551 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:39:20.934557 20335 solver.cpp:244]     Train net output #1: loss = 0.416661 (* 1 = 0.416661 loss)
I0625 21:39:20.934586 20335 sgd_solver.cpp:106] Iteration 2100, lr = 0.0001
I0625 21:39:22.599995 20335 solver.cpp:228] Iteration 2120, loss = 0.558746
I0625 21:39:22.600018 20335 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 21:39:22.600025 20335 solver.cpp:244]     Train net output #1: loss = 0.558746 (* 1 = 0.558746 loss)
I0625 21:39:22.600030 20335 sgd_solver.cpp:106] Iteration 2120, lr = 0.0001
I0625 21:39:24.257401 20335 solver.cpp:228] Iteration 2140, loss = 0.431407
I0625 21:39:24.257424 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:39:24.257431 20335 solver.cpp:244]     Train net output #1: loss = 0.431407 (* 1 = 0.431407 loss)
I0625 21:39:24.257436 20335 sgd_solver.cpp:106] Iteration 2140, lr = 0.0001
I0625 21:39:25.915105 20335 solver.cpp:228] Iteration 2160, loss = 0.502171
I0625 21:39:25.915128 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:39:25.915135 20335 solver.cpp:244]     Train net output #1: loss = 0.502171 (* 1 = 0.502171 loss)
I0625 21:39:25.915139 20335 sgd_solver.cpp:106] Iteration 2160, lr = 0.0001
I0625 21:39:27.573668 20335 solver.cpp:228] Iteration 2180, loss = 0.481985
I0625 21:39:27.573690 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:39:27.573698 20335 solver.cpp:244]     Train net output #1: loss = 0.481985 (* 1 = 0.481985 loss)
I0625 21:39:27.573703 20335 sgd_solver.cpp:106] Iteration 2180, lr = 0.0001
I0625 21:39:29.208274 20335 solver.cpp:337] Iteration 2200, Testing net (#0)
I0625 21:39:32.315438 20335 solver.cpp:404]     Test net output #0: accuracy = 0.689941
I0625 21:39:32.315546 20335 solver.cpp:404]     Test net output #1: loss = 0.652296 (* 1 = 0.652296 loss)
I0625 21:39:32.344228 20335 solver.cpp:228] Iteration 2200, loss = 0.363784
I0625 21:39:32.344255 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:39:32.344262 20335 solver.cpp:244]     Train net output #1: loss = 0.363784 (* 1 = 0.363784 loss)
I0625 21:39:32.344267 20335 sgd_solver.cpp:106] Iteration 2200, lr = 0.0001
I0625 21:39:34.010082 20335 solver.cpp:228] Iteration 2220, loss = 0.516235
I0625 21:39:34.010105 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:39:34.010113 20335 solver.cpp:244]     Train net output #1: loss = 0.516235 (* 1 = 0.516235 loss)
I0625 21:39:34.010118 20335 sgd_solver.cpp:106] Iteration 2220, lr = 0.0001
I0625 21:39:35.666191 20335 solver.cpp:228] Iteration 2240, loss = 0.609339
I0625 21:39:35.666214 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:39:35.666221 20335 solver.cpp:244]     Train net output #1: loss = 0.609339 (* 1 = 0.609339 loss)
I0625 21:39:35.666225 20335 sgd_solver.cpp:106] Iteration 2240, lr = 0.0001
I0625 21:39:37.322957 20335 solver.cpp:228] Iteration 2260, loss = 0.359876
I0625 21:39:37.322978 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:39:37.322986 20335 solver.cpp:244]     Train net output #1: loss = 0.359876 (* 1 = 0.359876 loss)
I0625 21:39:37.322990 20335 sgd_solver.cpp:106] Iteration 2260, lr = 0.0001
I0625 21:39:38.982532 20335 solver.cpp:228] Iteration 2280, loss = 0.371871
I0625 21:39:38.982556 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:39:38.982563 20335 solver.cpp:244]     Train net output #1: loss = 0.371871 (* 1 = 0.371871 loss)
I0625 21:39:38.982568 20335 sgd_solver.cpp:106] Iteration 2280, lr = 0.0001
I0625 21:39:40.615458 20335 solver.cpp:337] Iteration 2300, Testing net (#0)
I0625 21:39:43.859210 20335 solver.cpp:404]     Test net output #0: accuracy = 0.675537
I0625 21:39:43.859238 20335 solver.cpp:404]     Test net output #1: loss = 0.68532 (* 1 = 0.68532 loss)
I0625 21:39:43.887959 20335 solver.cpp:228] Iteration 2300, loss = 0.633955
I0625 21:39:43.887989 20335 solver.cpp:244]     Train net output #0: accuracy = 0.5625
I0625 21:39:43.887995 20335 solver.cpp:244]     Train net output #1: loss = 0.633955 (* 1 = 0.633955 loss)
I0625 21:39:43.888000 20335 sgd_solver.cpp:106] Iteration 2300, lr = 0.0001
I0625 21:39:45.551167 20335 solver.cpp:228] Iteration 2320, loss = 0.381632
I0625 21:39:45.551189 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:39:45.551197 20335 solver.cpp:244]     Train net output #1: loss = 0.381632 (* 1 = 0.381632 loss)
I0625 21:39:45.551201 20335 sgd_solver.cpp:106] Iteration 2320, lr = 0.0001
I0625 21:39:47.207643 20335 solver.cpp:228] Iteration 2340, loss = 0.43581
I0625 21:39:47.207669 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:39:47.207675 20335 solver.cpp:244]     Train net output #1: loss = 0.43581 (* 1 = 0.43581 loss)
I0625 21:39:47.207679 20335 sgd_solver.cpp:106] Iteration 2340, lr = 0.0001
I0625 21:39:48.870851 20335 solver.cpp:228] Iteration 2360, loss = 0.548694
I0625 21:39:48.870879 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:39:48.870889 20335 solver.cpp:244]     Train net output #1: loss = 0.548694 (* 1 = 0.548694 loss)
I0625 21:39:48.870896 20335 sgd_solver.cpp:106] Iteration 2360, lr = 0.0001
I0625 21:39:50.531707 20335 solver.cpp:228] Iteration 2380, loss = 0.461223
I0625 21:39:50.531730 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:39:50.531738 20335 solver.cpp:244]     Train net output #1: loss = 0.461223 (* 1 = 0.461223 loss)
I0625 21:39:50.531743 20335 sgd_solver.cpp:106] Iteration 2380, lr = 0.0001
I0625 21:39:52.171748 20335 solver.cpp:337] Iteration 2400, Testing net (#0)
I0625 21:39:55.285341 20335 solver.cpp:404]     Test net output #0: accuracy = 0.685059
I0625 21:39:55.285368 20335 solver.cpp:404]     Test net output #1: loss = 0.679395 (* 1 = 0.679395 loss)
I0625 21:39:55.314064 20335 solver.cpp:228] Iteration 2400, loss = 0.361152
I0625 21:39:55.314090 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:39:55.314097 20335 solver.cpp:244]     Train net output #1: loss = 0.361152 (* 1 = 0.361152 loss)
I0625 21:39:55.314102 20335 sgd_solver.cpp:106] Iteration 2400, lr = 0.0001
I0625 21:39:56.986614 20335 solver.cpp:228] Iteration 2420, loss = 0.557436
I0625 21:39:56.986639 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:39:56.986646 20335 solver.cpp:244]     Train net output #1: loss = 0.557436 (* 1 = 0.557436 loss)
I0625 21:39:56.986650 20335 sgd_solver.cpp:106] Iteration 2420, lr = 0.0001
I0625 21:39:58.650189 20335 solver.cpp:228] Iteration 2440, loss = 0.3421
I0625 21:39:58.650213 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:39:58.650219 20335 solver.cpp:244]     Train net output #1: loss = 0.3421 (* 1 = 0.3421 loss)
I0625 21:39:58.650223 20335 sgd_solver.cpp:106] Iteration 2440, lr = 0.0001
I0625 21:40:00.309604 20335 solver.cpp:228] Iteration 2460, loss = 0.627373
I0625 21:40:00.309630 20335 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 21:40:00.309638 20335 solver.cpp:244]     Train net output #1: loss = 0.627373 (* 1 = 0.627373 loss)
I0625 21:40:00.309643 20335 sgd_solver.cpp:106] Iteration 2460, lr = 0.0001
I0625 21:40:01.969401 20335 solver.cpp:228] Iteration 2480, loss = 0.395831
I0625 21:40:01.969429 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:40:01.969436 20335 solver.cpp:244]     Train net output #1: loss = 0.395831 (* 1 = 0.395831 loss)
I0625 21:40:01.969442 20335 sgd_solver.cpp:106] Iteration 2480, lr = 0.0001
I0625 21:40:03.608651 20335 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_2500.caffemodel
I0625 21:40:03.630132 20335 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_2500.solverstate
I0625 21:40:03.641746 20335 solver.cpp:337] Iteration 2500, Testing net (#0)
I0625 21:40:06.760164 20335 solver.cpp:404]     Test net output #0: accuracy = 0.684814
I0625 21:40:06.760200 20335 solver.cpp:404]     Test net output #1: loss = 0.657503 (* 1 = 0.657503 loss)
I0625 21:40:06.788714 20335 solver.cpp:228] Iteration 2500, loss = 0.394893
I0625 21:40:06.788739 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:40:06.788746 20335 solver.cpp:244]     Train net output #1: loss = 0.394893 (* 1 = 0.394893 loss)
I0625 21:40:06.788753 20335 sgd_solver.cpp:106] Iteration 2500, lr = 0.0001
I0625 21:40:08.459998 20335 solver.cpp:228] Iteration 2520, loss = 0.458877
I0625 21:40:08.460022 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:40:08.460029 20335 solver.cpp:244]     Train net output #1: loss = 0.458877 (* 1 = 0.458877 loss)
I0625 21:40:08.460034 20335 sgd_solver.cpp:106] Iteration 2520, lr = 0.0001
I0625 21:40:10.120008 20335 solver.cpp:228] Iteration 2540, loss = 0.594028
I0625 21:40:10.120035 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:40:10.120043 20335 solver.cpp:244]     Train net output #1: loss = 0.594028 (* 1 = 0.594028 loss)
I0625 21:40:10.120046 20335 sgd_solver.cpp:106] Iteration 2540, lr = 0.0001
I0625 21:40:11.784176 20335 solver.cpp:228] Iteration 2560, loss = 0.41116
I0625 21:40:11.784200 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:40:11.784207 20335 solver.cpp:244]     Train net output #1: loss = 0.41116 (* 1 = 0.41116 loss)
I0625 21:40:11.784219 20335 sgd_solver.cpp:106] Iteration 2560, lr = 0.0001
I0625 21:40:13.447707 20335 solver.cpp:228] Iteration 2580, loss = 0.325538
I0625 21:40:13.447731 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:40:13.447749 20335 solver.cpp:244]     Train net output #1: loss = 0.325538 (* 1 = 0.325538 loss)
I0625 21:40:13.447754 20335 sgd_solver.cpp:106] Iteration 2580, lr = 0.0001
I0625 21:40:15.082713 20335 solver.cpp:337] Iteration 2600, Testing net (#0)
I0625 21:40:18.184188 20335 solver.cpp:404]     Test net output #0: accuracy = 0.684326
I0625 21:40:18.184219 20335 solver.cpp:404]     Test net output #1: loss = 0.681634 (* 1 = 0.681634 loss)
I0625 21:40:18.212673 20335 solver.cpp:228] Iteration 2600, loss = 0.547454
I0625 21:40:18.212703 20335 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 21:40:18.212712 20335 solver.cpp:244]     Train net output #1: loss = 0.547454 (* 1 = 0.547454 loss)
I0625 21:40:18.212718 20335 sgd_solver.cpp:106] Iteration 2600, lr = 0.0001
I0625 21:40:19.881126 20335 solver.cpp:228] Iteration 2620, loss = 0.372772
I0625 21:40:19.881150 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:40:19.881167 20335 solver.cpp:244]     Train net output #1: loss = 0.372772 (* 1 = 0.372772 loss)
I0625 21:40:19.881172 20335 sgd_solver.cpp:106] Iteration 2620, lr = 0.0001
I0625 21:40:21.541399 20335 solver.cpp:228] Iteration 2640, loss = 0.43992
I0625 21:40:21.541422 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:40:21.541429 20335 solver.cpp:244]     Train net output #1: loss = 0.43992 (* 1 = 0.43992 loss)
I0625 21:40:21.541434 20335 sgd_solver.cpp:106] Iteration 2640, lr = 0.0001
I0625 21:40:23.203747 20335 solver.cpp:228] Iteration 2660, loss = 0.562282
I0625 21:40:23.203779 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:40:23.203788 20335 solver.cpp:244]     Train net output #1: loss = 0.562282 (* 1 = 0.562282 loss)
I0625 21:40:23.203793 20335 sgd_solver.cpp:106] Iteration 2660, lr = 0.0001
I0625 21:40:24.863945 20335 solver.cpp:228] Iteration 2680, loss = 0.37217
I0625 21:40:24.863970 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:40:24.863976 20335 solver.cpp:244]     Train net output #1: loss = 0.37217 (* 1 = 0.37217 loss)
I0625 21:40:24.863981 20335 sgd_solver.cpp:106] Iteration 2680, lr = 0.0001
I0625 21:40:26.496158 20335 solver.cpp:337] Iteration 2700, Testing net (#0)
I0625 21:40:29.672742 20335 solver.cpp:404]     Test net output #0: accuracy = 0.697266
I0625 21:40:29.672772 20335 solver.cpp:404]     Test net output #1: loss = 0.657031 (* 1 = 0.657031 loss)
I0625 21:40:29.700788 20335 solver.cpp:228] Iteration 2700, loss = 0.427882
I0625 21:40:29.700816 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:40:29.700824 20335 solver.cpp:244]     Train net output #1: loss = 0.427882 (* 1 = 0.427882 loss)
I0625 21:40:29.700829 20335 sgd_solver.cpp:106] Iteration 2700, lr = 0.0001
I0625 21:40:31.380064 20335 solver.cpp:228] Iteration 2720, loss = 0.562169
I0625 21:40:31.380087 20335 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 21:40:31.380095 20335 solver.cpp:244]     Train net output #1: loss = 0.562169 (* 1 = 0.562169 loss)
I0625 21:40:31.380100 20335 sgd_solver.cpp:106] Iteration 2720, lr = 0.0001
I0625 21:40:33.046941 20335 solver.cpp:228] Iteration 2740, loss = 0.325686
I0625 21:40:33.046967 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:40:33.046973 20335 solver.cpp:244]     Train net output #1: loss = 0.325686 (* 1 = 0.325686 loss)
I0625 21:40:33.046978 20335 sgd_solver.cpp:106] Iteration 2740, lr = 0.0001
I0625 21:40:34.723676 20335 solver.cpp:228] Iteration 2760, loss = 0.556705
I0625 21:40:34.723753 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:40:34.723762 20335 solver.cpp:244]     Train net output #1: loss = 0.556705 (* 1 = 0.556705 loss)
I0625 21:40:34.723767 20335 sgd_solver.cpp:106] Iteration 2760, lr = 0.0001
I0625 21:40:36.386015 20335 solver.cpp:228] Iteration 2780, loss = 0.400123
I0625 21:40:36.386039 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:40:36.386046 20335 solver.cpp:244]     Train net output #1: loss = 0.400123 (* 1 = 0.400123 loss)
I0625 21:40:36.386051 20335 sgd_solver.cpp:106] Iteration 2780, lr = 0.0001
I0625 21:40:38.024461 20335 solver.cpp:337] Iteration 2800, Testing net (#0)
I0625 21:40:41.174999 20335 solver.cpp:404]     Test net output #0: accuracy = 0.690918
I0625 21:40:41.175026 20335 solver.cpp:404]     Test net output #1: loss = 0.656489 (* 1 = 0.656489 loss)
I0625 21:40:41.203287 20335 solver.cpp:228] Iteration 2800, loss = 0.3285
I0625 21:40:41.203320 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:40:41.203328 20335 solver.cpp:244]     Train net output #1: loss = 0.3285 (* 1 = 0.3285 loss)
I0625 21:40:41.203333 20335 sgd_solver.cpp:106] Iteration 2800, lr = 0.0001
I0625 21:40:42.870406 20335 solver.cpp:228] Iteration 2820, loss = 0.415517
I0625 21:40:42.870431 20335 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 21:40:42.870439 20335 solver.cpp:244]     Train net output #1: loss = 0.415517 (* 1 = 0.415517 loss)
I0625 21:40:42.870443 20335 sgd_solver.cpp:106] Iteration 2820, lr = 0.0001
I0625 21:40:44.531478 20335 solver.cpp:228] Iteration 2840, loss = 0.540089
I0625 21:40:44.531502 20335 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 21:40:44.531510 20335 solver.cpp:244]     Train net output #1: loss = 0.540089 (* 1 = 0.540089 loss)
I0625 21:40:44.531514 20335 sgd_solver.cpp:106] Iteration 2840, lr = 0.0001
I0625 21:40:46.190668 20335 solver.cpp:228] Iteration 2860, loss = 0.37314
I0625 21:40:46.190695 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:40:46.190701 20335 solver.cpp:244]     Train net output #1: loss = 0.37314 (* 1 = 0.37314 loss)
I0625 21:40:46.190706 20335 sgd_solver.cpp:106] Iteration 2860, lr = 0.0001
I0625 21:40:47.849172 20335 solver.cpp:228] Iteration 2880, loss = 0.383584
I0625 21:40:47.849197 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:40:47.849205 20335 solver.cpp:244]     Train net output #1: loss = 0.383584 (* 1 = 0.383584 loss)
I0625 21:40:47.849208 20335 sgd_solver.cpp:106] Iteration 2880, lr = 0.0001
I0625 21:40:49.487045 20335 solver.cpp:337] Iteration 2900, Testing net (#0)
I0625 21:40:52.585654 20335 solver.cpp:404]     Test net output #0: accuracy = 0.681885
I0625 21:40:52.585683 20335 solver.cpp:404]     Test net output #1: loss = 0.679432 (* 1 = 0.679432 loss)
I0625 21:40:52.614275 20335 solver.cpp:228] Iteration 2900, loss = 0.464116
I0625 21:40:52.614302 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:40:52.614310 20335 solver.cpp:244]     Train net output #1: loss = 0.464116 (* 1 = 0.464116 loss)
I0625 21:40:52.614316 20335 sgd_solver.cpp:106] Iteration 2900, lr = 0.0001
I0625 21:40:54.284730 20335 solver.cpp:228] Iteration 2920, loss = 0.337771
I0625 21:40:54.284754 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:40:54.284761 20335 solver.cpp:244]     Train net output #1: loss = 0.337771 (* 1 = 0.337771 loss)
I0625 21:40:54.284766 20335 sgd_solver.cpp:106] Iteration 2920, lr = 0.0001
I0625 21:40:55.948880 20335 solver.cpp:228] Iteration 2940, loss = 0.390813
I0625 21:40:55.948904 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:40:55.948911 20335 solver.cpp:244]     Train net output #1: loss = 0.390813 (* 1 = 0.390813 loss)
I0625 21:40:55.948915 20335 sgd_solver.cpp:106] Iteration 2940, lr = 0.0001
I0625 21:40:57.613353 20335 solver.cpp:228] Iteration 2960, loss = 0.391295
I0625 21:40:57.613376 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:40:57.613384 20335 solver.cpp:244]     Train net output #1: loss = 0.391295 (* 1 = 0.391295 loss)
I0625 21:40:57.613402 20335 sgd_solver.cpp:106] Iteration 2960, lr = 0.0001
I0625 21:40:59.274909 20335 solver.cpp:228] Iteration 2980, loss = 0.441957
I0625 21:40:59.274932 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:40:59.274951 20335 solver.cpp:244]     Train net output #1: loss = 0.441957 (* 1 = 0.441957 loss)
I0625 21:40:59.274955 20335 sgd_solver.cpp:106] Iteration 2980, lr = 0.0001
I0625 21:41:00.912783 20335 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_3000.caffemodel
I0625 21:41:00.934285 20335 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_3000.solverstate
I0625 21:41:00.945850 20335 solver.cpp:337] Iteration 3000, Testing net (#0)
I0625 21:41:04.050024 20335 solver.cpp:404]     Test net output #0: accuracy = 0.694092
I0625 21:41:04.050053 20335 solver.cpp:404]     Test net output #1: loss = 0.676354 (* 1 = 0.676354 loss)
I0625 21:41:04.078661 20335 solver.cpp:228] Iteration 3000, loss = 0.347215
I0625 21:41:04.078688 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:41:04.078696 20335 solver.cpp:244]     Train net output #1: loss = 0.347215 (* 1 = 0.347215 loss)
I0625 21:41:04.078701 20335 sgd_solver.cpp:106] Iteration 3000, lr = 0.0001
I0625 21:41:05.749346 20335 solver.cpp:228] Iteration 3020, loss = 0.49397
I0625 21:41:05.749478 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:41:05.749488 20335 solver.cpp:244]     Train net output #1: loss = 0.49397 (* 1 = 0.49397 loss)
I0625 21:41:05.749493 20335 sgd_solver.cpp:106] Iteration 3020, lr = 0.0001
I0625 21:41:07.412469 20335 solver.cpp:228] Iteration 3040, loss = 0.311869
I0625 21:41:07.412495 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:41:07.412503 20335 solver.cpp:244]     Train net output #1: loss = 0.311869 (* 1 = 0.311869 loss)
I0625 21:41:07.412508 20335 sgd_solver.cpp:106] Iteration 3040, lr = 0.0001
I0625 21:41:09.073504 20335 solver.cpp:228] Iteration 3060, loss = 0.482169
I0625 21:41:09.073530 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:41:09.073537 20335 solver.cpp:244]     Train net output #1: loss = 0.482169 (* 1 = 0.482169 loss)
I0625 21:41:09.073542 20335 sgd_solver.cpp:106] Iteration 3060, lr = 0.0001
I0625 21:41:10.735193 20335 solver.cpp:228] Iteration 3080, loss = 0.240679
I0625 21:41:10.735216 20335 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0625 21:41:10.735224 20335 solver.cpp:244]     Train net output #1: loss = 0.240679 (* 1 = 0.240679 loss)
I0625 21:41:10.735227 20335 sgd_solver.cpp:106] Iteration 3080, lr = 0.0001
I0625 21:41:12.373055 20335 solver.cpp:337] Iteration 3100, Testing net (#0)
I0625 21:41:15.592747 20335 solver.cpp:404]     Test net output #0: accuracy = 0.689453
I0625 21:41:15.592777 20335 solver.cpp:404]     Test net output #1: loss = 0.656418 (* 1 = 0.656418 loss)
I0625 21:41:15.621179 20335 solver.cpp:228] Iteration 3100, loss = 0.27706
I0625 21:41:15.621206 20335 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 21:41:15.621213 20335 solver.cpp:244]     Train net output #1: loss = 0.27706 (* 1 = 0.27706 loss)
I0625 21:41:15.621217 20335 sgd_solver.cpp:106] Iteration 3100, lr = 0.0001
I0625 21:41:17.290576 20335 solver.cpp:228] Iteration 3120, loss = 0.446889
I0625 21:41:17.290599 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:41:17.290606 20335 solver.cpp:244]     Train net output #1: loss = 0.446889 (* 1 = 0.446889 loss)
I0625 21:41:17.290611 20335 sgd_solver.cpp:106] Iteration 3120, lr = 0.0001
I0625 21:41:18.954205 20335 solver.cpp:228] Iteration 3140, loss = 0.386095
I0625 21:41:18.954229 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:41:18.954246 20335 solver.cpp:244]     Train net output #1: loss = 0.386095 (* 1 = 0.386095 loss)
I0625 21:41:18.954251 20335 sgd_solver.cpp:106] Iteration 3140, lr = 0.0001
I0625 21:41:20.617542 20335 solver.cpp:228] Iteration 3160, loss = 0.475473
I0625 21:41:20.617576 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:41:20.617584 20335 solver.cpp:244]     Train net output #1: loss = 0.475473 (* 1 = 0.475473 loss)
I0625 21:41:20.617588 20335 sgd_solver.cpp:106] Iteration 3160, lr = 0.0001
I0625 21:41:22.282179 20335 solver.cpp:228] Iteration 3180, loss = 0.363129
I0625 21:41:22.282202 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:41:22.282209 20335 solver.cpp:244]     Train net output #1: loss = 0.363129 (* 1 = 0.363129 loss)
I0625 21:41:22.282213 20335 sgd_solver.cpp:106] Iteration 3180, lr = 0.0001
I0625 21:41:23.918889 20335 solver.cpp:337] Iteration 3200, Testing net (#0)
I0625 21:41:27.068213 20335 solver.cpp:404]     Test net output #0: accuracy = 0.684082
I0625 21:41:27.068244 20335 solver.cpp:404]     Test net output #1: loss = 0.680094 (* 1 = 0.680094 loss)
I0625 21:41:27.096029 20335 solver.cpp:228] Iteration 3200, loss = 0.49742
I0625 21:41:27.096055 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:41:27.096062 20335 solver.cpp:244]     Train net output #1: loss = 0.49742 (* 1 = 0.49742 loss)
I0625 21:41:27.096067 20335 sgd_solver.cpp:106] Iteration 3200, lr = 0.0001
I0625 21:41:28.766566 20335 solver.cpp:228] Iteration 3220, loss = 0.319252
I0625 21:41:28.766593 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:41:28.766599 20335 solver.cpp:244]     Train net output #1: loss = 0.319252 (* 1 = 0.319252 loss)
I0625 21:41:28.766626 20335 sgd_solver.cpp:106] Iteration 3220, lr = 0.0001
I0625 21:41:30.428383 20335 solver.cpp:228] Iteration 3240, loss = 0.302976
I0625 21:41:30.428407 20335 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0625 21:41:30.428416 20335 solver.cpp:244]     Train net output #1: loss = 0.302976 (* 1 = 0.302976 loss)
I0625 21:41:30.428421 20335 sgd_solver.cpp:106] Iteration 3240, lr = 0.0001
I0625 21:41:32.089695 20335 solver.cpp:228] Iteration 3260, loss = 0.379868
I0625 21:41:32.089720 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:41:32.089727 20335 solver.cpp:244]     Train net output #1: loss = 0.379868 (* 1 = 0.379868 loss)
I0625 21:41:32.089731 20335 sgd_solver.cpp:106] Iteration 3260, lr = 0.0001
I0625 21:41:33.751189 20335 solver.cpp:228] Iteration 3280, loss = 0.412861
I0625 21:41:33.751221 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:41:33.751229 20335 solver.cpp:244]     Train net output #1: loss = 0.412861 (* 1 = 0.412861 loss)
I0625 21:41:33.751232 20335 sgd_solver.cpp:106] Iteration 3280, lr = 0.0001
I0625 21:41:35.390197 20335 solver.cpp:337] Iteration 3300, Testing net (#0)
I0625 21:41:38.546072 20335 solver.cpp:404]     Test net output #0: accuracy = 0.680176
I0625 21:41:38.546219 20335 solver.cpp:404]     Test net output #1: loss = 0.688092 (* 1 = 0.688092 loss)
I0625 21:41:38.574800 20335 solver.cpp:228] Iteration 3300, loss = 0.360966
I0625 21:41:38.574827 20335 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 21:41:38.574836 20335 solver.cpp:244]     Train net output #1: loss = 0.360966 (* 1 = 0.360966 loss)
I0625 21:41:38.574841 20335 sgd_solver.cpp:106] Iteration 3300, lr = 0.0001
I0625 21:41:40.244248 20335 solver.cpp:228] Iteration 3320, loss = 0.515937
I0625 21:41:40.244283 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:41:40.244292 20335 solver.cpp:244]     Train net output #1: loss = 0.515937 (* 1 = 0.515937 loss)
I0625 21:41:40.244297 20335 sgd_solver.cpp:106] Iteration 3320, lr = 0.0001
I0625 21:41:41.908337 20335 solver.cpp:228] Iteration 3340, loss = 0.376938
I0625 21:41:41.908367 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:41:41.908375 20335 solver.cpp:244]     Train net output #1: loss = 0.376938 (* 1 = 0.376938 loss)
I0625 21:41:41.908380 20335 sgd_solver.cpp:106] Iteration 3340, lr = 0.0001
I0625 21:41:43.571147 20335 solver.cpp:228] Iteration 3360, loss = 0.479587
I0625 21:41:43.571177 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:41:43.571184 20335 solver.cpp:244]     Train net output #1: loss = 0.479587 (* 1 = 0.479587 loss)
I0625 21:41:43.571188 20335 sgd_solver.cpp:106] Iteration 3360, lr = 0.0001
I0625 21:41:45.229460 20335 solver.cpp:228] Iteration 3380, loss = 0.289696
I0625 21:41:45.229485 20335 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 21:41:45.229491 20335 solver.cpp:244]     Train net output #1: loss = 0.289696 (* 1 = 0.289696 loss)
I0625 21:41:45.229496 20335 sgd_solver.cpp:106] Iteration 3380, lr = 0.0001
I0625 21:41:46.864413 20335 solver.cpp:337] Iteration 3400, Testing net (#0)
I0625 21:41:49.972376 20335 solver.cpp:404]     Test net output #0: accuracy = 0.698975
I0625 21:41:49.972404 20335 solver.cpp:404]     Test net output #1: loss = 0.653058 (* 1 = 0.653058 loss)
I0625 21:41:50.000691 20335 solver.cpp:228] Iteration 3400, loss = 0.359354
I0625 21:41:50.000721 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:41:50.000731 20335 solver.cpp:244]     Train net output #1: loss = 0.359354 (* 1 = 0.359354 loss)
I0625 21:41:50.000738 20335 sgd_solver.cpp:106] Iteration 3400, lr = 0.0001
I0625 21:41:51.670384 20335 solver.cpp:228] Iteration 3420, loss = 0.494037
I0625 21:41:51.670410 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:41:51.670418 20335 solver.cpp:244]     Train net output #1: loss = 0.494037 (* 1 = 0.494037 loss)
I0625 21:41:51.670423 20335 sgd_solver.cpp:106] Iteration 3420, lr = 0.0001
I0625 21:41:53.334302 20335 solver.cpp:228] Iteration 3440, loss = 0.395547
I0625 21:41:53.334327 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:41:53.334334 20335 solver.cpp:244]     Train net output #1: loss = 0.395547 (* 1 = 0.395547 loss)
I0625 21:41:53.334338 20335 sgd_solver.cpp:106] Iteration 3440, lr = 0.0001
I0625 21:41:54.993096 20335 solver.cpp:228] Iteration 3460, loss = 0.555323
I0625 21:41:54.993131 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:41:54.993139 20335 solver.cpp:244]     Train net output #1: loss = 0.555323 (* 1 = 0.555323 loss)
I0625 21:41:54.993142 20335 sgd_solver.cpp:106] Iteration 3460, lr = 0.0001
I0625 21:41:56.653945 20335 solver.cpp:228] Iteration 3480, loss = 0.393719
I0625 21:41:56.653970 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:41:56.653976 20335 solver.cpp:244]     Train net output #1: loss = 0.393719 (* 1 = 0.393719 loss)
I0625 21:41:56.653980 20335 sgd_solver.cpp:106] Iteration 3480, lr = 0.0001
I0625 21:41:58.291093 20335 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_3500.caffemodel
I0625 21:41:58.312552 20335 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_3500.solverstate
I0625 21:41:58.323945 20335 solver.cpp:337] Iteration 3500, Testing net (#0)
I0625 21:42:01.398663 20335 solver.cpp:404]     Test net output #0: accuracy = 0.680664
I0625 21:42:01.398689 20335 solver.cpp:404]     Test net output #1: loss = 0.68133 (* 1 = 0.68133 loss)
I0625 21:42:01.427310 20335 solver.cpp:228] Iteration 3500, loss = 0.412034
I0625 21:42:01.427340 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:42:01.427346 20335 solver.cpp:244]     Train net output #1: loss = 0.412034 (* 1 = 0.412034 loss)
I0625 21:42:01.427351 20335 sgd_solver.cpp:106] Iteration 3500, lr = 0.0001
I0625 21:42:03.093674 20335 solver.cpp:228] Iteration 3520, loss = 0.364948
I0625 21:42:03.093711 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:42:03.093719 20335 solver.cpp:244]     Train net output #1: loss = 0.364948 (* 1 = 0.364948 loss)
I0625 21:42:03.093724 20335 sgd_solver.cpp:106] Iteration 3520, lr = 0.0001
I0625 21:42:04.756278 20335 solver.cpp:228] Iteration 3540, loss = 0.335916
I0625 21:42:04.756305 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:42:04.756312 20335 solver.cpp:244]     Train net output #1: loss = 0.335916 (* 1 = 0.335916 loss)
I0625 21:42:04.756319 20335 sgd_solver.cpp:106] Iteration 3540, lr = 0.0001
I0625 21:42:06.417409 20335 solver.cpp:228] Iteration 3560, loss = 0.308186
I0625 21:42:06.417434 20335 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 21:42:06.417441 20335 solver.cpp:244]     Train net output #1: loss = 0.308186 (* 1 = 0.308186 loss)
I0625 21:42:06.417445 20335 sgd_solver.cpp:106] Iteration 3560, lr = 0.0001
I0625 21:42:08.078722 20335 solver.cpp:228] Iteration 3580, loss = 0.403371
I0625 21:42:08.078747 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:42:08.078753 20335 solver.cpp:244]     Train net output #1: loss = 0.403371 (* 1 = 0.403371 loss)
I0625 21:42:08.078758 20335 sgd_solver.cpp:106] Iteration 3580, lr = 0.0001
I0625 21:42:09.714496 20335 solver.cpp:337] Iteration 3600, Testing net (#0)
I0625 21:42:10.818707 20335 blocking_queue.cpp:50] Data layer prefetch queue empty
I0625 21:42:12.796780 20335 solver.cpp:404]     Test net output #0: accuracy = 0.699463
I0625 21:42:12.796808 20335 solver.cpp:404]     Test net output #1: loss = 0.6652 (* 1 = 0.6652 loss)
I0625 21:42:12.825601 20335 solver.cpp:228] Iteration 3600, loss = 0.365634
I0625 21:42:12.825630 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:42:12.825637 20335 solver.cpp:244]     Train net output #1: loss = 0.365634 (* 1 = 0.365634 loss)
I0625 21:42:12.825642 20335 sgd_solver.cpp:106] Iteration 3600, lr = 0.0001
I0625 21:42:14.494942 20335 solver.cpp:228] Iteration 3620, loss = 0.453519
I0625 21:42:14.494967 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:42:14.494974 20335 solver.cpp:244]     Train net output #1: loss = 0.453519 (* 1 = 0.453519 loss)
I0625 21:42:14.494979 20335 sgd_solver.cpp:106] Iteration 3620, lr = 0.0001
I0625 21:42:16.155977 20335 solver.cpp:228] Iteration 3640, loss = 0.423976
I0625 21:42:16.156000 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:42:16.156008 20335 solver.cpp:244]     Train net output #1: loss = 0.423976 (* 1 = 0.423976 loss)
I0625 21:42:16.156011 20335 sgd_solver.cpp:106] Iteration 3640, lr = 0.0001
I0625 21:42:17.818856 20335 solver.cpp:228] Iteration 3660, loss = 0.500785
I0625 21:42:17.818881 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:42:17.818888 20335 solver.cpp:244]     Train net output #1: loss = 0.500785 (* 1 = 0.500785 loss)
I0625 21:42:17.818892 20335 sgd_solver.cpp:106] Iteration 3660, lr = 0.0001
I0625 21:42:19.476307 20335 solver.cpp:228] Iteration 3680, loss = 0.382042
I0625 21:42:19.476331 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:42:19.476339 20335 solver.cpp:244]     Train net output #1: loss = 0.382042 (* 1 = 0.382042 loss)
I0625 21:42:19.476343 20335 sgd_solver.cpp:106] Iteration 3680, lr = 0.0001
I0625 21:42:21.109447 20335 solver.cpp:337] Iteration 3700, Testing net (#0)
I0625 21:42:24.215025 20335 solver.cpp:404]     Test net output #0: accuracy = 0.692139
I0625 21:42:24.215054 20335 solver.cpp:404]     Test net output #1: loss = 0.670026 (* 1 = 0.670026 loss)
I0625 21:42:24.244387 20335 solver.cpp:228] Iteration 3700, loss = 0.328684
I0625 21:42:24.244415 20335 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 21:42:24.244421 20335 solver.cpp:244]     Train net output #1: loss = 0.328684 (* 1 = 0.328684 loss)
I0625 21:42:24.244426 20335 sgd_solver.cpp:106] Iteration 3700, lr = 0.0001
I0625 21:42:25.903843 20335 solver.cpp:228] Iteration 3720, loss = 0.472477
I0625 21:42:25.903869 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:42:25.903877 20335 solver.cpp:244]     Train net output #1: loss = 0.472477 (* 1 = 0.472477 loss)
I0625 21:42:25.903880 20335 sgd_solver.cpp:106] Iteration 3720, lr = 0.0001
I0625 21:42:27.558764 20335 solver.cpp:228] Iteration 3740, loss = 0.416335
I0625 21:42:27.558800 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:42:27.558807 20335 solver.cpp:244]     Train net output #1: loss = 0.416335 (* 1 = 0.416335 loss)
I0625 21:42:27.558811 20335 sgd_solver.cpp:106] Iteration 3740, lr = 0.0001
I0625 21:42:29.210782 20335 solver.cpp:228] Iteration 3760, loss = 0.480557
I0625 21:42:29.210805 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:42:29.210813 20335 solver.cpp:244]     Train net output #1: loss = 0.480557 (* 1 = 0.480557 loss)
I0625 21:42:29.210818 20335 sgd_solver.cpp:106] Iteration 3760, lr = 0.0001
I0625 21:42:30.883534 20335 solver.cpp:228] Iteration 3780, loss = 0.466842
I0625 21:42:30.883569 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:42:30.883576 20335 solver.cpp:244]     Train net output #1: loss = 0.466842 (* 1 = 0.466842 loss)
I0625 21:42:30.883580 20335 sgd_solver.cpp:106] Iteration 3780, lr = 0.0001
I0625 21:42:32.519320 20335 solver.cpp:337] Iteration 3800, Testing net (#0)
I0625 21:42:35.688848 20335 solver.cpp:404]     Test net output #0: accuracy = 0.691895
I0625 21:42:35.688910 20335 solver.cpp:404]     Test net output #1: loss = 0.676664 (* 1 = 0.676664 loss)
I0625 21:42:35.717408 20335 solver.cpp:228] Iteration 3800, loss = 0.38668
I0625 21:42:35.717437 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:42:35.717444 20335 solver.cpp:244]     Train net output #1: loss = 0.38668 (* 1 = 0.38668 loss)
I0625 21:42:35.717450 20335 sgd_solver.cpp:106] Iteration 3800, lr = 0.0001
I0625 21:42:37.384755 20335 solver.cpp:228] Iteration 3820, loss = 0.382007
I0625 21:42:37.384778 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:42:37.384785 20335 solver.cpp:244]     Train net output #1: loss = 0.382007 (* 1 = 0.382007 loss)
I0625 21:42:37.384789 20335 sgd_solver.cpp:106] Iteration 3820, lr = 0.0001
I0625 21:42:39.046805 20335 solver.cpp:228] Iteration 3840, loss = 0.28015
I0625 21:42:39.046838 20335 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 21:42:39.046845 20335 solver.cpp:244]     Train net output #1: loss = 0.28015 (* 1 = 0.28015 loss)
I0625 21:42:39.046850 20335 sgd_solver.cpp:106] Iteration 3840, lr = 0.0001
I0625 21:42:40.708056 20335 solver.cpp:228] Iteration 3860, loss = 0.303078
I0625 21:42:40.708181 20335 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 21:42:40.708192 20335 solver.cpp:244]     Train net output #1: loss = 0.303078 (* 1 = 0.303078 loss)
I0625 21:42:40.708196 20335 sgd_solver.cpp:106] Iteration 3860, lr = 0.0001
I0625 21:42:42.370533 20335 solver.cpp:228] Iteration 3880, loss = 0.3886
I0625 21:42:42.370558 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:42:42.370564 20335 solver.cpp:244]     Train net output #1: loss = 0.3886 (* 1 = 0.3886 loss)
I0625 21:42:42.370569 20335 sgd_solver.cpp:106] Iteration 3880, lr = 0.0001
I0625 21:42:44.003511 20335 solver.cpp:337] Iteration 3900, Testing net (#0)
I0625 21:42:47.108819 20335 solver.cpp:404]     Test net output #0: accuracy = 0.705566
I0625 21:42:47.108858 20335 solver.cpp:404]     Test net output #1: loss = 0.653141 (* 1 = 0.653141 loss)
I0625 21:42:47.136996 20335 solver.cpp:228] Iteration 3900, loss = 0.332641
I0625 21:42:47.137027 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:42:47.137034 20335 solver.cpp:244]     Train net output #1: loss = 0.332641 (* 1 = 0.332641 loss)
I0625 21:42:47.137039 20335 sgd_solver.cpp:106] Iteration 3900, lr = 0.0001
I0625 21:42:48.802743 20335 solver.cpp:228] Iteration 3920, loss = 0.400249
I0625 21:42:48.802767 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:42:48.802774 20335 solver.cpp:244]     Train net output #1: loss = 0.400249 (* 1 = 0.400249 loss)
I0625 21:42:48.802779 20335 sgd_solver.cpp:106] Iteration 3920, lr = 0.0001
I0625 21:42:50.458756 20335 solver.cpp:228] Iteration 3940, loss = 0.487006
I0625 21:42:50.458781 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:42:50.458787 20335 solver.cpp:244]     Train net output #1: loss = 0.487006 (* 1 = 0.487006 loss)
I0625 21:42:50.458791 20335 sgd_solver.cpp:106] Iteration 3940, lr = 0.0001
I0625 21:42:52.114069 20335 solver.cpp:228] Iteration 3960, loss = 0.393502
I0625 21:42:52.114095 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:42:52.114102 20335 solver.cpp:244]     Train net output #1: loss = 0.393502 (* 1 = 0.393502 loss)
I0625 21:42:52.114106 20335 sgd_solver.cpp:106] Iteration 3960, lr = 0.0001
I0625 21:42:53.771304 20335 solver.cpp:228] Iteration 3980, loss = 0.363923
I0625 21:42:53.771332 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:42:53.771338 20335 solver.cpp:244]     Train net output #1: loss = 0.363923 (* 1 = 0.363923 loss)
I0625 21:42:53.771343 20335 sgd_solver.cpp:106] Iteration 3980, lr = 0.0001
I0625 21:42:55.401510 20335 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_4000.caffemodel
I0625 21:42:55.423110 20335 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_4000.solverstate
I0625 21:42:55.434897 20335 solver.cpp:337] Iteration 4000, Testing net (#0)
I0625 21:42:58.654561 20335 solver.cpp:404]     Test net output #0: accuracy = 0.699707
I0625 21:42:58.654588 20335 solver.cpp:404]     Test net output #1: loss = 0.647783 (* 1 = 0.647783 loss)
I0625 21:42:58.682806 20335 solver.cpp:228] Iteration 4000, loss = 0.317563
I0625 21:42:58.682831 20335 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 21:42:58.682837 20335 solver.cpp:244]     Train net output #1: loss = 0.317563 (* 1 = 0.317563 loss)
I0625 21:42:58.682842 20335 sgd_solver.cpp:106] Iteration 4000, lr = 1e-05
I0625 21:43:00.350646 20335 solver.cpp:228] Iteration 4020, loss = 0.400272
I0625 21:43:00.350669 20335 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 21:43:00.350677 20335 solver.cpp:244]     Train net output #1: loss = 0.400272 (* 1 = 0.400272 loss)
I0625 21:43:00.350682 20335 sgd_solver.cpp:106] Iteration 4020, lr = 1e-05
I0625 21:43:02.004907 20335 solver.cpp:228] Iteration 4040, loss = 0.414879
I0625 21:43:02.004931 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:43:02.004938 20335 solver.cpp:244]     Train net output #1: loss = 0.414879 (* 1 = 0.414879 loss)
I0625 21:43:02.004942 20335 sgd_solver.cpp:106] Iteration 4040, lr = 1e-05
I0625 21:43:03.663135 20335 solver.cpp:228] Iteration 4060, loss = 0.567955
I0625 21:43:03.663164 20335 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 21:43:03.663172 20335 solver.cpp:244]     Train net output #1: loss = 0.567955 (* 1 = 0.567955 loss)
I0625 21:43:03.663177 20335 sgd_solver.cpp:106] Iteration 4060, lr = 1e-05
I0625 21:43:05.322731 20335 solver.cpp:228] Iteration 4080, loss = 0.459243
I0625 21:43:05.322756 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:43:05.322762 20335 solver.cpp:244]     Train net output #1: loss = 0.459243 (* 1 = 0.459243 loss)
I0625 21:43:05.322767 20335 sgd_solver.cpp:106] Iteration 4080, lr = 1e-05
I0625 21:43:06.957675 20335 solver.cpp:337] Iteration 4100, Testing net (#0)
I0625 21:43:10.039592 20335 solver.cpp:404]     Test net output #0: accuracy = 0.687012
I0625 21:43:10.039620 20335 solver.cpp:404]     Test net output #1: loss = 0.673488 (* 1 = 0.673488 loss)
I0625 21:43:10.067548 20335 solver.cpp:228] Iteration 4100, loss = 0.411072
I0625 21:43:10.067576 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:43:10.067584 20335 solver.cpp:244]     Train net output #1: loss = 0.411072 (* 1 = 0.411072 loss)
I0625 21:43:10.067589 20335 sgd_solver.cpp:106] Iteration 4100, lr = 1e-05
I0625 21:43:11.730973 20335 solver.cpp:228] Iteration 4120, loss = 0.471511
I0625 21:43:11.731097 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:43:11.731107 20335 solver.cpp:244]     Train net output #1: loss = 0.471511 (* 1 = 0.471511 loss)
I0625 21:43:11.731112 20335 sgd_solver.cpp:106] Iteration 4120, lr = 1e-05
I0625 21:43:13.388890 20335 solver.cpp:228] Iteration 4140, loss = 0.461077
I0625 21:43:13.388911 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:43:13.388918 20335 solver.cpp:244]     Train net output #1: loss = 0.461077 (* 1 = 0.461077 loss)
I0625 21:43:13.388922 20335 sgd_solver.cpp:106] Iteration 4140, lr = 1e-05
I0625 21:43:15.048063 20335 solver.cpp:228] Iteration 4160, loss = 0.464583
I0625 21:43:15.048087 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:43:15.048095 20335 solver.cpp:244]     Train net output #1: loss = 0.464583 (* 1 = 0.464583 loss)
I0625 21:43:15.048099 20335 sgd_solver.cpp:106] Iteration 4160, lr = 1e-05
I0625 21:43:16.703965 20335 solver.cpp:228] Iteration 4180, loss = 0.303282
I0625 21:43:16.703990 20335 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0625 21:43:16.703999 20335 solver.cpp:244]     Train net output #1: loss = 0.303282 (* 1 = 0.303282 loss)
I0625 21:43:16.704002 20335 sgd_solver.cpp:106] Iteration 4180, lr = 1e-05
I0625 21:43:18.336477 20335 solver.cpp:337] Iteration 4200, Testing net (#0)
I0625 21:43:21.407166 20335 solver.cpp:404]     Test net output #0: accuracy = 0.699219
I0625 21:43:21.407203 20335 solver.cpp:404]     Test net output #1: loss = 0.657387 (* 1 = 0.657387 loss)
I0625 21:43:21.435642 20335 solver.cpp:228] Iteration 4200, loss = 0.38905
I0625 21:43:21.435670 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:43:21.435678 20335 solver.cpp:244]     Train net output #1: loss = 0.38905 (* 1 = 0.38905 loss)
I0625 21:43:21.435683 20335 sgd_solver.cpp:106] Iteration 4200, lr = 1e-05
I0625 21:43:23.105801 20335 solver.cpp:228] Iteration 4220, loss = 0.46809
I0625 21:43:23.105826 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:43:23.105834 20335 solver.cpp:244]     Train net output #1: loss = 0.46809 (* 1 = 0.46809 loss)
I0625 21:43:23.105839 20335 sgd_solver.cpp:106] Iteration 4220, lr = 1e-05
I0625 21:43:24.764562 20335 solver.cpp:228] Iteration 4240, loss = 0.392118
I0625 21:43:24.764585 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:43:24.764603 20335 solver.cpp:244]     Train net output #1: loss = 0.392118 (* 1 = 0.392118 loss)
I0625 21:43:24.764608 20335 sgd_solver.cpp:106] Iteration 4240, lr = 1e-05
I0625 21:43:26.426584 20335 solver.cpp:228] Iteration 4260, loss = 0.503352
I0625 21:43:26.426606 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:43:26.426614 20335 solver.cpp:244]     Train net output #1: loss = 0.503352 (* 1 = 0.503352 loss)
I0625 21:43:26.426618 20335 sgd_solver.cpp:106] Iteration 4260, lr = 1e-05
I0625 21:43:28.090464 20335 solver.cpp:228] Iteration 4280, loss = 0.379327
I0625 21:43:28.090488 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:43:28.090495 20335 solver.cpp:244]     Train net output #1: loss = 0.379327 (* 1 = 0.379327 loss)
I0625 21:43:28.090500 20335 sgd_solver.cpp:106] Iteration 4280, lr = 1e-05
I0625 21:43:29.727890 20335 solver.cpp:337] Iteration 4300, Testing net (#0)
I0625 21:43:32.837610 20335 solver.cpp:404]     Test net output #0: accuracy = 0.697998
I0625 21:43:32.837638 20335 solver.cpp:404]     Test net output #1: loss = 0.660063 (* 1 = 0.660063 loss)
I0625 21:43:32.866899 20335 solver.cpp:228] Iteration 4300, loss = 0.300189
I0625 21:43:32.866932 20335 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0625 21:43:32.866945 20335 solver.cpp:244]     Train net output #1: loss = 0.300189 (* 1 = 0.300189 loss)
I0625 21:43:32.866951 20335 sgd_solver.cpp:106] Iteration 4300, lr = 1e-05
I0625 21:43:34.536232 20335 solver.cpp:228] Iteration 4320, loss = 0.379259
I0625 21:43:34.536268 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:43:34.536275 20335 solver.cpp:244]     Train net output #1: loss = 0.379259 (* 1 = 0.379259 loss)
I0625 21:43:34.536299 20335 sgd_solver.cpp:106] Iteration 4320, lr = 1e-05
I0625 21:43:36.196903 20335 solver.cpp:228] Iteration 4340, loss = 0.380544
I0625 21:43:36.196940 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:43:36.196948 20335 solver.cpp:244]     Train net output #1: loss = 0.380544 (* 1 = 0.380544 loss)
I0625 21:43:36.196952 20335 sgd_solver.cpp:106] Iteration 4340, lr = 1e-05
I0625 21:43:37.859701 20335 solver.cpp:228] Iteration 4360, loss = 0.437846
I0625 21:43:37.859725 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:43:37.859733 20335 solver.cpp:244]     Train net output #1: loss = 0.437846 (* 1 = 0.437846 loss)
I0625 21:43:37.859738 20335 sgd_solver.cpp:106] Iteration 4360, lr = 1e-05
I0625 21:43:39.522377 20335 solver.cpp:228] Iteration 4380, loss = 0.454998
I0625 21:43:39.522400 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:43:39.522408 20335 solver.cpp:244]     Train net output #1: loss = 0.454998 (* 1 = 0.454998 loss)
I0625 21:43:39.522413 20335 sgd_solver.cpp:106] Iteration 4380, lr = 1e-05
I0625 21:43:41.157407 20335 solver.cpp:337] Iteration 4400, Testing net (#0)
I0625 21:43:44.283397 20335 solver.cpp:404]     Test net output #0: accuracy = 0.693604
I0625 21:43:44.283511 20335 solver.cpp:404]     Test net output #1: loss = 0.6656 (* 1 = 0.6656 loss)
I0625 21:43:44.311838 20335 solver.cpp:228] Iteration 4400, loss = 0.418862
I0625 21:43:44.311864 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:43:44.311872 20335 solver.cpp:244]     Train net output #1: loss = 0.418862 (* 1 = 0.418862 loss)
I0625 21:43:44.311877 20335 sgd_solver.cpp:106] Iteration 4400, lr = 1e-05
I0625 21:43:45.980576 20335 solver.cpp:228] Iteration 4420, loss = 0.408779
I0625 21:43:45.980602 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:43:45.980610 20335 solver.cpp:244]     Train net output #1: loss = 0.408779 (* 1 = 0.408779 loss)
I0625 21:43:45.980615 20335 sgd_solver.cpp:106] Iteration 4420, lr = 1e-05
I0625 21:43:47.642734 20335 solver.cpp:228] Iteration 4440, loss = 0.59114
I0625 21:43:47.642758 20335 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 21:43:47.642777 20335 solver.cpp:244]     Train net output #1: loss = 0.59114 (* 1 = 0.59114 loss)
I0625 21:43:47.642782 20335 sgd_solver.cpp:106] Iteration 4440, lr = 1e-05
I0625 21:43:49.304707 20335 solver.cpp:228] Iteration 4460, loss = 0.340575
I0625 21:43:49.304730 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:43:49.304749 20335 solver.cpp:244]     Train net output #1: loss = 0.340575 (* 1 = 0.340575 loss)
I0625 21:43:49.304752 20335 sgd_solver.cpp:106] Iteration 4460, lr = 1e-05
I0625 21:43:50.966840 20335 solver.cpp:228] Iteration 4480, loss = 0.324514
I0625 21:43:50.966876 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:43:50.966882 20335 solver.cpp:244]     Train net output #1: loss = 0.324514 (* 1 = 0.324514 loss)
I0625 21:43:50.966886 20335 sgd_solver.cpp:106] Iteration 4480, lr = 1e-05
I0625 21:43:52.601536 20335 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_4500.caffemodel
I0625 21:43:52.623059 20335 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_4500.solverstate
I0625 21:43:52.634585 20335 solver.cpp:337] Iteration 4500, Testing net (#0)
I0625 21:43:55.718396 20335 solver.cpp:404]     Test net output #0: accuracy = 0.700195
I0625 21:43:55.718426 20335 solver.cpp:404]     Test net output #1: loss = 0.662113 (* 1 = 0.662113 loss)
I0625 21:43:55.747524 20335 solver.cpp:228] Iteration 4500, loss = 0.370573
I0625 21:43:55.747551 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:43:55.747558 20335 solver.cpp:244]     Train net output #1: loss = 0.370573 (* 1 = 0.370573 loss)
I0625 21:43:55.747563 20335 sgd_solver.cpp:106] Iteration 4500, lr = 1e-05
I0625 21:43:57.414329 20335 solver.cpp:228] Iteration 4520, loss = 0.456585
I0625 21:43:57.414366 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:43:57.414373 20335 solver.cpp:244]     Train net output #1: loss = 0.456585 (* 1 = 0.456585 loss)
I0625 21:43:57.414377 20335 sgd_solver.cpp:106] Iteration 4520, lr = 1e-05
I0625 21:43:59.078618 20335 solver.cpp:228] Iteration 4540, loss = 0.435426
I0625 21:43:59.078641 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:43:59.078649 20335 solver.cpp:244]     Train net output #1: loss = 0.435426 (* 1 = 0.435426 loss)
I0625 21:43:59.078654 20335 sgd_solver.cpp:106] Iteration 4540, lr = 1e-05
I0625 21:44:00.740403 20335 solver.cpp:228] Iteration 4560, loss = 0.564321
I0625 21:44:00.740439 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:44:00.740447 20335 solver.cpp:244]     Train net output #1: loss = 0.564321 (* 1 = 0.564321 loss)
I0625 21:44:00.740450 20335 sgd_solver.cpp:106] Iteration 4560, lr = 1e-05
I0625 21:44:02.400054 20335 solver.cpp:228] Iteration 4580, loss = 0.361512
I0625 21:44:02.400079 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:44:02.400097 20335 solver.cpp:244]     Train net output #1: loss = 0.361512 (* 1 = 0.361512 loss)
I0625 21:44:02.400101 20335 sgd_solver.cpp:106] Iteration 4580, lr = 1e-05
I0625 21:44:04.038786 20335 solver.cpp:337] Iteration 4600, Testing net (#0)
I0625 21:44:07.142998 20335 solver.cpp:404]     Test net output #0: accuracy = 0.694336
I0625 21:44:07.143035 20335 solver.cpp:404]     Test net output #1: loss = 0.6617 (* 1 = 0.6617 loss)
I0625 21:44:07.171668 20335 solver.cpp:228] Iteration 4600, loss = 0.389227
I0625 21:44:07.171700 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:44:07.171711 20335 solver.cpp:244]     Train net output #1: loss = 0.389227 (* 1 = 0.389227 loss)
I0625 21:44:07.171720 20335 sgd_solver.cpp:106] Iteration 4600, lr = 1e-05
I0625 21:44:08.831019 20335 solver.cpp:228] Iteration 4620, loss = 0.335672
I0625 21:44:08.831053 20335 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 21:44:08.831060 20335 solver.cpp:244]     Train net output #1: loss = 0.335672 (* 1 = 0.335672 loss)
I0625 21:44:08.831065 20335 sgd_solver.cpp:106] Iteration 4620, lr = 1e-05
I0625 21:44:10.483922 20335 solver.cpp:228] Iteration 4640, loss = 0.306433
I0625 21:44:10.483945 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:44:10.483952 20335 solver.cpp:244]     Train net output #1: loss = 0.306433 (* 1 = 0.306433 loss)
I0625 21:44:10.483958 20335 sgd_solver.cpp:106] Iteration 4640, lr = 1e-05
I0625 21:44:12.137679 20335 solver.cpp:228] Iteration 4660, loss = 0.292205
I0625 21:44:12.137704 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:44:12.137712 20335 solver.cpp:244]     Train net output #1: loss = 0.292205 (* 1 = 0.292205 loss)
I0625 21:44:12.137717 20335 sgd_solver.cpp:106] Iteration 4660, lr = 1e-05
I0625 21:44:13.790148 20335 solver.cpp:228] Iteration 4680, loss = 0.474442
I0625 21:44:13.790179 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:44:13.790201 20335 solver.cpp:244]     Train net output #1: loss = 0.474442 (* 1 = 0.474442 loss)
I0625 21:44:13.790210 20335 sgd_solver.cpp:106] Iteration 4680, lr = 1e-05
I0625 21:44:15.419008 20335 solver.cpp:337] Iteration 4700, Testing net (#0)
I0625 21:44:18.562536 20335 solver.cpp:404]     Test net output #0: accuracy = 0.694824
I0625 21:44:18.562575 20335 solver.cpp:404]     Test net output #1: loss = 0.667997 (* 1 = 0.667997 loss)
I0625 21:44:18.591142 20335 solver.cpp:228] Iteration 4700, loss = 0.436799
I0625 21:44:18.591184 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:44:18.591195 20335 solver.cpp:244]     Train net output #1: loss = 0.436799 (* 1 = 0.436799 loss)
I0625 21:44:18.591203 20335 sgd_solver.cpp:106] Iteration 4700, lr = 1e-05
I0625 21:44:20.252585 20335 solver.cpp:228] Iteration 4720, loss = 0.359648
I0625 21:44:20.252609 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:44:20.252616 20335 solver.cpp:244]     Train net output #1: loss = 0.359648 (* 1 = 0.359648 loss)
I0625 21:44:20.252620 20335 sgd_solver.cpp:106] Iteration 4720, lr = 1e-05
I0625 21:44:21.908036 20335 solver.cpp:228] Iteration 4740, loss = 0.573981
I0625 21:44:21.908077 20335 solver.cpp:244]     Train net output #0: accuracy = 0.65625
I0625 21:44:21.908089 20335 solver.cpp:244]     Train net output #1: loss = 0.573981 (* 1 = 0.573981 loss)
I0625 21:44:21.908097 20335 sgd_solver.cpp:106] Iteration 4740, lr = 1e-05
I0625 21:44:23.562000 20335 solver.cpp:228] Iteration 4760, loss = 0.362772
I0625 21:44:23.562023 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:44:23.562042 20335 solver.cpp:244]     Train net output #1: loss = 0.362772 (* 1 = 0.362772 loss)
I0625 21:44:23.562047 20335 sgd_solver.cpp:106] Iteration 4760, lr = 1e-05
I0625 21:44:25.217866 20335 solver.cpp:228] Iteration 4780, loss = 0.433203
I0625 21:44:25.217890 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:44:25.217907 20335 solver.cpp:244]     Train net output #1: loss = 0.433203 (* 1 = 0.433203 loss)
I0625 21:44:25.217911 20335 sgd_solver.cpp:106] Iteration 4780, lr = 1e-05
I0625 21:44:26.847885 20335 solver.cpp:337] Iteration 4800, Testing net (#0)
I0625 21:44:29.950469 20335 solver.cpp:404]     Test net output #0: accuracy = 0.696533
I0625 21:44:29.950497 20335 solver.cpp:404]     Test net output #1: loss = 0.662049 (* 1 = 0.662049 loss)
I0625 21:44:29.978873 20335 solver.cpp:228] Iteration 4800, loss = 0.333581
I0625 21:44:29.978906 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:44:29.978917 20335 solver.cpp:244]     Train net output #1: loss = 0.333581 (* 1 = 0.333581 loss)
I0625 21:44:29.978924 20335 sgd_solver.cpp:106] Iteration 4800, lr = 1e-05
I0625 21:44:31.659651 20335 solver.cpp:228] Iteration 4820, loss = 0.645868
I0625 21:44:31.659674 20335 solver.cpp:244]     Train net output #0: accuracy = 0.6875
I0625 21:44:31.659682 20335 solver.cpp:244]     Train net output #1: loss = 0.645868 (* 1 = 0.645868 loss)
I0625 21:44:31.659687 20335 sgd_solver.cpp:106] Iteration 4820, lr = 1e-05
I0625 21:44:33.322383 20335 solver.cpp:228] Iteration 4840, loss = 0.349531
I0625 21:44:33.322429 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:44:33.322437 20335 solver.cpp:244]     Train net output #1: loss = 0.349531 (* 1 = 0.349531 loss)
I0625 21:44:33.322440 20335 sgd_solver.cpp:106] Iteration 4840, lr = 1e-05
I0625 21:44:34.983517 20335 solver.cpp:228] Iteration 4860, loss = 0.47068
I0625 21:44:34.983541 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:44:34.983548 20335 solver.cpp:244]     Train net output #1: loss = 0.47068 (* 1 = 0.47068 loss)
I0625 21:44:34.983552 20335 sgd_solver.cpp:106] Iteration 4860, lr = 1e-05
I0625 21:44:36.636476 20335 solver.cpp:228] Iteration 4880, loss = 0.272824
I0625 21:44:36.636502 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:44:36.636509 20335 solver.cpp:244]     Train net output #1: loss = 0.272824 (* 1 = 0.272824 loss)
I0625 21:44:36.636513 20335 sgd_solver.cpp:106] Iteration 4880, lr = 1e-05
I0625 21:44:38.266855 20335 solver.cpp:337] Iteration 4900, Testing net (#0)
I0625 21:44:41.330801 20335 solver.cpp:404]     Test net output #0: accuracy = 0.698975
I0625 21:44:41.330829 20335 solver.cpp:404]     Test net output #1: loss = 0.663657 (* 1 = 0.663657 loss)
I0625 21:44:41.359256 20335 solver.cpp:228] Iteration 4900, loss = 0.398124
I0625 21:44:41.359282 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:44:41.359289 20335 solver.cpp:244]     Train net output #1: loss = 0.398124 (* 1 = 0.398124 loss)
I0625 21:44:41.359295 20335 sgd_solver.cpp:106] Iteration 4900, lr = 1e-05
I0625 21:44:43.018755 20335 solver.cpp:228] Iteration 4920, loss = 0.36602
I0625 21:44:43.018790 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:44:43.018797 20335 solver.cpp:244]     Train net output #1: loss = 0.36602 (* 1 = 0.36602 loss)
I0625 21:44:43.018802 20335 sgd_solver.cpp:106] Iteration 4920, lr = 1e-05
I0625 21:44:44.670260 20335 solver.cpp:228] Iteration 4940, loss = 0.269665
I0625 21:44:44.670287 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:44:44.670295 20335 solver.cpp:244]     Train net output #1: loss = 0.269665 (* 1 = 0.269665 loss)
I0625 21:44:44.670300 20335 sgd_solver.cpp:106] Iteration 4940, lr = 1e-05
I0625 21:44:46.323212 20335 solver.cpp:228] Iteration 4960, loss = 0.39686
I0625 21:44:46.323335 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:44:46.323345 20335 solver.cpp:244]     Train net output #1: loss = 0.39686 (* 1 = 0.39686 loss)
I0625 21:44:46.323350 20335 sgd_solver.cpp:106] Iteration 4960, lr = 1e-05
I0625 21:44:47.975265 20335 solver.cpp:228] Iteration 4980, loss = 0.41612
I0625 21:44:47.975289 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:44:47.975296 20335 solver.cpp:244]     Train net output #1: loss = 0.41612 (* 1 = 0.41612 loss)
I0625 21:44:47.975301 20335 sgd_solver.cpp:106] Iteration 4980, lr = 1e-05
I0625 21:44:49.599802 20335 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_5000.caffemodel
I0625 21:44:49.621438 20335 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_5000.solverstate
I0625 21:44:49.632943 20335 solver.cpp:337] Iteration 5000, Testing net (#0)
I0625 21:44:52.739050 20335 solver.cpp:404]     Test net output #0: accuracy = 0.687988
I0625 21:44:52.739083 20335 solver.cpp:404]     Test net output #1: loss = 0.675847 (* 1 = 0.675847 loss)
I0625 21:44:52.767004 20335 solver.cpp:228] Iteration 5000, loss = 0.444316
I0625 21:44:52.767030 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:44:52.767036 20335 solver.cpp:244]     Train net output #1: loss = 0.444316 (* 1 = 0.444316 loss)
I0625 21:44:52.767041 20335 sgd_solver.cpp:106] Iteration 5000, lr = 1e-05
I0625 21:44:54.434777 20335 solver.cpp:228] Iteration 5020, loss = 0.389394
I0625 21:44:54.434803 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:44:54.434809 20335 solver.cpp:244]     Train net output #1: loss = 0.389394 (* 1 = 0.389394 loss)
I0625 21:44:54.434814 20335 sgd_solver.cpp:106] Iteration 5020, lr = 1e-05
I0625 21:44:56.094718 20335 solver.cpp:228] Iteration 5040, loss = 0.683547
I0625 21:44:56.094740 20335 solver.cpp:244]     Train net output #0: accuracy = 0.625
I0625 21:44:56.094748 20335 solver.cpp:244]     Train net output #1: loss = 0.683547 (* 1 = 0.683547 loss)
I0625 21:44:56.094753 20335 sgd_solver.cpp:106] Iteration 5040, lr = 1e-05
I0625 21:44:57.756973 20335 solver.cpp:228] Iteration 5060, loss = 0.362532
I0625 21:44:57.756997 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:44:57.757004 20335 solver.cpp:244]     Train net output #1: loss = 0.362532 (* 1 = 0.362532 loss)
I0625 21:44:57.757009 20335 sgd_solver.cpp:106] Iteration 5060, lr = 1e-05
I0625 21:44:59.419898 20335 solver.cpp:228] Iteration 5080, loss = 0.344412
I0625 21:44:59.419921 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:44:59.419929 20335 solver.cpp:244]     Train net output #1: loss = 0.344412 (* 1 = 0.344412 loss)
I0625 21:44:59.419934 20335 sgd_solver.cpp:106] Iteration 5080, lr = 1e-05
I0625 21:45:01.058257 20335 solver.cpp:337] Iteration 5100, Testing net (#0)
I0625 21:45:04.171389 20335 solver.cpp:404]     Test net output #0: accuracy = 0.699463
I0625 21:45:04.171418 20335 solver.cpp:404]     Test net output #1: loss = 0.657182 (* 1 = 0.657182 loss)
I0625 21:45:04.199447 20335 solver.cpp:228] Iteration 5100, loss = 0.333418
I0625 21:45:04.199477 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:45:04.199488 20335 solver.cpp:244]     Train net output #1: loss = 0.333418 (* 1 = 0.333418 loss)
I0625 21:45:04.199496 20335 sgd_solver.cpp:106] Iteration 5100, lr = 1e-05
I0625 21:45:05.861289 20335 solver.cpp:228] Iteration 5120, loss = 0.606923
I0625 21:45:05.861315 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:45:05.861325 20335 solver.cpp:244]     Train net output #1: loss = 0.606923 (* 1 = 0.606923 loss)
I0625 21:45:05.861330 20335 sgd_solver.cpp:106] Iteration 5120, lr = 1e-05
I0625 21:45:07.516013 20335 solver.cpp:228] Iteration 5140, loss = 0.381135
I0625 21:45:07.516041 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:45:07.516052 20335 solver.cpp:244]     Train net output #1: loss = 0.381135 (* 1 = 0.381135 loss)
I0625 21:45:07.516059 20335 sgd_solver.cpp:106] Iteration 5140, lr = 1e-05
I0625 21:45:09.168335 20335 solver.cpp:228] Iteration 5160, loss = 0.53639
I0625 21:45:09.168364 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:45:09.168373 20335 solver.cpp:244]     Train net output #1: loss = 0.53639 (* 1 = 0.53639 loss)
I0625 21:45:09.168380 20335 sgd_solver.cpp:106] Iteration 5160, lr = 1e-05
I0625 21:45:10.826009 20335 solver.cpp:228] Iteration 5180, loss = 0.39415
I0625 21:45:10.826033 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:45:10.826043 20335 solver.cpp:244]     Train net output #1: loss = 0.39415 (* 1 = 0.39415 loss)
I0625 21:45:10.826050 20335 sgd_solver.cpp:106] Iteration 5180, lr = 1e-05
I0625 21:45:12.453680 20335 solver.cpp:337] Iteration 5200, Testing net (#0)
I0625 21:45:15.563251 20335 solver.cpp:404]     Test net output #0: accuracy = 0.699707
I0625 21:45:15.563278 20335 solver.cpp:404]     Test net output #1: loss = 0.660435 (* 1 = 0.660435 loss)
I0625 21:45:15.591502 20335 solver.cpp:228] Iteration 5200, loss = 0.42239
I0625 21:45:15.591532 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:45:15.591539 20335 solver.cpp:244]     Train net output #1: loss = 0.42239 (* 1 = 0.42239 loss)
I0625 21:45:15.591544 20335 sgd_solver.cpp:106] Iteration 5200, lr = 1e-05
I0625 21:45:17.252267 20335 solver.cpp:228] Iteration 5220, loss = 0.367381
I0625 21:45:17.252364 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:45:17.252374 20335 solver.cpp:244]     Train net output #1: loss = 0.367381 (* 1 = 0.367381 loss)
I0625 21:45:17.252378 20335 sgd_solver.cpp:106] Iteration 5220, lr = 1e-05
I0625 21:45:18.911119 20335 solver.cpp:228] Iteration 5240, loss = 0.211766
I0625 21:45:18.911145 20335 solver.cpp:244]     Train net output #0: accuracy = 0.9375
I0625 21:45:18.911161 20335 solver.cpp:244]     Train net output #1: loss = 0.211766 (* 1 = 0.211766 loss)
I0625 21:45:18.911166 20335 sgd_solver.cpp:106] Iteration 5240, lr = 1e-05
I0625 21:45:20.569070 20335 solver.cpp:228] Iteration 5260, loss = 0.395951
I0625 21:45:20.569100 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:45:20.569108 20335 solver.cpp:244]     Train net output #1: loss = 0.395951 (* 1 = 0.395951 loss)
I0625 21:45:20.569113 20335 sgd_solver.cpp:106] Iteration 5260, lr = 1e-05
I0625 21:45:22.227630 20335 solver.cpp:228] Iteration 5280, loss = 0.410588
I0625 21:45:22.227660 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:45:22.227668 20335 solver.cpp:244]     Train net output #1: loss = 0.410588 (* 1 = 0.410588 loss)
I0625 21:45:22.227671 20335 sgd_solver.cpp:106] Iteration 5280, lr = 1e-05
I0625 21:45:23.860743 20335 solver.cpp:337] Iteration 5300, Testing net (#0)
I0625 21:45:24.781021 20335 blocking_queue.cpp:50] Data layer prefetch queue empty
I0625 21:45:26.970798 20335 solver.cpp:404]     Test net output #0: accuracy = 0.696777
I0625 21:45:26.970835 20335 solver.cpp:404]     Test net output #1: loss = 0.663629 (* 1 = 0.663629 loss)
I0625 21:45:26.999382 20335 solver.cpp:228] Iteration 5300, loss = 0.485232
I0625 21:45:26.999408 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:45:26.999418 20335 solver.cpp:244]     Train net output #1: loss = 0.485232 (* 1 = 0.485232 loss)
I0625 21:45:26.999425 20335 sgd_solver.cpp:106] Iteration 5300, lr = 1e-05
I0625 21:45:28.667248 20335 solver.cpp:228] Iteration 5320, loss = 0.361036
I0625 21:45:28.667274 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:45:28.667284 20335 solver.cpp:244]     Train net output #1: loss = 0.361036 (* 1 = 0.361036 loss)
I0625 21:45:28.667291 20335 sgd_solver.cpp:106] Iteration 5320, lr = 1e-05
I0625 21:45:30.328022 20335 solver.cpp:228] Iteration 5340, loss = 0.429698
I0625 21:45:30.328047 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:45:30.328054 20335 solver.cpp:244]     Train net output #1: loss = 0.429698 (* 1 = 0.429698 loss)
I0625 21:45:30.328058 20335 sgd_solver.cpp:106] Iteration 5340, lr = 1e-05
I0625 21:45:31.989570 20335 solver.cpp:228] Iteration 5360, loss = 0.297176
I0625 21:45:31.989595 20335 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 21:45:31.989614 20335 solver.cpp:244]     Train net output #1: loss = 0.297176 (* 1 = 0.297176 loss)
I0625 21:45:31.989617 20335 sgd_solver.cpp:106] Iteration 5360, lr = 1e-05
I0625 21:45:33.650549 20335 solver.cpp:228] Iteration 5380, loss = 0.454183
I0625 21:45:33.650573 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:45:33.650580 20335 solver.cpp:244]     Train net output #1: loss = 0.454183 (* 1 = 0.454183 loss)
I0625 21:45:33.650584 20335 sgd_solver.cpp:106] Iteration 5380, lr = 1e-05
I0625 21:45:35.285995 20335 solver.cpp:337] Iteration 5400, Testing net (#0)
I0625 21:45:38.536902 20335 solver.cpp:404]     Test net output #0: accuracy = 0.699219
I0625 21:45:38.536932 20335 solver.cpp:404]     Test net output #1: loss = 0.664552 (* 1 = 0.664552 loss)
I0625 21:45:38.564954 20335 solver.cpp:228] Iteration 5400, loss = 0.293394
I0625 21:45:38.564985 20335 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 21:45:38.564996 20335 solver.cpp:244]     Train net output #1: loss = 0.293394 (* 1 = 0.293394 loss)
I0625 21:45:38.565003 20335 sgd_solver.cpp:106] Iteration 5400, lr = 1e-05
I0625 21:45:40.231132 20335 solver.cpp:228] Iteration 5420, loss = 0.567877
I0625 21:45:40.231161 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:45:40.231192 20335 solver.cpp:244]     Train net output #1: loss = 0.567877 (* 1 = 0.567877 loss)
I0625 21:45:40.231200 20335 sgd_solver.cpp:106] Iteration 5420, lr = 1e-05
I0625 21:45:41.892578 20335 solver.cpp:228] Iteration 5440, loss = 0.407782
I0625 21:45:41.892609 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:45:41.892621 20335 solver.cpp:244]     Train net output #1: loss = 0.407782 (* 1 = 0.407782 loss)
I0625 21:45:41.892627 20335 sgd_solver.cpp:106] Iteration 5440, lr = 1e-05
I0625 21:45:43.553669 20335 solver.cpp:228] Iteration 5460, loss = 0.395252
I0625 21:45:43.553699 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:45:43.553710 20335 solver.cpp:244]     Train net output #1: loss = 0.395252 (* 1 = 0.395252 loss)
I0625 21:45:43.553716 20335 sgd_solver.cpp:106] Iteration 5460, lr = 1e-05
I0625 21:45:45.214473 20335 solver.cpp:228] Iteration 5480, loss = 0.386108
I0625 21:45:45.214498 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:45:45.214509 20335 solver.cpp:244]     Train net output #1: loss = 0.386108 (* 1 = 0.386108 loss)
I0625 21:45:45.214516 20335 sgd_solver.cpp:106] Iteration 5480, lr = 1e-05
I0625 21:45:46.852336 20335 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_5500.caffemodel
I0625 21:45:46.873828 20335 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_5500.solverstate
I0625 21:45:46.885309 20335 solver.cpp:337] Iteration 5500, Testing net (#0)
I0625 21:45:49.991320 20335 solver.cpp:404]     Test net output #0: accuracy = 0.698486
I0625 21:45:49.991461 20335 solver.cpp:404]     Test net output #1: loss = 0.662103 (* 1 = 0.662103 loss)
I0625 21:45:50.019743 20335 solver.cpp:228] Iteration 5500, loss = 0.529843
I0625 21:45:50.019769 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:45:50.019776 20335 solver.cpp:244]     Train net output #1: loss = 0.529843 (* 1 = 0.529843 loss)
I0625 21:45:50.019781 20335 sgd_solver.cpp:106] Iteration 5500, lr = 1e-05
I0625 21:45:51.689663 20335 solver.cpp:228] Iteration 5520, loss = 0.51013
I0625 21:45:51.689687 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:45:51.689694 20335 solver.cpp:244]     Train net output #1: loss = 0.51013 (* 1 = 0.51013 loss)
I0625 21:45:51.689699 20335 sgd_solver.cpp:106] Iteration 5520, lr = 1e-05
I0625 21:45:53.349323 20335 solver.cpp:228] Iteration 5540, loss = 0.33312
I0625 21:45:53.349349 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:45:53.349355 20335 solver.cpp:244]     Train net output #1: loss = 0.33312 (* 1 = 0.33312 loss)
I0625 21:45:53.349359 20335 sgd_solver.cpp:106] Iteration 5540, lr = 1e-05
I0625 21:45:55.011059 20335 solver.cpp:228] Iteration 5560, loss = 0.494205
I0625 21:45:55.011083 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:45:55.011091 20335 solver.cpp:244]     Train net output #1: loss = 0.494205 (* 1 = 0.494205 loss)
I0625 21:45:55.011096 20335 sgd_solver.cpp:106] Iteration 5560, lr = 1e-05
I0625 21:45:56.673043 20335 solver.cpp:228] Iteration 5580, loss = 0.379283
I0625 21:45:56.673066 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:45:56.673074 20335 solver.cpp:244]     Train net output #1: loss = 0.379283 (* 1 = 0.379283 loss)
I0625 21:45:56.673079 20335 sgd_solver.cpp:106] Iteration 5580, lr = 1e-05
I0625 21:45:58.312119 20335 solver.cpp:337] Iteration 5600, Testing net (#0)
I0625 21:46:01.395709 20335 solver.cpp:404]     Test net output #0: accuracy = 0.699707
I0625 21:46:01.395750 20335 solver.cpp:404]     Test net output #1: loss = 0.667875 (* 1 = 0.667875 loss)
I0625 21:46:01.424093 20335 solver.cpp:228] Iteration 5600, loss = 0.419953
I0625 21:46:01.424116 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:46:01.424125 20335 solver.cpp:244]     Train net output #1: loss = 0.419953 (* 1 = 0.419953 loss)
I0625 21:46:01.424130 20335 sgd_solver.cpp:106] Iteration 5600, lr = 1e-05
I0625 21:46:03.090212 20335 solver.cpp:228] Iteration 5620, loss = 0.40108
I0625 21:46:03.090234 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:46:03.090242 20335 solver.cpp:244]     Train net output #1: loss = 0.40108 (* 1 = 0.40108 loss)
I0625 21:46:03.090246 20335 sgd_solver.cpp:106] Iteration 5620, lr = 1e-05
I0625 21:46:04.751093 20335 solver.cpp:228] Iteration 5640, loss = 0.405128
I0625 21:46:04.751130 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:46:04.751137 20335 solver.cpp:244]     Train net output #1: loss = 0.405128 (* 1 = 0.405128 loss)
I0625 21:46:04.751142 20335 sgd_solver.cpp:106] Iteration 5640, lr = 1e-05
I0625 21:46:06.414656 20335 solver.cpp:228] Iteration 5660, loss = 0.384987
I0625 21:46:06.414681 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:46:06.414688 20335 solver.cpp:244]     Train net output #1: loss = 0.384987 (* 1 = 0.384987 loss)
I0625 21:46:06.414693 20335 sgd_solver.cpp:106] Iteration 5660, lr = 1e-05
I0625 21:46:08.073547 20335 solver.cpp:228] Iteration 5680, loss = 0.426328
I0625 21:46:08.073571 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:46:08.073578 20335 solver.cpp:244]     Train net output #1: loss = 0.426328 (* 1 = 0.426328 loss)
I0625 21:46:08.073582 20335 sgd_solver.cpp:106] Iteration 5680, lr = 1e-05
I0625 21:46:09.705701 20335 solver.cpp:337] Iteration 5700, Testing net (#0)
I0625 21:46:12.807875 20335 solver.cpp:404]     Test net output #0: accuracy = 0.700439
I0625 21:46:12.807910 20335 solver.cpp:404]     Test net output #1: loss = 0.658211 (* 1 = 0.658211 loss)
I0625 21:46:12.836482 20335 solver.cpp:228] Iteration 5700, loss = 0.280728
I0625 21:46:12.836530 20335 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 21:46:12.836542 20335 solver.cpp:244]     Train net output #1: loss = 0.280728 (* 1 = 0.280728 loss)
I0625 21:46:12.836550 20335 sgd_solver.cpp:106] Iteration 5700, lr = 1e-05
I0625 21:46:14.501930 20335 solver.cpp:228] Iteration 5720, loss = 0.529504
I0625 21:46:14.501955 20335 solver.cpp:244]     Train net output #0: accuracy = 0.71875
I0625 21:46:14.501965 20335 solver.cpp:244]     Train net output #1: loss = 0.529504 (* 1 = 0.529504 loss)
I0625 21:46:14.501971 20335 sgd_solver.cpp:106] Iteration 5720, lr = 1e-05
I0625 21:46:16.162569 20335 solver.cpp:228] Iteration 5740, loss = 0.433664
I0625 21:46:16.162595 20335 solver.cpp:244]     Train net output #0: accuracy = 0.78125
I0625 21:46:16.162605 20335 solver.cpp:244]     Train net output #1: loss = 0.433664 (* 1 = 0.433664 loss)
I0625 21:46:16.162611 20335 sgd_solver.cpp:106] Iteration 5740, lr = 1e-05
I0625 21:46:17.828210 20335 solver.cpp:228] Iteration 5760, loss = 0.426735
I0625 21:46:17.828235 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:46:17.828243 20335 solver.cpp:244]     Train net output #1: loss = 0.426735 (* 1 = 0.426735 loss)
I0625 21:46:17.828248 20335 sgd_solver.cpp:106] Iteration 5760, lr = 1e-05
I0625 21:46:19.491647 20335 solver.cpp:228] Iteration 5780, loss = 0.407243
I0625 21:46:19.491670 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:46:19.491677 20335 solver.cpp:244]     Train net output #1: loss = 0.407243 (* 1 = 0.407243 loss)
I0625 21:46:19.491683 20335 sgd_solver.cpp:106] Iteration 5780, lr = 1e-05
I0625 21:46:21.133018 20335 solver.cpp:337] Iteration 5800, Testing net (#0)
I0625 21:46:24.207406 20335 solver.cpp:404]     Test net output #0: accuracy = 0.70166
I0625 21:46:24.207442 20335 solver.cpp:404]     Test net output #1: loss = 0.664806 (* 1 = 0.664806 loss)
I0625 21:46:24.235712 20335 solver.cpp:228] Iteration 5800, loss = 0.397695
I0625 21:46:24.235748 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:46:24.235759 20335 solver.cpp:244]     Train net output #1: loss = 0.397695 (* 1 = 0.397695 loss)
I0625 21:46:24.235769 20335 sgd_solver.cpp:106] Iteration 5800, lr = 1e-05
I0625 21:46:25.898344 20335 solver.cpp:228] Iteration 5820, loss = 0.497982
I0625 21:46:25.898366 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:46:25.898373 20335 solver.cpp:244]     Train net output #1: loss = 0.497982 (* 1 = 0.497982 loss)
I0625 21:46:25.898377 20335 sgd_solver.cpp:106] Iteration 5820, lr = 1e-05
I0625 21:46:27.553524 20335 solver.cpp:228] Iteration 5840, loss = 0.348371
I0625 21:46:27.553549 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:46:27.553557 20335 solver.cpp:244]     Train net output #1: loss = 0.348371 (* 1 = 0.348371 loss)
I0625 21:46:27.553562 20335 sgd_solver.cpp:106] Iteration 5840, lr = 1e-05
I0625 21:46:29.207366 20335 solver.cpp:228] Iteration 5860, loss = 0.497601
I0625 21:46:29.207391 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:46:29.207398 20335 solver.cpp:244]     Train net output #1: loss = 0.497601 (* 1 = 0.497601 loss)
I0625 21:46:29.207402 20335 sgd_solver.cpp:106] Iteration 5860, lr = 1e-05
I0625 21:46:30.866097 20335 solver.cpp:228] Iteration 5880, loss = 0.387543
I0625 21:46:30.866123 20335 solver.cpp:244]     Train net output #0: accuracy = 0.84375
I0625 21:46:30.866130 20335 solver.cpp:244]     Train net output #1: loss = 0.387543 (* 1 = 0.387543 loss)
I0625 21:46:30.866137 20335 sgd_solver.cpp:106] Iteration 5880, lr = 1e-05
I0625 21:46:32.507454 20335 solver.cpp:337] Iteration 5900, Testing net (#0)
I0625 21:46:35.587628 20335 solver.cpp:404]     Test net output #0: accuracy = 0.694092
I0625 21:46:35.587666 20335 solver.cpp:404]     Test net output #1: loss = 0.663486 (* 1 = 0.663486 loss)
I0625 21:46:35.616407 20335 solver.cpp:228] Iteration 5900, loss = 0.42182
I0625 21:46:35.616442 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:46:35.616456 20335 solver.cpp:244]     Train net output #1: loss = 0.42182 (* 1 = 0.42182 loss)
I0625 21:46:35.616462 20335 sgd_solver.cpp:106] Iteration 5900, lr = 1e-05
I0625 21:46:37.276419 20335 solver.cpp:228] Iteration 5920, loss = 0.339779
I0625 21:46:37.276443 20335 solver.cpp:244]     Train net output #0: accuracy = 0.90625
I0625 21:46:37.276450 20335 solver.cpp:244]     Train net output #1: loss = 0.339779 (* 1 = 0.339779 loss)
I0625 21:46:37.276455 20335 sgd_solver.cpp:106] Iteration 5920, lr = 1e-05
I0625 21:46:38.928292 20335 solver.cpp:228] Iteration 5940, loss = 0.386174
I0625 21:46:38.928316 20335 solver.cpp:244]     Train net output #0: accuracy = 0.8125
I0625 21:46:38.928323 20335 solver.cpp:244]     Train net output #1: loss = 0.386174 (* 1 = 0.386174 loss)
I0625 21:46:38.928328 20335 sgd_solver.cpp:106] Iteration 5940, lr = 1e-05
I0625 21:46:40.582967 20335 solver.cpp:228] Iteration 5960, loss = 0.396291
I0625 21:46:40.582989 20335 solver.cpp:244]     Train net output #0: accuracy = 0.75
I0625 21:46:40.582996 20335 solver.cpp:244]     Train net output #1: loss = 0.396291 (* 1 = 0.396291 loss)
I0625 21:46:40.583001 20335 sgd_solver.cpp:106] Iteration 5960, lr = 1e-05
I0625 21:46:42.235797 20335 solver.cpp:228] Iteration 5980, loss = 0.338285
I0625 21:46:42.235822 20335 solver.cpp:244]     Train net output #0: accuracy = 0.875
I0625 21:46:42.235829 20335 solver.cpp:244]     Train net output #1: loss = 0.338285 (* 1 = 0.338285 loss)
I0625 21:46:42.235834 20335 sgd_solver.cpp:106] Iteration 5980, lr = 1e-05
I0625 21:46:43.863270 20335 solver.cpp:454] Snapshotting to binary proto file data/models/bpnet_iter_6000.caffemodel
I0625 21:46:43.885087 20335 sgd_solver.cpp:273] Snapshotting solver state to binary proto file data/models/bpnet_iter_6000.solverstate
I0625 21:46:43.920625 20335 solver.cpp:317] Iteration 6000, loss = 0.303752
I0625 21:46:43.920649 20335 solver.cpp:337] Iteration 6000, Testing net (#0)
I0625 21:46:47.039332 20335 solver.cpp:404]     Test net output #0: accuracy = 0.700684
I0625 21:46:47.039363 20335 solver.cpp:404]     Test net output #1: loss = 0.660068 (* 1 = 0.660068 loss)
I0625 21:46:47.039369 20335 solver.cpp:322] Optimization Done.
I0625 21:46:47.039373 20335 caffe.cpp:222] Optimization Done.
